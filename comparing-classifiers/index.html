<!DOCTYPE html>
<html lang="en">
  <!-- type: head.html -->
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    
    

    
        <meta name="thumbnail" content="//martin-thoma.com/images/logos/ml.png" />
        <meta property="og:image" content="//martin-thoma.com/images/logos/ml.png" />
    

    <meta property="og:type" content="blog"/>

    <title>Comparing Classifiers</title>
    <link rel="stylesheet" href="//martin-thoma.com/css/screen.css" type="text/css" media="screen" />
    <link rel="stylesheet" href="//martin-thoma.com/css/style.css" type="text/css" media="screen" />
    <link rel="stylesheet" href="//martin-thoma.com/css/pygments.css" type="text/css" media="screen" />
    <link rel="stylesheet" href="//martin-thoma.com/css/tocplus-screen.css" type="text/css" media="screen" />
    <link rel="stylesheet" href="//martin-thoma.com/css/print.css" type="text/css" media="print" />
    <link rel="stylesheet" href="//martin-thoma.com/css/handheld.css" type="text/css" media="only screen and (max-device-width: 480px)" />

    <link rel="alternate" type="application/rss+xml" title="Martin Thoma RSS Feed" href="//martin-thoma.com/feed/" /><!--TODO-->
    <link rel="shortcut icon" href="//martin-thoma.com/favicon.ico" type="image/x-icon" />

    <link rel="canonical" href="//martin-thoma.com/comparing-classifiers" />
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:site" content="@themoosemind"/>
<meta name="twitter:creator" content="@themoosemind"/>
<meta name="twitter:title" content="Comparing Classifiers"/>

    <meta name="twitter:description" content="A blog about Code, the Web and Cyberculture" />


    <meta name="twitter:image" content="//martin-thoma.com/images/logos/ml.png"/>



<meta name="twitter:url" content="//martin-thoma.com/comparing-classifiers"/>
<meta name="twitter:domain" content="Martin Thoma.com"/>


    <script type='text/javascript' src="//martin-thoma.com/js/jquery.js"></script>
    <script type='text/javascript' src="//martin-thoma.com/js/jquery-migrate.min.js"></script>
    <style type="text/css">div#toc_container {width: 275px;}</style>
    <style type="text/css" id="syntaxhighlighteranchor"></style>

<!-- MathJax -->
<script type="text/x-mathjax-config">
<!--
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [ ['$$', '$$'], ['\\[','\\]'], ['<div class="latex">', '</div>']],
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
    processEscapes: true
  }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
// -->
</script>
<script type="text/javascript" async
  src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<!-- Latest compiled and minified CSS bootstrap -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
</head>

<!-- type: post.html -->
<body>
    <div id="wrapper">
        <div id="container" class="container">
            <div class="span-16">
                <!-- type: header.html -->
<div id="header" role="banner">
    <h1><a href="//martin-thoma.com">Martin Thoma</a></h1>
    <h2 style="margin-top: 0;">A blog about Code, the Web and Cyberculture.</h2>
</div>
<nav class="navcontainer" role="navigation">
    <ul id="nav">
        <li class=""><a href="//martin-thoma.com">Home</a></li>
        <li class="page_item page-item-41 "><a href="//martin-thoma.com/author/martin-thoma/">About Me</a></li>
        <li class="page_item page-item-91 "><a href="//martin-thoma.com/imprint/">Imprint</a></li>
    </ul>
</nav>

                <div id="content">
                    <article class="post type-post format-standard hentry clearfix ">
                        <h2 class="title entry-title">Comparing Classifiers</h2>
                        <div class="postdate entry-date">
                            <time datetime="2016-01-19T20:13:00+01:00">
                                January
                                19th,
                                  
                                2016
                            </time>
                        </div>

                        <div class="entry">
                            <p>Classification problems occur quite often and many different classification
algorithms have been described and implemented. But what is the best algorithm
for a given error function and dataset?</p>

<p>I read questions like "I have problem X. What is the best classifier?" quite
often and my first impulse is always to write: Just try them!</p>

<p>I guess people asking this question might think that it is super difficult to
do so. However, the sklearn tutorial contains a very nice example where
many classifiers are compared (<a href="http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html">source</a>).</p>

<p>This article gives you an overview over some classifiers:</p>

<ul>
<li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html">SVM</a></li>
<li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html">k-nearest neighbors</a></li>
<li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">Random Forest</a></li>
<li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html">AdaBoost Classifier</a></li>
<li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html">Gradient Boosting</a></li>
<li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html">Naive Bayes</a></li>
<li><a href="http://scikit-learn.org/0.16/modules/generated/sklearn.lda.LDA.html">LDA</a></li>
<li><a href="http://scikit-learn.org/0.16/modules/generated/sklearn.qda.QDA.html">QDA</a></li>
</ul>

<p>Of course, neural networks are also one very powerful ML classifier I may not
forget. As sklearn does not have neural networks, I've installed
<a href="https://github.com/tensorflow/skflow"><code>skflow</code></a>.</p>

<div id="toc_container" class="toc_light_blue no_bullets">
   <p class="toc_title">Contents</p>
   <ul class="toc_list">
      <li class="toc_level-1 toc_section-1">
         <a href="#tocAnchor-1-1"><span class="tocnumber">1</span> <span class="toctext">Tutorial example</span></a>
      </li>
      <li class="toc_level-1 toc_section-2">
         <a href="#tocAnchor-1-2"><span class="tocnumber">2</span> <span class="toctext">MNIST</span></a>
         <ul>
            <li class="toc_level-2 toc_section-3">
               <a href="#tocAnchor-1-2-1"><span class="tocnumber">2.1</span> <span class="toctext">Neural Networks</span></a>
            </li>
            <li class="toc_level-2 toc_section-4">
               <a href="#tocAnchor-1-2-2"><span class="tocnumber">2.2</span> <span class="toctext">SVM</span></a>
            </li>
            <li class="toc_level-2 toc_section-5">
               <a href="#tocAnchor-1-2-3"><span class="tocnumber">2.3</span> <span class="toctext">Random Forest</span></a>
            </li>
            <li class="toc_level-2 toc_section-6">
               <a href="#tocAnchor-1-2-4"><span class="tocnumber">2.4</span> <span class="toctext">k nearest neightbors</span></a>
            </li>
            <li class="toc_level-2 toc_section-7">
               <a href="#tocAnchor-1-2-5"><span class="tocnumber">2.5</span> <span class="toctext">Decision Tree</span></a>
            </li>
            <li class="toc_level-2 toc_section-8">
               <a href="#tocAnchor-1-2-6"><span class="tocnumber">2.6</span> <span class="toctext">Adaboost</span></a>
            </li>
            <li class="toc_level-2 toc_section-9">
               <a href="#tocAnchor-1-2-7"><span class="tocnumber">2.7</span> <span class="toctext">Gradient Boosting</span></a>
            </li>
            <li class="toc_level-2 toc_section-10">
               <a href="#tocAnchor-1-2-8"><span class="tocnumber">2.8</span> <span class="toctext">Naive Bayes</span></a>
            </li>
            <li class="toc_level-2 toc_section-11">
               <a href="#tocAnchor-1-2-9"><span class="tocnumber">2.9</span> <span class="toctext">LDA</span></a>
            </li>
            <li class="toc_level-2 toc_section-12">
               <a href="#tocAnchor-1-2-10"><span class="tocnumber">2.10</span> <span class="toctext">QDA</span></a>
            </li>
         </ul>
      </li>
      <li class="toc_level-1 toc_section-13">
         <a href="#tocAnchor-1-13"><span class="tocnumber">3</span> <span class="toctext">MNIST Summary</span></a>
      </li>
      <li class="toc_level-1 toc_section-14">
         <a href="#tocAnchor-1-14"><span class="tocnumber">4</span> <span class="toctext">IRIS summary</span></a>
      </li>
      <li class="toc_level-1 toc_section-15">
         <a href="#tocAnchor-1-15"><span class="tocnumber">5</span> <span class="toctext">TL;DR</span></a>
      </li>
   </ul>
</div><h2 id="tocAnchor-1-1">Tutorial example</h2>

<p>The sklearn tutorial creates three datasets with 100&amp;nbps;points per dataset and
2Â dimensions per point:</p>

<ol>
<li><strong>Moons</strong>: Two interleaving half-circles</li>
<li><strong>Circles</strong>: A larger circle containing the smaller one</li>
<li><strong>Linear</strong>: A linearly seperable dataset</li>
</ol>

<p>Each of those three datasets has added noise. This means for some points there
might be no way of classifying them correclty.</p>

<p>Here are the results</p>

<div style="width: 510px" class="wp-caption aligncenter">
   <a href="../images/2016/01/ml-classifiers-1.png">
      <img src="//martin-thoma.com/captions/ml-classifiers-1.png" alt="k nearest neighbors, linear and RBFSVM" width="500" height="357" class="" />
   </a>
   <p class="wp-caption-text">k nearest neighbors, linear and RBFSVM</p>
</div>

<p>One can see that k nearest neighbors gives arbitrary decision boundaries.
Overall, they look reasonable. However, there are often strange zig-zag
patterns.</p>

<p>The linear SVM in contrast has a very easy decision boundary: a line. It is no
suprise that it can't deal with the moons dataset. Note that a random guess
would be right in 50% of the cases.</p>

<p>The RBF SVM has very nice decision boundary. It is smooth, matches the pattern
and is able to adjust to all three examles.</p>

<div style="width: 510px" class="wp-caption aligncenter">
   <a href="../images/2016/01/ml-classifiers-2.png">
      <img src="//martin-thoma.com/captions/ml-classifiers-2.png" alt="Decision Tree, Random Forest, AdaBoost" width="500" height="363" class="" />
   </a>
   <p class="wp-caption-text">Decision Tree, Random Forest, AdaBoost</p>
</div>

<p>Decision Trees, Decision Forests and AdaBoost all show very similar
patterns. The boundaries change in parallel to the coordinate axes which looks
very unnatural.</p>

<div style="width: 510px" class="wp-caption aligncenter">
   <a href="../images/2016/01/ml-classifiers-3.png">
      <img src="//martin-thoma.com/captions/ml-classifiers-3.png" alt="Naive Bayes, LDA, QDA" width="500" height="342" class="" />
   </a>
   <p class="wp-caption-text">Naive Bayes, LDA, QDA</p>
</div>

<p>Naive Bayes shows nice, smooth patterns. However, those patterns seem to be
a bit too simple. LDA is again linear (see linear SVM). Comparing QDA to
Naive Bayes is interesting. Although they get similar performance for the first
dataset, I would argue that the naive bayes classifier is much better as it is
much more confident for its classification. Even more extrem is the last example.
I'm astonished that the QDA gets 93% with that boundary; Naive Bayes seems to
find a much better boundary.</p>

<h2 id="tocAnchor-1-2">MNIST</h2>

<p>MNIST is a dataset of (28\text{px} \times 28\text{px}) greyscale images.
Each of the images contains a digit (0, 1, 2, 3, 4, 5, 6, 7, 8, 9). The
task is to classify the image into one of the 10 digit classes.</p>

<p>Guessing randomly will give an accuracy of (\frac{1}{10} = 0.1).</p>

<h3 id="tocAnchor-1-2-1">Neural Networks</h3>

<p>Please note that there are neural networks which get much better accuracy.
Most notably the <a href="https://www.tensorflow.org/versions/master/tutorials/mnist/pros/index.html#deep-mnist-for-experts">MNIST Expert tutorial</a> with 99.2% accuracy.</p>

<h4 id="simple-network">Simple Network</h4>
<div class="highlight">
   <pre><code class="language-text" data-lang="text">Classifier: NN 500:200
Training time: 79.5696s
Testing time: 0.3480s
Confusion matrix:
[[2248    1    5    1    2    4    8    2    5    2]
 [   1 2565   10    1    1    0    2    7    1    0]
 [   7    2 2258   14    5    0    9    6   10    3]
 [   0    0   12 2294    0   23    0    6    3   10]
 [   0    3    3    0 2161    0    8    5    1   30]
 [   4    1    1   16    1 2014   17    1    5    9]
 [  11    7    1    0    5    6 2237    0    4    0]
 [   3    6   14    7    3    1    0 2355   10   18]
 [   3    7    3   14    2   17    4    1 2161    3]
 [   4    4    0    4   16    8    0    7    6 2340]]
Accuracy: 0.9798
</code></pre>
</div>
<h4 id="dropout-network">Dropout Network</h4>
<div class="highlight">
   <pre><code class="language-text" data-lang="text">Classifier: NN 500:200 dropout
Training time: 118.2654s
Testing time: 0.3918s
Confusion matrix:
[[2250    1    7    1    1    1    5    4    4    4]
 [   1 2567    9    1    1    0    0    3    5    1]
 [   6    6 2272    3    2    1    3   10    8    3]
 [   0    0   26 2260    0   24    0   10   19    9]
 [   0    3    5    0 2152    0    7    3    1   40]
 [   8    3    3   12    2 1983   20    6   21   11]
 [  11    6    3    0    7    1 2237    0    6    0]
 [   2    7   13    3   11    0    1 2363    5   12]
 [   7    7    9    5    3    3    1    2 2170    8]
 [   3    3    1    3   13    2    0   19    8 2337]]
Accuracy: 0.9780
</code></pre>
</div>
<h4 id="cnn">CNN</h4>
<div class="highlight">
   <pre><code class="language-text" data-lang="text">Classifier: CNN
Training time: 391.8810s
Testing time: 1.2035s
Confusion matrix:
[[2243    0    5    0    0    5    9    1   12    3]
 [   1 2548   20    4    2    0    1    6    6    0]
 [   3    8 2253    9    3    1    4   17   14    2]
 [   0    4   13 2290    0   12    0    9   11    9]
 [   2    4    5    0 2164    0    8    5    3   20]
 [   6    2    3   15    0 2016    9    3    9    6]
 [  12   12    1    1    6    6 2227    0    6    0]
 [   3    4   11    3    4    1    0 2374    4   13]
 [   3   15    6   13    4   11    3    8 2145    7]
 [   6    5    0   11   16    8    0   24   13 2306]]
Accuracy: 0.9769
</code></pre>
</div>
<h3 id="tocAnchor-1-2-2">SVM</h3>

<p>There is a ton of literature / papers about <abbr title="Support Vector Machines">SVMs</abbr>.
I've summed up the basics on <a href="https://martin-thoma.com/svm-with-sklearn/">Using SVMs with sklearn</a>.</p>

<p>I've trained two SVMs: A simple, linear one and one with an RBF kernel as I
found it online (I'm sorry, I don't remember where I found those parameters :-/).</p>

<h4 id="linear-svm">Linear SVM</h4>
<div class="highlight">
   <pre><code class="language-text" data-lang="text">Classifier: linear SVM
Training time: 168.6950s
Testing time: 158.0101s
Confusion matrix:
[[2226    0    9    2    6   12    8    3   11    1]
 [   1 2537   18    3    3    1    1    7   17    0]
 [  12   16 2158   25   24    6   27   19   25    2]
 [   3    7   46 2188    4   47    3   18   27    5]
 [   2    5   19    1 2117    1    8    6    3   49]
 [  18   13   11   73   20 1872   31    0   26    5]
 [  20    6   22    1   10   30 2179    0    3    0]
 [   5   10   32   11   30    5    0 2268    5   51]
 [  11   39   26   47   10   40    7    7 2018   10]
 [  11    9    9   24   64    8    0   61   14 2189]]
Accuracy: 0.9416
</code></pre>
</div>
<h4 id="adjusted-svm">Adjusted SVM</h4>
<div class="highlight">
   <pre><code class="language-text" data-lang="text">Classifier: adj. SVM
Training time: 347.1539s
Testing time: 234.5724s
Confusion matrix:
[[2258    1    4    1    2    2    3    1    4    2]
 [   1 2566    9    1    1    0    0    7    3    0]
 [   4    1 2280    5    4    0    1    9    8    2]
 [   0    0   14 2304    1   13    0    6    8    2]
 [   2    2    2    0 2183    0    7    5    0   10]
 [   4    0    0   16    3 2026   12    1    4    3]
 [   7    5    3    0    5    2 2245    0    4    0]
 [   1    6   11    2    5    1    0 2373    5   13]
 [   3    9    4    9    4   10    2    3 2166    5]
 [   3    2    2    6   19    6    0   12   10 2329]]
Accuracy: 0.9840
</code></pre>
</div>
<h3 id="tocAnchor-1-2-3">Random Forest</h3>

<p>Data:</p>

<ul>
<li><code>n_estimators=50</code></li>
<li><code>n_jobs=10</code></li>
</ul>
<div class="highlight">
   <pre><code class="language-text" data-lang="text">Classifier: Random Forest
Training time: 2.1359s
Testing time: 26.0763s
Confusion matrix:
[[2246    1    4    1    4    2    7    2   11    0]
 [   1 2543   18    5    5    2    3    7    4    0]
 [   7    2 2233   20    9    2    9   16   14    2]
 [   0    3   36 2240    0   20    3   16   19   11]
 [   3    1    5    0 2142    1   11    3    7   38]
 [   7    4    4   30    6 1977   16    3   14    8]
 [  13   11    4    0   10   15 2210    0    8    0]
 [   3    8   29    2   19    0    0 2315    7   34]
 [   3   12   18   17    9   26    4    7 2103   16]
 [  10    6    6   24   27   13    3   20   18 2262]]
Accuracy: 0.9641
</code></pre>
</div>
<p>Alternatively:</p>

<ul>
<li><code>max_depth=5</code></li>
<li><code>n_estimators=10</code></li>
<li><code>max_features=1</code></li>
</ul>
<div class="highlight">
   <pre><code class="language-text" data-lang="text">Classifier: Random Forest 2
Training time: 0.2077s
Testing time: 22.2770s
Confusion matrix:
[[1955   32   63   64   12    4  109   21   13    5]
 [   1 2524   20   14    1    6   10    6    6    0]
 [ 252  425 1198  151   64    1  145   15   55    8]
 [ 136  195  140 1641   28   11   22   95   65   15]
 [  92  320   21   45 1199    9   76  153    8  288]
 [ 312  383   67  655   78  268   47   94  134   31]
 [ 199  364  125   58   96   13 1408    5    2    1]
 [  83  424   10   70  101    1   19 1555   56   98]
 [ 392  574   44  147   52   17   71  106  773   39]
 [  71  338   11   43  579    2    8  632   24  681]]
Accuracy: 0.5715
</code></pre>
</div>
<h3 id="tocAnchor-1-2-4">k nearest neightbors</h3>
<div class="highlight">
   <pre><code class="language-text" data-lang="text">Classifier: k nn
Training time: 4.6439s
Testing time: 1261.7815s
Confusion matrix:
[[2260    1    4    0    0    1    6    2    2    2]
 [   0 2572    5    0    0    0    1    8    1    1]
 [  16   15 2235    9    1    0    5   26    5    2]
 [   2    5   14 2276    0   27    1    8    9    6]
 [   4   19    0    0 2131    0    8    4    0   45]
 [  10    5    3   28    5 1977   25    2    4   10]
 [  12    9    0    0    4    7 2239    0    0    0]
 [   1   18    4    1   12    0    0 2349    3   29]
 [  11   32    8   36   11   34    5    7 2053   18]
 [   6    8    4   14   26    4    0   19    5 2303]]
Accuracy: 0.9695
</code></pre>
</div>
<h3 id="tocAnchor-1-2-5">Decision Tree</h3>

<p>Data:</p>

<ul>
<li><code>max_depth=5</code></li>
</ul>
<div class="highlight">
   <pre><code class="language-text" data-lang="text">Classifier: Decision Tree
Training time: 3.1346s
Testing time: 0.0313s
Confusion matrix:
[[1767    0   11   25   12  120  137   71  114   21]
 [   1 2065  128  108   13   17   41   66  131   18]
 [  42   44 1248   37  121   21  227   76  339  159]
 [  33   22   32 1484   33  107   52   81  266  238]
 [   0   15   45   33 1284   42   42   45  213  492]
 [  42   10   21  229  166  577  137  123  254  510]
 [  34   33   66   24  103   65 1734   24  102   86]
 [  10   14  179   57   53   21   19 1775   79  210]
 [   1   98  129   43   43   42  160   29 1439  231]
 [   4    8   86   59  125   95   36   75  167 1734]]
Accuracy: 0.6540
</code></pre>
</div>
<h3 id="tocAnchor-1-2-6">Adaboost</h3>

<p>You should note that you can use arbitrary base classifiers with Adaboost.
The default ones of <a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html"><code>sklearn.ensemble.AdaBoostClassifier</code></a> is <a href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"><code>sklearn.tree.DecisionTreeClassifies</code></a></p>
<div class="highlight">
   <pre><code class="language-text" data-lang="text">Classifier: AdaBoost
Training time: 37.6443s
Testing time: 1.5815s
Confusion matrix:
[[1994    0   75    8    6  113   51    3   15   13]
 [   0 2435   27   22    2   10   12   37   42    1]
 [  97   39 1341   85   39   38  416   39  196   24]
 [ 108   52   37 1508   13  313   66   64  122   65]
 [  11   16   48   23 1662   49   23  134   90  155]
 [  81   56   30  309   51 1255   57   17  129   84]
 [  29   28  151    7   80   43 1914    2   17    0]
 [  25   37   33   36   70   30    0 1761   37  388]
 [  30   80   48  215   16   85   30   19 1615   77]
 [  13   29   68   66  356   74    1  171   78 1533]]
Accuracy: 0.7367
</code></pre>
</div>
<h3 id="tocAnchor-1-2-7">Gradient Boosting</h3>

<p>Gradient boosting with <code>xgboost</code> has won in the Rossmann Store Sales prediction
(<a href="http://blog.kaggle.com/2015/12/21/rossmann-store-sales-winners-interview-1st-place-gert/">source</a>).</p>

<p>See also:</p>

<ul>
<li><a href="http://blog.kaggle.com/2015/09/22/caterpillar-winners-interview-1st-place-gilberto-josef-leustagos-mario/">Caterpillar Winners' Interview</a></li>
<li><a href="http://blog.kaggle.com/2015/10/20/caterpillar-winners-interview-3rd-place-team-shift-workers/">Caterpillar Winners' Interview: 3rd place</a></li>
<li><a href="http://blog.kaggle.com/2015/09/28/liberty-mutual-property-inspection-winners-interview-qingchen-wang/">Liberty Mutual Property Inspection, Winner's Interview</a></li>
<li><a href="http://blog.kaggle.com/2015/10/21/recruit-coupon-purchase-winners-interview-2nd-place-halla-yang/">Recruit Coupon Purchase Winner's Interview: 2nd place</a></li>
<li><a href="http://blog.kaggle.com/2015/10/30/dato-winners-interview-2nd-place-mortehu/">Dato Truly Native? Winner's Interview: 2nd place</a></li>
</ul>
<div class="highlight">
   <pre><code class="language-text" data-lang="text">Classifier: Gradient Boosting
Training time: 2409.8094s
Testing time: 0.4159s
Confusion matrix:
[[2214    1    3    5   10    8    9    3   24    1]
 [   1 2528   16   11    3    5    5    7    9    3]
 [   8    5 2165   34   16    5   12   22   37   10]
 [   1    9   27 2182    4   42    1   22   37   23]
 [   5    4   16    1 2088    5   12    5   10   65]
 [   9    6    7   41    8 1928   27    6   18   19]
 [  15    7    4    1   19   29 2181    1   14    0]
 [   6   16   27   15   22    6    0 2246    8   71]
 [   5   20   14   25   15   29    6    6 2057   38]
 [   6   10    8   24   49   15    1   54   17 2205]]
Accuracy: 0.9435
</code></pre>
</div>
<h3 id="tocAnchor-1-2-8">Naive Bayes</h3>
<div class="highlight">
   <pre><code class="language-text" data-lang="text">Classifier: Naive Bayes
Training time: 0.3814s
Testing time: 0.8863s
Confusion matrix:
[[2094    4   11   10    6    7   56    3   69   18]
 [   4 2432    9   11    2    4   28    1   77   20]
 [ 278   64  703  143    6    4  558    4  528   26]
 [ 202  136   18  791    5    5  106   21  886  178]
 [  96   26   16   14  296    8  169   13  535 1038]
 [ 327   63   15   39   14   87  100    5 1253  166]
 [  34   51   17    1    1    5 2109    0   52    1]
 [  19   21    3   23   20    2    7  737  123 1462]
 [  39  326   13   16    8   18   25    7 1482  281]
 [  15   26    8    2   14    2    1   41   40 2240]]
Accuracy: 0.5615
</code></pre>
</div>
<h3 id="tocAnchor-1-2-9">LDA</h3>
<div class="highlight">
   <pre><code class="language-text" data-lang="text">Classifier: LDA
Training time: 20.6464s
Testing time: 0.0910s
Confusion matrix:
[[2131    2   10   14   12   47   20    4   36    2]
 [   0 2454   20   10    5   16    5    5   71    2]
 [  22   71 1873   77   51    8   82   20  101    9]
 [   5   32   56 1992   11   77   11   40   80   44]
 [   1   21   17    0 1983   12   12    2   21  142]
 [  19   18   11  112   18 1682   37   11  103   58]
 [  28   30   32    3   43   51 2046    0   37    1]
 [  16   57   25   20   70    8    0 1990   11  220]
 [   9  113   16   64   33  115   13   10 1781   61]
 [  15   10    6   35  133   14    0  122   22 2032]]
Accuracy: 0.8642
</code></pre>
</div>
<h3 id="tocAnchor-1-2-10">QDA</h3>
<div class="highlight">
   <pre><code class="language-text" data-lang="text">Classifier: QDA
Training time: 23.0527s
Testing time: 6.2259s
Confusion matrix:
[[2212    3   12   14    1    4   20    5    6    1]
 [  66 2409   12   10    0    0   32    2   39   18]
 [ 961   25  689  143    3    1  310    2  166   14]
 [1231   48   29  606    3   13   66   10  232  110]
 [ 810   22   25   27  250    4  143   17  345  568]
 [ 909   15   13   33    1  214  140    4  666   74]
 [  83   18   14    1    1    2 2146    0    6    0]
 [  81   13    6   52   14    2    1  776  120 1352]
 [ 487  181   18   20    6   17   58    3 1320  105]
 [  65   14   12    7   10    0    0   23   33 2225]]
Accuracy: 0.5561
</code></pre>
</div>
<h2 id="tocAnchor-1-13">MNIST Summary</h2>

<table class="table">
  <thead>
    <tr>
        <th>Classifier</th>
        <th>Accuracy</th>
        <th>Training Time</th>
        <th>Testing Time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
        <td>MLP (500:200)</td>
        <td align="right">97.98%</td>
        <td align="right">79.5696s</td>
        <td align="right">0.3480s</td>
    </tr>
    <tr>
        <td>Dropout NN (500:200)</td>
        <td align="right">97.80%</td>
        <td align="right">118.2654s</td>
        <td align="right">0.3918s</td>
    </tr>
    <tr>
        <td>CNN<br />(32 5Ã5 filters : 2Ã2 max pool : 64 5Ã5 filters : 2Ã2 max pool : 1024)</td>
        <td align="right">97.69%</td>
        <td align="right">391.8810s</td>
        <td align="right">1.2035s</td>
    </tr>
    <tr>
        <td>Adjusted SVM</td>
        <td align="right"><b>98.40%</b></td>
        <td align="right">347.1539s</td>
        <td align="right" class="danger">234.5724s</td>
    </tr>
    <tr>
        <td>Linear SVM</td>
        <td align="right">94.16%</td>
        <td align="right">168.6950s</td>
        <td align="right" class="danger">158.0101s</td>
    </tr>
    <tr>
        <td>Random Forest (n_estimators=50, n_jobs=10)</td>
        <td align="right">96.41%</td>
        <td align="right">2.1359s</td>
        <td align="right" class="danger">26.0763s</td>
    </tr>
    <tr>
        <td>Random Forest (n_estimators=10, max_features=1, max_depth=5)</td>
        <td align="right" class="danger">57.15%</td>
        <td align="right"><b>0.2077s</b></td>
        <td align="right" class="danger">22.2770s</td>
    </tr>
    <tr>
        <td>k nearest neightbors (k=3)</td>
        <td align="right">96.95%</td>
        <td align="right">4.6439s</td>
        <td align="right" class="danger">1261.7815s</td>
    </tr>
    <tr>
        <td>Decision Tree(max_depth=5)</td>
        <td align="right" class="danger">65.40%</td>
        <td align="right">3.1346s</td>
        <td align="right"><b>0.0313s</b></td>
    </tr>
    <tr>
        <td>Adaboost</td>
        <td align="right" class="danger">73.67%</td>
        <td align="right">37.6443s</td>
        <td align="right">1.5815s</td>
    </tr>
    <tr>
        <td>Naive Bayes</td>
        <td align="right" class="danger">56.15%</td>
        <td align="right">0.3814s</td>
        <td align="right">0.8863s</td>
    </tr>
    <tr>
        <td>LDA</td>
        <td align="right">86.42%</td>
        <td align="right">20.6464s</td>
        <td align="right">0.0910s</td>
    </tr>
    <tr>
        <td>QDA</td>
        <td align="right" class="danger">55.61%</td>
        <td align="right">23.0527s</td>
        <td align="right" class="danger">6.2259s</td>
    </tr>
    <tr>
        <td>Gradient Boosting</td>
        <td align="right" class="danger">94.35%</td>
        <td align="right">2409.8094s</td>
        <td align="right">0.4159s</td>
    </tr>
  </tbody>
</table>

<h2 id="tocAnchor-1-14">IRIS summary</h2>

<p>Just for fun, I tried the script from above with very minor adjustments to the
<a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">IRIS flower dataset</a>:</p>

<table class="table">
  <thead>
    <tr>
        <th>Classifier</th>
        <th>Accuracy</th>
        <th>Training Time</th>
        <th>Testing Time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
        <td>AdaBoost</td>
        <td align="right">92.00%</td>
        <td align="right">0.1203s</td>
        <td align="right">0.0101s</td>
    </tr>
    <tr>
        <td>Decision Tree</td>
        <td align="right">92.00%</td>
        <td align="right">0.0005s</td>
        <td align="right"><b>0.0001s</b></td>
    </tr>
    <tr>
        <td>Gradient Boosting</td>
        <td align="right">92.00%</td>
        <td align="right">0.2227s</td>
        <td align="right">0.0007s</td>
    </tr>
    <tr>
        <td>LDA</td>
        <td align="right"><b>96.00%</b></td>
        <td align="right">0.0027s</td>
        <td align="right">0.0002s</td>
    </tr>
    <tr>
        <td>NN 20:5</td>
        <td align="right">90.00%</td>
        <td align="right">1.6628s</td>
        <td align="right">0.0046s</td>
    </tr>
    <tr>
        <td>Naive Bayes</td>
        <td align="right">90.00%</td>
        <td align="right">0.0010s</td>
        <td align="right">0.0004s</td>
    </tr>
    <tr>
        <td>QDA</td>
        <td align="right">94.00%</td>
        <td align="right">0.0009s</td>
        <td align="right">0.0003s</td>
    </tr>
    <tr>
        <td>Random Forest</td>
        <td align="right">90.00%</td>
        <td align="right">0.2147s</td>
        <td align="right">0.1395s</td>
    </tr>
    <tr>
        <td>Random Forest 2</td>
        <td align="right">90.00%</td>
        <td align="right">0.1481s</td>
        <td align="right">0.1249s</td>
    </tr>
    <tr>
        <td>SVM, adj.</td>
        <td align="right">90.00%</td>
        <td align="right">0.0010s</td>
        <td align="right">0.0004s</td>
    </tr>
    <tr>
        <td>SVM, linear</td>
        <td align="right" class="danger">88.00%</td>
        <td align="right">0.0006s</td>
        <td align="right">0.0002s</td>
    </tr>
    <tr>
        <td>k nn</td>
        <td align="right">92.00%</td>
        <td align="right">0.0007s</td>
        <td align="right">0.0009s</td>
    </tr>
</tbody>
</table>

<h2 id="tocAnchor-1-15">TL;DR</h2>

<p>Neural networks take their time to train and a feeling for the topology, but
their classification results are nice and the testing time is good as well.</p>

<p>Random Forests and SVMs are also a model a type of model one should think of.
However, the stard implementation is very slow compared to neural networks.</p>

<p><a href="http://scikit-learn.org/0.16/modules/generated/sklearn.lda.LDA.html"><code>sklearn.lda.LDA</code></a>
might also be worth a try. The rest seems to be quite bad compared with those
classifiers.</p>

<p>The code which generated the examples from above is <a href="https://github.com/MartinThoma/algorithms/tree/master/ML/mnist/many-classifiers">here</a>.</p>

                        </div>
                        <div class="postmeta">Posted in
                            
                                <a href="//martin-thoma.com/category/cyberculture/">cyberculture</a><!--TODO: Displayed category name should be upper case! -->
                             | Tags:
                            
                                
                                    <a href="//martin-thoma.com/tag/python/">Python</a>
                                
                            
                                , <a href="//martin-thoma.com/tag/machine-learning/">Machine Learning</a>
                                
                            
                                , <a href="//martin-thoma.com/tag/classification/">Classification</a>
                                
                             by <a rel="author" class="vcard author" href="//martin-thoma.com/author/martin-thoma/"><span class="fn">Martin Thoma</span></a> on <span class="updated"><span class="value-title" title="2016-01-19 20:13:00 +0100">
                                January
                                19th
                                  ,
                                2016</span></span></div>

                            <div class="navigation clearfix">
                                <div class="alignleft">
                                
                                    &laquo; <a href="//martin-thoma.com/function-approximation/" rel="prev">Function Approximation</a>
                                
                                </div>
                                <div class="alignright">
                                
                                </div>
                            </div>

                        </article>
                        <div id="respond">
                            <h3>Leave a Reply</h3>
                                <!-- comment discuss code -->
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'martinthoma'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="//disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    <!-- comment discuss code -->

                        </div>
                    </div>
                </div>
            <div class="span-8 last">
                <div id="subscriptions">
<a href="//martin-thoma.com/feed/"><img src="//martin-thoma.com/css/images/rss.png" alt="Subscribe to RSS Feed" title="Subscribe to RSS Feed" width="72" height="47" /></a>		
<a href="https://twitter.com/#!/themoosemind" title="Follow me on Twitter!"><img src="//martin-thoma.com/css/images/twitter.png" title="Follow me on Twitter!" alt="Follow me on Twitter!"  width="76" height="47" /></a>
</div>

                <div id="sidebar">
                <!-- type: searchbox.html - TODO-->
<ul>
    <li id="search">
        <div class="searchlayout">
            <form method="get" id="searchform" action="//google.com/cse" role="search">
                <input type="hidden" name="cx" value="017345337424948206369:qrnnnentkkk" />
                <input type="search" value="" name="q" id="s" placeholder="Search with Google"/>
                <input type="image" src="//martin-thoma.com/css/images/search.gif" style="border:0; vertical-align: top;" alt="search"/> 
            </form>
        </div>
    </li>
</ul>

                <div class="addthis_toolbox">   
    <div class="custom_images">
            <a href="//twitter.com/share?url=//martin-thoma.com/comparing-classifiers&amp;hashtags=python,machine-learning,classification,&amp;via=themoosemind" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/twitter.png" width="32" height="32" alt="Twitter" /></a>
            <a href="//del.icio.us/post?url=//martin-thoma.com/comparing-classifiers&amp;title=Comparing%20Classifiers" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/delicious.png" width="32" height="32" alt="Delicious" /></a>
            <a href="//www.facebook.com/sharer.php?u=//martin-thoma.com/comparing-classifiers" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/facebook.png" width="32" height="32" alt="Facebook" /></a>
            <a href="//digg.com/submit?phase=2&amp;url=//martin-thoma.com/comparing-classifiers&amp;title=Comparing%20Classifiers" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/digg.png" width="32" height="32" alt="Digg" /></a>
            <a href="//www.stumbleupon.com/submit?url=//martin-thoma.com/comparing-classifiers&amp;title=Comparing%20Classifiers" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/stumbleupon.png" width="32" height="32" alt="Stumbleupon" /></a>
            <a href="//plusone.google.com/_/+1/confirm?hl=en&amp;url=//martin-thoma.com/comparing-classifiers" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/gplus.png" width="32" height="32" alt="Google Plus" /></a>
            <a href="//reddit.com/submit?url=//martin-thoma.com/comparing-classifiers&amp;title=Comparing%20Classifiers" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/reddit.png" width="32" height="32" alt="Reddit" /></a>
    </div>
</div>

                <ul>
                    <li id="categories-3" class="widget widget_categories">
                        <!-- type: categories -->
<h2 class="widgettitle">Categories</h2>
    <ul>
        <li class="cat-item cat-item-11"><a href="//martin-thoma.com/category/code/" title="Tipps for coding in different languages like Python oder C++.">Code</a></li>
        <li class="cat-item cat-item-21"><a href="//martin-thoma.com/category/web/" title="New emerging websites and technologies.">The Web</a></li>
        <li class="cat-item cat-item-31"><a href="//martin-thoma.com/category/cyberculture/" title="Lolcats, planking, Trollfaces, ...">Cyberculture</a></li>
        <li class="cat-item cat-item-3404"><a href="//martin-thoma.com/category/maths/" title="View all posts filed under Mathematics">Mathematics</a></li>
        <li class="cat-item cat-item-881"><a href="//martin-thoma.com/category/bits-and-bytes/" title="Sometimes posts don&#039;t fit in any category.">My bits and bytes</a></li>
        <li class="cat-item cat-item-41"><a href="//martin-thoma.com/category/deutschland/" title="[All Posts here are written in German about German topics] - Die Bahn, unsere Politik und Europa.">German posts</a></li>
	</ul>

                    </li>
                    <li id="tag_cloud-3" class="widget widget_tag_cloud">
                        <h2 class="widgettitle">Tags</h2>
                        <div class="tagcloud"><a style='font-size: 130.31%' href='//martin-thoma.com/tag/ai/' title='9 topics'>AI</a>
<a style='font-size: 102.50%' href='//martin-thoma.com/tag/algebra/' title='6 topics'>Algebra</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/assembly-language/' title='5 topics'>Assembly language</a>
<a style='font-size: 102.50%' href='//martin-thoma.com/tag/bash/' title='6 topics'>Bash</a>
<a style='font-size: 191.61%' href='//martin-thoma.com/tag/c/' title='22 topics'>C</a>
<a style='font-size: 137.54%' href='//martin-thoma.com/tag/cpp/' title='10 topics'>CPP</a>
<a style='font-size: 113.08%' href='//martin-thoma.com/tag/challenge/' title='7 topics'>Challenge</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/chrome/' title='5 topics'>Chrome</a>
<a style='font-size: 137.54%' href='//martin-thoma.com/tag/clip/' title='10 topics'>Clip</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/command-line/' title='5 topics'>Command Line</a>
<a style='font-size: 102.50%' href='//martin-thoma.com/tag/computer-science/' title='6 topics'>Computer science</a>
<a style='font-size: 122.23%' href='//martin-thoma.com/tag/digitaltechnik/' title='8 topics'>Digitaltechnik</a>
<a style='font-size: 102.50%' href='//martin-thoma.com/tag/flashgames/' title='6 topics'>Flashgames</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/geometry/' title='5 topics'>Geometry</a>
<a style='font-size: 130.31%' href='//martin-thoma.com/tag/google/' title='9 topics'>Google</a>
<a style='font-size: 122.23%' href='//martin-thoma.com/tag/google-code-jam/' title='8 topics'>Google Code Jam</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/html5/' title='5 topics'>HTML5</a>
<a style='font-size: 130.31%' href='//martin-thoma.com/tag/it-security/' title='9 topics'>IT-Security</a>
<a style='font-size: 225.38%' href='//martin-thoma.com/tag/java/' title='36 topics'>Java</a>
<a style='font-size: 102.50%' href='//martin-thoma.com/tag/javascript/' title='6 topics'>JavaScript</a>
<a style='font-size: 177.85%' href='//martin-thoma.com/tag/kit/' title='18 topics'>KIT</a>
<a style='font-size: 210.55%' href='//martin-thoma.com/tag/klausur/' title='29 topics'>Klausur</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/kogsys/' title='5 topics'>KogSys</a>
<a style='font-size: 200.38%' href='//martin-thoma.com/tag/latex/' title='25 topics'>LaTeX</a>
<a style='font-size: 177.85%' href='//martin-thoma.com/tag/linear-algebra/' title='18 topics'>Linear algebra</a>
<a style='font-size: 169.77%' href='//martin-thoma.com/tag/linux/' title='16 topics'>Linux</a>
<a style='font-size: 155.53%' href='//martin-thoma.com/tag/machine-learning/' title='13 topics'>Machine Learning</a>
<a style='font-size: 122.23%' href='//martin-thoma.com/tag/matrix/' title='8 topics'>Matrix</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/os/' title='5 topics'>OS</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/operating-systems/' title='5 topics'>Operating Systems</a>
<a style='font-size: 130.31%' href='//martin-thoma.com/tag/php/' title='9 topics'>PHP</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/physics/' title='5 topics'>Physics</a>
<a style='font-size: 237.57%' href='//martin-thoma.com/tag/programming/' title='43 topics'>Programming</a>
<a style='font-size: 130.31%' href='//martin-thoma.com/tag/project-euler/' title='9 topics'>Project Euler</a>
<a style='font-size: 270.00%' href='//martin-thoma.com/tag/python/' title='69 topics'>Python</a>
<a style='font-size: 102.50%' href='//martin-thoma.com/tag/review/' title='6 topics'>Review</a>
<a style='font-size: 130.31%' href='//martin-thoma.com/tag/swt-i/' title='9 topics'>SWT I</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/science/' title='5 topics'>Science</a>
<a style='font-size: 130.31%' href='//martin-thoma.com/tag/theoretical-computer-science/' title='9 topics'>Theoretical computer science</a>
<a style='font-size: 102.50%' href='//martin-thoma.com/tag/tikz/' title='6 topics'>Tikz</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/ubuntu/' title='5 topics'>Ubuntu</a>
<a style='font-size: 155.53%' href='//martin-thoma.com/tag/video/' title='13 topics'>Video</a>
<a style='font-size: 130.31%' href='//martin-thoma.com/tag/vimeo/' title='9 topics'>Vimeo</a>
<a style='font-size: 137.54%' href='//martin-thoma.com/tag/web-development/' title='10 topics'>Web Development</a>
<a style='font-size: 102.50%' href='//martin-thoma.com/tag/wikipedia/' title='6 topics'>Wikipedia</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/windows-7/' title='5 topics'>Windows 7</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/wolfram-alpha/' title='5 topics'>Wolfram|Alpha</a>
<a style='font-size: 144.07%' href='//martin-thoma.com/tag/youtube/' title='11 topics'>YouTube</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/advertising/' title='5 topics'>advertising</a>
<a style='font-size: 122.23%' href='//martin-thoma.com/tag/algorithms/' title='8 topics'>algorithms</a>
<a style='font-size: 113.08%' href='//martin-thoma.com/tag/analysis/' title='7 topics'>analysis</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/cheat-sheet/' title='5 topics'>cheat sheet</a>
<a style='font-size: 165.34%' href='//martin-thoma.com/tag/funny/' title='15 topics'>funny</a>
<a style='font-size: 165.34%' href='//martin-thoma.com/tag/learning/' title='15 topics'>learning</a>
<a style='font-size: 137.54%' href='//martin-thoma.com/tag/lecture-notes/' title='10 topics'>lecture-notes</a>
<a style='font-size: 251.91%' href='//martin-thoma.com/tag/mathematics/' title='53 topics'>mathematics</a>
<a style='font-size: 188.42%' href='//martin-thoma.com/tag/puzzle/' title='21 topics'>puzzle</a>
</div>
                    </li>
                </ul>
                </div>
            </div>
        </div><!--/container-->
            <footer id="footer">
                <a href="//martin-thoma.com"><strong>Martin Thoma</strong></a> -  A blog about Code, the Web and Cyberculture. <br />
                <div class="footer-credits">
                    <a href="http://flexithemes.com/themes/modern-style/">Modern Style</a> theme by <a href="http://flexithemes.com/">FlexiThemes</a>
                </div>
            </footer><!--/footer-->

    </div><!--/wrapper-->
<!-- type: footer -->
<!-- TOC Plus -->
<script type='text/javascript'>
/* <![CDATA[ */
var tocplus = {"visibility_show":"show","visibility_hide":"hide","width":"275px"};
/* ]]> */
</script>
<script type='text/javascript' src="//martin-thoma.com/js/tocplus-front.js"></script>

</body>
</html>

