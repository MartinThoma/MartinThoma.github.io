---
layout: post
title: Computer Vision for Human-Computer Interaction
slug: cv-hci
author: Martin Thoma
date: 2016-10-19 20:00
category: German posts
tags: Klausur, CV
featured_image: logos/klausur.png
---
<div class="info">Dieser Artikel beschäftigt sich mit der Vorlesung &bdquo;Computer Vision for Human-Computer Interaction&ldquo; am KIT. Er dient als Prüfungsvorbereitung. Ich habe die Vorlesungen bei <a href="https://cvhci.anthropomatik.kit.edu/people_596.php">Herrn Prof. Dr.-Ing. Rainer Stiefelhagen</a> im Wintersemester 2016/2017 gehört. Die Inhalte sind dementsprechend stark an der Vorlesung angelehnt bzw. komplette Teile sind daraus übernommen. Noch ist der Artikel in der Entwurfsphase.</div>

Der Kern der Vorlesung 'Computer Vision for Human-Computer Interaction' ist das finden und verfolgen von Personen / Gesichtern in Bildern und Bildfolgen. Dabei werden folgende Themenfelder besprochen:

* Trackingverfahren: Kalman-Filter und Partikelfilter


## Behandelter Stoff

<table>
<tr>
    <th>#</th>
    <th>Datum</th>
    <th>Kapitel</th>
    <th>Inhalt</th>
</tr>
<tr>
    <td>1</td>
    <td>18.10.2016</td>
    <td>Einführung</td>
    <td>Organisatorisches und Überblick über den Stoff</td>
</tr>
<tr>
    <td>2</td>
    <td>21.10.2016</td>
    <td>Klassifikation</td>
    <td>Gaussian Mixture Models, EM, SVMs, Perceptron</td>
</tr>
<tr>
    <td>3</td>
    <td>24.10.2016</td>
    <td>Face Detection I</td>
    <td>Color Spaces (<i>HS</i>V, Y<i>UV</i>), Histogram Backprojection, Histogram Matching, Mixture of Gaussians, ROC, Morphological Operations</td>
</tr>
<tr>
    <td>4</td>
    <td>28.10.2016</td>
    <td>Face Detection II</td>
    <td>Perceptron, MLP, Histogram Equalization, Haar-like features, Adaboost (Viola and Jones), </td>
</tr>
<tr>
    <td>5</td>
    <td>31.10.2016</td>
    <td>Face Recognition I</td>
    <td>Eigenface, Fisherface</td>
</tr>
<tr>
    <td>6</td>
    <td>04.11.2016</td>
    <td>Programmierprojekte</td>
    <td>Organisatorisches / Einführung dazu</td>
</tr>
<tr>
    <td>7</td>
    <td>07.11.2016</td>
    <td>Face Recognition 2</td>
    <td>Alignment (range affine warps), Morphing models of 3d forms (PCA), </td>
</tr>
<tr>
    <td>8</td>
    <td>11.11.2016</td>
    <td>CNNs</td>
    <td>Convolution, Pooling, ReLU, Normalization layers,</td>
</tr>
<tr>
    <td>9</td>
    <td>14.11.2016</td>
    <td></td>
    <td>Besprechung der Papers</td>
</tr>
</table>


### Klassifikatoren

* [Curse of Dimensionality](https://martin-thoma.com/average-distance-of-points/)
* [k-means](https://martin-thoma.com/k-nearest-neighbor-classification-interactive-example/)
* [SVM](https://martin-thoma.com/svm-with-sklearn/)


### Histogramme

<dl>
    <dt><dfn id="histogram-equalization"><a href="https://en.wikipedia.org/wiki/Histogram_equalization">Histogram equalization</a></dfn></dt>
    <dd>

        This method usually increases the global contrast of many images,
        especially when the usable data of the image is represented by close
        contrast values. Through this adjustment, the intensities can be better
        distributed on the histogram. This allows for areas of lower local
        contrast to gain a higher contrast. Histogram equalization accomplishes
        this by effectively spreading out the most frequent intensity values.<br/>
        <br/>
        (Source: Wikipedia)

        The intensity values of the image are modified in such a way that the
        histogram is flattened.

    </dd>
    <dt><dfn id="image-normalization"><a href="https://en.wikipedia.org/wiki/Normalization_(image_processing)">Image normalization</a></dfn></dt>
    <dd>

        Normalization is a process that changes the range of pixel intensity
        values. Applications include photographs with poor contrast due to
        glare, for example. Normalization is sometimes called contrast
        stretching or histogram stretching.<br/>
        <br/>
        (Source: Wikpedia)

    </dd>
</dl>


### Face Detection

<dl>
    <dt><dfn>Face Detection</dfn></dt>
    <dd>

        Face Detection ist die Aufgabe, in einem gegebenen Bild eine
        Bounding-Box um jedes Gesicht zu zeichnen.<br/>
        <br/>
        Ein Ansatz ist, zu versuchen "Gesichtsfarbe" zu erkennen.<br/>
        <br/>
        Die Modellierung kann mit Histogrammen erfolgen.
    </dd>
    <dt><dfn>Histogram Backprojection</dfn></dt>
    <dd>

        Man geht für die Trainingsbeispiele alle Hautfarbe-Pixel durch. Bekommt
        man nun ein neues Bild, so geht man für dieses Bild jeden Pixel durch.
        Die Ausgabe ist ein Graustufenbild selber Größe, wo die Pixelfarbe die
        Anzahl der Hautfarbenen Pixel dieser Farbe ist.

    </dd>
    <dt><dfn>Histogram Matching</dfn></dt>
    <dd>

        Erstelle ein Histogram für Hautfarbe. Um ein neues Bild zu
        klassifizieren, bildet man Ausschnitte für das Bild. Für jeden
        Ausschnitt vergleicht man das Histogram des Ausschnitts mit dem
        Hautfarbe-Histogram. Dazu können folgende Metriken verwendet werden:

        <ul>
            <li>Battacharya distance</li>
            <li>Histogram intersection</li>
            <li>Earth-movers distance</li>
        </ul>

    </dd>
    <dt><dfn>ROC</dfn></dt>
    <dd>TODO</dd>
</dl>


### Face Recognition

Alignment:

* Works only with "nice" images (no occlusion, high resolution)
* Eyes are hard
* Computationally intensive (not suitable for real time applications)

Face features:

<dl>
    <dt><dfn>Face Recognition Tasks</dfn></dt>
    <dd>

        <ul>
            <li>Closed set recognition: 120 Celebrities - who is it?</li>
            <li>Known / unknown: Is it one of the persons in the known set?</li>
            <li>Verification: Is it George Clooney?</li>
            <li>Open Set recognition: First known/unknwon, then closed set.</li>
        </ul>

    </dd>
    <dt><dfn>Gabor Filter</dfn></dt>
    <dd>TODO</dd>
    <dt><dfn>Local Binary Pattern</dfn> (<dfn>LBP</dfn>)</dt>
    <dd>TODO</dd>
    <dt><dfn>SIFT</dfn></dt>
    <dd>TODO

        SIFT vector is 128 dimensional
    </dd>
    <dt><dfn>Bag of Visual Words</dfn> (<dfn>BoVW</dfn>)</dt>
    <dd>TODO</dd>
    <dt><dfn>Fisher Encoding</dfn></dt>
    <dd>TODO</dd>
</dl>

Datasets

* LFW: [Labeled Faces in the Wild](http://vis-www.cs.umass.edu/lfw/)
* YTF: [Youtube Faces](http://www.cs.tau.ac.il/~wolf/ytfaces/)


### CNNs

* Lernen Gabor Wavelets (TODO: Quelle?)
* Warum tiefere Netze? → Muster können geteilt werden (Räder für Traktoren / Motorräder)
* TODO: Filter response = Feature Map?
* TODO: Warum ist es ok, dass der Gradient von ReLU(x) für $x \leq 0$ gleich 0 ist? (Saturierungsproblem)
* TODO: Negative Log Likelihood vs Cross Correlation - what are differences?


<dl>
    <dt><dfn>Pooling</dfn> (<dfn>Subsampling</dfn>)</dt>
    <dd>

        Auf eine $k \times k$ Region der Feature-Map wird ein Operator (z.B. max, mean)
        angewendet, der diese Zusammenfasst. Typischerweise wird diese Operation
        mit einem Stride > 1 verwendet. Durch den Stride wird zugleich die
        Datenmenge auf $\frac{1}{s^2}$ reduziert.<br/>
        <br/>
        Pooling wird seperat pro Feature-Map angewendet.

    </dd>
    <dt><dfn>Normalization Layers</dfn></dt>
    <dd>

        TODO

        <ul>
            <li>Contrast Normalization</li>
            <li>Range Normalization</li>
        </ul>

    </dd>
</dl>

Die Paper

* [Deep Face: closing the gap to human level performance](https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf) ([summary](http://www.shortscience.org/paper?bibtexKey=conf/cvpr/TaigmanYRW14#martinthoma))
* [FaceNet: A unified embedding for face recognition and clustering](https://arxiv.org/abs/1503.03832) ([summary](http://www.shortscience.org/paper?bibtexKey=journals/corr/1503.03832))
* [Deep Face recognition](https://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf) ([summary](http://www.shortscience.org/paper?bibtexKey=conf/bmvc/ParkhiVZ15))


## Praktische Aufgaben

Es gibt 3 praktische Aufgaben, die 10% der Note ausmachen:

* Haut erkennen
* Detektieren ob auf einem Bild eine Person ist oder nicht
* Erkennen ob auf zwei gegebenen Bildern die selbe Person ist

Die Aufgaben müssen mit C++ gemacht werden. OpenCV kann verwendet werden. Es
ist Beispielcode gegeben.

Man muss in 180s die Modelle trainieren.

Bewertet wird eine Präsentation, die am **16.01.2016** gemacht werden muss. Die
Präsentation soll mindestens 3 Folien, maximal 5 Folien haben. In diesen 5
Folien sollen alle 3 Aufgaben beschrieben werden. Es soll beschrieben werden
wie die Aufgaben gelöst wurden / was geklappt bzw. nicht geklappt hat. Die
Präsentation soll ca. 8 - 10 min pro Team dauern.

Es ist ok private Datensätze zu verwenden um ggf. Hyperparameter zu bestimmen.

Für weitere Fragen steht <a href="https://cvhci.anthropomatik.kit.edu/~manel/">Manuel Martinez</a> zur Verfügung.

## Prüfungsfragen

* Was ist das Hauptproblem der Gesichtserkennung?<br/>
  → Beleuchtung / Pose missmatch (ECCV'94)


## Material und Links

* [Vorlesungswebsite](https://cvhci.anthropomatik.kit.edu/600_1526.php)
* [lecture-demo.ira.uka.de](https://lecture-demo.ira.uka.de/): Interaktive Demos, insbesondere  Rosenblatt-Perceptron,

<!-- * [Anki-Karteikarten Deck](https://ankiweb.net/shared/info/22317474) -->


## Fazit

Kommt noch.


## Vorlesungs&shy;empfehlungen

Folgende Vorlesungen sind ähnlich:

* [Analysetechniken großer Datenbestände](https://martin-thoma.com/analysetechniken-grosser-datenbestaende/)
* [Informationsfusion](https://martin-thoma.com/informationsfusion/)
* [Machine Learning 1](https://martin-thoma.com/machine-learning-1-course/)
* [Machine Learning 2](https://martin-thoma.com/machine-learning-2-course/)
* [Mustererkennung](https://martin-thoma.com/mustererkennung-klausur/)
* [Neuronale Netze](https://martin-thoma.com/neuronale-netze-vorlesung/)
* [Lokalisierung Mobiler Agenten](https://martin-thoma.com/lma/)
* [Probabilistische Planung](https://martin-thoma.com/probabilistische-planung/)

Weitere:

* Einführung in die Bildfolgenauswertung
* [Content-based Image and Video Retrival](https://cvhci.anthropomatik.kit.edu/600_1482.php)


## Termine und Klausurablauf

Die Veranstaltung wird mündlich geprüft, jedoch sind 10% der Note durch
praktische Aufgaben zu erlangen. Üblicherweise dauert eine Prüfung
etwa 30 min.
