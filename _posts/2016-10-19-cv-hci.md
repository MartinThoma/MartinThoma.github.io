---
layout: post
title: Computer Vision for Human-Computer Interaction
slug: cv-hci
author: Martin Thoma
date: 2016-10-19 20:00
category: German posts
tags: Klausur, CV
featured_image: logos/klausur.png
---
<div class="info">Dieser Artikel beschäftigt sich mit der Vorlesung &bdquo;Computer Vision for Human-Computer Interaction&ldquo; am KIT. Er dient als Prüfungsvorbereitung. Ich habe die Vorlesungen bei <a href="https://cvhci.anthropomatik.kit.edu/people_596.php">Herrn Prof. Dr.-Ing. Rainer Stiefelhagen</a> im Wintersemester 2016/2017 gehört. Die Inhalte sind dementsprechend stark an der Vorlesung angelehnt bzw. komplette Teile sind daraus übernommen. Noch ist der Artikel in der Entwurfsphase.</div>

Der Kern der Vorlesung 'Computer Vision for Human-Computer Interaction' ist das finden und verfolgen von Personen / Gesichtern in Bildern und Bildfolgen. Dabei werden folgende Themenfelder besprochen:

* Trackingverfahren: Kalman-Filter und Partikelfilter


## Behandelter Stoff

<table>
<tr>
    <th>#</th>
    <th>Datum</th>
    <th>Kapitel</th>
    <th>Inhalt</th>
</tr>
<tr>
    <td>1</td>
    <td>18.10.2016</td>
    <td>Einführung</td>
    <td>Organisatorisches und Überblick über den Stoff</td>
</tr>
<tr>
    <td>2</td>
    <td>21.10.2016</td>
    <td>Klassifikation</td>
    <td>Gaussian Mixture Models, EM, SVMs, Perceptron</td>
</tr>
<tr>
    <td>-</td>
    <td>04.11.2016</td>
    <td>Programmierprojekten</td>
    <td>Organisatorisches / Einführung dazu</td>
</tr>
</table>


### Klassifikatoren

* [Curse of Dimensionality](https://martin-thoma.com/average-distance-of-points/)
* [k-means](https://martin-thoma.com/k-nearest-neighbor-classification-interactive-example/)
* [SVM](https://martin-thoma.com/svm-with-sklearn/)


### Histogramme

<dl>
    <dt><dfn id="histogram-equalization"><a href="https://en.wikipedia.org/wiki/Histogram_equalization">Histogram equalization</a></dfn></dt>
    <dd>

        This method usually increases the global contrast of many images,
        especially when the usable data of the image is represented by close
        contrast values. Through this adjustment, the intensities can be better
        distributed on the histogram. This allows for areas of lower local
        contrast to gain a higher contrast. Histogram equalization accomplishes
        this by effectively spreading out the most frequent intensity values.<br/>
        <br/>
        (Source: Wikipedia)

        The intensity values of the image are modified in such a way that the
        histogram is flattened.

    </dd>
    <dt><dfn id="image-normalization"><a href="https://en.wikipedia.org/wiki/Normalization_(image_processing)">Image normalization</a></dfn></dt>
    <dd>

        Normalization is a process that changes the range of pixel intensity
        values. Applications include photographs with poor contrast due to
        glare, for example. Normalization is sometimes called contrast
        stretching or histogram stretching.<br/>
        <br/>
        (Source: Wikpedia)

    </dd>
</dl>

<!-- ### Grundlagen

Slides: `ProPlan-1-Anschrieb.pdf`

<dl>
  <dt><dfn>$\sigma$-Algebra</dfn></dt>
  <dd>Sei $S$ eine Menge und $\mathcal{A}$ ein Menge aus Teilmengen von $S$.
      $\mathcal{A}$ heißt eine $\sigma$-Algebra über $S$, genau dann, wenn
      gilt:

      <ul>
          <li>$S \in \mathcal{A}$</li>
          <li>$\forall M \in \mathcal{A} \Rightarrow (S \setminus M) \in \mathcal{A}$</li>
          <li>$M_1, M_2, \dots \in \mathcal{A} \Rightarrow \bigcup_{n \in \mathbb{N}} M_n \in \mathcal{A}$</li>
      </ul>

      </dd>
  <dt><dfn>Wahrscheinlichkeitsmaß</dfn> (<dfn id="probability-measure">Probability measure</dfn>)</dt>
  <dd>Eine Funktion $P: \mathcal{A} \rightarrow \mathbb{R}$ (mit $\mathcal{A}$ ist
      Sigma-Algebra über der Grundmenge $S$) heißt
      <i>Wahrscheinlichkeitsmaß</i>, wenn die Kolmogorov'schen Axiome gelten:

      <ul>
          <li>Nicht-negativität: $\forall M \in \mathcal{A}: P(M) \geq 0$</li>
          <li>Normiertheit: $\forall P(S) = 1$</li>
          <li>$M_1, M_2 \in \mathcal{A} \land M_1 \cap M_2 = \emptyset \Rightarrow P(M_1 \cup M_2) = P(M_1) + P(M_2)$</li>
      </ul>

      </dd>
  <dt><dfn>Normalverteilung</dfn></dt>
  <dd>Die Normalverteilung $\mathcal{N}(\mu, \sigma^2)$ ist eine
      kontinuierliche Verteilung mit der Dichtefunktion

      $$f(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} e^{- \frac{(x - \mu)^2}{2\sigma^2}}$$

      Die multivariate Normalverteilung $\mathcal{N}(\mu, \Sigma)$ hat die
      Dichtefunktion

      $$f(x) = \frac{1}{ \sqrt{(2\pi)^n \det(\Sigma)} } \exp \left(-\frac{1}{2}({\mathbf x}-{\boldsymbol\mu})^\mathrm{T}{\boldsymbol\Sigma}^{-1}({\mathbf x}-{\boldsymbol\mu}) \right)$$

      </dd>
</dl> -->


## Praktische Aufgaben

Es gibt 3 praktische Aufgaben, die 10% der Note ausmachen:

* Haut erkennen
* Detektieren ob auf einem Bild eine Person ist oder nicht
* Erkennen ob auf zwei gegebenen Bildern die selbe Person ist

Die Aufgaben müssen mit C++ gemacht werden. OpenCV kann verwendet werden. Es
ist Beispielcode gegeben.

Man muss in 180s die Modelle trainieren.

Bewertet wird eine Präsentation, die am **16.01.2016** gemacht werden muss. Die
Präsentation soll mindestens 3 Folien, maximal 5 Folien haben. In diesen 5
Folien sollen alle 3 Aufgaben beschrieben werden. Es soll beschrieben werden
wie die Aufgaben gelöst wurden / was geklappt bzw. nicht geklappt hat. Die
Präsentation soll ca. 8 - 10 min pro Team dauern.

Es ist ok private Datensätze zu verwenden um ggf. Hyperparameter zu bestimmen.

Für weitere Fragen steht <a href="https://cvhci.anthropomatik.kit.edu/~manel/">Manuel Martinez</a> zur Verfügung.

## Prüfungsfragen

Kommt noch

<!-- Strategiesuche ist NICHT relevant für meine Prüfung am 4.&nbsp;August 2016.


* Welche 3 Themengebiete wurden in der Vorlesung behandelt und was sind die
  Unterschiede?<br/>
  → <a href="#mdp">MDP</a>, <a href="#pomdp">POMDP</a>, <a href="#rl">RL</a>
* Welche Paradoxa haben wir in den Vorlesungen kennen gelernt?<br/>
  → Allais-Paradoxon -->


## Material und Links

* [Vorlesungswebsite](https://cvhci.anthropomatik.kit.edu/600_1526.php)
* [lecture-demo.ira.uka.de](https://lecture-demo.ira.uka.de/): Interaktive Demos, insbesondere  Rosenblatt-Perceptron,

<!-- * [Anki-Karteikarten Deck](https://ankiweb.net/shared/info/22317474) -->


## Fazit

Kommt noch.


## Vorlesungs&shy;empfehlungen

Folgende Vorlesungen sind ähnlich:

* [Analysetechniken großer Datenbestände](https://martin-thoma.com/analysetechniken-grosser-datenbestaende/)
* [Informationsfusion](https://martin-thoma.com/informationsfusion/)
* [Machine Learning 1](https://martin-thoma.com/machine-learning-1-course/)
* [Machine Learning 2](https://martin-thoma.com/machine-learning-2-course/)
* [Mustererkennung](https://martin-thoma.com/mustererkennung-klausur/)
* [Neuronale Netze](https://martin-thoma.com/neuronale-netze-vorlesung/)
* [Lokalisierung Mobiler Agenten](https://martin-thoma.com/lma/)
* [Probabilistische Planung](https://martin-thoma.com/probabilistische-planung/)

Weitere:

* Einführung in die Bildfolgenauswertung
* [Content-based Image and Video Retrival](https://cvhci.anthropomatik.kit.edu/600_1482.php)


## Termine und Klausurablauf

Die Veranstaltung wird mündlich geprüft, jedoch sind 10% der Note durch
praktische Aufgaben zu erlangen. Üblicherweise dauert eine Prüfung
etwa 30 min.
