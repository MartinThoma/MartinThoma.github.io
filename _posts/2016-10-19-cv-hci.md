---
layout: post
title: Computer Vision for Human-Computer Interaction
slug: cv-hci
author: Martin Thoma
date: 2016-10-19 20:00
category: German posts
tags: Klausur, CV
featured_image: logos/klausur.png
---
<div class="info">Dieser Artikel beschäftigt sich mit der Vorlesung &bdquo;Computer Vision for Human-Computer Interaction&ldquo; am KIT. Er dient als Prüfungsvorbereitung. Ich habe die Vorlesungen bei <a href="https://cvhci.anthropomatik.kit.edu/people_596.php">Herrn Prof. Dr.-Ing. Rainer Stiefelhagen</a> im Wintersemester 2016/2017 gehört. Die Inhalte sind dementsprechend stark an der Vorlesung angelehnt bzw. komplette Teile sind daraus übernommen. Noch ist der Artikel in der Entwurfsphase.</div>

Der Kern der Vorlesung 'Computer Vision for Human-Computer Interaction' ist das finden und verfolgen von Personen / Gesichtern in Bildern und Bildfolgen. Dabei werden folgende Themenfelder besprochen:

* Trackingverfahren: Kalman-Filter und Partikelfilter


## Behandelter Stoff

<table>
<tr>
    <th>#</th>
    <th>Datum</th>
    <th>Kapitel</th>
    <th>Inhalt</th>
</tr>
<tr>
    <td>1</td>
    <td>18.10.2016</td>
    <td>Einführung</td>
    <td>Organisatorisches und Überblick über den Stoff</td>
</tr>
<tr>
    <td>2</td>
    <td>21.10.2016</td>
    <td>Klassifikation</td>
    <td>Gaussian Mixture Models, EM, SVMs, Perceptron</td>
</tr>
<tr>
    <td>3</td>
    <td>24.10.2016</td>
    <td>Face Detection I</td>
    <td>Color Spaces (<i>HS</i>V, Y<i>UV</i>), Histogram Backprojection, Histogram Matching, Mixture of Gaussians, ROC, Morphological Operations</td>
</tr>
<tr>
    <td>4</td>
    <td>28.10.2016</td>
    <td>Face Detection II</td>
    <td>Perceptron, MLP, Histogram Equalization, Haar-like features, Adaboost (Viola and Jones), </td>
</tr>
<tr>
    <td>5</td>
    <td>31.10.2016</td>
    <td>Face Recognition I</td>
    <td>Eigenface, Fisherface</td>
</tr>
<tr>
    <td>6</td>
    <td>04.11.2016</td>
    <td>Programmierprojekte</td>
    <td>Organisatorisches / Einführung dazu</td>
</tr>
<tr>
    <td>7</td>
    <td>07.11.2016</td>
    <td>Face Recognition 2</td>
    <td>Alignment (range affine warps), Morphing models of 3d forms (PCA), </td>
</tr>
<tr>
    <td>8</td>
    <td>11.11.2016</td>
    <td>CNNs</td>
    <td>Convolution, Pooling, ReLU, Normalization layers,</td>
</tr>
<tr>
    <td>9</td>
    <td>14.11.2016</td>
    <td>Programmierprojekte</td>
    <td>Besprechung der praktischen Aufgaben</td>
</tr>
<tr>
    <td>10</td>
    <td>18.11.2016</td>
    <td>?</td>
    <td>?</td>
</tr>
<tr>
    <td>11</td>
    <td>21.11.2016</td>
    <td>?</td>
    <td>?</td>
</tr>
<tr>
    <td>12</td>
    <td>25.11.2016</td>
    <td>?</td>
    <td>?</td>
</tr>
<tr>
    <td>13</td>
    <td>28.11.2016</td>
    <td>Head Pose Estimation</td>
    <td>Model-based approaches, Appearence-based approaches</td>
</tr>
<tr>
    <td>14</td>
    <td>02.12.2016</td>
    <td>Person Detection</td>
    <td>Introduction, HOG people detector, Shilouette matching</td>
</tr>
<tr>
    <td>15</td>
    <td>05.12.2016</td>
    <td>?</td>
    <td>?</td>
</tr>
<tr>
    <td>16</td>
    <td>09.12.2016</td>
    <td>?</td>
    <td>?</td>
</tr>
</table>


### Klassifikatoren

* [Curse of Dimensionality](https://martin-thoma.com/average-distance-of-points/)
* [k-means](https://martin-thoma.com/k-nearest-neighbor-classification-interactive-example/)
* [SVM](https://martin-thoma.com/svm-with-sklearn/)


### Histogramme

<dl>
    <dt><dfn id="histogram-equalization"><a href="https://en.wikipedia.org/wiki/Histogram_equalization">Histogram equalization</a></dfn></dt>
    <dd>

        This method usually increases the global contrast of many images,
        especially when the usable data of the image is represented by close
        contrast values. Through this adjustment, the intensities can be better
        distributed on the histogram. This allows for areas of lower local
        contrast to gain a higher contrast. Histogram equalization accomplishes
        this by effectively spreading out the most frequent intensity values.<br/>
        <br/>
        (Source: Wikipedia)

        The intensity values of the image are modified in such a way that the
        histogram is flattened.

    </dd>
    <dt><dfn id="image-normalization"><a href="https://en.wikipedia.org/wiki/Normalization_(image_processing)">Image normalization</a></dfn></dt>
    <dd>

        Normalization is a process that changes the range of pixel intensity
        values. Applications include photographs with poor contrast due to
        glare, for example. Normalization is sometimes called contrast
        stretching or histogram stretching.<br/>
        <br/>
        (Source: Wikpedia)

    </dd>
</dl>


### Face Detection

<dl>
    <dt><dfn>Face Detection</dfn></dt>
    <dd>

        Face Detection ist die Aufgabe, in einem gegebenen Bild eine
        Bounding-Box um jedes Gesicht zu zeichnen.<br/>
        <br/>
        Ein Ansatz ist, zu versuchen "Gesichtsfarbe" zu erkennen.<br/>
        <br/>
        Die Modellierung kann mit Histogrammen erfolgen.
    </dd>
    <dt><dfn>Histogram Backprojection</dfn></dt>
    <dd>

        Man geht für die Trainingsbeispiele alle Hautfarbe-Pixel durch. Bekommt
        man nun ein neues Bild, so geht man für dieses Bild jeden Pixel durch.
        Die Ausgabe ist ein Graustufenbild selber Größe, wo die Pixelfarbe die
        Anzahl der Hautfarbenen Pixel dieser Farbe ist.

    </dd>
    <dt><dfn><a href="https://en.wikipedia.org/wiki/Histogram_matching">Histogram Matching</a></dfn></dt>
    <dd>

        Erstelle ein Histogram für Hautfarbe. Um ein neues Bild zu
        klassifizieren, bildet man Ausschnitte für das Bild. Für jeden
        Ausschnitt vergleicht man das Histogram des Ausschnitts mit dem
        Hautfarbe-Histogram. Dazu können folgende Metriken verwendet werden:

        <ul>
            <li>Battacharya distance</li>
            <li>Histogram intersection</li>
            <li>Earth-movers distance</li>
        </ul>

    </dd>
    <dt><dfn><a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">ROC</a></dfn></dt>
    <dd>TODO</dd>
</dl>


### Face Recognition

Alignment:

* Works only with "nice" images (no occlusion, high resolution)
* Eyes are hard
* Computationally intensive (not suitable for real time applications)

Face features:

<dl>
    <dt><dfn id="face-recognition-dfn">Face Recognition</dfn></dt>
    <dd>Face recognition has 4 main tasks:

    <ul>
        <li><b>Face detection</b>: Given an image, draw a rectangle around every face</li>
        <li><b>Face alignment</b>: Transform a face to be in a canonical pose</li>
        <li><b>Face representation</b>: Find a representation of a face which is suitable for follow-up tasks (small size, computationally cheap to compare, invariant to irrelevant changes)</li>
        <li><b>Face verification</b>: Images of two faces are given. Decide if it is the same person or not.</li>
    </ul>

    The face verification task is sometimes (more simply) a face classification
    task (given a face, decide which of a fixed set of people it is).

    Important papers:

        <ul>
            <li><a href="https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf">Deep Face: closing the gap to human level performance</a> (<a href="http://www.shortscience.org/paper?bibtexKey=conf/cvpr/TaigmanYRW14#martinthoma">summary</a>)</li>
            <li><a href="https://arxiv.org/abs/1503.03832">FaceNet: A unified embedding for face recognition and clustering</a> (<a href="http://www.shortscience.org/paper?bibtexKey=journals/corr/1503.03832">summary</a>)</li>
            <li><a href="https://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf">Deep Face recognition</a> (<a href="http://www.shortscience.org/paper?bibtexKey=conf/bmvc/ParkhiVZ15">summary</a>)</li>
        </ul>


        Datasets

        <ul>
            <li><a href="http://vis-www.cs.umass.edu/lfw/">LFW</a> (Labeled Faces in the Wild)</li>
            <li><a href="http://www.cs.tau.ac.il/~wolf/ytfaces/">YTF</a> (Youtube Faces)</li>
        </ul>

    </dd>
    <dt><dfn>Face Recognition Tasks</dfn></dt>
    <dd>

        <ul>
            <li>Closed set recognition: 120 Celebrities - who is it?</li>
            <li>Known / unknown: Is it one of the persons in the known set?</li>
            <li>Verification: Is it George Clooney?</li>
            <li>Open Set recognition: First known/unknwon, then closed set.</li>
        </ul>

    </dd>
    <dt><dfn id="gabor-filter"><a href="https://en.wikipedia.org/wiki/Gabor_filter">Gabor Filter</a></dfn></dt>
    <dd>TODO</dd>
    <dt><dfn><a href="https://en.wikipedia.org/wiki/Local_binary_patterns">Local Binary Pattern</a></dfn> (<dfn id="lbp">LBP</dfn>)</dt>
    <dd>TODO</dd>
    <dt><dfn id="sift"><a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform">SIFT</a></dfn></dt>
    <dd>TODO

        SIFT vector is 128 dimensional
    </dd>
    <dt><dfn><a href="https://en.wikipedia.org/wiki/Bag-of-words_model_in_computer_vision">Bag of Visual Words</a></dfn> (<dfn id="bovw">BoVW</dfn>)</dt>
    <dd>TODO</dd>
    <dt><dfn id="fisher-encoding">Fisher Encoding</dfn></dt>
    <dd>TODO</dd>
</dl>


### CNNs

* Lernen Gabor Wavelets (TODO: Quelle?)
* Warum tiefere Netze? → Muster können geteilt werden (Räder für Traktoren / Motorräder)
* TODO: Filter response = Feature Map?
* TODO: Warum ist es ok, dass der Gradient von ReLU(x) für $x \leq 0$ gleich 0 ist? (Saturierungsproblem)
* TODO: Negative Log Likelihood vs Cross Correlation - what are differences?


<dl>
    <dt><dfn>Pooling</dfn> (<dfn>Subsampling</dfn>)</dt>
    <dd>

        Auf eine $k \times k$ Region der Feature-Map wird ein Operator (z.B. max, mean)
        angewendet, der diese Zusammenfasst. Typischerweise wird diese Operation
        mit einem Stride > 1 verwendet. Durch den Stride wird zugleich die
        Datenmenge auf $\frac{1}{s^2}$ reduziert.<br/>
        <br/>
        Pooling wird seperat pro Feature-Map angewendet.

    </dd>
    <dt><dfn>Normalization Layers</dfn></dt>
    <dd>

        TODO

        <ul>
            <li>Contrast Normalization</li>
            <li>Range Normalization</li>
        </ul>

    </dd>
</dl>


### Head-pose Estimation

* State of the Art: Regression based apprach (Random Regression Forests) is 15 years old
* slide 14: $r$ is distance, $f$ is focus length, $b$ is baseline, $d_L, d_R$ is distance left/right - in the later slides is a figure.
* Pan / Tilt / Jaw

<dl>
    <dt><a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)"><dfn id="entropy">Entropy</dfn></a></dt>
    <dd>The entropy $H$ of a discrete random variable $X$ is

        $$H(X) = \mathbb{E}[-\ln(P(X))] = - \sum_{i=1}^n P(x_i) \log_2 P(x_i)$$

    </dd>
    <dt><a href="https://en.wikipedia.org/wiki/Information_gain_in_decision_trees"><dfn>Information Gain</dfn></a> (<dfn>Kullback–Leibler divergence</dfn>)</dt>
    <dd>

        The expected information gain is the change in entropy $H$ from a prior
        state to a state that takes some information as given:

        $$IG(T,a) = H(T) - H(T|a)$$

    </dd>
</dl>


### Person detection

<dl>
    <dt>Detection</dt>
    <dd>Detection is classification with localization</dd>
    <dt>Person detection</dt>
    <dd>Person detection (sometimes also pedestrian detection) is the
        task of finding people in an image or video. This is usually done with
        bounding boxes, although tight segmentation methodes exist.<br/>
        <br/>
        One can divide the methods the following way:
        <ul>
            <li>Input: Single image / video</li>
            <li>Detection approach
            <ul>
                <li>Global: Detection of the person as a whole</li>
                <li>Part-based: Detection of arms, legs, head, ...</li>
            </ul>
            </li>
            <li>Model type
            <ul>
                <li>Generative: Models how the data was generated (+ is interpretable - hard to create)</li>
                <li>Discriminative</li>
            </ul>
            </li>
        </ul>

        Shilouette matchin is a discriminative, global, single image approach.
        HOG people detector is a single image approach (TODO: global/part based? generative / discriminative?)
    </dd>
    <dt>L2 hysterese</dt>
    <dd>A variant of the L2 norm which cuts peaks</dd>
    <dt>HOG People Detector</dt>
    <dd>TODO</dd>
    <dt>Shilouette Matching</dt>
    <dd>

        Shilouette matching is practically not used anymore. It uses chemfer
        matching, 2/3 distance. It can be speeded up with a template hierarchy.

    </dd>
</dl>


## Praktische Aufgaben

Es gibt 3 praktische Aufgaben, die 10% der Note ausmachen:

* Haut erkennen
* Detektieren ob auf einem Bild eine Person ist oder nicht
* Erkennen ob auf zwei gegebenen Bildern die selbe Person ist

Die Aufgaben müssen mit C++ gemacht werden. OpenCV kann verwendet werden. Es
ist Beispielcode gegeben.

Man muss in 180s die Modelle trainieren.

Bewertet wird eine Präsentation, die am **16.01.2016** gemacht werden muss. Die
Präsentation soll mindestens 3 Folien, maximal 5 Folien haben. In diesen 5
Folien sollen alle 3 Aufgaben beschrieben werden. Es soll beschrieben werden
wie die Aufgaben gelöst wurden / was geklappt bzw. nicht geklappt hat. Die
Präsentation soll ca. 8 - 10 min pro Team dauern.

Es ist ok private Datensätze zu verwenden um ggf. Hyperparameter zu bestimmen.

Für weitere Fragen steht <a href="https://cvhci.anthropomatik.kit.edu/~manel/">Manuel Martinez</a> zur Verfügung.

## Prüfungsfragen

* Was ist das Hauptproblem der Gesichtserkennung?<br/>
  → Beleuchtung / Pose missmatch (ECCV'94)


## Material und Links

* [Vorlesungswebsite](https://cvhci.anthropomatik.kit.edu/600_1526.php)
* [lecture-demo.ira.uka.de](https://lecture-demo.ira.uka.de/): Interaktive Demos, insbesondere  Rosenblatt-Perceptron, ...
* StackExchange:
    * [Why do CNNs with ReLU learn that well?](http://datascience.stackexchange.com/q/15081/8820)
    * [How is the evaluation setup for YouTube faces of FaceNet?](http://datascience.stackexchange.com/q/15215/8820)
    * [What are interleaved layers of convolutions?](http://datascience.stackexchange.com/q/15214/8820)
* [Video Analysis lecture](https://www.youtube.com/playlist?list=PLuRaSnb3n4kSgSV35vTPDRBH81YgnF3Dd)

<!-- * [Anki-Karteikarten Deck](https://ankiweb.net/shared/info/22317474) -->


## Fazit

Kommt noch.


## Vorlesungs&shy;empfehlungen

Folgende Vorlesungen sind ähnlich:

* [Analysetechniken großer Datenbestände](https://martin-thoma.com/analysetechniken-grosser-datenbestaende/)
* [Informationsfusion](https://martin-thoma.com/informationsfusion/)
* [Machine Learning 1](https://martin-thoma.com/machine-learning-1-course/)
* [Machine Learning 2](https://martin-thoma.com/machine-learning-2-course/)
* [Mustererkennung](https://martin-thoma.com/mustererkennung-klausur/)
* [Neuronale Netze](https://martin-thoma.com/neuronale-netze-vorlesung/)
* [Lokalisierung Mobiler Agenten](https://martin-thoma.com/lma/)
* [Probabilistische Planung](https://martin-thoma.com/probabilistische-planung/)

Weitere:

* Einführung in die Bildfolgenauswertung
* [Content-based Image and Video Retrival](https://cvhci.anthropomatik.kit.edu/600_1482.php)


## Termine und Klausurablauf

Die Veranstaltung wird mündlich geprüft, jedoch sind 10% der Note durch
praktische Aufgaben zu erlangen. Üblicherweise dauert eine Prüfung
etwa 30 min.
