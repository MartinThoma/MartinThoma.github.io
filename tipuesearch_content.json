{"pages":[{"url":"https://martin-thoma.com/strings/","text":"Strings are essential for developing applications. Yet they are not covered (enough) if you study computer science. In this article, I will explain what a string is, what Unicode, UTF-8, ASCII and encodings are and what their relationship is. Just when I was about to finish this, I found Joel Spolskys article . It is better to read, but a lot longer than what I wrote here. Datatype basics Datatypes are not a hardware feature. The CPU knows a couple (well, a lot) of different commands. Those are called the instruction set of a CPU. One of the best known ones is the x86 instruction set . If you search for \"multiply\" on this page, you get 50 results. MULPD and MULSD for the multiplication of doubles, FIMUL for integer multiplication, ... Those commands work on registers. Registers are memory slots which can contain 32 bit or 64 bit, depending on which architecture your CPU uses. Hence the CPU instruction interprets the values of the registers in a different way, but the values themselves don't have types. In compiled languages like C and C++, the compiler takes care of the type and creates a sequence of instructions which interpret the registers content as desired. In Python, the interpreter takes care of it. Simple Strings: Character Sequences In the simplest case, one could store a string as an array of characters. Hence one has a continuous part of the memory, where each byte is interpreted as a character. As we know, the memory doesn't have data types. Hence each byte just contains a natural number in \\([0, 2&#94;8 - 1]\\) . It is only how we interpret those numbers that makes it a character. ASCII ASCII is a standard. It maps 7 bit numbers (yes, 7, not 8 - ASCII is old) to characters. Hence it defines how all of those 128 possible numbers should be interpreted: Number Character Description Number Character Description 0 NULL ( \\0 ) 1 START OF HEADING 2 START OF TEXT 3 END OF TEXT 4 END OF TRANSMISSION 5 ENQUIRY 6 ACKNOWLEDGE 7 BELL 8 BACKSPACE 9 CHARACTER TABULATION ( \\t ) 10 LINE FEED (LF) 11 LINE TABULATION 12 FORM FEED (FF) 13 CARRIAGE RETURN (CR) ( \\r ) 14 SHIFT OUT 15 SHIFT IN 16 DATA LINK ESCAPE 17 DEVICE CONTROL ONE 18 DEVICE CONTROL TWO 19 DEVICE CONTROL THREE 20 DEVICE CONTROL FOUR 21 NEGATIVE ACKNOWLEDGE 22 SYNCHRONOUS IDLE 23 END OF TRANSMISSION BLOCK 24 CANCEL 25 END OF MEDIUM 26 SUBSTITUTE 27 ESCAPE 28 INFORMATION SEPARATOR FOUR 29 INFORMATION SEPARATOR THREE 30 INFORMATION SEPARATOR TWO 31 INFORMATION SEPARATOR ONE 32 SPACE 33 ! EXCLAMATION MARK 34 \" QUOTATION MARK 35 # NUMBER SIGN 36 $ DOLLAR SIGN 37 % PERCENT SIGN 38 & AMPERSAND 39 ' APOSTROPHE 40 ( LEFT PARENTHESIS 41 ) RIGHT PARENTHESIS 42 * ASTERISK 43 + PLUS SIGN 44 , COMMA 45 - HYPHEN-MINUS 46 . FULL STOP 47 / SOLIDUS 48 0 49 1 50 2 51 3 52 4 53 5 54 6 55 7 56 8 57 9 58 : 59 ; 60 < 61 = 62 > 63 ? 64 @ 65 A 66 B 67 C 68 D 69 E 70 F 71 G 72 H 73 I 74 J 75 K 76 L 77 M 78 N 79 O 80 P 81 Q 82 R 83 S 84 T 85 U 86 V 87 W 88 X 89 Y 90 Z 91 [ 92 \\ 93 ] 94 &#94; 95 _ 96 ` 97 a 98 b 99 c 100 d 101 e 102 f 103 g 104 h 105 i 106 j 107 k 108 l 109 m 110 n 111 o 112 p 113 q 114 r 115 s 116 t 117 u 118 v 119 w 120 x 121 y 122 z 123 { 124 | 125 } 126 ~ 127 DELETE Latin-1 Latin-1 (aka ISO 8859-1 ) is an extension to ASCII. So it makes use of the last bit and defines the number 160 to 255. Yes, there is an undefined gap. So this extension helped a lot of languages (e.g. French and German). But it was not enough. And it was a mess, pretty soon. Other character encodings like ISO 8859-2 , ISO 8859-3 , ..., ISO 8859-16 were created. Now exchanging documents between those formats becomes a mess. You've probably experienced it when suddenly the replacement character ï¿½ appears in an application. Or something like Â¿Â½. Unicode Unicode is a standard ( link ). It defines a number - the unicode code point -, the glyph which belongs to this number, a short textual description of the glyph and an example how it could look like. Unicode code points are just identifier. In contrast, in ASCII the numbers are both an identifier and how the character is represented in the memory. For example, the codepoint U+0041 has the description LATIN CAPITAL LETTER A as shown nicely on fileformat.info . This notation uses an hexadecimal base. Hence the number is \\((41)_{16} = 16 \\cdot 4 + 1 = 65\\) - just like ASCII! In fact, Unicode is a superset of ASCII. And of Latin-1. Unicode 10 contains 136 690 characters and 139 writing systems. It has Emoji, mathematical symbols and musical symbols. You can search mathematical symbols with write-math.com and Emoticons with unicode.party . An interesting concept in Unicode are combining characters. For example, a female firefighter is represented by the women code point and by the fire engine code point. UTF-8 UTF-8 is a character encoding capable of encoding all possible Unicode code points. The name is short for Transformation Format - 8 bit. It uses between 1 and 4 bytes to represent Unicode code points. So while Unicode defines an identifier for the concepts of characters, UTF-8 defines how those are stored in memory. There were issues with byte order (high endian, low endian; see Byte Order Mark (BOM)) which are fixed with UTF-8. UTF-8 uses between one and 6 bytes per character. Alternatives: UCS-2 : Use two bytes for a unicode character. Always. high-endian UCS-2 low-endian UCS-2 UCS-4 : Store each code point in 4 bytes - hence it blows up english text to have 4x the size. UTF-7 UTF-16 : Represent the Unicode code point by itself. Used by .NET and Java. Fonts Fonts are a completely different story. Each character can have a font, but it stays the same. A font just deals with the appearence, whereas the Unicode code point defines what it is. The concept. The encoding defines how it is stored in the memory. Interestingly, there can't be a single font which covers all unicode symbols, because OpenType is limited to 65536 glyphs. The GNU Unicode Font covers over 34,000 characters ( source ) Font family Usually, you only want to define a font family. If you make the text bold, the font changes but the font family is still the same. By using font families it seems to be possible to cover more symbols than 65536. For example, noto seems to have a lot. How to use it C L\"Literal UCS-2 string\" C++ wchar_t (\"wide char\") Python Use either UCS2* or UCS4 for unicode characters. Which one is used is a compile time option. The unicode(your_string) function creates a unicode object from the given encoded string. Don't forget to put # -*- coding: utf-8 -*- at the beginning of all of your scripts. Python 2 Python 3 What it does unicode Object str Object handles text. Can be encoded (utf-8, latin-1) str Object bytes plain sequence of bytes By using from __future__ import unicode_literals you get the default behaviour of Python 3 within Python 2: All \"string literals\" are unicode strings. Otherwise, they are byte strings. A couple of really helpful examples from Bakuriu : >>> len ( u 'Ã ' ) # a single code point 1 >>> len ( 'Ã ' ) # by default utf-8 -> takes two bytes 2 >>> len ( u 'Ã ' . encode ( 'utf-8' )) 2 >>> len ( u 'Ã ' . encode ( 'latin1' )) # in latin1 it takes one byte 1 >>> print u 'Ã ' . encode ( 'utf-8' ) # terminal encoding is utf-8 Ã  >>> print u 'Ã ' . encode ( 'latin1' ) # it cannot understand the latin1 byte ï¿½ Pitfalls Some pitfalls are listed in this SO answer : Counting : The combining code points can generate some confusion on what you might expect and what you get. Similar look, but different : U+006E (n), and U+0303 (a combining tilde) forms nÌƒ, but the code point U+00F1 forms Ã± Equality, the second : There is Latin A , CYRILLIC CAPITAL LETTER A and GREEK CAPITAL LETTER ALPHA . The same look, but not the same codepoint. See also Joel Spolsky: The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!) StackExchange: Is ASCII code 7-bit or 8-bit? How are C++ strings stored? What is Unicode, UTF-8, UTF-16? How is unicode represented internally in Python? Formatting Strings with Python A Programmer's Introduction to Unicode Python Docs: Unicode HOWTO Overcoming frustration: Correctly using unicode in python2","tags":"Code","title":"Strings"},{"url":"https://martin-thoma.com/python-data-visualization/","text":"Python has a lot of libraries for data visualization and I recently stumbled over an awesome talk which gives an overview over them: Matplotlib seaborn : statistical data visualization Pandas : Dataframes networkx : Graphs ggpy : Python implementation of the grammar of graphics Yellow Brick scikit-plot Datashader : Turns even the largest data into images Vaex : visualize and explore large (~billion rows/objects) tabular datasets interactively Holoviews Javascript plotly bokeh cufflinks bqplot : Plotting library for IPython/Jupyter Notebooks pythreejs : A Jupyter - ThreeJS bridge ipyleaflet : IPython Widget for Leaflet Maps ipyvolume OpenGL Vispy : interactive scientific visualization Glumpy : scientific visualization Specification languages: Vega Vincent : A Python to Vega Translator Vega Lite Altair d3po : Denoising, Deconvolving, and Decomposing Photon Observations","tags":"Machine Learning","title":"Data Visualization with Python"},{"url":"https://martin-thoma.com/nlp-reuters/","text":"Reuters is a benchmark dataset for document classification . To be more precise, it is a multi-class (e.g. there are multiple classes), multi-label (e.g. each document can belong to many classes) dataset. It has 90 classes , 7769 training documents and 3019 testing documents . It is the ModApte (R(90)) subest of the Reuters-21578 benchmark ( source ). The mean number of words per document, grouped by class, is between 93 and 1263 on the training set. The training set has a vocabulary size of 35247 . Even if you restrict it to words which appear at least 5 times and at most 12672 times in the training set, there are still 12017 words. Classes and Labels nr of documents mean number of class name train test words in train set 1: earn : 2877 1087 104.4 2: acq : 1650 719 150.1 3: money-fx : 538 179 219.0 4: grain : 433 149 223.6 5: crude : 389 189 247.3 6: trade : 368 117 294.3 7: interest : 347 131 198.0 8: wheat : 212 71 225.6 9: ship : 197 89 203.7 10: corn : 181 56 259.1 11: money-supply : 140 34 170.5 12: dlr : 131 44 230.4 13: sugar : 126 36 247.2 14: oilseed : 124 47 277.9 15: coffee : 111 28 264.1 16: gnp : 101 35 372.8 17: gold : 94 30 188.5 18: veg-oil : 87 37 291.0 19: soybean : 78 33 347.9 20: livestock : 75 24 222.9 21: nat-gas : 75 30 257.7 22: bop : 75 30 288.1 23: cpi : 69 28 235.4 24: cocoa : 55 18 266.4 25: reserves : 55 18 216.1 26: carcass : 50 18 259.7 27: copper : 47 18 201.6 28: jobs : 46 21 232.7 29: yen : 45 14 282.8 30: ipi : 41 12 232.1 31: iron-steel : 40 14 220.5 32: cotton : 39 20 366.3 33: barley : 37 14 272.9 34: gas : 37 17 209.4 35: rubber : 37 12 274.5 36: alum : 35 23 180.5 37: rice : 35 24 359.8 38: palm-oil : 30 10 234.5 39: meal-feed : 30 19 387.1 40: sorghum : 24 10 511.3 41: retail : 23 2 324.8 42: zinc : 21 13 189.9 43: silver : 21 8 221.0 44: pet-chem : 20 12 204.9 45: wpi : 19 10 200.9 46: tin : 18 12 322.1 47: rapeseed : 18 9 168.6 48: orange : 16 11 169.6 49: strategic-metal : 16 11 205.6 50: housing : 16 4 207.2 51: hog : 16 6 162.3 52: lead : 15 14 216.7 53: soy-oil : 14 11 568.7 54: heat : 14 5 190.4 55: fuel : 13 10 194.6 56: soy-meal : 13 13 551.0 57: lei : 12 3 134.7 58: sunseed : 11 5 425.1 59: dmk : 10 4 212.1 60: lumber : 10 6 242.1 61: tea : 9 4 365.1 62: income : 9 7 286.4 63: nickel : 8 1 193.6 64: oat : 8 6 648.4 65: l-cattle : 6 2 298.0 66: instal-debt : 5 1 134.3 67: platinum : 5 7 174.8 68: groundnut : 5 4 258.0 69: rape-oil : 5 3 167.2 70: sun-oil : 5 2 201.9 71: coconut-oil : 4 3 471.4 72: jet : 4 1 109.6 73: coconut : 4 2 264.5 74: propane : 3 3 352.0 75: potato : 3 3 161.2 76: cpu : 3 1 133.2 77: rand : 2 1 345.7 78: palmkernel : 2 1 326.3 79: copra-cake : 2 1 495.0 80: dfl : 2 1 764.7 81: naphtha : 2 4 206.7 82: palladium : 2 1 93.0 83: nzdlr : 2 2 508.8 84: groundnut-oil : 1 1 277.5 85: castor-oil : 1 1 194.0 86: sun-meal : 1 1 153.0 87: lin-oil : 1 1 262.5 88: cotton-oil : 1 2 1262.7 89: rye : 1 1 383.0 90: nkr : 1 2 122.3 By far most documents have either one or two labels, but some have up to 15: labelcount= 1, documentcount=9160 labelcount= 2, documentcount=1173 labelcount= 3, documentcount= 255 labelcount= 4, documentcount= 91 labelcount= 5, documentcount= 52 labelcount= 6, documentcount= 27 labelcount= 7, documentcount= 9 labelcount= 8, documentcount= 7 labelcount= 9, documentcount= 5 labelcount=10, documentcount= 3 labelcount=11, documentcount= 2 labelcount=14, documentcount= 2 labelcount=12, documentcount= 1 labelcount=15, documentcount= 1 Let's look at the relationship between the classes. Which classes occur often together? Are there classes which can be used to predict the presence of other classes? For example, wheat should imply grain . Here are the 50 strongest predictors: castor-oil => cotton-oil (0.999742566611) castor-oil => groundnut-oil (0.999742566611) castor-oil => lin-oil (0.999742566611) castor-oil => nkr (0.999742566611) castor-oil => rye (0.999742566611) castor-oil => sun-meal (0.999742566611) copra-cake => palmkernel (0.999742566611) cotton-oil => castor-oil (0.999742566611) cotton-oil => groundnut-oil (0.999742566611) cotton-oil => lin-oil (0.999742566611) cotton-oil => nkr (0.999742566611) cotton-oil => rye (0.999742566611) cotton-oil => sun-meal (0.999742566611) groundnut-oil => castor-oil (0.999742566611) groundnut-oil => cotton-oil (0.999742566611) groundnut-oil => lin-oil (0.999742566611) groundnut-oil => nkr (0.999742566611) groundnut-oil => rye (0.999742566611) groundnut-oil => sun-meal (0.999742566611) lin-oil => castor-oil (0.999742566611) lin-oil => cotton-oil (0.999742566611) lin-oil => groundnut-oil (0.999742566611) lin-oil => nkr (0.999742566611) lin-oil => rye (0.999742566611) lin-oil => sun-meal (0.999742566611) nkr => castor-oil (0.999742566611) nkr => cotton-oil (0.999742566611) nkr => groundnut-oil (0.999742566611) nkr => lin-oil (0.999742566611) nkr => rye (0.999742566611) nkr => sun-meal (0.999742566611) palmkernel => copra-cake (0.999742566611) rye => castor-oil (0.999742566611) rye => cotton-oil (0.999742566611) rye => groundnut-oil (0.999742566611) rye => lin-oil (0.999742566611) rye => nkr (0.999742566611) rye => sun-meal (0.999742566611) sun-meal => castor-oil (0.999742566611) sun-meal => cotton-oil (0.999742566611) sun-meal => groundnut-oil (0.999742566611) sun-meal => lin-oil (0.999742566611) sun-meal => nkr (0.999742566611) sun-meal => rye (0.999742566611) castor-oil => copra-cake (0.999613849916) castor-oil => dfl (0.999613849916) castor-oil => naphtha (0.999613849916) castor-oil => nzdlr (0.999613849916) castor-oil => palladium (0.999613849916) castor-oil => palmkernel (0.999613849916) Multi-label Scoring I have to work on the scoring; it seems as if I made a mistake in my experiments when I calculated the score. I've never been in a multi-label context, so it was not directly clear to me which scoring is used. Thanks to Chirag Nagpal who pointed me in the right direction. Let \\(Y_i \\in \\{0, 1\\}&#94;k\\) be the set of correct labels for document \\(i\\) and \\(Z_i \\in \\{0, 1\\}&#94;k\\) be the set of predicted labels: Binary Accuracy : For each document, one has to make a decision for each possible category. Hence \\(\\text{acc} = \\frac{1}{n}\\sum_{i=1}&#94;n \\frac{|Y_i \\cap Z_i|}{k}\\) . As most documents belong to one or two categories, the simplest classifier simply decides all the time that the document does not belong to any category. For the used dataset, this leads to an accuracy of 0.986. Hence accuracy is not suitable. Subset Accuracy : This is calculated by sklearn . The set of predicted labels must be exactly the same as the true labels. F1 score : See user manual Micro/macro averaged ROC or Precision/Recall curve: Micro: Calculate metrics globally by counting the total true positives, false negatives and false positives. Macro: Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account. Coverage error: See user manual A nice overview is given by A Literature Survey on Algorithms for Multi-label Learning . n-gram Features See N-Gram-Based Text Categorization: Categorizing Text With Python . I will give this a try when I find some time. If you make it before, please share the results. You could adjust my tf-idf code . Classifier comparison (tf-idf) The following are the accuracies as well as the training and test times. All classifiers got the same tf-idf features. Used vocabulary size = 26147 Classifier Acc F1 -------------------------------------------------------------------------------- MLP : 82.61% 85.56% in 676.44s train / 0.91s test LinearSVC : 81.05% 84.04% in 27.00s train / 6.45s test Logistic Regression (C=1000) : 80.79% 84.10% in 35.48s train / 6.46s test k nn 5 : 72.97% 76.07% in 9.89s train / 1092.29s test k nn 3 : 72.28% 75.43% in 9.90s train / 1080.20s test Logistic Regression (C=1) : 67.47% 67.21% in 30.22s train / 6.44s test Random Forest (200 estimators): 65.75% 64.36% in 57.56s train / 4.15s test Random Forest (50 estimators) : 64.79% 63.69% in 14.82s train / 1.30s test Decision Tree : 55.75% 53.23% in 28.43s train / 0.22s test Naive Bayes : 43.86% 47.98% in 214.75s train / 88.79s test SVM, linear : 33.55% 29.67% in 6326.33s train / 2397.51s test There are a couple of things to notice here: Speed : Naive Bayes and k-nn is slow Random forests and MLP are fast SVM depends extremely on the implementation (see What is the difference between LinearSVC and SVC(kernel=\"linear\")? ) Prediction Quality : LinearSVC, logistic regression and MLP are accurate Achieving high binary accuracy seems to be easier than achieving high F1 scores. It's no surprise that high subset accuracy is hard to achieve. The MLP has a reasonable prediction quality and test time. Multilayer Perceptron When training a multilayer perceptron for a multi-label classification task, there are two important things to keep in mind: Output layer : Do not use softmax, as the normalization does not make sense in this case. Loss : Use `binary_crossentropy When you print precision, recall, F1-score and accuracy you note the following: Binary accuracy gets to 98% in the first epoch and over 99% in the second. It stays that high. Precision is at about 4% in the first epoch and over 97% in the second. It stays that high. Recall needs about 15 epochs of steady progress to get over 98%. As a consequence, the F1 score steadily increases. Hence by using other metrics one can see that the classifier makes great improvements, although the accuracy is pretty high from the beginning. Code See GitHub . If you use it, please cite this article or link to this blog post: @Misc{Thom2017-reuters, Title = {The Reuters Dataset}, Author = {Martin Thoma}, Month = jul, Year = {2017}, Url = {https://martin-thoma.com/nlp-reuters} } Data loading #!/usr/bin/env python # -*- coding: utf-8 -*- \"\"\" Utility file for the Reuters text categorization benchmark dataset. See also -------- http://www.vision.caltech.edu/Image_Datasets/Caltech101/ \"\"\" from nltk.corpus import reuters from nltk.corpus import stopwords from sklearn.preprocessing import MultiLabelBinarizer from sklearn.feature_extraction.text import TfidfVectorizer n_classes = 90 labels = reuters . categories () def load_data ( config = {}): \"\"\" Load the Reuters dataset. Returns ------- Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`. \"\"\" stop_words = stopwords . words ( \"english\" ) vectorizer = TfidfVectorizer ( stop_words = stop_words ) mlb = MultiLabelBinarizer () documents = reuters . fileids () test = [ d for d in documents if d . startswith ( 'test/' )] train = [ d for d in documents if d . startswith ( 'training/' )] docs = {} docs [ 'train' ] = [ reuters . raw ( doc_id ) for doc_id in train ] docs [ 'test' ] = [ reuters . raw ( doc_id ) for doc_id in test ] xs = { 'train' : [], 'test' : []} xs [ 'train' ] = vectorizer . fit_transform ( docs [ 'train' ]) . toarray () xs [ 'test' ] = vectorizer . transform ( docs [ 'test' ]) . toarray () ys = { 'train' : [], 'test' : []} ys [ 'train' ] = mlb . fit_transform ([ reuters . categories ( doc_id ) for doc_id in train ]) ys [ 'test' ] = mlb . transform ([ reuters . categories ( doc_id ) for doc_id in test ]) data = { 'x_train' : xs [ 'train' ], 'y_train' : ys [ 'train' ], 'x_test' : xs [ 'test' ], 'y_test' : ys [ 'test' ], 'labels' : globals ()[ \"labels\" ]} return data if __name__ == '__main__' : config = {} data = load_data ( config ) print ( \"len(data['x_train'])={}\" . format ( len ( data [ 'x_train' ]))) print ( \"data['x_train'].shape={}\" . format ( data [ 'x_train' ] . shape )) MLP #!/usr/bin/env python \"\"\"Train and evaluate a MLP.\"\"\" import time from keras.layers import Activation , Input , Dropout from keras.layers import Dense from keras.models import Model from keras.optimizers import Adam import reuters from keras import backend as K from scoring import get_tptnfpfn , get_accuracy , get_f_score def create_model ( nb_classes , input_shape ): \"\"\"Create a MLP model.\"\"\" input_ = Input ( shape = input_shape ) x = input_ x = Dense ( 256 , activation = 'relu' )( x ) x = Dropout ( 0.5 )( x ) x = Dense ( 256 , activation = 'relu' )( x ) x = Dense ( nb_classes )( x ) x = Activation ( 'sigmoid' )( x ) model = Model ( inputs = input_ , outputs = x ) return model def recall ( y_true , y_pred ): \"\"\" Recall metric. Only computes a batch-wise average of recall. Computes the recall, a metric for multi-label classification of how many relevant items are selected. \"\"\" true_positives = K . sum ( K . round ( K . clip ( y_true * y_pred , 0 , 1 ))) possible_positives = K . sum ( K . round ( K . clip ( y_true , 0 , 1 ))) recall = true_positives / ( possible_positives + K . epsilon ()) return recall def precision ( y_true , y_pred ): \"\"\" Precision metric. Only computes a batch-wise average of precision. Computes the precision, a metric for multi-label classification of how many selected items are relevant. Source ------ https://github.com/fchollet/keras/issues/5400#issuecomment-314747992 \"\"\" true_positives = K . sum ( K . round ( K . clip ( y_true * y_pred , 0 , 1 ))) predicted_positives = K . sum ( K . round ( K . clip ( y_pred , 0 , 1 ))) precision = true_positives / ( predicted_positives + K . epsilon ()) return precision def f1 ( y_true , y_pred ): \"\"\"Calculate the F1 score.\"\"\" p = precision ( y_true , y_pred ) r = recall ( y_true , y_pred ) return 2 * (( p * r ) / ( p + r )) def get_optimizer ( config ): \"\"\"Return an optimizer.\"\"\" lr = config [ 'optimizer' ][ 'initial_lr' ] optimizer = Adam ( lr = lr ) # Using Adam instead of SGD to speed up training return optimizer def main ( data_module ): \"\"\"Load data, train model and evaluate it.\"\"\" data = data_module . load_data () model = create_model ( data_module . n_classes , ( data [ 'x_train' ] . shape [ 1 ], )) print ( model . summary ()) optimizer = get_optimizer ({ 'optimizer' : { 'initial_lr' : 0.001 }}) model . compile ( loss = 'binary_crossentropy' , optimizer = optimizer , metrics = [ precision , recall , f1 , \"accuracy\" ]) t0 = time . time () model . fit ( data [ 'x_train' ], data [ 'y_train' ], batch_size = 32 , epochs = 20 , validation_data = ( data [ 'x_test' ], data [ 'y_test' ]), shuffle = True , # callbacks=callbacks ) t1 = time . time () res = get_tptnfpfn ( model , data ) t2 = time . time () print (( \"{clf_name:<30}: {acc:0.2f}% {f1:0.2f} % i n {train_time:0.2f}s \" \"train / {test_time:0.2f}s test\" ) . format ( clf_name = \"MLP\" , acc = ( get_accuracy ( res ) * 100 ), f1 = ( get_f_score ( res ) * 100 ), train_time = ( t1 - t0 ), test_time = ( t2 - t1 ))) if __name__ == '__main__' : main ( reuters ) See also NLTK: Other datasets Reuters-21578 Publications: Text Categorization with Support Vector Machines: Learning with Many Relevant Features Blog posts: Miguel Malvarez: Classifying Reuters-21578 collection with Python: Representing the data Miguel Malvarez: Classifying Reuters-21578 collection with Python","tags":"Machine Learning","title":"The Reuters Dataset"},{"url":"https://martin-thoma.com/document-classification/","text":"This article explains how to classify texts. Suppose you have a text classification problem. For example, you want to classify incoming emails as (C1) spam (C2) notifications (C3) personal. Hence each email belongs to exactly one of three classes. Basic Setup Suppose you have corpus of 1000 emails. You make a stratified split into 600 training emails and 400 test emails. The class C1 is 40% of the data, C2 is 10% of the data and C3 is 50% of the data in both, the training and the test set. Don't touch the test set until the very end. Let \\(I_1 \\subsetneq 1, \\dots, 600\\) be the set of indices of emails which belong to class C1, \\(I_2 \\subsetneq 1, \\dots, 600\\) be the set of indices of emails which belong to set C2 and \\(I_3 \\subsetneq 1, \\dots, 600\\) be the set of emails which belong to set C3. Get Features Now you build a list of unique words \\(w\\) . Let \\(W \\in \\mathbb{N}\\) denote the total number of unique words in the training set. So you know which words appear in the documents in the training set. There are certainly words which you did not see in the training set. Don't worry about this. Let the count how often word \\(w\\) appears in email \\(i = 1, \\dots, N\\) be denoted by \\(n_{w,i} \\in \\mathbb{N}\\) . Let \\(n_{w, \\text{total}} = \\sum_{i=1}&#94;N n_{w,i}\\) be the count how often the word \\(w\\) appears in all documents combined. Word Presence Feature For each word, you can have a binary feature: Either the word is in the e-mail or not. I call this the \"word presence feature\". Now you can calculate: If a word \\(w\\) appears in a document, the probability that the e-mail belongs to class 1 is $$P(C_1|w) = \\frac{\\sum_{i \\in I_1} 1_{n_{w,i} \\geq 1}}{n_{w, \\text{u}} = \\sum_{i \\in I_1 \\cup I_2 \\cup I_3} 1_{n_{w,i} \\geq 1}}$$ Hence you divide the number of e-mails of the first class in which the word \\(w\\) appeared at least once by the total count of e-mails in which the word \\(w\\) appeared at least once. Ok, but you don't only have one feature, but many. You are interested in \\(P(C_1 | w_1, \\dots, w_N)\\) . By applying Bayes Rule, we get: \\begin{align} P(C_1 | w_1, \\dots, w_N) &= \\frac{P(w_1, \\dots, w_N | C_1) \\cdot P(C_1)}{P(w_1, \\dots, w_N)}\\\\ &= \\frac{P(w_1 | C_1) \\cdot P(w_2 | w_2, C_1) \\dots \\cdot P( w_{N} |w_1, \\dots, w_{N-1}, C_1) \\cdot P(C_1)}{P(w_1, \\dots, w_N)} \\end{align} Now, \\(P(C_1) = 0.4\\) is called the a priori probability of the class \\(C_1\\) . So if we knew nothing about the content of the e-mail, we would guess \\(C_1\\) has a probability of 40% as it is the amout of e-mails in that class. The other terms are more difficult. We don't have enough data for this. So we make the simplifying (and wrong!) assumption that words are independant of each other. Then we get: \\begin{align} P(C_1 | w_1, \\dots, w_N) &= \\frac{P(w_1 | C_1) \\cdot P(w_2 | C_1) \\dots \\cdot P( w_{N} | C_1) \\cdot P(C_1)}{P(w_1, \\dots, w_N)} \\end{align} As we know that $$1 = \\sum_{i=1}&#94;3 P(C_i | w_1, \\dots, w_N)$$ it is sufficient to calculate the nominators and divide each of the three denominators by the sum of all three. Congratulations, your first document classifier is working! Tf-idf For each word, we can measure how often it appears in a given e-mail. Certainly, the more often it appears the more important it is. But the longer the e-mail is, the less important it is. So we should divide by the total count of words of an e-mail. This is called the term frequency (Tf) of a word in a document (e-mail). Sometimes, this is also denoted by \\(\\text{tf}(w, d)\\) where \\(w\\) is the word (term) and \\(d\\) is the document (e-mail). Next, we realize that some words contain more information than others. For example, the word \"the\" might occur in almost every document. We do so by dividing by $$\\text{idf}(w, D) = \\frac{N}{|d \\in D: w \\in d|}$$ where \\(N = 600\\) is the total amount of documents we have in the training set. The denominator is the total count of words in all documents in the training set combined. Hence we can get a Tf-idf feature for all words. You can see that this allows us to apply the same Bayesian approach as before. In fact, you should now see that the Bayesian approach is not part of the features, but a classifier! And if you look at the tf-idf Wikipedia page you can see that there are a couple of similar features! Terms instead of Words I've only talked about words before, but you can calculate tf-idf for terms , too. Take \"New York\" as an example. You might see \"New\" in an e-mail and you might see \"York\" in an e-mail. But the combined term \"New York\" is something different than seeing both single words. Hence you might want to have the tf-idf feature of \"New York\", too. Classifiers I've introduced the Bayes Classifer, but there are a lot more. Most notably: SVMs Neural Networks Decision Trees (and Random Forests) See my Comparing Classifiers for a lot more classifiers. Feature Engineering One thing I would try to find out is which features are really good. You can probably figure out keywords with this approach. Hence you can make sense of the decision. And you might be able to throw away a lot of words. PCA / LDA are two feature reduction methods that might be interesting. Other methods are: Forward Feature Construction: Start with an empty set of features. For each feature not in the feature list: Find the one where adding it leads to the best accuracy. If the desired accuracy is reached, stop. Otherwise continue with 2. Feature Elimination Start with all features. For each feature in the feature list: Try where removing it leads to the least loss in accuracy. If the accuracy dropped below the required accuracy, stop and take the last feature list. Otherwise, continue with 2. Evaluation Last, but not least, I suggest the following approach to evaluate what you apply for your e-mail classifier: Split the training set into 500 e-mails for training and 100 e-mails for validation Traing all methods you guess on the 500 e-mails. Evluate on the 100 e-mails what is best. Make sure everything is what you think it should be like. Run your experiments with those 500 / 100 e-mails When you're finished, evaluate on the 400 e-mails your final setup. Only once. This is your estimate how good you really are. You might also want to have a look at cross-validation. Public Datasets I'm not aware of public datasets for document classification, but you can easily create one by scraping wikipedia categories / subreddits. Leave a comment if I forgot something / you know more details :-) Literature Juan Ramos: Using TF-IDF to Determine Word Relevance in Document Queries","tags":"Machine Learning","title":"Document Classification"},{"url":"https://martin-thoma.com/design/","text":"Most people think about really fancy things when they hear \"design\". Some think about Apple products, websites or art. When I say design, I mean it as a very general concept. For this article, I mean usability. How to structure things. And things could be websites or phones, but also anything else. This article is mainly an excercise for me to keep my eyes open and recognize good and bad designs in the wild. Citys Company buildings / stores should be placed towards streets. So people can easily see them. Living spaces should be in buildings in the back. House Kitchen Let's take my kitchen as an example: My kitchen The general placement of the sink is good: You want to be able to have space on both sides so that you can have the dirty stuff on one side, clean it, and put it on the clean side. This way you don't have to lift anything dirty over the clean tableware. And you want to have the stove on the side where the dirty stuff is, because if you make something in the pan the fat could make the stuff around dirty. But thinking a bit more about it, you can see a downside of this kitchen: The sink has no included rack. This means when I lift something out of the sink and put it on the table rack to the left, the table gets wet. Modern sinks all have this: A modern sink has a place where you can put the wet stuff. It has its own drain. So the layout of a kitchen should be like this: Layout of a kitchen: Some place on the very right, then the stove, then some place for dirty plates, the sink, and an integrated board where you can put the clean, wet plates. For me, it feels a bit more natural to take things from the right side, but the mirrored version is fine, too. Doors Doors should never open to the corridor. People might go fast through corridors and opening doors could cause injuries. Residential buildings: It should be possible to open a door a bit more than 90Â°. If it is opened like this, the door should be placed wide enough away from the next wall so that you can put a small shelf behind it. Bathroom Shower curtains: Do not use them. They are cheap, yes. But they get pulled in by the temperature difference. They look bad. They get dirty and have to be replaced. Washing machines: They should always have a display which shows how long they need to finish. Receipts Receipts are designed quite bad. In order to give you a feeling for it, have a look at the following: 3 Receipts of Penny, Lidl and Aldi Useful for the customer Green: Adress Orange: Opening times Blue: What was bought and when Black: Might be required by law Trash for the customer: Pink: Advertisement Turquoise: Might be useful for the company; information about the transaction Yellow: Trash for everybody How could it be done better? Just design it like a letter: Adress and opening times at the top (Lidl has a good format) Then the Date Then what was bought (again, Lidl has a good format there - make the end price significantly larger than the rest) Put legal stuff next Put stuff you need for your busines last And especially: Reduce everything which might not be necessary for the customer to a minimum. Medicine Package Inserts Package insert of medicine There are a couple of things to notice here: A lot of text Only in German No (obvious) way to find it in another language I would expect the following: Make the name very obvious âœ” Add an URL where you can download the receipt as a (searchable) PDF âœ˜ Make blocks for important sections âœ” Use standardized icons for some sections: Pregnancy (there is a Unicode symbol ) Interactions with other medicine (e.g. â‡„) What it is for (e.g. ðŸ›ˆ) How / when / how much to take (e.g. â°) Interactions with preconditions (e.g. ðŸ¤’ or ðŸ˜· or ðŸ¤•) Driving and heavy machineary (e.g. ðŸš—) Storage (e.g. â„) Possible side-effects (e.g. ðŸ’Š â†’ ðŸ¤’) Add a description how the medicine looks like! Laptop An office laptops (for work / studying) needs to have the following: Easy possiblity to connect to beamers Easy to carry Lightweight enough, including all power supplies / adapaters Easy to grab, even if you have multiple other things to carry Power supply: For gods sake, make standardized power supplies! I understand that we need more than one (e.g. office laptops vs. gaming laptops)... but certainly we do not need more than 5! It was possible for smartphones with the common EPS (yes, Apple has a bad design here again), so please make something similar for laptops too. Touchpad: Add a hardware switch for enabling / disabling it. Software Interactive Shells Stolen from Amjith Ramanujam - Awesome Command Line Tools : Persistent History History Search Auto-Completion Minimal Config Syntax Coloring For Python, you can use the prompt toolkit for the prompt options and Pygments for syntax highlighting.","tags":"My bits and bytes","title":"Design"},{"url":"https://martin-thoma.com/docker/","text":"Docker is a tool which allows developers to make deployment of their software easier. Imagine you have a web service. Then you usually not only have your own software, but you built it with other libraries. You run it on a web server. The server needs some configuration, exposes some ports, reads and writes data. Being a good developer, you identified different components which can be built (and scaled) independently (aka microservices). They have a way to talk with each other and they need to run in order to make the service work. As you are the developer, you know what you need. But you might not be the one who deploys the software. Hence you have to write documentation about it. And you can create a (Docker) container. Glossary Image An image is an immutable file which contains the application code, the operating system, the required software. They are created with docker build . Images can be stored in a registry such as hub.docker.com . An image is defined using a Dockerfile . Typically, an image is built on another image. You can list images on your machine with docker images . Container A virtual operating system. It is an instance of an image. A container is created with docker run . A methaphor used by paislee is that an image is a class and a container is an object. They encapsulate the environment in which the application runs. docker ps -a lists all containers - running and stopped. Docker Compose A tool for defining and running multi-container applications. Docker Swarm A tool to deploy containers in a cluster. Similar to Kubernetes. Kubernetes A tool to deploy containers in a cluster. Similar to Docker Swarm. Context Containers vs Virtual Machines Resource sharing / isolation : Docker containers share resources. A docker container is similar to a host process, hence the memory / CPU scheduling will be handled by the host for Docker. Docker is less isolated than a VM. Docker containers use less disk space and less memory. Startup time : A VM takes minutes to start, Docker takes seconds to start Kernel : Docker containers share the same kernel (the host kernel) whereas each virtual machine has its own kernel. Alternatives Although Docker seems to be by far the most common container tool, there are alternatives: Rocket LXD Flockport And there are VMs: VirtualBox VMware Workstation Using Docker First, install Docker . Dockerfile A Dockerfile defines an image. It is a simple text file which could look as follows: FROM ubuntu:latest LABEL maintainer=\"info@martin-thoma.de\" # Settings for the local user ENV APP_USER docker ENV APP_USER_UID 9999 ENV APP_USER_GROUP docker ENV APP_USER_GROUP_GID 4711 # Install and update software RUN apt-get update -y RUN apt-get install -y python-pip python-dev build-essential RUN apt-get upgrade -y # Copy projects code COPY . /opt/app WORKDIR /opt/app RUN pip install -r requirements.txt # Create user RUN groupadd --gid ${ APP_USER_GROUP_GID } ${ APP_USER_GROUP } RUN useradd --uid ${ APP_USER_UID } --create-home -g ${ APP_USER_GROUP } ${ APP_USER } RUN chown -R $APP_USER : $APP_USER_GROUP /opt/app # Start app USER docker RUN mkdir -p /opt/app/uploads ENTRYPOINT [\"python\"] CMD [\"app.py\"] Let's go through it: FROM defines on which base image we built our image. We add another layer to that one. LABEL : Add metadata in a key=value based fashion to the image. RUN <command> : Execute this. COPY <src> <dest> : Copy files from src on the host to dest in the container. WORKDIR /abs/path/to/workdir : Work directory for and RUN , CMD , ENTRYPOINT instruction that follows ENTRYPOINT [\"executable\", \"param1\", \"param2\"] : Run this when the Docker container is started. CMD [\"executable\",\"param1\",\"param2\"] : The command is to run via the entrypoint. Commands Docker needs to be run in super-user mode. I indicate that with # . You can run sudo su in order to run all subsequent commands as a superuser. List all images: # docker image ls List all running containers: # docker container ls Go into an interactive ( -i ) bash in a pseudo-tty ( -t ) in a container with ID 4f7d3f0763ad : # docker exec -it 4f7d3f0763ad bash Volumes If you copy the code directly into the image, you need to rebuild the image every time you make a change to the code. In order to prevent this, you can use volumes. There are two types of volumes: Persist and share data between containers Share folders between host and containers List volumes: # docker volume ls Remove volumes: # docker volume rm <volume name> docker-compose.yml The docker-compose.yml is a YAML file which defines multi-container applications. It looks like this: version: '3' # Version number of the docker-compose file format services: web: build: . command: app.py ports: - \"8082:5000\" volumes: - .:/opt/app # enables hot code reloading - uploads:/opt/app/uploads # for data persistance (<volume name>:<abs path in container>) links: - db hostname: myappserver environment: - MYSQL_ROOT_PASSWORD=p@ssw0rd123 - MYSQL_DATABASE=flask_db - MYSQL_HOST=db - MYSQL_PORT=3306 depends_on: - db db: image: mysql ports: - \"3307:3306\" environment: - MYSQL_ROOT_PASSWORD=p@ssw0rd123 - MYSQL_DATABASE=flask_db - MYSQL_HOST=mysqlserver volumes: - ./flask_db.sql:/docker-entrypoint-initdb.d/flask_db.sql volumes: uploads: driver: local Start it with docker-compose up . The host name of each service is the name of the service itself. You can find the data persistance volume with: # docker volumes ls DRIVER VOLUME NAME local db6caef4eae28832f35af0951e95ae77d6c29189a793300f5aa9523cd25af362 local flaskmysqldockerized_uploads And you can find the path on the host with # docker volume inspect flaskmysqldockerized_uploads [ { \"Driver\": \"local\", \"Labels\": { \"com.docker.compose.project\": \"flaskmysqldockerized\", \"com.docker.compose.volume\": \"uploads\" }, \"Mountpoint\": \"/var/lib/docker/volumes/flaskmysqldockerized_uploads/_data\", \"Name\": \"flaskmysqldockerized_uploads\", \"Options\": {}, \"Scope\": \"local\" } ] Cleanup Kill all running containers: # docker kill $(docker ps -q) Delete all stopped containers # docker rm $(docker ps -a -q) Delete all images # docker rmi $(docker images -q) Remove unused data # docker system prune See also Docker.com Dockerfile reference Compose file version 3 reference StackOverflow ( docker tag ) Docker image vs container How is Docker different from a normal virtual machine? What is the difference between CMD and ENTRYPOINT in a Dockerfile? Docker Clustering Tools Compared: Kubernetes vs Docker Swarm github.com/MartinThoma/flask_mysql_dockerized : A minimal example how to use a database and a webserver with docker-compose .","tags":"Code","title":"Docker"},{"url":"https://martin-thoma.com/ml-get-data/","text":"Machine Learning is only possible with data. The more data, the better. For many services this is a self-improving system. The more data the system gets, the better it becomes. The better the system is, the more users use it. The more users use the system, the more data the system gets. This is an awesome property, but what do you do if you don't have any / enough data to create a useful system? How do you bootstrap a machine learning system? I will take write-math.com (handwritten symbol recognition) and Amazon book recommendations as examples. Generate Data yourself Sometimes, it is possible to generate data yourself. This is what I did for write-math.com. It could be expected that users are not too different - after all, single symbols should look somewhat similar, no matter who wrote them. This is not possible for Amazon recommendations as they are mainly dependant on the user. Ask friends You can ask friends / collegues to use your system and feed it with data. I did this with write-math.com, too. Gamification Sometimes, you can make a game which is interesting enough to attract users to use your system and feed it with data. For example, Google did this with Quickdraw . Side-steping Some tasks can be re-formulated so that they are intersting for other problems. Examples are Asirra and reCaptcha: You are given 12 images. Your task is to identify all images which contain dogs. The developer knows the content of 11 images. If you get those 11 right, some trust is put into your classification of the 12th image. Similar, for reCaptcha you are given two words. The developer knows one of them. It is placed randomly on the left or the right. If you get that one right, some trust is put into your classification of the other one. Another example is Duolingo. Alternative Algorithms You could use other algorithms with do not need data. Expert systems are examples for this kind of algorithm. Just let an expert hand-craft rules. This could work for Amazon recommendations: Get besteller lists to rank books initially. As soon as the user liked one book of one author, add a little bit to the score of all other books of that author. Users who bought one edition of a book usually don't buy the same book in another edition. Hence reduce the score for them. ... Sparse matrix completion For recommendation systems, you can define user \"prototypes\" (\"the nerd\", \"the artist\", \"the gamer\", ...). Define their properties. Find one person for each prototype. Let them rank the books. Not necessarily every book, but many. You could add rules to infer the ranking of missing books. As soon as a new user arrives, ask them about some distinguishing books. Try to see in which prototypes (or mixture of prototypes) they fit best. Recommend new books according to that mixture.","tags":"Machine Learning","title":"How to get Data for ML systems"},{"url":"https://martin-thoma.com/unsupervised-pretraining/","text":"Neural networks have thousands, often millions of parameters. They take hundrets of features and predict thousands of classes. The features can often not be seen independantly, but have to be taken as a whole into consideration. Most parameters are not independant either. And still, we use only on the order of several ten-thousand to a million data points to optimize the millions of parameters in a network. We know that more labeled data leads to better results, but labeling is costly. Obtaining more data, however, is comparatively cheap. Hence we want to use the unlabeled data to learn good features. The complete process is semi-supervised and works as follows: Unsupervised training : Train a neural network with unlabeled data Network modification : Change something in the network. Often, the output layer is adjusted. Supervised training : Train the neural network with labeled data In the following, I will introduce all unsupervised training methods I know. Auto-Encoders The idea of an auto-encoder is to restore the input. Hence it has to have an output layer which is capable of doing so. This means you have to choose your activation function carefully and probably normalize the range of values of the input. For example, if your inputs have negative values you cannot use the logistic function or ReLU. If it doesn't sum to one, you can't use softmax. If the range of values is outside of [-1, 1], you can't use most of the activation functions. Also, you have to make sure the shape of the output is the same as the input. After that, you have multiple options: Bottleneck features: You can force the auto-encoder to learn a feature reduction by introducing a bottleneck. After the training is finished, everything after the bottleneck could be removed. Restauration: The input of the network is changed in some way which has to be restored by the network. This could be white noise, Gaussian noise, or completely removing some parts of the image (as done in Context Encoders: Feature Learning by Inpainting ). Look for \"denoising auto-encoder\". Literature: Jonathan Masci, Ueli Meier, Dan Ciresan, and JÃ¼rgen Schmidhuber: Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction Crop position prediction If you have a CNN and images as input, crop it into 9 pieces which are loosely placed in a grid over the image (with some variable padding). Give the network the middle crop and randomly one of the 8 others. The network has to predict which crop it got. Hence the network has 8 output units. Predict the position of an image crop Image source: Unsupervised Visual Representation Learning by Context Prediction Literature: Carl Doersch, Abhinav Gupta, Alexei A. Efros: Unsupervised Visual Representation Learning by Context Prediction Order I could imagine that you could do something similar to the crop position prediction with time series data. For example, if you have audio data you could give the network two samples and let it predict which one comes first. Or if you have a video, you can predict the next frame. See Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning . Predict the next frame of a video. Image source: Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning Weakly Supervision The more detailed / high quality labels are, the more expensive. For example, it is often simpler to classify one complete image than to assign a class label to each pixel of the image. But you can build models for semantic segmentation without having a single image which was semantically labeled. This is what I call weak supervision . Another example is counting: You have many images of street scenes. Each image has the number of cars in that image as a label. The idea is that a neural network should learn a car classifier from this information. I think I have seen something similar before, but I don't remember where (NIPS 2016?) More I have seen Discriminative Unsupervised Feature Learning with Convolutional Neural Networks but I didn't understand what they are doing. They take a random patch of one image, apply random data augmentations to that image and assign it a (random) class. How is that supposed to help?","tags":"Machine Learning","title":"Unsupervised Pretraining"},{"url":"https://martin-thoma.com/ml-review-5/","text":"This Review gives an overview of intersting stuff I stumbled over which are related to machine learning. News Canada's AI Moment AI is one step closer to mastering StarCraft : Multiagent Bidirectionally-Coordinated Nets for Learning to Play StarCraft Combat Game Deep learning for satellite imagery via image segmentation Hardware: Nvidia Volta ( reddit ) Nvidia BB 8 (self-driving car) First In-Depth Look at Google's TPU Architecture Datasets: Medical ImageNet READ-BAD - detecting baselines in scanned documents Google's AlphaGo AI still undefeated, beats world's best human Ke Jie again Live Demos, Websites and Blogs Jonathan Pilault: Adam-Nesterov results : Related to the OpenAI gym. lyrebird.ai : Imitate voices with only one minute of recorded speech Publications Beyond Face Rotation: Global and Local Perception GAN for Photorealistic and Identity Preserving Frontal View Synthesis - generate frontal view faces from side view input Cyclical Learning Rates for Training Neural Networks BAM! The Behance Artistic Media Dataset for Recognition Beyond Photography : A dataset with 393000 labeled images, 7 types of images (vector art, pencil-sketch, ...) and 9 classes Software FaceApp caffe2 - although caffe will be continued, it is probably a good idea to switch? CycleGAN : Translate between horses and Zebras FaceApp : See this and reddit fastText : library for efficient learning of word representations and sentence classification FBLearner Flow Interesting Questions What are 2D dimensionality reduction algorithms good for? What is the memory cost of a CNN? How should the bias be initialized and regularized? Is there a relationship between LDA, linear SVMs and Perceptron? Miscallenious Blogs / Websites distill.pub : Some nice articles (e.g. one about t-SNE) Meetings Amsterdam, 8. April 2017: PyData Austin (Texas, USA), 10. July 2017: SciPy 2017 Â« Previous Review","tags":"Machine Learning","title":"ML Review 5"},{"url":"https://martin-thoma.com/nlp/","text":"Natural language processing (NLP) is a scientific field which deals with language in textual form. Tasks Classification : Is an e-mail spam or not? Topic: Is it about sports, science or religion? Language: Is it English, German or French? Sentence boundary: Is a character the boundary of a sentence or not? Author: Identify the author from a given set of authors Age of the author Gender of the author Sentiment analysis (Opinion mining, opinion extraction, sentiment mining, subjectivity analysis) Machine Translation (MT): Given a text in language A, return the same content in language B. Similarity calculation : Given a corpus of n texts and one text A as input, find passages of the corpus which are similar to passages of A. This can be used to detect if students copied content / copyright violation. Minimum Edit Distance Spelling correction : Find places where the grammar / writing needs to be fixed. Word sense disambiguation : If \"mouse\" is in a sentence, is it about the computer mouse or the animal. POS Tagging : Detect adjectives, verbs, nouns in a sentence. Summarization / Paraphrasing Information extraction : For example, find the date in a calender application when the user enters the name of the event. Or dates in an e-mail in order to allow users to create a calender date. Named Entity Recognition (NER): Find names in a text Classify names into names of places, people, organizations and non-names. Relation Extraction Compound splitting : For German, \"DonaudampfschiffskapitÃ¤n\" can be split into the compounds \"Donau\" (a river) \"dampfschiff\" (steam boat) and \"kapitÃ¤n\" (captain). Sentiment analysis Find out how users feel about something. Opinion mining and sentiment analysis Sentiment Lexicons are compared by Christopher Potts (\"Sentiment Tutorial\", 2011): General Inquirer is free for research use List of categories Positive (1915 words) and negative (2291 words) strong vs weak, active vs passive, overstated vs understated pleasure, pain, virtue, vice, motivation, cognitive orientation, ... Spreadsheet LIWC - Linguistic Inquiry and Word count: 30 US-Dollar or 90 US-Dollar fee 2300 words, more than 70 classes affective process (negative and positive emotion) cognitive processes: Tentative (maybe, perhaps, guess), Inhibition (block, constraint) Pronouns, Negation (no, never), Quantifiers (few, many) Bing Liu Opinion Lexicon 6786 words (2006 positive, 4783 negative) SentiWordNet Positivity of a word can be infered from reviews. Reviews with many stars should have positive words, reviews with only one or two stars should have negative words. Text generation Generate text in a given style / tone. Andrej Karpathy: The Unreasonable Effectiveness of Recurrent Neural Networks Named Entity Recognition Named entities are sequences of word tokens. Each word token can either be other (O), the beginning of a namend entity (B) or the continuation of a named entity (I): IO-encoding IOB-encoding Adam PER B-PER gives O O Berta PER B-PER Charlies PER B-PER Smith PER I-PER 's O O table O O -------------------------------------- #NER 2 3 IOB encoding Relation Extraction ACE (Automated Content Extraction): 17 relations from 2007 \"Relation Extraction Task\" UMLS (Unified Medical Language System): 134 entity types, 54 relations One approach is taking seed relations to find language patterns. For example, a seed relation could be BORN-IN(Albert Einstein, Ulm) . Now find all sentences in a corpus which contain \"Albert Einstain\" and \"Ulm\". You might find find patterns like: Albert Einstein, born in Ulm, ... Albert Einstein (1879, Ulm) ... One son of Ulm is Albert Einstein. Now you can extract language patterns: X, born in Y, ... X (?, Y), ... One son of Y is X. Unsupervised Information Extraction (or Open Information Extraction) does not start with given relations or training data. The textrunner algorithm is one way to do it. Data sources and Corpora Thesaurus: WordNet Twitter Wikipedia News websites Amazon Reviews AP Newswire IMDB: Polarity data 2.0 (sentiment analysis) Reuters newswire dataset DBPedia: 1 billion RDF triples Freebase: many relations Name Tokens Types Switchboard phone conversations 2 400 000 20 000 Shakespeare 884 000 31 000 Google N-Grams 1 000 000 000 000 13 000 000 bAbI ? ? Libraries NLTK : The natural language toolkit. Written in Python, for Python. ( Book ) SpaCy : According to reddit , it is cleaner than NLTK but less complete. TextBlob : A simple to start toolkit for Python. CoreNLP: Faster than NLTK (source?), written in Java, Python wrappers available gensim : topic modeling and document similarity analysis fasttext : a classifier on top of a sentence2vec model DeepText: an NLP engine Tensorflow syntaxnet and Parsey McParseface ( paper ) Products aspell Google n-gram Viewer Google Translate Quora: Duplication detection IBM Watson Terminology / Methods Backoff: Use trigram if possible. If not, backoff to bigram (or unigram). Alternatively, use interpolation of trigram, bigram and unigram Filled pauses: \"uh\" in English or \"Ã¤hm\" in German Fragment: A part of a word (e.g. if you transcribe spoken text and somebody stutters) Lemma: Two words belong to the same lemma if they have the same stem, belong to the same POS and have the same meaning. Lexer: One type of tokenizer Maxent classifiers n-gram model: Model language by counting word-tuples of length n. Naive Bayes OOV: Out of vocabulary, <UNK> token Porters Algorithms Regular expressions (see regexpal.com to test) sentence2vec: Similar to word2vec. Statistical parsing Stemming: Bring a word in a normed form (the stem). Mostly for verbs. Tokenization: Segment the text into tokens. Tokenizer: Splits a text into tokens. Viterbi Algorithm word2vec: Embedd any word in a (high-dimensional) vector space. Allows vector arithmetic. More might me in my ML Glossary . Smoothing A common task in NLP is estimating the probability of a word given some other words: \\(P(w_i | w_{i-1}, w_{i-2})\\) . You can do that by counting n-grams \\((w_{i-2}, w_{i-1}, w_{i})\\) : $$P(w_i | w_{i-1}, w_{i-2}) = \\frac{N((w_{i-2}, w_{i-1}, w_i))}{N((w_{i-2}, w_{i-1}))}$$ But you will quite often have the case that you did not see a 3-gram. How do you deal with that? Smoothing is the answer. The simplest method is Laplace Smoothing (aka Add-one smoothing). How do you deal with words you've never seen? The Good-Turing smoothing method uses things you've seen once to estimate things you've never seen: $$P&#94;*_{GT}(\\text{things never seen}) = \\frac{N_1}{N}$$ $$P&#94;*_{GT}(\\text{thing seen}) = (\\frac{(c+1) N_{c+1}}{N_c}) / N$$ when \\(c\\) bekomes \"large\" (depends on the dataset), just replace \\(N_c\\) by a best-fit power law. Other smoothing methods Interpolated Kneser-Ney Good-Turing Smoothing Stupid backoff: For very large N-grams Another important concept is the continuation probability. While some words (like \"a\", \"to\", \"the\", ...) can be followed / preceeded by many different words, others (like \"San\", \"Angelo\", \"D.C.\", \"United States of\", ...). The continuation probability quantifies how likely it is that a word is continued by something novel. Putting this together with absolute discounting gives the Kneser-Ney Smoothing algorithm: $$P_{KN}(w_i | w_{i-1}) = \\frac{\\max( c(w_{i-1}, w_i) - d, 0)}{c(w_{i-1})} + \\lambda (w_{i-1}) P_{continuation}(w_i)$$ where \\(\\lambda \\in \\mathbb{R}\\) weights how important the continuation probability is, Data structures Bloom filter : a space-efficient probabilistic data structure that is used to test whether an element is a member of a set Trie : A prefix-tree Resources KIT: The ASR course has some NLP content Reddit: /r/LanguageTechnology StackExchange: datascience.stackexchange.com Online Courses: Coursera: Introduction to Natural Language Processing Stanford: Natural Language Processing with Deep Learning Dan Jurafsky and Chris Manning on YouTube: Stanford NLP Oxford: Lecture Notes Machine Translation","tags":"Machine Learning","title":"Natural Language Processing"},{"url":"https://martin-thoma.com/cfg-files-defaults/","text":"I often need configuration files in the software I develop. In principle, I can think of two ways to deal with configuration files: Complete : The configuration file has to have all values which will later be accessed by the application Partial : The configuration file might only define some values. In case the application needs a value which is not in the user defined configuration file, a default value is used. The complete approach has the major drawback of making updates difficult. The user(s) might have different configuration files for different usage scenarios. In the worst case the user has to update his files manually, just because the developer added a couple of possibilities to customize the application. Hence I prefer the partial approach where a default configuration file is part of the application. This default config file will not be overwritten. It contains all values necessary for the user. But the user may define a user config file which he may adjust. The user can peek at the default file to see what he can customize, but he can keep his config file clean. Here is a small example how you can do this with Python: #!/usr/bin/env python # -*- coding: utf-8 -*- \"\"\"Example how to load config file with defaults.\"\"\" import json def load_config ( cfg_filename ): \"\"\"Load a configuration file.\"\"\" with open ( cfg_filename ) as data_file : data_loaded = json . load ( data_file ) return data_loaded def merge_dicts ( cfg_defaults , cfg_user ): \"\"\" Merge two dictionaries. Parameters ---------- cfg_defaults : dict Iterate through this dict cfg_user : dict Update this dict so that it has all keys which the other file has. \"\"\" for k , v in cfg_defaults . iteritems (): if k not in cfg_user : cfg_user [ k ] = v elif isinstance ( v , dict ): merge_dicts ( v , cfg_user [ k ]) def load_config_defaults ( cfg_filename , cfg_default_filename ): \"\"\"Load a configuration file with defaults.\"\"\" cfg_defaults = load_config ( cfg_default_filename ) cfg_user = load_config ( cfg_filename ) # Idea: Take the user config. If anything is missing, add it from the # defaults. # So iterate through the default dict and check if it is in the user dict, # too. Add it if not. cfg = cfg_user merge_dicts ( cfg_defaults , cfg ) return cfg print ( load_config_defaults ( \"user_cfg.json\" , \"default_cfg.json\" )) See also Configuration files in Python","tags":"Code","title":"Defaults of Configuration Files"},{"url":"https://martin-thoma.com/amazons-power/","text":"Once in a while I see people demanding to buy products in stores rather than on Amazon. It is interesting that Amazon is seen as the only online retailer, but as it certainly is the biggest retailer in Germany I will focus on it for now. To make the following simpler to write, lets say Steven wants Alice to buy stuff in shops while Alice usually uses Amazon. Why Amazon replaces Retail Stores Price : Alice mainly cares about the price. And in many cases, Amazon sells the product for the cheapest price or is at least competitive. Range of products : Amazon offers pretty much everything. There are only a few products which you can find in stores but not on Amazon. Why should Alice bother to go to a store if she might end up buying it on Amazon anyway because the store does not have the production she is looking for? Reliability : At the beginning, Alice worried what she could do if something went wrong. If the product she bought didn't arrive. If it was damaged. If she changed her mind and wanted to give it back. But after a couple of years she built up trust. In contrast to the local store, she knows Amazon. She never had a problem. She doesn't even know anybody personally who ever had a problem which could not be resolved. But with local shops, she already had a couple of problems. The most simple was is loosing the receipt. Simple to use : Alice goes on amazon.de, searches for the product name (and he doesn't need to remember the correct name due to fuzzy search). She clicks on the product, on buy. That's it. Buying a product can be done within a few seconds. No need to go out of the house. Alice already has an Amazon account, so there is no need to create a new account. Anonymity : For some products, Alice might feel uncomfortable to buy them from a person. It doesn't matter that the information that the user bought a product is stored by Amazon. It's not a top-secret thing. And Alice trusts Amazon that they do not make her purchases public. Recommendations : Once in a while Alice goes to Amazon to buy something and gets a good recommendation for another product. It's just so simple to buy this one, too. So quite a bit of the advantage is just that online shops have advantages over local shops. The other bit is the massive size of Amazon and the data it gets. Stevens arguments Steven predicts that local shops will close if Alice doesn't buy her stuff in those shops. This is a really shitty argument. Why should a person who does not buy something in a store care if the store is closed? It might even be desirable because there is more room for stores Alice actually cares about. Or more room for apartments. Steven continues that people working in local shops will loose their jobs . Alice mentions coachman, litter carriers and wagon makers who lost their jobs by the automobile, bank clerks who are replaced by cash dispensers, Charcoal burners , type setters, ... Probably all of them demanded not to use the technology by which they lost their jobs. What is different in this case? Steven says Amazon does not pay taxes and does not treat their workers fair. Well, this might be a valid reason. But then you would have to check the conditions of the shops which you use instead, too. And, after all, it is the duty of politics and worker organizations to force all employers to have fair working conditions. How to fix it Most advantages of Amazon are mainly advantages of online shops. Except for cloths, food and a few very special items Alice does not need to see the item before she buys it. She only needs to know the specifications. If single shops really wanted to break the power of Amazon, they could collaboratively create one online shop. Not every shop on its own, but together. One open shopping platform. Many small shops and some bigger shops could be shareholders of this platform. Probably the government should also be a big shareholder of it. Just to make sure that the interests of many people are considered. It might not even be necessary to actually sell the product online, but just to have a list of currently available products online. Then Alice could check where the closest shop is that has this product and buy it there instead of Amazon. Apparently, the situation of those small shops is not so bad. Otherwise they could start creating such a shop. The Einzelhandelsverband , for example, claims to have 100 000 members. Seems to be big enough to start such an open platform. In fact, there is a platform called fairmondo which tried this. But the retails did not join it. The real problems Amazon is a monopoly. One company dominates online sales. Businesses can use Amazons platform to sell their products, but Amazon can also not allow some of them to sell it. Amazon can (and does) analyze which kind of product is easy to produce and get sold often. They have the data what kinds of features are important to the customers. So they can shift product by product from only a platform which sells products to producing the products themselves. Now, what happens if Amazon is down? What happens if the US government decides to put sanctions on a country? Also, Amazon is bigger than you might think. But Amazon AWS is probably another topic. More ArchÃ¤ologie der Arbeit: Berufe, die es nicht mehr gibt (German)","tags":"Cyberculture","title":"Amazons Power"},{"url":"https://martin-thoma.com/msthesis/","text":"Thesis Analysis and Optimization of Convolutional Neural Network Architectures Models For each of the 8 datasets you can find 10 trained baseline models and 10 trained optimized models here: zenodo.org/record/582892 Code github.com/MartinThoma/msthesis-experiments To be fixed STL-10 evaluation setup: I used the complete training set for training, but the datasets page gives 10-folds. Hence I have about 11% more labeled training data than intended.","tags":"My bits and bytes","title":"Master Thesis"},{"url":"https://martin-thoma.com/working-at-fzi/","text":"If you are writing your Bachelors or Masters thesis or if you're a HiWi at FZI , you might find the following useful. OpenVPN Download the client.ovpn from the website your advisor gives you. This website can only be accessed outside of FZI and needs to be accessed by https:// - http:// does not work. Run it with sudo openvpn --config client.ovpn Verify it with ifconfig - there should be tun0 WLAN Wi-Fi Security: WPA & WPA2 Enterprise; PEAP; No CA certificate required; MSCHAPv2 IPv4: Automatic (DHCP) IPv6: Ignore Python Virtalenv You don't have root access. However, you can install Python packages via virtualenv (at nobackup - you don't need this to be backed up and you want to have less limitations on your venv size): $ mkdir ml-venv $ cd ~/ml-venv $ virtualenv ml $ source ml/bin/activate Add the source ml/bin/activate (with the absolute path) to your ~/.bashrc . Now you can use pip install ... to install whatever you need in which version you need. cuDNN Add export LD_LIBRARY_PATH=/fzi/ids/thoma/nobackup/cuda/lib64/ to your ~/.bashrc . If that doesn't exist anymore, just download cuDNN and adjust the path to the lib64 folder. Blame users With nvidia-smi you can see which processes currently use the graphics card: Thu Apr 13 19:14:50 2017 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 361.93.02 Driver Version: 361.93.02 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | |===============================+======================+======================| | 0 GeForce GTX 980 Ti On | 0000:01:00.0 On | N/A | | 53% 83C P2 255W / 250W | 5621MiB / 6083MiB | 93% Default | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | |=============================================================================| | 0 2473 G /usr/bin/X 24MiB | | 0 32756 C ./caffe 5591MiB | +-----------------------------------------------------------------------------+ But it doesn't tell you how long the process is already running and which user started it. With $ ps -p 32756 -o user -o time (replace 32756 by the process ID, of course) you can find the user name and how long the process is running. Send files See Linux Commands for Working from home and How to copy files from one machine to another using ssh . Copy foo.txt from localhost to a remote host: $ scp foo.txt yourusername@remotehost.com:/home/remote/dir Disk usage $ quota -s -u user1 $ df -h . $ du -h . SSH / screen How do I force detach Screen from another SSH session? Kill detached screen session Misc top or htop for showing processes / who uses much memory / CPU How to use Sublime Text via SSH users to see who is currently logged in. Personalabteilung If you want to get your money back from the code card, you have to go to the \"Personalabteilung\". They have very limited opening times: Opening times of FZI","tags":"Cyberculture","title":"Working at FZI"},{"url":"https://martin-thoma.com/rental-scam/","text":"I am currently searching for a flat in Munich. While doing so, I've seen (and contacted) three scammers. As most of the communication is in German, I will continue this article in German. You can use Google Translate . BetrÃ¼gerische Nachrichten Wohnung 1 Inserat auf immonet.de: Miete zzgl. NK: 393 â‚¬ WohnflÃ¤che: ca. 55 mÂ² Objekt-ID: Immonet-Nr.: 30652500 80538 MÃ¼nchen , Kanalstrasse 6 www.immonet.de/angebot/30652500 Von Dr. S. Ch. Ku s.ch.ka71@gmail.com . Hallo, Danke fÃ¼r Ihr Interesse meine Wohnung zu mieten. Mein Deutsch ist sehr schlecht, ich wÃ¼rde schÃ¤tzen, wenn wir in Englisch sprechen kÃ¶nnen. Ich mÃ¶chte mich vorstellen auch. Mein Name ist Sandra Christina Kutson und ich bin ein 46-jÃ¤hrige Arzt aus Manchester / GroÃŸbritannien. Die Wohnung, die ich von meinem GroÃŸvater, der vor 2 Jahren gestorben vererbt. Auch habe ich zwei kinder, aber nach wenigen gesprÃ¤chen mit ihnen, wird niemand kommen in Deutschland zu bleiben, so mÃ¶chte ich die wohnung fÃ¼r einen beliebigen zeitraum zu mieten (ab 1 monat bis 20 jahre oder mehr). Doch selbst nehme ich die entscheidung, nach Deutschland nicht zurÃ¼ck, ich mÃ¶chte nicht, die wohnung zu verkaufen. Die Wohnung befindet sich auf Kanalstrasse 6, 80538 MÃ¼nchen, ist komplett mÃ¶bliert und vor kurzem renoviert, wie man auf den Fotos sah. Die Wohnung befindet sich im zweiten Stock und das GebÃ¤ude ist in sehr gutem Zustand und haben auch Zugang zum Aufzug. Dies ist ein 2 zimmer wohnung (1 Schlafzimmer, 1 Bad, 1 KÃ¼che, 1 Wohnzimmer, 1 Keller) mit einer GesamtflÃ¤che von 55m Â². Die Wohnung ist ausgestattet mit: Klimaanlage, Waschmaschine, Staubsauger, Haartrockner, Herd, Flatiron, Mikrowelle, Grill, Toaster, Mixer, KÃ¼hlschrank, Kaffeemaschine, LED-TV, DVD-Player, usw. Die Nebenkosten (Heizkosten, Strom, Gas, Wasserkosten, MÃ¼llabfuhr, Grundsteuer, GebÃ¤udeversicherung, Internet, Kabel-TV und Parkplatz) ausgestattet sind, in der \"Warmmiete\" enthalten von 393 EUR / Monat. Ich will eine \"Kaution\" von 393 Euro, rÃ¼ckzahlbar, wenn Sie sich bewegen (ich muss zu verlassen innerhalb von 30 Tagen wissen). In der Zwischenzeit kÃ¶nnen Sie bestÃ¤tigen Sie bitte die folgenden Schritte aus: Â· Wie viele Menschen auf dem GrundstÃ¼ck leben wÃ¼rden? Â· Wann mÃ¶chten Sie sich zu bewegen? (Check-in Datum) Â· Welche Begriff / LÃ¤nge mieten mÃ¶chten Sie? Â· Haben Sie Haustiere? Â· Wann sind Ihre am besten geeigneten Zeiten / Tage, um die Immobilie zu sehen? Bei Interesse weiter, mir bitte einige Informationen Ã¼ber sich selbst geben (Alter, Beruf, Lebensstil oder was auch immer denken Sie macht einen guten Mieter). Ich hoffe, dass die E-Mail nicht zu lang war, Ich mag mÃ¶glichst grÃ¼ndlich. Freundliche GrÃ¼ÃŸe aus GroÃŸbritannien! PS: Ich akzeptiere keine JobCentre. Wohnung 2 Inserat: Miete zzgl. NK: 350 â‚¬ WohnflÃ¤che: ca. 105 mÂ² Objekt-ID: Immonet-Nr.: 30651870 80336 MÃ¼nchen - Ludwigsvorstadt-Isarvorstadt, Stielerstrasse 3 www.immonet.de/angebot/30651870 E-Mail von Gregory Barnett <gregorybarnett90@hotmail.com> Hallo, Vielen Dank fÃ¼r Ihr Interesse an meiner 3 zimmer Wohnung. Sie hat eine WohnflÃ¤che von 105 mÂ², 2 Schlafzimmer, ist vollstÃ¤ndig mÃ¶bliert und wurde vor kurzem renoviert. Hier finden Sie einige Fotos: http://imgur.com/a/c1Qav Die Immobilie kann auch unmÃ¶bliert gemietet werden, in diesem Fall sorge ich fÃ¼r den Abtransport und die Lagerung der MÃ¶bel. Die Wohnung hat eine Klimaanlage, GeschirrspÃ¼ler, Herd, KÃ¼hlschrank / Gefrierschrank, Waschmaschine, LED-TV, Staubsauger etc. Die Nebenkosten (Wasser, Strom, Internet, Kabelfernsehen) sind in der Miete von 350 â‚¬ bereits enthalten und werden monatlich automatisch von meinem Konto beglichen. Wie Sie sehen kÃ¶nnen, die Miete ist sehr erschwinglich. Ich bin nicht die Wohnung fÃ¼r einen Gewinn zu mieten. Ich ziehe jemanden zu haben, es verwenden, anstatt es leer zu halten. Die Kaution in HÃ¶he von 450 â‚¬ wird Ihnen bei Auszug erstattet (eine Anmeldung 30 Tage im Voraus ist dafÃ¼r nÃ¶tig). Haustiere sind erlaubt, sofern sie keinen ernsten Schaden anrichten. Nun ein bisschen zu meiner Person: Mein Name ist Gregory Barnett und ich bin Bauingenieur aus Grossbritannien. Ich habe die Wohnung gekauft und renoviert, als ich 2014 fÃ¼r 10 Monate in Deutschland gelebt und gearbeitet habe. Nun bin ich dauerhaft wieder in England, suche also einen zuverlÃ¤ssigen Mieter. Am besten wÃ¤re ein Vertrag von langer Dauer, muss aber nicht unbedingt so sein. Leider kann ich in den nÃ¤chsten Monaten aus beruflichen und gesundheitlichen GrÃ¼nden nicht mehr ins Ausland reisen, kann Sie daher auch nicht sofort persÃ¶nlich treffen. Daher habe ich eine Ã¶rtliche Immobilienagentur mit groÃŸer Erfahrung im Bereich internationaler Vermietungen beauftragt, den ganzen Vorgang abzuwickeln. Die Kosten dafÃ¼r werde ich vollstÃ¤ndig Ã¼bernehmen. Also, wenn Ihnen das zusagt, lassen Sie mich wissen, mit wie vielen Personen Sie beabsichtigen, einzuziehen und fÃ¼r welchen Zeitraum. Ãœber nÃ¤here Informationen zu Ihrer Person wÃ¼rde ich mich auÃŸerdem sehr freuen. Sie kÃ¶nnen in Englisch oder Deutsch antworten. Viele GrÃ¼ÃŸe und einen schÃ¶nen Tag noch! Da die Bilder von ImgUr eventuell verschwinden habe ich sie hier mal in niedriger AuflÃ¶sung kopiert: Meine Antwort: Dear Mr. Barnett, I can't find the advertisement for the flat. As I send a couple of requests I'm not quite sure about which one you're talking. Could you please send me the link to it? (or at least the address) I am seeking a flat only for myself. I am a software engineer and I want to rent the flat from the beginning of June. Right now, I don't know how long I will stay but likely for several years. Best regards (and get well soon), Martin Antwort \"Mietverfahren\" von Gregory Barnett <gregorybarnett90@gmail.com> Thank you for replying, The property is managed by Chelsea Homes, a local real estate agency, specialized in international transactions. Their website is: www.chelsea-homes.co.uk . They will arrange a viewing for you, and handle the payments and contract. Also if you have any questions, feel free to contact them anytime you need, because I might not always be available. You can find their details on the Contact page of their website. Now here's how the rental works: 1. First you need to register with the agency at: www.chelsea-homes.co.uk/register.html by entering your details in the form and clicking SUBMIT. 2. I'll drop off 2 sets of keys and the necessary paperwork at their office 3. The agency will email you the invoice for the first rent (350â‚¬)+ Kaution (450â‚¬). This is just to reserve the property, and not a final commitment of course,. Once you've made the payment, the agency will book the viewing for you, and within 1-2 days, one of their agents will meet you in Germany to show you the property and help you with all the formalities. 4. After the viewing, if you're satisfied with the place you will sign a contract with the agent and receive the keys so you can move in. However if you don't like the apartment, for whatever reason, you will have no obligations and the full payment will be refunded by the agent immediately. The whole procedure shouldn't take more than 3 days in total. I'm paying for the services of the agency, so there will be no extra costs for you. Also, in case you're tied up in another contract and cannot move in immediately, we can arrange the viewing now, and reserve the apartment for you. Since we're unable to meet in person I've attached a copy of my passport, so you can have a reference of your potential landlord. Please consider my offer and let me know if we have a deal, because there are several others interested in the apartment, and I need to make a decision soon. Have a great day! --------------------------------------------------- Gregory Barnett Er hat auch \"seinen\" Reisepass in den Anhang getan: Passport No: 209742387 Name: Gregory Barnett P<GBRGREGORY<BARNETT<<<<< 2097423878GBR7912207M1904286<<<<<<<<<02 Gregory Barnett Mal schauen was / wer sich hinter chelsea-homes.co.uk steckt: whois chelsea-homes.co.uk Domain name: chelsea-homes.co.uk Registrant: Chelsea Homes Group Ltd. Trading as: CHELSEA HOMES GROUP LTD Registrant type: UK Limited Company, (Company number: 10358460) Registrant's address: 78 Golders Green Road London 02081444194 NW11 8LN United Kingdom Data validation: Nominet was able to match the registrant's name and address against a 3rd party data source on 21-Feb-2017 Registrar: eNom LLC [Tag = ENOM] URL: http://www.enom.com Relevant dates: Registered on: 21-Feb-2017 Expiry date: 21-Feb-2018 Last updated: 24-Feb-2017 Registration status: Registered until expiry date. Name servers: dns1.namecheaphosting.com dns2.namecheaphosting.com WHOIS lookup made at 09:28:03 06-Apr-2017 Mit companieshouse.gov.uk kann man noch mehr Informtionen ermitteln: Registered office address: Office 35 78 Golders Green Road, London, United Kingdom, NW11 8LN Nature of business (SIC) : 68100 - Buying and selling of own real estate Company type : Private limited Company Incorporated on : 5 September 2016 Company Director 1 : Mr Hanan Shapira Date of Birth : **/01/1969 Nationality : Romanian Company Director 2 : Mr Oded Loulay Date of Birth : **/06/1980 Nationality : British Sucht man nach dieser Firma, findet man wohnungsbetrug.blogspot.de mit genau diesen Daten. Naja, egal. Mal schauen wie viel SpaÃŸ man mit BetrÃ¼gern haben kann. Meine Antwort: Dear Mr. Barnett, Your flat looks really gorgeous and I really want it, but I'm also a bit unsure about scams. Before I register to this site I don't know, could you please help me to trust you? You could, for example, take a photo of yourself holding up a sign with your name and the current data (or a recent newspaper). Alternatively, you could send me 10 Euro to https://www.paypal.me/MartinThoma so that I know it is actually your passport. Best regards, Martin Wohnung 3 Inserat: Miete zzgl. NK: 350 â‚¬ WohnflÃ¤che: ca. 90 mÂ² Objekt-ID: Immonet-Nr.: 30652495 80807 MÃ¼nchen - Milbertshofen-Am Hart, Leopoldstr. 188 80807 MÃ¼nchen Schwabing Von claudia Marsik <claudiaosterrich@outlook.com> mit denisewalter@ymail.com im CC Hallo, Danke fÃ¼r Ihr Interesse , Ich kaufte diese Wohnung fÃ¼r meinen Sohn wÃ¤hrend seines Studiums , aber jetzt ist er wieder zu Hause in GroÃŸbritannien dauerhaft, so dass ich die Vermietung der Ort fÃ¼r unbegrenzte Zeit. Bevor wir weiter gehen, mÃ¶chte ich etwas Ã¼ber Sie wissen , wie zB wie viele Personen Sie beabsichtigen, in der Wohnung leben, was ist Ihre Aufgabe Wie alt bist du und fÃ¼r wie lange Sie bleiben Die Wohnung ist genau wie auf den Bildern, voll mÃ¶bliert ausgestattet und renoviert in diesem Jahr. Auch sehr wichtige, die Versorgungsunternehmen Wasser, Strom, Heizung, Gas, Internet, TV-Kabel, SpÃ¼lmaschine, MÃ¼llabfuhr, sind im Preis von 350 Euro pro Monat inklusive und ich glaube, es bequem fÃ¼r uns beide ist. Alle Rechnungen werden von mir bezahlt werden und Sie nur das Geld fÃ¼r die Miete im Monat zahlen. Die Kaution ist auch 350 â‚¬, und Sie bekommen es zurÃ¼ck wenn Sie sich entscheiden, die Wohnung zu verlassen ( Sie haben mir mindestens 1 Monat KÃ¼ndigungsfrist zu geben ). Sie kÃ¶nnen meine MÃ¶bel verwenden, oder Sie kÃ¶nnen auch Ihre eigenen verwenden, wenn Sie bevorzugen. Ich bin ein Neuro-Onkologie Arzt aus GroÃŸbritannien. Ich kann Vorkehrungen, um die Wohnung von hier aus schnell und einfach mieten machen . Ich freuen, bald von Ihnen zu hÃ¶ren. Hab einen schÃ¶nen Tag! Meine Antwort: Dear Mrs. Marsik, We can also communicate in English if that is more comfortable for you. I want to live alone in the flat. I am 27 years old, a software engineer and I hope to stay in Munich for several years. I can't find the link to the flat. Could you please send it to me again? Best regards, Martin P.S.: Who is Denise Walter? Die Antwort von \"claudia Marsik\" (diesmal mit Marsik <Marsikclaudia@t-online.de> ) waren nur ein paar Bilder: Meine Antwort: Thank you for the nice images. The flat loos gorgeous! Could you please tell me the adress of it again? (I want to live quite central in Munich) Wohnung 4 Via immonet from ÐÐ½Ð°ÑÑ‚Ð°ÑÐ¸Ñ Ð‘Ð¾Ð½Ð´Ð°Ñ€ÑŒ <anastasiia.bondar@amls.email> : Hello, I am in search of persons to rent my apartment, to use and be a responsible loyal tenant to stay in there for minimum 2 months and max 5 years, could either be students or workers. My apartment is still available, it was rented by some students and now they left. It is already furnished with all basic stuff, as well as the kitchen is also fully equipped with all you need daily incl. a dishwasher, washing machine, dryer, tv. The price for my apartment includes all extra costs (electricity, heating, hot water, internet), the total monhtly rent is 550,00 EUR. You can use my furniture, or you can also use your own if you prefer. Foto's: postimg.org/gallery/xgakskw8/ Address of apartment is: Nordendstrasse 2, 80799 MÃ¼nchen. I am looking forward to hearing from you. Thanks Anastasiia Bondar. My answer: Hello Anastasiia, that sounds good! When can I have a look at the apartment? (I'm currently in Karlsruhe; the soonest I could come is on Sunday. Otherwise, I can come at any time / day) Best regards, Martin Scammer reply: Hello, My apartment was rented through Uniplaces agency by some students and now they left. So, my apartment is available for rent. You can rent for more than 5 years , there is no problem because we can renew our contract. Don't matter if you are student or not, you can book through Uniplaces. I would like to use Uniplaces again because they are currently managing my property. Once you will confirm the booking on Uniplaces you will check the property. Using Uniplaces system both parties are fully protected, because they will hold the funds until you will sign the rental contract. Let me explain you the process step by step for a better understanding: - I will list the property on Uniplaces for EUR 550 per month with bills included . The rental contract can be made for at least 2 months - up to 5 years. - You will have to pay 2 months deposit ( EUR 1100) to Uniplaces in order to confirm your booking. This 2 months deposit covers ( 1 months of rent + 1 month security deposit) - All the taxes and bills are included in the rental price; It includes also 1 parking places; - Like mentioned several times a viewing before booking is not possible since I'm not there, but Uniplaces is guaranteeing the whole transaction between us. In case something gets damaged, you can deduct the amount from the rental price, of course with a bill attached. If everything sounds good to you, I'll be able to send you the Uniplaces listing so you can book it at your convenience. Also, in case you have another apartment right now, and you can't move immediately, we can make the agreement as explained here, and consider it only an inspection and reservation until you are able to move there. I am looking forward to hearing from you. Best Regards , Anastasiia Bondar Wohnung 5 Von Jonathan Addy <jonnaddy@gmail.com> : Hallo, Die Wohnung ist verfÃ¼gbar. Die monatliche Miete ist 350â‚¬ (einschlieÃŸlich Stromkosten, Gaskosten, Wasserkosten und TV-Internetzugang, 1 Parkplatz-Tiefgarage). Die Kaution ist 700â‚¬. Zu Beginn Ich habe ein paar Fragen: - wie viele Personen bleiben in der Wohnung? - Wie lange wollen Sie bleiben? - Hast du einen Job? Oder Sie sind Student? - Wie werden Sie zahlen die Miete? Die Haustiere sind erlaubt. Sie kÃ¶nnen mieten die Wohnung von minimal 2 Monate bis zu 10 Jahren (mit VerlÃ¤ngerungsmÃ¶glichkeit). Die Wohnung haben MÃ¶bel aber ich kann es zu entfernen falls Sie es wollen. Die TV und Internetverbindung sind enthalten im Mietpreis. InnenausrÃ¼stung: Waschmaschine, Mikrowelle, Staubsauger, KÃ¼hlschrank, Herd. Ich reise mit meinem Job und ein Treffen von Angesicht zu Angesicht ist nicht mÃ¶glich. Wir kÃ¶nnen nutzen eine Immobilienagentur fÃ¼r diese Miete Prozess. Ich komme aus GroÃŸbritannien also bitte entschuldigen mich mein schlechtes Deutsch. Sie kÃ¶nnen sehen Fotos hier: http://imgur.com/a/F0Zf0 Danke, Jonathan Addy. Meine Antwort: Sehr geehrter Herr Addy, - Nur ich werde in der Wohnung wohnen. - Ich suche etwas langfristiges, hÃ¤tte also gerne einen unbefristeten Vertrag. - Ich habe einen Job als IT-Consultant. - Ich werde die Miete Ã¼berweisen. Wann kÃ¶nnte man die Wohnung besichtigen? Mit freundlichen GrÃ¼ÃŸen, Martin Thoma Seine Antwort: Hallo, Danke fÃ¼r Ihre E-Mail. Das warmmiete ist 350â‚¬ monatlich. Die Kaution ist 700â‚¬. Die Gesamtmenge ist 1.050â‚¬ (Ein Monat und die Kaution). In der monatlichen Miete du hast inbegriffen: Stromkosten, Gaskosten, Wasserkosten, TV-Internetzugang, 1 ParkplÃ¤tze, MÃ¼llentsorgung. Ich bin bereit zu senden Ihnen die SchlÃ¼ssel so dass Sie besuchen und Ã¼berprÃ¼fen die Wohnung. Die Ãœbergabe der SchlÃ¼ssel und der Mietvertrag (Von mir signiert) wird werden gemacht von Airbnb (airbnb. com). Diese Miete Prozess-Service geben einen Schutz fÃ¼r beide von uns. Achtung - Das Geld muss geschickt bei Airbnb bevor du erhalten die SchlÃ¼ssel. Wenn Sie zustimmen Senden Sie mir Ihre Daten zu starten die Transaktion. Nachdem ich erhalten die BestÃ¤tigung von Airbnb dass Sie machte den Transfer, Ich werde senden das Paket mit dem Mietvertrag und die Wohnung SchlÃ¼ssel. Ich werde senden die Tracking-Nummer zu Airbnb und zu Ihnen. Wenn Sie nicht mÃ¶gen die Wohnung Airbnb erstatten die Ãœbertragung in Ihrem Bankkonto. Wenn du zustimmst zu mieten die Wohnung Airbnb sendet die Ãœbertragung in mein Bankkonto. Wenn du willst bezahlen im Voraus fÃ¼r 6 Monate oder 1 Jahr, ich kann machen ein Rabatt. FÃ¼r 6 Monate du wirst zahlen 1.750â‚¬ und fÃ¼r 1 Jahr du wirst zahlen 3.300â‚¬. Zu starten die Transaktion Ich brauche die folgenden Angaben: VollstÃ¤ndiger Name: StraÃŸe: Stadt: Postleitzahl: Land: Handynummer: Wie viel Sie wollen zu zahlen: 1.050â‚¬ (Ein Monat und die Kaution), 1.750â‚¬ (fÃ¼r 6 Monate-Kaution inbegriffen) oder 3.300â‚¬ (fÃ¼r 1 Jahr-Kaution inbegriffen)? Ich werde fÃ¼r die Dienste der Agentur zahlen, so dass es keine Kosten fÃ¼r Sie. Vielen Dank! Scam entlarven Bilder Ã¼ber tineye.com oder andere Reverse-Image Search Engines suchen. Wenn man dieselben Wohnungsbilder unter anderen Adressen sieht, weiÃŸ man was Sache ist. Preisvergleich: Wenn es zu gÃ¼nstig wird, wÃ¤re ich vorsichtig Fotos anschauen: Die Fotos die ich bekommen habe sehen zu professionel aus Nichts vorher zahlen: Insbesondere wurde mir abgeraten etwas nach GroÃŸbritannien oder Ã¼ber Western Union zu Ã¼berweisen. Scam melden Googlemail Sonst habe ich leider recht wenige MÃ¶glichkeiten gesehen. Eigentlich hÃ¤tte ich erwartet, dass man die E-Mail Konten ziemlich leicht melden kann, die Accounts bei den WohnungsbÃ¶rsen sofort gesperrt werden und man eine Untersuchung der Polizei einleiten kann. Bei der Polizei bin ich noch und habe auch schnell den Rat bekommen mich auf keinen Fall zu registrieren / Geld zu Ã¼berweisen, aber sonst scheint mir das Interesse nur gering zu sein. Naja, mal schauen. Ich werde den Artikel jedenfalls aktuell halten.","tags":"Cyberculture","title":"Rental Scam"},{"url":"https://martin-thoma.com/git-bundle/","text":"Sometimes you need to share code via E-Mail / stick. If the code you need to share is a git repository, creating a bundle is a pretty good way to do it. You can create a bundle with $ git bundle create repository-name.bundle --all Then you can restore the repository by cloning: $ git clone repository-name.bundle You can also use a bundle as a remote. Hence $ git fetch origin $ git pull Docs git-scm.com/docs/git-bundle How to use git-bundle for keeping development in sync?","tags":"Code","title":"Git Bundle"},{"url":"https://martin-thoma.com/extraordinary-materials/","text":"Line-X Line-X is a protective polymer coating. Vantablack Vantablack is a substance made of vertically aligned carbon nanotube arrays and is the blackest artificial substance known, absorbing up to 99.965% of radiation in the visible spectrum. ( Wikipedia ) Ultra-Ever Dry Superhydrophobic coating Sodium polyacrylate Superabsorbent polymer ( )","tags":"My bits and bytes","title":"Extraordinary Materials"},{"url":"https://martin-thoma.com/silence-tf/","text":"Set the environment variable TF_CPP_MIN_LOG_LEVEL=2 if you're also annoyed by messages like I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally [...] W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations. W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations. W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations. W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations. W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations. W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations. I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: name: GeForce 940MX major: 5 minor: 0 memoryClockRate (GHz) 1.2415 pciBusID 0000:02:00.0 Total memory: 1.96GiB Free memory: 1.55GiB I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0: Y I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce 940MX, pci bus id: 0000:02:00.0) W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 1.11GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available. W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 1.11GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available. I've added export TF_CPP_MIN_LOG_LEVEL=2 to my ~/.profile . Note that this only suppresses the warnings. The better solution would be to compile Tensorflow with SSE-X support.","tags":"Machine Learning","title":"How to silence TensorFlow"},{"url":"https://martin-thoma.com/zca-whitening/","text":"Whitening is a transformation of data in such a way that its covariance matrix \\(\\Sigma\\) is the identity matrix. Hence whitening decorrelates features. It is used as a preprocessing method. When you have \\(N\\) data points in \\(\\mathbb{R}&#94;n\\) , then the covariance matrix \\(\\Sigma \\in \\mathbb{R}&#94;{n \\times n}\\) is estimated to be: $$\\hat{\\Sigma}_{jk} = \\frac{1}{N-1} \\sum_{i=1}&#94;N (x_{ij} - \\bar{x}_j) \\cdot (x_{ik} - \\bar{x}_k)$$ where \\(\\bar{x}_j\\) denotes the \\(j\\) -th component of the estimated mean of the samples \\(x\\) . Any matrix \\(W \\in \\mathbb{R}&#94;{n \\times n}\\) which satisfies the condition $$W&#94;T W = C&#94;{-1}$$ whitens the data. ZCA whitening is the choice \\(W = M&#94;{- \\frac{1}{2}}\\) . PCA is another choice. According to \"Neural Networks: Tricks of the Trade\" PCA and ZCA whitening differ only by a rotation. How to do it When you look at the Keras code , you can see the following: # Calculate principal components sigma = np.dot(flat_x.T, flat_x) / flat_x.shape[0] u, s, _ = linalg.svd(sigma) principal_components = np.dot(np.dot(u, np.diag(1. / np.sqrt(s + 10e-7))), u.T) # Apply ZCA whitening whitex = np.dot(flat_x, principal_components) So, at first you compute the covariance matrix \\(\\Sigma\\) . I'm not quite sure, but I think they should divide by flat_x.shape[0] - 1 for the unbiased estimator. Then you apply singular value decomposition to the estimated covariance matrix. The matrix \\(u \\in \\mathbb{R}&#94;{n \\times n}\\) is unitary and \\(s \\in \\mathbb{R}&#94;{n \\times n}\\) is a diagonal matrix with non-negative real numbers on the diagonal. Those number are the singular values of \\(\\Sigma\\) . Next, the principal components are calculated: [u \\cdot \\frac{1}{\\sqrt{s + 10&#94;{-7}}} I \\cdot u&#94;T] By adding 10e-7 one prevents division by zero. Whitening is then simply the multiplication with the principal components. See also Alex Krizhevsky and Geoffrey Hinton: Learning multiple layers of features from tiny images Optimal whitening and decorrelation","tags":"Machine Learning","title":"ZCA Whitening"},{"url":"https://martin-thoma.com/abschlussbericht-studienstiftung/","text":"Stipendiaten der Studienstiftung des deutschen Volkes mÃ¼ssen am Ende ihres Studiums einen Abschlussbericht schreiben. Damit sich andere Stipendiaten nicht auch jedes mal die Vorlage erstellen mÃ¼ssen, stelle ich meine LaTeX-Vorlage hier bereit. Wenn ihr VerbesserungsvorschlÃ¤ge habt, kÃ¶nnt ihr mir gerne eine E-Mail schreiben (info@martin-thoma.de) oder einen Kommentar hinterlassen. Vorlage \\documentclass [a4paper,12pt] { article } \\usepackage { amssymb } % needed for math \\usepackage { amsmath } % needed for math \\usepackage [utf8] { inputenc } % this is needed for umlauts \\usepackage [ngerman] { babel } % this is needed for umlauts \\usepackage [T1] { fontenc } % this is needed for correct output of umlauts in pdf \\usepackage [margin=2.5cm,headheight=40pt] { geometry } %layout \\usepackage { fancyhdr } % needed for the footer \\usepackage { lastpage } % needed for the footer \\usepackage { hyperref } % links im text \\usepackage { graphicx } %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Hier eigene Daten einfÃ¼gen % %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\newcommand { \\Name }{ Martin Thoma } \\newcommand { \\Datum }{ \\today } % Wann wurde der Bericht erstellt? \\newcommand { \\Ort }{ Karlsruhe } \\newcommand { \\Uni }{ KIT } %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\hypersetup { pdfauthor = { \\Name } , pdfkeywords = { Studienstiftung; \\Uni ; \\Name } , pdftitle = { Abschlussbericht von \\Name } } \\pagestyle { fancy } \\fancyhead [CO,CE] { Abschlussbericht von \\Name } % \\renewcommand{\\headrulewidth}{0pt} \\renewcommand { \\footrulewidth }{ 0pt } \\fancyfoot [C] {} \\fancyfoot [R] { Seite~ \\thepage ~von \\pageref { LastPage }} \\pagenumbering { arabic } \\begin { document } \\title { Abschlussbericht von \\Name } \\author { \\Name } \\date { \\Datum } Was waren die wichtigsten Ereignisse in Ihrem Studium? Was hÃ¤tten Sie im RÃ¼ckblick lieber anders gemacht, was hat sich bewÃ¤hrt? Welche Bedeutung hatte die FÃ¶rderung durch die Studienstiftung fÃ¼r Ihr Studium und Ihre persÃ¶nliche Entwicklung? Welche Angebote der Studienstiftung waren fÃ¼r Sie hilfreich, welche weniger? Denken Sie dabei bitte neben den Veranstaltungen (Sommerakademie, Sprachkurs) auch an die Sprechstunden der Referenten, die Vertrauensdozentengruppe, das Intranet und die AuslandsfÃ¶rderung. Was haben Sie unter den Angeboten der Studienstiftung vermisst? Wo sehen Sie VerbesserungsmÃ¶glichkeiten fÃ¼r unsere FÃ¶rderung von Stipendiaten? Wie sehen Ihre ZukunftsplÃ¤ne aus? In welche Richtung orientieren Sie sich zurzeit? \\vspace { 1cm } \\\\ \\Ort , der \\Datum\\\\ \\\\ % see https://martin-thoma.com/how-to-create-a-digital-signature/ Martin Thoma \\end { document } und Makefile DOKUMENT = abschlussbericht make : pdflatex $( DOKUMENT ) .tex -output-format = pdf pdflatex $( DOKUMENT ) .tex -output-format = pdf make clean clean : rm -rf $( TARGET ) *.class *.html *.log *.aux *.out FAQ Wozu dient der Bericht? â†’ \"Ein RÃ¼ckblick auf Ihr Studium hilft uns unter anderem bei der Beratung jÃ¼ngerer Stipendiaten.\" (vgl. Daidalosnet, Abschlussbericht) Welche Form soll der Bericht haben? â†’ Es gibt keine Vorgabe. 2 - 3 Seiten Umfang sind angemessen. Was soll inhaltlich rein? â†’ vgl. Daidalosnet Was waren die wichtigsten Ereignisse in Ihrem Studium? Was hÃ¤tten Sie im RÃ¼ckblick lieber anders gemacht, was hat sich bewÃ¤hrt? Welche Bedeutung hatte die FÃ¶rderung durch die Studienstiftung fÃ¼r Ihr Studium und Ihre persÃ¶nliche Entwicklung? Welche Angebote der Studienstiftung waren fÃ¼r Sie hilfreich, welche weniger? Denken Sie dabei bitte neben den Veranstaltungen (Sommerakademie, Sprachkurs) auch an die Sprechstunden der Referenten, die Vertrauensdozentengruppe, das Intranet und die AuslandsfÃ¶rderung. Was haben Sie unter den Angeboten der Studienstiftung vermisst? Wo sehen Sie VerbesserungsmÃ¶glichkeiten fÃ¼r unsere FÃ¶rderung von Stipendiaten? Wie sehen Ihre ZukunftsplÃ¤ne aus? In welche Richtung orientieren Sie sich zurzeit? Wer liest den Bericht? â†’ Nur der/die VertrauensdozentIn und ReferentIn. Die Berichte werden wohl sehr vertraulich behandelt. Zum Beispiel hat die Studienstiftung auch die jeweiligen Berichte im Laufe der Ermittlungen gegen die RAF-Mitglieder nicht rausgerÃ¼ckt.","tags":"Cyberculture","title":"Abschlussbericht der Studienstiftung"},{"url":"https://martin-thoma.com/ml-review-4/","text":"This Review gives an overview of intersting stuff I stumbled over which are related to machine learning. New Developments KittiSeg ( reddit ): A toolkit for semantic segmentation based on TensorVision AudioSet : A dataset for accoustic events Publications Evolution Strategies as a Scalable Alternative to Reinforcement Learning Controllable Text Generation Stopping GAN Violence: Generative Unadversarial Networks : Probably one of the funniest ML things I've seen so far. Reminds me of Machine Learning A Cappella - Overfitting Thriller Deep Neural Networks Do Not Recognize Negative Images Twitter100k: A Real-world Dataset for Weakly Supervised Cross-Media Retrieval MINC-2500 dataset Second-order Convolutional Neural Networks Software Pi-DeepLearning ( reddit ) DeepDetect ( GitHub ) Interesting Questions How to predict an item's category given its name? How do you share models? How many FLOPs does tanh need? Miscallenious Color Maps Color Maps are important for visualizing data. But the default color map for many applications is jet, which is bad for several reasons: It's hard to estimate distances from jet Doesn't work well when printed in grayscale Even worse if you are colorblind Jet and the new colormaps The YouTube clip A Better Default Colormap for Matplotlib by Nathaniel Smith and StÃ©fan van der Walt gives a short introduction into color theory. They introduce colorspacious and viscm . viscm is a tool for creating new color maps. They created viridis as a better alternative to jet . A blog post with roughly the same content is at bids.github.io/colormap . This is the default for matplotlib 2.0. If you wonder which matplotlib version you have: $ python - c \"import matplotlib;print(matplotlib.__version__)\" That is how you update matplotlib: $ sudo -H pip install matplotlib --upgrade Here is a list of other matplotlib colormaps: ['Accent', 'afmhot', 'autumn', 'binary', 'Blues', 'bone', 'BrBG', 'brg', 'BuGn', 'BuP', 'bwr', 'CMRmap', 'cool', 'coolwarm', 'copper', 'cubehelix', 'Dark2', 'flag', 'gist_earth', 'gist_gray', 'gist_heat', 'gist_ncar', 'gist_rainbow', 'gist_stern', 'gist_yarg', 'GnB', 'gnuplot', 'gnuplot2', 'gray', 'Greens', 'Greys', 'hot', 'hsv', 'jet', 'nipy_spectral', 'ocean', 'Oranges', 'OrRd', 'Paired', 'Pastel1', 'Pastel2', 'pink', 'PiYG', 'PRGn', 'prism', 'PuB', 'PuBuGn', 'PuOr', 'PuRd', 'Purples', 'rainbow', 'RdB', 'RdGy', 'RdP', 'RdYlB', 'RdYlGn', 'Reds', 'seismic', 'Set1', 'Set2', 'Set3', 'Spectral', 'spectral', 'spring', 'summer', 'terrain', 'Vega10', 'Vega20', 'Vega20b', 'Vega20c', 'winter', 'Wistia', 'YlGn', 'YlGnB', 'YlOrBr', 'YlOrRd'] Finally, some interesting links: How to use viridis in matplotlib 1.4 Matplotlib: Choosing Colormaps Class distribution You should always know if your data is severly unevenly distributed. Here is a little script to visualize the data distribution: import matplotlib.pyplot as plt data = y . flatten () # your labels plt . hist ( data , bins = np . arange ( data . min (), data . max () + 2 )) # yes, +2. plt . show () or import seaborn as sns data = y . flatten () # your labels sns . distplot ( data ) sns . plt . show () For the CIFAR100 training data, this is pretty boring: Distribution of the CIFAR 100 training data. Blogs / Websites Ensembles How to train and classify images using Google Cloud Machine Learning and Cloud Dataflow Machine Learning Startup Competition Baidu Deep Voice explained: Part 1 â€” the Inference Pipeline Laying a trap for self-driving cars SotA in Classification SotA in Object detection Â« Previous Review Next Review Â»","tags":"Machine Learning","title":"ML Review 4"},{"url":"https://martin-thoma.com/object-detection/","text":"Object detection is the following task: You have an image and you want axis-aligned bounding boxes around every instance of a pre-defined set of object classes. The set of object classes is finite and typically not bigger than 1000. Here is an easy to use example Prerequisites Tensorflow CUDA CuDNN Keras weights_SSD300.hdf5 (103.2MB, MD5: 9ae4b93e679ea30134ce37e3096f34fa ) ssd.py and ssd_utils.py from github.com/MartinThoma/algorithms Code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 #!/usr/bin/env python \"\"\" Run object detection with VOC classes. This is just a minor modification of code from https://github.com/rykov8/ssd_keras \"\"\" from keras.applications.imagenet_utils import preprocess_input from keras.preprocessing import image import matplotlib.pyplot as plt import numpy as np from scipy.misc import imread import sys from ssd import SSD300 from ssd_utils import BBoxUtility def create_overlay ( img , results , voc_classes , plt_fname ): \"\"\" Create a visualization of the found objects in img. Paramters --------- img : numpy array Original array results : numpy array Found objects voc_classes : list of strings Names of the classes in Pascal VOC. plt_fname : string Path where the visualization gets stored. \"\"\" plt . clf () # Parse the outputs. det_label = results [:, 0 ] det_conf = results [:, 1 ] det_xmin = results [:, 2 ] det_ymin = results [:, 3 ] det_xmax = results [:, 4 ] det_ymax = results [:, 5 ] # Get detections with confidence higher than 0.6. top_indices = [ i for i , conf in enumerate ( det_conf ) if conf >= 0.6 ] top_conf = det_conf [ top_indices ] top_label_indices = det_label [ top_indices ] . tolist () top_xmin = det_xmin [ top_indices ] top_ymin = det_ymin [ top_indices ] top_xmax = det_xmax [ top_indices ] top_ymax = det_ymax [ top_indices ] colors = plt . cm . hsv ( np . linspace ( 0 , 1 , 21 )) . tolist () plt . imshow ( img / 255. ) currentAxis = plt . gca () currentAxis . axis ( 'off' ) for i in range ( top_conf . shape [ 0 ]): xmin = int ( round ( top_xmin [ i ] * img . shape [ 1 ])) ymin = int ( round ( top_ymin [ i ] * img . shape [ 0 ])) xmax = int ( round ( top_xmax [ i ] * img . shape [ 1 ])) ymax = int ( round ( top_ymax [ i ] * img . shape [ 0 ])) score = top_conf [ i ] label = int ( top_label_indices [ i ]) label_name = voc_classes [ label - 1 ] display_txt = '{:0.2f}, {}' . format ( score , label_name ) coords = ( xmin , ymin ), xmax - xmin + 1 , ymax - ymin + 1 color = colors [ label ] currentAxis . add_patch ( plt . Rectangle ( * coords , fill = False , edgecolor = color , linewidth = 2 )) currentAxis . text ( xmin , ymin , display_txt , bbox = { 'facecolor' : color , 'alpha' : 0.5 }) plt . savefig ( plt_fname ) def main ( img_paths ): \"\"\" Detect objects in images. Parameters ---------- img_paths : list of strings \"\"\" # Load the model voc_classes = [ 'Aeroplane' , 'Bicycle' , 'Bird' , 'Boat' , 'Bottle' , 'Bus' , 'Car' , 'Cat' , 'Chair' , 'Cow' , 'Diningtable' , 'Dog' , 'Horse' , 'Motorbike' , 'Person' , 'Pottedplant' , 'Sheep' , 'Sofa' , 'Train' , 'Tvmonitor' ] NUM_CLASSES = len ( voc_classes ) + 1 input_shape = ( 300 , 300 , 3 ) model = SSD300 ( input_shape , num_classes = NUM_CLASSES ) model . load_weights ( 'weights_SSD300.hdf5' , by_name = True ) bbox_util = BBoxUtility ( NUM_CLASSES ) # Load the inputs inputs = [] images = [] for img_path in img_paths : img = image . load_img ( img_path , target_size = ( 300 , 300 )) img = image . img_to_array ( img ) images . append ( imread ( img_path )) inputs . append ( img . copy ()) inputs = preprocess_input ( np . array ( inputs )) # Predict preds = model . predict ( inputs , batch_size = 1 , verbose = 1 ) results = bbox_util . detection_out ( preds ) # Visualize for i , img in enumerate ( images ): create_overlay ( img , results [ i ], voc_classes , \"{}-det.png\" . format ( img_paths [ i ])) def get_parser (): \"\"\"Get parser object.\"\"\" from argparse import ArgumentParser , ArgumentDefaultsHelpFormatter parser = ArgumentParser ( description = __doc__ , formatter_class = ArgumentDefaultsHelpFormatter ) parser . add_argument ( \"-f\" , \"--file\" , dest = \"filename\" , help = \"Detect objects in image\" , metavar = \"IMAGE\" ) parser . add_argument ( \"--folder\" , dest = \"folder\" , help = \"Detect objects in JPG images in folder\" , metavar = \"FOLDER\" ) return parser if __name__ == \"__main__\" : args = get_parser () . parse_args () if args . folder is not None : import glob images = glob . glob ( \" %s /*.jpg\" % args . folder ) elif args . filename is not None : images = [ args . filename ] else : args . print_help () sys . exit ( 0 ) main ( images ) Examples St Josep La Boqueria Sagrada Familia Cat Barcelona EmiMa-079 EmiMa-100 EmiMa-103 EmiMa-105 Ryck Pittsburgh Conclusion The person detector is somewhat useful out-of-the-box, but for the rest you will need to adjust the algorithm. Having only the 20 classes from Pascal VOC is not enough. See also Dat Tran: Building a Real-Time Object Recognition App with Tensorflow and OpenCV , 22.06.2017","tags":"Machine Learning","title":"Object Detection"},{"url":"https://martin-thoma.com/image-classification/","text":"Image classification is the following task: You have an image and you want to assign it one label. The set of possible labels is finite and typically not bigger than 1000. So for example, you might ask: What can you see in this image? A jellyfish It is one of the most common and probably simplest tasks in the intersection of machine learning and computer vision. A commonly used dataset is ImageNet , which consists of exactly 1000 classes and has more than 1 000 000 training samples. To be exact, it is the ImageNet Large Scale Visual Recognition Challenge (ILSVRC). However, I miss easy to use examples. So here you are. Prerequisites Tensorflow CUDA CuDNN Keras Code The following code is taken from Keras / FranÃ§ois Chollet . Full credit to him for doing the difficult work. The code defines one of the state of the art models, a so called ResNet. See Deep Residual Learning for Image Recognition for details. Then it downloads the weights, stores them for subsequent uses and applies it to the data. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 #!/usr/bin/env python # -*- coding: utf-8 -*- \"\"\"ResNet50 model for Keras.\"\"\" from __future__ import print_function import numpy as np import json import os import time from keras import backend as K from keras.preprocessing import image from keras.applications import ResNet50 from keras.utils.data_utils import get_file CLASS_INDEX = None CLASS_INDEX_PATH = ( 'https://s3.amazonaws.com/deep-learning-models/' 'image-models/imagenet_class_index.json' ) def preprocess_input ( x , dim_ordering = 'default' ): \"\"\" Standard preprocessing of image data. 1. Make sure the order of the channels is correct (RGB, BGR, depending on the backend) 2. Mean subtraction by channel. Parameters ---------- x : numpy array The image dim_ordering : string, optional (default: 'default') Either 'th' for Theano or 'tf' for Tensorflow Returns ------- numpy array The preprocessed image \"\"\" if dim_ordering == 'default' : dim_ordering = K . image_dim_ordering () assert dim_ordering in { 'tf' , 'th' } if dim_ordering == 'th' : x [:, 0 , :, :] -= 103.939 x [:, 1 , :, :] -= 116.779 x [:, 2 , :, :] -= 123.68 # 'RGB'->'BGR' x = x [:, :: - 1 , :, :] else : x [:, :, :, 0 ] -= 103.939 x [:, :, :, 1 ] -= 116.779 x [:, :, :, 2 ] -= 123.68 # 'RGB'->'BGR' x = x [:, :, :, :: - 1 ] return x def decode_predictions ( preds , top = 5 ): \"\"\" Decode the predictionso of the ImageNet trained network. Parameters ---------- preds : numpy array top : int How many predictions to return Returns ------- list of tuples e.g. (u'n02206856', u'bee', 0.71072823) for the WordNet identifier, the class name and the probability. \"\"\" global CLASS_INDEX if len ( preds . shape ) != 2 or preds . shape [ 1 ] != 1000 : raise ValueError ( '`decode_predictions` expects ' 'a batch of predictions ' '(i.e. a 2D array of shape (samples, 1000)). ' 'Found array with shape: ' + str ( preds . shape )) if CLASS_INDEX is None : fpath = get_file ( 'imagenet_class_index.json' , CLASS_INDEX_PATH , cache_subdir = 'models' ) CLASS_INDEX = json . load ( open ( fpath )) results = [] for pred in preds : top_indices = pred . argsort ()[ - top :][:: - 1 ] result = [ tuple ( CLASS_INDEX [ str ( i )]) + ( pred [ i ],) for i in top_indices ] results . append ( result ) return results def is_valid_file ( parser , arg ): \"\"\" Check if arg is a valid file that already exists on the file system. Parameters ---------- parser : argparse object arg : str Returns ------- arg \"\"\" arg = os . path . abspath ( arg ) if not os . path . exists ( arg ): parser . error ( \"The file %s does not exist!\" % arg ) else : return arg def get_parser (): \"\"\"Get parser object.\"\"\" from argparse import ArgumentParser , ArgumentDefaultsHelpFormatter parser = ArgumentParser ( description = __doc__ , formatter_class = ArgumentDefaultsHelpFormatter ) parser . add_argument ( \"-f\" , \"--file\" , dest = \"filename\" , type = lambda x : is_valid_file ( parser , x ), help = \"Classify image\" , metavar = \"IMAGE\" , required = True ) return parser if __name__ == \"__main__\" : args = get_parser () . parse_args () # Load model model = ResNet50 ( include_top = True , weights = 'imagenet' ) img_path = args . filename img = image . load_img ( img_path , target_size = ( 224 , 224 )) x = image . img_to_array ( img ) x = np . expand_dims ( x , axis = 0 ) x = preprocess_input ( x ) print ( 'Input image shape:' , x . shape ) t0 = time . time () preds = model . predict ( x ) t1 = time . time () print ( \"Prediction time: {:0.3f}s\" . format ( t1 - t0 )) for wordnet_id , class_name , prob in decode_predictions ( preds )[ 0 ]: print ( \"{wid} \\t {prob:>6}% \\t {name}\" . format ( wid = wordnet_id , name = class_name , prob = \" %0.2f \" % ( prob * 100 ))) Store it as resnet50.py and make it executable. (In case the JSON becomes unavailable: Here you are ) How to use $ ./resnet50.py -f honey-bee.jpg alternatively, if you have a GPU but not that much memory: $ CUDA_VISIBLE_DEVICES = \"\" ./resnet50.py -f honey-bee.jpg If you apply this to the jellyfish image from above, you get: Input image shape: (1, 224, 224, 3) n01910747 100.00% jellyfish n01496331 0.00% electric_ray n10565667 0.00% scuba_diver n01914609 0.00% sea_anemone n02607072 0.00% anemone_fish This takes about 6 seconds on CPU on my laptop. Alternative Models If you are building an application, you might want to look into alternatives: Modelname Model size Input Size Top1-Accuracy Top5-Accuracy Time ResNet50 102.9 MB 224 Ã— 224 77.15% 93.29% 0.495s VGG16 553.5 MB 224 Ã— 224 73.0% 91.2% 0.488s InceptionV3 95.1 MB 299 Ã— 299 78.8% 94.4% 0.681s Xception 91.9 MB 299 Ã— 299 79.0% 94.5% 0.761s The speed only for the prediction. The model size is several 100 MB, so this takes a while. In a real application you can (1) load the model only once and (2) run the evaluation on a batch of many images to speed things up. More models: titu1994/Inception-v4 See also Building powerful image classification models using very little data","tags":"Machine Learning","title":"Image Classification"},{"url":"https://martin-thoma.com/curl-vs-wget/","text":"I recently had to download large files (see post ). Before I used a download helper, I used curl . It is a standard tool for downloading files. But there is another standard tool: wget . Let's see what I find in the first 10 Google hits about their differences. curl wget Initial Release 1997 1996 License MIT/X derivate GNUv3 Written in C C OS cross-platform cross-platform Protocols FTP, FTPS, Gopher, HTTP, HTTPS, SCP, SFTP, TFTP, TELNET, DICT, LDAP, LDAPS, FILE, POP3, IMAP, SMB/CIFS, SMTP, RTMP, RTSP HTTP, HTTPS, FTP Usage curl -O [URL] wget [url] curl strengths curl supports much more protocols and platforms (OS/400, TPF - never heard of them before) curl supports more authentication methods curl supports gzip and deflate Content-Encoding and does automatic decompression wget strengths Recursive! Wget's major strong side compared to curl is its ability to download recursively, or even just download everything that is referred to from a remote resource, be it a HTML page or a FTP directory listing. wget can recover from a prematurely broken transfer and continue downloading. Wget enables more features by default: cookies, redirect-following, time stamping from the remote resource etc. With curl most of those features need to be explicitly enabled. Interesting wget options -b : Put the download in background. Interersting for large downloads. --user-agent=\"Mozilla/5.0\" -i [filename] : Specify a filename with newline separated URLs to download --mirror -p : Download a webpage --convert-links : Convert links for offline viewing -P ./LOCAL-DIR : where to store the webpage --reject=gif : Don't download gif files -Q5m : Stop downloading when the file size exceeds 5 MB Conclusiong Use wget when you want to download a single file or a website. Use curl for more fancy stuff. See also Daniel Stenberg: curl vs Wget Unix.SE: What is the difference between curl and wget?","tags":"Cyberculture","title":"curl vs wget"},{"url":"https://martin-thoma.com/ensembles/","text":"Models which are combinations of other models are called an ensemble . The simplest way to combine several classifiers is by averaging their predictions. For example, if you have three models and four classes, you might get predictions like this: model 1(x1) = [0.1, 0.5, 0.3, 0.1], model 2(x1) = [0.5, 0.3, 0.1, 0.1], model 3(x1) = [0.4, 0.4, 0.1, 0.1] the ensemble predicts $$\\left [\\frac{0.1+0.5+0.4}{3}, \\frac{0.5+0.3+0.4}{3}, \\frac{0.4+0.2+0.2}{3}, \\frac{0.1+0.1+0.1}{3} \\right] \\approx \\left [0.3, 0.4, 0.2, 0.1 \\right ]$$ for \\(x_1\\) . Note that this is different from pluarlity voting (PV) where every model gives only one vote for the most likely class. In the case from above, it would be model 1(x1) = [0, 1, 0, 0], model 2(x1) = [1, 0, 0, 0], model 3(x1) = [1, 0, 0, 0] # tie - lets just take the first So the plurality voting ensemble would predict class 1, whereas the average probability ensemble predicts class 2. This comes from the fact that everybody might have different first choices, but they might agree on the second choice. Please note that a tie in the predictions of a classifier with less than 100 classes is unlikely due to the higher precision of floating point numbers. However, a tie in votes can happen. According to Andrej Karpathy, this gives you about +2 percentage points in accuracy. Tiny Experiment on CIFAR 100 I've just tried this with three (almost identical) models for CIFAR 100 . All of them were trained with Adam with the same training data (the same batches). Model 1 and model 3 only differed in the second-last layer (one uses ReLU, the other tanh), model 1 and model 2 only differed in the border mode for one convolutional layer (valid vs same). The accuracies of the single models were: model 1: 57.02 model 2: 61.85 model 3: 48.59 The ensemble accuracy is 62.98%. Hence the ensemble is 1.13 percentage points better than the best single model! Although I have read things like this before, it is the first time I actually tried it myself. Ensemble Techniques There are much more sophisticated ensemble techniques than simple averaging of the output: Bagging How does it work? Train models on different data (Learnier is fit, results are mean/median aggregated) Why is it used? Reduction of variance Common techniques: Random subspaces: Take a part of the features (e.g. Random Forests) Pasting: Take a part of the training data without replacement Boosting How does it work? Train one classifier. Obtain the results. Weight the training data higher if the classifier got it wrong. Train a new classifier on the weighted training data. Iterate. Why is it used? Reduction of bias Examples: AdaBoost , Gradient boosting Stacking How does it work? Train $n$ classifiers on the data. Train a classifier on the predictions of the $n$ classifiers. Why is it used? Reduction of bias and reduction of variance I made some images to make this more clear: Bagging trains the classifiers on different data. Boosting reweights the training data. Stacking trains the combiner. Combiners Some choices for combiners are: Average of predictions of base classifiers Plurality vote (sometimes also called majority vote) Learning Naive Bayes Neural Network See also sklearn ensemble user guide Scholarpedia MIT 6.034 Artificial Intelligence: 17. Learning: Boosting","tags":"Machine Learning","title":"Ensembles"},{"url":"https://martin-thoma.com/download-data/","text":"Machine Learning algorithms for computer vision need huge amounts of data. Here are a few remarks on how to download them. Make sure you have enough space ( df -h ) Get a download manager. I use aria2c ( sudo apt-get install aria2 ) For ImageNet, you have to register at image-net.org . Download the files like this: $ aria2c -s 16 [ URL ] After downloading the file, use $ md5sum [ Filename ] and compare the hash with the provided hash. If it differs, download the file again. The ImageNet training data tar file contains 1000 files of the form n01440764.tar , n01443537.tar , ... Each of those files contains JPEGs of one class. You can look the class label up with from nltk.corpus import wordnet as wn print ( wn . _synset_from_pos_and_offset ( 'n' , 1440764 )) print ( wn . _synset_from_pos_and_offset ( 'n' , 1443537 )) which reveals Synset('tench.n.01') Synset('goldfish.n.01') If you extract all 1000 of those tar files into one directory, this takes about 6 hours with a script like this: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #!/usr/bin/env python import glob import tarfile def untar ( fname , targetd_dir ): with tarfile . open ( fname ) as tar : tar . extractall ( path = targetd_dir ) files = glob . glob ( \"ILSVRC2012_img_train/*.tar\" ) for f in files : untar ( f , \"extracted\" ) This gives 1281170 files in total. Datasets Download ImageNet Download Places365","tags":"Machine Learning","title":"How to download ImageNet"},{"url":"https://martin-thoma.com/umzug/","text":"The following article is in German. Use Google Translator if you don't speak German. Das ist meien TODO-Liste, wenn ich umziehe: Wohnung finden wg-gesucht.de : Super fÃ¼r WGs! 1a-immobilienmarkt.de immobilienmarkt.sueddeutsche.de Facebook-Gruppen Funktionen immobilienscout24.de immonet.de immowelt.de wg-gesucht Suche-Merken âœ” Stadtteil-Auswahl âœ” âœ” âœ” âœ” Min-Max Miete âœ” âœ” âœ˜ âœ” Min-Max WohnflÃ¤che âœ” âœ”/âœ˜ âœ” âœ”/âœ˜ EBK -Filter âœ” âœ” âœ” Max Preis incl. Nebenkosten âœ˜ âœ˜ âœ˜ âœ˜ Wohnungstausch-Filter - - âœ˜ Untermiete-Filter âœ˜ âœ˜ âœ˜ âœ˜ Betrugsversuche 1 3 3 0 Was ich will: Ort : MÃ¼nchen (Am Hart, Au, Bogenhausen, Freimann, Haidhausen, Harlaching, Laim, Lehel, Ludwigsvorstadt, Isarvorstadt, Maxvorstadt, Schwabing, Schwabing-West, SchwantalerhÃ¶he, Sendling, Sendling-Westpark, Untergiesing) WohnflÃ¤che : min \\(19m&#94;2\\) Zimmer : 2 wÃ¤ren cool (ein kleines Schlafzimmer wo eigentlich nur das Bett rein muss und ein Wohnzimmer / Esszimmer / KÃ¼che). Aber 1 ist auch ok Miete : Max 1000 Euro kalt, warm nicht mehr als 1100 Euro. Sonstiges : EBK: Herd-Kochfeld-Kombi sollte schon vorhanden sein. Zumindest jedoch die KÃ¼chenzeile. Waschmaschinen-Anschluss in der Wohnung Glossar EBK: EinbaukÃ¼che ELW: Einliegerwohnung FbH: FuÃŸbodenheizung Gge: Garage HMS: Hausmeisterservice HWR: Hauswirtschaftsraum MKM: Monatskaltmiete NK: Nebenkosten RGB: RÃ¼ckgebÃ¤ude Whg: Wohnung WM: Waschmaschine 1 ZKBB: Zimmer KÃ¼che Bad Balkon Lessons learned Mit ca. 1100 Euro muss man rechnen. Nebenkosten sind teilweise abartig hoch. Ich habe Wohnungen mit deutlich Ã¼ber 300 Euro Nebenkosten (bei ca. 750 Euro Miete) gesehen. Aufpassen mit Betrug : Wenn etwas zu gut aussieht um wahr zu sein, ist es das eventuell auch. numbeo.com gibt Lebenshaltungskosten ganz gut an. Unterlagen Schufa-Auskunft (kostenlos nach Â§ 34 Bundesdatenschutzgesetz, vgl. Vorsicht Abzocke: So erhalten Sie die Schufa-Auskunft kostenlos ) Umzugsunternehmen Habe keine Erfahrung damit. umzug-easy.de my-hammer.de Bei den grÃ¶ÃŸten Sachen lohnt es sich eventuell diese in Karlsruhe zu verkaufen und in MÃ¼nchen neu zu kaufen: Fahrrad: 250 Euro Billy-Regal : 39 Euro Tisch Stuhl : 60 Euro Bett Einzelbett : 129 Euro 7 Zonen Latterost : 129 Euro Matratze : 75 Euro Neue Wohnung Namen an Briefkasten und Klingelschild anbringen Bett Regale Tisch und StÃ¼hle KÃ¼che: KÃ¼hlschrank / Gefrierschrank Ofen / Herd Mikrowelle Waschmaschine Neue Adresse melden Rathaus (Einwohnermeldeamt / BÃ¼rgerbÃ¼ro) UniversitÃ¤t âœ” Bank âœ” Krankenkasse GEZ Mobilfunk-Anbieter Online Amazon: Achtung bei Vorbestellungen! ebay Freunde Vor Ort Zeug finden: Ã„rzte (Zahnarzt, Allgemeinarzt) Lebensmittel (z.B. Aldi, Lidl, Rewe) Haushalt (z.B. dm, MÃ¼ller) Handwerksbedarf (Baumarkt) BÃ¤ckerei Bar Erledigen Monatsfahrkarte Wohnung einrichten Fotos aufhÃ¤ngen (z.B. Wikipedia Commons oder amazing places ) Pflanze besorgen (z.B. Ficus Benjamini )","tags":"My bits and bytes","title":"Umzug"},{"url":"https://martin-thoma.com/ml-review-3/","text":"This Review gives an overview of intersting stuff I stumbled over which are related to machine learning. New Developments Tensorflow 1.0 is released Human-strenght and Super-human strength programs Super-human strength programs are programs, which surpass even the best human (on the long run) in a specified task. Human-strength programs behave similar to an (untrained) human. Although those are not new, seeing them as a list ( source ) was new to me. However, except for the games and lip reading, I doubt that we are there yet. Interesting, non the less: Games 1995, Checkers: Chinook 1996, Chess: DeepBlue 2016, Go: AlphaGo Lip reading: 2016, Lip Reading Sentences in the Wild ( YouTube ) Geolocation by photos, PlaNet - Photo Geolocation with Convolutional Neural Networks Speech transcription: 2016, Achieving Human Parity in Conversational Speech Recognition Translation: 2016, Zero-Shot Translation with Google's Multilingual Neural Machine Translation System Driving: 2016, Waymo Live Demos and Websites universe.openai.com : Related to the OpenAI gym. Project Malmo : Train RL agents in Minecraft VISIIR : VIsual Seek for Interactive Image Retrieval - classifying food Image-to-Image Publications High-Resolution Image Inpainting using Multi-Scale Neural Patch Synthesis and Code The Game Imitation: Deep Supervised Convolutional Networks for Quick Video and YouTube playlist Deep Nets Don't Learn Via Memorization Software Interesting Questions Why is the accuracy of my CNN not reproducible? How much does a GPU instance cost? Miscallenious Trump QA idea I was just watching this clip and wodered how well a question answering system would work which is trained on Trump speaches. Very often, when reporters / journalists / moderators ask Trump a question, he answers with \"I am the [most / best / least] [positive / negative statement]. [Inconsistent answer follows]\". The answers themself would almost certainly be hilarous. Second, one could make an experiment and ask people if Trump actually answered a question like this. Meetings London, 4. December 2016: Data Visualization Challenge Barcelona, 5. December 2016 - 10. December 2016: Neural Information Processing Systems (NIPS) ( Link ) Mannheim, 7. April 2017: DataFest Germany Â« Previous Review Next Review Â»","tags":"Machine Learning","title":"ML Review 3"},{"url":"https://martin-thoma.com/how-to-use-glpk/","text":"GLPK, the GNU Linear Programming Kit, is a piece of software which solves linear optimization problems. You only have to modell the problem. Installation $ sudo apt-get install glpk-utils libglpk-dev glpk-doc python-glpk Assignment problem The assignment problem The following file is in the examples of GLPK. Save it as problem.mod : param m , integer , > 0 ; /* number of agents */ param n , integer , > 0 ; /* number of tasks */ set I : = 1. . m ; /* set of agents */ set J : = 1. . n ; /* set of tasks */ param c { i in I , j in J }, >= 0 ; /* cost of allocating task j to agent i */ var x { i in I , j in J }, >= 0 ; /* x[i,j] = 1 means task j is assigned to agent i note that variables x[i,j] are binary, however, there is no need to declare them so due to the totally unimodular constraint matrix */ s . t . phi { i in I } : sum { j in J } x [ i , j ] <= 1 ; /* each agent can perform at most one task */ s . t . psi { j in J } : sum { i in I } x [ i , j ] = 1 ; /* each task must be assigned exactly to one agent */ minimize obj : sum { i in I , j in J } c [ i , j ] * x [ i , j ]; /* the objective is to find a cheapest assignment */ solve ; printf \" \\n \" ; printf \"Agent Task Cost \\n \" ; printf { i in I } \"%5d %5d %10g \\n \" , i , sum { j in J } j * x [ i , j ], sum { j in J } c [ i , j ] * x [ i , j ]; printf \"---------------------- \\n \" ; printf \" Total: %10g \\n \" , sum { i in I , j in J } c [ i , j ] * x [ i , j ]; printf \" \\n \" ; data ; /* These data correspond to an example from [Christofides]. */ /* Optimal solution is 76 */ param m : = 8 ; param n : = 8 ; param c : 1 2 3 4 5 6 7 8 := 1 13 21 20 12 8 26 22 11 2 12 36 25 41 40 11 4 8 3 35 32 13 36 26 21 13 37 4 34 54 7 8 12 22 11 40 5 21 6 45 18 24 34 12 48 6 42 19 39 15 14 16 28 46 7 16 34 38 3 34 40 22 24 8 26 20 5 17 45 31 37 43 ; end ; Now run it with glpsol --model assignment.mod You will see GLPSOL : GLPK LP / MIP Solver , v4 . 57 Parameter ( s ) specified in the command line : -- model assignment . mod Reading model section from assignment . mod ... Reading data section from assignment . mod ... assignment . mod : 60 : warning : final NL missing before end of file 60 lines were read Generating phi ... Generating psi ... Generating obj ... Model has been successfully generated GLPK Simplex Optimizer , v4 . 57 17 rows , 64 columns , 192 non - zeros Preprocessing ... 16 rows , 64 columns , 128 non - zeros Scaling ... A : min | aij | = 1.000 e + 00 max | aij | = 1.000 e + 00 ratio = 1.000 e + 00 Problem data seem to be well scaled Constructing initial basis ... Size of triangular part is 16 0 : obj = 2.240000000 e + 02 inf = 7.000 e + 00 ( 1 ) 13 : obj = 1.750000000 e + 02 inf = 0.000 e + 00 ( 0 ) * 28 : obj = 7.600000000 e + 01 inf = 0.000 e + 00 ( 0 ) OPTIMAL LP SOLUTION FOUND Time used : 0.0 secs Memory used : 0.2 Mb ( 192291 bytes ) Agent Task Cost 1 1 13 2 8 8 3 7 13 4 5 12 5 2 6 6 6 16 7 4 3 8 3 5 ---------------------- Total : 76 Model has been successfully processed See also GLPK Documentation BwInf 31.1, A2 IBM: Introduction to linear optimization , Intermediate problems in linear programming , Advanced problems and elegant solutions WikiBook","tags":"Code","title":"How to use GLPK"},{"url":"https://martin-thoma.com/p-value/","text":"The \\(p\\) value is often used in applications to determine if some improvement is significant or if it was just random chance. Loosely speaking, it defines how likely it is (under the assumption of an hypothesis \\(H_0\\) ) to get more extreme results. This is interesting for studies in medicine and similar scenarios. You have a drug and a placebo. You want to figure out if the drug is better than the placebo. Hypothesis testing In statistics, hypothesis testing works as follows: Define a statistical model : This means you have a sample \\(\\mathfrak{X}\\) and an assumption about the distribution of the data. For example, \\(\\mathfrak{X} = \\mathbb{R}&#94;n\\) where \\(n \\in \\mathbb{N}\\) is your sample size and \\(X_1, \\dots, X_n \\stackrel{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma&#94;2)\\) Define a hypothesis and an alternative : For example \\(H_0: \\mu = 100\\) and \\(H_1: \\mu > 100\\) might be hypotheses if you want to check if a drug increases the IQ. Controll errors : You can make two errors. Either \\(H_0\\) is true and you reject it or \\(H_1\\) is true, but you don't reject \\(H_0\\) . In statistics, the first error is usually controlled. So the test is made in such a way that the first error is less than some \\(\\alpha \\in (0, 1)\\) . Usually, \\(\\alpha = 0.05\\) or \\(\\alpha = 0.01\\) or even lower. Test statistic : You have a value which indicates something about the parameters in the hypotheses. For example \\(T(X_1, \\dots, X_n) = \\frac{1}{n}\\sum_{i=1} X_i\\) . Test statistic distribution : \\(T\\) itself is a random variable and you can calculate its distribution (e.g. \\(T \\stackrel{H_0}{\\sim} \\mathcal{N}(\\mu, \\frac{\\sigma&#94;2}{n})\\) ). Calculate test decision : Hence you can calculate a \\(c \\in \\mathbb{R}\\) such that \\(P_{H_0}(H_0 \\text{ is rejected}) = P_{H_0}(T \\leq c) \\leq \\alpha\\) . It does not have to be \\(T < c\\) , but often it is. The p value Now note that you could also make it the other way round. You could calculate $$p&#94;* = P_{H_0} (T(X) \\geq T(x))$$ If \\(p&#94;* \\leq \\alpha\\) , then \\(H_0\\) can be rejected on Niveau \\(\\alpha\\) . Interesting statements I just came across the following statments which I think are interesting enough to share them. All of them are wrong. The follwing was takine from a German statistics exam by Dr. Klar (KIT, WS 2013/2014). Assume for the following, that an experiment resulted in a \\(p\\) value of \\(0.01\\) . \\(H_0\\) is certainly false. \\(H_0\\) is with probability \\(0.01\\) false. \\(H_1\\) is certainly correct. You can calculate the probability that \\(H_1\\) is correct with the \\(p\\) value. If one decides to reject \\(H_0\\) , then the \\(p\\) value is the probability of making the wrong decision. The experimental result is reliable, meaning that if the experiment is repeated often one would get a significant result in 99% of the cases. I'm not too sure if (5) is really wrong. p hacking See also The p-Value You Can't Buy","tags":"Mathematics","title":"The p value"},{"url":"https://martin-thoma.com/abs-function/","text":"I was never really taught how to deal with the absolute value function, but I need it from time to time. So here are a few hints. Solving Equations Lets say you want to solve the equation $$|x - a | = b$$ for \\(x\\) . Then you need to realize that this equation is equivalent to two equations: $$x - a = b \\qquad \\text{ and } \\qquad -(x-a) = b$$ you can solve both of them independantly. You can get 0, 1 or 2 solutions when the absolute function is involved: $$x = a + b \\qquad \\text{ and } \\qquad x = a - b$$ or shorter $$x = a \\pm b$$ Solving Inequalities Lets say you want to solve the inequality $$|a - x| \\leq b$$ for \\(x\\) . Again, this inequality is equivalent to the two inequalities $$a - x \\leq b \\qquad \\text{ and } \\qquad -(a-x) \\leq b$$ You can solve both of them independantly for \\(x\\) : $$a - b \\leq x \\qquad \\text{ and } \\qquad -x \\leq a + b$$ leading to $$a - b \\leq x \\leq a + b$$ Note that both inequalities have to be fulfilled at the same time! Just try it for \\(a = 0\\) and \\(b = -5\\) ! Derivatives The function \\(f(x) = |x|\\) is equivalent to \\(f(x) = \\sqrt{x&#94;2}\\) . Hence you can derive the absolute value by deriving the root of the square function of its argument. And the chain rule, of course: \\begin{align} f'(x) &= (\\sqrt{x&#94;2})'\\\\ &= \\frac{1}{2 \\sqrt{x&#94;2}} \\cdot (2 x)\\\\ &= \\frac{x}{\\sqrt{x&#94;2}}\\\\ &= \\frac{x}{|x|}\\\\ &= \\text{sign}(x) \\end{align} Note that the derivative is not devined at 0. See also Wikipedia","tags":"Mathematics","title":"The Absolute Value Function"},{"url":"https://martin-thoma.com/best-of-ml/","text":"This post is a summary of articles, websites and material in general about machine learning. Articles RNNs Get an overview: The Unreasonable Effectiveness of Recurrent Neural Networks Understand them: Understanding LSTM Networks Using convolutional neural nets to detect facial keypoints tutorial Clever Methods of Overfitting Understanding the Bias-Variance Tradeoff An overview of gradient descent optimization algorithms cs231n: Convolutional Neural Networks (CNNs / ConvNets) ( YouTube playlist ) Evolution Strategies Warning Signs in Experimental Design and Interpretation : Not the typical ML literature, but interesting and relevant non the less as ML is driven by experiments. Books Neural Networks and Deep Learning Ian Goodfellow, Yoshua Bengio, and Aaron Courville: Deep Learning MOOCs Coursera: Machine Learning by Andrew Ng CS224d: Deep Learning for Natural Language Processing Machine Learning : Kurs der UniversitÃ¤t Oxford Convolutional Neural Networks for Visual Recognition : Kurs von Stanford Tools Caffe : Used often for Computer Vision, but more and more people jump to TensorFlow sklearn : Python Machine learning toolkit Theano : Used often for Speech Recognition Lasagne : Python, supports nVidia GPU training of neural networks nolearn TensorFlow : C++ and Python, supports nVidia GPU training of neural networks Keras.io : Extremely nice for beginners Data Collections OpenML : A lot of datasets (it also has a Python package) Kaggle Benchmark Datasets MNIST : 70 000 images of \\(28 \\times 28\\) px with labels (digits 0-9) HASY : 168 233 images of \\(32 \\times 32\\) px with labels (369 classes, all of them are characters) HWRT : Handwritten symbols (similar to HASY, but online data) IRIS : 3 classes, 50 items per class, 3 features per item KITTI : Road vision dataset Lists: metacademy.org : A lot of material when you know what to look for computervisiononline.com : Eine Liste sehr vieler DatensÃ¤tze YACVID : Computer Vision Index To Datasets dmoz.org Cheat Cheats Choosing the right estimator Machine learning algorithm cheat sheet Lists Machine Learning Tutorials by Ujjwal Karn (Facebook employee) Awesome Random Forest : A curated list of resources regarding tree-based methods and more, including but not limited to random forest, bagging and boosting. Miscallenious Kaggle : Machine Learning Challenges Stack Exchange datascience.stackexchange.com stats.stackexchange.com awesome-machine-learning : A list with MANY links to machine learning tools Demos: Neural Machine Translation : English â†’ German, French write-math.com : Symbol recognition Tensorflow Playground : Demo for decision boundary of neural network lecture-demo.ira.uka.de : Rosenblatt-Perceptron, GMMs, ... demos.algorithmia.com/colorize-photos : Colorize a grayscale photo","tags":"Machine Learning","title":"Best of ML"},{"url":"https://martin-thoma.com/matplotlib-markers/","text":"Matplotlib is a simple Python library to create plots like this one: Validation curve of one model with ReLU and one with PReLU As I always have to look up different styles of markers / lines, here is a little summary. Simple plots Here is some sample code: #!/usr/bin/env python # -*- coding: utf-8 -*- \"\"\"Visualize matplotlib marker styles.\"\"\" import matplotlib.pyplot as plt import numpy as np from matplotlib.lines import Line2D # Get colors / markers / functions colors = ( 'b' , 'g' , 'r' , 'c' , 'm' , 'y' , 'k' ) markers = [] for m in Line2D . markers : try : if len ( m ) == 1 and m != ' ' : markers . append ( m ) except TypeError : pass f1 = lambda xs : [ x ** 2 for x in xs ] f2 = lambda xs : [ x ** 3 for x in xs ] f3 = lambda xs : np . sin ( xs ) f4 = lambda xs : np . log ( xs ) f5 = lambda xs : [ x ** 0.5 for x in xs ] f6 = lambda xs : [ x for x in xs ] f7 = lambda xs : [ x + 1 for x in xs ] functions = [ f1 , f2 , f3 , f4 , f5 , f6 , f7 ] # Define the plot plt . ylim ( - 1.0 , 1.0 ) plt . title ( u \"Example for matplotlib markers\" , fontweight = 'bold' , fontsize = 20 ) plt . xlabel ( r \"\"\"x-axis label\"\"\" , fontsize = 20 ) plt . ylabel ( r \"\"\"y-axis label\"\"\" , fontsize = 20 ) # Define at which x positions to evaluate the functions f_i(x) xmin = - 1 xmax = 1 samples = 50 xs = np . linspace ( xmin , xmax , samples ) # Plot the functions for color , marker , f in zip ( colors , markers , functions ): format_str = \"{color}{marker}-\" . format ( color = color , marker = marker ) plt . plot ( xs , f ( xs ), format_str , label = format_str ) plt . axhline ( y = 0.20 ) plt . legend ( fontsize = 20 ) plt . savefig ( \"matplotlib-marker-styles.png\" ) # or plt.show() Markers Basically, the matplotlib tries to have identifiers for the markers which look similar to the marker: Triangle-shaped: v , < , > , &#94; Cross-like: * , + , 1 , 2 , 3 , 4 Circle-like: o , . , h , p , H , 8 Markers 1 Markers 2 Markers 3 Markers 4 Line Types Matplotlib line styles Documentation matplotlib.markers filledmarker_demo.py matplotlib.lines line_styles.py","tags":"Code","title":"Matplotlib Markers"},{"url":"https://martin-thoma.com/lidl-connect/","text":"Finding good solutions to have a phone number and decent internet when being in another country is a annoying task. For this reason, I wrote the following article: To help students who come to Germany. General overview In Germany, pre-paid sim cards are pretty good compared to contracts. Well-known providers of pre-paid cards are: Discounters Aldi Talk Lidl Connect Online blau.de (former \"simyo\") simquardat.de Why I like Lidl Connect I haven't used it for long, so take this with a grain of salt. But what I've seen so far is nice: A clean user interface Cheap \"Festznetz-Flat\" (8 Euro - much cheaper than the rest) Prepaid I pay the same in the other countries of the EU - no more \"EU packages\". Simply the same. No roaming. As far as I understand it. This is what finally got me. For my 10 day trip in Barcelona, I paied about 20 Euro to Blau. ( Lidl source , other source ) If you want to switch to Lidl Connect, let me know. I (and you) will get 5 Euro for that. How to get Lidl Connect card Go to a Lidl store. Near the check-out, there are small cardboard cards. When you paid for it, they will give you a similar small \"box\". This box contains the sim card (standard, micro and nano) as well as instructions (German only) Go to Lidl Connect and register a new account with the card you just bought. The card gets activated within 30 minutes. You can login at kundenkonto.lidl-connect.de User Interface User Interface of Lidl Connect The Lidl connect app seems to work fine. It shows the important information. Switching from Blau.de to Lidl As Simyo recently was changed into blau.de (E-Plus), I am a customer of Blau.de. However, the service is worse than the one of Lidl, so I switched. edit: I've recently heard from Marvin that the service hotline of Blau.de asks for the first four characters of your password. So they store the password as plain text. After getting your Lidl Connect card, you have to tell Blau that you want to keep the number (Rufnummernmitnahme). Fill out this form and send it to the address on the form. Your \"SIM-Kartennummer\" is printed on the sim card itself. I sent it on 23.12.2016 to them. I'm still (02.01.2016) waiting for a response. 19.01.2016: Still waiting for a response. I tried to contact them, but the chat was not working. I tried to find a phone number, but there seems not to be any on the website. Only for new contracts. But at least that automatic number said that 0177 177 11 59 is customer service. More than 2 minutes until I reached them. Blau is so shitty. At least the person helped me. 5 minutes later I've got a SMS: Lieber Blau Kunde, Ihre Freigabe der Rufnummer-Mitnahme zu einem anderen Anbieter (PortierungserklÃ¤rung) fÃ¼r 016123456789 ist eingegangen und gÃ¼ltig bis 20.03.2017. FÃ¼r die Rufnummer-Mitnahme wird eine WechselgebÃ¼hr entsprechend der aktuell gÃ¼ltigen Preisliste berechnet. It's 25 Euro. Update, 02.02.2017: The new Lidl Connect SIM card with my old number arrived. Seems not to be active at the moment. Update, 06.02.2017: Finally, I have the Lidl SIM card with my new number ðŸ™‚","tags":"Cyberculture","title":"Lidl Connect"},{"url":"https://martin-thoma.com/sota/","text":"It is difficult to keep track of the current state of the art (SotA). Also, it might not be directly clear which datasets are relevant. The following list should help. If you think some datasets / problems / SotA results are missing, let me know in the comments or via E-mail ( info@martin-thoma.de ). I will update it. Papers and blog posts which summarize a topic or give a good introduction are always welcome. In the following, a + will indicate \"higher is better\" and a - will indicate \"lower is better\". Computer Vision Image Classification Dataset Year Score Type Paper ImageNet 2012 2015 3.08 % Top-5 error - [SIVA16] MNIST 2013 0.21 % error - [WZZ+13] CIFAR-10 2017 2.72 % error - [G17] CIFAR-100 2016 15.85 % error - [G17] STL-10 2017 78.66 % accuracy + [Tho17-2] SVHN 2016 1.54 % error - [ZK16] Caltech-101 2014 91.4 % accuracy + [HZRS14] Caltech-256 2014 74.2 % accuracy + [ZF14] HASYv2 2017 85.92 % accuracy + [Tho17-2] Graz-02 2010 78.98 % accuracy + [BMDP10] YFCC100m CUB-200-2011 Birds 2015 84.1 accuracy + [LRM15] DISFA 2017 48.5 accuracy + [LAZY17] BP4D EMNIST 2017 50.93 accuracy + [CATS17] Megaface 2015 74.6% accuracy + Google - FaceNet v8 CelebA ? ? ? ? GTSRB 2017 99.51% accuracy + [Tho17-2] State of the art in this category are CNN models which use skip connections in the form of residual connections or dense connections. The evaluation metrics are straight-forward: Accuracy : Count how many elements of the test dataset you got right, divided by the total number of elements in the test dataset. The accuracy is in \\([0, 1]\\) . Higher is better. Error = 1 - accuracy. The error is in \\([0, 1]\\) . Lower is better. Top-k accuracy : Sometimes, there are either extremely similar classes or the application allows having multiple guesses. Hence not the Top-1 guess of the network has to be right, but the correct label has to be within the top \\(k\\) guesses. The top- \\(k\\) accuracy is in \\([0, 1]\\) . Higher is better. Detection (Images) Face recognition is a special case of detection. Common metrics are: mAP (Mean Average Precision): A detection is successfull, if the bounding box prediction and the true bounding box \\(\\frac{intersection}{union}\\) (IU, IoU) ratio is at least 0.5. Then the average precision = \\(\\frac{TP}{TP + FP}\\) is calculated for each class and the mean is calculated of those (see Explanation , What does the notation mAP@[.5:.95] mean? ) MR (miss rate) Dataset Year Score Type Paper PASCAL VOC 2012 2015 75.9 mAP@.5 + [RHGS15] PASCAL VOC 2011 2014 62.7 mean IU + [LSD14] PASCAL VOC 2010 2011 30.2 mean accuracy + [Kol11] PASCAL VOC 2007 2015 71.6 mAP@.5 + [LAES+15] MS COCO 2015 46.5 mAP@.5 + [LAES+15] CityPersons 2017 33.10 MR - [ZBS17] Detection (Videos) Dataset Year Score Type Paper YouTube-BoundingBoxes Person Re-Identitification Person Re-ID is the task of identifying a person again which was already seen in a video stream. Person following and MTMCT seems to be very similar if not identical. Dataset Year Score Type Paper Market-1501 2017 62.1 mAP + [SZDW17] CUHK03 2017 84.8 mAP + [SZDW17] DukeMTMC 2017 56.8 mAP + [SZDW17] Semantic Segmentation A summary of classical methods for semantic segmentation, more information to several datasets and metrics for evaluation can be found in A Survey of Semantic Segmentation . Dataset Year Score Type Paper MSRC-21 2011 84.7 mean accuracy + [Kol11] KITTI Road 96.69 Max F1 + NYUDv2 2014 34.0 mean IO + [Kol11] SIFT Flow 2014 39.5 mean IU + [LSD14] DIARETDB1 Warwick-QU Ciona17 2017 51.36 % mean IoU + [GTRM17] Instance Segmentation See [DHS15] Dataset Year Score Type Paper CityScapes Action Recognition Action recognition is a classification problem over a short video clip. Dataset Year Score Type Paper YouTube-8M Sports-1M 2015 68.7 % Clip Hit@1 accuracy + [NHV+15] UCF-101 2015 70.8 % Clip Hit@1 accuracy + [NHV+15] KTH 2015 95.6 % EER + [RMRMD15] UCF Sport 2015 97.8 % EER + [RMRMD15] UCF-11 Human Action 2015 89.5 % EER + [RMRMD15] Super Resolution See github.com/huangzehao Dataset Year Score Type Paper I'm not sure how super resolution is benchmarked. One way to do it would be to get high resolution images, scale them down, feed them to the network and measure the mean squared error for each pixel: $$\\frac{1}{|I|} \\sum_{t \\in I} {(t - \\hat{t})}&#94;2$$ However, this might be sensitive to the way the images were downsampled. Lip Reading Dataset Year Score Type Paper GRID 2016 95.2 % accuracy + [ASWF16] Other Datasets For the following datasets, I was not able to find where to download them Mapping global urban areas using MODIS 500-m data: New methods and datasets based on urban ecoregions TorontoCity: Seeing the World with a Million Eyes ASR Automatic Speech Recognition (ASR). Sentence-Level Dataset Year Score Type Paper WSJ (eval92) 2015 3.47 WER - [CL15] Switchboard Hub5'00 2016 6.3% WER - [XDSS+16] See Word Error Rate (WER) for an explanation of the metric. Relevant papers might be Deep Speech 2: End-to-End Speech Recognition in English and Mandarin Phoneme-Level Dataset Year Score Type Paper TIMIT 2013 17.7 % error rate - [GMH13] Language Natural Language Processing (NLP) deals with how to represent language. It is related and often a part of ASR. Dataset Year Score Type Paper WikiText-103 2016 48.7 Perplexity - [GJU16] Penn Treebank (PTB) 2016 62.4 Perplexity - [ZL16] ( summary ) Stanford Sentiment Treebank NLP benchmarks use perplexity to measure how good a result is. Translation Dataset Year Score Type Paper MT03 2003 35.76 BLEU [OGKS+03] The BLEU score is used to measure how good a translation system is. Another score is the Translation Edit Rate (TER) introduced by Snover et al., 2006 . Matrix completion Collaborative filtering is an application of matrix completion. More datasets are on entaroadun/gist:1653794 . Dataset Year Score Type Paper MovieLens Jester Reinforcment Learning The OpenAI Gym offers many environments for testing RL algorithms. Challenge Year Score Type Paper Chess 3395 Stockfishchess Go 2015 3,168 ELO + AlphaGo Star Craft Control Dataset Year Score Type Paper Cart Pole See also Are we there yet ? Some state-of-the-arts in natural language processing and their discussion aclweb.org: State of the art - NLP tasks wer_are_we : SotA in ASR github.com/michalwols/ml-sota More datasets List of datasets for machine learning research traffic-signs-dataset Stanford Dogs Awesome Public Datasets archive.ics.uci.edu/ml/datasets.html Tiny ImageNet Visual Recognition Challenge","tags":"Machine Learning","title":"State of the Art in ML"},{"url":"https://martin-thoma.com/skdata/","text":"I really like Machine Learning. I like reading papers, understanding and evaluating new ideas. But one part I always have to spend quite a bit of time on is loading the data. It's always a mess to find the datasets, understand where exactly I can download them and how they've packaged the information. Just a few days ago I found skdata . It is a Python package which aims at helping to load standard datasets. If I can trust the git commit message, then the development was started in August 2011 by James Bergstra! This is before AlexNet! edit: Although it seemed to be a cool project, it seems to be dead, too. The last commit is from July 2015. Usage One way to use skdata is the following: #!/usr/bin/env python \"\"\"MNIST example with skdata.\"\"\" try : from skdata.mnist.view import OfficialVectorClassification except ImportError : # Fallback, if you have an old version from skdata.mnist.views import OfficialVectorClassification from sklearn.tree import DecisionTreeClassifier # Load the data view = OfficialVectorClassification () train_idx = view . fit_idxs # indices of training data val_idx = view . val_idxs # incices of validation data test_idx = view . tst_idxs # indices of test data # Fit a simple classifier print ( \"Start fitting DecisionTreeClassifier.\" ) clf = DecisionTreeClassifier ( max_depth = 5 ) features = view . all_vectors [ train_idx ] # select features of training data targets = view . all_labels [ train_idx ] # select labels of training data clf . fit ( features , targets ) # Evaluate the classifier predict = clf . predict ( view . all_vectors [ test_idx ]) accuracy = sum ( predict == view . all_labels [ test_idx ]) / float ( len ( test_idx )) print ( \"Fitted DecisionTreeClassifier has test accuracy of %0.4f .\" % accuracy ) However, it is inteded to be used like this: from skdata.mnist.view import OfficialVectorClassification from sklearn.tree import DecisionTreeClassifier # Load the data mnist_view = OfficialVectorClassification () train_idx = mnist_view . fit_idxs val_idx = mnist_view . val_idxs test_idx = mnist_view . tst_idxs # Fit a simple classifier from skdata.base import SklearnClassifier learning_algo = SklearnClassifier ( DecisionTreeClassifier ) mnist_view . protocol ( learning_algo ) print ( learn_algo . results [ 'loss' ][ 0 ][ 'task_name' ] == 'tst' ) ... but this doesn't work (for me) Other Data-Loading Projects You can access R data with rpy2 . from rpy2.robjects import r from rpy2.robjects import pandas2ri def data ( name ): return pandas2ri . ri2py ( r [ name ]) df = data ( 'iris' ) print ( df . describe ()) quandl fuel You can also load mnist , cifar10 , cifar100 , imdb , reuters with keras: from keras.datasets import mnist ( X_train , y_train ), ( X_test , y_test ) = mnist . load_data () See also skdata documentation skdata on Github How to Create a New Dataset Module Protocol List of datasets fuel kerosene ImageNet","tags":"Machine Learning","title":"skdata"},{"url":"https://martin-thoma.com/label-correction-algorithm/","text":"The label-correction algorithm is a generalization which includes very common graph search algorithms like breadth first search (BFS), depth first search (DFS), A* , Dijkstra's algorithm and Branch and bound as special cases. Pseudocode Pseudocode for the Label correction algorithm Explanation: First if : The left hand side is a lower bound to get from start to v , to c and then to t . If this lower bound is not lower than either u or the distance to c directly, then it will not be part of the optimal solution. Special cases: Depth-first search : K is LIFO list / Stack Breadth-first search : K is FIFO list Dijkstra's algorithm : K is priority queue A* : K ist priority queue, \\(h_j\\) is non-trivial Branch and bound : K ist priority queue, \\(h_j\\) and \\(m_j\\) are non-trivial Python 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 #!/usr/bin/env python \"\"\"Label Correction algorithm.\"\"\" import logging import sys logging . basicConfig ( format = ' %(asctime)s %(levelname)s %(message)s ' , level = logging . DEBUG , stream = sys . stdout ) class LIFO ( list ): \"\"\"A LIFO storage.\"\"\" def insert ( self , el ): self . append ( el ) class Graph ( object ): \"\"\"An undirected graph.\"\"\" def __init__ ( self ): self . nodes = [] self . edges = [] self . name2index = {} self . index2name = {} self . neighbors = [] def add_node ( self , name = None ): \"\"\"Add a new node and return its index.\"\"\" node_index = len ( self . nodes ) if name . startswith ( 'index-' ): logging . warning ( 'Node names beginning with \"index-\" may cause ' 'problems.' ) if name is None : name = \"index- %i \" % node_index self . nodes . append ( node_index ) self . name2index [ name ] = node_index self . index2name [ node_index ] = name # Add weight from new node to other nodes and vice-versa self . edges . append ([]) for n1 in self . nodes : self . edges [ node_index ] . append ( float ( 'inf' )) if n1 != node_index : self . edges [ n1 ] . append ( float ( 'inf' )) # From the node to itself has distance 0 self . edges [ node_index ][ node_index ] = 0 self . neighbors . append ([]) return node_index def get_node_index ( self , name ): \"\"\"Get node index by name.\"\"\" return self . name2index [ name ] def set_edge_by_name ( self , a , b , weight ): \"\"\" Set edge weight by node names. Parameters ---------- a : str First edge name b : str Second edge name weight : number New edge weight \"\"\" i1 = self . get_node_index ( a ) i2 = self . get_node_index ( b ) self . edges [ i1 ][ i2 ] = weight self . edges [ i2 ][ i1 ] = weight self . neighbors [ i1 ] . append ( i2 ) self . neighbors [ i2 ] . append ( i1 ) def label_correction ( graph , start_node , t , h = None , m = None , K = None ): \"\"\" Label correction algorithm for graph searches. Parameters ---------- graph : Needs 'graph.childs' which returns a list of child indices for each node, 'graph.edges[node1][node2]' which always returns an edge weight, start_node : int Index of start node as given by the graph node iterator t : int Index of target node as given by the graph node iterator h : lower_heuristic, optional Takes (graph, node1, node2) and returns a number which underestimates the distance from node1 to node2. If this is not given, the trivial distance 0 is chosen. m : upper_heuristic, optional K : list-like data structure, optional Needs 'insert', 'pop' \"\"\" if h is None : h = lambda g , n1 , n2 : 0.0 if m is None : m = lambda g , n1 , n2 : float ( 'inf' ) if K is None : K = LIFO () d = [] parents = [] for node in graph . nodes : d . append ( float ( 'inf' )) parents . append ( None ) d [ start_node ] = 0 u = float ( 'inf' ) # shortest distance from start_node to t K . append ( start_node ) while len ( K ) > 0 : logging . info ( \"K= %s \" % str ( K )) v = K . pop () for c in graph . neighbors [ v ]: if d [ v ] + graph . edges [ v ][ c ] + h ( graph , c , t ) < min ( d [ c ], u ): d [ c ] = d [ v ] + graph . edges [ v ][ c ] parents [ c ] = v if c != t and c not in K : K . insert ( c ) if c == t : u = d [ v ] + graph . edges [ v ][ t ] u = min ( u , d [ c ] + m ( graph , c , t )) # Reconstruct the path path , named_path = [], [] current = t while current != start_node : path . append ( current ) named_path . append ( graph . index2name [ current ]) current = parents [ current ] path . append ( current ) named_path . append ( graph . index2name [ current ]) return { 'shortest_distance' : u , 'path' : path [:: - 1 ], 'named_path' : named_path [:: - 1 ]} def sample_1 (): \"\"\"A simple search problem.\"\"\" g = Graph () for i in range ( 13 ): g . add_node ( name = chr ( ord ( 'A' ) + i )) g . set_edge_by_name ( 'A' , 'B' , 1 ) g . set_edge_by_name ( 'A' , 'C' , 1 ) g . set_edge_by_name ( 'B' , 'D' , 1 ) g . set_edge_by_name ( 'B' , 'E' , 1 ) g . set_edge_by_name ( 'C' , 'F' , 1 ) g . set_edge_by_name ( 'C' , 'G' , 1 ) g . set_edge_by_name ( 'D' , 'H' , 1 ) g . set_edge_by_name ( 'D' , 'I' , 1 ) g . set_edge_by_name ( 'E' , 'J' , 1 ) g . set_edge_by_name ( 'G' , 'K' , 1 ) g . set_edge_by_name ( 'H' , 'L' , 1 ) g . set_edge_by_name ( 'J' , 'M' , 1 ) i1 = g . get_node_index ( 'A' ) i2 = g . get_node_index ( 'F' ) ret = label_correction ( g , i1 , i2 ) print ( ret ) if __name__ == '__main__' : sample_1 () Examples Project Euler 18 hackerrank See also My implementations on GitHub Python Lists as Fifo, Lifo Queues Using Deque Collections","tags":"Machine Learning","title":"Label Correction Algorithm"},{"url":"https://martin-thoma.com/statistik-vorlesung/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žStatistik\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr. Bernhard Klar im Wintersemester 2016 / 2017 gehÃ¶rt. Behandelter Stoff Kapitel 0: Vorwissen Empirisches $p$-Quantil Das empirische $p$-Quantil, $0 < p < 1$, ist definiert durch $$x_p := \\begin{cases}x_{(\\lceil n p\\rceil)} & n \\cdot p \\notin \\mathbb{N}\\\\ \\frac{1}{2} \\left ( x_{(np)} + x_{(np + 1)}\\right ) & n \\cdot p \\in \\mathbb{N}\\end{cases}$$ Unteres Quartil $$x_{1/4}$$ Empirischer Median $$x_{1/2}$$ Rechenregeln fÃ¼r Covarianz $$C(U_1 + U_2, V) = C(U_1, V) + C(U_2, V)$$ $$C(AU, B&#94;T V) = A C(U, V) B$$ Normalverteilung Dichte: $$f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e&#94;{- \\frac{1}{2} {\\left ( \\frac{x-\\mu}{\\sigma} \\right )}&#94;2}$$ Korrelationskoeffizient $$\\rho_{X,Y} =\\frac{\\operatorname{Cov}(X,Y)}{\\sqrt{\\operatorname{Var}(X)\\operatorname{Var}(Y)}}=\\frac{\\sigma_{X,Y}&#94;2}{\\sigma_{X}\\sigma_{Y}}$$ Kapitel 1: ParameterÂ­schÃ¤tzung Stichprobenraum Der Stichprobenraum $\\mathfrak{X}$ ist eine Menge von Daten. Statistisches Modell Ein Tupel $(\\mathfrak{X}, (P_\\theta)_{\\theta \\in \\Theta})$ heiÃŸt statistisches Modell , wenn $\\mathfrak{X}$ ein Stichprobenraum und $(P_\\theta)_{\\theta \\in \\Theta}$ eine Familie von Verteilungen $P_\\theta$ ist, welche durch $\\theta \\in \\Theta$ parametrisiert ist. SchÃ¤tzer Sei $(\\mathfrak{X}, (P_\\theta)_{\\theta \\in \\Theta})$ ein statistisches Modell und $T: \\mathfrak{X} \\rightarrow \\tilde{\\Theta}$ eine Abbildung. Dann heiÃŸt $T$ ein SchÃ¤tzer fÃ¼r $\\theta$. Maximum-Likelihood-SchÃ¤tzer Likelihood-Funktion : Multipliziere die Wahrscheinlichkeit der Werte um $L_x(\\vartheta)$ zu bestimmen Log-Likelihood : Logarithmiere die Likelihood-Funktion $l_x(\\vartheta) = \\log L_x(\\vartheta)$, falls dadurch die Funktion vereinfacht wird Maximieren : Leite die (Log)likelihood-Funktion ab und setze sie gleich 0 um den Maximum-Likelihood-SchÃ¤tzer $\\hat{\\vartheta}$ zu bestimmen. Maximalstelle : PrÃ¼fe ob zweite Ableitung negativ ist MomentenschÃ¤tzer Es sollen z.B. $\\mu$ und $\\sigma&#94;2$ geschÃ¤tzt werden. DrÃ¼cke $\\mu$ und $\\sigma&#94;2$ als Funktion der Momente $E X$, $E X&#94;2$, ... aus. NÃ¼tzlich: $V(X) = E X&#94;2 - (E X)&#94;2$ Starkes Gesetz groÃŸer Zahlen Es seien $Y_1, Y_2, Y_3, \\dots$ eine Folge u.i.v. ZV mit existierendem Erwartungswert. Dann gilt: $$P(\\left \\{ \\omega \\in \\Omega : \\lim_{n \\rightarrow \\infty} \\frac{1}{n} \\sum_{i=1}&#94;n Y_i(\\omega) = E Y_i \\right \\}) = 1$$ Schreibweise: $$\\frac{1}{n} \\sum_{i=1}&#94;n Y_i \\stackrel{P-f.s.}{\\longrightarrow} E(Y_1)$$ Score-Funktion $$U_\\vartheta(X_1) := \\frac{\\partial \\log f(X_1, \\vartheta)}{\\partial \\vartheta}$$ Fisher-Information $$I(\\vartheta) := \\mathbb{E}_\\vartheta(U_\\vartheta&#94;2) = - \\mathbb{E}_\\vartheta \\left [ \\frac{\\partial U_\\vartheta (X_1)}{\\partial \\vartheta} \\right ] \\in [0, \\infty]$$ CramÃ©r-Rao Ungleichung $$V_\\vartheta(T) \\geq \\frac{[E_\\vartheta' (T) (\\vartheta)]&#94;2}{n I (\\vartheta)}$$ FÃ¼r erwartungstreue SchÃ¤tzer $T$ gilt: $$V_\\vartheta(T) \\geq \\frac{1}{n I (\\vartheta)}$$ Cauchy-Schwarz Ungleichung $$|\\langle x, y \\rangle | \\leq \\| x \\| \\cdot \\| y \\|$$ Zentraler Grenzwertsatz ( ZGWS ) Sei $(X_n)_{n \\geq 1}$ eine Folge von u.i.v. Zufallsvariablen mit $0 < \\sigma&#94;2 = V(X_1) < \\infty $. Mit $\\mu = \\mathbb{E}(X_1)$ gilt dann: $$P(\\frac{\\sqrt{n}(\\bar{X}_n - \\mu)}{\\sigma} < c) \\stackrel{n \\rightarrow \\infty}{\\longrightarrow} \\Phi(c)$$ Score-Gleichung Score-Funktion gleich 0 setzen: $$\\sum_{i=1}&#94;n \\frac{\\partial f(x_i, \\vartheta)}{\\partial \\vartheta} = 0$$ Bias ( Verzerrung ) $$b_T(\\vartheta) := E_\\vartheta(T) - \\gamma(\\vartheta)$$ Mittlere Quadratische Abweichung ( MQA ) $$MQA_T(\\vartheta) = E_\\vartheta(T - \\gamma(\\vartheta))&#94;2$$ Es gilt: $$MQA_T(\\vartheta) = V_\\vartheta(T) + b_T&#94;2 (\\vartheta)$$ Satz 1.7.5 ( Asymptotische Verteilung konsistenter SchÃ¤tzer ) $$\\sqrt{n} (\\hat{\\vartheta}_n - \\vartheta) \\stackrel{D_\\vartheta}{\\rightarrow} \\mathcal{N}(0, \\frac{1}{I_1 (\\vartheta)})$$ Kapitel 2: KonfidenzÂ­bereiche Konfidenzintervall ( Vertrauensintervall ) Ein Konfidenzintervall ist ein Intervall $[U, O]$ fÃ¼r einen Parameter $\\vartheta$, sodass gilt: $$P([U, O] \\ni \\vartheta) = 1 - \\alpha$$ 1-Stichproben-t-Test: $I(X) = \\left [\\bar{X} - \\frac{S}{\\sqrt{n}} \\cdot t_{n-1;1-\\frac{\\alpha}{2}}, \\bar{X} + \\frac{S}{\\sqrt{n}} \\cdot t_{n-1;1-\\frac{\\alpha}{2}} \\right]$ Approximativer Binomialtest: $I(X) = \\left [ \\hat{p}_n - z_{1-\\frac{\\alpha}{2}} \\sqrt{\\hat{p}_n (1- \\hat{p}_n)/n}, \\hat{p}_n + z_{1-\\frac{\\alpha}{2}} \\sqrt{\\hat{p}_n (1- \\hat{p}_n) / n} \\right ]$ Konfidenzintervalle zur Konfidenzwahrschwahrscheinlichkeit $1-\\alpha$ haben immer die Form: $$[T - \\hat{\\sigma} \\cdot z_{1-\\frac{\\alpha}{2}; T + \\hat{sigma} \\cdot z_{1-\\frac{\\alpha}{2}}]$$ wobei $T$ der SchÃ¤tzer ist, $\\hat{\\sigma}$ die geschÃ¤tze Varianz des SchÃ¤tzers und $z_{1-\\frac{\\alpha}{2}$ die Quantilfunktion zur Verteilung des SchÃ¤tzers. Satz von Student Es seien $X_1, X_2, \\dots, X_n \\stackrel{uiv}{\\sim} \\mathcal{N}(\\mu, \\sigma&#94;2),\\quad n\\geq 2$ sowie $\\bar{X} = \\frac{1}{n} \\sum_{i=1}&#94;n X_i$, $S&#94;2 = \\frac{1}{n-1} \\sum_{i=1}&#94;n {(X_i - \\bar{X})}&#94;2$ sowie $S = \\sqrt{S&#94;2}$. Dann gilt: $\\bar{X} \\sim \\mathcal{N}(\\mu, \\frac{\\sigma}{n})$ $\\bar{X}$ und $S&#94;2$ sind unabhÃ¤ngig $\\frac{1}{\\sigma&#94;2} \\sum_{i=1}&#94;n {(X_i - \\bar{X})}&#94;2 \\sim \\chi_{n-1}&#94;2$ $T = \\frac{\\sqrt{n} (\\bar{X} - \\mu)}{S} \\sim t_{n-1}$ Kapitel 3: Statistische Tests Tests Allgemein Bei statistischen Tests hat man immer eine TestgrÃ¶ÃŸe $T(x_1, \\dots, x_n)$, die auf der Stichprobe $x_1, \\dots, x_n$ basiert. Um Aussagen machen zu kÃ¶nnen, muss man die Verteilung von $T$ unter der Nullhypothese $H_0$ kennen. Wenn die Verteilung von $T$ der Studentischen-$t$-Verteilung entspricht ($T \\sim t_n$), dann hat man einen $t$-Test. Wenn der Testentscheid, ob $H_0$ verworfen wird so aussieht: $$H_0 \\text{ wird verworfen, falls } T < 123$$ dann liegt ein einseitiger Test vor. Falls der Testentscheid, ob $H_0$ verworfen wird so aussieht: $$H_0 \\text{ wird verworfen, falls } T < -123 \\text{ oder } T > +123$$ dann liegt ein zweiseitiger Test vor. Kurz schreibt man dann auch meistens $$H_0 \\text{ wird verworfen, falls } |T| > 123$$ In dem beschriebenen Fall liegt eine Stichprobe $X_1, \\dots, X_n$ vor, welche aus einer Verteilung gezogen wurde. Es ist aber auch mÃ¶glich, dass man zwei Stichproben $X_1, \\dots, X_n$ und $Y_1, \\dots, Y_m$ hat. Das ist z.B. bei Medikamententests hÃ¤ufig der Fall. Da will man wissen ob beide Stichproben aus der gleichen Verteilung stammen (also das Medikament nichts macht) oder eben nicht. $z$-Test Hypothesen: $H_0$: $\\mu = \\mu_0$ vs $H_1: \\mu < \\mu_0$ TestgrÃ¶ÃŸe: $T(x_1, \\dots, x_n) = \\frac{\\sqrt{n} (\\bar{x} - \\mu_0)}{\\sigma}$ Verteilung: $T \\stackrel{H_0}{\\sim} \\mathcal{N}(0, 1)$ Testentscheid: $H_0$ verwerfen, falls $T \\leq \\Phi&#94;{-1}(\\alpha) = z_\\alpha$ Zweiseitiger Ein-Stichproben-$t$-Test TestgrÃ¶ÃŸe: $T(x_1, \\dots, x_n) = \\frac{\\sqrt{n} (\\bar{x} - \\mu_0)}{s}$ Verteilung: $T \\stackrel{H_0}{\\sim} t_{n-1}$ Testentscheid: $H_0$ verwerfen, falls $|T| \\geq t_{n-1; 1-\\frac{\\alpha}{2}}$ Einseitiger Ein-Stichproben-$t$-Test TestgrÃ¶ÃŸe: $T(x_1, \\dots, x_n) = \\frac{\\sqrt{n} (\\bar{x} - \\mu_0)}{s}$ Verteilung: $T \\stackrel{H_0}{\\sim} t_{n-1}$ Testentscheid: $H_0$ verwerfen, falls $T \\geq t_{n-1; 1-\\alpha}$ Ein-Stichproben-Varianz-Test Hypothesen: $H_0: \\sigma&#94;2 = \\sigma_0&#94;2$ gegen $H_1: \\sigma&#94;2 > \\sigma_0&#94;2$ TestgrÃ¶ÃŸe: $\\chi&#94;2 := \\frac{(n-1)S&#94;2}{\\sigma_0&#94;2}$ Verteilung: $\\chi&#94;2 \\stackrel{H_0}{\\sim} \\chi_{n-1}&#94;2$ Testentscheid: $H_0$ verwerfen, falls $\\chi&#94;2 \\geq \\chi&#94;2_{n-1;1-\\alpha}$ GÃ¼tefunktion Die GÃ¼tefunktion ist $g(\\vartheta) = P_\\vartheta(\\text{Test verwirft } H_0), \\quad \\vartheta \\in \\Theta$. Ist die Nullhypothese einelementig (also $H_0: \\vartheta = \\vartheta_0$), so gilt $g(\\vartheta_0) = \\alpha$. Ist die Alternative einelementig (also: $H_1: \\vartheta = \\vartheta_1$), so gilt $g(\\vartheta_1) = 1- \\text{Fehler 2. Art}$. Neyman-Pearson-Test ( NP-Test ) Sei $h_0(x) = \\prod_{i=1}&#94;n f(x, \\vartheta_0)$ und $h_1(x) = \\prod_{i=1}&#94;n f(x, \\vartheta_1)$. Testentscheid: Verwerfe $H_0$, falls $h_0(x) \\leq c h_1(x)$, wobei $c$ so gewÃ¤hlt wird, dass das Niveau $\\alpha$ eingehalten wird. Likelihood-Quotienten-Test TestgrÃ¶ÃŸe: $$\\Lambda = \\frac{\\sup_{\\vartheta \\in \\Theta} L_x (\\vartheta)}{\\sup_{\\vartheta \\in \\Theta_0} L_x (\\vartheta)}$$ Hypothesen: $H_0$: $\\vartheta \\in \\Theta_0$ vs $H_1$: $\\vartheta \\in \\Theta \\setminus \\Theta_0$ Verteilung: Ist der SchÃ¤tzer konsistent, so gilt $$2 \\log(\\Lambda_n) \\sim \\chi_1&#94;2$$ Testentscheid: Verwerfe $H_0$, falls $\\Lambda > c$. WÃ¤hle $c$ so, dass Niveau $\\alpha$ eingehalten wird. Also: Verwerfe $H_0$, falls $2 \\log \\Lambda_n \\geq \\chi&#94;2_{1, 1-\\alpha}$ Approximativer Binomialtest Gegeben seien $X_1, \\dots, X_n \\sim Bin(1, p)$, $p$ unbekannt. Hypothesen: $H_0: p = p_0$ vs $H_1: p = p_1$ TestgrÃ¶ÃŸe: $T_n(x) = \\frac{\\sqrt{n}(\\bar{X} - p)}{\\sqrt{p (1-p)}}$ Verteilung: $T_n \\stackrel{H_0}{\\sim} \\mathcal{N}(0, 1)$ Testentscheid: $H_0$ verwerfen, falls $T_n > z_{1-\\alpha}$ Kapitel 4: 2-Stichproben Vergleiche (NV) F-Test fÃ¼r den Varianzquotienten Gegeben sind zwei Stichproben $X_1, \\dots, X_m$ sowie $Y_1, \\dots, Y_n$ mit $X_i \\sim \\mathcal{N}(\\mu, \\sigma&#94;2)$ und $\\mathcal{N}(\\nu, \\tau&#94;2)$. Hypothesen: $H_0: \\sigma&#94;2 = \\tau&#94;2$ vs $H_1: \\sigma&#94;2 \\neq \\tau&#94;2$ TestgrÃ¶ÃŸe: $$Q_{m,n} = \\frac{\\frac{1}{m-1} \\sum_{i=1}&#94;m {(X_i - \\bar{X}_m)}&#94;2}{\\frac{1}{n-1} \\sum_{i=1}&#94;n {(Y_i - \\bar{Y}_n)}&#94;2}$$ Verteilung: $Q_{m,n} \\stackrel{H_0}{\\sim} F_{m-1, n-1}$ Testentscheid: $H_0$ verwerfen, falls $Q_{m,n} \\leq F_{m-1,n-1;\\frac{\\alpha}{2}}$ oder $Q_{m,n} \\geq F_{m-1,n-1;1-\\frac{\\alpha}{2}}$ Kapitel 5: Lineare Regression Satz 5.4.1 Unter $H_0$ ist die Teststatistik $F = \\frac{(TSS - RSS)/(p-r)}{RSS/(n-p)}$ Fisher-verteilt mit $p-r$ ZÃ¤hler- und $n-p$ Nenner-Freiheitsgraden. ANOVA-Tafel Freiheitsgrade Quadratsumme mittlere Quadratsumme Teststatistik Regression $k-1$ TSS - RSS $\\frac{TSS-RSS}{k-1}$ F = $\\frac{TSS-RSS/(k-1)}{RSS/(n-k)}$ Residuen $n-k$ RSS $\\frac{RSS}{n-k}$ Gesamt $n-1$ TSS $H_0$: $\\mu_1 = \\mu_2 = \\dots = \\mu_k$ $H_0$ verwerfen, wenn $F \\geq F_{k-1, n-k; 1- \\alpha}$. Kleinster-Quadrate-SchÃ¤tzer Der Kleinste-Quadrate-SchÃ¤tzer fÃ¼r das klassische lineares Modell $Y = X \\beta + \\epsilon$ lautet: $$\\hat{\\beta} = (X&#94;T X)&#94;{-1} X&#94;T Y$$ $$\\hat{Y} \\sim N_n(X \\beta, \\sigma&#94;2 H)$$ $$\\hat{\\varepsilon}_i \\sim \\mathcal{N}(0, (1-H_{ii}) \\sigma&#94;2)$$ Der Ã¼bliche SchÃ¤tzer fÃ¼r $\\sigma&#94;2$ ist $$\\hat{\\sigma}&#94;2 = \\frac{1}{n-p} \\| Y - \\hat{Y} \\|&#94;2$$ Die folgenden Sachen kann man alle in der Klausur aus obigen Angaben herleiten (vgl. math.SE ): Es gilt: $$\\hat{\\beta} \\sim N_p(\\beta, \\sigma&#94;2 (X&#94;T X)&#94;{-1})$$ $$\\hat{\\beta}_i \\sim \\mathcal{N}(\\beta_i, \\sigma&#94;2 (X&#94;T X)&#94;{-1}_{i+1, i+1})$$ sowie $$(n-p)\\hat{\\sigma}&#94;2/\\sigma&#94;2 \\sim \\chi&#94;2_{n-p}$$ SchÃ¤tzer fÃ¼r die Standardabweichung von $\\hat{\\beta}$: $$se(\\hat{\\beta}_i) = \\hat{\\sigma} \\sqrt{{(X&#94;T X)}&#94;{-1}_{i,i}}$$ Kapitel 6: Varianz- und KovarianzÂ­analyse Modellannahmen der Varianzanalyse Das Rauschen ist unabhÃ¤ngig und jeweils $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma&#94;2)$. Summenrestriktionen Es muss ein balanciertes Design ($n_1 = n_2 = \\dots = n_k$) vorliegen. Dann muss $$\\sum_{i=1}&#94;k \\alpha_i = 0$$ gelten. Das Modell ist $Y = X \\beta + \\varepsilon$ mit Design-Matrix $$X = \\begin{pmatrix}1 & 1& 0 & &0\\\\ \\vdots & \\vdots & \\vdots & &\\vdots\\\\ \\vdots & 1 & 0 & &\\vdots\\\\ \\vdots & 0 & 1 & &\\vdots\\\\ \\vdots & \\vdots & \\vdots & & \\vdots\\\\ \\vdots & \\vdots & 1 & & 0\\\\ \\vdots & \\vdots & 0 & & 1\\\\ \\vdots & \\vdots & \\vdots & \\ddots &\\vdots\\\\ \\vdots & 0 & 0 & & 1\\\\ \\vdots & -1 & -1 & \\dots & -1\\\\ \\vdots & \\vdots & \\vdots & & \\vdots\\\\ 1 & -1 & -1 & \\dots & -1\\\\\\end{pmatrix}$$ und Parametervektor $$\\beta := \\begin{pmatrix}\\mu\\\\\\alpha_2\\\\\\dots\\\\\\alpha_k\\end{pmatrix}$$ Bonferroni-Korrektur Es liegt eine Familie von $m$ Tests vor. Man macht eine globale Nullhypothese, dass alle Nullhypothesen gelten. Alle $m$ Test werden auf dem Niveau $\\frac{\\alpha}{m}$ durchgefÃ¼hrt, sodass insgesamt das Niveau $\\alpha$ erreicht wird. BestimmtheitsmaÃŸ $R&#94;2$ $$R&#94;2 = 1 - \\frac{RSS}{TSS} = 1 - \\frac{\\sum_{i=1}&#94;n (y_i - \\hat{y}_i)}{\\sum_{i=1}&#94;n (y_i - \\bar{y}_i)}$$ Es gilt: $R&#94;2 \\in [0, 1]$ Ist die Kenntnis von $x$ wichtig fÃ¼r die Vorhersage von $y$, so ist das BestimmtheitsmaÃŸ nahe bei 1. Globaler $F$-Test Hypothesen: $H_0$: $\\mu_1 = \\mu_2 = \\dots = \\mu_k$ vs $H_1: \\exists i, j: \\mu_i \\neq \\mu_j$ TestgrÃ¶ÃŸe: $F = \\frac{(TSS - RSS) / (k-1)}{RSS / (n-k)}$ Verteilung: $F \\stackrel{H_0}{\\sim} F_{k-1, n-k}$ Testentscheid: $H_0$ verwerfen, falls $F \\geq F_{k-1, n-k; 1 - \\alpha}$ Kapitel 7: Kategoriale Daten - Kapitel 8: NichtÂ­parametrische Verfahren Vorzeichen-Test fÃ¼r den Median Teste die Hypothese ob eine GrÃ¶ÃŸe $M$ den Mittelwert $\\mu$ hat gegen die Alternative $H_1$: $M \\neq \\mu$. Bilde die PrÃ¼fgrÃ¶ÃŸe $$S_n = \\sum_{i=1}&#94;n \\mathbb{1}_{X_i > \\mu}$$ Falls $H_0$ gilt, dann ist $S_n \\sim Bin(n, 0.5)$ Lehne $H_0$ ab, wenn $S_n \\leq c$ oder $S_n \\geq n - c$. Bestimme $c$ so, dass $$P_{H_0}(S_n \\leq c) + P_{H_0}(S_n \\geq n - c) \\stackrel{!}{\\leq} \\alpha$$ AbkÃ¼rzungen MQA: Mittlere Quadratische Abweichung RSS: Residual Sum of Squares SQI: Summe der Quadrate innerhalb der Gruppen SQZ: Summe der Quadrate zwischen den Gruppen TSS: Total Sum of Squares ( \\(TSS = \\sum_{i=1}&#94;n {(y_i - \\bar{y}_n)}&#94;2\\) ) uiv, u.i.v.: unabhÃ¤ngig identisch verteilt Symbolverzeichnis Symbol Bedeutung $c_\\alpha$ $\\Phi&#94;{-1}(\\alpha)$: Inverse Verteilungsfunktion der Standardnormalverteilung $E(X)$ Erwartungswert der Zufallsvariable $X$ $\\mathcal{N}(\\mu, \\sigma&#94;2)$ Normalverteilung mit Mittelwert $\\mu$ und Standardabweichung $\\sigma$ $Pois(\\lambda)$ Poisson-Verteilung $t_{n; \\beta}$ Das $\\beta$-Quantil der $t_n$-Verteilung. $V(X)$ Varianz der Zufallsvariable $X$ $\\mathfrak{X}$ Stichprobenraum $X \\sim A$ Die Zufallsvariable $X$ ist $AB$-Verteilt. $z_{1 - \\alpha}$ Inverse quantilsfunktion der Standardnormalverteilung: $z_{1 - \\alpha} = \\Phi&#94;{-1}(1-\\alpha)$ Verteilungen Verteilung Schreibweise $\\mathbb{E}(X)$ $Var(x)$ Bemerkung Binomial-Verteilung $X \\sim Bin(n, p)$ $n \\cdot p$ $n \\cdot p \\cdot (1-p)$ $n$-maliges Bernoulli-Experiment Poisson-Verteilung $X \\sim Pois(\\lambda)$ $\\lambda$ $\\lambda$ Exponential-Verteilung $X \\sim Exp(\\lambda)$ $\\frac{1}{\\lambda}$ $\\frac{1}{\\lambda&#94;2}$ Zerfall-Prozess Normalverteilung $X \\sim \\mathcal{N}(\\mu, \\sigma&#94;2)$ $\\mu$ $\\sigma&#94;2$ Gleichverteilung $X \\sim U[a, b]$ $\\frac{b-a}{2}$ $\\chi&#94;2$-Verteilung $X \\sim \\chi&#94;2_n$ $n$ $2n$ Summe von $n$ normalverteilugen Zuvallsvariablen $X_1, \\dots, X_n$ $t$-Verteilung $X \\sim t_k$ $n$ $2n$ $X = \\frac{N}{\\sqrt{\\frac{Y}{k}}}$ mit $Y \\sim \\chi&#94;2_k$ und $N \\sim \\mathcal{N}(0, 1)$ $F$-Verteilung $X \\sim F_{m,n}$ $\\frac{n}{n-2}$ fÃ¼r $n > 2$ $\\frac{2n&#94;2 (m+n-2)}{m(n-2)&#94;2 (n-4)}$ fÃ¼r $n > 4$ $X = \\frac{\\frac{1}{r}R}{\\frac{1}{s}S}$ mit $R \\sim \\chi&#94;2_r$, $S \\sim \\chi&#94;2_s$ Python You might want to look into scipy.stats as it offers many convenient functions. For example, if you have to find the 95%-Quantile of the \\(F_{k=3,n=19}\\) distribution, this is what you do: import scipy.stats # Create a variable representing the distribution rv = scipy . stats . f ( dfn = 3 , dfd = 19 ) # Percent point function rv . ppf ( 0.95 ) # gives 3.1273500051133989 Klausur Aufbau Aufgabe 1 und 2 ML-SchÃ¤tzer bestimmen Score-Funktion / Fisher-Information CramÃ©r-Rao-Schranke asymptotisch Erwartungstreue / Konsistenz von SchÃ¤tzern Erwartungswert, Varianz, MQA eines SchÃ¤tzers bestimmen MomentenschÃ¤tzer bestimmen Aufgabe 3 Neyman-Pearson-Test ZGWS Likelihood-Quotienten-Test Aufgabe 4 Statistisches Modell angeben Quartile und Median einer Stichprobe bestimmen Vorzeichen-Test fÃ¼r Median Aufgabe 5 Satz von Student Konfidenzintervall GÃ¼tefunktion Beziehung zwischen Konfidenzintervall und Tests Aufgabe 6 Korrelationskoeffizient ANOVA-Tafel Modellannahmen bei einfacher Varianzanalyse Aufgabe 7 Lineares Regressionsmodell Kleinster-Quadrate-SchÃ¤tzer BestimmtheitsmaÃŸ Chi-Quadrat-Test auf HomogenitÃ¤t ( \\(D := \\sum_{i=1}&#94;n \\frac{n_i {(\\hat{p}_i - \\hat{p})}&#94;2}{\\hat{p} (1 - \\hat{p})} \\stackrel{H_0}{\\sim} \\chi&#94;2_{k-1}\\) ) Various Exp-Verteilung und Zusammenhang mit Gamma-Verteilung Binomial-Verteilung 1-Stichproben t-Test F-Test fÃ¼r den Varianzquotienten Globaler F-Test PrÃ¼fungsfragen Kann ein SchÃ¤tzer Erwartungstreu und Konsistent sein? â†’ Ja. Seien \\(X_1, \\dots, X_n \\stackrel{uiv}{\\sim} Bin(1, \\vartheta)\\) mit \\(\\vartheta \\in (0, 1)\\) . Sei auÃŸerdem \\(\\hat{\\vartheta}_n = \\frac{1}{n} \\sum_{i=1}&#94;n x_i\\) . \\(\\hat{\\vartheta}_n\\) ist erwartungstreu und konsistent. Kann ein SchÃ¤tzer weder Erwartungstreu noch Konsistent sein? â†’ Ja. Seien \\(X_1, \\dots, X_n \\stackrel{uiv}{\\sim} Bin(1, \\vartheta)\\) mit \\(\\vartheta \\in (0, 1)\\) . Der SchÃ¤tzer \\(\\hat{\\vartheta} = 0.5\\) ist weder Erwartungstreu noch konsistent fÃ¼r \\(\\vartheta \\neq 0.5\\) . Kann ein SchÃ¤tzer Erwartungstreu, aber nicht konsistent sein? â†’ Ja. Setting wie zuvor und \\(\\hat{\\vartheta} = x_n\\) (siehe math.SE ) Kann ein SchÃ¤tzer nicht Erwartungstreu, aber konsistent sein? â†’ Ja. Setting wie zuvor und \\(\\hat{\\vartheta} = \\frac{1}{n} \\sum_{i=1}&#94;n x_i + \\frac{1}{n}\\) (siehe math.SE ) Material und Links Vorlesungswebsite Illias StackExchange Percentile vs quantile vs quartile When is Fishers exact test used; when are approximative tests used? What is the range of values of the Fisher information? How can I calculate the distribution of the least-squares estimator \\(\\hat{\\beta}\\) ? Blog-Artikel The Absolute Value Function - vgl. Konfidenzintervalle The p value Anki-Karten ( direct download ) Verteilungsfunktion der Normalverteilung als Tabelle Inverse Verteilungsfunktion der Normalverteilung als Tabelle Fehlende MusterlÃ¶sungen: KIT-Musterloesungen - Verbesserungshinweise nehme ich immer gerne entgegen ( info@martin-thoma.de ) Literatur Skript von Dr. B. Klar: Statistik [ Bic01 ] P.J. Bickel and K.A. Doksum. Mathematical statistics, 2nd ed. [ Cza11 ] C. Cazado and T. Schmidt. Mathematische Statistik. Ãœbungsbetrieb ÃœbungsblÃ¤tter sind freiwillig. Termine und Klausurablauf Datum : 01.03.2017, 7:30 - 9:30 Uhr (Quelle: Vorlesungswebsite - Ja, es ist wirklich so frÃ¼h!) Ort : Benz-HÃ¶rsaal Geb. 10.21 Punkte : 60 Zeit : 2h Punkteverteilung : TODO Bestehensgrenze : mit 20 Punkten hat man bestanden Ãœbungsschein : gibt es nicht Bonuspunkte : gibt es nicht Nicht vergessen : Studentenausweis Taschenrechner Uhr Brille Geodreieck Einsicht : Am 2. MÃ¤rz standen schon die Noten fest. Am 16.03.17 um 11:00 - 11:30 Uhr im Raum 2.071 des MathematikgebÃ¤udes ist die Einsicht.","tags":"German posts","title":"Statistik - Klausur"},{"url":"https://martin-thoma.com/autofill-phishing/","text":"Autofill phishing is a simple technique I wasn't aware of until a few hours ago. It simply uses the fact that we are so used to filling out forms, that we usually let our Browser fill out the forms. Maybe we check if there is data which we don't want to submit and remove that. However, the browser (tested with Google Chrome 55) also fills out forms which we can't see. Check if you are affected Go to martin-thoma.de/autofill-phishing/?hidden=margin Fill out the displayed items with autofill Click on submit. It will show which data was submitted by you. I do not store this data. Solutions As a user Disable autofill. For Chrome, go to chrome://settings/search#Enable%20autofill and uncheck it: Autofill settings in Google Chrome As a developer Show the user a pop-up which displays which information is filled in (with checkboxes so that the user can decide not to fill certain items). I've heard Safari does something like this (Screenshots are welcome, if you have Safari) Overview Browser margin display hidden Google Chrome 55 Affected Ok Ok If you have another Browser, feel free to test it and leave a comment what is (not) affected. Alternatively, you can send an Email to info@martin-thoma.de . See also The Guardian: Browser autofill used to steal personal details in new phishing attack , 10.01.2017. Autocomplete Types","tags":"Cyberculture","title":"Autofill Phishing"},{"url":"https://martin-thoma.com/paper-list/","text":"The following includes my reading list and a list of papers organized in tracks which I can recommend to read. Most (all?) of them are about machine learning and neural networks. Reading List I am aware of the following papers and I want to read them ... when I have time: Doubly Convolutional Neural Networks Multifaceted Feature Visualization: Uncovering the Different Types of Features Learned By Each Neuron in Deep Neural Networks Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning Convolutional Neural Fabrics Evolving Neural Networks through Augmenting Topologies and A Hypercube-Based Encoding for Evolving Large-Scale Neural Networks Deep Convolutional Neural Network Inference with Floating-point Weights and Fixed-point Activations : Making networks smaller (file size) All You Need is Beyond a Good Init: Exploring Better Solution for Training Extremely Deep Convolutional Neural Networks with Orthonormality and Modulation Large-Scale Evolution of Image Classifiers Best of The following is a list of papers, organized by the year I read (or written) them. Not when they were published. 2016 Lipton, Z.C., 2016. The Mythos of Model Interpretability . IEEE Spectrum. ( summary ) Zhang, C., Bengio, S., Hardt, M., Recht, B. and Vinyals, O., 2016. Understanding deep learning requires rethinking generalization . arXiv preprint arXiv:1611.03530. ( summary ) Deep Learning without Poor Local Minima and Matrix Completion has No Spurious Local Minimum Tracks Weight Initialization X. Glorot and Y. Bengio, \" Understanding the difficulty of training deep feedforward neural networks .\" in Aistats, vol. 9, 2010, pp. 249â€“256. ( summary ) A. M. Saxe, J. L. McClelland, and S. Ganguli, \" Exact solutions to the nonlinear dynamics of learning in deep linear neural networks ,\" arXiv preprint arXiv:1312.6120, Dec. 2013. ( summary ) K. He, X. Zhang, S. Ren, and J. Sun, \" Delving deep into rectifiers: Surpassing human-level performance on imagenet classification ,\" in Proceedings of the IEEE International Conference on Computer Vision, Feb. 2015, pp. 1026â€“1034. ( summary ) D. Mishkin and J. Matas, \" All you need is a good init ,\" arXiv preprint arXiv:1511.06422, Nov. 2015. ( summary ) Ideas Establishing Human-Level scores for Benchmarks User Interfaces: What are good examples? Herarchical Classification Pooling: Can it be replaced by convolutions? Ensembles: Train an ensemble, use it to get better labels than simple one-hot encoding, train new single network on new labels. (Possibly the same as Distilling the Knowledge in a Neural Network ) OCR and semantic segmentation Negative images How does taking grayscale images on color-image trained networks decrease performance?","tags":"Science","title":"Paper List"},{"url":"https://martin-thoma.com/r-lang/","text":"Quite a while ago, I had to use R for a statistics class. Nice things about R R has a neat programming environment called rstudio : RStudio As you can see, RStudio conveniently shows: The code, an interactive console, a window with plots, loaded variables / functions as well as their values edit: RStudio also has the possibility to edit keyboard shortcuts. Nice :-) Simple plots are relatively easy to generate. The one you can see in the screenshot was generated by ## Aufgabe 16 # In einem Test wird die Nullhypothese, dass fÃ¼r eine bestimmte Altersgruppe # mit n Personen die durchschnittliche Punktzahl Î¸ bei einem Leistungstest 40 # betrÃ¤gt, gegen die Alternative, dass diese ungleich 40 ist, getestet. Sie # kÃ¶nnen davon ausgehen, dass die erreichten Punktzahlen normalverteilt mit # Varianz Ïƒ&#94;2 = 36 sind. ## Aufgabe c # GÃ¼tefunktion: # g(\\theta) = P_\\theta(X \\in Kritischem Bereich) # = P_\\theta(Entscheidung fÃ¼r H_1) g_a = function ( theta ) { # H_0: Î¸ = 40 # H_1: Î¸ != 40 ifelse ( theta == 40 , pnorm ( 4 , mean = 0 , sd = 2 ) - pnorm ( -4 , mean = 0 , sd = 2 ), pnorm ( 4 , mean = abs ( theta -40 ), sd = 2 ) - pnorm ( -4 , mean = abs ( theta -40 ), sd = 2 )) } g_b = function ( theta ) { # H_0: Î¸ = 40 # H_1: Î¸ != 40 ifelse ( theta == 40 , pnorm ( 2 , mean = 0 , sd = 1 ) - pnorm ( -2 , mean = 0 , sd = 1 ), pnorm ( 2 , mean = abs ( theta -40 ), sd = 1 ) - pnorm ( -2 , mean = abs ( theta -40 ), sd = 1 )) } curve ( g_a , from = 30 , to = 50 , xlab = \"\" , ylab = \"\" , lwd = 2 ) curve ( g_b , from = 30 , to = 50 , add = T , col = \"red\" , xlab = \"\" , lwd = 2 ) # ist besser title ( main = \"GÃ¼tefunktion der Tests (a) und (b)\" , sub = \"Aufgabe 16\" , xlab = expression ( theta ), ylab = \"g_a(x) und g_b(x)\" ) legend ( \"topright\" , legend = c ( \"g_a(x)\" , \"g_b(x)\" ), lty = c ( 1 , 1 ), lwd = c ( 2 , 2 ), col = c ( \"black\" , \"red\" )) Expected R has a few properties which I expect from any programming language today: A code repository ( cran.r-project.org ) where people can add packages. R has its niche: Statistics (although I expect Python to replace R on the long run) R has a tutorial . In this introduction, one can also see the focus on statistics. Bad things about R The name. Try searching for \"R\" ... \"rlang\" seems to work, though. But it is close to \"erlang\", another language. This makes searching for answers harder than necessary. There seems to be no possibility to run an R script from console like python script.py . : This is simply wrong. If you edit the keyboard shortcuts (\"run all code\"), you can see it. But I have to say that it's pretty well-hidden ;-) (Thanks to Tariq for correcting me!) There seems to be no possibility to run an R script completely within rstudio. I've seen users who know R for several years pressing ctrl + enter for every single line to execute the script line by line. Indexing starts with 1 , not with 0 . Community R seems to have a pretty active community according to langpop.corger.nl ... however, not comparable with Python ( githut.info ). And they love forking repos. Why Python can replace R One thing mentioned all the time as a reason to use R are nice visualizations which are easy to create. Well, in Python there is matplotlib and seaborn (as well as ggplot , bokeh , pygal , geoplotlib , gleam , missingo , leather , ...). For example, the plot from above can be made with matplotlib like this: #!/usr/bin/env python # -*- coding: utf-8 -*- ur \"\"\" # Aufgabe 16 In einem Test wird die Nullhypothese, dass fÃ¼r eine bestimmte Altersgruppe mit n Personen die durchschnittliche Punktzahl Î¸ bei einem Leistungstest 40 betrÃ¤gt, gegen die Alternative, dass diese ungleich 40 ist, getestet. Sie kÃ¶nnen davon ausgehen, dass die erreichten Punktzahlen normalverteilt mit Varianz Ïƒ&#94;2 = 36 sind. ## Aufgabe c GÃ¼tefunktion: g(\\theta) = P_\\theta(X \\in Kritischem Bereich) = P_\\theta(Entscheidung fÃ¼r H_1) \"\"\" import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm def g ( thetas , sd , x ): u \"\"\" Calculate the probability between [-x, x] of a random variable. H_0: Î¸ = 40 H_1: Î¸ != 40 \"\"\" values = [] for theta in thetas : if theta == 40 : mean = 0 else : mean = abs ( theta - 40 ) rv = norm ( mean , sd ) values . append ( rv . cdf ( x ) - rv . cdf ( - x )) return values def main ( xmin = 30 , xmax = 50 , samples = 100 ): \"\"\"Create plots.\"\"\" x = np . linspace ( xmin , xmax , samples ) # sample 100 values between 30 and 50 plt . plot ( x , g ( x , sd = 2 , x = 4 ), color = '#000000' , label = \"$g_a(x)$\" ) plt . plot ( x , g ( x , sd = 1 , x = 2 ), color = '#ff0000' , label = \"$g_b(x)$\" ) plt . title ( u \"GÃ¼tefunktion der Tests (a) und (b)\" , fontweight = 'bold' ) plt . xlabel ( r \"\"\"$\\theta$\"\"\" ) plt . ylabel ( r \"\"\"$g_a(x)$ und $g_b(x)$\"\"\" ) plt . legend () plt . suptitle ( \"Aufgabe 16\" ) plt . show () if __name__ == '__main__' : main () which results in Matplotlib plot example To me, the Python code seems much cleaner, easier to understand and to adjust to other cases. And it can be easily imported from other scripts / executed at once. rpy2 You can access R data with rpy2 . from rpy2.robjects import r from rpy2.robjects import pandas2ri def data ( name ): return pandas2ri . ri2py ( r [ name ]) df = data ( 'iris' ) print ( df . describe ()) Python - R dictionary Python R Explanation scipy.stats.norm(0, 2).cdf(4) pnorm(4, mean=0, sd=2) Cumulative Density function at 4 of a normal distributed variable with mean 0 and standard deviation 2. Links stats.stackexchange.com Manuals www.r-tutor.com tryr.codeschool.com www.cyclismo.org/tutorial/R","tags":"Cyberculture","title":"R - A language"},{"url":"https://martin-thoma.com/typeset-chess-games/","text":"Chessboard Simple example Chessboard - simple example \\documentclass { article } \\usepackage [pdftex,active,tightpage] { preview } \\setlength\\PreviewBorder { 5mm } \\usepackage { chessboard } \\begin { document } \\begin { preview } \\chessboard [setfen=5rk1/pp3N1p/4P3/2P5/3Q1PK1/P7/1Pr3pq/R3R3 w - - 0 0, showmover] \\end { preview } \\end { document } From tex.stackexchange.com . Skak Simple example Simple example with skak \\documentclass { article } \\usepackage [pdftex,active,tightpage] { preview } \\setlength\\PreviewBorder { 5mm } \\usepackage { skak } \\begin { document } \\begin { preview } % sets the internal board or a new game \\newgame % typesets the moves and updates the board \\mainline { 1.e4 e5 2. Nf3 Nc6 3.Bb5 } \\\\ % show the current board position \\showboard \\end { preview } \\end { document } See also Chessboard documentation Skak documentation - short reference","tags":"Cyberculture","title":"How to typeset chess games with LaTeX"},{"url":"https://martin-thoma.com/this-blog/","text":"This article gives all information what I'm currently using to provide this blog to you. Part Service / Program Price Hosting GitHub Free as in beer Domain namecheap 86.35 EUR per 10 Years HTTPS Cloudflare Free as in beer Blog creation Pelican Free as in beer and speach Writing Sublime Text 3 70 US-Dollar (once) Comments Disqus Free as in beer Search Tipue Free as in beer and speach Uptime monitoring Pingdom Free as in beer HTML Validator validator.w3.org Free as in beer Page analysis nibbler Free as in beer Page speed analysis gtmetrix , pagescoring , Chrome Developer Tools Free as in beer Accessibility Wave Free as in beer Mobile Friendliness Google Free as in beer API monitoring runscope.com Free as in beer More Tests uitest.com I've also used Google Analytics / Piwik some years ago, but I think it is not worth it. I don't want to spy my readers. And I would not change anything in my blog knowing who reads it. Custom Domain If you want to host your content at GitHub, but have a custom Domain like martin-thoma.com instead of martinthoma.github.io , you have to: Add an A-record to Github on namecheap (see example ) Add a file called CNAME with content martin-thoma.com (yes, without http:// ) to the root of your directory GitHub also offers some help on setting up a custom domain with Pages . Cloudflare Do this step after the custom domain works. To set up HTTPS with namecheap and Cloudflare you have to go through the following steps: On Cloudflare: Click on \"Add Site\" and enter your URL (e.g. \"ml-ka.de\") Click on \"Begin Scan\". This will take about 2 minutes. After that, click on \"Continue\". Click on \"Continue\" until they show you the nameservers. Write them down, you will need them for changes on namecheap. On namecheap: Go to \"Domain List\", \"Domains - Details\", \"Nameservers\" Change it to \"Custom\" and \"amy.ns.cloudflare.com\" and \"kai.ns.cloudflare.com\" Click on the checkmark to make changes permanent. This might take up to 48 hours.","tags":"Cyberculture","title":"This Blog - Technical Stuff"},{"url":"https://martin-thoma.com/arxiv-data/","text":"I've written a draft for this in June 2014 and recently decided to publish it. The article is certainly not of high quality, but I want to keep it as a reminder for some of the problems I ran into and the solutions I've used. I've recently talked to my bachelors thesis advisers. A short reminder: I write a thesis about the recognition of handwritten mathematical symbols. As a practical part I implement everything on write-math.com . My advisers said me that I need at least 100 training examples per symbol. As I currently have about 1070 symbols in the database, including symbols like \\bat or \\Mundus . As they are extremely unlikely to be used in math mode, I will simply skip them. The more symbols I can skip, the less training symbols I need to get. So I want to skip as many as possible. I think \\up[greek letter] like \\updelta and \\Updelta are also rare. But my adviser doesn't think so. This means I need to prove it. One way to prove it is by looking at much data and counting. One of the biggest datasources for LaTeX is arXiv , a repository of electronic preprints of scientific papers in the fields of mathematics, physics, astronomy, computer science, quantitative biology, statistics, and quantitative finance, which can be accessed online. Why parsing LaTeX is hard Special cases. Lots of them. At first you would think: Dude, it's only counting strings in documents. Is that really worth writing an article? Yes, it is. Just think about the many ways you can define your own commands (called macros): \\newcommand{[search]}{[replace]} \\newcommand{[search]} {[replace]} \\def[search]{[replace]} \\newcommand*{[search]}{[replace]} \\newenvironment ... Then remember that you can import files \\input{package} \\input package.sty \\include \\usepackage and weird commands like \\begin{filecontents*} . And even more weird self-defined ones: \\def\\be{\\begin{equation}} \\def\\ee{\\end{equation}} \\newcommand{\\beq}{\\begin{equation}} \\newcommand{\\eeq}{\\end{equation}} \\def\\bea{\\begin{eqnarray}} \\def\\eea{\\end{eqnarray}} \\newcommand\\beq{\\begin{equation}} \\newcommand\\eeq{\\end{equation}} \\newcommand\\beqa{\\begin{eqnarray}} \\newcommand\\eeqa{\\end{eqnarray}} \\def\\({\\left(} \\def\\){\\right)} \\def\\[{\\left[} \\def\\]{\\right]} \\def\\<{\\left\\langle} \\def\\>{\\right\\rangle} As some of these were quite common, sed and find saved me some work: find . -type f -print0 | xargs -0 \\ sed -i 's/\\\\newcommand{\\\\beq}{\\\\begin{equation}}/%%%%%%%%%%%%%%/g' find . -type f -print0 | xargs -0 \\ sed -i 's/\\\\newcommand\\\\eeq{\\\\end{equation}}/%%%%%%%%%%%%%%/g' find . -type f -print0 | xargs -0 \\ sed -i 's/\\\\newcommand{\\\\eeq}{\\\\end{equation}}/%%%%%%%%%%%%%%/g' find . -type f -print0 | xargs -0 \\ sed -i 's/\\\\newcommand{\\\\be}{\\\\begin{equation}}/%%%%%%%%%%%%%%/g' find . -type f -print0 | xargs -0 \\ sed -i 's/\\\\newcommand{\\\\ee}{\\\\end{equation}}/%%%%%%%%%%%%%%/g' find . -type f -print0 | xargs -0 \\ sed -i 's/\\\\def\\\\ee{\\\\end{equation}}/%%%%%%%%%%%%%%/g' find . -type f -print0 | xargs -0 \\ sed -i 's/\\\\def\\\\be{\\\\begin{equation}}/%%%%%%%%%%%%%%/g' find . -type f -print0 | xargs -0 \\ sed -i 's/\\\\def\\\\ee{\\\\end{equation}}/%%%%%%%%%%%%%%/g' What I currently don't check Commands with parameters: \\makeatletter \\def\\imod #1 { \\allowbreak\\mkern 10mu( { \\operator @font mod } \\,\\, #1) } \\makeatother Structure of arXiv arXiv uses Amazon S3 with the \"requester pays\" option. The storage containers of S3 are called \"buckets\" and they are adressed in an URI style: s3://arxiv/pdf/arXiv_pdf_manifest.xml A tool to get data from S3 under Linux is s3cmd . It can be used like this: $ s3cmd ls --add-header = \"x-amz-request-payer: requester\" s3://arxiv/pdf/arXiv_pdf_manifest.xml 2011 -02-15 04 :12 246144 s3://arxiv/pdf/arXiv_pdf_manifest.xml $ s3cmd get --add-header = \"x-amz-request-payer: requester\" s3://arxiv/pdf/arXiv_pdf_manifest.xml s3://arxiv/pdf/arXiv_pdf_manifest.xml -> ./arXiv_pdf_manifest.xml [ 1 of 1 ] 246144 of 246144 100 % in 0s 377 .85 kB/s done $ s3cmd ls --add-header = \"x-amz-request-payer: requester\" s3://arxiv/pdf/ \\* The manifest contains all information about the real data. Remember, you have to pay for the downloads! According to arXiv, it's about $0.12/GB transferred. This means for 150 GB I would have to pay at least $18. The manifest is an XML file, which looks like this: <?xml version='1.0' standalone='yes'?> <arXivSRC> <file> <content_md5sum> cacbfede21d5dfef26f367ec99384546 </content_md5sum> <filename> src/arXiv_src_0001_001.tar </filename> <first_item> astro-ph0001001 </first_item> <last_item> quant-ph0001119 </last_item> <md5sum> 949ae880fbaf4649a485a8d9e07f370b </md5sum> <num_items> 2364 </num_items> <seq_num> 1 </seq_num> <size> 225605507 </size> <timestamp> 2010-12-23 00:13:59 </timestamp> <yymm> 0001 </yymm> </file> <file> <content_md5sum> d90df481661ccdd7e8be883796539743 </content_md5sum> <filename> src/arXiv_src_0002_001.tar </filename> <first_item> astro-ph0002001 </first_item> <last_item> quant-ph0002094 </last_item> <md5sum> 4592ab506cf775afecf4ad560d982a00 </md5sum> <num_items> 2365 </num_items> <seq_num> 1 </seq_num> <size> 227036528 </size> <timestamp> 2010-12-23 00:18:09 </timestamp> <yymm> 0002 </yymm> </file> <file> <content_md5sum> 3388afd7bfb2dfd9d3f3e6b353357b33 </content_md5sum> <filename> src/arXiv_src_0003_001.tar </filename> <first_item> astro-ph0003001 </first_item> <last_item> quant-ph0003151 </last_item> <md5sum> b5bf5e52ae8532cdf82b606b42df16ea </md5sum> <num_items> 2600 </num_items> <seq_num> 1 </seq_num> <size> 230986882 </size> <timestamp> 2010-12-23 00:22:15 </timestamp> <yymm> 0003 </yymm> </file> ... The differrent files mean: content_md5sum : MD5 sum of all the files in the tar package concatenated but not packaged. Use md5sum for the md5sum of the tar package which should match the S3 MD5 sum. filename : Name of file within bucket, prefix bucket name s3://arxiv/ for complete identifier first_item and last_item : arXiv identifier of article PDF first in tar package, and last in tar package md5sum : MD5 sum of tar package, can be used as check against downloaded file num_items : Number of PDF files in tar package seq_num : Sequence number within month yymm size : Size of tar package in bytes timestamp : Timestamp of tar package (unix mtime when created, expressed at YYYY-MM-DD HH:MM::SS) yymm : Two digit year and month of items in the tar package. Starts with 9108 for 1991-08, rolls past y2k to 0001 for 2000-01, 1008 for 2010-08 etc.","tags":"Code","title":"How to use arXiv data"},{"url":"https://martin-thoma.com/learning-machine-learning/","text":"There is plenty of material online for learning machine learning. I like to share some links in this post to what I know. Feel free to add comments with other material. Stanford: Deep Learning for Natural Language Processing Natural language processing (NLP) is one of the most important technologies of the information age. Understanding complex language utterances is also a crucial part of artificial intelligence. Applications of NLP are everywhere because people communicate most everything in language: web search, advertisement, emails, customer service, language translation, radiology reports, etc. There are a large variety of underlying tasks and machine learning models powering NLP applications. Recently, deep learning approaches have obtained very high performance across many different NLP tasks. These models can often be trained with a single end-to-end model and do not require traditional, task-specific feature engineering. In this spring quarter course students will learn to implement, train, debug, visualize and invent their own neural network models. The course provides a deep excursion into cutting-edge research in deep learning applied to NLP. The final project will involve training a complex recurrent neural network and applying it to a large scale NLP problem. On the model side we will cover word vector representations, window-based neural networks, recurrent neural networks, long-short-term-memory models, recursive neural networks, convolutional neural networks as well as some very novel models involving a memory component. Through lectures and programming assignments students will learn the necessary engineering tricks for making neural networks work on practical problems. syllabus They provide YouTube videos and slides. The videos are simply recordings of the lecture, but in good quality. Udacity: Intro to Machine Learning Machine Learning is a first-class ticket to the most exciting careers in data analysis today. As data sources proliferate along with the computing power to process them, going straight to the data is one of the most straightforward ways to quickly gain insights and make predictions. Machine learning brings together computer science and statistics to harness that predictive power. It's a must-have skill for all aspiring data analysts and data scientists, or anyone else who wants to wrestle all that raw data into refined trends and predictions. This is a class that will teach you the end-to-end process of investigating data through a machine learning lens. It will teach you how to extract and identify useful features that best represent your data, a few of the most important machine learning algorithms, and how to evaluate the performance of your machine learning algorithms. Link: udacity.com/course/ud120 Lessons 1-4: Supervised Classification Lesson 5: Datasets and Questions Lesson 6 and 7: Regressions and Outliers Lesson 8: Unsupervised Learning Lessons 9-12: Features, Features, Features Lessons 13-14: Validation and Evaluation Lesson 15: Wrapping it all Up Udacity: Intro to Artificial Intelligence Artificial Intelligence (AI) is a field that has a long history but is still constantly and actively growing and changing. In this course, you'll learn the basics of modern AI as well as some of the representative applications of AI. Along the way, we also hope to excite you about the numerous applications and huge possibilities in the field of AI, which continues to expand human capability beyond our imagination. Link: udacity.com/course/cs271 Part I: Fundamentals of AI Overview of AI Statistics, Uncertainty, and Bayes networks Machine Learning Logic and Planning Markov Decision Processes and Reinforcement Learning Hidden Markov Models and Filters Adversarial and Advanced Planning Part II: Applications of AI Image Processing and Computer Vision Robotics and robot motion planning Natural Language Processing and Information Retrieval Udacity: Artificial Intelligence for Robotics Learn how to program all the major systems of a robotic car from the leader of Google and Stanford's autonomous driving teams. This class will teach you basic methods in Artificial Intelligence, including: probabilistic inference, planning and search, localization, tracking and control, all with a focus on robotics. Extensive programming examples and assignments will apply these methods in the context of building self-driving cars. Link: udacity.com/course/cs373 Lesson 1: Localization Lesson 2: Kalman Filters Lesson 3: Particle Filters Lesson 4: Search Lesson 5: PID Control Lesson 6: SLAM (Simultaneous Localization and Mapping) Side notes Make sure you have enough disk space Even deleting that much takes a lot of time More links Learning Deep Learning : A list of deep learning books, papers and websites. Deep Learning, Feature Learning Deep Learning Master Class Tutorial on Deep Learning for Vision Neural Network Debugging Machine Learning Glossary","tags":"Cyberculture","title":"Learning Machine Learning"},{"url":"https://martin-thoma.com/astonishing-places/","text":"There are some places which look astonishing. I would like to visit them and to see them with my own eyes. Arctic Frost flower (Image source: Wikimedia ) Hair Ice (Image source: Wikimedia ) Nacreous Clouds (Image source: Wikimedia ) Snow Chimneys Asia Turkmenistan Door to Hell (Image source: Wikimedia ) Thailand Khao Yai National Park (Image source: Wikimedia ) Khlong Lan National Park (Image source: Wikimedia ) Europe Norway Aurora Borealis (Image source: Wikimedia ) Svalbard or Lofoten ( image ) might be a good place to see it. Denmark Black Sun (Image Source: Wikimedia ) Iceland Vulcanic Lightning, for example at EyjafjallajÃ¶kull (Image source: Wikimedia ) Ice cave (Image source: Wikimedia ) Geyser (Image source: Wikimedia ) Sunset at GoÃ°afoss waterfall (Image source: reddit ). One can see the aurora there, too ( source ). Steam Towers: Hverir Auroras (e.g. in Reykjavik from late September to early April) Spain Mallorca (Image source: reddit: EarthPorn ) Caminito del Rey (Image source: Wikipedia Commons ) Turkey Travertine Pools of Pamukkale (Image source: Wikimedia ) Greece Mykonos (Image source: Wikimedia ) Ukraine Protiate Kaminnia Natural Geological Monument (Image source: Wikimedia ) North America Belize Great Blue Hole (Image source: Wikimedia ) Canada Spotted Lake : Looks interesting in Summer when the water evaporates (Image source: Wikimedia Commons ) United States Volcanic Lightning (Alaska, Augustine Volcano ) South America Bolivia Salar de Uyuni is one of the most famous salt pans (Image source: Wikimedia Commons ) Venezuela Catatumbo lightning (Image source: Wikimedia Commons ) Oceania New Zealand Moeraki Boulders (Image source: Wikimedia ) See also What are some of the best rare natural phenomena that occur on Earth?","tags":"My bits and bytes","title":"Astonishing Places"},{"url":"https://martin-thoma.com/mp3-player/","text":"I thought MP3 players were basically a solved problem, meaning they are only improved in price, storage capacity and battery. However, there are some design flaws with a new MP3 player I recently got. In this post I just want to collect some design ideas which I think are important. Physical features: Dedicated volume button (up and down) On-off switch which does not easily get pushed by accident (e.g. a switch, not a button) A single \"start / stop\" button Navigation buttons: up / down / select (select can be the same button as \"play / stop\", but then there has to be a way to get out of the menu fast and easy) Illuminated display which is big enough to show battery, current title, playback time. No need to be able to play videos. Standard plug for headphones. Standard Smartphone USB slot (micro-b?) for charging and transfering data. microSD card slot which accepts at least 32GB cards. Software features: When the MP3 player is shut down while playing an MP3, it should save where it was and play it from this point (or rather 5 seconds earlier) when it is turned on again. Playlists Have a simple, open, standard format for playlists. For example M3U or better XSPF Play playlist files. Create a playlist from a folder. Possibility to remove a song from a playlist Possibility to add a song to a playlist Possibility to move the position of a song in a playlist Act as a simple USB stick when connected to a computer. No special file system should be necessary. It would be nice if the MP3 player supported USB 3, but I don't think that is necessary.","tags":"Cyberculture","title":"MP3 Player"},{"url":"https://martin-thoma.com/gr-20/","text":"Der Korsika GR 20 (franz.: Grande RandonnÃ©e 20) ist ein Fernwanderweg. Ich bin den Nordteil von Calvi bis Vizzavona vom 25.09.2016 bis zum 09.10.2016 gelaufen. Allgemeines Zelten ist nur bei den HÃ¼tten erlaubt (ca. 7 Euro pro Nacht und Person) Markierung rot/weiss, alpine Varianten mit gelben Doppelstrichen besonders auf den nÃ¶rdlichen Etappen und im SpÃ¤tsommer/Herbst kaum Quellen, d.h. Wasser von HÃ¼tten mitnehmen Nicht Ã¼berall Handynetz, keine MÃ¶glichkeit zum Nachladen des Akkus! Sonnenaufgang (September): 7:08 Sonnenuntergang (September): 19:28 Krankheiten Da muss man sich wohl eigentlich keine Sorgen machen. Was ich vorher gefunden hatte (aber ignoriert habe): Bilharziose (Schistosomiasis): Wasser des Flusses Cavu (Symptome: Hautausschlag) - Badewarnung aufgehoben ( Quelle ) Impfungen ( Quelle ): Diphtherie Keuchhusten (Tdap) Tetanus Packliste Kleidung Die Kleidung ist so ausgewÃ¤hlt, dass man sie in Schichten Ã¼bereinander tragen kann. Bitte berÃ¼cksichtigt, dass es auf dem Berg mit Wind nachts wirklich sehr kalt werden kann. Ich habe zeitweise mit dem Schlafsack, einem Inlet und noch 4 Schichten Kleidung (T-Shirt, Unterhemd, Softshell, Windjacke) geschlafen. Beine: 3 Boxershorts (Icebreaker Herren Unterhose Anatomica, ASIN B016D9ZS9Y) 1 lange Unterhose (Icebreaker Herren Oasis Leggings, ASIN B00ER4H1DY) 1 Hose (VAUDE Herren Hose Farley Stretch Pants II, ASIN B01HL94DU0) 1 Regenhose 1 kurze Hose (Puma Essential Woven 5 Zoll, Art-Nr. 831874-0001) OberkÃ¶rper 3 T-Shirts (Icebreaker Herren T-Shirt Tech Lite Short Sleeve, ASIN B00L6EHH4Q und Odlo George T-Shirt, Art-Nr. 221802) 1 Softshell (Odlo Herren Pullover Midlayer 1/2 Zip Sun Peaks, ASIN B00DG1BOK0) 1 Regen / Windjacke 1 Regenponcho 3 Paar Socken (FALKE Herren Trekking Socken TK2 Short Coool, ASIN B001E11Y1I) Wanderschuhe (Meindl Air Revolution Dynamix) 1 Badehose 1 Halstuch Essen Das hier ist fÃ¼r 2 Leute gedacht: 1 Camping-Kocher (Bleuet 206-Kartusche von Camping-Gaz gibt es wohl Ã¼berall): Haben wir in Calvi im \"Casino Drive\" gekauft. Kartusche und Kocher. 1 Feuerzeug / ZÃ¼ndhÃ¶lzer: Da muss man sich halt sicher sein, was man im Flugzeug mitnehmen darf. Aber ein gutes Feuerzeug sollte man schon mitnehmen. Insbesondere sollten die halt auch bei Wind ohne Probleme funktionieren. 2 tiefe Teller (Suppe!) 1 Kochtopf 1 Gabel, 1 Messer, 1 LÃ¶ffel Wasserreinigungstabletten (Micropur) Ich bin zuerst von 3500 Kalorien pro Tag (vgl. Energiebedarf ) ausgegangen. Aber schlussendlich haben wir 5 MÃ¼sliriegel, eine Suppe sowie ein Fertiggericht fÃ¼r jeden Tag eingeplant. Teebeutel Trinkflaschen fÃ¼r min. 2L Suppenpulver Nudeln Produkt Kalorien pro 100g Kalorien pro StÃ¼ck Macadamia-NÃ¼sse (Aldi) 762 kcal Paranusskerne (Aldi) 690 kcal Nussknacker Schokolade (Aldi) 585 kcal 585 kcal ja! weisse (Rewe) 565 kcal 565 kcal Alpenvollmich-Nuss (Rewe) 556 kcal 556 kcal Knuspy MÃ¼sli-Riegel 382 kcal 96 kcal Weiteres und andere Packlisten Ausweis / Reisepass Flugtickets Geld: \\((7 + 10) \\frac{\\text{Euro}}{\\text{Tag}} \\cdot 14\\text{ Tage} + 30\\text{ Euro} + 40\\text{ Euro (Gas)}= 308\\text{ Euro}\\) Wanderrucksack (Deuter Air Contact 55 + 10; ASIN B01CBOADW2) Taschenmesser Schlafen Zelt Schlafsack (Moorhead Micro Lite III 185: Extrem (-8 &#8451) Limit (+5 â„ƒ) Komfort (+9 â„ƒ)) Isomatte (Loftra Isomatte Thermomatte selbstaufblasend ultraleicht 183x51x3cm Explorer) Hygiene ZahnbÃ¼rste + Zahnpasta Kernseife Toilettenpapier Reisehandtuch PlastiktÃ¼ten fÃ¼r MÃ¼ll 4 WÃ¤scheklammern Elektronik Armbanduhr mit Alarm-Funktion Smartphone (Nexus 4) Powerbank (Anker PowerCore 20100mAh) Kamera (Panasonic Lumix DMC-TZ 41) Erste Hilfe (Blasenpflaster, TaschentÃ¼cher, Schmerztabletten, 1 : Tatonka Erste Hilfe First Aid Basic, ASIN B001QXDQOM) WanderfÃ¼hrer (nach Juni 2015 wegen Umleitung); Kartenmaterial Notizbuch + Stift Kartenspiel Taschenlampe (LED Lenser P7.2, ASIN B00F9ZH4O6) Stirnlampe Sonnencreme Nadel und Garn Gewebeband (Reperatur Tape 5m von Relags) Paracord (war super praktisch als WÃ¤scheleine und um den Camping-Kocher am Rucksack zu befestigen) Folgendes haben andere Packlisten beinhaltet, habe ich aber nicht mitnehmen: Kerzen GPS-GerÃ¤t: Die sind sowieso nur 16h lauffÃ¤hig und der Weg ist sehr gut markiert. Andere Packlisten: kaffeeersatz.com Solak'sche Checkliste Wikinger-Reisen Anfahrt und Abreise Optionen Abflugsort: Flughafen StraÃŸburg (SXB) - Ã¶ffnet erst ab 4 Uhr Flughafen Karlsruhe (FKB) Flughafen Stuttgart (STR) Optionen Ankunftsort: Nizza (NCE), Genua (GOA), Bastia (BIA), Ajaccio (AJA), Figari (FSC) Calvi (CLY) Man kann auch mit der FÃ¤hre Ã¼ber Nizza (NCE) / die Ile Rousse anreisen. Allerdings muss man hier darauf achten, dass es zeitlich funktioniert. Insbesondere sollte man berÃ¼cksichtigen, dass die FahrplÃ¤ne am Sonntag deutlich schlechter sind. Anreise (So, 25.09.2016) 96.60 Euro , exklusive Flug: 18:35 - 20:07: von Garmisch-Partenkirchen nach MÃ¼nchen ZOB (21.10 Euro) 21:00 - 02:15: mit Meinfernbus von MÃ¼nchen ZOB nach StraÃŸburg, Busbahnhof Place de l'Ã‰toile (39.50 Euro) (2.1 km / 26 min laufen) 02:45 - 04:45 StraÃŸburg Hbf, mit dem Pendelzug , 2.60 Euro p.P. / alternativ 40 Euro gesamt fÃ¼rs Taxi 05:05 Aeorport 06:15 - 07:45: SXB - AJA 15:23 - 19:42: Ajaccio - Camp Raffalli GR20 (Umsteigen in Ponte Leccia); 16.00 Euro p.P. (vgl. PlÃ¤ne ) 19:42 - 22:00: Camp Raffalli nach Calenzana laufen (2.1 km; TODO: Karte drucken) Siehe auch: kraxl.de Abreise (SO, 09.10.2016) Ich habe keine MÃ¶glichkeit gefunden von Conca nach Figari ohne Auto und Taxi zu kommen. Daher wird die Tour bei Vizzavona (Etappe 9 von 15) beendet. Wenn man gut im Plan ist kÃ¶nnte man auch Richtung Ajaccio wandern oder noch zur Refuge de Capannelle (Etappe 10) und wieder zurÃ¼ck. Oder an der Bahn-Strecke entlang. 32.60 Euro , exklusive Flug: Von Vizzavona nach Ajaccio mit dem Zug fahren (siehe Fahrplan Bastia - Ajaccio ). 12:45 - 14:20: AJA - SXB 15:23 - 15:31: SXB - StraÃŸburg Hbf mit dem Pendelzug fÃ¼r 2.60 Euro p.P. 15:46 - 16:25: StraÃŸburg Hbf - Karlsruhe fÃ¼r 30 Euro (ohne Zugbindung; ab 16:22 wÃ¤re es nur 18.60 Euro) Etappen Ich habe nur die ersten 10 Etappen gemacht. Tag Ort km Hm GZ Kommentare 0 Calenzana 1 Refuge Ortu di u Piobbu 11.0 km + 1360 m - 50 m 6.0 h 2 Refuge de Carrozzu 7.0 km + 750 m - 950 m 7.0 h Pass Col de la Pisciaghia liegt auf dem Weg 3 Haut Asco 7.0 km + 800 m - 650 m 5.5 h Cirque de Solitude ( Video ; Seit Juni 2015 wird der GR 20 am Fusse des Monte Cinto umgeleitet und verlÃ¤uft nicht mehr durch den Cirque de la Solitude.); Col de Perdu (2183m); Bocca Minuta (2218m) 4 Refuge de Tighjettu 10.0 km + 1150 m - 1200 m 8.5 h Pointe des Eboulis (2607 m) liegt auf dem Weg 5 Refuge Ciottulu di i Mori ? ? ? 6 Col de Vergio (Skistation) ? ? ? 7 Refuge de Manganu 14.5 km + 750 m - 570 m 6.0 h Pass Col St Pierre; See Lac de Nino; entlang des Flusses des Tavignano 8 Refuge de Petra Piana 9.0 km + 870 m, - 650 m 6.0 h Felsspalte BrÃ¨che de Capitello; Pass Col de la Haute Route 9 Refuge de l'Onda 7.0 km + 260 m, - 680 m 4.5 h Besteigung des Monte Rotondo; 10 Gare de Vizzavona 10.0 km + 710 m, - 1220 m 6.0 h Proviant auffÃ¼llen 11 Refuge de Capannelle 16.0 km + 860 m, - 190 m 5.5 h Pass Col de Palmente; 12 Col de Verde 12.0 km + 350 m - 580 m 4.0 h 13 Refuge d'Usciolu 15.0 km + 1250 m - 850 m 7.5 h â€žl'ArÃªte des Statues\" [Grat der Statuen] 14 Plateau Cuscione 13.0 km + 600 m - 820 m 5.0 h 15 Col de Bavella 15.0 km + 1110 m - 1310 m 8.5 h 16 Conca / Conza 18.0 km + 400 m - 1350 m 7.5 h Refuge de Paliri Details Am Anfang muss man eine Gaskartusche besorgen. CampingGaz: Stechkartuschen gibts Ã¼berall Ventilkartuschen in allen SupermÃ¤rkten Coleman, Markill etc Schraubkartuschen: Bastia: siehe Hawe, Calvi: beim Intersport am Ortsausgang von Calvi -> Strasse nach Porto /Bastia, Corte: im Bergsportladen auf der Hauptstrasse...inshallah... Wichtige SÃ¤tze Auf Korsika wird FranzÃ¶sisch gesprochen. Also: Wir wÃ¼rden hier gerne Zelten. : Nous aimerions camper ici. Wie viel kostet das? : Combien Ã§a coÃ»te? Wo ist die Wasserquelle? : Ou est la source? Wir brauchen hilfe. : Nous avons besoin d'aide. Links le-gr20.fr Abenteuer GR 20 http://parc-corse.org/ GR20 Weitwanderweg Korsika â€“ Grande RandonnÃ©e - ausfÃ¼hrlich corsica.forhikers.com/gr20 paradisu.de : Inclusive Packliste theglobetrotter.de : Packliste Verkehr: Ã–PNV auf Korsika Zug sncf.com Bus FÃ¤hren Google Flights WETTER Alternativ Wanderung zum Lac de Nino Monte Cinto - der KÃ¶nig der korsischen Berge : von Monte Cinto aus kann bei gutem wetter vom einen ende der insel zum anderen gucken marina-aleria.com : Campen; strand ist direkt am naturschutzgebiet.. der nÃ¤chste spar ist 1/1,5 km weg, und die leute da sind sehr nett","tags":"My bits and bytes","title":"Korsika GR 20"},{"url":"https://martin-thoma.com/new-year-2017/","text":"It's new years eve and - as always - I try to finish some things and have some plans for next year. Review of 2016 This year was pretty awesome. I went to a summer school in Greifswald where I got to know a lot of nice people. I participated in a wind surfing and in a sailing course. I hiked the GR 20 , finished my first via ferrata ( Alpspitz-Ferrata ), went to the Salewa-Klettersteig and the Tegelberg Klettersteig near FÃ¼ssen. In July, I got to know Bouldering and managed to finish the first Fb 6c - 7b routes. However, only routes up to 5c are always easy for me (see table with climbing grades and wiki article ). In December, I've got the chance to go to NIPS 2016 Here are some other mentionable facts: ML-KA is still active. I have 15 838 points on StackOverflow and reached 5.1 million people with my posts ( source ). I wrote 53 articles for this blog (including this one) in 2016. A couple of them might be interesting for a very specific audience ( SVMs , classifier comparison , machine learning glossary ). I've uploaded 835 files to Wikipedia Commons in 2016 ( source ). My uploads to Wikipedia Commons are about 3 GiB in total now. On commons, I made 4414 edits in total. Old year resolutions âœ” 05.02.2016: Sold my old vacuum cleaner âœ” 17.02.2016: Quit church âœ” 08.05.2016: Migrate Blog to Pelican âœ” 14.04.2016: Contact BSI, BKA, CCC and the car sellers and send them my paper in which I summarize current problems in car security. (Later, I found this . Coincidence?) âœ” 01.11.2016: I got rid of my old bed. âœ” 03.11.2016: I painted some walls in my appartment (not all, though). I failed to get all my stuff from my father to my place. However, most of it is here now. Also, I didn't find new slippers. Old year predictions Machine Learning and Technology Networks will get deeper. Currently about 8 layers is usual; I expect this to get to over 30 layers. Deep Residual Learning for Image Recognition has networks with over 1000 layers. âœ” First hacks / funny results by people abusing the fact that machine learning is used will appear. Twitter taught Microsoft's AI chatbot to be a racist asshole in less than a day , /r/howhot âœ” Machines will generate \"high\" resolution images of at least 256 Ã— 256 pixels. StackGANs generate 256 px Ã— 256 px images âœ” Speech synthesis will fastly improve. To benchmark this, I will use the original quotation that explained the importance of towels is found in Chapter 3 of Adams' work The Hitchhiker's Guide to the Galaxy. See Towel Day , Google Translate Recording , Festival Recording âœ— ALPHABET INC. (C) (GOOGLE) shares at Frankfurt Stock Exchange will go up to about 900 Euro sometime in the year (currently, it is at 690 Euro). âœ— It only went up to 760 Euro. Solar Roadways will make some tiny advances. âœ— Very, very, tiny updates. About Me One of my papers will get cited at least 5 times. âœ— I will spend at least 2 weeks abroad. Done : My trip to Corsica was a bit longer than 2 weeks. Then 10 days in Barcelona. I will publish at leat 40 articles on my blog. Done : 53 articles. I will get a 90 days streak on GitHub (currently, my longest is 43 days). Failed I will get 15 000 points on StackExchange (see StackExchange profile ) âœ” Politics The European Union will still exist and Britain will still be part of it (see Brexit ). Correct (Yes, they voted for Brexit. But currently they are still part of the EU. And I doubt they will really quit the EU.) Donald Trump will be the republican candidate and Hillary Clinton the democrat candidate. I was right about this. The republican candidate will get president. Correct More mass shootings in the US and terrorist attacks all over the world will happen. Correct GrÃ¼ne and SPD will still be in Baden-WÃ¼rttemberg (see Landtagswahl in Baden-WÃ¼rttemberg 2016 ). False : GrÃ¼ne and CDU. New year resolutions The plans for my new year are: [ ] Get all my stuff from my fathers apartment to my room. I've already packed most of it in boxes (In total: 1.00m (+0.30m?) Ã— 0.39m Ã— 0.60m by 4 boxes) [ ] Get new slippers [ ] Finish my masters degree [ ] Participate in a Flashmob [ ] Get comfortable with Orange Bouldering routes (5c-6c) and finish at least 5 harder ones (6c - 7b) [ ] Visit a country I haven't been to before. Finishing things I always do some cleanup before the new year begins. This means especially cleaning my computer stuff of unnecessary trash. âœ” Deleting several hundret E-mails. âœ” Clean up my smartphones TODO list. [ ] Clean up my notes. [ ] Clean up my Desktop / Download folder. [ ] Make Backup of Facebook ( tutorial ), Google+ and Gmail ( takeout ), Twitter ( tutorial ), WhatsApp ( tutorial ), Amazon, Banking. âœ” Push git stuff Predictions for 2017 Machine Learning and Technology Networks will not get deeper (currently: about 600 layers, max 2000 layers), but work about how to get the same accuracy with less parameters / FLOPs will be written. GANs will be able to create 1024px x 1024px images. An AI will play Star Craft and at least one nice video of it will be online. About Me I will publish at least two papers (one will be my masters thesis) I will finish my masters degree. I will publish at least 40 articles on my blog. I will get at least 20 000 points on StackOverflow (see StackExchange profile ) Politics The European Union will still exist and Britain will still be part of it, although somebody will be going in front of curt because of it (see Brexit ). German elections: 35% for CDU/CSU, 18% for SPD, 15% for AfD, 9% for GrÃ¼ne, 9% Linke. Trump will not build a complete wall to Mexico. See also New Year 2016","tags":"Cyberculture","title":"New Year 2017"},{"url":"https://martin-thoma.com/alpspitze-via-ferrata/","text":"The Alpspitze (not to confuse with Alpspitz ) is a mountain in the alps with one of the simplest via ferratas . It was my first one, too. I documented what you need for it so that you can easily hike / climb the same route. I planned the route as a 2-day route. One day to get to the starting point, the second day to take the route. Equipment I'll put the German word in brackets, as I'm not totally sure about the best translation. Climbing helmet (Steinschlaghelm): The more expensive ones are more lightweight. Everything with EN 12492 should be good. 30 - 80 Euro (\"Edelrid Zodiac\" was 55 Euro and weights 359 g) Sit harness (Klettergurt): The more expensive ones are more lightweight / more comfortable. (\"Ocun: Twist Basic XS - M\" was 55 Euro) Ferrata set (\"Elliot: Forril Tech Klettersteigset mit BandfalldÃ¤mpfer\" was 65 Euro) Carabiner (\"Mammut: HMS Bionic Twistlock Plus basalt\" was 19 Euro) Webbing loop (\"Elliot Bandschlinge 60cm\" was 3 Euro) Travel Sheet (HÃ¼ttenschlafsack) Headlamp (\"Moorhead Stirnlampe\", about 15 Euro) Cycling gloves Map I like the following cloths for hiking. They are comfortable in a wide range of temperatures and they don't stink that much / feel bad when you sweat: VAUDE Herren Hose Farley Stretch Pants II (ASIN B01HL94DU0) Icebreaker Herren T-Shirt Tech Lite Short Sleeve (ASIN B00L6EHH4Q) Odlo Herren Pullover Midlayer 1/2 Zip Sun Peaks (ASIN B00DG1BOK0) FALKE Herren Trekking Socken TK2 Short Coool (ASIN B001E11Y1I) Icebreaker Herren Unterhose Anatomica (ASIN B016D9ZS9Y) Don't forget that it will be much colder up there than on the ground. Other things you need / might want to take with you: Food (e.g. an apple, sausages and several cereal bars) At least 1 L of water (can be refilled at the house) Toothbrush and toothpaste Money (25 Euro for sleeping at Kreuzeckhaus, 60 Euro for food and miscallenious stuff, 32 Euro for the cable car) Medicine and hygiene stuff (For example, I always want to have tissues and dental floss with me) Camera Smartphone and loading cable / power bank Route Day 1 (Friday, 23.09.2016) 06:01 - 08:25: From Karlsruhe to Reutlingen Hbf via train 08:30 - 12:00: From Reutlingen to Garmisch-Partenkirchen (station Kreuzeck/Alpspitzbahn) via car 12:00: We hike to Kreuzeckhaus Day 2 (Saturday, 24.09.2016) 07:30: Start from Kreuzeckhaus ( description ) 12:30: Osterfelderkopf (3 km from Kreuzeckhaus and 350 m height; at 2033 m) 15:00: Alpspitz-Gipfel (at 2628 m) Going down again over the Ostgrat, down to the Oberkar Nordwandsteig 17:00: back to Osterfelderkopf with cable car down to the valley Going back to Karlsruhe See also Alpspitz Ferrata - Alpspitze Klettersteig Alpspitz-Ferrata alpspitze.org hoehenrausch.de How to use a ferrata set (German)","tags":"My bits and bytes","title":"Alpspitze via ferrata"},{"url":"https://martin-thoma.com/reinforcement-learning/","text":"Reinforcement learning is a sub-field of mathematics and computer science. It deals with the following kind of problems: You're given a set of states \\(\\mathcal{X} \\subseteq \\mathbb{R}&#94;n\\) and a starting state \\(x_0 \\in \\mathcal{X}\\) . For every time step \\(k = 0, 1, 2, \\dots\\) you have a set of possible actions, depending on your current state: $$\\mathcal{A}_k(x_k)$$ Depending on what your action and your current state is, the new state is $$P(x_k, a_k, x_{k+1}) \\in [0, 1]$$ So the transition from state \\(x_k\\) to state \\(x_{k+1}\\) with action \\(a_k\\) is stochastic. For some states \\(x_k\\) , actions \\(a_k\\) at time \\(k\\) , you receive rewards: $$r_k(x_k, a_k) \\in \\mathbb{R}$$ Your goal is to maximize $$\\mathbb{E}(\\sum_{k=0}&#94;\\infty \\gamma&#94;k \\cdot r_k(x_k, a_k))$$ where \\(\\gamma in (0, 1)\\) is a discounting factor which makes sure we don't get infinite rewards. \\(\\gamma = 0.99\\) is a typical choice. Applications This very general problem description can be applied in almost any scenario: Learning automatically to play games Learning to control robots Why RL is difficult Credit assignment: In chess, you only get a reward (positiv or negative) at the end of the game. How to you tell which move was good or bad? Exploration vs. exploitation : When should you stick to what you know and when should you try something new? State equivalence: Typically, your state is very high-dimensional. For example when learning very old computer games from raw pixels you have $$210 \\cdot 160 \\cdot 3 = 100800$$ dimensions in your feature vector. But the relevant game states might be much less. Approaches A policy network gets the state as input and outputs the action. It learns by executing many episodes (e.g. a complete game; from start until you reach a final state or at least a state with reward) and labels all actions before with the received reward. There might be many which were good even in a lost game, but in average you expect to punish bad decisions and encourage good decisions. Resources If you are a student at KIT, I can recommend to visit the lecture Probabilistic Planning . Other resources you might want to have a look at: Deep Reinforcement Learning: Pong from Pixels Pong example Guest Post (Part I): Demystifying Deep Reinforcement Learning Human-level control through deep reinforcement learning by V. Mnih et al. Playing Atari with Deep Reinforcement Learning on arXiv Deterministic Policy Gradient Algorithms","tags":"Machine Learning","title":"Reinforcement Learning"},{"url":"https://martin-thoma.com/word-vectors/","text":"The idea behind word vectors is to represent natural language words like \"king\" in \\(\\mathbb{R}&#94;n\\) in such a way, that you can do arithmetic. For example, $$\\text{vec}(\\text{king}) - \\text{vec}(\\text{man}) + \\text{vec}(\\text{woman}) \\approx \\text{vec}(\\text{queen})$$ The Python library gensim implements this. Requirements pip install gensim --user pip install nltk --user Example An easy to use example is from gensim.models import Word2Vec from nltk.corpus import brown model = Word2Vec ( brown . sents ()) model . most_similar ( positive = [ 'woman' , 'king' ], negative = [ 'man' ], topn = 3 ) which returns [(u'scored', 0.9442702531814575), (u'calling', 0.9424217939376831), (u'native', 0.9412217736244202)] So the corpus is not that good, but it should work with a bigger one. See also The amazing power of word vectors Deep learning with word2vec and gensim","tags":"Code","title":"Word Vectors"},{"url":"https://martin-thoma.com/ml-review-2/","text":"This Review gives an overview of intersting stuff I stumbled over which are related to machine learning. Most of it was posted in KITs machine learning group (on Facebook). A lot of stuff can be found in my article about NIPS 2016 . New Developments Random forests for courier detection: Has a rampaging AI algorithm called Skynet really killed thousands in Pakistan? Live Demos and Websites Quickdraw Quickdraw is a program which tries to guess what you drew. However, it is difficult to check if they really apply machine learning, because it tells you what to draw and then tries to recognize it. I had to draw a piano, a floor lamp, a chandelier, a suitcase, a candle and a lipstick each in under 20 seconds. It looks very much like an attempt to get lots of training data. However, this plan might not work that well: Interesting Quickdraw Fails You might find more stuff like Quickdraw on aiexperiments.withgoogle.com . Loss Functions lossfunctions.tumblr.com is a blog created by Andrej Karpathy where he collects - well, let's call them \"interesting\" - loss functions. Eyescream Have you heard about GANs ? Eyescream is a demo for the generator. Publications Deep Neural Networks are Easily Fooled The input of CNNs for image classification can be manipulated in two ways: An image, on which a human does not recognize anything (e.g. white noise) gets a high score for some object class. An image on which a human is certain to recognize one class (e.g. \"cat\") is manipulated in a way that the CNN classifies with high certainty something different (e.g. \"factory\"). See also: Anh Nguyen, Jason Yosinski, Jeff Clune: Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images on arxiv. Evolving AI Lab: Deep Neural Networks are Easily Fooled on YouTube in 5:33 min. Google: Inceptionism: Going Deeper into Neural Networks . 17.06.2016. Breaking Linear Classifiers on ImageNet Andrej Karpathy has once again written a nice article. The article describes the problem that linear classifiers can be broken easily . Hinton commented something simmilar on Reddit . Where am I? Google Unveils Neural Network with \"Superhuman\" Ability to Determine the Location of Almost Any Image One gives the neural network a photo and it tells you where it was taken. LIME \"Why Should I Trust You?\": Explaining the Predictions of Any Classifier deals with the problem of analyzing black box models decision making process. Lip Reading See the paper LipNet: Sentence-Level Lipreading for details. More Learning to Protect Communications with Adversarial Neural Cryptography 2016 Report : One Hundred Year Study on Artificial Intelligence (AI100) Software Seaborn Example plot generated by Seaborn Seaborn is a Python package for the visualization of data and statistics. See stanford.edu/~mwaskom/software/seaborn . RecNet JÃ¶rg made recnet publicly available. It is a framework based on Theano to simplify the creation of recurrent networks. Image Segmentation Using DIGITS 5 I didn't try it by now, but the images in the article Image Segmentation Using DIGITS 5 look awesome. I would be happy to hear what you think about it. Keras.js Run Keras models (trained using Tensorflow backend) in your browser, with GPU support. Models are created directly from the Keras JSON-format configuration file, using weights serialized directly from the corresponding HDF5 file. See github.com/transcranial/keras-js for more. Interesting Questions When being in a perfect \"Long Valley\" situation, does momentum help? Are non-zero paddings used? Why do CNNs with ReLU learn that well? Is there a metric for the similarity of two image filters? Miscallenious Eugenio Culurciello's blog: Neural Network Architectures Aaditya Prakash's blog: One by One [ 1 x 1 ] Convolution - counter-intuitively useful Adit Deshpande's blog: The 9 Deep Learning Papers You Need To Know About (Understanding CNNs Part 3) Artificial-intelligence system surfs web to improve its performance ( paper ) The 9 Deep Learning Papers you need to know about : Explains AlexNet, ZDNet, ResNets, (Fast(er)) RCNNs, GANs The Neural Network Zoo Selective Search : Creating region proposals for object detection GANs Adverserial Examples Google Projector : Display high-dimensional data Andrej Karpathy: Yes you should understand backprop OpenNMT : A machine translation system Pete Warden's blog: Why GEMM is at the heart of deep learning StackExchange Dataset Meetings London, 4. December 2016: Data Visualization Challenge Barcelona, 5. December 2016 - 10. December 2016: Neural Information Processing Systems (NIPS) ( Link ) Â« Previous Review Next Review Â»","tags":"Machine Learning","title":"ML Review 2"},{"url":"https://martin-thoma.com/nips-2016/","text":"The Conference and Workshop on Neural Information Processing Systems (NIPS) is probably the biggest conference with machine learning / deep learning as a main topic. This year, about 6000 people attended it. My friend Marvin and me were supported by Begabtenstiftung Informatik Karlsruhe . The complete program can be found in the Conference Book , but I would like to point out some of my highlights. Hot Topics To get an idea what NIPS 2016 was about, I generated a word cloud from the titles of the accepted papers: The organization team made something similar, but they had access to the information how the papers were tagged: (Image source: www.tml.cs.uni-tuebingen.de ) The top 10 topics were: 01: Deep Learning or Neural Networks 42: (Application) Computer Vision 02: Large Scale Learning and Big Data 05: Learning Theory 53: (Other) Optimization 08: Sparsity and Feature Selection 51: (Other) Classification 03: Convex Optimization 54: (Other) Probabilistic Models and Methods 56: (Other) Unsupervised Learning Methods I would say the top five hot topics (first is hottest) are: GANs Reinforcment Learning: Look for \"bandit\" in the paper titles unsupervised learning alternative ways to train DNNs reducing the need for data (transfer learning, domain adaptation, semi-supervised learning) GANs Generative Adverserial Networks (short: GANs) were one hot topic at NIPS. The idea is to train two networks: A generator \\(G\\) and a discriminator \\(D\\) . The generator creates content (e.g. images) and the discriminator has to decide if the content is of the natural distribution (the training set) or made by the generator. An introduction can be found at blog.evjang.com Noteworthy papers and ideas are: Learning What and Where to Draw InfoGAN : Get more control about properties of the generated content. How to Train a GAN? Tips and tricks to make GANs work Generative Visual Manipulation on the Natural Image Manifold : Allow interactive generation of images (see also: Reddit ) Applications of GANs are (according to Eric Jang ): reinforcement learning: paper domain adaptation security ML compression Bayesian Deep Learning Combinding deep learning with graphical models like CRFs / Markov Random Fields has been done for semantic segmentation for a while now. It seems like the combination of those two is called \"bayesian deep learning\". If you look for the keyword \"variational\" it seems to belong in this category. I don't really know this area, so I leav it to Eric Jang to point out important papers. Nut's and Bolts of ML Andrew Ng gave a talk in which he summarized what he thinks are some of the most important topics when training machine learning systems. Most of it is probably also in his book Machine Learning Yearning or in his Coursera course . Here are some of the things he talked about: When you design a speech recognition system, you can measure 3 types of errors: Human error, training set error and test set error. The difference between the human error and the training error is \"avoidable error\" (bias), the difference between training and test error is \"variance\". Human level performance is ambiguous: In a medical application, is an amateur, a doctor, an experienced doctor or a team of (experienced) doctors the \"human level performance\"? Role of an \"AI Product Manager\" More Papers Clustering: Fast and Provably Good Seedings for k-Means Optimization: MetaGrad: Multiple Learning Rates in Online Learning https://bitbucket.org/wmkoolen/metagrad Optimal Learning for Multi-pass Stochastic Gradient Methods Layer Normalization : An successor for Batch Normalization? Theory: Deep Learning without Poor Local Minima : Local Minima are global minima in \"typical\" networks Matrix Completion has No Spurious Local Minimum Understanding the Effective Receptive Field in Deep Convolutional Neural Networks Topology learning: Learning the Number of Neurons in Deep Networks From another talk. Most add nodes / edges over time from an initial seed network: 1960, ErdÃ¶s & Renyi: Random graphs 1998, Watts & Strogatz: Small-world graph 1999, Barabasi & Albert: Preferential attachment 1999, Kleinburg et al.: Copying model 2003, Vazquez et al.: Duplication-divergence 2007, Leskovec et al.: Forest fire 2008, Clauset et al.: Hierarchical random graphs 2010, Leskovec et al.: Kronecker graphs Network compression Dynamic Network Surgery for Efficient DNNs PerforatedCNNs: Acceleration through Elimination of Redundant Convolutions Swapout: Learning an ensemble of deep architectures Analysis of ML models: Blind Attacks on Machine Learners Measuring Neural Net Robustness with Constraints : Measure robustnes against adverserial examples Robustness of classifiers: from adversarial to random noise Unsupervised Risk Estimation Using Only Conditional Independence Structure Blind Attacks on Machine Learners Examples are not Enough, Learn to Criticize! Criticism for Interpretability ( github ) Identifying Unknown Unknowns in the Open World: Representations and Policies for Guided Exploration Content creation: Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks Labeling: Active Learning from Imperfect Labelers Fundamental Limits of Budget-Fidelity Trade-off in Label Crowdsourcing Avoiding Imposters and Delinquents: Adversarial Crowdsourcing and Peer Prediction Content based Image Retrival (CBIR): Improved Deep Metric Learning with Multi-class N-pair Loss Objective Learning Deep Embeddings with Histogram Loss Local Similarity-Aware Deep Feature Embedding CliqueCNN: Deep Unsupervised Exemplar Learning What Makes Objects Similar: A Unified Multi-Metric Learning Approach Misc: Learnable Visual Markers : Visual markers are something like barcodes Neurally-Guided Procedural Models: Amortized Inference for Procedural Graphics Programs using Neural Networks Universal Correspondence Network : Find semantically meaningful similar points in two images. For example, to frontal images of different humans, where the network finds eyes, nose, chin, lips in both images. Scene Recognition Demo TorontoCity: Seeing the World with a Million Eyes : A new benchmark dataset by Raquel Urtasun What makes ImageNet good for Transfer Learning? by Jacob Huh (UC Berkeley), Pulkit Agrawal (UC Berkeley), and Alexei Efros (UC Berkeley) Lessons learned for conferences Bring a camera: The information comes very fast. Too fast to take notes, but you can shoot a photo of the slides. In fact, quite a lot of people do so. Shoot a photo of the first slide, so that you know what the talk was about when you look at your slides. If you give a talk / poster... ... let the first slide be there long enough, so that people can take a photo of it. ... or have a URL / the title of the paper on every single slide ... let every slide be visible long enough, so that people can take photos ... don't use QR-codes only, but also (shortened) URLs ... make it available online as PDF ... answer key questions: (1) Which problem did you tackle? (2) How did you test your results? (3) To what is your \"solution\" similar? As a session organizer... ... make sure there is a schedule at the door (outside) ... make sure the schedule is online ... make sure the schedule is changed everywhere, if it is actually changed Miscallenious Advances in Neural Information Processing Systems 29 (NIPS 2016) pre-proceedings Jobs unify.id bluevisionlabs.com NIPS Papers Kaggle Dataset blog.aylien.com: Highlights of NIPS 2016: Adversarial Learning, Meta-learning and more salon-des-refuses.org should contain papers which were refused, but are also of high quality. However, the website seems to be down. Martin Zinkevich: Rules of Machine Learning: Best Practices for ML Engineering Implementations for NIPS 2016 papers YouTube: GAN Workshop playlist Yann Le Cun Energy-based GANs & other adverserial training","tags":"Machine Learning","title":"NIPS 2016"},{"url":"https://martin-thoma.com/fake-news/","text":"The US election of 2016 in which Trump became president of the united states shed a light on fake news. Those are stories written similar in style to real news, but with faked content. One example of fake news is that Pope Francis supports Trump as a candidate. [ Koe03 ] Another example is that Denzel Washington supports Trump. [ Bum16 ] So fake news is used to manipulate people. They can be completely imaginary, but they might get shared millions of times. And they might have had a significant influence in the last US election. Now people are demanding from Facebook to \"do something\" against the spread of Fake news. Facebook is giving users the possibility to report fake news. If enough people reported a link as fake news, a human reviewer fact-checks it. If the reviewer decides it is fake, then users get warned before they view such content. [ Ohl16 ] However, this approach has many problems: Speed: Facebook might have problems to identify fake news before it gets viral Quality: What if the reviewers make mistakes? Power: Do we want to rely on Facebook for this? I argue that fake news is just a symptom of an underlying problem which isn't addressed by anybody so far: News organizations don't give checkable sources and we don't demand it. What we should do Be skeptical. Ask for sources. Ask: \"Why should I trust you?\" The Author The first and most important part is probably the author of an article. If an article does not have an author, it is probably fake. Even if there is a name, it might be imaginary. So we need a way to validate it. One way to do that is the following procedure: Author pages : Authors should have webpages. This does not necessarily mean they host it; there are plenty of services where you can put stuff about yourself online. For researchers, there is ORCiD , for journalists LinkedIn might be a reasonable choice. Links to author pages : The name of the author in a news article should link to the author page. Backlinks : The author page has to contain a link to every single article. Microformats : This is a technical bit. Microformats like hnews allow semantic tagging of content. This means we can write programs to extract meaning from webpages. For example, it is possible to tag which part of the page contains the name of the author. Or to make clear to simple programs that the page is a news page. This kind of semantic tagging makes it possible to automatically check if the minimal quality / trust criteria are met. How does this help? Well, first of all you would know not only one article of the author, but all articles of the author. Second, the author wants to make himself as trustworthy as possible. In networks like LinkedIn, this might be possible by having endorsements or connections which seem trustworthy. Demand Sources and Details This one is for the \"reputable\" news organizations. Most newspapers barely give any references / sources for statements in their articles. As an example, I had a look at the first article of the Washington post ( The oil and gas industry is quickly amassing power in Trump's Washington ). Lets see which claims they make for which I would expect a source: After eight years of being banished and sometimes vilified by the Obama administration ExxonMobil chief executive Rex Tillerson is Trump's nominee to be secretary of state \"It feels like the grizzly bear in â€˜The Revenant' has been suddenly pulled off our chest,\" said Luke Popovich George H.W. Bush, who co-founded and ran Zapata Oil \"I think there's a level to which the puppeteers have become the actors, a change unprecedented in its breadth,\" said Dan Becker Those are only the first few where I think sources should be added. It is not enough to say \"said Luke Popovich\". In this case I'm not sure if they spoke themselves with Luke Popovich (then I'd expect a note that he was interviewed by one of the authors) or if it was a public statement. Also: When exactly did he say so? In this case it might not be too important, but there might be many where it is. Demanding sources as well as details like when a statement was made by whom and how or in which context is crucial. By the way, we should not only ask for sources when journalists or newspapers make statements. Also when politicians do so. Just like Trevor Noah suggest to adapt to Donald Trump's Lies . Build a Journalists Network Currently, it is harder than necessary to check the reputation of a journalist. I suggest we should built a web service which allows journalists and news organizations to create public profiles. News organizations can say who they currently trust and journalists can do so as well. Probably only for certain topics such as computer science , middle east , economy ... Every journalist can add articles to their profile. The articles have to contain a link to the same page to make sure they don't claim credit for something they don't deserve it for. Every news article has its own page. The page allows comments / clarifications to be made as well as adding links to related articles. Everybody can register, endorse journalists / articles and add friends. By this network, a trust score is calculated. For example, PageRank or Matrix completion algorithms could be used to complete the trustworthiness which you didn't directly assign. Relation to Fake News You might wonder how this is related to fake news. Well, imagine if journalists would add their sources to every statement. Imagine you could check an authors reputation as easy as I described it. Do you really think it would be that simple to create blatantly fake news as we have it nowadays? No. We would look at it, miss the sources and close the news. Probably within seconds. See also What I described in this article is a long-term solution for the problem of lies and propaganda. More immediate responses are described in We built a Twitter bot that replies to people who share fake news : Bullshit detector : A Chrome extension that warns users about unreliable news Fake News Monitor : A Chrome extension which gives websites a score for trustworthiness Sources [ Evo16 ] Dan Evon. Nope Francis. Snopes.com, 24.07.2016. ( Source ) [ Bum16 ] Philip Bump. Denzel Washington endorsed Trump, according to AmericaNews, Breitbartt, USANewsHome â€” and Facebook. Washington Post, 14.11.2016. ( Source ) [ Ohl16 ] Abby Ohlheiser. Mark Zuckerberg outlines Facebook's ideas to battle fake news. Washington Post, 19.11.2016. ( Source )","tags":"Cyberculture","title":"Fake News: It's a symptom, not the problem"},{"url":"https://martin-thoma.com/url-regex/","text":"A very short thing to share, but likely valuable: An RegEx for URLs. In search of the perfect URL validation regex has several positive and negative examples for URLs as well as several regular expressions to test against those test cases. The only one which matched all correctly is by diegoperini and has 502 characters: _&#94;(?:(?:https?|ftp)://)(?:\\S+(?::\\S*)?@)?(?:(?!10(?:\\.\\d{1,3}){3})(?!127(?:\\.\\d{1,3}){3})(?!169\\.254(?:\\.\\d{1,3}){2})(?!192\\.168(?:\\.\\d{1,3}){2})(?!172\\.(?:1[6-9]|2\\d|3[0-1])(?:\\.\\d{1,3}){2})(?:[1-9]\\d?|1\\d\\d|2[01]\\d|22[0-3])(?:\\.(?:1?\\d{1,2}|2[0-4]\\d|25[0-5])){2}(?:\\.(?:[1-9]\\d?|1\\d\\d|2[0-4]\\d|25[0-4]))|(?:(?:[a-z\\x{00a1}-\\x{ffff}0-9]+-?)*[a-z\\x{00a1}-\\x{ffff}0-9]+)(?:\\.(?:[a-z\\x{00a1}-\\x{ffff}0-9]+-?)*[a-z\\x{00a1}-\\x{ffff}0-9]+)*(?:\\.(?:[a-z\\x{00a1}-\\x{ffff}]{2,})))(?::\\d{2,5})?(?:/[&#94;\\s]*)?$_iuS","tags":"Code","title":"URL RegEx"},{"url":"https://martin-thoma.com/ml-review-1/","text":"This Review gives an overview of intersting stuff I stumbled over which are related to machine learning. Most of it was posted in KITs machine learning group (on Facebook). New Developments Random forests for courier detection: Has a rampaging AI algorithm called Skynet really killed thousands in Pakistan? Live Demos and Websites Quickdraw Quickdraw is a program which tries to guess what you drew. However, it is difficult to check if they really apply machine learning, because it tells you what to draw and then tries to recognize it. I had to draw a piano, a floor lamp, a chandelier, a suitcase, a candle and a lipstick each in under 20 seconds. It looks very much like an attempt to get lots of training data. However, this plan might not work that well: Interesting Quickdraw Fails You might find more stuff like Quickdraw on aiexperiments.withgoogle.com . Loss Functions lossfunctions.tumblr.com is a blog created by Andrej Karpathy where he collects - well, let's call them \"interesting\" - loss functions. Publications Deep Neural Networks are Easily Fooled The input of CNNs for image classification can be manipulated in two ways: An image, on which a human does not recognize anything (e.g. white noise) gets a high score for some object class. An image on which a human is certain to recognize one class (e.g. \"cat\") is manipulated in a way that the CNN classifies with high certainty something different (e.g. \"factory\"). See also: Anh Nguyen, Jason Yosinski, Jeff Clune: Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images on arxiv. Evolving AI Lab: Deep Neural Networks are Easily Fooled on YouTube in 5:33 min. Google: Inceptionism: Going Deeper into Neural Networks . 17.06.2016. Breaking Linear Classifiers on ImageNet Andrej Karpathy has once again written a nice article. The article describes the problem that linear classifiers can be broken easily . Hinton commented something simmilar on Reddit . Where am I? Google Unveils Neural Network with \"Superhuman\" Ability to Determine the Location of Almost Any Image One gives the neural network a photo and it tells you where it was taken. LIME \"Why Should I Trust You?\": Explaining the Predictions of Any Classifier deals with the problem of analyzing black box models decision making process. Lip Reading See the paper LipNet: Sentence-Level Lipreading for details. More Learning to Protect Communications with Adversarial Neural Cryptography 2016 Report : One Hundred Year Study on Artificial Intelligence (AI100) Software Seaborn Example plot generated by Seaborn Seaborn is a Python package for the visualization of data and statistics. See stanford.edu/~mwaskom/software/seaborn . RecNet JÃ¶rg made recnet publicly available. It is a framework based on Theano to simplify the creation of recurrent networks. Image Segmentation Using DIGITS 5 I didn't try it by now, but the images in the article Image Segmentation Using DIGITS 5 look awesome. I would be happy to hear what you think about it. Keras.js Run Keras models (trained using Tensorflow backend) in your browser, with GPU support. Models are created directly from the Keras JSON-format configuration file, using weights serialized directly from the corresponding HDF5 file. See github.com/transcranial/keras-js for more. Interesting Questions When being in a perfect \"Long Valley\" situation, does momentum help? Are non-zero paddings used? Why do CNNs with ReLU learn that well? Is there a metric for the similarity of two image filters? Miscallenious Why robots, not trade, are behind so many factory job losses halite.io : A website for ML challenges. Google DeepMind's next gaming challenge: can AI beat StarCraft II? (and the post on deepnet ) All it takes to steal your face is a special pair of glasses - and the paper Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition When A Machine Learning Algorithm Studied Fine Art Paintings, It Saw Things Art Historians Had Never Noticed Image Synthesis from Yahoo's open_nsfw Cops have a database of 117M faces. You're probably in it Ants Challenge - Part I : identify and track individual ants over time; recognize when ants engage in food transfer Five years of observations from tandem satellites produce 3D world map of unprecedented accuracy Stealing Machine Learning Models via Prediction APIs DeepMind's AI has learned to navigate the Tube using memory Meetings London, 7. April 2016: Deep Learning in Healthcare Summit ( Link ) Next Review Â»","tags":"Machine Learning","title":"ML Review 1"},{"url":"https://martin-thoma.com/colors-in-latex/","text":"LaTeX knows the following colors without any packages: black blue brown cyan darkgray gray green lime magenta olive orange pink purple red teal violet white yellow If you want other colors, you can define them with \\usepackage{xcolor} and \\definecolor{name}{model}{color-spec} where: name is the name of the color you want to define, model is the color space (gray, rgb, RGB, HTML, cmyk) color-spec is the definition of the color in the chosen model For example: \\definecolor{orange}{HTML}{FF7F00} \\definecolor{orange}{rgb}{1,0.5,0} \\definecolor{orange}{RGB}{255,127,0} \\definecolor{orange}{cmyk}{0,0.5,1,0} You can find suitable colors with a color picker See also Wikibooks: LaTeX/Colors","tags":"Cyberculture","title":"Colors in LaTeX"},{"url":"https://martin-thoma.com/why-trump-might-be-good/","text":"After Trump became elected president of the United States, a lot of people began writing as if the world is going to end. While I also fear many bad things that might happen, here are some things that might be good: Some people got a lot of money from bets ( source ). Trump things drone attacks are too expensive (about $320 000 according to this source ). However, he also wants to bomb the shit out of terrorists ( source ). Trump is against TTIP. Trump wants to have good relationships to Russia. It might be easier for us to get what we want from the US. Just compliment Trump ( source ) The brick industry is going to go through the roof! ( source ) House of Cards can finally get that Emmy in the \"documentary\" category Alec Baldwin can become a full-time Trump impersonator I have a question with over 10 000 views on politics.SE ( source ) Speaches are easier to understand due to the simple vocabulary. We will get more funny videos like this one . The \"Deutsche Bank\" will be stronger ( source )","tags":"Cyberculture","title":"Why Trump might be Good"},{"url":"https://martin-thoma.com/lectures-on-youtube/","text":"I was just (rhetorically) asked by a lecturer You don't really prefer YouTube over lectures, do you? The plain and simple answer is: Yes. I do like watching lectures on YouTube more than attending them. Let me elaborate on this. Side note: When I write YouTube in the following, I'm not limiting the statements on this particular platform. I mean any professional video streaming website. A very good alternative is Vimeo, for example. Reasons for providing online lectures Schedules Lectures are typically only offered every second semester. For me, most interesting lectures are in the winter semester. This means I have a lot of overlapping lectures. And never forget that there are some days when you're ill. If a lecture is on YouTube, you can simply watch it whenever you have time. Rate of Words People speak very slow. You are able to listen to at least double the speed in which they are able to talk. Even faster, if they need to write at the same time. On YouTube, you can play any video in double speed. Just try it yourself: For 15 lectures of 1.5 hours each, this means I waste over 11 hours. Volume For some lectures, the lecturer is much too loud for me. It is hard to focus on new concepts if you're thinking about just going to the back of the room. At the same time, some lecturers could speak up a bit. This really depends on where you sit. Of course, depending on the lecturer, the room and your ears you could choose your seat. However, you usually also need to see the blackboard. So in case your eyes are not so good either, this might not be so easy. On YouTube, you just turn the volume up or down to your personal preference. Rate of Progress per day Although people speak slow, some lecturers make progress very fast. For some statements, you need time to think about it. Although I could hear the statement much faster, after it was said I need a pause to process it. It is impossible to get those pauses right if more than a single student is in the room. Everybody has different previous knowledge. And even if two students had exactly the same lectures before, one might have an easier time understanding a new concept than another. On YouTube, you can simply pause the video. In lectures, you have to repeat it afterwards or simply ignore the fact that you didn't completely understand it. Rate of Progress per semester If I'm really interested in something, I can spend a lot of time with that topic. It doesn't feel natural to me to stop, just because 1.5 hours are over. Availability Lectures are about three months, then you have an exam. For most students and lectures, that's it. They will never come back to most things they've learned. However, sometimes you need something you know you had in a lecture. If it was a lecture which is available on YouTube, you can simply search for it. In case the lecture has a good book or you have lecture notes, this might also work with \"live lectures\". However, usually people tend to say things in a very different way than how they would write it. Sometimes it just happens that you know that you understood a concept, but you need a refresher on it. This might work much faster if it is available via YouTube. Distractions Lectures are typically in lecture rooms. A lot of people are there. Some are playing on their smartphones, some come late, others bounce their legs. The other students are just distracting. They are not necessary at this point . Also, there are internal distractions: I might be hungry or sleepy. I can't just take a 5 minute nap in the lecture. I also feel like I shouldn't just eat in the lecture as it might distract fellow students. In contrast, when I watch lectures from udacity or coursera , I'm in a place where I can fully concentrate. If I need a break to sleep, eat or think about something else, I can do so. Correctness It is not possible to get everything always right. Lecturers will sometimes say things in a wrong way or in a way which is misleading. If the lectures are split up into small pieces, they can re-make the part which was wrong. Or at least put a text overlay there to mention the mistake. As many students over the years will listen to the lectures, it seems to be more likely that errors will be spotted and noted. Interactivity It is not really possible to make a lecture interactive. Yes, there are good options like socrative where you can allow students to simply post an answer anonymously. But compare that to multiple choice in YouTube videos where students can thinks as long as they want about a problem. Or even free answers, where you allow the student to check for themselves if they got it right, wrong or if they need a clarification. I really don't like questions in lectures. Either they are too easy and I am bugged by that or wondering if I got something really wrong. Or they are too hard and I would need more than the usual 5 seconds to think about the question. Or I just was thinking about something else and I need some more context to understand the question / answer in the expected way. What would I do with a YouTube video if I just lost the context? I would skip back a minute. Open Knowledge Most German universities are heavily funded by the public. There is no good reason to not make the content created by tax payers available to all tax payers. Reasons against providing online lectures Creating an online lecture is time intensive. The video has to be made, cut and uploaded. In case of errors, they should be fixed. Ideally, the video should be cut into small sections or at least an index should be created (see Videos of Prof. Henze , for example. Every lecture has a lot of links to parts within the video to make the content more accessible) So time / money is a valid reason why lectures are not available online. Pseudo-reasons against online lectures Lecture halls would be empty So what? If we really don't need them (which I really doubt), we could use them for something else. For example, for paper discussion groups such as the one I organized for machine learning (see ML-KA/PDG ). Or we could have more small rooms for learning in silence / in groups. No Discussion This is plain wrong. A professional video portal always has a comment section. So it is possible to have a discussion. Ideally, online lectures would be hosted on a platform which is suitable for lectures. This means it should have a Q&A part directly linked to lectures where students can ask questions and answer them. Quite similar to StackOverflow . I think I have seen that on coursera. Sebastian Thrun said students answered the questions of other students so fast, that he only watched the questions and answers popping up. Only in rare cases he had to answer questions or correct a wrong answer. Students don't get to know each other People don't get to know each other in lecture halls. Most try to have at least one empty seat between themselves and students they don't know. If there are waiting times, at least half of the students look at their smartphones. Students get to know each other in leisure time activities, Facebook groups for the different lectures, in search of other students for exam preparation (via e-mail lists and Facebook groups) or via student groups like my machine learning group ML-KA . KIT is an \"Elite University\" You mean like MIT ( online courses ), Stanford ( online courses ) or Harvard and Berkeley ( online courses ) and many more, which rank much higher than KIT?","tags":"Cyberculture","title":"Lectures on YouTube"},{"url":"https://martin-thoma.com/constants-as-music/","text":"I've just seen the following video and I wondered how hard it was to automatically generate this myself only with software. Turns out, it is super easy. Python You have to install MIDIUtil : $ sudo pip install MIDIUtil and then you can execute the following code: #!/usr/bin/env python from midiutil.MidiFile import MIDIFile # Just an example try : # import version included with old SymPy from sympy.mpmath import mp except ImportError : # import newer version from mpmath import mp mp . dps = 1000 # set number of digits # Create the MIDIFile Object with 1 track MyMIDI = MIDIFile ( 1 ) track = 0 channel = 0 pitch = 60 time = 0 duration = 1 volume = 100 for digit in str ( mp . pi ): if digit == '.' : continue MyMIDI . addNote ( track , channel , pitch + int ( digit ), time , duration , volume ) time += 1 if time == 180 : break # And write it to disk. binfile = open ( \"output.mid\" , 'wb' ) MyMIDI . writeFile ( binfile ) binfile . close () This will make the first 180 digits of \\(\\pi\\) to a MIDI file. See MIDIUtil docs for more information. Create MP3 I use timidity to create a .wav and then lame to convert it to mp3: $ timidity -Ow -o output.wav output.mid $ lame output.wav pi.mp3 For YouTube, I had to convert it to avi: $ ffmpeg -loop 1 -r 1 -i pi.jpg -i pi.mp3 -c:a copy -shortest pi.avi Examples \\(\\pi\\) : It sounds much more intersting if you play two versions of it simultaneously, starting at different points: \\(e\\) : \\(\\sqrt{2}\\) Ideas You could reserve one digit for meta-choices, e.g. making 0 a control character. If 0 is followed by... ... 0, all modifiers are reset ... 1, the pitch is doubled all the time ... 2, the pitch is doubled for 10 notes ... 3, `time = time - 5.5` ... 4, `tempo = tempo*2` ... 5, `tempo = tempo*4 ... 6, `tempo = tempo - 10 ... 7, volume increases in as many beats as the next two digits indicate ... 8, volume decreases by 10 in the next 2 seconds ... 9, duration is doubled Let me know if you made something that sounds interesting :-)","tags":"Cyberculture","title":"Constants as Music"},{"url":"https://martin-thoma.com/ml-glossary/","text":"The following is a list of short explanations of different terms in machine learning. The aim is to keep things simple and brief, not to explain the terms in full detail. Active Learning The algorithm gives a pattern and asks for a label. Backpropagation A clever implementation of gradient descent for neural networks. Bias Bias is a concept which describes a systematic error. A classifier with a high bias tends to give one answer more often, no matter what the input is. This concept is relatied to variance and well described with the images here . BLSTM , BiLSTM Bidirectional long short-term memory (see paper and poster ). Co-Training A form of semi-supervised learning. Two independant classifiers are trained on different labeled datasets. The classifiers are applied to the unlabeled data. Data with high confidence will be added to the other classifiers data. Collaborative Filtering You have users and items which are rated. No user rated everything. You want to fill the gaps (see article ). Computer Vision The academic discipline which deals with how to gain high-level understanding from digital images or videos. Common tasks include image classifiction, semantic segmentation, detection and localization. Curriculum learning A method for pretraining. First optimize a smoothed objective and gradually consider less smoothing. So a curriculum is a sequence of training criteria. One might show gradually more difficult training examples. See Curriculum Learning by Benigo, Louradour, Collobert and Weston for details. Curse of dimensionality Various problems of high-dimensional spaces that do not occur in low-dimensional spaces. High-dimensional often means several 100 dimensions. See also: Average Distance of Points DCGAN ( Deep Convolutional Generative Adverserial Networks ) TODO DCIGN ( Deep Convolutional Inverse Graphic Network ) TODO DCNN ( Doubly Convolutional Neural Network ) Introduced in this paper ( summary ). Note Some people also call Deep Convolutional Neural Networks DCNNs. DNN Deep Neural Network. The meaning of \"deep\" differs. Sometimes it means at least one hidden layer, sometimes it means at least 12 hidden layers. Domain adaptation A model is trained on dataset $A$. How does it have to be changed to work on dataset $B$? Detection in Computer Vision ( Object detection ) Object detection in an image is a computer vision task. The input is an image and the output is a list with rectangles which contain objects of the given type. Face detection is one well-studied example. A photo could contain no face or hundrets of them. The rectangles can overlap. Deep Learning Buzzword. The meaning depends on who you ask / in which year you asked. Sometimes it means multi-layer perceptrons with more than $N$ layers (some say $N=2$ is already deep learning, others want N>20 or nowadays $N>100$). Discriminative Model The model gives a conditional probability of the classes $k$, given the feature vector $x$: $P(k | x)$. This kind of model is often used for prediction. FC7-Features Features of an image which was run through a trained neural network. AlexNet called the last fully connected layer FC7. However, FC7 features are not necessarily created by AlexNet. FMLLR Feature-Space Maximum Likelihood Linear Regression Feature Map A feature map is the result of a single filter of a convolutional layer being applied. So it is the activation of that filter over the given input. Fine-tuning See pre-training GMM Gaussian Mixture Model GEMM ( GEneral Matrix to Matrix Multiplication ) General Matrix to Matrix Multiplication is the problem of calculating the result of $C = A \\cdot B$ with $A \\in \\mathbb{R}&#94;{n \\times m}, B \\in \\mathbb{R}&#94;{m \\times k}, C \\in \\mathbb{R}&#94;{n \\times k}$. Generative model The model gives the relationship of variables: $P(x, y)$. This kind of model can be used for prediction, too. Gradient Descent An iterative optimization algorithm for differentiable functions. HMM Hidden Markov Model i-vector speaker identity vector. See Front-End Factor Analysis for Speaker Verification . MANN Memory-Augmented Neural Networks (see Blog post ) Machine Vision Computer vision applied for industrial applications. Matrix Completion See collaborative filtering . MLLR Maximum Likelihood Linear Regression MMD ( Maximum Mean Descrepancy ) MMD is a measure of the difference between a distribution $P$ and a distribution $Q$: $$MMD(F, p, q) = sup_{f \\in F} (\\mathbb{E}_{x \\sim p} [f(x)] - \\mathbb{E}_{y \\sim q} [f(y)])$$ Multi-Task learning Train a model which does multiple tasks at the same time, e.g. segmentation and detection (see MultiNet ). NEAT Neuroevolution of Augmenting Topologies (see Blogpost ). Object recognition Classification on images. The task is to decide in which class a given image falls, judging by the content. This can be cat, dog, plane or similar. One-Shot learning Learn only with one or very few examples per class. See One-Shot Learning of Object Categories . Optical Flow Optical flow is defined for two images. It describes how the points in one image moved when switching to the second image. PCA Principal component analysis (short: PCA) is a linear transformation which projects $n$ points $\\mathbf{x} \\in \\mathbb{R}&#94;{n \\times s}$ with $s$ features each on a hyperplane in such a way that the projection error is minimal. Hence it is an unsupervised method for feature reduction. It simply works by finding a matrix $P \\in \\mathbb{R}&#94;{s \\times m}$, where $m \\leq s$ can be chosen as small as desired. Pre-training You have machine learning model $m$. Pre-training : You have a dataset $A$ on which you train $m$. You have a dataset $B$. Before you start training the model, you initialize some of the parameters of $m$ with the model which is trained on $A$. Fine-tuning : You train $m$ on $B$. Regularization Regularization are techniques to make the fitted function smoother. This helps to prevent overfitting. Examples: L1, L2, Dropout, Weight Decay in Neural Networks. Parameter $C$ in SVMs. Reinforcement Learning Reinforcment learning is a sub-field of machine learning, which focuses on the question how to find actions which lead to higher rewards. See German lecture notes . Self-Learning One form of semi-supervised learning, where you train an initial system on the labeled data, then label the unlabeled data where the classifier is 'sure enough'. After that, you train a new system on all data and re-label the unlabeled data. This is iterated. Semi-supervised learning Some training data has labels, but most has no labels. Supervised learning All training data has labels. Spatial Pyramid Pooling ( SPP ) SPP is the idea of dividing the image into a grid with a fixed number of cells and a variable size, depending on the input. Each cell computes one feature and hence leads to a fixed-size representation of a variable-sized input. See paper and summary TF-IDF TF-IDF (short for Term frequencyâ€“inverse document frequency) is a measure that reflects how important a word is to a document in a collection or corpus. Transductive learning label unlabeled data (the aim here is NOT to find a hypothesis) Unsupervised learning No training data has labels. VC-Dimension A theoretical natural number assigned to any classifier. The higher the VC dimension of a classifier, the more situations it is able to capture (see longer explanation , german explanation ). VLAD Vector of Locally Aligned Descriptors VTLN vocal tract length normalization WRN Wide residual network Zero-Shot learning Learning to predict classes, of which no example has been seen during training. For example, Flicker gets several new tags each day and they want to predict tags for new images. One idea is to use WordNet and ImageNet to generate a common embedding. This way, new words of WordNet could already have an embedding and thus new images categories could also automatically be classified the right way. See Zero-Shot Learning with Semantic Output Codes as well as this YouTube video . See also Lectures: Analysetechniken groÃŸer DatenbestÃ¤nde Informationsfusion Machine Learning 1 Machine Learning 2 Mustererkennung Neuronale Netze Lokalisierung Mobiler Agenten Probabilistische Planung Wikipedia scholarpedia Other alumni.media.mit.edu robotics.stanford.edu ee.columbia.edu The Machine Learning Dictionary 37steps.com asimovinstitute.org : The Neural Network Zoo","tags":"Machine Learning","title":"Machine Learning Glossary"},{"url":"https://martin-thoma.com/average-distance-of-points/","text":"In machine learning, the \"curse of dimensionality\" is often stated but much less often explained. At least not in detail. One just gets told that points are farer away from each other in high dimensional spaces. Maximum minimal distance One approach to this is to calculate the maximum minimal distance of \\(k\\) points in \\([0, 1]&#94;n\\) . So you try to place \\(k\\) points in such a way, that the minimum over the pairwise distances of those \\(k\\) points is maximal. Let's call this \\(\\alpha(n, k)\\) . However, it is not easily possible to calculate \\(\\alpha(n, k)\\) for arbitrary \\(n > 2\\) and \\(k > 2\\) (see link ). But the special case \\(k = 2\\) and \\(k = 2&#94;n\\) is easy: \\(\\alpha(n, 2) = \\sqrt{n}\\) \\(\\alpha(n, 2&#94;n) = 1\\) So you can see that two points get can be farer apart in higher dimensions and that it needs much more points in higher dimensions to force at least two of them to have distance 1. Average distance Another approach is to calculate the average distance of \\(k\\) uniformly randomly sampled points in \\([0, 1]&#94;n\\) . Let's call it \\(\\beta(n, k)\\) . One first insight is that \\(\\beta(n, k) = \\beta(n, j)\\) for and \\(k, j \\geq 2\\) . Hence we will only use \\(\\beta(n)\\) in the following. It is possible to calculate this, but it is rather tedious ( link ). Just two calculated solutions for \\(k=2\\) points: \\(\\beta(1) = \\frac{1}{3}\\) \\(\\beta(2) = \\frac{2+\\sqrt{2}+5\\operatorname{arcsinh}(1)}{15}=\\frac{2+\\sqrt{2}+5\\log(1+\\sqrt{2})}{15} \\approx 0.52140543316472\\ldots\\) However, it is pretty easy to simulate it. Density of Hypercubes One interesting question is how much of the \\(n\\) -dimensional hypercube can be filled by one inscribed \\(n\\) -dimensional hyperball. The volume of an \\(n\\) -dimensional hypercube is \\(V_C(a) = a&#94;n\\) where \\(a\\) is the cubes side length. So for 1 dimension it is \\(a\\) , for 2 dimensions (a square) it is \\(a&#94;2\\) , for 3 dimensions it is \\(a&#94;3\\) (a cube). The volume of an \\(n\\) -dimensional ball is $$V_S(r) = r&#94;n \\frac{\\pi&#94;{n/2}}{\\Gamma (\\frac{n}{2} + 1)}$$ Source: Wikipedia So for 1 dimension it is \\(r \\frac{\\sqrt{\\pi}}{\\Gamma(1.5)} = r \\frac{\\sqrt{\\pi}}{0.5 \\Gamma(0.5)} = 2r\\) , for 2 dimensions it is \\(r&#94;2 \\frac{\\pi}{\\Gamma (2)} = r&#94;2 \\frac{\\pi}{\\Gamma (1)} = r&#94;2 \\pi\\) and for 3 dimensions it is \\(r&#94;3 \\frac{\\pi&#94;{3/2}}{\\Gamma (\\frac{5}{2})} = r&#94;3 \\frac{\\pi&#94;{3/2}}{1.5 \\cdot 0.5 \\cdot \\Gamma (\\frac{1}{2})} = r&#94;3 \\frac{\\pi}{\\frac{3}{4}}\\) . This means the percentage of space of a unit hypercube which can be filled by the biggest inscribed hyperball is $$ \\begin{align} \\frac{V_S(0.5)}{V_C(1)} &= \\frac{r&#94;n \\frac{\\pi&#94;{n/2}}{\\Gamma (\\frac{n}{2} + 1)}}{1} \\\\ &= \\frac{0.5&#94;n \\pi&#94;{n/2}}{\\Gamma (\\frac{n}{2} + 1)} \\\\ &= \\frac{0.5&#94;n \\pi&#94;{n/2}}{\\frac{n}{2} \\cdot \\Gamma (\\frac{n}{2})} \\\\ &= \\frac{0.5&#94;n \\cdot 2 \\cdot \\pi&#94;{n/2}}{n \\cdot \\frac{2 \\frac{n}{2}!}{n}} \\\\ &= \\frac{0.5&#94;n \\cdot \\pi&#94;{n/2}}{\\frac{n}{2}!} \\end{align} $$ You can see that this term goes to 0 with increasing dimension. This means most of the volume is not in the center, but in the edges of the \\(n\\) dimensional hypercube. It also means that \\(k\\) nearest neighbors with Euclidean Distance measure will need enormously large spheres to get to the next neighbours. Average angle One interesting question is how the average angle between two points (and the origin) changes with higher dimensions. Suppose all points are in the \\([-1, 1]&#94;n\\) hypercube. I thought about this for a while and came to the conclusion that it should be 90Â° in average due to symmetry. No matter how high the dimension is. A short experiment confirms that: #!/usr/bin/env python from scipy import spatial import numpy as np import seaborn as sns def cosine_dist ( p1 , p2 ): \"\"\" Calculate the cosine distance between to points in R&#94;n. Examples -------- >>> cosine_dist([1, 0], [0, 1]) 90.0 >>> cosine_dist([1, 0], [2, 0]) 0.0 >>> cosine_dist([1, 0], [-1, 0]) 180.0 \"\"\" ang = 1 - spatial . distance . cosine ( p1 , p2 ) if not ( - 1 <= ang <= 1 ): if ang >= 1 : return 0 if ang <= - 1 : return 180 return np . degrees ( np . arccos ( ang )) def get_angles ( n , num_points = 100 ): \"\"\"Get angles of random points in n-dimensional unit hypercube.\"\"\" points = 2 * np . random . rand ( num_points , n ) - 1 angles = [] for p1 in points : for p2 in points : angles . append ( cosine_dist ( p1 , p2 )) return angles if __name__ == \"__main__\" : import doctest doctest . testmod () for n in [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 100 , 1000 , 10000 ]: angles = get_angles ( n ) print ( \"{:>5} dim: {:0.4f} avg angle\" . format ( n , sum ( angles ) / len ( angles ))) sns . distplot ( angles , kde = False , rug = False ) sns . plt . show () Also interesting: How does the distribution of angles change? The plots generated by the code from above: Distribution of angles between randomly placed points in 1D Distribution of angles between randomly placed points in 2D Distribution of angles between randomly placed points in 3D Distribution of angles between randomly placed points in 4D Distribution of angles between randomly placed points in 10D Distribution of angles between randomly placed points in 100D Distribution of angles between randomly placed points in 1000D Distribution of angles between randomly placed points in 10000D Hence I guess the cosine distance is not a good measure in high-dimensional spaces. (One should measure this for non-random points to get more certain about it.) Empirical results #!/usr/bin/env python \"\"\" Get the empirical statements about the distance of two points in [0, 1]&#94;n. The points are uniformly randomly sampled. \"\"\" import numpy.random def random_points_dist ( n ): \"\"\"Get the distance of one sample of 2 points in [0, 1]&#94;n.\"\"\" assert n >= 1 points = [] for _ in range ( 2 ): p = numpy . random . rand ( n ) points . append ( p ) return numpy . linalg . norm ( points [ 0 ] - points [ 1 ]) def beta ( n ): \"\"\"Calculate the average distance of 2 points in [0, 1]&#94;n.\"\"\" sum_ = 0.0 count_ = 10 ** 6 less_one = 0 max_d = 0 for _ in range ( count_ ): dist = random_points_dist ( n ) if dist < 1.0 : less_one += 1 max_d = max ( max_d , dist ) sum_ += dist return ( sum_ / count_ , float ( less_one ) / count_ , max_d ) for n in [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 100 , 1000 ]: avg_dist , pr , max_d = beta ( n ) tmp = ( \"beta(n= %i ) = %0.4f ; \" % ( n , avg_dist )) print ( \" %s Pr(d(p1, p2) < 1) = %0.4f ; alpha(n= %i , 2) = %0.4f \" % ( tmp , pr , n , max_d )) One can easily see that points get spaced much farer away in average the higher the dimension \\(n\\) is. Now lets try to calculate the probability that two points in the unit hypercube have a distance of less than 1. Here are a couple of results. Just a short reminder: \\(\\alpha(n, 2)\\) is the maximum distance two points can have in a unit cube in \\(\\mathbb{R}&#94;n\\) \\(\\beta(n)\\) is the average distance of two points in \\(\\mathbb{R}&#94;n\\) \\(Pr(d(p_1, p_2) < 1)\\) is the probability, that two uniformly randomly placed points have a distance of less than 1 in \\(\\mathbb{R}&#94;n\\) \\(V_S(0.5)/V_C(1)\\) is the amount a unit ball can fill a unit cube $n$ $\\alpha(n, 2)$ $\\beta(n)$ $Pr(d(p_1, p_2) < 1)$ $V_S(0.5)/V_C(1)$ 1 0.9994 0.3332 1.0000 1 2 1.3797 0.5211 0.9749 0.7854 3 1.6116 0.6616 0.9100 0.5236 4 1.8130 0.7776 0.8066 0.3084 5 1.8645 0.8786 0.6787 0.1645 6 1.9659 0.9693 0.5419 0.0807 7 2.0891 1.0515 0.4125 0.0369 8 2.1513 1.1280 0.3006 0.0159 9 2.2888 1.2002 0.2096 0.0064 10 2.3327 1.2671 0.1411 0.0025 100 5.2152 4.0753 0.0000 $\\approx 10&#94;{-70}$ 1000 14.0719 12.9073 0.0000 $\\approx 10&#94;{-1187}$ 10000 41.9675 40.8245 0.0000 $\\approx 10&#94;{-16851}$ $n$ ? $\\approx 0.41 \\cdot \\sqrt{n}$ ? $\\frac{0.5&#94;n \\cdot \\pi&#94;{n/2}}{\\frac{n}{2}!}$ You can easily see that the average distance of two points gets less and less different from the maximal distance of two points. See also The Concentration of Fractional Distances How is the distance of two random points in a unit hypercube distributed? Curse of dimensionality","tags":"Machine Learning","title":"Average Distance of Random Points in a Unit Hypercube"},{"url":"https://martin-thoma.com/cv-hci/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žComputer Vision for Human-Computer Interaction\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr.-Ing. Rainer Stiefelhagen im Wintersemester 2016/2017 gehÃ¶rt. Die Inhalte sind dementsprechend stark an der Vorlesung angelehnt bzw. komplette Teile sind daraus Ã¼bernommen. Noch ist der Artikel in der Entwurfsphase. Der Kern der Vorlesung 'Computer Vision for Human-Computer Interaction' ist das finden und verfolgen von Personen / Gesichtern in Bildern und Bildfolgen. Dabei werden folgende Themenfelder besprochen: Trackingverfahren: Kalman-Filter und Partikelfilter Behandelter Stoff # Datum Kapitel Inhalt 1 18.10.2016 EinfÃ¼hrung Organisatorisches und Ãœberblick Ã¼ber den Stoff 2 21.10.2016 Klassifikation Gaussian Mixture Models, EM, SVMs, Perceptron 3 24.10.2016 Face Detection I Color Spaces ( HS V, Y UV ), Histogram Backprojection, Histogram Matching, Mixture of Gaussians, ROC, Morphological Operations 4 28.10.2016 Face Detection II Perceptron, MLP, Histogram Equalization, Haar-like features, Adaboost (Viola and Jones) 5 31.10.2016 Face Recognition I Eigenface, Fisherface 6 04.11.2016 Programmierprojekte Organisatorisches / EinfÃ¼hrung dazu 7 07.11.2016 Face Recognition 2 Alignment (range affine warps), Morphing models of 3d forms (PCA), 8 11.11.2016 CNNs Convolution, Pooling, ReLU, Normalization layers, 9 14.11.2016 Programmierprojekte Besprechung der praktischen Aufgaben 10 18.11.2016 ? ? 11 21.11.2016 Facial Feature Detection ? 12 25.11.2016 Automatic Facial Expression Analysis ? 13 28.11.2016 Head Pose Estimation Model-based approaches, Appearence-based approaches 14 02.12.2016 Person Detection Introduction, HOG people detector, Shilouette matching 15 05.12.2016 ? ? 16 09.12.2016 ? ? 17 16.12.2016 Tracking II ? - 20.01.2017 Visuelle Perzeption Kinect, Block Matching - 23.01.2017 Gesture Recognition HMMs; Pro Gesture eine HMM trainieren 18 27.01.2017 Action & Activity Recognition I ? 19 30.01.2017 Action & Activity Recognition II ? 20 06.02.2017 Wrap-up Zusammenfassung der wichtigsten Themen Klassifikatoren Classification SVM EM-Algorithmus (Expectation Maximizaion) Perceptron-Algorithmus k nearest neighbor ( Mahalanobis-Distanz ) Clustering k-means Agglomerative Hierarchical Clustering Curse of Dimensionality Dimensionality reduction PCA LDA LDA ( Linear discriminant analysis ) Maximizes class seperability (LDA) Face Detection Face Detection Face Detection ist die Aufgabe, in einem gegebenen Bild eine Bounding-Box um jedes Gesicht zu zeichnen. Ein Ansatz ist, zu versuchen \"Gesichtsfarbe\" zu erkennen. Die Modellierung kann mit Histogrammen erfolgen. DatensÃ¤tze: ECU face detection database ECU face skin detection database MIT and CMU frontal face database Chromatic Color Spaces Nur zweidimensional (HS von HSV, UV von YUV, normalized rg von RGB). Soll robuster fÃ¼r die Erkennung von Hautfarbe sein. Histogram Backprojection Man geht fÃ¼r die Trainingsbeispiele alle Hautfarbe-Pixel durch. Bekommt man nun ein neues Bild, so geht man fÃ¼r dieses Bild jeden Pixel durch. Die Ausgabe ist ein Graustufenbild selber GrÃ¶ÃŸe, wo die Pixelfarbe die Anzahl der Hautfarbenen Pixel dieser Farbe ist. Histogram Matching Erstelle ein Histogram fÃ¼r Hautfarbe. Um ein neues Bild zu klassifizieren, bildet man Ausschnitte fÃ¼r das Bild. FÃ¼r jeden Ausschnitt vergleicht man das Histogram des Ausschnitts mit dem Hautfarbe-Histogram. Dazu kÃ¶nnen folgende Metriken verwendet werden: Battacharya distance Histogram intersection Earth-movers distance Histogram equalization This method usually increases the global contrast of many images, especially when the usable data of the image is represented by close contrast values. Through this adjustment, the intensities can be better distributed on the histogram. This allows for areas of lower local contrast to gain a higher contrast. Histogram equalization accomplishes this by effectively spreading out the most frequent intensity values. (Source: Wikipedia) The intensity values of the image are modified in such a way that the histogram is flattened. It roughly works like this: Let $p(x_i) = \\frac{n_i}{n}$ be the probability of a pixel having level $i$. Let $c(i) = \\sum_{j=0}&#94;i p(x_j)$ be the cumulative distribution. Find transformation $T$ such that the cumulative distribution $y = T(x)$ is linear. Image normalization Normalization is a process that changes the range of pixel intensity values. Applications include photographs with poor contrast due to glare, for example. Normalization is sometimes called contrast stretching or histogram stretching. (Source: Wikpedia) ROC Die ROC-Kurve misst die AbwÃ¤gung zwischen True-Positve Rate ($\\frac{TP}{Pos}$, y-Achse) und False Positive Rate (\\frac{FP}{Neg}, x-Achse). Intersection over Union ( IoU ) Siehe StackExchange Haar-like features Based on Haar wavelets as features. Developed by Viola and Jones. A Haar-like feature considers adjacent rectangular regions at a specific location in a detection window, sums up the pixel intensities in each region and calculates the difference between these sums. Can be computed efficiently by using integral images. AdaBoost TODO Face Recognition Alignment: Works only with \"nice\" images (no occlusion, high resolution) Eyes are hard Computationally intensive (not suitable for real time applications) Face Recognition Face recognition has 4 main tasks: Face detection : Given an image, draw a rectangle around every face Face alignment : Transform a face to be in a canonical pose Face representation : Find a representation of a face which is suitable for follow-up tasks (small size, computationally cheap to compare, invariant to irrelevant changes) Face verification : Images of two faces are given. Decide if it is the same person or not. The face verification task is sometimes (more simply) a face classification task (given a face, decide which of a fixed set of people it is). Challenges: Extrinsic Variations Illumination View-point Occlusion Imaging process (low resolution) Intrinsic Variations Aging Facial expressions Approaches: Feature-Based (Geometric) fiducial points distances, angles, areas Appearence-Based holistic, fiducial regions statistical Important papers: Deep Face: closing the gap to human level performance ( summary ) FaceNet: A unified embedding for face recognition and clustering ( summary ) Deep Face recognition ( summary ) Datasets LFW (Labeled Faces in the Wild, results ) YTF (Youtube Faces) Face Recognition Tasks Closed set recognition: 120 Celebrities - who is it? Known / unknown: Is it one of the persons in the known set? Verification: Is it George Clooney? Open Set recognition: First known/unknwon, then closed set. Gabor Filter TODO Local Binary Pattern ( LBP ) TODO SIFT TODO SIFT vector is 128 dimensional Bag of Visual Words ( BoVW ) TODO Fisher Encoding TODO CNNs Lernen Gabor Wavelets (TODO: Quelle?) Warum tiefere Netze? â†’ Muster kÃ¶nnen geteilt werden (RÃ¤der fÃ¼r Traktoren / MotorrÃ¤der) TODO: Filter response = Feature Map? TODO: Warum ist es ok, dass der Gradient von ReLU(x) fÃ¼r \\(x \\leq 0\\) gleich 0 ist? (Saturierungsproblem) TODO: Negative Log Likelihood vs Cross Correlation - what are differences? Pooling ( Subsampling ) Auf eine $k \\times k$ Region der Feature-Map wird ein Operator (z.B. max, mean) angewendet, der diese Zusammenfasst. Typischerweise wird diese Operation mit einem Stride > 1 verwendet. Durch den Stride wird zugleich die Datenmenge auf $\\frac{1}{s&#94;2}$ reduziert. Pooling wird seperat pro Feature-Map angewendet. Normalization Layers TODO Contrast Normalization Range Normalization Head-pose Estimation State of the Art: Regression based apprach (Random Regression Forests) is 15 years old slide 14: \\(r\\) is distance, \\(f\\) is focus length, \\(b\\) is baseline, \\(d_L, d_R\\) is distance left/right - in the later slides is a figure. Pan / Tilt / Jaw Entropy The entropy $H$ of a discrete random variable $X$ is $$H(X) = \\mathbb{E}[-\\ln(P(X))] = - \\sum_{i=1}&#94;n P(x_i) \\log_2 P(x_i)$$ Information Gain ( Kullbackâ€“Leibler divergence ) The expected information gain is the change in entropy $H$ from a prior state to a state that takes some information as given: $$IG(T,a) = H(T) - H(T|a)$$ DisparitÃ¤tenkarte TODO Facial Feature Detection Facial Features Nose tip Ears Eyes Chin Lips (corners) Eyebrow Facial Feature Detection Is important for alignment Problems: Expression variations Scale variations / angle Lightning Occlusions Statistical Appearence Models Represent shape and texture (learned seperately): \\(x \\approx \\bar{x} + P_s b_s\\) , wobei \\(P_s\\) eigenvektor of covariance; \\(b_s = P_s&#94;T (x-\\bar{x})\\) Fit shape Model Active shape model (fitting algorithm) Automatic Facial Expression Analysis Allgemein Valence-Arousal Modell von Russel 1980 Facial Action Cod FACS ( Facial Action Coding System ) 44 Action Units, welche Menschliche Mimik beschreiben 30 Gesichtsmuskeln (12 upper, 12 lower) Viele BinÃ¤r, manche mit IntensitÃ¤t Emotionen sind Kombinationen daraus Datenbanken Cohen-Kanade AU-Coded Facial Expression Database Emotion Recognition in the Wild (EmotiW) AFEW db Bag of Visual Words TODO Person detection Detection Detection is classification with localization Person detection Person detection (sometimes also pedestrian detection) is the task of finding people in an image or video. This is usually done with bounding boxes, although tight segmentation methodes exist. One can divide the methods the following way: Input: Single image / video Detection approach Global: Detection of the person as a whole Part-based: Detection of arms, legs, head, ... Model type Generative: Models how the data was generated (+ is interpretable - hard to create) Discriminative Shilouette matchin is a discriminative, global, single image approach. HOG people detector is a single image approach (TODO: global/part based? generative / discriminative?) L2 hysterese A variant of the L2 norm which cuts peaks HOG People Detector TODO Shilouette Matching Shilouette matching is practically not used anymore. It uses chemfer matching, 2/3 distance. It can be speeded up with a template hierarchy. Tracking Multi Camera Systems Topologies Stero-Cameras (cars) wide baseline multi-camera system (conference room) non-overlapping fields of view (security system) Kalibrierung: IntensitÃ¤t und extTODOs z.B. mit Schachbrettmuster bestimmen. TDOA ( Time Delay of Arrival ) In the case of multiple microphones and one audio source, the time delay when microphone 1 records the same as microphone 2 is called TDOA. It can be used to locate the audio source. Adaptive Merkmalsgewichtung TODO Gesten Gesten Gesten bedeuten nicht Ã¼berall das selbe. Ein Nicken bedeutet in vielen, aber nicht in allen Kulturen Zustimmung ( Quelle ) Action / Activity Recognition Aktion Zielgerichtete Interaktion mit der Umgebung; tendentiell mit wenigen oder einzelschritten / kurzen Perioden AktivitÃ¤t Sind auf viele Einzelaktionen aufgebaut. Zwei verschiedene AktivitÃ¤ten kÃ¶nnen aus sehr Ã¤hnlichen Bewegungen bestehen, aber deutlich unterschiedliche Semantik haben. Ein Beispiel ist das Ã¶ffnen einen Schlosses mit einem SchlÃ¼ssel und das herausdrehen einer Schraube mit einem Schraubenzieher. Es ist ein Klassifikationsproblem mit Bild-Sequenzen. LÃ¶sungsansÃ¤tze: HMMs, RNNs Features: Optical Flow aus Histogram Global Lokal (Bild aufteilen) Implicit Shape Models Deskriptoren (SIFT) Datasets : UCF Sport; Hollywood 2; Sports-1M Zero-Crossing Rate Extrem einfaches Audio-Merkmal, welches es erlaubt Auto-Hintergrundrauschen von Sprache zu unterscheiden. TODO MFCC ( Mel Frequency Cepstral Coefficients ) MFCCs sind gÃ¤ngige Features der Sprachverarbeitung. BoW ( Bag of Words , Bag of Visual Words ) Cluster Features for objects by feature similarity; gives histogram representation of object; TODO HOG ( Histogram of Gradients ) Ein Merkmal fÃ¼r Bilder welches in SIFT eingesetzt wird; TODO Optical Flow ( OF ) TODO HOF ( Histogram of Optical Flow ) TODO MBH ( Motion Boundary Histogram ) TODO Dense Trajectories TODO Wrap-up pinhole model, calibrarion (extrinsische / intrinsische Parameter), stereo processing (disparitÃ¤ten) Features Color, fg/bg, stereo edges, edge histogram, Gabor- und Haar-Filter (Viola&Jones), LBP Mid-level-Representations *: GMM, Bow, BoW+Spatial layout (body parts) DimensionalitÃ¤tsreduktion : PCA (Eigenfaces) / LDA (Fischer-Faces) Classifiers: Boosting, SVM, CNN, Regression Trees, HMMs, k-NN Wie finde ich keypoints? Descriptors (SIFT!) Space-Time-Features: Space-Time-Interest points; HOG / HOF, Dense Trajectories: Bildfolge, finde Trajektorie Implicit Shape Model: Baog-of-Words + Spacial Layout Statistische Modelle: Active Shape / Active appearence Chromatische FarbrÃ¤ume: Helligkeit rausnormalisieren (2-dimensional: rg, HS, UV) Morphable 3D models: PCA - laser scans Active Shape: Statistische Modellierung der Form; Textur entlang der shape. Nutzt PCA. Lernt Textur. Active Appearence: 2D. Gemeinsames statistisches Modell von Shape & Appearence; Textur innerhalb von Mesh / Punkten. Nutzt auch PCA. Lernt Textur. 6 Basic Emotions: FACS, Action Units HOG modelliert Textur HOF modelliert Bewegung Praktische Aufgaben Es gibt 3 praktische Aufgaben, die 10% der Note ausmachen: Haut erkennen Detektieren ob auf einem Bild eine Person ist oder nicht Erkennen ob auf zwei gegebenen Bildern die selbe Person ist Die Aufgaben mÃ¼ssen mit C++ gemacht werden. OpenCV kann verwendet werden. Es ist Beispielcode gegeben. Man muss in 180s die Modelle trainieren. Bewertet wird eine PrÃ¤sentation, die am 16.01.2016 gemacht werden muss. Die PrÃ¤sentation soll mindestens 3 Folien, maximal 5 Folien haben. In diesen 5 Folien sollen alle 3 Aufgaben beschrieben werden. Es soll beschrieben werden wie die Aufgaben gelÃ¶st wurden / was geklappt bzw. nicht geklappt hat. Die PrÃ¤sentation soll ca. 8 - 10 min pro Team dauern. Es ist ok private DatensÃ¤tze zu verwenden um ggf. Hyperparameter zu bestimmen. FÃ¼r weitere Fragen steht Manuel Martinez zur VerfÃ¼gung. PrÃ¼fungsfragen Was ist das Hauptproblem der Gesichtserkennung? â†’ Beleuchtung / Pose missmatch (ECCV'94), Occlusion, illumination Welche Farbbasierten AnsÃ¤tze gibt es zur Gesichtserkennung? â†’ Parametric vs Non-Parametric, Histogram Backprojection, GMM, Bayes, FarbrÃ¤ume Welche Feature-Basierten AnsÃ¤tze gibt es zur Gesichtserkennung? â†’ Ellipsis, Eigenfaces, Fisherfaces, ANN, EvaluationsmaÃŸ: ROC / AUC, Viola&Jones: Rotierte Gesichter -> in trainingsdaten verwenden WofÃ¼r steht DCT und AAM? â†’ TODO PCA vs LDA: Was ist zur Face Recognition besser? â†’ Das Hauptziel der PCA ist Gesichter gut rekonstruieren zu kÃ¶nnen. TODO Wozu ist die Histogram Equalization gut? â†’ TODO Welche Feature-Basierten AnsÃ¤tze gibt es zur Face Recognition? â†’ Facial Features (Abstand der Augen) vs Appearence-based Warum macht man Tracking und nicht einfach Frame-weise Detection? â†’ Tracking ist leichter, weil man Annahmen Ã¼ber die Position machen kann Was sind Anwendungen von Action und Activity Recognition? â†’ Fahrer beobachten (ist er aufmerksam? spielt er mit dem Handy?), FuÃŸgÃ¤nger beobachten (will er auf die StraÃŸe?), PatientenÃ¼berwachung, Sicherheitssystem (aggressives Verhalten) Was ist Kalibrierung? â†’ TODO Woher kommt die Skalen-Invarianz bei SIFT? â†’ Finden einer charakteristischen Skala Woher kommt die Rotationsinvarianz bei SIFT? â†’ Kantenhistogramme, Maximalausrichtung (vgl. People detection) Was ist der Unterschied zwischen Diskriminativen und Generativen Modellen? â†’ Generative Modelle modellieren explizit die Verteilung (Bayes-Formel) Wie funktioniert Histogram Backprojection? â†’ TODO Welche Metriken kann man zum Benchmarken benutzen?? â†’ ROC, TP-Rate, FP-Rate Was macht Computer Vision schwer? â†’ Beleuchtung, Pose, Occlusion (manche AnsÃ¤tze sind weniger AnfÃ¤llig, z.B. Part-based approaches) Welche Annahmen macht man im Kalman-Filter, die man nicht im Particle-Filter hat? â†’ TODO Welche Anwendungen gibt es fÃ¼r CV in der HCI? â†’ Smart Houses, Roboter-Interaktion, Smart Cars, Smart Rooms, Assistenztechnologien z.B. fÃ¼r Blinde Auf welcher Ebene, wann und wie werden Informationen zusammengefÃ¼hrt (z.B. Face / Pose)? â†’ TODO Material und Links Vorlesungswebsite lecture-demo.ira.uka.de : Interaktive Demos, insbesondere Rosenblatt-Perceptron, ... StackExchange: Why do CNNs with ReLU learn that well? How is the evaluation setup for YouTube faces of FaceNet? What are interleaved layers of convolutions? Video Analysis lecture Fazit Kommt noch. VorlesungsÂ­empfehlungen Folgende Vorlesungen sind Ã¤hnlich: Analysetechniken groÃŸer DatenbestÃ¤nde Informationsfusion Machine Learning 1 Machine Learning 2 Mustererkennung Neuronale Netze Lokalisierung Mobiler Agenten Probabilistische Planung Weitere: EinfÃ¼hrung in die Bildfolgenauswertung Content-based Image and Video Retrival - 3 ECTS, 2 SWS Termine und Klausurablauf Die Veranstaltung wird mÃ¼ndlich geprÃ¼ft, jedoch sind 10% der Note durch praktische Aufgaben zu erlangen. Ãœblicherweise dauert eine PrÃ¼fung etwa 30 min. Die Anmeldung zur PrÃ¼fung erfolgt per Email an das Sekretariat ( corinna.haas-hecker@kit.edu ). Weitere PrÃ¼fungstermine erst nach dem 18. April.","tags":"German posts","title":"Computer Vision for Human-Computer Interaction"},{"url":"https://martin-thoma.com/graph-iteration/","text":"Today I was thinking if one could iterate over all possible feed forward network architectures possible. A feed forward network is essentially only a directed acyclic graph. To make things simpler, lets just think about multilayer perceptrons. This means we only have connections between neighboring layers (and we have layers). Terms A directed acyclic graph (DAG) is a finite graph \\(G = (V, E)\\) with vertices \\(V\\) and edges \\(E \\subseteq V \\times V\\) where no cycle can be found. A cycle is a set of edges \\(e_1, \\dots, e_n\\) such that \\(e_i = (v_i, v_{i+1})\\) with \\(e_n = (v_n, v_1)\\) . Iteration Now, what does it mean to iterate over the graphs? One can iterate over all natural numbers like this: i = 1 while True : print ( i ) i += 1 Resulting in the sequence \\(1, 2, 3, \\dots\\) which is guaranteed to reach any natural number \\(k \\in \\mathbb{N}\\) at some point. Similar, one can iterate over \\(\\mathbb{Q}_0&#94;+\\) : x = 0 y = 0 while True : if x > 0 : y += 1 x -= 1 else : x = y y = 1 print ( x / y ) this is the pattern in which the numbers are generated: Iterate over $\\mathbb{Q}_0&#94;+$ Graph iteration There are finitely many directed graphs \\(G = (V, E)\\) with \\(E \\subseteq V \\times V\\) with \\(n = |V|\\) nodes. So if one wanted to iterate over all of them, one could iterate over all graphs with \\(n=1\\) node (only one graph), then over all graphs with two nodes, ... At this point, it should be obvious that it is possible. However, how can we iterate over the structures without unnecessary duplication? How can we take into account that we also need connected graphs with a fixed size for the first layer and a fixed size for the last layer? Similar to the iteration over \\(\\mathbb{Q}_0&#94;+\\) , you first generate all MLPs with exactly one neuron. Then all MLPs with exactly two neurons, ... To generate all MLPs with exactly \\(n\\) neurons in \\(k\\) layers, you first generate all MLPs with \\(n-i\\) neurons in \\(k-1\\) layers and add \\(i\\) neurons to the \\(k\\) -th layer: #!/usr/bin/python # -*- coding: utf-8 -*- \"\"\"Iterate over all MLPs.\"\"\" import numpy from itertools import count def gen_vecs ( n , k ): \"\"\"Generate all integer vectors of length k which sums up to n.\"\"\" assert n > 0 assert k > 0 assert n >= k , \"n= %i AND k= %i \" % ( n , k ) if k == 1 : yield numpy . array ([ n ]) else : for i in range ( 1 , n - k + 2 ): xs = gen_vecs ( n - i , k - 1 ) for y in xs : x = numpy . zeros ( k ) for j in range ( k - 1 ): x [ j ] = y [ j ] x [ k - 1 ] = i yield x def gen_all_mlps_size_n ( n ): \"\"\" Generate all ways to have hidden layers with exactly n nodes. Make it by the number of hidden layers. First one hidden layer, then two, ... until n hidden layers with each exactly one neuron. There are 2&#94;{n-1} of those. \"\"\" for k in range ( 1 , n + 1 ): vec_generator = gen_vecs ( n , k ) for vec in vec_generator : yield vec def gen_all_mlps (): \"\"\"Generate all MLPs.\"\"\" for neurons in count ( 1 ): gen = gen_all_mlps_size_n ( neurons ) for graph in gen : yield graph # Just for fun, generate the first 100 graphs: gen = gen_all_mlps () for i in range ( 100 ): print ( gen . next ())","tags":"Machine Learning","title":"Iterating over Graphs"},{"url":"https://martin-thoma.com/internet-traffic/","text":"Do you have any idea how much internet traffic (volume) you need? How much do you download / upload on a usual day? I didn't have any idea, so I started recording it. In this article I will show you the results. For the context: A couple of internet providers moved from flatrates to volume contracts. For example, 1&1 \"DSL Basic\" contract is for 100 GB of internet traffic per month (and they unashamedly still call it an internet flat rate). Anyway, this made me wonder how much internet traffic I need. So I started recording it with vnstat . How to measure Install vnstat and vnstati : $ sudo apt-get install vnstat vnstati Then execute $ ip link 1 : lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1 link/loopback 00 :00:00:00:00:00 brd 00 :00:00:00:00:00 2 : enp0s31f6: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc pfifo_fast state DOWN mode DEFAULT group default qlen 1000 link/ether 98 :76:54:32:10:45 brd ff:ff:ff:ff:ff:ff 3 : wlp3s0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP mode DORMANT group default qlen 1000 link/ether 12 :34:56:78:90:ab brd ff:ff:ff:ff:ff:ff to find your network interface. In my case, it is wlp3s0 . In most cases, it will be wlan0 or eth0 if you use a cable. I was mainly interested in WLAN. In my case, this is the interface wlp3s0 . Now I have to enable monitoring of that interface: $ vnstat -u -i wlp3s0 To get the nice images, you have to execute the following code (with your network interface). It will create a summary.png image: $ vnstati -vs -i wlp3s0 -o ~/summary.png Internet traffic of August Results To interpret the following, you should know that rx is the received traffic and tx is the transferred traffic. General I was not at home most of August, so the results you see in the image above might be different than usually. So lets get a summary for this year: $ vnstati -vs -m -i wlp3s0 -o ~/summary.png Internet traffic of May, June, July, August Now you have to realize that I am only recording my notebook. I have a tablet and a smartphone, too. I also only recorded WLAN, but I use the cable when I want to download / upload a lot. Also, my connection is not so fast. This means when I watch videos, I usually don't watch them in HD (although my computer would be awesome for that). So 50 GB to 70 GB download and about 5 GB to 6 GB upload might be a conservative estimate of what I need. Watching News Watching the German 20 o'clock news (15 minutes on tagesschau.de) is about 200 MiB rx and about 3 MiB tx. Publishing Blog articles For ml-ka.de it is less than 10 KiB.","tags":"Cyberculture","title":"Internet Traffic"},{"url":"https://martin-thoma.com/sommerakademie-greifswald/","text":"Eine Sommerakademie ist eine Veranstaltung der Studienstiftung des deutschen Volkes, bei der einige Dutzend Stipendiaten zusammenkommen und knapp zwei Wochen mit einander verbringen. Es gibt Kurse und AbendvortrÃ¤ge zu welchen man kommen muss, sowie einiges an Freizeitprogramm das durch die Stipendiaten organisiert wird. Sommerakademien sind eine wunderbare MÃ¶glichkeit neue Menschen kennen zu lernen und FÃ¤higkeiten in Gebieten aufzubauen welche nicht die eigene Fachrichtung sind. Oder auch neue Personen kennen zu lernen, die an der eigenen Fachrichtung interessiert sind. Ryck bei Greifswald Es gibt einige Standorte, an denen immer wieder Sommerakademien statt finden. Greifswald ist einer davon. Dieser Artikel ist fÃ¼r Stipendiaten welche noch nie auf einer Sommerakademie waren oder welche sich Ã¼ber Besonderheiten von Greifswald informieren wollen. Da die Kurse immer unterschiedlich sind, werde ich dazu nichts schreiben. Anfahrt Die meisten werden mit der Bahn zum Bahnhof Greifswald fahren. Von dort kann man mit Linie 2 zur Haltestelle \"Wieck BrÃ¼cke\" fahren. Dann sind es noch ca. 100 m an der Ryck (ein Fluss welcher in die Ostsee mÃ¼ndet) entlang zum MaJuWi. Das MaJuWi ist auf der rechten Seite, auf der Linken hat man den Fluss. Tipp: Achtet bei Bahn-Tickets darauf, dass dort \"Greifswald+City\" oder Ã¤hnliches steht. Das kostet beim Kauf nicht mehr, aber ihr kÃ¶nnt dann bis zum MaJuWi fahren und mÃ¼sst nicht noch 2 Euro an den lokalen Verkehrsverbund zahlen. Ablauf Werktags (Montag - Freitag) lÃ¤uft die Akademie wie folgt ab: 7:30 - 8:30 Uhr FrÃ¼hstÃ¼ck 9:00 - 12:30 Uhr Kurs in GebÃ¤uden der Uni Greifswald 12:30 - 14:00 Uhr Mittagessen in der Mensa der Uni Greifswald 19:30 - 20:00 Uhr AnkÃ¼ndigungen 20:00 - 21:00 Uhr Abendvortrag der Dozenten Dabei ist zu beachten, dass das MaJuWi (wo man schlÃ¤ft) schon ein gutes StÃ¼ck von der Uni (wo die Kurse stattfinden) entfernt ist. Daher ist ein Fahrrad sehr hilfreich. Das kann man sich entweder selbst mitbringen, von Stipendiaten in Greifswald ausleihen oder kostenpflichtig von einer Firma ausleihen. Das sollte aber unbedingt vorher geklÃ¤rt werden. Bei uns wurde ein Bus in der FrÃ¼h vom MaJuWi zum Rubenow-Denkmal sowie einer um 12:45 vom Rubenow-Denkmal Ã¼ber die Mensa (Haltestelle \"Am St. Georgsfeld\") zum MaJuWi zurÃ¼ck. Am letzten Freitag gibt es einen \"Bunten Abend\". Dieser wird von den Stipendiaten organisiert und soll die Akademie unterhaltsam ausklingen lassen. Typischerweise fasst man den eigenen Kurs unterhaltsam zusammen (bzw. nimmt ihn ordentlich auf die Schippe - man muss ja auch Ã¼ber sich selbst lachen kÃ¶nnen). RÃ¤ume Die Stipendiaten werden im Maritimen Jugenddorf Wieck (MaJuWi) untergebracht. Es sind 6-Bett Zimmer, welche 2016 mit grÃ¶ÃŸtenteils 4 Personen belegt waren. Leider gibt es nur 2 SchlÃ¼ssel pro Zimmer. Das Problem haben wir gelÃ¶st, indem wir den SchlÃ¼ssel an der Rezeption abgegeben haben. Photo-Sphere des MaJuWi Auch an der Uni gibt es wenig Steckdosen. Wenn ihr also mit den Notebooks arbeiten wollt, solltet ihr unbedingt eine Steckdosenleiste mitbringen. Auch ein HDMI-VGA-Adapter kÃ¶nnte nÃ¶tig sein, wenn ihr nur einen VGA-Anschluss habt. Freizeit Seilgarten Boulderhalle : Zwar ist die Halle recht klein, aber sie hat ein interessantes Flair. Gerade fÃ¼r AnfÃ¤nger gibt es mehr als genug Routen, aber man sollte nichts vergleichbares wie in Karlsruhe / MÃ¼nchen erwarten. Die Halle ist ziemlich versteckt. Segeln und Surfen : Segeln und Surfen bietet sich in Greifswald an. Allerdings sollte man die Teilnehmer mindestens 2 Wochen vorher anmelden, damit genug PlÃ¤tze zur VerfÃ¼gung stehen. Wir haben 4 Gruppen (2x Segeln und 2x Surfen) fÃ¼r jeweils Mo-Do von 15:00 bis 18:00 Uhr angemeldet. Die Segler sollten Kleidung mitnehmen welche nass werden darf. Ich hatte eine Badehose, ein Funktionsshirt sowie die \"Aqua Sphere BEACHWALKER XP\" Badeschuhe an (alte Turnschuhe tuns auch). Zum Surfen kann man in Badekleidung kommen, da die NeoprenanzÃ¼ge ausgeliehen werden und im Preis inbegriffen sind. Herr Knopp von der Segel- / Surfschule ist hier sehr hilfreich bei der Beantwortung der Fragen. FÃ¼r 25 Euro mehr kann man eine PrÃ¼fung machen und bekommt den Grundschein. Das sollte man sich recht frÃ¼h Ã¼berlegen, damit man das Kursmaterial durchgehen kann. Die Segelschule ist auf der gleichen Seite der Ryck wie das MaJuWi. Man muss einfach ein paar Meter Richtung Ostsee laufen und hat die Segelschule dann auf der rechten Seite. Bezahlt wird am ersten Tag, jeder fÃ¼r sich (obwohl es da wohl auch eine Regelung mit der Segelschule und dem MaJuWi gibt), in Bar. Wer die PrÃ¼fung macht bekommt die Urkunde vom VDWS . Zoo / Botanischer Garten Kreidefelsen auf RÃ¼gen Kreidefelsen und \"Wandern\" auf RÃ¼gen / Usedom / Hiddensee / Stralsund sind beliebte Ausflugsziele fÃ¼r das Wochenende Kajak-Fahren: FÃ¼r 10 Euro kann man ein 2-er Kajak fÃ¼r 2 Stunden ausleihen. Wenn man lÃ¤nger unterwegs sein will kostet es halt mehr. Der Strand auf der anderen Seite, wenn man aus der Bucht / dem Hafen / der Anlegestelle (keine Ahnung wie man das nennt) heraus paddelt ist ganz nett. Lagerfeuer am MaJuWi Lagerfeuer mit Stockbrot und Gesang: Auf dem GelÃ¤nde des MaJuWi ist eine Stelle wo man ein Lagerfeuer machen kann. Einfach beim MaJuWi nachfragen, dann bekommt man das Feuerholz (25 Euro?) sowie Teig fÃ¼r Stockbrot (0.50 Euro/person). In der NÃ¤he des Strandbades kann man StÃ¶cke fÃ¼r das Stockbrot finden. Wendelstein 7-X : Kann man besuchen, muss man aber anmelden. Spieleabende: Bei Werwolf sind immer einige dabei. Auch Russisch Tabu und Black Stories finden hÃ¤ufig regen Anklang. PowerPoint-Karaoke: Sollte auf max. 5 Minuten pro Beitrag beschrÃ¤nkt werden, die Folien sollten zumindest ein paar Bilder beinhalten und mÃ¶glichst abwechslungsreich sein (also nicht nur z.B. Chemische Formeln / nur Mathe / nur Texte) Packliste Kleidung und Hygiene-Zeugs (surprise, surprise). Es empfiehlt sich recht viel an Kleidung dabei zu haben, da man nicht direkt am MaJuWi waschen kann. Zwar kann man in der Pension \"Ship In\" fÃ¼r 4 Euro waschen und fÃ¼r nochmals 4 Euro trocknen, aber das hat - zumindest bei mir - nicht so toll geklappt. Eventuell lohnt es sich etwas Handwaschmittel und einen KleiderbÃ¼gel zum trocknen dabei zu haben. HandtÃ¼cher bekommt man vom MaJuWi, aber ein groÃŸes Handtuch fÃ¼r den Strand sollte man mitnehmen. Mehrfachsteckdosenleisten : Es gibt in den 6-Bett Zimmern nur eine Steckdose. Wenn nun 4 Leute mit Smartphone, Notebook, elektrischer ZahnbÃ¼rste, Digitalkamera und Rasierer kommen sollte man das auf jeden Fall mitnehmen. Ich hatte den Anker PowerCore 20100mAh dabei und war damit recht glÃ¼cklich. Stirnlampe / Taschenlampe: Ist nÃ¼tzlich, wenn man abends nicht mehr das Licht anmachen will aber dennoch was sehen muss. Beispielsweise wenn man ins Zimmer kommt wenn die anderen schon schlafen. Die Stirnlampe ist zusÃ¤tzlich zum Fahrradfahren praktisch. Von den geliehenen RÃ¤dern waren bei vielen die Lichter kaputt. MÃ¼cken-Abwehrmittel (z.B. Autan): Auf dem MaJuWi-GelÃ¤nde ist ein Teich und abends gibt es Unmengen an MÃ¼cken. Sport Tischtennis-SchlÃ¤ger: Es gibt Tischtennis-Platten und man kann SchlÃ¤ger ausleihen. Aber eventuell wollt ihr ja eure eigenen SchlÃ¤ger mitnehmen. Boulder-Schuhe: Man kann glaube ich Boulder-Schuhe ausleihen, aber nicht sonderlich viele. Wenn ihr also bouldern wollt und selbst Schuhe habt, dann nehmt sie einfach mit. Kamera: Es ist schÃ¶n, wenn man nach der Akademie ein paar Erinnerungen hat. Mindestens einer sollte fÃ¼r das Abschlussfoto auch eine gute Kamera dabei haben. Rucksack: Wenn man TagesausflÃ¼ge macht oder einfach nur das Kursmaterial (Block, Notebook, whatever) vom MaJuWi zu den KursrÃ¤umen bringen will sollte man schon einen kleinen Rucksack dabei haben. Organisatorisches Eine Austauschplatform (z.B. eine Facebook-Gruppe) vor Beginn der Akademie einzurichten ist praktisch. Dann kann man die gemeinsame An- und Abreise organisieren, Kurs-relevantes klÃ¤ren sowie die Freizeit-Sachen planen. Wenn ihr - wie wir es gemacht haben - eine Facebook-Gruppe erstellt, solltet ihr darauf rÃ¼cksicht nehmen, dass manche Leute Facebook nicht benutzen wollen. Dann kann man Ã¼ber das Daidalosnet auch die wichtigsten Informationen an alle per E-Mail schicken. Es sollten sich Personen fÃ¼r folgende Gruppen finden: Bunter Abend: Irgendjemand muss es organisieren und moderieren sowie z.B. die Technik-Fragen klÃ¤ren. Bar-Team: Einkaufen von GetrÃ¤nken, tragen der GetrÃ¤nke zum MaJuWi, aufrÃ¤umen von eventuell herumstehenden Flaschen. Mindestens einen Autofahrer braucht man hier. Vom MaJuWi kann man dann auch eine KÃ¼hltruhe bekommen. Chor: Ist immer schÃ¶n fÃ¼r den Bunten Abend Segeln / Surfen: z.B. Anmeldung Ã¼ber Google Docs (Vorname, Nachname, Segeln und- / oder Surfen). FahrrÃ¤der: Vermutlich wollen immer einige Leute ein Fahrrad in Greifswald haben, kÃ¶nnen aber keines mitbringen. Das sollte man vorher klÃ¤ren. Wir haben fÃ¼r fahrtaugliche, aber dennoch recht schlechte RÃ¤der 4.50 Euro / Tag fÃ¼r 2 Wochen bezahlt. Eventuell kann man da was besser machen. Weiteres 1Zeit-Ausstellung Fotos auf Wikipedia What kind of ship is this?","tags":"German posts","title":"Sommerakademie Greifswald"},{"url":"https://martin-thoma.com/diverging-gradient-descent/","text":"When you take the function $$f(x, y) = 3x&#94;2 + 3y&#94;2 + 2xy$$ and start gradient descent at \\(x_0 = (6, 6)\\) with learning rate \\(\\eta = \\frac{1}{2}\\) it diverges. Gradient descent Gradient descent is an optimization rule which starts at a point \\(x_0\\) and then applies the update rule $$x_{k+1} = x_k + \\eta d_k(x_k)$$ where \\(\\eta\\) is the step length (learning rate) and \\(d_k\\) is the direction. The direction is $$d_k(x_k) = - \\nabla f(x_k)$$ Example $$\\nabla f(x, y) = \\begin{pmatrix}6x + 2y\\\\6y + 2x\\end{pmatrix}$$ \\begin{align} x_0 &= (6, 6) & d_k(6, 6) &= (-24, -24)\\\\ x_1 &= (-18, -18) & d_k(-18, -18) &= (72, 72\\\\ x_2 &= (54, 54) & d_k(54, 54) &= (-216, -216)\\\\ x_3 &= (-162, -162) & d_k(-162, -162) &= (648, 648) \\end{align} In general: \\begin{align} x_n &= (x_{n-1} - 8 \\cdot \\frac{1}{2} \\cdot x_{n-1}, x_{n-1} - 8 \\cdot \\frac{1}{2} \\cdot x_{n-1})\\\\ x_n &= (-3x_{n-1}, -3x_{n-1}) \\end{align} You can clearly see that any learning rate \\(\\eta > \\frac{1}{8}\\) will diverge. For this example, the learning rate \\(\\eta = \\frac{1}{8}\\) would find the solution in one step and any \\(\\eta < \\frac{1}{8}\\) will converge to the global optimum.","tags":"Machine Learning","title":"Diverging Gradient Descent"},{"url":"https://martin-thoma.com/tf-xor-tutorial/","text":"The XOR-Problem is a classification problem, where you only have four data points with two features. The training set and the test set are exactly the same in this problem. So the interesting question is only if the model is able to find a decision boundary which classifies all four points correctly. The XOR classification problem. 4 datapoints and two classes. All datapoints have 2 features. Neural Network basics I think of neural networks as a construction kit for functions. The basic building block - called a \"neuron\" - is usually visualized like this: It gets a variable number of inputx \\(x_0, x_1, \\dots, x_n\\) , they get multiplied with weights \\(w_0, w_1, \\dots, w_n\\) , summed and a function \\(\\varphi\\) is applied to it. The weights is what you want to \"fine tune\" to make it actually work. When you have more of those neurons, you visualize it like this: In this example, it is only one output and 5 inputs, but it could be any number. The number of inputs and outputs is usually defined by your problem, the intermediate is to allow it to fit more exact to what you need (which comes with some other implications). Now you have some structure of the function set, you need to find weights which work. This is where backpropagation 3 comes into play. The idea is the following: You took functions ( \\(\\varphi\\) ) which were differentiable and combined them in a way which makes sure the complete function is differentiable. Then you apply an error function (e.g. the euclidean distance of the output to the desired output, Cross-Entropy) which is also differentiable. Meaning you have a completely differentiable function. Now you see the weights as variables and the data as given parameters of a HUGE function. You can differentiate (calculate the gradient) and go from your random weights \"a step\" in the direction where the error gets lower. This adjusts your weights. Then you repeat this steepest descent step and hopefully end up some time with a good function. For two weights, this awesome image by Alec Radford visualizes how different algorithms based on gradient descent find a minimum ( Source with even more of those): So think of back propagation as a shortsighted hiker trying to find the lowest point on the error surface: He only sees what is directly in front of him. As he makes progress, he adjusts the direction in which he goes. Targets and Error function First of all, you should think about how your targets look like. For classification problems, one usually takes as many output neurons as one has classes. Then the softmax function is applied. 1 The softmax function makes sure that the output of every single neuron is in \\([0, 1]\\) and the sum of all outputs is exactly \\(1\\) . This means the output can be interpreted as a probability distribution over all classes. Now you have to adjust your targets. It is likely that you only have a list of labels, where the \\(i\\) -th element in the list is the label for the \\(i\\) -th element in your feature list \\(X\\) (or the \\(i\\) -th row in your feature matrix \\(X\\) ). But the tools need a target value which fits to the error function. The usual error function for classification problems is cross entropy (CE). When you have a list of \\(n\\) features \\(x\\) , the target \\(t\\) and a classifier \\(clf\\) , then you calculate the cross entropy loss for this single sample by: $$CE(x, t) = - \\sum_{i=1}&#94;n \\left (t&#94;{(i)} \\log \\left ({clf(x)}&#94;{(i)} \\right ) \\right)$$ Now we need a target value for each single neuron for every sample \\(x\\) . We get those by so called one hot encoding : The \\(k\\) classes all have their own neuron. If a sample \\(x\\) is of class \\(i\\) , then the \\(i\\) -th neuron should give \\(1\\) and all others should give \\(0\\) . 2 sklearn provides a very useful OneHotEncoder class. You first have to fit it on your labels (e.g. just give it all of them). In the next step you can transform a list of labels to an array of one-hot encoded targets: #!/usr/bin/env python \"\"\"Mini-demo how the one hot encoder works.\"\"\" from sklearn.preprocessing import OneHotEncoder import numpy as np # The most intuitive way to label a dataset \"X\" # (list of features, where X[i] are the features for a datapoint i) # is to have a flat list \"labels\" where labels[i] is the label for datapoint i. labels = [ 0 , 1 , 1 , 1 , 0 , 0 , 1 ] # The OneHotEncoder transforms those labels to something our models can # work with enc = OneHotEncoder () def trans_for_ohe ( labels ): \"\"\"Transform a flat list of labels to what one hot encoder needs.\"\"\" return np . array ( labels ) . reshape ( len ( labels ), - 1 ) labels_r = trans_for_ohe ( labels ) # The encoder has to know how many classes there are and what their names are. enc . fit ( labels_r ) # Now you can transform print ( enc . transform ( trans_for_ohe ([ 0 , 1 ])) . toarray () . tolist ()) Install Tensorflow The documentation about the installation makes a VERY good impression. Better than anything I can write in a few minutes, so ... RTFM ðŸ˜œ For Linux systems with CUDA and without root privileges, you can install it with: $ pip install https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl --user But remember you have to set the environment variable LD_LIBRARY_PATH and CUDA_HOME . For many configurations, adding the following lines to your .bashrc will work: export LD_LIBRARY_PATH = \" $LD_LIBRARY_PATH :/usr/local/cuda/lib64\" export CUDA_HOME = /usr/local/cuda I currently (19.07.2016) to use Tensorflow rc0.7 ( installation instructions ) with CUDA 7.5 ( installation instructions ). I had a couple of problems with other versions (e.g. #3342 , #2810 , #2034 , but that might only have been bad luck. Who knows.). Tensorflow basics Tensorflow helps you to define the neural network in a symbolic way. This means you do not explicitly tell the computer what to compute to inference with the neural network, but you tell it how the data flow works. This symbolic representation of the computation can then be used to automatically caluclate the derivates. This is awesome! So you don't have to make this your own. But keep it in mind that it is only symbolic as this makes a few things more complicated and different from what you might be used to. Tensorflow has placeholders and variables . Placeholders are the things in which you later put your input. This is your features and your targets, but might be also include more. Variables are the things the optimizer calculates. Now you should be able to understand the following code which solves the XOR problem. It defines a neural network with two input neurons, 2 neurons in a first hidden layer and 2 output neurons. All neurons have biases. #!/usr/bin/env python \"\"\" Solve the XOR problem with Tensorflow. The XOR problem is a two-class classification problem. You only have four datapoints, all of which are given during training time. Each datapoint has two features: x o o x As you can see, the classifier has to learn a non-linear transformation of the features to find a propper decision boundary. \"\"\" __author__ = \"Martin Thoma\" __email__ = \"info@martin-thoma.de\" import tensorflow as tf import matplotlib.pyplot as plt import numpy as np from sklearn.preprocessing import OneHotEncoder def trans_for_ohe ( labels ): \"\"\"Transform a flat list of labels to what one hot encoder needs.\"\"\" return np . array ( labels ) . reshape ( len ( labels ), - 1 ) def analyze_classifier ( sess , i , w1 , b1 , w2 , b2 , XOR_X , XOR_T ): \"\"\"Visualize the classification.\"\"\" print ( ' \\n Epoch %i ' % i ) print ( 'Hypothesis %s ' % sess . run ( hypothesis , feed_dict = { input_ : XOR_X , target : XOR_T })) print ( 'w1= %s ' % sess . run ( w1 )) print ( 'b1= %s ' % sess . run ( b1 )) print ( 'w2= %s ' % sess . run ( w2 )) print ( 'b2= %s ' % sess . run ( b2 )) print ( 'cost (ce)= %s ' % sess . run ( cross_entropy , feed_dict = { input_ : XOR_X , target : XOR_T })) # Visualize classification boundary xs = np . linspace ( - 5 , 5 ) ys = np . linspace ( - 5 , 5 ) pred_classes = [] for x in xs : for y in ys : pred_class = sess . run ( hypothesis , feed_dict = { input_ : [[ x , y ]]}) pred_classes . append (( x , y , pred_class . argmax ())) xs_p , ys_p = [], [] xs_n , ys_n = [], [] for x , y , c in pred_classes : if c == 0 : xs_n . append ( x ) ys_n . append ( y ) else : xs_p . append ( x ) ys_p . append ( y ) plt . plot ( xs_p , ys_p , 'ro' , xs_n , ys_n , 'bo' ) plt . show () # The training data XOR_X = [[ 0 , 0 ], [ 0 , 1 ], [ 1 , 0 ], [ 1 , 1 ]] # Features XOR_Y = [ 0 , 1 , 1 , 0 ] # Class labels assert len ( XOR_X ) == len ( XOR_Y ) # sanity check # Transform labels to targets enc = OneHotEncoder () enc . fit ( trans_for_ohe ( XOR_Y )) XOR_T = enc . transform ( trans_for_ohe ( XOR_Y )) . toarray () # The network nb_classes = 2 input_ = tf . placeholder ( tf . float32 , shape = [ None , len ( XOR_X [ 0 ])], name = \"input\" ) target = tf . placeholder ( tf . float32 , shape = [ None , nb_classes ], name = \"output\" ) nb_hidden_nodes = 2 # enc = tf.one_hot([0, 1], 2) w1 = tf . Variable ( tf . random_uniform ([ 2 , nb_hidden_nodes ], - 1 , 1 , seed = 0 ), name = \"Weights1\" ) w2 = tf . Variable ( tf . random_uniform ([ nb_hidden_nodes , nb_classes ], - 1 , 1 , seed = 0 ), name = \"Weights2\" ) b1 = tf . Variable ( tf . zeros ([ nb_hidden_nodes ]), name = \"Biases1\" ) b2 = tf . Variable ( tf . zeros ([ nb_classes ]), name = \"Biases2\" ) activation2 = tf . sigmoid ( tf . matmul ( input_ , w1 ) + b1 ) hypothesis = tf . nn . softmax ( tf . matmul ( activation2 , w2 ) + b2 ) cross_entropy = - tf . reduce_sum ( target * tf . log ( hypothesis )) train_step = tf . train . GradientDescentOptimizer ( 0.1 ) . minimize ( cross_entropy ) # Start training init = tf . initialize_all_variables () with tf . Session () as sess : sess . run ( init ) for i in range ( 20001 ): sess . run ( train_step , feed_dict = { input_ : XOR_X , target : XOR_T }) if i % 10000 == 0 : analyze_classifier ( sess , i , w1 , b1 , w2 , b2 , XOR_X , XOR_T ) The output is: Epoch 0 Hypothesis [[ 0.48712057 0.51287943] [ 0.3380821 0.66191792] [ 0.65063184 0.34936813] [ 0.50317246 0.4968276 ]] w1=[[-0.79593647 0.93947881] [ 0.68854761 -0.89423609]] b1=[-0.00733338 0.00893857] w2=[[-0.79084051 0.93289936] [ 0.69278169 -0.8986907 ]] b2=[ 0.00394399 -0.00394398] cost (ce)=2.87031 Epoch 10000 Hypothesis [[ 0.99773693 0.00226305] [ 0.00290442 0.99709558] [ 0.00295531 0.99704474] [ 0.99804318 0.00195681]] w1=[[-6.62694693 7.5230279 ] [ 6.91208076 -7.39292192]] b1=[ 3.32245016 3.76204181] w2=[[ 6.63465023 -6.49259233] [ 6.40471792 -6.61061859]] b2=[-9.65064621 9.65065193] cost (ce)=0.0100926 Epoch 20000 Hypothesis [[ 9.98954773e-01 1.04520109e-03] [ 1.35455502e-03 9.98645484e-01] [ 1.37042452e-03 9.98629570e-01] [ 9.99092221e-01 9.07782756e-04]] w1=[[-7.04857063 7.84673214] [ 7.33061123 -7.68837786]] b1=[ 3.53246188 3.89587545] w2=[[ 7.35948515 -7.21742725] [ 7.14059925 -7.34649038]] b2=[-10.74944687 10.74944115] cost (ce)=0.00468077 The resulting decision boundary looks like this: Decision boundary of the trained network. I recommend reading the Tensorflow Whitepaper if you want to understand Tensorflow better. Footnotes Softmax is similar to the sigmoid function, but with normalization. â†© Actually, we don't want this. The probability of any class should never be exactly zero as this might cause problems later. It might get very very small, but should never be 0. â†© Backpropagation is only a clever implementation of gradient descent. It belongs to the bigger class of iterative descent algorithms. â†©","tags":"Machine Learning","title":"XOR tutorial with TensorFlow"},{"url":"https://martin-thoma.com/estimating-demand/","text":"I've just had the problem that I'm helping to plan a group event, where the participants should all have bikes. There are 170 participants and 80 bikes. Some of the participants might be able to bring their own bikes. So we asked them to tell us who can't bring a bike with them. Only 79 answered. Only 7 of them can bring their own bike. How many bikes should we try to organize to be 95% sure that everybody will have a bike? Modelling Let \\(X\\) be the random variable which represents the number of people who will not bring their own bikes. I will assume that the participants bring or bring not their bikes independent of each other. So have a binomial distribution: $$X \\sim Bin(n=91, p=\\frac{79-7}{79})$$ The sample of \\(n=79\\) people who answered will be called \\(S\\) . Let \\(b \\in \\mathbb{N}_0\\) be our guess of the number of people of those \\(91\\) who do not bring their bikes. The higher we estimate \\(b\\) , the more conservative we are. This means a higher certainty (e.g. 99% instead of 95%) should result in a higher \\(b\\) . We want to be \\(95\\%\\) confident that we have enough bikes. The task $$ \\begin{align} P(X \\leq b) &\\geq 95\\%\\\\ \\sum_{i=0}&#94;b \\binom{n}{k} p&#94;k {(1-p)}&#94;{n-k} &\\geq 95\\%\\\\ b &= \\lceil binom.ppf(95\\%, n, p) \\rceil \\end{align} $$ I am lazy with calculating, so lets do it with Python: from scipy.stats import binom confidence = 0.95 n = 91 p = 1 - 7. / 79 binom . ppf ( confidence , n , p ) This gives 87. So we assume only 4 more people will bring their own bike.","tags":"Mathematics","title":"Estimating Demand"},{"url":"https://martin-thoma.com/optimization-basics/","text":"Optimization is a subfield of mathematics / computer science which deals with finding the best solution. Typically, problems in optimization are stated like this: $$ \\begin{align} &\\underset{x}{\\operatorname{minimize}}& & f(x) \\\\ &\\operatorname{subject\\;to} & &g_i(x) \\leq 0, \\quad i = 1,\\dots,m \\\\ &&&h_i(x) = 0, \\quad i = 1, \\dots,p \\end{align} $$ where \\(f(x): \\mathbb{R}&#94;n \\to \\mathbb{R}\\) is the loss function (objective function) to be minimized over the variable \\(x\\) , \\(g_i(x) \\leq 0\\) are called inequality constraints , and \\(h_i(x) = 0\\) are called equality constraints . By convention, the standard form defines a minimization problem . A maximization problem can be treated by negating the objective function. (That was copied from en.wikipedia.org/w/Optimization_problem and only slightly edited.) I'm now going to explain some very basic techniques which are used for finding good solutions to optimization problems. Please note that there are also discrete optimization problems where you have to finde a solution \\(x \\in \\mathbb{N}&#94;n\\) . I will only focus on continuous optimization problems. Simulated Annealing Simulated Annealing is a heuristical optimization algorithm. It starts at a random point \\(x \\in \\mathbb{R}&#94;n\\) . Then it takes a random point \\(y\\) of the environment of \\(x\\) : $$y \\in U(x)$$ If \\(f(y) \\leq f(x)\\) , then the current position \\(x\\) is overwritten with \\(y\\) : $$x \\leftarrow y$$ Otherwise, it might be overwritten with probability \\(\\exp \\left (-\\frac{f(y)-f(x)}{T(t)} \\right )\\) where \\(T: \\mathbb{N}_0 \\rightarrow \\mathbb{R}_{> 0}\\) is called the temperature at time \\(t\\) . So the optimization algorithm is: Take a random point $x \\in \\mathbb{R}&#94;n$ Take a random point $y \\in U(x)$ $$x \\leftarrow \\begin{cases}y &\\text{if } f(y) \\leq f(x)\\\\ y &\\text{if } \\operatorname{rand}(0,1) < \\exp \\left (-\\frac{f(y)-f(x)}{T(t)} \\right )\\\\ x &\\text{otherwise}\\end{cases}$$ Go to step 2. See also my German description . Gradient descent The gradient descent algorithm can easily be applied when the optimization problem has no constraints and the objective function \\(f\\) is differentiable. The idea is to just take a random starting point \\(x \\in \\mathbb{R}&#94;n\\) and iteratively improve it. There are many algorithms which follow this approach (Simulated annealing, L-BFGS, Newton's method, Quasi-Newtonian, Conjugate Gradient, ...). Instead of randomly going in other directions, the gradient \\(\\nabla f\\) is calculated at the position \\(x\\) . The gradient points in the direction of maximum increase, so we go in the opposite direction: $$x_{\\text{new}} = x - \\nabla f(x)$$ The problem with this approach is that the surface of the objective function might first go down in the direction of \\(\\nabla f(x)\\) , but if you go a bit further it can go up by a lot. So we want to make very small steps. To achive this, we multiply the gradient with a factor \\(\\eta \\in (0, 1]\\) . In machine learining, this \\(\\eta\\) is called the learning rate and typically one chooses \\(\\eta = 0.01\\) . However, there are learning rate scheduling algorithms which adapt this parameter during training. The update rule is: $$x_{\\text{new}} = x - \\eta \\nabla f(x)$$ Iterative Descent A more general formulation of the Gradient descent algorithm is called iterative descent. The idea is to start at some arbitrary \\(x_0\\) and iteratively update the current guess of the minimum to $$x_{k+1} = x_k + \\eta \\cdot d_k$$ where \\(\\eta \\in (0, 1]\\) is the step length (learning rate) and $$d_k = -D_k \\nabla f(x_k)$$ is the direction of the descent. The direction depends on the Gradient \\(\\nabla f(x_k)\\) , but also on a matrix \\(D_k\\) : $D_k = I$: Gradient descent $D_k = H_f&#94;{-1}(x_k)$: Newtons method, where $H_f$ is the Hessian matrix of $f$ Linear Regression with MSE In linear regression one is given a list of \\(n\\) points \\((x, y)\\) with \\(x \\in \\mathbb{R}&#94;m\\) and \\(y \\in \\mathbb{R}\\) . The task is to find a matrix \\(A \\in \\mathbb{1 \\times m}\\) such that the predicted value \\(\\hat{y}\\) of the linear model $$\\hat{y}(x) = A \\cdot x$$ minimizes the term $$\\text{MSE} = \\sum_{i=1}&#94;n (y_i - \\hat{y}(x_i))&#94;2$$ For convenience, one can write the list of points as a matrix \\(\\mathbf{X} \\in \\mathbb{R}&#94;{n \\times m}\\) and a vector \\(\\mathbf{y} \\in \\mathbb{R}&#94;n\\) : $$\\text{MSE} = \\|\\mathbf{y} - \\mathbf{X} A&#94;T\\|_2$$ with the Euclidean norm $$\\| v \\|_2 := \\sqrt{ ( v_1 )&#94;2 + ( v_2 )&#94;2 + \\dotsb + ( v_n )&#94;2 } = \\left( \\sum_{i=1}&#94;n ( v_i )&#94;2 \\right)&#94;{1/2}$$ Every part of the sum is non-negative, so exponentiating the Euclidean norm with a positive factor will not change the result of the minimization: $$\\operatorname{minimize}_{A} \\|\\mathbf{y} - \\mathbf{X} A&#94;T\\|_2&#94;2$$ Now we can see that this is every element of the vector squared. So we can get rid of the norm and then use distributivity: $$ \\begin{align} \\operatorname{minimize}_{A}&(\\mathbf{y} - \\mathbf{X} A&#94;T)&#94;T \\cdot (\\mathbf{y} - \\mathbf{X} A&#94;T)\\\\ \\Leftrightarrow \\operatorname{minimize}_{A}&(\\mathbf{y}&#94;T - A \\mathbf{X}&#94;T) \\cdot (\\mathbf{y} - \\mathbf{X} A&#94;T)\\\\ \\Leftrightarrow \\operatorname{minimize}_{A}&\\mathbf{y}&#94;T \\mathbf{y} - A \\mathbf{X}&#94;T \\mathbf{y} - \\mathbf{y}&#94;T \\mathbf{X} A&#94;T + A\\mathbf{X}&#94;T \\mathbf{X} A&#94;T\\\\ \\end{align} $$ You need to know that $$ \\begin{align} A \\mathbf{X}&#94;T \\mathbf{y} &= ((A \\mathbf{X}&#94;T \\mathbf{y})&#94;T)&#94;T\\\\ &= (\\mathbf{y}&#94;T \\mathbf{X} A&#94;T)&#94;T\\\\ &= \\mathbf{y}&#94;T \\mathbf{X} A&#94;T\\\\ \\end{align} $$ You can get rid of the last transposing operation, because $$(\\mathbf{y}&#94;T \\mathbf{X} A&#94;T) \\in \\mathbb{R}&#94;{1 \\times 1}$$ This simplifies the optimization problem to $$\\operatorname{minimize}_{A}\\underbrace{\\mathbf{y}&#94;T \\mathbf{y} - 2 A \\mathbf{X}&#94;T \\mathbf{y} + A\\mathbf{X}&#94;T \\mathbf{X} A&#94;T}_{E_{X, y}(A)}$$ Now you can calculate the gradient of this term with respect to \\(A\\) : $$\\nabla E_{X, y}(A) = 2 X&#94;T X A&#94;T - X&#94;T y - X&#94;T y = 2 X&#94;T (X A&#94;T - y)$$ A necessary condition of a minimum is the gradient to be 0: $$ \\begin{align} \\nabla E_{X, y}(A) &\\overset{!}{=} 0\\\\ \\Leftrightarrow 0 &\\overset{!}{=} 2 X&#94;T (X A&#94;T - y)\\\\ \\Leftrightarrow 0 &\\overset{!}{=} X&#94;T X A&#94;T - X&#94;T y\\\\ \\Leftrightarrow A &\\overset{!}{=} ((X&#94;T X)&#94;{-1} X&#94;T y)&#94;T\\\\ \\end{align} $$ As \\(H_{E_{X, y}} = \\nabla&#94;2 E_{X, y}(A) = 2 X&#94;T X\\) is positive definite, this is a minimum. Hence, the optimal solution to this problem is: $$A = ((X&#94;T X)&#94;{-1} X&#94;T y)&#94;T$$ Lagrange multipliers Lagrange multipliers are a trick in optimization problems with constraints. They can be used to get rid of the constraints. The Lagrange function has the form $$\\mathcal{L} (x, \\lambda_1, \\dots, \\lambda_n) = f(x) + \\sum_{j=1}&#94;n \\lambda_j h_j(x)$$ with the Lagrange multipliers \\(\\lambda_j \\in \\mathbb{R}\\) and \\(h_j\\) are equality constraints. Necessary conditions for a minimum \\(x&#94;*\\) is: $\\nabla_x \\mathcal{L} = \\nabla_x f(x&#94;*) + \\sum_{j=1}&#94;n \\lambda_j \\nabla_x h_j(x&#94;*) \\overset{!}{=} 0$ $\\frac{\\partial}{\\partial \\lambda_j} \\mathcal{L} = h_j(x&#94;*) \\overset{!}{=} 0, \\quad j=1, \\dots, $ See [ Smi04 ] for many examples. Optimization Problem characteristics There are some properties of optimization problems which make it easier / harder to solve: Property Easy Hard Objective linear non-linear Optimization Variable small discrete, continuous large discrete Constraints No Constraints Constraints Resources Reddit: Overview of Optimization Algorithms References [ Smi04 ] B. T. Smith, \"Lagrange multipliers tutorial in the context of support vector machines,\" Memorial University of Newfoundland St. John's, Newfoundland, Canada, Jun. 2004.","tags":"Machine Learning","title":"Optimization Basics"},{"url":"https://martin-thoma.com/python-map-reduce-filter/","text":"I recently was challenged to re-write Pythons map , reduce and filter as list comprehensions. Examples First of all, I want to make sure you understand what those functions do. You might also want to have a look at my old article Functional Programming in Python . map numbers = list ( range ( 10 )) squares = map ( lambda x : x ** 2 , numbers ) print ( squares ) gives [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] filter def is_prime ( element ): if element == 2 : return True elif element <= 1 or element % 2 == 0 : return False else : for i in range ( 3 , element , 2 ): if element % i == 0 : return False return True myList = [ 4 , 4 , 9 , 12 , 13 , 2 , 7 , 9 , 11 , 11 ] r = filter ( is_prime , myList ) print ( r ) gives [13, 2, 7, 11, 11] . reduce numbers = list ( range ( 10 )) diff = reduce ( lambda x , y : x - y , numbers ) print ( diff ) gives -45 , because $$((((((((0-1)-2)-3)-4)-5)-6)-7)-8)-9 = -45$$ Sequential solution The standard way to do these tasks without map , filter and reduce is to use loops. map numbers = list ( range ( 10 )) squares = [] for x in numbers : squares . append ( x ** 2 ) print ( squares ) filter def is_prime ( element ): if element == 2 : return True elif element <= 1 or element % 2 == 0 : return False else : for i in range ( 3 , element , 2 ): if element % i == 0 : return False return True my_list = [ 4 , 4 , 9 , 12 , 13 , 2 , 7 , 9 , 11 , 11 ] r = [] for x in my_list : if is_prime ( x ): r . append ( x ) print ( r ) reduce numbers = list ( range ( 10 )) x = numbers [ 0 ] for y in numbers [ 1 :]: x = x - y print ( x ) List comprehensions List comprehensions are - according to Guido van Rossum - the way to go. So lets see how the code looks like without map , reduce and filter . map numbers = list ( range ( 10 )) squares = [ x ** 2 for x in numbers ] print ( squares ) I think that is much more readable than the map solution. filter def is_prime ( element ): if element == 2 : return True elif element <= 1 or element % 2 == 0 : return False else : for i in range ( 3 , element , 2 ): if element % i == 0 : return False return True my_list = [ 4 , 4 , 9 , 12 , 13 , 2 , 7 , 9 , 11 , 11 ] r = [ x for x in my_list if is_prime ( x )] print ( r ) I also think this is more readable, as you can easily combine it with more transformations. reduce This is the tricky one. List comprehensions create lists again, so using only list comprehensions is not going to work. However, you could cheat. sum(numbers) is essentially reduce(lambda x, y: x + y, numbers) . So we only have to change the sign, except for the first one: numbers = list ( range ( 10 )) diff = sum ([ numbers [ 0 ]] + [ - x for x in numbers [ 1 :]]) print ( diff ) So, granted, the code using reduce looks much better. However, people argue that you should use the sequential solution because it is simpler to understand. By now, I understood every piece of code using reduce . But I haven't seen it too often.","tags":"Code","title":"Pythons map, reduce and filter as list comprehensions"},{"url":"https://martin-thoma.com/linear-classification/","text":"In classification problems you have data points \\(x \\in \\mathbb{R}&#94;m\\) which you want to classify into one of \\(k \\in \\mathbb{N}_{\\geq 2}\\) classes. This is a supervised task. This means you have \\(n\\) data points for training in a matrix \\(X \\in \\mathbb{R}&#94;{n \\times m}\\) with their labels. 1 Initially, the label might be something like \"cat\" or \"dog\". But the machine learning algorithms can't deal with those directly, so you need to encode the labels. The simplest way of encoding them is to use integers \\(0, 1, \\dots, k - 1\\) . However, in many cases it is handy to use a one-hot encoding . This means you make a \\(k\\) -dimensional vector for each label. \\((1, 0)\\) might encode \"dog\" and \\((0, 1)\\) might encode \"cat\". sklearn supports this encoding in a convenient way ( docs ). Another common encoding is \\(-1\\) and \\(1\\) for binary classification problems. 2 A linear model is one which applies only linear operations to the features. So basically the model may only be a matrix. Typically the elements of the matrix are called weights , because they weight the importance of each feature. The objective of such a classifier 4 is to find a matrix \\(W&#94;*\\) such that the MSE is as small as possible on the test set \\(D\\) : $$W&#94;* = \\arg \\min_{W} E_{MSE} (f_W, D)$$ One-hot encoding If one-hot encoded labels are used, 3 a linear classifier $$f: \\text{feature space} \\rightarrow \\text{class space}$$ usually works like this: $$f(x) = {\\arg \\max}_{i \\in 1, \\dots, k} (W \\cdot x)&#94;{(i)}$$ with \\(W \\in \\mathbb{R}&#94;{k \\times m}\\) and \\(&#94;{(i)}\\) denoting the \\(i\\) -th element of the vector. Given a test set $$D = \\{(x_i, y_i) \\text{ with } i \\in \\{1, \\dots, n_t\\}, x_i \\in \\mathbb{R}&#94;{m}, y_i \\in \\mathbb{R}_+&#94;{k}\\}$$ you can calculate the mean squared error (MSE) of the classifier \\(f\\) : $$E_{MSE}(f, D) = \\frac{1}{n_t}\\sum_{i=1}&#94;{n_t} (t_i - W \\cdot x_i)&#94;T (t_i - W \\cdot x_i)$$ Please note that the MSE is always non-negative for every single data point. Normalizing the output The nice thing about the MSE is that it is simple. It can easily be calculated and is used in regression problems very often. What is not so nice is the fact that it punishes several good solutions, too. For example, say we have a data point \\(x_1\\) which has the target \\((1, 0)&#94;T\\) . The classification output $$c_1 = \\begin{pmatrix}101\\\\0\\end{pmatrix}\\quad E_{MSE}(f, x_1) = 100&#94;2\\tag{1.1}$$ while the classification output of another point \\(x_2\\) is $$c_2 = \\begin{pmatrix}0\\\\0.1\\end{pmatrix}\\quad E_{MSE}(f, x_2) = 1 + 0.1&#94;2\\tag{1.2}$$ This is problematic, as the actual classification in \\((1.1)\\) is correct whereas the classification in \\((1.2)\\) is wrong. However, this can easily be fixed by normalizing the result. Simple Normalization The simplest way to normalize the result of the classifier would be to divide each entry by the sum of all entries, e.g. for \\((1.1)\\) we get $$ \\begin{align} c_1' &= \\begin{pmatrix}1\\\\0\\end{pmatrix}\\quad &E_{MSE}(f'', x_1) &= 0\\tag{2.1}\\\\ c_2' &= \\begin{pmatrix}0\\\\1\\end{pmatrix}\\quad &E_{MSE}(f', x_2) &= 1\\tag{2.2} \\end{align} $$ Standardization You might want to interpret the output of your classifier as a probability of the data point belonging to the different classes. Then you may not have negative values and you also want to avoid a probability of 0. A common normalization then is the softmax function \\(\\sigma\\) . It first exponentiates the single values and then normalizes: $$\\begin{align} c_1'' &= \\begin{pmatrix}\\frac{e&#94;{101}}{e&#94;{101} + e&#94;0}\\\\\\frac{e&#94;{0}}{e&#94;{101} + e&#94;0}\\end{pmatrix} \\approx \\begin{pmatrix}1\\\\0\\end{pmatrix}\\quad &E_{MSE}(f'', x_1) &\\approx 0\\tag{3.1}\\\\ c_2'' &= \\begin{pmatrix}\\frac{e&#94;{0}}{e&#94;{0} + e&#94;{0.1}}\\\\\\frac{e&#94;{0.1}}{e&#94;{0} + e&#94;{0.1}}\\end{pmatrix} \\approx \\begin{pmatrix}0.475\\\\0.525\\end{pmatrix}\\quad &E_{MSE}(f'', x_2) &\\approx 0.551\\tag{3.2} \\end{align}$$ Note that this is the same as a neural network with only an input layer and a softmax output layer. Now the optimization problem is: $$ \\begin{align} W&#94;* &= \\arg \\min_{W \\in \\mathbb{R}&#94;{k \\times m}} E(f'', D)\\\\ &= \\arg \\min_{W \\in \\mathbb{R}&#94;{k \\times m}} \\frac{1}{n} \\sum_{i=1}&#94;n (t_i - \\sigma(W x_i))(t_i - \\sigma(W x_i))&#94;T \\\\ &= \\arg \\min_{W \\in \\mathbb{R}&#94;{k \\times m}} \\sum_{i=1}&#94;n (t_i - \\sigma(W x_i))(t_i - \\sigma(W x_i))&#94;T \\\\ \\end{align} $$ This is a differentiable function. This means to optimize we can calculate the gradient and apply gradient descent: $$ \\begin{align} &\\frac{\\partial}{\\partial W} \\sum_{i=1}&#94;n (t_i - \\sigma(W x_i))(t_i - \\sigma(W x_i))&#94;T\\\\ =& \\sum_{i=1}&#94;n \\frac{\\partial}{\\partial W} (t_i - \\sigma(W x_i))(t_i - \\sigma(W x_i))&#94;T\\\\ =& \\sum_{i=1}&#94;n \\left (\\frac{\\partial}{\\partial W} (t_i - \\sigma(W x_i)) \\right ) \\left(t_i - \\sigma(W x_i) \\right)&#94;T + (t_i - \\sigma(W x_i)) \\left (\\frac{\\partial}{\\partial W} (t_i - \\sigma(W x_i))\\right )\\\\ =& \\sum_{i=1}&#94;n \\left (\\frac{\\partial}{\\partial W} \\sigma(W x_i) \\right ) \\left(t_i - \\sigma(W x_i) \\right)&#94;T + (t_i - \\sigma(W x_i)) \\left (\\frac{\\partial}{\\partial W} \\sigma(W x_i)\\right )&#94;T\\\\ \\end{align}$$ as you can see it gets quite ugly. I don't want to continue this calculation here. But I hope you can see that this is possible. stats.stackexchange.com gives some hints on how to continue. Decision boundary The decision boundary for a two-class problem with 2-dimensional data vectors (and one bias) can be calculated as $$ \\begin{align} &W&#94;{(0, 0)} \\cdot 1 + W&#94;{(0, 1)} \\cdot x_1 + W&#94;{(0, 2)} \\cdot x_2 = W&#94;{(1, 0)} \\cdot 1 + W&#94;{(1, 1)} \\cdot x_1 + W&#94;{(1, 2)} \\cdot x_2\\tag{DB}\\\\ \\Leftrightarrow x_2&= \\frac{W&#94;{(0, 0)} \\cdot 1 + W&#94;{(0, 1)} \\cdot x_1 - (W&#94;{(1, 0)} \\cdot 1 + W&#94;{(1, 1)} \\cdot x_1)}{W&#94;{(1, 2)} - W&#94;{(0, 2)}}\\\\ \\Leftrightarrow x_2 &= \\frac{(W&#94;{(0, 1)} - W&#94;{(1, 1)})}{W&#94;{(1, 2)} - W&#94;{(0, 2)}} \\cdot x_1 + \\frac{W&#94;{(0, 0)} - W&#94;{(1, 0)}}{W&#94;{(1, 2)} - W&#94;{(0, 2)}} \\end{align} $$ As you can see, the decision boundary of the non-normalized form is a line: $$y = a \\cdot x + b \\qquad a, b \\in \\mathbb{R}$$ Please also note that \\(W&#94;{(1, 2)} = W&#94;{(0, 2)}\\) is possible, which would mean that the line is parallel to the \\(x_2\\) axis. So this model basically only has 2 parameter combinations which matter, although it has 6 values which can be adjusted. But many combinations are equivalent. What does normalization change? For given \\(W, x\\) it only divides both sides of the equation by the same constant. Hence it doesn't change the decision boundary. What does standardization with softmax change? Just like with normalization, softmax makes equation \\((DB)\\) to be divided by a constant. This can be ignored. The exponentiation can also be ignored as we can simply take the logartihm of both sides of \\((DB)\\) . Or in other words: A neural network with only one input layer and one softmax output layer also has a linear decision boundary! -1/+1 encoding In the 2-class case one might consider to use -1 for one class and +1 for the other class as targets. Then the classifcation is $$ \\begin{cases} \\text{class with label 1}&\\text{if } f(x) \\geq 0\\\\ \\text{class with label -1}&\\text{if } f(x) < 0 \\end{cases} $$ The matrix \\(W\\) is now in \\(\\mathbb{R}&#94;{1 \\times 3}\\) and the classifier is $$f(x) = W x$$ To make sure that this is either \\(-1\\) or \\(+1\\) , one can modify it to $$f'(x) = \\frac{W x}{|W x|}$$ Note that this ignores the case \\(Wx = 0\\) . Now we can easily calculate the MSE: $$E_{MSE}(f, D) = \\sum_{i=1}&#94;{n_t} {(t_i - f'(x))}&#94;2$$ Differences from target encoding You might wonder if it makes a difference which type of encoding you use for your target. There are some things which come to my mind: (+) One-hot encoding can easily be expanded to more than two classes, in contrast to \\(-1/+1\\) encoding. (+) With one-hot encoding, you can easily get a probability distribution for the classes you are interested in. This is certainly also possible with \\(-1/+1\\) encoding, but it doesn't strike my eye as clearly. (-) One-hot encoding needs more storage space. (?) \\(-1/+1\\) encoding is used in SVMs (see SVM article ), so it might have advantages in maximum margin classification. Implementation If I had to implement a linear binary classifier, I would use the delta rule and a perceptron unit: #!/usr/bin/env python \"\"\"Example for a linear classifier using a perceptron and the delta rule.\"\"\" from sklearn.datasets.samples_generator import make_blobs import matplotlib.pyplot as plt import numpy as np class Perceptron ( object ): def __init__ ( self , eta = 0.01 , epochs = 50 ): \"\"\" Single perceptron unit. Credit to Sebastian Raschka: http://sebastianraschka.com/Articles/2015_singlelayer_neurons.html This was slightly modified. \"\"\" self . eta = eta self . epochs = epochs def fit ( self , X , y ): self . w_ = np . zeros ( 1 + X . shape [ 1 ]) self . errors_ = [] for _ in range ( self . epochs ): errors = 0 for xi , target in zip ( X , y ): update = self . eta * ( target - self . predict ( xi )) self . w_ [ 1 :] += update * xi self . w_ [ 0 ] += update errors += int ( update != 0.0 ) self . errors_ . append ( errors ) return self def net_input ( self , X ): return np . dot ( X , self . w_ [ 1 :]) + self . w_ [ 0 ] def predict ( self , X ): return np . where ( self . net_input ( X ) >= 0.0 , 1 , - 1 ) # Generate data X , target = make_blobs ( random_state = 0 , centers = 2 , cluster_std = 0.5 ) # Fit perceptron f = Perceptron ( epochs = 100 ) f . fit ( X , target ) # Plot decision boundary xs = np . linspace ( start = min ( X [:, 0 ]), stop = max ( X [:, 0 ])) plt . plot ( xs , [ - ( f . w_ [ 0 ] + f . w_ [ 1 ] * xi ) / f . w_ [ 2 ] for xi in xs ], 'r--' ) # Plot data plt . gray () _ = plt . scatter ( X [:, 0 ], X [:, 1 ], c = target ) plt . show () which gives: Classification with a Perceptron. Looks about right. You can also see that this probably minimizes the MSE, but it does not maximize the margin between the classes. This would be done by SVMs. Footnotes A label and a class are two different things. The class is a set which contains all data points which belong to this class. The label is only a pointer to this class. â†© Classification problems with only two classes. â†© Also called \"targets\" sometimes, as we want our classifier to output those values. â†© The objective function defines what is to be done during fitting / training / learning. â†©","tags":"Machine Learning","title":"Linear Classification"},{"url":"https://martin-thoma.com/kalman-filter/","text":"The Kalman Filter is an algorithm which helps to find a good state estimation in the presence of time series data which is uncertain. For example, when you want to track your current position, you can use GPS. However, GPS is not totally accurate as you know if you ever used Google Maps on your mobile device. Sensor data is noisy and the programmer and the users have to deal with it. The GPS signal in space will provide a \"worst case\" pseudorange accuracy of 7.8 meters at a 95% confidence level. Source: gps.gov , see also What is the maximum Theoretical accuracy of GPS? The Kalman filter is the optimal linear filter ( BLUE : B est L inear U nbiased E stimator). This means, there is no estimator for the state which has a linear state model which is better. It assumes the noise is Gaussian. If the noise is Gaussian, then the Kalman filter minimizes the mean squared error of the estimated state parameters. So it in this case it is not only the best linear filter, but the best filter. The name \"filter\" is used because the Kalman filter removes (filters) the noise. Step-by-step Step 1: Problem description First, note what you're given. This should be: The type of data you measure \\(z \\in \\mathbb{R}&#94;{n_z}\\) , the type of values you want to derive from that \\(\\mathbf{x} \\in \\mathbb{R}&#94;{n_x}\\) , the types of action \\(a_k \\in \\mathbb{R}&#94;{n_a}\\) you can do. Step 2: Modelling The Kalman Filter is a linear filter. This means you have to model your system in the form $$\\mathbf{x}_{k+1} = A_k \\mathbf{x}_k + B_k a_k + r_k&#94;{(s)}$$ with \\(\\mathbf{x}_{k+1}, \\mathbf{x}_{k} \\in \\mathbb{R}&#94;{n_x}\\) being the state vectors, \\(A_k \\in \\mathbb{R}&#94;{n_x \\times n_x}\\) being the system matrix, \\(B_k \\in \\mathbb{R}&#94;{n_x \\times n_a}\\) being the control matrix, \\(a_k \\in \\mathbb{R}&#94;{n_a}\\) being the control matrix vector ( \\(a\\) for action), \\(r_k&#94;{(s)} \\sim \\mathcal{N(0, C_k&#94;{(r_s)})}\\) with \\(C_k&#94;{(r_s)} \\in \\mathbb{R}&#94;{n_x \\times n_x}\\) being Gaussian noise. \\(C_k&#94;{(r_s)} \\in \\mathbb{R}&#94;{n_x \\times n_x}\\) is called the process error covariance matrix. You can also make a model of your measurements . They should be some linear combination of the state with Gaussian noise \\(r_k&#94;{(m)}\\) : $$z_k = H \\cdot \\mathbf{x}_k + r_k&#94;{(m)}$$ with \\(z_k \\in \\mathbb{R}&#94;{n_m}\\) : The measurement vector \\(r_k&#94;{(r_m)} \\sim \\mathcal{N(0, C_k&#94;{(r_m)})}\\) with \\(C_k&#94;{(r_m)} \\in \\mathbb{R}&#94;{n_m \\times n_m}\\) being Gaussian noise. \\(C_k&#94;{(r_m)} \\in \\mathbb{R}&#94;{n_m \\times n_m}\\) is called the measurment noise covariance matrix. \\(H \\in \\mathbb{R}&#94;{n_m \\times n_x}\\) : A matrix which transforms the state vector \\(\\mathbf{x}\\) to a measurement vector. This matrix is a constant over the whole process. It is most likely to have only 0s and 1s as entrys. Step 3: The algorithm Overview of the Kalman-filter. The inputs are orange , the outputs are blue . The matrices which were not explained so far are: \\(P_k \\in \\mathbb{R}&#94;{n_x \\times n_x}\\) is the state vector covariance matrix. It is the uncertainty. \\(K_k \\in \\mathbb{R}&#94;{n_x \\times n_m}\\) : The Kalman gain. Higher values indicate that we give more trust to the measurment. Lower values indicate that we give more trust to our last prediction. If the measurement uncertainty \\(C_k&#94;{(m)}\\) is small compared to the state uncertainty \\(P_k&#94;{(P)}\\) , then the Kalman Gain is big. So we will rely more on the measurement and less of what we predicted before. The complexity of the Kalman filter is \\(\\mathcal{O}(n_z&#94;{2.4} + n_x&#94;2)\\) According to Cyrill Stachniss . The factor \\(2.4\\) comes from matrix inversion. Example Suppose you want to track the position of a car in 2D. What you get as sensor data is the current position. So the state is $$\\mathbf{x} = \\begin{pmatrix}x\\\\y\\\\\\dot{x}\\\\\\dot{y}\\end{pmatrix}$$ where \\(x \\in \\mathbb{R}\\) is the position in m away from some predefined point, \\(\\dot{x} \\in \\mathbb{R}\\) is the velocity in m/s at starting time and \\(\\ddot{x} \\in \\mathbb{R}\\) is the acceleration in \\(m/s&#94;2\\) . The measurements are $$\\mathbf{z} = \\begin{pmatrix}x&#94;{(M)}\\\\y&#94;{(M)}\\end{pmatrix}$$ What you get to choose is the acceleration at each time step \\(i\\) (time steps have the length \\(t\\) ): $$a = \\begin{pmatrix}\\ddot{x}&#94;{(a)}\\\\\\ddot{y}&#94;{(a)}\\end{pmatrix}$$ As the Kalman filter is a linear filter, the state model is: $$\\mathbf{x}&#94;{(P)}_k = A\\mathbf{x}_k + Ba_k$$ The measurement is dependent on the state, with some noise \\(r_k&#94;m\\) : $$\\mathbf{z}_k = H \\mathbf{x}_k + r_k&#94;m$$ with \\(A \\in \\mathbb{R}&#94;{4 \\times 4}\\) , \\(H \\in \\mathbb{R}&#94;{2 \\times 4}\\) . As one can decompose the acceleration / speed in the directions and the equation for the new position is $$\\begin{align}x_{new}(t) &= x + \\dot{x} t + 0.5 \\ddot{x} t&#94;2\\\\ y_{new}(t) &= y + \\dot{y} t + 0.5 \\ddot{y} t&#94;2\\\\ \\dot{x}_{new}(t) &= \\dot{x} + \\ddot{x} t\\\\ \\dot{y}_{new}(t) &= \\dot{y} + \\ddot{y} t\\end{align}$$ So given the state model, we get: $$\\mathbf{x}&#94;{(P)} = \\underbrace{\\begin{pmatrix}1& 0 & t & 0\\\\ 0& 1 & 0 & t\\\\ 0& 0 & 1 & 0\\\\ 0& 0 & 0 & 1\\end{pmatrix}}_{A_k} \\mathbf{x}_k + \\underbrace{\\begin{pmatrix}0.5t&#94;2 & 0\\\\ 0 & 0.5t&#94;2\\\\ t & 0\\\\ 0 & t\\end{pmatrix}}_{B_k} \\cdot a_k$$ The choice of the initial uncertainty covariance matrix \\(P_0 \\in \\mathbb{R}&#94;{4 \\times 4}\\) / the initial state \\(\\mathbf{x}\\) doesn't matter too much. The Kalman filter algorithm will fix both over enough steps. Common choices are the zero-vector for \\(\\mathbb{x}\\) and \\(P_0 = c \\cdot I\\) as the covariance matrix with the identity matrix \\(I\\) and \\(c\\) being big compared with the noise. For this example, a reasonable choice is the diagonal matrix $$P_0 = \\begin{pmatrix}a_1 & 0 & 0 & 0\\\\ 0 & a_2 & 0 & 0\\\\ 0 & 0 & a_3 & 0\\\\ 0 & 0 & 0 & a_4\\end{pmatrix}$$ with \\(a_1 = a_2 = 20000000\\) as the earths diameter is about \\(40000\\textrm{ km}\\) and \\(a_3=a_4=90\\) as going more than \\(324\\textrm{ km/h}\\) is extremely rarely going to happen for a car. For the initial state parameter, you could wait two time steps: $$\\mathbf{x}_0 = \\begin{pmatrix}x&#94;{(M)}_{-1}\\\\ y&#94;{(M)}_{-1}\\\\ x&#94;{(M)}_{-1} - x&#94;{(M)}_{-2}\\\\ y&#94;{(M)}_{-1} - y&#94;{(M)}_{-2}\\end{pmatrix}$$ Prediction step The state prediction works as above: $$\\mathbf{x}&#94;{(P)}_{k+1} = A_k \\mathbf{x}_{k} + B_k a_k$$ Covariance prediction: $$P_{k+1}&#94;{(P)} = A P_k A&#94;T + C_k&#94;{(r_s)} \\quad \\text{with}\\quad C_k&#94;{(r_s)} \\in \\mathbb{R}&#94;{4 \\times 4}.$$ The process error covariance \\(C_k&#94;{(r_s)}\\) expresses the error in the system. It is a covariance matrix and thus has to be symmetric and positive definite. It encodes errors in the modeling itself as well as errors in the actions. Innovation step Innovation, which compares the measurement with the prediction: $$\\tilde{y}_{k+1} = z_{k+1} - H \\mathbf{x}&#94;{(P)}_{k+1}$$ The observation matrix \\(H \\in \\mathbb{R}&#94;{2 \\times 4}\\) in the example is $$H = \\begin{pmatrix}1 & 0 & 0 & 0\\\\0 & 1 & 0 & 0\\end{pmatrix},$$ as it encodes the relationship between the state and the measurement. Innovation Covariance: $$S_{k+1} = H P_{k+1}&#94;{(P)} H&#94;T + C_k&#94;{(r_m)}$$ For the measurement error covariance \\(C_k&#94;{(r_m)} \\in \\mathbb{R}&#94;{2 \\times 2}\\) I have to know something about the way my sensors work. I guess this will usually be a diagonal matrix, as the sensors will be independent(?). Kalman Gain: $$K_{k+1} = P_{k+1}&#94;{(P)} H&#94;T S&#94;{-1}_{k+1}$$ Now, finally the state and covariance update: $$\\mathbf{x}_{k+1} = \\mathbf{x}&#94;{(P)}_{k+1} + K_{k+1} \\tilde{y}$$ $$P_{k+1} = (I - K_{k+1} H) P_{k+1}&#94;{(P)}$$ Miscallenious facts Error estimates How does the error estimate change in the Kalman filter steps? In the prediction step, you have a matrix $$\\tilde{P} = A \\cdot P \\cdot A&#94;T, \\qquad A, P \\in \\mathbb{R}&#94;{n \\times n}$$ ( \\(A\\) is the system matrix and \\(P\\) is the estimate of the error.) It has the property: $$\\det(\\tilde{P}) = \\det(A) \\cdot \\det(P) \\cdot \\det(A&#94;T) = 2 \\cdot \\det(A) \\cdot \\det(P)$$ So if the determinant of \\(P\\) is how we say if it gets bigger, then it will get bigger in the prediction step if \\(\\det(A) > 0.5\\) . Otherwise, it might still get bigger as the system noise \\(C_{k}&#94;{(s)}\\) gets added. In the filter step, things are more complicated. I don't know what to write about it, so I asked for help: How does the error estimate change in the Kalman filter? Perfect sensor What is the value of \\(K_k\\) if the sensor is perfect? A perfect sensor has no uncertainty. This means the variance \\(C_k&#94;{(m)}\\) is 0. It follows: $$K_k = P_k&#94;{(P)} H&#94;T (H&#94;T)&#94;{-1} (P_k&#94;{(P)})&#94;{-1} H&#94;{-1} = H&#94;{-1}$$ This leads to the uncertainty \\(P_k\\) getting 0 and the state \\(x_k\\) will be the measurement \\(z_k\\) . Really bad sensor What is the value of \\(K_k\\) if the sensor is as bad as possible? If we don't trust the sensor at all, the uncertainty is huge. The inverse of a huge term is close to 0. so the Kalman gain \\(K_k\\) is close to 0. This means neither the state \\(x_k\\) nor the error estimate \\(P_k\\) will change. Notation The system noise covariance matrix \\(C_k&#94;{(r_s)}\\) is often denoted with \\(Q\\) . Alternative State Equation Sometimes, the noise in the state equation is modelled in a different way: $$\\mathbf{x}_{k+1} = A_k \\mathbf{x}_k + B_k a_k + G r_k&#94;{(s)}$$ Then you also have to adjust the filter step to $$P_{k+1}&#94;{(P)} = A_k P_k A_k&#94;T + G C_k&#94;{(r_s)} G&#94;T$$ See Why does it make sense to have noise of a different shape than the state vector? Extensions EKF UKF: Unscented Kalman filter deterministic sampling approximation of the first two moments does not need derivative (in contrast to EKF) Extended Kalman Filter The Kalman filter is the best filter for linear systems, but if you have a non-linear system model $$ \\begin{align} x_{k+1} &= p_k(x_k, a_k) + r_k&#94;{(s)}\\tag{system model}\\\\ z_k &= h_k(x_k) + r_k&#94;{(m)}\\tag{measurement model} \\end{align} $$ it cannot be applied any more. But the Extended Kalman Filter linearizes the function around some point with multivariate Taylor Series expansions and uses LQR with a Kalman filter. Assumptions: $p_k$ is differentiable. The non-linear part of $p_k$ in the environment of the linearization point is neglectable. One linearizes around nominal values \\(\\bar{x}_k, \\bar{a}_k\\) . $$p_k(x_k, a_k) \\approx p_k(\\bar{x}_k, \\bar{a}_k) + A_k (\\underbrace{x_k - \\bar{x}_k}_{=: \\Delta x_k}) + B_k (\\underbrace{a_k - \\bar{a}_k}_{\\Delta a_k})$$ with Jacobian matrices : $$A_k = \\frac{\\partial}{\\partial x_k} p_k(x_k, a_k)|_{x_k = \\bar{x}_k, a_k = \\bar{a}_k}$$ $$B_k = \\frac{\\partial}{\\partial a_k} p_k(x_k, a_k)|_{x_k = \\bar{x}_k, a_k = \\bar{a}_k}$$ \\(\\Rightarrow\\) Lineares Modell: \\(\\Delta x_{k+1} \\approx A_k \\cdot \\Delta x_k + B_k \\Delta a_k\\) mit \\(\\Delta x_{k+1} = p_k(x_k, a_k) - p_k(\\bar{x}_k, \\bar{a}_k)\\) Choice of nominal values \\(\\bar{x}_k, \\bar{a}_k\\) : Policy: Zielzustand $\\bar{x}_k = x_+ = [0, \\dots, 0]&#94;T,\\quad\\bar{a}_k = [0, \\dots, 0]&#94;T\\qquad\\forall k$ Zustandssolltrajektorien bei Verfolgungsproblem PrÃ¤diktiv: $\\bar{x}_{k+1} = p_k(\\bar{x}_k, \\bar{a}_k)$ mit $\\bar{x}_0 = E(x_0)$ und beliebig $\\bar{a}_{0:N-1}$ Iterativ: Starte mit beliebigem $\\bar{a}_{0:N-1}$ und $\\bar{x}_0 = E(x_0)$ Bestimme $\\bar{x}_{k+1} = p_k(\\bar{x}_k, \\bar{a}_k) \\forall k$ Linearisiere und lÃ¶se LQR $\\Rightarrow \\bar{a}_k = \\pi_k(\\bar{x}_k)$ zurÃ¼ck zu 1. SchÃ¤tzer: Linearisierung um $\\bar{x}_k = \\hat{x}_k&#94;l, \\bar{a}_k=\\pi_k(\\hat{x}_k&#94;l)$ $$\\hat{x}&#94;p_{k+1} = p_k(\\hat{x}_k&#94;l, \\bar{a}_k)$$ $$C_{k+1}&#94;P = A_k C_k&#94;e A_k&#94;T + C_k&#94;w$$ Filterschritt: Linearisierung um $\\bar{x}_k = \\hat{x}_k&#94;p$ $$\\hat{x}_k&#94;e = \\hat{x}_k&#94;P + K_k (z_k - h_k(\\hat{x}_k&#94;P))$$ $$C_k&#94;e = C_k&#94;P - K_k H_k C_k&#94;P$$ See also: Das Extended Kalman Filter einfach erklÃ¤rt (German) Lectures There are several lectures at KIT which introduce Kalman filters: Probabilistische Planung Informationsfusion Lokalisierung mobiler Agenten Analyse und Entwurf multisensorieller Systeme There is also an series of YouTube videos I can recommend: Literature and Weblinks Bar-Shalom, Yaakov, X. Rong Li, and Thiagalingam Kirubarajan. Estimation with applications to tracking and navigation: theory algorithms and software. John Wiley & Sons, 2004. Greg Czerniak: Introduction to Kalman filters How do I choose the parameters of a Kalman filter? StackExchange: math , CV , DSP What is the difference between kalman filter and extended kalman filter? Python implementation","tags":"Code","title":"Kalman Filter"},{"url":"https://martin-thoma.com/thoughts-about-language/","text":"Language is a method of communication. It is used to transport information from one individuals brain to another brain. I'm not entirely sure about it, but I think every language which is wide-spread might be complete in a sense that once you know every word of the language you will be able to convey any concept or idea. In fact, even a tiny subset of natural languages might be enough to transport those ideas. Basic components of a complete language A complete language is always specific for the species for which it is used as one fundamental part is to describe sensory inputs . For example, bees can see other parts of the spectrum. They might describe flowers very different from us. Some of the sensory words are: pain bright, dark, red, blue, round, rectangular, straight, curved sweet, bitter smokey, stinking hard / soft, warm / cold, rough Another fundamental part of complete language are relationships : Spacial: A is over / below / right of B Temporal: A is before / after B Structural: A is part of B; A is a type of B Comparing: A is smaller than B; A is better than B; A is higher than B Thinking about this, there seem to be many conceptual words which cannot be explained with the ones given before: Language, knowledge, idea, wisdom, time, space Other components of natural languages Natural languages are much more than complete languages. They have words to define new words. Many words can be completely described with other words, but it is cumbersome to use many sentences instead of a single word. Also, there are synonyms, filling words, words and grammar which helps to distinguish other words and make sure the other one does not missunderstand you. Conclusions There are two important conclusions from these thoughts: First, the purpose of language is to convey ideas. This means one the one hand that you should use language like others do most of the time. On the other hand, there are some circumstances where you might want to ignore the \"official\" writing (e.g. in German \" das Kalman-Filter\" would be correct, but most people would intuitively say \" der Kalman-Filter\" - going with the intuitive version is fine here). Second, it might be possible to define a minimal complete language to describe the world.","tags":"Cyberculture","title":"Thoughts about Language"},{"url":"https://martin-thoma.com/us-problems/","text":"In the last few months I've seen a couple of astonishing and frightening stories about the US. I'm not sure how much of a problem those stories really are. Police, Agencies and Justice Faking Terrorism On Thursday, roughly 67% of prosecutions involving suspected ISIS supporters include evidence from undercover operations, according to The New York Times. In many cases, agents will seek out people who have somehow demonstrated radical views, and then coax them into plotting an act of terrorism â€” often providing weapons and money. Before the suspects can carry out their plans, though, they're arrested. Busiess Insider: The FBI is 'manufacturing terrorism cases' on a greater scale than ever before Police legally robbing people It is called \"Civil Forfeiture\": More John Oliver: Mandatory Minimums John Oliver: Death Penalty - costly, they make faults John Oliver: Bail John Oliver: Municipal Violations No Fly List John Oliver: Torture Guantanamo Bay detention camp John Oliver: Elected Judges John Oliver: Public Defenders not having enough time to properly prepare Democracy In the US there seem to be several measures in place solely to make people not being able to vote. And if they can vote, then they can't get what they want with their vote. Namely: John Oliver: Voting - voter registration votes which were designed to make minorities vote less An overly complicated, unintuitive voting process ( John Oliver: Primaries and Caucuses ), John Oliver: Washington DC Statehood John Oliver: Puerto Rico Felony disenfranchisement : Making people not being allowed to vote - this seems to be a problem in Germany, too. Voter suppression in the United States Consumer Safety John Oliver: Lead : Flint water crisis Education John Oliver: Sex Education John Oliver: Native Advertising - I think we have that problem in Germany, too (Apotheken Umschau, if I recall correctly) John Oliver: Student Debt John Oliver: Texas Republicans . Mary Lee Bruner on the Texas State Board of Education. Creationism (e.g. Creation and evolution in public education in the United States ) John Oliver: The Lottery - Cuts in education spendings which should be filled by gains from Lottery. Miscallenious John Oliver: Nuclear Weapons John Oliver: Special Districts","tags":"My bits and bytes","title":"US problems"},{"url":"https://martin-thoma.com/informationsfusion/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žInformationsfusion\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen nicht gehÃ¶rt, aber die Folien von Herrn Prof. Dr.-Ing. Michael Heizmann aus dem Wintersemester 2015/2016 gelesen. In der Vorlesung 'Informationsfusion' ist der Kalman-Filter ein zentraler Inhalt. Behandelter Stoff Grundlagen Slides: IF-Kap1_151110.pdf Es wurden Grundbegriffe wie Daten, Information, Merkmal, Informationsfusion, Signal, usw. eingefÃ¼hrt. Information Information ist alles was potentiell zur Verringerung von Ungewissheit beitrÃ¤gt. Sinnvolle Informationen besteht aus Fakten und zugehÃ¶rigen Unsicherheiten. Signal Ein Signal ist eine Funktion oder Wertefolge welche Information trÃ¤gt. Daten Daten sind maschinenlesbare ReprÃ¤sentationen von Informationen. Sie werden als Zeichen oder Zeichenketten gespeichert. Merkmal Ein Merkmal ist eine beobachtbare oder physikalisch messbare Eigenschaft eines oder mehrerer Objekte. Vorraussetzungen fÃ¼r Informationsfusion Gemeinsamer Sachverhalt Kompatibler Definitionsbereich Kompatibler Wertebereich Unsicherheiten: Die Informationen mÃ¼ssen ein MaÃŸ fÃ¼r ihre Unsicherheit tragen Vorteile von Informationsfusion HÃ¶here Robustheit Erweterung der Sensorabdeckung ErhÃ¶hte AuflÃ¶sung (z.B. Accelerometer + Kompas in Kamera) Kostenreduktion (z.B. mehrere billige Bildsensoren, dann Daten mitteln zur Rauschreduktion) Unsicherheit Verringern (z.B. FLIR + Radar) Indirektes schlieÃŸen auf GrÃ¶ÃŸen (z.B. OberflÃ¤chennormalen) WÃ¼nschenswerte Eigenschaften von Merkmalen Leicht gewinnbar Interpretierbar Hohe Relevanz: Merkmalsvektor ist gut fÃ¼r die Aufgabe geeignet (z.B. lineare separierbarkeit der Klassen bei Klassifikationsproblemen in Merkmalsraum) Robustheit gegen StÃ¶rungen Invarianzen werden berÃ¼cksichtigt (z.B. Drehung des Objekts) Geringe DimensionalitÃ¤t des Merkmalsvektors Geringe AbhÃ¤ngigkeit zwischen Merkmalen Eigenschaften von Sensorsystemen HomogenitÃ¤t / HeterogenitÃ¤t Wirkmechanismus / Struktur ZuverlÃ¤ssigkeit KommensurabilitÃ¤t (GleichdimensionalitÃ¤t) Kollokiertheit (Identische Ausschnitte der Szene): Falls nicht gegeben, ist Registrierung erforderlich Weitere: Aktive / passive Sensoren: z.B. Laser beeinflusst die Umwelt Virtuelle Sensorsysteme: Gleiche Sensoren, aber unterschiedliche Parameter Kosten, Material WT Slides: IF-Kap2_151215.pdf Wahrscheinlichkeitsraum, Zufallsvariable Guide to the Expression of Uncertainty in Measurement (GUM) Bayessche Methodik Kolmogorov-Axiome Siehe Probabilistische Planung Kovarianz ( Covariance ) Es seien $X, Y$ Zufallsvariablen. Dann heiÃŸt $$COV(X, Y) = \\mathbb{E}((X - \\mathbb{E}(X)) \\cdot (Y - \\mathbb{E}(Y)))$$ die Kovarianz von $X$ und $Y$. Statistisches Modell Es sei $X$ eine Zufallsvariable. Dann heiÃŸt ein Tupel $(X, (P_\\theta)_{\\theta \\in \\Theta})$ ein statistisches Modell, wenn $(P_\\theta)_{\\theta \\in \\Theta}$ eine Familie von Wahrscheinlichkeitsverteilungen ist. SchÃ¤tzer Sei $\\mathcal{X}_n = (X_1, \\dots, X_n)$ eine Stichprobe und $\\theta$ ein Parameter. Dann heiÃŸt die Abbildung $$T: \\mathcal{X} \\rightarrow \\tilde{\\Theta}$$ mit $\\tilde{\\Theta} \\supseteq \\Theta$ ein SchÃ¤tzer fÃ¼r $\\theta$. Konsistenter SchÃ¤tzer Sei $\\mathcal{X}_n = (X_1, \\dots, X_n)$ eine Stichprobe, $\\theta$ ein Parameter und $T(\\mathcal{X}_n)$ ein SchÃ¤tzer fÃ¼r $\\theta$. $T(\\mathcal{X}_n)$ heiÃŸt konsistent, wenn gilt: $$\\lim_{n \\rightarrow \\infty} P_\\theta (|T(\\mathcal{X}_n) - \\theta| \\geq \\varepsilon) = 0$$ Asymptotisch Erwartungstreuer SchÃ¤tzer Ein SchÃ¤tzer $\\hat{\\theta} = \\hat{\\theta}(X_1, \\dots, X_n)$ heiÃŸt asymptotisch erwartungstreu, wenn der Grenzwert der zu schÃ¤tzenden Folge unter Annahme von $\\theta$ gleich $\\theta$ ist: $$\\lim_{n \\rightarrow \\infty} \\mathbb{E}(\\hat{\\theta}) = \\theta$$ Kalman-Filter ( KF ) Siehe Kalman-filter Artikel . Extended Kalman Filter ( EKF ) Siehe Kalman-filter Artikel . GUM ( Guide to the Expression of Uncertainty in Measurement ) GUM ist eine internationale Norm welche das Ziel hat, die Vergleichbarkeit zwischen Messergebnissen herzustellen. Dazu wurden in der Norm GrundsÃ¤tze und Vorgehensweisen zur Bestimmung der Messunsicherheit festgelegt. GUM ist auf metrische Merkmale beschrÃ¤nkt. Vorgehen: Modellgleichung formulieren: $Y = f(X_1, \\dots, X_n)$, wobei $Y$ die MessgrÃ¶ÃŸe und $X_i$ die EingangsgrÃ¶ÃŸen sind. EingangsgrÃ¶ÃŸen und Unsicherheiten bestimmen (entweder durch Messreihen oder durch Erfahrungswerte / HandbÃ¼cher) SchÃ¤tzwert $\\hat{y}$ fÃ¼r MessgrÃ¶ÃŸe $Y$ bestimmen Ermittlung der kombinierten Unsicherheit Standardunsicherheit Die Standardunsicherheit einer Messung ist $$u_i = s(\\bar{x_i}) = \\sqrt{\\frac{s&#94;2(x_i)}{n}}$$ Dempster-Shafer-Theorie Slides: IF-Kap3_160125.pdf For this chapter, I highly recommend reading Anwendung der Dempster-Shafer Evidenztheorie auf die BonitÃ¤tsprÃ¼fung . Frame of discernment ( Wahrnehmungsrahmen ) Der Wahrnehmungsrahmen ist eine Menge $\\Omega$. Die Elemente dieser Mengen heiÃŸen Alternativen oder Aussagen. Eine Hypothese ist eine Teilmenge $H \\subseteq \\Omega$ des Wahrnehmungsrahmens. BasismaÃŸ ( basic probability mass ) Sei $\\Omega$ ein Wahrnehmungsrahmen und $$m: \\mathcal{P}(\\Omega) \\rightarrow [0, 1]$$ eine Abbildung von der Potenzmenge von $\\Omega$ in das Einheitsintervall. $m$ heiÃŸt BasismaÃŸ , wenn gilt: $m(\\emptyset) = 0$ $\\sum_{X \\subseteq \\Omega} m(X) = 1$ Belief function ( Glaubensfunktion ) Sei $\\Omega$ ein Wahrnehmungsrahmen, $m$ ein BasismaÃŸ und $$Bel: \\mathcal{P}(\\Omega) \\rightarrow [0, 1]$$ eine Funktion. $Bel$ heiÃŸt Glaubensfunktion, wenn gilt: $$Bel(X) := \\sum_{Y \\subseteq X} m(Y)$$ Die Glaubensfunktion stellt also eine untere Grenze fÃ¼r eine unbekannte Wahrscheinlichkeitsfunktion dar. Plausibility function ( PlausibilitÃ¤tsfunktion ) Sei $\\Omega$ ein Wahrnehmungsrahmen, $m$ ein BasismaÃŸ und $$Pl: \\mathcal{P}(\\Omega) \\rightarrow [0, 1]$$ eine Funktion. $Pl$ heiÃŸt PlausibilitÃ¤tsfunktion, wenn gilt: $$Pl(X) := \\sum_{Y \\cap X \\neq \\emptyset} m(Y)$$ Die PlausibilitÃ¤tsfunktion stellt also eine obere Grenze fÃ¼r eine unbekannte Wahrscheinlichkeitsfunktion dar. Fokale Ereignisse Ein Ereignis $A$ heiÃŸt fokal bzg. eines BasismaÃŸes $m$, wenn $m(A) \\neq 0$ gilt. Dempsters Kombinationsregel ( Dempsters rule of combination , DRC ) $$m_1 \\oplus m_2 (A) := \\begin{cases}0&\\text{for } A = \\emptyset\\\\ \\frac{\\sum_{X, Y: X \\cap Y = A} m_1(X) m_2(Y)}{|1-K|}\\end{cases}$$ fÃ¼r Konfliktgrad $$K := \\sum_{X, Y: X \\cap Y = \\emptyset} m_1(X) m_2(Y)$$ Bei einem Konfliktgrad von $0 < K < 1$ spricht man von einem partiellen Konflikt. Ist der Konfliktgrad gleich $K=1$, so ist DRC nicht anwendbar. DRC ist assoziativ und kommutativ, allerdings nicht idempotent. Es gilt also im Allgemeinen nicht $m \\oplus m = m$. Bei der Berechnung des Konfliktgrades genÃ¼gt es fokale Ereignisse zu betrachten. Bayessche Fusion Angenommen man hat eine Klassifikationsaufgabe. $z$ gehÃ¶rt einer der Klassen $A, B, C$ an. Nun liefert ein Klassifizierer $d_1$ die Wahrscheinlichkeitsverteilung $$m_1(A) = 0.01 \\qquad m_1(B) = 0.99 \\qquad m_1(C) = 0$$ und ein zweiter Klassifizierer $d_2$ liefert $$m_2(A) = 0.01 \\qquad m_2(B) = 0 \\qquad m_2(C) = 0.99$$ Gesucht ist eine Wahrscheinlichkeitsverteilung, welche die beiden Ergebnisse fusioniert. Da kein Vorwissen existiert, wird das Maximum-Entropie-Prinzip fÃ¼r die a priori Wahrscheinlichkeitsverteilung verwendet. Man geht also a priori davon aus, dass jede Klasse gleich wahrscheinlich ist: $$P(z) = (\\frac{1}{3}; \\frac{1}{3}; \\frac{1}{3})$$ Nun gilt: $$ \\begin{align} P(z | d_1, d_2)&= \\frac{P(d_1, d_2 | z) \\cdot P(z)}{P(d_1, d_2)}\\\\ &= \\frac{P(d_1 | z) \\cdot P(d_2 | d_1, z) \\cdot P(z)}{P(d_1, d_2)}\\\\ &\\overset{(1)}{=} \\frac{P(d_1 | z) \\cdot P(d_2 | z) \\cdot P(z)}{P(d_1, d_2)}\\\\ &= \\frac{\\begin{pmatrix}0.1\\\\0.99\\\\0\\end{pmatrix} \\cdot \\begin{pmatrix}0.1\\\\0\\\\0.99\\end{pmatrix} \\cdot \\begin{pmatrix}1/3\\\\1/3\\\\1/3\\end{pmatrix}}{P(d_1, d_2)}\\\\ &= \\frac{\\begin{pmatrix}1/300\\\\0\\\\0\\end{pmatrix}}{P(d_1, d_2)}\\\\ &\\overset{(2)}{=} \\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix}\\\\ \\end{align} $$ bei (1) wurde UnabhÃ¤ngigkeit vorausgesetzt, bei (2) wurde auf 1 normiert, damit eine Wahrscheinlichkeitsverteilung herauskommt. Fuzzy-Systeme Slides: IF-Kap4_160125.pdf Zur EinfÃ¼hrung: Fuzzy Logic - Computerphile Fuzzy Logic: An Introduction An Introduction to Fuzzy Logic : An example with breaks ZugehÃ¶rigkeitsfunktion ( membership function ) Sei $\\Omega$ ein Grundraum und $A$ eine unscharfe Menge, fÃ¼r die $\\mu_A: X \\rightarrow [0, 1]$ den Grad der ZugehÃ¶rigkeit definiert. $\\mu_A$ heiÃŸt ZugehÃ¶rigkeitsfunktion, wenn gilt $$\\mu_{\\Omega \\setminus A}(t) = 1 - \\mu_{A}$$ Gesetz vom ausgeschlossenen Dritten FÃ¼r eine beliebige Aussage muss mindestens die Aussage selbst oder ihr Gegenteil gelten. Dies gilt in der klassischen Mengenlehre, jedoch nicht fÃ¼r unscharfe Mengen. Gesetz vom ausgeschlossenen Widerspruch Zwei einander widersprechende Aussagen kÃ¶nnen nicht zugleich zutreffen. Dies gilt in der klassischen Mengenlehre, jedoch nicht fÃ¼r unscharfe Mengen. Fuzzy-Operationen Es seien $\\mu_A, \\mu_B$ die ZugehÃ¶rigkeitsfunktionen zweier unscharfer Mengen $A, B$ Ã¼ber dem Grundraum $\\Omega$. Dann gilt: Not: $$\\forall x \\in \\Omega: \\mu_{\\Omega \\setminus A}(x) = 1 - \\mu_A(x)$$ Konjunktion (AND, Minimum-T-Norm): $$\\forall x \\in \\Omega: \\mu_{A \\land B}(x) = \\min(\\mu_A(x), \\mu_B(x))$$ Disjunktion (OR, Maximum-T-Norm): $$\\forall x \\in \\Omega: \\mu_{A \\lor B}(x) = \\max(\\mu_A(x), \\mu_B(x))$$ Defuzzifizierung ( Defuzzification ) Unter Defuzzifizierung versteht man die Berechnung des scharfen Wertes der AusgangsgrÃ¶ÃŸe. Methoden: Schwerpunktverfahren Maximum-Mittelwert-Methode Schwerpunktverfahren ( center of gravity , COG ) Das Schwerpunktverfahren dient zur Defuzzifizierung. Maximum-Mittelwert-Methode ( Mean of maxima , MOM ) Das Schwerpunktverfahren dient zur Defuzzifizierung. Fuzzy-Fusion Definition linguistischer Variablen (z.B. Temperatur) und Terme (Werte der linguistischen Variablen, z.B. kalt, kÃ¼hl, lau, warm, heiÃŸ) ZugehÃ¶rigkeitsfunktionen definieren Fuzzifizierung: Transformation der vorliegenden Information mithilfe der ZugehÃ¶rigkeitsfunktionen in Fuzzy-konforme Form. ZugehÃ¶rigkeitsfunktionen bilden numerische Terme auf linguistische Variablen ab. Kombination der Terme durch Anwendung von Fuzzy-Logik in der Regelbasis. Die Regeln haben die Form IF PrÃ¤misse THEN Konklusion. Defuzzifizierung: Abbildung auf Ausgangsbasis (Schwerpunktregel, Maximummethode oder Maximum-Mittelwert Methode) Neuronale Netze Slides: IF-Kap5_160125.pdf Siehe Vorlesung Neuronale Netze Registrierung Slides: IF-Kap6_160125.pdf Wurde nicht besprochen. EnergieÂ­funktionale Slides: IF-Kap7_160125.pdf Funktional Ein Funktional ist eine Funktion aus einem Vektorraum $V$ in den KÃ¶rper, der dem Vektorraum zugrunde liegt. Oft ist $V$ ein Funktionenraum, also ein Vektorraum, dessen Elemente reell- oder komplexwertige Funktionen sind. Ein Funktional ist somit eine Funktion auf Funktionen. Energiefunktionale Durch die EinfÃ¼hrung von Energietermen $E_k$ lassen sich fusionsrelevante Informationen modellieren. Die Fusionsaufgabe wird dann durch das Energiefunktional $$E = \\sum_k \\lambda_k E_k, \\qquad \\lambda_k > 0$$ reprÃ¤sentiert. Die unterschiedliche Relevanz der Energieterme $E_k$ wird durch die Vorfaktoren $\\lambda_k$ berÃ¼cksichtigt. Gibbs-Verteilung Die Gibbs-Verteilung mit dem Energiefunktional $E$ ist $$\\pi_{\\beta, E}(x) = \\frac{1}{Z} e&#94;{- \\beta E(x)},$$ mit Normierungskonstante $Z$ und der inversen Temperatur $\\beta = \\frac{1}{T}$. Interpretation : Es sei $E: V \\rightarrow \\mathbb{R}$, $V$ endlich. $V$: Die Menge aller Konfigurationen eines physikalischen Systems. $E(x)$: Energie des Systems, wenn es sich in der Konfiguration $x$ befindet. $T$: Temperatur. Ist die Temperatur groÃŸ, so sind alle Konfigurationen etwa gleich wahrscheinlich. Bei niedriger Temperatur werden Konfigurationen mit niedriger Energie bevorzugt. $\\pi_{\\beta, E}(x)$: Wahrscheinlichkeit, dass sich das System in der Konfiguration $x$ befindet. FÃ¼r $E$ kann dann eine Gibbsche Wahrscheinlichkeitsdichtefunktion WDF $$WDF \\propto e&#94;{- \\beta E} = \\prod_k e&#94;{-\\frac{\\lambda_k E_k}{T}}$$ definiert werden. Energieminimierung LÃ¶sung eines linearen Gleichungssystems (selten mÃ¶glich) Graph-Cuts-Verfahren Approximative LÃ¶sung durch sukzessive Optimierung Methode des steilsten abstiegs Monte-Carlo-Methode Simulated Annealing Lineare Programme Dynamische Programmierung Mean Field Theorie (Betrachte Erwartungswerte) Ãœberblick Unsicherheitsmodellierung Wahrscheinlichkeiten Verallgemeinerte W-Keiten Linguistisch Neuronale Netze Fusion Bayes-Fusion DRC Fuzzy-Fusion Unsicherheiten Wahrscheinlichkeit in [0, 1] BasismaÃŸ in [0, 1] ZugehÃ¶rigkeit in [0, 1] AbkÃ¼rzungen EKF: Extended Kalman Filter GUM: Guide to the Expression of Uncertainty in Measurement KF: Kalman Filter LS: Least Squares UKF: Unscented Kalman Filter Meine Fragen Kapitel 1, Folie 61: Was ist der Definitions / Wertebereich von Information? Kapitel 2, Folie 5: Alle Ereignisse paarweise disjunkt Kapitel 2, Folie 22: Man muss fÃ¼r wirksame SchÃ¤tzer noch fordern, dass sie erwartungstreu sind. Es gibt immer den konstanten SchÃ¤tzer, welcher die Stichprobe ignoriert und somit eine Varianz von 0 hat. Kapitel 2, Folie 37: Was ist ein Arbeitspunkt? Kapitel 2, Folie 44f: Fusion 2er GrÃ¶ÃŸen / Verteilungen Kapitel 2, Folie 79: Was ist der Trunkation error? Was ist der base point error und warum ist es ein Problem, dass man um den SchÃ¤tzwert und nicht um den wahren Wert linearisiert? Ãœbungsaufgaben Die LÃ¶sungen sind auch online (ausfÃ¼hrlicher und besser als ich es hier habe). ÃœB 1 Aufgabe 1.1: http://math.stackexchange.com/q/1919394/6876 Aufgabe 1.2: \\(P(A) = 0.5 = P(B) = P(C)\\) , $$ \\begin{align} P(A) \\cdot P(B) &= 0.25 = P(A \\cap B)\\\\ P(A) \\cdot P(C) &= 0.25 = P(A \\cap C)\\\\ P(A) \\cdot P(B) \\cdot P(C) &= 0.125 \\neq 0.25 = P(A \\cap B \\cap C) \\end{align} $$ Daher sind die Ereignisse \\(A\\) und \\(B\\) , die Ereignisse \\(A, C\\) , die Ereignisse \\(B, C\\) unabhÃ¤ngig. Die Ereignisse \\(A, B, C\\) sind jedoch nicht unabhÃ¤ngig. Aufgabe 1.3a: \\(5 \\cdot (\\frac{1}{6} \\cdot \\frac{1}{6}) = \\frac{5}{36}\\) Aufgabe 1.3b: \\(\\frac{\\frac{2}{5} \\cdot \\frac{5}{36}}{1-0.25} = \\frac{2}{27}\\) Aufgabe 1.4: \\(P(X = 2) = P(X=12) = \\frac{1}{36}\\) \\(P(X = 3) = P(X=11) = \\frac{2}{36}\\) \\(P(X = 4) = P(X=10) = \\frac{3}{36}\\) \\(P(X = 5) = P(X=9) = \\frac{4}{36}\\) \\(P(X = 6) = P(X=8) = \\frac{5}{36}\\) \\(P(X = 7) = \\frac{6}{36}\\) \\(F(x) = \\sum_{i=2}&#94;x P(X = i)\\) \\(\\mathbb{E}(X) = 2 \\cdot 3.5 = 7\\) Aufgabe 1.5a: \\(\\int_0&#94;\\infty (\\alpha \\cdot \\exp(-\\alpha x)) \\mathrm{d}x = \\alpha \\int_0&#94;\\infty \\exp(-\\alpha x) \\mathrm{d}x = \\alpha [-\\frac{1}{\\alpha} \\exp(-\\alpha x)]_0&#94;\\infty = 1\\) Aufgabe 1.5b: Erwartungswert einer Zufallsvariable ist \\(\\int_{-\\infty}&#94;{+\\infty} x f(x) \\mathrm{d} x\\) . Aufgabe 1.6: \\(G\\) : E-mail ist geschÃ¤ftlich, \\(\\bar{G}\\) ist privat \\(S\\) : E-mail ist spam, \\(\\bar{S}\\) ist ham \\(F\\) : E-mail enthÃ¤lt das Wort \"Free\" \\(P(S | F) = \\frac{P(F | S) \\cdot P(S)}{P(F)} = \\frac{0.9 \\cdot 0.7}{0.9 \\cdot 0.7 + 0.01 \\cdot 0.3} = \\frac{210}{211}\\) ÃœB 2 Aufgabe 1.1: Die kontinuierliche Entropie ist kein resultat immer feiner werdender Diskretisierungen der diskreten Entropie Aufgabe 1.2a: \\(P(B \\cap L) = P(B) \\cdot P(L) = 1/3 \\cdot 1/3 = 1/9\\) Aufgabe 1.2b: 1/9 Aufgabe 1.2c: Das Prinzip der maximalen Entropie fÃ¼r Zufallsvariablen fÃ¼hrt zur UnabhÃ¤ngigkeitsannahme. Aufgabe 1.2d: Die Entropie wird im Erwartungswert reduziert, wenn eine GrÃ¶ÃŸe durch eine andere bedingt wird. Aufgabe 1.3a: \\(P(z=z_A| d_A) = 0.45\\) , \\(P(z=z_B| d_A) = 0.45\\) , \\(P(z=z_K| d_A) = 0.1\\) Aufgabe 1.3b: Ist hier ein Zahlendreher passiert? Aufgabe 1.4a: Mit \"Detektionsleistung\" ist gemeint, wie wahrscheinlich der Sensor ein Objekt detektiert, wenn eines da ist. Mit \"Klassifikationsleistung\" ist gemeint, wie Wahrscheinlich der Sensor bei vorhandenem Objekt dieses richtig klassifiziert. Aufgabe 1.4b: Zentralisierte Bayessche Fusion (Likelihoodmatrizen) Aufgabe 1.4c: Zentralisierte Bayessche Fusion (A-posteriori-Verteilung) Aufgabe 1.4d: Verteilte Fusion Aufgabe 1.5: Berechnung der Log-A-posteriori-Verteilung Aufgabe 1.6: 0.043 (Das typische Patenten-Test-Beispiel) ÃœB 3 Aufgabe 1.1: \\(Bel(A) = \\sum_{B \\subseteq A} m(B)\\) \\(Pl(A) = 1 - Bel(\\bar{A}) = \\sum_{B \\cap A \\neq \\emptyset} m(B)\\) Aufgabe 1.2a: Obwohl beide BasismaÃŸe dem Ereignis A eine sehr niedriges MaÃŸ zuweisen, ist es durch DRC das Ereignis mit dem hÃ¶chsten Wert. Das liegt daran, dass die anderen jeweils exakt 0 haben. Aufgabe 1.2b: Jeder einzelne Experte gab A nur geringen glauben. Dennoch wird A deutlich am meisten Glauben nach der Fusion geschenkt. Aufgabe 1.2c: Das gleiche Ergebnis. Aufgabe 1.3a: \\(m_{123}(111) = 0.82\\) , das Ergebnis ist also zu 82% glaubwÃ¼rdig. (SchÃ¶nes beispiel, dass DRC nicht idempotent ist) Aufgabe 1.3b: Rechnen mit BasismaÃŸen / DRC Aufgabe 1.3c: Rechnen mit BasismaÃŸen / DRC Aufgabe 1.4: \\(P(s=A | w=A) + P(s=B | w=B) = 0.6\\) Aufgabe 2.1: Spielen mit Fuzzy-Mengen Aufgabe 2.2: XOR fÃ¼r Fuzzy-Mengen PrÃ¼fungsfragen Welche Bedingungen mÃ¼ssen erfÃ¼llt sein, damit Informationen fusioniert werden kÃ¶nnen? â†’ Gemeinsamer Sachverhalt; kompatible Definitions- und Wertebereiche; Unsicherheitsbehaftet Welche Arten von Unsicherheit kennen Sie? â†’ Unsicherheit kann man mit Wahrscheinlichkeiten, BasismaÃŸe (Dempster-Shafer-Theorie) und Ã¼ber unscharfe Mengen (Fuzzy-Systeme) sowie Ã¼ber unsicheres Erfahrungswissen (Neuronale Netze) beschreiben. Was ist der Unterschied zwischen Wahrscheinlichkeiten und BasismaÃŸen? â†’ BasismaÃŸe sind nicht monoton und nicht additiv. Wie lautet die Formel fÃ¼r verteilte Bayessche Fusion? â†’ Wie zentrale bayessche Fusion, nur dass die Likelihood-Funktionen vorab berechnet werden (zweimaliges Anwenden der Bayes-Rule mit UnabhÃ¤ngigkeitsannahme zwischendurch) Wie lauten die Axiome von Kolmogorov? â†’ Siehe oben Was sind ZugehÃ¶rigkeitsfunktionen? â†’ Siehe oben Wie funktioniert Informationsfusion mit Fuzzy-Systemen? â†’ Siehe oben . Welche Vorteile bietet Informationsfusion? â†’ Siehe oben . Welche Eigenschaften sind bei Merkmalen wÃ¼nschenswert? â†’ Siehe oben . Welche Beziehung gilt zwischen Erwartungstreue und Konsistenz von SchÃ¤tzern? â†’ TODO Kalman-Filter Aus welchen Schritten besteht der Kalman-Filter? â†’ PrÃ¤diktion, Innovation Welche Erweiterungen zum Kalman-Filter kennen Sie? â†’ Extended Kalman Filter (EKF), UKF (Unscented Kalman Filter) FÃ¼r welche Systeme ist der Kalman-Filter geeignet? â†’ Lineare Zeitinvariante Systeme (LTI-Systeme) Wie entwickeln sich die Wahrscheinlichkeiten beim Kalman-Filter? â†’ Bei der PrÃ¤diktion steigt die Unsicherheit, bei der Innovation sinkt sie. Wie lautet das Systemmodell im Kalman-Filter? â†’ vgl. Kalman-Filter Artikel Absprachen Kapitel 5 (Neuronale Netze) und Kapitel 6 (Registrierung) kommen nicht dran. Ãœbungsaufgaben sind auch PrÃ¼fungsrelevant. Material und Links Vorlesungswebsite Anki-Deck Anwendung der Dempster-Shafer Evidenztheorie auf die BonitÃ¤tsprÃ¼fung Mein PrÃ¼fungsprotokoll Literatur: Bayes-Methoden : James O. Berger: Statistical Decision Theory and Bayesian Analysis. 2nd edition, Springer, 2006. ISBN 0-387-96098-8. Anwendungen : Rick S. Blum, Zheng Liu (Hrsg.): Multi Sensor Image Fusion and Its Applications. Taylor & Francis, 2006. ISBN 0849334179. Energiefunktionale : James J. Clark, Alan L. Yuille: Data Fusion for Sensory Information Processing Systems. Kluwer Academic Publishers, 1990. ISBN 0792391209. Fuzzy Logic : Jochen Heinsohn; Rolf Socher-Ambrosius: Wissensverarbeitung: eine EinfÃ¼hrung. Spektrum Akademischer Verlag, 1999. ISBN 3827403081. VorlesungsÂ­empfehlungen Folgende Vorlesungen sind Ã¤hnlich: Analysetechniken groÃŸer DatenbestÃ¤nde Informationsfusion Machine Learning 1 Machine Learning 2 Mustererkennung Neuronale Netze Lokalisierung Mobiler Agenten Probabilistische Planung Termine und Klausurablauf Es ist eine mÃ¼ndliche PrÃ¼fung. Ich habe meine am Fraunhofer IOSB, Fraunhoferstr. 1, 76131 Karlsruhe am 11.10.2016 um 15:30 Uhr bei Herrn Dr. Heizmann.","tags":"German posts","title":"Informationsfusion"},{"url":"https://martin-thoma.com/lma/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žLokalisierung Mobiler Agenten\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Dr.-Ing. Gerhard Kurz im Sommersemester 2016 gehÃ¶rt. Behandelter Stoff Ãœbersicht Datum Kapitel Inhalt 17.05.2016 5. Vorlesung Hessische Normalform, Least Squares 24.05.2016 6. Vorlesung Least Squares 21.06.2016 10. Vorlesung OptimalitÃ¤tsbeweise (Erwartungstreue); Stochastische Kombination 28.06.2016 11. Vorlesung Dynamische Lokalisierung (Kalman Filter: PrÃ¤diktions und Filterschritt) 05.07.2016 12. Vorlesung Kalman Filter: Filterschritt; SLAM 12.07.2016 13. Vorlesung Particle Filter, SLAM Statische Lokalisierung Slides: 20160517-lma-1 Hessische Normalform ( Hesse normal form ) An equation describing a plane: $$x \\cdot n - d = 0$$ where $x$ is a point, $n$ is the normal of the plane and $d$ is the distance of the plane to $0$. Methode der kleinsten Quadrate ( Least Squares Methode ) Bei der Lokalisierung mobiler Agenten in einem Raum mit 4 WÃ¤nden genÃ¼gen zwei nicht-parallele Abstandsmessungen. Hat man mehr Messungen, so kann man mit der Methode kleinster Quadrate die beste Position bestimmen. Der Fehler ist dann $e = y - H x$. Damit definiert man das GÃ¼temaÃŸ $$G(x) = (y- Hx)&#94;T W&#94;{-1} (y-Hx)$$ wobei $W&#94;{-1}$ eine symmetrisch positiv definite Gewichtungsmatrix ist. Rekursive Methode kleinster Quadrate Wenn bereits einmal die beste Ebene bestimmt wurde will man nicht wieder alles neu berechnen, wenn ein neues Sensorergebnis hinzukommt. Bei uns mit Vektorwertigen Sensoren, nicht wie im wie im Skript mit Skalaren. Slides: 6. Vorlesung Sherman-Morrison-Woodbury Formel FÃ¼r zwei $n\\times k$-Matrizen $U, V$ gilt: Die $k\\times k$-Matrix $E-V&#94;T A&#94;{-1}U$ sei regulÃ¤r, dann gilt $$(A-UV&#94;T)&#94;{-1} = A&#94;{-1}+A&#94;{-1}U(E-V&#94;TA&#94;{-1}U)&#94;{-1}V&#94;T A&#94;{-1}$$ Dynamische Lokalisierung Kalman-Filter Siehe Kalman-filter Artikel . SLAM SLAM ( Simultaneous Location and Mapping ) SLAM ist ein Algorithmus, welcher zugleich eine Karte erstellt und einen mobilen Agenten auf der Karte lokalisiert. Eine Karte sind positionen von Landmarken. AnsÃ¤tze : Filterung (rekursiv): z.B. Kalman-Filter; EKF , UKF (sigma-Punkte / samples; einfach zu implementieren und liefert hÃ¤ufig bessere Ergebnisse als EKF), Partikelfilter (Wahrscheinlichkeitsdichten werden durch Partikel / samples reprÃ¤sentiert) $\\Rightarrow$ SchÃ¤tzen fÃ¼r Zeitschritt Smoothing / GlÃ¤ttung (batch): Nachteile (Rechenaufwendig, erst nach batch ist Ergebnis da, man muss Daten speichern) und Vorteile (komplette Trajektorie, optimale SchÃ¤tzung selbiger); z.B. Graph-based SLAM Loop Closure : Wenn der Agent wieder an einen Punkt kommt, an dem er bereits war, kann ein Kreis geschlossen werden. Daher kÃ¶nnen die vorherigen Landmarken im Kreis neu geschÃ¤tzt werden. Allerdings kann ein falsches Loop Closure zur Divergenz des Filters fÃ¼hren. Herausforderungen : Datenassoziation: Erkennen ob Landmarken die gleichen sind. KomplexitÃ¤t (groÃŸe Karte) VerÃ¤nderung der Umgebung: z.B. Auto als Landmarke erkannt; neue BrÃ¼cke kommt hinzu oder wurde abgerissen NichtlinearitÃ¤ten des Prolems Landmarke Ein gut sichtbares / wiedererkennbares Objekt, welches zur Abstandsmessung benutzt werden kann. EKF SLAM EKF SLAM basiert auf dem Extended Kalman Filter. Vereinfachungen : Problem in 2D Feste Zahl von punktfÃ¶rmigen Landmarken Assoziationen bekannt: Landmarken werden zuverlÃ¤ssig erkannt und nicht verwechselt. Zustand $\\mathbf{x}_k = [\\underbrace{x_k, y_k, \\theta_k}_{\\text{Pose des Roboters}}, \\underbrace{m_{1, x}, m_{1, y}}_{\\text{LM 1}}, \\dots, \\underbrace{m_{M, x}, m_{M, y}}_{\\text{LM } M}]$ Dimension von $\\mathbf{x}_k$: $3 + 2 M$. Kovarianz hat $(3+2M)&#94;2$ Elemente, d.h. der Speicheraufwand ist quadratisch in der Zahl der Landmarken. Systemgleichung: $x_{k+1} = a_k (x_k, M_k) + w_k$ $x_{k+1} \\approx A_k x_k + w_k,$ wobei $A_k$ Jaccobi-Matrix von $a_k(x_k, u_k)$ fÃ¼r festes $u_k$ an der Stelle $\\hat{x}_k&#94;e$. Messgleichung: $y_k = h(x_k) + v_k$ In der Regel sind nicht alle Landmarken zugleich sichtbar. In diesem Fall werden Zeilen in der Messabbildung weggelassen. $$y_k = H_k(x_k) + v_k,$$ wobei $H_k$ die Jaccobi-Matrix von $h(x_k)$ an der Stelle $\\hat{x}_k&#94;P$ ist. Particle Filter ( Partikelfilter , Sequential Monte Carlo , SMC ) Idee: SchÃ¤tze Zustand Ã¼ber Partikel. Ansatz : Sample aus Tranistionsdichte $$f(x_{k+1} | x_k = p_k&#94;1, u_k$$ Implementierung: Rauschen $w_k$ samples $\\rightarrow v_k&#94;1, \\dots, v_k&#94;N$ Propagiere durch $x_{k+1} = a_N(x_N, u_N) + w_N$, d.h. $p&#94;1_{k+1} = a_k (p_k&#94;1, u_k) + v_k&#94;1$ Gewichte bleiben gleich Problem : Viele Partikel $p_k&#94;i$ haben geringes Gewicht $w_k&#94;i$ LÃ¶sung : Resampling mit sequential importance resampling (SIR: ziehe $N$ neue Partikel mit Gewichten $\\frac{1}{n}$ aus Menge der alten Partikel, wobei die Wahrscheinlichkeit das Partikel $p_k&#94;i$ zu ziehen gerade $w_k&#94;i$ ist.) Material und Links Die Vorlesung wurde gestreamt und ist unter mml-streamdb01.ira.uka.de verfÃ¼gbar. Vorlesungswebsite Literatur und Links: SLAM-Vorlesung der Uni Freiburg ( Material ) Vorlesungsempfehlungen Folgende Vorlesungen sind Ã¤hnlich: Analysetechniken groÃŸer DatenbestÃ¤nde Informationsfusion Machine Learning 1 Machine Learning 2 Mustererkennung Neuronale Netze Lokalisierung Mobiler Agenten Probabilistische Planung Termine und Klausurablauf Es ist eine mÃ¼ndliche PrÃ¼fung.","tags":"German posts","title":"Lokalisierung Mobiler Agenten"},{"url":"https://martin-thoma.com/tools-for-academia/","text":"When you're studying or researching, there a quite a couple of tools which come in very handy in various situations. In the last 5 years at university I got to know quite a few, so I want to share my list with you. Discovery Sometimes, I just like to stumble around some papers. I'm not actively searching anything, but just looking for something interesting. In my field of research, gitxiv.com is really interesting for that. But also the recent papers at arXiv and trendingarxiv . I know that a couple of people recently liked arxitics.com and control.kylemcdonald.net/arxiv , but I'm not using that too much. See also: How to find new Papers Search When I'm actively searching for papers where you know keywords, scholar.google.com is the search engine of my choice. academic.microsoft.com could be an interesting alternative. Summaries and Explanations A site which I discovered in the beginning of 2016 is shortscience.org . It gives you the possibility to save and share your summaries of papers. Have a look at my profile if you're interested. The service is still in its early stages, but I like it very much. Scholarpedia.org is a site where you can finde some high-quality explanations. If I remember right, Hinton wrote some articles on Scholarpedia. Of course, Wikipedia is always an option to get introduced to basics. Writing I do the actual writing with Sublime Text . Typesetting The typesetting system of my choice is LaTeX . It produces beautiful results, especially for mathematical formulae. A couple of years ago I wrote some installation instructions . If you need help with something specific, tex.stackexchange.com is really nice. If you're only looking for a symbol to write with LaTeX, I can recommend write-math.com . Other options are available, too. Content If I have questions about academic writing (the content), then academia.stackexchange.com is the site of my choice. Spell- and Stylechecking I use aspell for spellchecking and Academic-Writing-Check to get some ideas where I might improve my writing style. Reference Management I like JabRef as it is in the standard repositories of Ubuntu and works out of the box to manage my references. I use it to fill my BibTeX files and add as much content to papers as I can. JabRef also has some nice options to find / open the paper for yourself. Publishing arxiv.org is one of the best places to publish your paper quickly. Even faster, but a lot less reach has zenodo.org . The nice thing about Zenodo is that you can share datasets, too. Zenodo also gives all your uploads a DOI and offers visitors various ways to cite it. For example, for my HWRT database the BibTeX entry is @misc { thoma _ 2015 _ 50022, author = { Thoma, Martin } , title = { HWRT database of handwritten symbols } , month = jan, year = 2015, doi = { 10.5281/zenodo.50022 } , url = { http://dx.doi.org/10.5281/zenodo.50022 } } Building a Profile I'm not sure how important this is in Science, but there are some social networks for researchers. ORCiD is one site which aims to give researchers unique numbers so that you can track who wrote what, even if people are in the same field of research and have the same names. It also allows you to add a CV as you can see with my ORCiD . Google Scholar offers a simple version of that, too. See my profile or the profile of Hinton . More Sci-Hub academictorrents.com : I just found this on Reddit csauthors.net to calculate your ErdÃ¶s number Machine Learning: Keras TensorFlow ml-ka.de paper discussion group and the ML-KA Facebook Group for news What do you use?","tags":"Science","title":"Tools for Academia"},{"url":"https://martin-thoma.com/probabilistische-planung/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žProbabilistische Planung\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Dr.-Ing. Marco Huber im Sommersemester 2015 und 2016 gehÃ¶rt. Die Inhalte sind dementsprechend stark an der Vorlesung angelehnt bzw. komplette Teile sind daraus Ã¼bernommen. In der Vorlesung 'Probabilistische Planung' fÃ¼hrt in das Thema Reinforcement Learning ein. Dabei werden drei Themenfelder besprochen: Markov'sche Entscheidungsprobleme (MDPs) Planung bei Messunsicherheiten (POMDPs) Reinforcement Learning (RL) An Algorithmen sind insbesondere der Label-Korrektur-Algorithmus, das Dynamische Programmieren, der Kalman-Filter sowie die value- und policy iteration zu nennen. Behandelter Stoff # Datum Kapitel Inhalt 1 26.04.2016 Grundlagen Wahrscheinlichkeitsraum, Grundraum, EreignisÂ­raum, Resultate, ElementarÂ­ereignis, $\\sigma$-Algebra, WahrscheinlichkeitsÂ­maÃŸ, Bedingte Wahrscheinlichkeit, Ziegenproblem, Dichtefunktion 2 28.04.2016 Grundlagen Allais-Paradoxon , Nutzentheorie, PrÃ¤ferenzrelation , Nutzenfunktion 3 06.05.2016 Grundlagen EinfÃ¼hrung in die Optimierungstheorie: Notwendige und Hinreichende Bedingungen, Konvexe Optimierung, Numerische Methoden (z.B. iterativer Abstieg ) 4 11.05.2016 MDPs Definition eines MDP, Plan vs. Strategie, OptimalitÃ¤tsprinzip, DP 5 18.05.2016 MDPs Endliche Planungsprobleme, Value- und Policy Iteration 6 25.05.2016 MDPs KÃ¼rzeste-Wege Suche (Tiefensuche, Breitensuche, Dijkstra, A*, Branch & Bound; Label-Korrektur-Algorithmus); Trellis-Diagramm; Differentialantrieb; Pontryagin's Minimumprinzip 7 01.06.2016 MDPs ( Folien ) Pontryagin's Minimumprinzip, Hamilton-Funktion , Riccati-Gleichung; LQR ; SicherheitsÃ¤quivalenz Aufgabe 11, Aufgabe 12, Aufgabe 13 8 08.06.2016 POMDPs Motivation und Definition von POMDP; Hinreichende Statistik; Bayes-SchÃ¤tzer Aufgabe 14 9 15.06.2016 POMDPs Lineare Planungsprobleme (Kalman-Filter); Sperationsproblem; LQR , Endliche Planungsprobleme 10 22.06.2016 POMDPs Endliche Planungsprobleme (Optimale Strategie, $\\alpha$-Vektoren); Approximative Planung: OL , OLF , ModellprÃ¤diktive Planung Aufgabe 16 11 29.06.2016 POMDPs EKF , Parametrische / Nichtparametrische approximative Planung (SicherheitsÃ¤quivalenz bei deterministischen Problemen); Funktionsapproximatoren fÃ¼r Wertefunktion / Strategie; Sensoreinsatzplanung Aufgabe 18 12 06.07.2016 POMDPs, RL Lineare Probleme; POMDPs: Sensoreinsatzplanung Aufgabe 19 13 13.07.2016 RL Monte Carlo Verfahren (Strategiebewertung), Exploration vs Exploitation, Explorations-Strategien; policy iteration; Temporal Difference Verfahren (Einschritt TD, Mehrschritt TD) Aufgabe 20 14 20.07.2016 RL Eligibility Traces (TD-Verfahren); Funktionsapproximatoren; Modellernende Verfahren ( Dyna-Q , Adaptive DP , PILCO) Folien: 25.05.2016: Folie 4 - Die Knoten sind ZustÃ¤nde und die Kanten sind Aktionen \\(g_{ij}&#94;k = \\infty\\) : Kein Ãœbergang von \\(i\\) nach \\(j\\) in Schritt \\(k\\) . Grundlagen Slides: ProPlan-1-Anschrieb.pdf $\\sigma$-Algebra Sei $S$ eine Menge und $\\mathcal{A}$ ein Menge aus Teilmengen von $S$. $\\mathcal{A}$ heiÃŸt eine $\\sigma$-Algebra Ã¼ber $S$, genau dann, wenn gilt: $S \\in \\mathcal{A}$ $\\forall M \\in \\mathcal{A} \\Rightarrow (S \\setminus M) \\in \\mathcal{A}$ $M_1, M_2, \\dots \\in \\mathcal{A} \\Rightarrow \\bigcup_{n \\in \\mathbb{N}} M_n \\in \\mathcal{A}$ WahrscheinlichkeitsmaÃŸ ( Probability measure ) Eine Funktion $P: \\mathcal{A} \\rightarrow \\mathbb{R}$ (mit $\\mathcal{A}$ ist Sigma-Algebra Ã¼ber der Grundmenge $S$) heiÃŸt WahrscheinlichkeitsmaÃŸ , wenn die Kolmogorov'schen Axiome gelten: Nicht-negativitÃ¤t: $\\forall M \\in \\mathcal{A}: P(M) \\geq 0$ Normiertheit: $\\forall P(S) = 1$ $M_1, M_2 \\in \\mathcal{A} \\land M_1 \\cap M_2 = \\emptyset \\Rightarrow P(M_1 \\cup M_2) = P(M_1) + P(M_2)$ Normalverteilung Die Normalverteilung $\\mathcal{N}(\\mu, \\sigma&#94;2)$ ist eine kontinuierliche Verteilung mit der Dichtefunktion $$f(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma&#94;2}} e&#94;{- \\frac{(x - \\mu)&#94;2}{2\\sigma&#94;2}}$$ Die multivariate Normalverteilung $\\mathcal{N}(\\mu, \\Sigma)$ hat die Dichtefunktion $$f(x) = \\frac{1}{ \\sqrt{(2\\pi)&#94;n \\det(\\Sigma)} } \\exp \\left(-\\frac{1}{2}({\\mathbf x}-{\\boldsymbol\\mu})&#94;\\mathrm{T}{\\boldsymbol\\Sigma}&#94;{-1}({\\mathbf x}-{\\boldsymbol\\mu}) \\right)$$ Markov'sche EntscheidungsÂ­probleme Slides: 11.05.2016 Markov'sches Entscheidungsproblem ( Markov Decision Process , MDP ) Ein MDP wird durch 8 Eigenschaften gekennzeichnet: Zustandsraum $X \\subseteq \\mathbb{R}&#94;n$ mit ZustÃ¤nden $x \\in \\mathcal{X}$. Diskrete Zeitschritte $k=0, 1, \\dots, N$ mit Endzeitpunkt $N$. Dabei ist der 0-te Schritt gegeben. Initialzustand $x_o \\in \\mathcal{X}$ des Agenten zum Zeitpunkt $k=0$. Nichtleere Aktionsmenge $A_k(x_k) \\subseteq A$ mit Aktion $a_k$. HÃ¤ufig $A_k(x_k)=A$ fÃ¼r alle $k=0, \\dots, N$ (Zeit- und Zustandsinvarianz) Ãœbergangswahrscheinlichkeit $x_{k+1} \\sim P_x(\\cdot | x_k, a_k)$. Markov-Annahme: $P_x(\\cdot | x_k, a_k) = P(\\cdot | x_{0:k}, a_{0:k})$, wobei die Notation $x_{0:k} = x_0, x_1, \\dots, x_k$ bedeutet. Das heiÃŸt, der Folgezustand ist nur vom Zustand $x_k$ und der gewÃ¤hlten Aktion $a_k$ abhÃ¤ngig. Im Fall diskreter ZustÃ¤nde ist die ÃœbergangsÂ­wahrscheinlichkeit eine bedingte ZÃ¤hldichte: $$f(x_{k+1} | x_k, a_k) = P_x(x=x_{k+1} | x_k, a_k)$$ Bei kontinuierlichen ZustÃ¤nden eine bedingte WahrscheinlichkeitsÂ­dichte: $$f(x_{k+1} | x_k, a_k) = \\frac{\\partial F(x | x_k, a_k)}{\\partial x} |_{x=x_{k+1}}$$ Additive Kostenfunktion $$g_N (x_N) + \\sum_{k=0}&#94;{N-1} g_k(x_k, a_k)$$ wobei $g_N$ die terminalen Kosten und $g_k$ Schrittkosten genannt werden. Der Zustand ist fÃ¼r jedes $k$ direkt beobachtbar . Vor Anwendung bzw Auswahl einer Aktion $a_k$ zum Zeitpunkt $k$ $$x_{k+1} \\sim P_x(\\cdot | x_k, a_k)$$ wobei $x_k, a_k$ exakt bekannt sind. Nach Anwendung der Aktion $a_k$ zum Zeitpunkt $k+1$ ist $x_{k+1}$ exakt bekannt. Ziel : Minimierung der erwarteten Kosten $$J_{\\pi_{0:N-1}}(x_0) := \\mathbb{E} \\left (g_N(x_k) + \\sum_{k=0}&#94;{N-1} g_k (x_k, \\pi_k(x_k)) \\right )$$ bzgl. einer Strategie $\\pi_{0:N-1} = (\\pi_0, \\pi_1, \\dots, \\pi_{N-1})$ mit Funktionen $\\pi_k(x_k) = a_k \\in A_k(x_k)$. Policy ( Strategie ) Eine Strategie $\\pi: S \\rightarrow A$ ist die Vorschrift, in welchem Zustand welche Aktion ausgefÃ¼hrt werden soll. Eine Strategie ist ein Plan mit ZustandsrÃ¼ckfÃ¼hrung. PrÃ¤ferenzrelation Sei $\\mathcal{X}$ eine Zustandsmenge und $\\geq \\subseteq \\mathcal{X} \\times \\mathcal{X}$ eine binÃ¤re Relation auf $\\mathcal{X}$. $\\geq$ heiÃŸt (schwache) PrÃ¤ferenzrelation, wenn gilt: $\\geq$ ist vollstÃ¤ndig: $\\forall x, y \\in \\mathcal{X}: x \\geq y \\lor y \\geq x$ $\\geq$ ist transitiv: $\\forall x, y, z \\in \\mathcal{X}: x \\geq y \\land y \\geq z \\Rightarrow x \\leq z$ Indifferenz Zwei Elemente $x, y \\in \\mathcal{X}$ heiÃŸen bzgl. einer PrÃ¤ferenzrelation $\\geq \\subseteq \\mathcal{X} \\times \\mathcal{X}$ indifferent, wenn gilt: $$x \\leq y \\land y \\leq x$$ Nutzenfunktion Sei $\\mathcal{X}$ eine Zustandsmenge und $u: \\mathcal{X} \\rightarrow \\mathbb{R}$ eine Funktion. Sei auÃŸerdem $\\geq$ eine PrÃ¤ferenzrelation. $u$ heiÃŸt eine Nutzenfunktion welche $\\geq$ abbildet, wenn gilt: $$\\forall x, y \\in \\mathcal{X}: x \\geq y \\Leftrightarrow u(x) \\geq u(y)$$ Jede PrÃ¤ferenzrelation hat mindestens eine Nutzenfunktion. Sie ist eindeutig bis auf streng monoton steigende Transformationen. Von-Neumann-Morgenstern Axiome Sei $\\mathcal{X}$ eine Zustandsmenge und $\\mathcal{P}$ die Menge aller Verteilungen $P: \\mathcal{X} \\rightarrow [0, 1]$. $\\geq$ ist eine PrÃ¤ferenzrelation UnabhÃ¤ngigkeitsaxiom: Gilt fÃ¼r $P, Q \\in \\mathcal{P}$ die Beziehung $P \\geq Q$, dann gilt auch: $$\\alpha \\cdot P + (1 - \\alpha) \\cdot R \\geq \\alpha \\cdot Q + (1 - \\alpha) \\cdot R$$ fÃ¼r beliebiges $R \\in \\mathcal{P}$ und beliebiges $\\alpha \\in [0, 1]$. Salopp: StÃ¶rungen $R$ beeinflussen die PrÃ¤ferenz von $P$ und $Q$ nicht. Stetigkeitsaxiom: FÃ¼r beliebige $P, Q, R \\in \\mathcal{P}$ mit $P > Q > R$ gibt es $\\alpha, \\beta \\in (0, 1)$ derart, dass $$\\alpha \\cdot P + (1 - \\alpha) \\cdot R > Q > \\beta \\cdot P + (1-\\beta)R$$ gilt. Salopp: PrÃ¤ferenzrelationen sind nicht anfÃ¤llig gegenÃ¼ber kleinen Ã„nderungen. Allais Paradoxon Das Allais-Paradoxon ist ein experimentell beobachtbarer VerstoÃŸ gegen das UnabhÃ¤ngigkeitsaxiom der wirtschaftswissenschaftlichen Entscheidungstheorie. Dieses besagt, dass die Hinzu-/Wegnahme von gemeinsamen Konsequenzen einer Entscheidung die PrÃ¤ferenz des Entscheiders nicht verÃ¤ndern darf. Lotterie 1: a: $P(X = 2500) = 0.33$, $P(X = 2400) = 0.66$, $P(X = 0) = 0.01$ b: $P(X = 2400) = 1$ Lotterie 2: a': $P(X = 2500) = 0.33$, $P(X = 0) = 0.67$ b': $P(X = 2400) = 0.34$, $P(X = 0) = 0.66$ Rationale Entscheidung Folgt eine PrÃ¤ferenzrelation $\\geq$ den Von-Neumann-Morgenstern-Axiomen, so werden Planungsentscheidungen auf der Grundlage von $\\geq$ als rational bezeichnet. Satz der rationalen Entscheidungen (PrPlan-2, Folie 19) Eine Relation $\\geq$ auf $P$ erfÃ¼llt die Von-Neumann-Morgenstern Axiome genau dann, wenn eine Funktion $u: X \\rightarrow \\mathbb{R}$ existiert, sodass $$P \\geq Q \\Leftrightarrow \\mathbb{E}_P (u(x)) \\geq E_Q (u(x))$$ gilt. Die Funktion $u$ ist bist auf affine Transformationen $$c \\cdot u(x) + d \\text{ mit } c>0$$ eindeutig. Kritik an der Nutzentheorie Die Nutzenfunktion kann nicht systematisch konstruiert werden. Die Nutzenfunktion bzw. -theorie stimmt nicht mit der Menschlichen Intuition Ã¼berein (vgl. Allais Paradoxon ) Verteilungen mÃ¼ssen bekannt sein. Alternative : MinMax Optimierungsproblem Ein allgemeines optimierungsproblem besteht aus einer Optimierungsvariable $x \\in \\mathbb{R}&#94;n$, fÃ¼r welche ein \"bester\" Parameter gewÃ¤hlt werden soll. DafÃ¼r gibt es eine Bewertungsfunktion $f$ (Zielfunktion): $$ \\begin{align} &\\underset{x}{\\operatorname{minimize}}& & f(x) \\\\ &\\operatorname{subject\\;to} & &g;_i(x) \\leq 0, \\quad i = 1,\\dots,m \\\\ &&&h;_i(x) = 0, \\quad i = 1, \\dots,p \\end{align} $$ Siehe auch: Optimization Basics Positiv Definite Matrix Eine Matrix $A \\in \\mathbb{R}&#94;{n \\times n}$ heiÃŸt positiv definit, wenn $$x&#94;T A x > 0 \\quad \\forall x \\in \\mathbb{R}&#94;n \\setminus \\{0\\}$$ Ã„quivalent gilt: $A$ heiÃŸt positiv definit, wenn alle Eigenwerte von $A$ positiv definit sind. Notwendige Bedingung fÃ¼r optimale LÃ¶sung $\\nabla f(x) \\overset{!}{=} 0$ Hinreichende Bedingung fÃ¼r optimale LÃ¶sung $\\nabla f(x) \\overset{!}{=} 0$ und $\\nabla&#94;2 f(x) =: H_f$ ist positiv definit. Dabei ist $H_f$ die Hessematrix: $$\\begin{pmatrix} \\frac{\\partial&#94;2 f}{\\partial x_1 \\partial x_1} & \\dots & \\frac{\\partial&#94;2 f}{\\partial x_1 \\partial x_l}\\\\ \\vdots & \\ddots & \\vdots\\\\ \\frac{\\partial&#94;2 f}{\\partial x_l \\partial x_1} & \\dots & \\frac{\\partial&#94;2 f}{\\partial x_l \\partial x_l} \\end{pmatrix}$$ Allerdings ist diese Bedingung nicht notwendig. Beispielsweise ist fÃ¼r $$f(x) = x&#94;4$$ an der Stelle $x=0$ das globale Minimum. Es gilt: $$\\nabla f(x) = 4 x&#94;3$$ und $$H_f(x&#94;*) = 12 (x&#94;*)&#94;2 = 0$$ Damit ist $H_f(x&#94;*)$ nicht positiv definit und somit keine Entscheidung darÃ¼ber mÃ¶glich, ob $x&#94;* = 0$ ein Minimum ist. Ableitungsregeln fÃ¼r Matrizen Es seien im Folgenden $x, a$ Vektoren. $$\\frac{\\partial x&#94;T a}{\\partial x} = \\frac{\\partial a&#94;T x}{\\partial x} = a$$ Es sei $A$ eine quadratische Matrix: $$\\frac{\\partial x&#94;T A}{\\partial x} = \\frac{\\partial A x}{\\partial x} = A$$ $$\\frac{\\partial x&#94;T A x}{\\partial x} = 2 A x$$ Konvexe Optimierungsprobleme Eine Funktion $f: \\mathbb{R}&#94;l \\rightarrow \\mathbb{R}$ heiÃŸt konvex , wenn gilt: $$f(\\Theta u + (1 - \\Theta) \\cdot v) \\leq \\Theta f(u) + (1-\\Theta) \\cdot f(v)$$ fÃ¼r beliebige $u, v \\in \\mathbb{R}&#94;l$ und $\\Theta \\in [0, 1]$ gilt. Salopp : Der Graph der Funktion ist unter der Sekante. Ein Optimierungsproblem heiÃŸt konvex , wenn die Gleichungsnebenbedingungen affin und die Zielfunktion sowie die Ungleichungsnebenbedingungen konvex sind. Ein Optimierungsproblem mit konvexer Zielfunktion $f$ hat folgende besonderen Eigenschaften Jedes lokale Optimum ist ein globales Optimum. Ein strikt konvexes Optimierungsproblem hat ein eindeutiges Optimum. Die notwendige Bedingung ist auch hinreichend: Ohne Nebenbedingungen: $\\nabla f(x) \\overset{!}{=} 0$ Mit Nebenbedingungen: $(\\nabla f(x&#94;*))&#94;T \\cdot (x - x&#94;*) \\geq 0 \\quad \\forall x \\in \\mathcal{F}$, wobei $\\mathcal{F}$ eine konvexe Menge ist. Iterativer Abstieg ( Iterative Descent ) Der Iterative Abstieg ist ein numerisches Optimierungsverfahren ohne Nebenbedingungen. Man geht wie folgt vor: WÃ¤hle einen Startwert $x_k$ mit $k=0$ beliebig. WÃ¤hle einen weiteren Wert $$x_{k+1} = x_k + \\alpha \\cdot d_k$$ wobei $\\alpha > 0$ die Schrittweite (oder Lernrate) genannt wird. $d_k$ ist die Abstiegsrichtung. Weiter zu 2. Wahl der Abstiegsrichtung : Taylor-Reihenentwicklung von $f$ um $x_k$: $$f(x_{k+1}) = f(x_k + \\alpha d_k) = f(x_k) + \\underbrace{\\alpha_k \\nabla f(x_k)&#94;T \\cdot d_k}_{\\text{dominiert } O(\\alpha_k) \\text{ fÃ¼r kleine } \\alpha_k} + O(\\alpha_k)$$ WÃ¤hle dann $\\alpha_k \\nabla f(x_k)&#94;T \\cdot d_k < 0 \\Rightarrow$ $f(x_{k+1}) < f(x_k)$, d.h. der Gradient und die Abstiegsrichtung mÃ¼ssen einen Winkel von mehr als 90Â° einschlieÃŸen. HÃ¤ufig wird $d_k = - D_k \\nabla f(x_k)$ gewÃ¤hlt, wobei $D_k$ eine positiv definite Matrix ist. Gradientenabstieg (\"Steilster Abstieg\"): $D_k = I$ Newton-Verfahren: $D_k = H_f&#94;{-1}(x_k)$ wobei $H_f$ die Hesse-Matrix von $f$ ist Wahl der Schrittweite : $\\alpha_k$ konstant $\\alpha_k$ (streng) monoton fallend Liniensuche, d.h. Optimierung bzgl. $\\alpha_k$: $\\alpha_k&#94;* = \\text{arg }\\min_{\\alpha > 0} f(x_k + \\alpha_k d_k)$ Bellman-Gleichungen Eine Bellman-Gleichung stellt die LÃ¶sung eines Problems rekursiv dar. Sie zeigt, dass und wie man die LÃ¶sung eines komplexen Problems aus LÃ¶sungen von Teilproblemen aufbauen kann. Die Belmann-Gleichungen lauten: $$ \\begin{align} J_N(x_n) &= g_N(x_N)\\\\ J_k(x_k) &= \\min_{a_k \\in A_k(x_k)} \\left (g_k(x_k, a_k) + \\mathbb{E}(J_{k+1}(x_{k+1})| x_k, a_k) \\right ) \\end{align} $$ Probleme, fÃ¼r die man eine Bellman-Gleichung aufstellen kann haben optimale Substruktur . Example with the value function: $$V(s) = \\max_{a} (R(s, a) + \\gamma \\sum_{s'} T(s, a, s') V(s'))$$ where $V(s)$ is the value of the state $s$, $R(s,a)$ is the reward you get when you apply action $a$ in state $s$, $\\gamma \\in [0, 1]$ is the discount factor, $T(s, a, s') \\in [0, 1]$ is the transormation matrix which gives you the probability that you will end up in state $s'$ when you apply action $a$ in state $s$. Differentiation Rules $$ \\begin{align} \\frac{\\partial x&#94;T a}{\\partial x} &= \\frac{\\partial a&#94;T x}{\\partial x} = a\\\\ \\frac{\\partial x&#94;T A}{\\partial x} &= \\frac{\\partial A x}{\\partial x} = A \\qquad A \\in \\mathbb{R}&#94;{n \\times n}\\\\ \\frac{\\partial x&#94;T A x}{\\partial x} &= 2 A x \\qquad A \\in \\mathbb{R}&#94;{n \\times n} \\end{align} $$ $Q$-Funktion ( Action-Value function , Quality function ) Die Funktion $Q&#94;\\pi: S \\times A \\rightarrow \\mathbb{R}$ gibt den erwarteten Wert einer eines Zustandes $s$ unter der Strategie $\\pi$, wenn die Aktion $a$ ausgefÃ¼hrt wird an. Es gilt: $$Q&#94;\\pi(s, \\pi(s)) = V&#94;\\pi(s)$$ Dynamische Programmierung ( Dynamic Programming ) Dynamische Programmierung ist eine Methode zum LÃ¶sen von Optimierungsproblemen. Dabei wird die Tatsache genutzt, dass fÃ¼r jeden initialen Zustand $x_0 \\in \\mathcal{X}$ die optimalen Kosten $J&#94;*(x_0)$ in $$J&#94;*(x_0) = \\min_{\\pi_{0:N-1}} J_{\\pi_{0:N-1}} (x_0)$$ gleich dem Wert $J_0(x_0)$, welcher sich aus dem letzten Schritt der Rekursion $$ \\begin{align} J_N(x_N) &= g_N (x_N)\\\\ J_k(x_k) &= \\min_{a_k \\in A_k(x_k)} \\{g_k (x_k, a_k) + \\mathbb{E}(J_{k+1} (x_{k+1})|x_k, a_k)\\} \\text{ fÃ¼r } k = 0, \\dots, N-1 \\end{align} $$ ergibt. Pseudocode for Dynamic Programming LaufzeitkomplexitÃ¤t: $\\mathcal{O}(N |\\mathcal{X}|&#94;2 |A|)$ 18.05.2016 Endliche Planungsprobleme Hat man einen endlichen Zustandsraum $\\mathcal{X} = \\{1, 2, \\dots, n_x\\} \\subsetneq \\mathbb{N}$ und eine endliche Aktionsmenge $A = \\{1, 2, \\dots, n_a\\} \\subsetneq \\mathbb{N}$, in einem Planungsproblem, so spricht man von einem endlichen Planungsproblem. Markov-Kette Ãœbergangswahrscheinlichkeiten in einem endlichen Planungsproblem sind gegeben. Die naive LÃ¶sung mit Brute-Force ist in $\\mathcal{O}(|A|&#94;{N \\cdot |X|})$. Planungsprobleme nach Horizont $N=1$: Gierige Planung, ein einschrittiges Planungsproblem. Hat geringe KomplexitÃ¤t, aber zukÃ¼nftige Effekte werden nicht berÃ¼cksichtig. Bei submodularen Kostenfunktionen kann man die Kosten, die durch die gierige Planung entstehen, abschÃ¤tzen. $N<\\infty$: Wurde bisher betrachtet und betrifft die meisten Planungsprobleme. Nachteil ist, dass die Strategie $\\pi_k$ zeitinvariant ist. $N = \\infty$: Bei Planungsproblemen mit sehr langem Horizont, wenn ein Ende nicht abzulesen ist. Beispiele sind die kÃ¼rzeste-Wege-Suche sowie bei Reinforcement Learning. Probleme sind unendliche Kosten und die ZeitabhÃ¤ngigkeit der Schrittkosten und Ãœbergangswahrscheinlichkeiten. Discount factor ( Diskontierungsfaktor ) Ein Diskontierungsfaktor $\\gamma \\in [0, 1]$ encodiert den Bedeutungsverlust zwischen einer direkten Belohnung und einer spÃ¤teren Belohnung. Es sollte $\\gamma < 1$ gelten um unendliche Belohnungen zu vermeiden. Diskontiertes Planungsproblem Ãœbergangswahrscheinlichkeiten und Schrittkosten sind Zeitinvariant, dh. $f_{ij}&#94;k(a) = f_{ij}(a)$ und $g_k(i,a) = g(i, a) \\forall k$. Es gilt die optimale Wertefunktion $J&#94;*$ zu finden, welche durch $$J&#94;*(x_0) = \\min_{\\pi_0, \\pi_1, \\dots} (J_{\\pi_0}(x_0))$$ definiert ist. Diese minimiert die erwarteten diskontierten Kosten $$J_{\\pi_0} (x_0) = \\lim_{N \\rightarrow \\infty} \\mathbb{E}(\\alpha&#94;N g(x_N)+ \\sum_{k=0}&#94;{N-1} \\alpha&#94;k \\cdot g(x_k, \\pi_k(x_k)))$$ Dabei heiÃŸt $\\alpha \\in (0, 1)$ ein Diskontierungsfaktor . Er verhindert, dass die Kosten unendlich werden. Dies kann man mit DP lÃ¶sen, indem man eine VorwÃ¤rtsrekursion macht: $$ \\begin{align} J_k(1) &= \\min_{a \\in A(i)}(g(i, a) + \\alpha \\sum_{j=1}&#94;{n_x} f_{ij}(a) \\cdot J_{k-1}(j))\\\\ J_0(i) &= g(i) \\end{align} $$ Das ist mÃ¶glich, da das Problem zeitinvariant ist. Dies kann man durch Indexverschiebung zeigen. Bellman-Operator The Bellman-operator $T$ is a function which takes a function as an argument and returns a function. When $T$ is applied to a cost function $J$, it is defined for each state $i$ as: $$(T J) (i) = \\min_{a \\in A(i)} (g(i,a) + \\alpha \\cdot \\sum_j f_{ij}(a) \\cdot J(j))$$ where $\\alpha \\in [0, 1]$ is a discount factor. $$T&#94;k J = \\begin{cases}(T(T&#94;{k-1} J)) &\\text{if } k \\geq 1\\\\ J &\\text{otherwise} \\end{cases}$$ One can show: $$J&#94;* = \\lim_{N \\rightarrow \\infty} T&#94;N J \\text{ for arbitrary } J$$ Hence successive applications of the Bellman operator are guaranteed to converge against the global optimum. Strategiebewertung $$(T_\\pi J)(i) = g(i, \\pi(i)) + \\alpha \\cdot \\sum_j f_{ij} (\\pi(i)) \\cdot J(j)$$ FÃ¼r eine optimale Strategie $\\pi&#94;*$ gilt: $$(T J)(i) = (T_{\\pi&#94;*} J)(i)$$ Wertevektor $$J = (J(1), \\dots, J(nx))&#94;T$$ Kontraktion Eine Funktion $f: M \\rightarrow M$ in einem metrischen Raum $(M, d)$ heiÃŸt Kontraktion genau dann, wenn $$\\exists \\lambda \\in [0, 1) \\forall x, y \\in M: d(f(x), f(y)) \\leq \\lambda d(x, y)$$ gilt. Banach'scher Fixpunktsatz Sei $(M, d)$ ein vollstÃ¤ndig metrischer Raum und $f$ eine Kontraktion, welche Lipschitz-Stetig ist mit Konstante $0 \\leq \\lambda < 1$. Dann gilt: Es gibt genau einen Fixpunkt $\\xi \\in M$ mit $f(\\xi) = \\xi$. A-priori-AbschÃ¤tzung: $d(x_n,\\xi)\\le\\frac{\\lambda&#94;n}{1-\\lambda}d(x_0,x_1)$ A-posteriori-AbschÃ¤tzung: $d(x_n,\\xi)\\le\\frac{\\lambda}{1-\\lambda}d(x_{n-1},x_n)$ T-Kontraktion FÃ¼r beliebige Wertevektoren $J, J'$, eine beliebige Strategie $\\pi$, die Maximums-Norm $d$: $$d(J, J') = \\max_{i \\in \\mathcal{X}} |J(i) - J'(i)|$$ und fÃ¼r alle $k=0,1, \\dots$ gilt: Es existiert ein $\\alpha \\in [0, 1)$ mit $$d(T&#94;k J, T&#94;k J') \\leq \\alpha&#94;k \\cdot d(J, J')$$ $$d(T&#94;k_\\pi J, T&#94;k J') \\leq \\alpha&#94;k \\cdot d (J, J')$$ Das bedeutet, der Bellman-Operator ist eine Kontraktion und laut dem Banachschem Fixpunktsatz gibt es daher einen Fixpunkt. Werte-Iteration ( Value iteration ) $$J&#94;* = \\lim_{N \\rightarrow \\infty} T&#94;N J$$ where $J&#94;*$ is the optimal value, $T$ is the Bellman operator an $N \\in \\mathbb{N}_{\\geq 1}$ is the planning horizon. $g$ is the cost function for each step. Pseudocode for Value iteration algorithm Remark : The value function is usually denoted with $V$, not with $J$. Satz von der SationÃ¤ren Strategie FÃ¼r jede stationÃ¤re Strategie $\\pi = \\pi_{0:N-1}$ erfÃ¼llt der dazugehÃ¶rige Wertevektor $J_\\pi$ die Fixpunktgleichung $J_\\pi = T_\\pi J_\\pi$. Dabei ist $J_\\pi$ der eindeutige Fixpunkt. Eine sationÃ¤re Strategie $\\pi&#94;*$ ist genau dann optimal, wenn $\\pi&#94;*$ $$T J&#94;* = T_{\\pi&#94;*} J&#94;*$$ erfÃ¼llt. (Also: Die optimale Strategie ist eine stationÃ¤re Strategie) Der Beweis fÃ¼r (1) folgt aus dem Banach'schen Fixpunktsatz. Strategie-Iteration ( Policy iteration ) Man kann beobachten, dass bei der Werte-Iteration die Stategie schneller konvergiert als der Wertevektor. AuÃŸerdem ist die Anzahl der Strategien endlich, aber es gibt unendlich viele Wertevektoren. Pseudocode for Policy iteration algorithm wobei $$F(\\pi) = \\begin{pmatrix}f_{11}(\\pi) & \\dots & f_{1 n_x}(\\pi)\\\\ \\vdots & \\ddots & \\vdots\\\\ f_{n_x 1}(\\pi) & \\dots & f_{n_x n_x}(\\pi)\\end{pmatrix}$$ die Transitionsmatrix ist ($f_{ij}(\\pi)$ gibt die Wahrscheinlichkeit an, von Zustand $i$ in Zustand $j$ unter der Strategie $\\pi$ zu wechseln). AuÃŸerdem sind der Schrittkostenvektor $g(\\pi)$ und der Wertefunktionsvektor $J$ von folgender Struktur: $$ \\begin{align} g(\\pi) &= \\begin{pmatrix}g(x_1, \\pi(x_1))\\\\ g(x_2, \\pi(x_2))\\\\ \\vdots\\\\ g(x_n, \\pi(x_n))\\end{pmatrix}\\\\ J &= \\begin{pmatrix} J(x_1)\\\\ J(x_2)\\\\ \\vdots\\\\ J(x_n) \\end{pmatrix} \\end{align} $$ Die folgenden beiden Schritte werden alternierend ausgefÃ¼hrt: Strategieauswertung: $$V&#94;\\pi(s) \\gets R(s, \\pi(s)) + \\gamma \\sum_{s'} T(s, \\pi(s), s') V&#94;\\pi(s')$$ Strategieverbesserung: $$\\pi'(s) \\gets \\text{arg max}_a (R(s, a) + \\gamma \\sum_{s'} T(s, a, s') V&#94;\\pi(s'))$$ Siehe CMU Value iteration vs Policy iteration Die policy iteration konvergiert in weniger Schritten. Jeder Schritt der policy iteration ist teurer als in der Werteoperation, da die Strategieauswertung die LÃ¶sung eines LGS ist (in $\\mathcal{O}(n_x&#94;3)$). AuÃŸerdem ist die policy iteration nie fÃ¼r $\\alpha=1$ lÃ¶sbar (kann auch sonst passieren). Label-Korrektur-Algorithmus Der Label-Korrektur-Algorithmus ist ein Meta-Algorithmus zur kÃ¼rzeste-Wege-Suche dient. SpezialfÃ¤lle von diesem sind die Tiefensuche (K ist LIFO-Liste / Stack) und Breitensuche (K ist FIFO-Liste), der Dijkstra-Algorithmus (K ist Priority-Queue), der A*-Algorithmus (K ist Priority-Queue, $h_j$ ist nicht-trivial) sowie Branch & Bound (K ist Priority-Queue, $h_j$ ist nicht-trivial und $m_j$ ist nicht trivial). Pseudocode for the Label correction algorithm Explanation: First `if`: The left hand side is a lower bound to get from start to `v`, to `c` and then to `t`. If this lower bound is not lower than either `u` or the distance to `c` directly, then it will not be part of the optimal solution. Trellis-Diagramm Eine Diagramm welches anzeigt welche ZustÃ¤nde Ã¼ber die Zeit gewÃ¤hlt werden. Pontryagin's Minimum-Prinzip ( Maximumprinzip ) Das Pontryagin'sche Minimum-Prinzip kÃ¶nnte als die russische Variante der Bellman-Gleichungen fÃ¼r deterministische MDPs bezeichnet werden. Es stellt eine notwendige Bedingung an ein Optimum dar. Siehe auch Pontryagin's Minimum Principle by Steven M. LaValle. Pontryagin's maximum principle by Emo Todorov Hamilton-Funktion Die Hamilton-Funktion der Kontrolltheorie stellt eine notwendige Bedingung fÃ¼r die optimale LÃ¶sung eines Steuerungsproblems ist. Damit eine LÃ¶sung eines Steuerungsprobelms optimal ist, muss die LÃ¶sung die Hamilton-Funktion minimieren. Die Aktionen $a_{0:N-1}$ sollen so gewÃ¤hlt werden, dass $$J(x_{0:N}, a_{0:N-1})$$ minimiert wird. Dabei ist $x_k$ der Systemzustand mit $$ \\begin{align} x_0 &= c\\\\ x_{k+1} &= h_k(x_k, a_k) \\qquad \\text{ fÃ¼r } k=0, \\dots, N-1 \\end{align} $$ Daraus ergibt sich das Optimierungsproblem: $$\\begin{align} &\\underset{x_{0:N}, a_{0:N}}{\\operatorname{minimize}}& & J(x_{0:N}, a_{0:N-1}) \\\\ &\\operatorname{subject\\;to} &&x;_{k+1} = h_k(x_k, a_k), \\quad k = 0, \\dots,N-1\\\\ &&&x;_0 = \\text{cost} = c \\end{align}$$ Es ergibt sich die Lagrange-Funktion $$\\mathcal{L}(x_{0:N}, a_{0:N-1}, \\lambda_{0:N}) = J(x_{0:N}, a_{0:N-1}) + (c - x_0) \\cdot \\lambda_0 + \\sum_{k=0}&#94;{N-1} \\underbrace{\\left (h_k(x_k, a_k) - x_{k+1} \\right )&#94;T \\lambda_{k+1}}_{N \\text{ eindimensionale Nebenbedingungen}}$$ In diesem Fall ist die Hamilton-Funktion $$H_k(x_k, a_k, \\lambda) = g_k(x_k, a_k) + h_k(x_k, a_k)&#94;T \\cdot \\lambda_{k+1},$$ wobei $\\lambda(t)$ Lagrange-Multiplikatoren sind. Insgesamt ergeben sich folgende notwendigen Bedingungen an die optimale LÃ¶sung fÃ¼r $k=0, \\dots, N-1$ mit $\\lambda_N = g_N&#94;x(x_N)$ und $x_0$ fest: ZustandsÃ¼bergÃ¤nge: $x_{k+1} = h(x_k, a_k)$ $\\lambda_k = g_k&#94;x (x_k, a_k) + h_k&#94;x(x_k, a_k)&#94;T \\cdot \\lambda_{k+1}$ $0 = \\nabla_{a_k} H_k(x_k, a_k, \\lambda_{k+1})$ (oder $a_k = \\text{arg }\\min H_k (x_k, a_k, \\lambda_{k+1})$) Diese (insbesondere das arg min) ist als Pontryagins Minimum-Prinzip bekannt. Lineares Zustandsmodell $$x_{k+1} = A_k + x_k + B_k \\cdot a_k + r_k&#94;{(s)}$$ Linearer Quadratischer Regulator ( LQR ) Der LQR ist ein Regler (Regulator) fÃ¼r einen lineareren Zustandsraum mit quadratischer Kostenfunktion. Ein Reger will typischerweise den Zustand $x = \\vec{0}$ erreichen, wohingegen ein Tracker den aktuellen Zustand bestmÃ¶glich schÃ¤tzen will. Das lineare Zustandsraummodell lautet: $$x_{k+1} = A_k \\cdot x_k + B_k \\cdot a_k + r_k&#94;{(s)}$$ Die zu minimierende Kostenfunktion sei $$\\mathbb{E} \\left ( \\underbrace{x_N&#94;T \\cdot Q_N \\cdot x_N + \\sum_{k=0}&#94;{N-1} x_k&#94;T \\cdot Q_k \\cdot x_k}_{\\text{ZustandsabhÃ¤ngige Kosten}} + \\underbrace{\\sum_{k=0}&#94;{N-1} a_k&#94;T \\cdot R_k \\cdot a_k}_{\\text{aktionsabhÃ¤ngige Kosten}} \\right )$$ Dabei sind die Gewichtungsmatrizen $Q_k, Q_N, R_k$ symmetrisch und positiv definit. Auch die cost-to-go Matrix $P_{k+1}$ ist symmetrisch und positiv definit. Die optimale LÃ¶sung fÃ¼r dieses Problem lautet: $$a_k&#94;* = \\underbrace{-{(R_k + B_k&#94;T P_{k+1} B_k)}&#94;{-1} \\cdot B_k&#94;T \\cdot P_{k+1} \\cdot A_k}_{\\text{VerstÃ¤rkungsmatrix } L_k} x_k$$ wobei $P_k$ durch die iterative Riccati-Gleichung gefunden wird: $$ \\begin{align} P_N &= Q_N\\\\ P_k &= A_k&#94;T \\left ( \\underbrace{P_{k+1} - \\overbrace{P_{k+1} B_k (B_k&#94;T P_{k+1} B_k + R_k)&#94;{-1}}&#94;{\\text{see Kalman gain}} B_k&#94;T P_{k+1}}_{\\text{see error estimate update in Kalman filter}} \\right ) A_k + Q_k \\end{align}$$ Alternativ kann man $P_k$ also so ausdrÃ¼cken: $$\\begin{align} P_k &= A_k&#94;T \\left ( (I-K_k B_k&#94;T) P_{k+1} \\right ) A_k + Q_k\\\\ K_k &= P_{k+1} B_k (B_k&#94;T P_{k+1} B_k + R_k)&#94;{-1} \\end{align}$$ PWLC ( Piece-wise linear and Concave ) Siehe Basics of Solving POMDPs SicherheitsÃ¤quivalenz ( Certainty Equivalence ) Die SicherheitsÃ¤quivalenz besagt, dass im Fall eines linearen Modells mit einer quadratischen Zielfunktion und additivem Rauschen die optimale LÃ¶sung des Kontroll-Problems die Gleiche ist, wie wenn das Rauschen nicht vorhande wÃ¤re. Anders gesagt: Die VerstÃ¤rkungsmatrix $L_k$ und somit die Strategie $\\pi_k&#94;*$ sind unabhÃ¤ngig vom Rauschen $r_k&#94;{(s)}$. Die selbe optimale Strategie ergibt sich bei Betrachtung des korrespondierendne deterministischen Zustandsraummodel $$x_{k+1} = A_k x_k + B_k a_k$$ welchem das Rauschen $r_k&#94;{(s)}$ durch dessen Erwartungswert $\\mathbb{E}(r_k&#94;{(s)}) = 0$ ersetzt ist. $\\Rightarrow$ Deterministisches Problem POMDPs Partially observable Markov decision process (POMDP) Die Messungen sind unsicherheitsbehaftet. Das Planungsproblem ist wie folgt definiert: Zustand: Der Agent erhÃ¤lt nur noch Beobachtungen / Messungen des Zustands. Probleme dabei sind: Rauschen von Sensoren Indirekt: Position ist interessant, aber man kann z.B. mit GPS nur die Laufzeiten ermitteln. Niederdimensional: MessgrÃ¶ÃŸe ist niedrigdimensonaler als die interessierte GrÃ¶ÃŸe. Erst durch mehrere Messungen gelangt man an die interessante GrÃ¶ÃŸe. Ein POMDP ist ein MDP mit folgenden Unterschieden: Initialzustand $x_0$ ist Zufallsvariable mit Verteilung $P(x_0)$. Beobachtungen / Messungen $z_k \\in Z$ gemÃ¤ÃŸ der bedingten Verteilung $$z_k \\sim P(\\cdot | x_k, a_{k-1})$$ (Beobachtungswahrscheinlichkeit) Diskrete Beobachtungen $\\rightarrow$ bedingte ZÃ¤hldichte $$f(z_k | x_k a_{k-1}) = P(z=z_k | x_k, a_{k-1})$$ Kontinuierliche Beobachtungen $\\rightarrow$ bedingte Wahrscheinlichkeitsdichte $$f(z_k | x_k, a_{k-1}) = \\frac{\\partial f(z | x_k, a_{k-1})}{\\partial z} |_{z=z_k}$$ Minimierung der erwarteten Kosten $$J_{\\pi_{0:N-1}}(\\square) = \\mathbb{E}(g_N (x_n) + \\sum_{k=0}&#94;{N-1} g_n(x_k, \\pi_k(\\square)))$$ Reformulierung als MDP: Problem: keine vollstÃ¤ndige Information Ã¼ber den Zustand $x_k$, aber Zugriff auf Beobachtungen Idee: Definieren eines neuen Zustands (Informationsvektor $\\mathcal{I}$, engl. Information state), welcher direkt zugÃ¤nglich ist, alle verfÃ¼gbaren Informationen Ã¼ber $x_k$ zum Zeitpunkt $k$ enthÃ¤lt Der Informationsvektor $\\mathcal{I}$ enthÃ¤lt alle Beobachtungen: $$\\mathcal{I} = (z_0, \\dots, z_k, a_{0}, \\dots, a_{k-1}) \\text{ fÃ¼r } k=0, \\dots, N-1$$ Der Informationsvektor $\\mathcal{I}_k$ beschreibt die zeitliche Entwicklung des Agenten. Mit $P(x_0)$ und $\\mathcal{I}_k$ ist sÃ¤mtliche Information gegeben um zum Zeitpunkt $k$ eine Planungsentscheidung zu treffen. Das korrespondierende MDP wird Informations-MDP genannt. Das zu lÃ¶sende dynamische Programm lautet: $$J_N(\\mathcal{I}_N) = \\mathbb{E}(g_N(x_N) | \\mathcal{I}_N)$$ $$J_k(\\mathcal{I}_k) = \\min_{a_k} (\\mathbb{E}_{x,z}(g_k(x_k, a_k) + J_{k+1}(\\mathcal{I}_k, z_{k+1}, a_k)(\\mathcal{I}_k, a_k))) \\text{ fÃ¼r } k=0, 1, \\dots, N-1$$ Die LÃ¶sung ist eine Ã¶ptimale Strategie $\\pi_k&#94;* (\\mathcal{I}_k) = a_k&#94;*$ Nur in AusnahmefÃ¤llen geschlossen lÃ¶sbar, z.B. lineare Modelle. Statistik Seien $S=\\{z_1, \\dots, z_n\\}$ Stichproben (Samples) einer Zufallsvariablen $z \\sim P(z | \\Theta)$ mit unbkanntem Parameter $\\Theta$. Eine Statistik ist eine Funktion $T(S)=t$, welche zwar von $S$, nicht aber von $\\Theta$ abhÃ¤ngt. Konstante Funktionen, minimum, maximum, durschschnitt, median, ... Hinreichende Statistik (engl. sufficient statistic ) Ziel: Kompression, d.h. Darstellung von $\\mathcal{I}_k$ von geringer Dimension. Eine Statistik $T$ heiÃŸt hinreichend fÃ¼r $\\Theta$, wenn keine weitere Statstik auf $S$ existiert, welche zusÃ¤tzliche Informationen Ã¼ber $\\Theta$ liefert. Ist $T(S) = t$ gegeben, dann liefert die volle Kentnis von $S$ keine Zusatzinformation Ã¼ber $\\Theta$. Beispiel: Der Stichprobenmittelwert $\\hat{z}$ von $n$ unabhÃ¤ngigen Stichproben $z_i$ einer normalverteilten Zuvallsvariabeln $z \\sim \\mathcal{N}(\\mu, \\sigma)$ ist eine hinreichende Statistik fÃ¼r $\\mu$. Bayes'scher SchÃ¤tzer Suppose an unknown parameter $\\theta$ is known to have a prior distribution $\\pi$. Let $\\widehat{\\theta} = \\widehat{\\theta}(x)$ be an estimator of Î¸ (based on some measurements $x$), and let $L(\\theta,\\widehat{\\theta})$ be a loss function, such as squared error. The Bayes risk of $\\widehat{\\theta}$ is defined as $E_\\pi(L(\\theta, \\widehat{\\theta}))$, where the expectation is taken over the probability distribution of $\\theta$: this defines the risk function as a function of $\\widehat{\\theta}$. An estimator $\\widehat{\\theta}$ is said to be a Bayes estimator if it minimizes the Bayes risk among all estimators. Equivalently, the estimator which minimizes the posterior expected loss $E(L(\\theta,\\widehat{\\theta}) | x)$ for each x also minimizes the Bayes risk and therefore is a Bayes estimator. Source: Wikipedia In general, the Bayes estimator has no closed-form solution. The Extended Kalman filter is a Bayes estimator. See also: Recursive Bayesian estimation Bayes Filter Verteilungs-MDP ( Belief-state MDP ) POMDPs haben Ã¤quivalente Verteilungs-MDPs. Dabei wird eine Wahrscheinlichkeitsverteilung fÃ¼r den aktuellen Zustand angegeben. Verschiedene Verteilungen werden diskretisiert und als ZustÃ¤nde angesehen. Dann kann jeder beliebige MDP-LÃ¶sungsalgorithmus auch fÃ¼r POMDPs verwendet werden. Siehe: POMDPs by Geoff Hollinger. Lineare Planungsprobleme in POMDPs Zustandsraummodell (Systemmodell): $$x_{k+1} = A_k \\cdot x_k + B_k \\cdot a_k + r_k&#94;{(s)}$$ Messmodell (Sensormodell): $$z_k = H_k \\cdot x_k + r_k&#94;{(m)}$$ $r_k&#94;{(s)}, r_k&#94;{(m)}$ sind normalverteilte Rauschterme: $$f_k&#94;x(x_k) = N(x_k; \\hat{x}_k, C_k&#94;x) = \\frac{1}{\\sqrt{|2 \\pi C_k&#94;x|}} \\exp(-1/2 (x_k - \\hat{x}_k)&#94;T (C_k&#94;x)&#94;{-1} (x_k - \\hat{x}_k))$$ mit Mittelwert $\\hat{x}_k$ und Kovarianzmatrix $C_k&#94;x$ $X = \\mathbb{R}&#94;{n_x}, A=\\mathbb{R}&#94;{n_k}, Z=\\mathbb{R}&#94;{n_z}$ Ziel: ÃœberfÃ¼hrung des Zustandes $x_0$ in Zielzustand $x_t = [0, ..., 0]&#94;T$ durch Minimierung der quatratischen Kostenfunktion $\\mathbb{E}(x_N&#94;T Q_N x_n + \\sum_{k=0}&#94;{N-1} (x_k&#94;T Q_k x_k + a_k&#94;T R_k a_k) | I_N)$ mit symmetrisch, positiv definiten Gewichtungsmatrizen $Q_N, Q_k, R_k$ und Informationsvektor $\\mathcal{I}_N$. Dies ist ein lineares, quadratisches GauÃŸ'sches Planungsprobelm (LQG) Planer besteht aus 2 Komponenten: ZustandsschÃ¤tzer Strategie ZustandsschÃ¤tzer: Annahme: beliebige Aktionsfolge $a_{0:N-1}$ gegeben: Kalman-Filter PrÃ¤diktion ($k \\rightarrow k+1$) Gegeben: A posteriori Wahrscheinlichkeitsdichte $f_a&#94;e(x_k) = N(x_k; \\hat{x}_k&#94;e, C_k&#94;e) = P(x_k | I_k)$ Gesucht: prÃ¤dizierte Wahrscheinlichkeitsdichte $f_{k+1}&#94;p(x_{k+1}) = N(x_{k+1}; \\hat{x}_k&#94;P, C_k&#94;P) = P(x_{k+1} | I_k, a_k)$ Berechnung der Parameter: Mittelwert: $\\hat{x}_{k+1}&#94;{(P)} = A_k \\hat{x}_k&#94;e + B_k a_k$ Kovarianzmatrix: $P_k&#94;{(P)} = A_k P_k&#94;e A_k&#94;T + C_k&#94;{(s)}$ Filterschritt ($k \\overset{Z_k}{\\rightarrow} k$) Gegeben: prÃ¤dizierte Dichte $f_k&#94;P(x_k)$, Messung $z_k$ Gesucht: a-posteriori Dichte $f_k&#94;e(x_k)$ Berechnung der Parameter: Mittelwert: $\\hat{x}_k&#94;e = \\hat{x}_k&#94;P + K_k (z_k - H_k \\hat{x}_k&#94;{(P)})$ Kovarianzmatrix: $P_k&#94;e = C_k&#94;{(P)} - K_k H_k C_k&#94;{(P)}$ Kalman-Gain: $K_k = P_k&#94;{(P)} H_k&#94;T (H_k C_k&#94;{(P)} H_k&#94;T + C_k&#94;{(m)})&#94;{-1}$ Insgesamt: Geschlossene Berechnung der Zustandsverteilung Kalman-Filter erfÃ¼llt BLUE -Eigenschaft Regelkreis ( Control system ) Ein Regelkreis ist ein technisches System, welches einen Zielzustand anstrebt. Open-loop Planung ( OL Planung ) Unter einem Open-loop Control system (offener Regelkreis) versteht man ein technisches System welches ohne ZustandsrÃ¼ckfÃ¼hrung, also ohne Messung des Zustands nachdem die Regelung begonnen wurde, arbeitet. Beispiele sind SpÃ¼hlmaschinen und Rasensprenger. In der Open-loop Planung wird ein optimaler Plan bestimmt: $$a_{0:N-1}&#94;* = \\text{arg}\\min_{a_{0:N-1}} \\mathbb{E}\\{g_N (x_N) + \\sum_{k=0}&#94;{N-1} g_k (x_k, a_k)\\}$$ Da der Plan \"blind\", also ohne ZustandsrÃ¼ckfÃ¼hrung, angwedet wird sind deterministische Planungsverfahren anstelle von DP anwendbar. Closed-loop Planung ( CL Planung ) Unter einem Closed-loop control system (geschlossenem Regelkreis) versteht man ein technisches System welches mit ZustandsrÃ¼ckfÃ¼hrung, also mit Messung des Zustands wÃ¤hrend der Regelung, arbeitet. Beispiele sind System im Auto zum halten der Geschwindigkeit oder Rasensprenger welche die Feuchtigkeit Ã¼berprÃ¼fen. Closed-loop Planung kann mit dynamischer Programmierung gelÃ¶st werden. Geschlossene LÃ¶sung nur in AusnahmefÃ¤llen, sonst numerische LÃ¶sungsverfahren. In der closed-loop Planung wird eine optimale Strategie bestimmt. Open-Loop-Feedback Planung ( OLF Planung ) OLF-Planung ist ein Mittelweg zwischen OL-Planung und CL-Planung. Es wird der aktuelle Informationsvektor $\\mathcal{I}_k$ verwendet um $P(x_k | I_k)$ zu bestimmen. Dann wird mittels OL-Planung der optimale Plan $a_{k:N-1}&#94;*$ bestimmt. Die OLF-Planung ist eine Folge von $N$ OL-Planungsschritten: $P(x_k | I_k)$ wird berechnet. $a_{k:N-1}&#94;* \\gets \\arg \\min \\mathbb{E}(g_N(x_N) + \\sum_{i=k}&#94;{N-1} g_i(x_i, a_i) | I_k)$ Wende $a_{k:N-1}&#94;*$ und gehe wieder zu 1 Es gilt: $$J_{CL} \\leq J_{OLF} \\leq J_{OL}$$ ModellprÃ¤diktive Planung OLF-Planung Ã¼ber kÃ¼rzeren, aber wandernden Horizont $M \\ll N$ Ablauf (on-line): Berechnung von $P(x_k | I_k)$ Berechnung von $a_{k:M-1}&#94;*$ durch Minimierung von $$\\mathbb{E}(\\sum_{i=k}&#94;{k+M-1} g_i(x_i, a_i) | \\mathcal{I}_k)$$ Anwendung von $a_k&#94;*$, zurÃ¼ck zu 1. Eigenschaften: Effiziente Planung fÃ¼r groÃŸe $N$, insbesondere fÃ¼r $N=a$ VerlÃ¤ngerung von $M$ fÃ¼hrt nicht notwendigerweise zu besseren Planungsergebnissen; d.h. $M$ ist kein Trade-off zwischen QualitÃ¤t und KomplexitÃ¤t. Hier wird der Plan aktualisiert; OLF minimiert die Kosten garantiert stÃ¤rker als OL-Planung (gleichheit im deterministischen Fall) Linearisierung ( Extended Kalman Filter , EKF ) Siehe auch: EKF . Bedingte Differentielle Entropie $$H(x|z, a) = - \\int_z f(z|a) \\cdot \\int_{\\mathcal{X}} f(x|z, a) \\cdot \\log (f(x|z, a)) \\mathrm{d}x \\mathrm{d} z$$ Die differentielle Entropie erweitert die Schannon-Entropie auf den kontinuierlichen Fall. UnschÃ¶n ist, dass sie negativ werden kann. Sie bewertet Unsicherheit anhand der \"rÃ¤umlichen\" Konzentration von Wahrscheinlichkeitsmassen. Sensoreinsatzplanung Das Ziel der Sensoreinsatzplanung ist es, die Sensoren so zu positionieren / auszurichten / konfigurieren, dass der Informationsgewinn maximiert wird. Gegeben Kontinuierlicher Zustandsraum $\\mathcal{X}$ Kontinuierlicher Beobachtungsraum $\\mathcal{Z}$ Endliche Menge der Konfigurationen $A$ ZustandsÃ¼bergang: $f(x_{k+1} | x_k)$ bzw. $x_{k+1} = p_k(x_k, w_k)$ Messmodell: $f(z_k | x_k, a_k)$ bzw. $z_k = h_k(x_k, a_k, v_k)$ Schrittkosten $g_k$, welche den Informationsgewinn durch die Wahl einer geeigneten Konfiguration $a_k$ bewerten. Dabei kann man z.B. Kovarianzbasiert vorgehen, also die rÃ¤umliche Ausdehnung der Kovarianzmatrix als Bewertungsgrundlage verwenden. Die Spur der Kovarianzmatrix ist proportional zum Umfang, die Determinante ist proportional zur FlÃ¤che. Alternativ kann man Informationstheoretisch vorgehen. So ist die bedingte differentielle Entropie : $$H(x | z, a) = - \\int_{\\mathcal{Z}} f(z | a) \\cdot \\int_{\\mathcal{X}} f(x|z,a) \\cdot \\log f(x | z,a) \\mathrm{d} x \\mathrm{d} z$$ (vgl. Entropie- vs Varianz ) Ein weiteres MaÃŸ fÃ¼r informationstheoretische Kosten ist die Transinformation (engl. Mutual information): $$ \\begin{align} T(x; z) &= \\int_{\\mathcal{Z}} \\int_{\\mathcal{X}} f(x, z) \\cdot \\log \\frac{f(x,z)}{f(x) \\cdot f(z)} \\mathrm{d}z \\mathrm{d}x\\\\ &= H(x) - H(x|z) \\geq 0 \\end{align} $$ Keine Terminalen Kosten Das Problem wird nun wie folgt gelÃ¶st: Informationsvektor $\\mathcal{I}_k = (a_{0:k}, z_{0:k})$ Dynamisches Programm $J_N = 0$ $$J_k(P(x_k | \\mathcal{I}_{k-1})) = \\min_{a_k} \\left \\{g_k(x_k, a_k) + \\mathbb{E}_{z_k} \\left \\{J_{k+1} (P(x_{k+1} | \\mathcal{I}_k) | I_{k-1} ) \\right \\} \\right \\}$$ Im Allgemeinen gibt es hier keine geschlossene LÃ¶sung. Informationstheoretische Kosten gehen im linearen Planungsfall in Kovarianz-basierte Kosten Ã¼ber. Siehe z.B. Entropie: $$H(x_k | z_k, a_k) = \\frac{1}{2} \\log |2 \\pi \\underbrace{Cov(x_k | a_k)}_{C_k&#94;e}| \\approx |Cov(\\cdot | \\cdot)|$$ In der Sensoreinsatzplanung liefern Open-Loop und Closed Loop Verfahren, gegeben die initiale Verteilung $P(x_0)$, die selben Kosten. Daher wird Open-Loop-Planung verwendent. Das heiÃŸt, der optimale Plan $a_{0:N-1}&#94;*$ wird mittels deterministischer Planung (also KÃ¼rzeste-Wege-Suche), bestimmt. $g_i(x_i, a)$: Schrittkosten Der Suchbaum hat $|A|&#94;N$ Pfade. (0-1 Programme) Monotonie der Riccati-Gleichung (Siehe Folie 4 ) Sei $$V_k(\\Lambda, C) := C_k&#94;w + (A_k - \\Lambda \\cdot H_k) C \\cdot (A_k - \\Lambda H_k)&#94;T + \\Lambda C_k&#94;v V&#94;T$$ mit $$\\Lambda = K_k = A_k C H_k&#94;T (H_k C H_k&#94;T)&#94;{-1} \\text{ und } C = C_k&#94;P$$ gilt $V_k = S_k$, da $$ \\begin{align} V(K, C&#94;P) &= C&#94;W + (A - KH) C&#94;P (A-KH)&#94;T + KC&#94;V K&#94;T\\\\ &= C&#94;W + AC&#94;P A&#94;T - KH C&#94;P A&#94;T + KHC&#94;P H&#94;T K&#94;T - A C&#94;P H&#94;T K&#94;T KC&#94;v K&#94;T\\\\ &= C&#94;W + AC&#94;P A&#94;T - KH C&#94;P A&#94;T - AC&#94;P H&#94;T K&#94;T + K (HC&#94;P H&#94;T + C&#94;v) K&#94;T \\cdot A&#94;CP H {(H C&#94;P H&#94;T + C&#94;V)}&#94;{-1}\\\\ &= C&#94;W + AC&#94;P A&#94;T - KH C&#94;P A&#94;T = S_k(C&#94;P) \\end{align} $$ Weiterhin ist $\\Lambda = K_k$ das Minimum von $V_k$ fÃ¼r gegebenes $C$, da der Kalman-Filter der optimale SchÃ¤tzer fÃ¼r lineare Modelle ist. Mit $\\tilde{K}_k = A_k \\tilde{C} H_k&#94;T {(H_k \\bar{C} H_k&#94;T + C_k&#94;v)}&#94;{-1}$ gilt $$S_k(C) = V_k(K_k, C) \\prec V_k(\\bar{K}_k, C) \\prec V_k(\\bar{K}_k, \\bar{C}) = S_k(\\tilde{C})$$ Siehe auch: Algebraic Riccati equation , LQR Approximative Planung Abbildung auf lineare Sensoreinsatzplanung mittels Linearisierung und ModellprÃ¤diktiver Planung Linearisierung Hier werden Nominalwerte $\\bar{x}_{k:N-1}$ benÃ¶tigt. Da die Aktion nur die Messgleichung, nicht jedoch die Systemgleichung betrifft kÃ¶nnen die $$\\bar{x}_k = \\hat{x}_k&#94;P; \\qquad \\bar{x}_{k+1} = p_k(\\bar{x}_k, 0)$$ AnschlieÃŸend wird linearisiert. Ablauf Nach Messung: (approximative) Berechnung ovn $P(x_k | I_k)$ bzw. $P(x_{k+1} | I_k)$ z.B. mittels EKF. Berechnung der Nominalwerte $\\bar{x}_{k+1:k+M}$ mit $\\bar{x}_{k+1} = \\mathbb{E}(x_{k+1} | I_k) = \\hat{x}_{k+1}&#94;P$ Linearisierung Berechnung des optimalen Plans $a_{k+1:k+M}&#94;*$ fÃ¼r lineares Problem. Anwenden von $a_{k+1}&#94;*$; zurÃ¼ck zu 1. Beispiel : Steuerung eines mobilen Sensors Objekt: $x_{k+1} = \\begin{pmatrix}1 & T & 0 & 0\\\\ 0 & 1 & 0 & 0\\\\ 0 & 0 & 1 & T\\\\ 0 & 0 & 0 & 1\\end{pmatrix} \\cdot x_k + w_k$ mit $x_k = \\begin{pmatrix}x_k\\\\ \\dot{x}_k, y_k, \\dot{y}_k\\end{pmatrix}$ Sensor: $z_k = \\sqrt{(x_k - x_k&#94;S(a_k))&#94;2 + (y_k - y_k&#94;S(a_k))&#94;2} + v_k$ Aktion $a_k$ ist Lenkwinkel Kinematisches Sensormodell: $$\\begin{pmatrix}x_{k+1}&#94;S\\\\ y_{k+1}&#94;S\\\\ \\phi_{k+1}&#94;S\\end{pmatrix} = \\begin{pmatrix}x_{k}&#94;S\\\\ y_{k}&#94;S\\\\ \\phi_{k}&#94;S\\end{pmatrix} + \\begin{pmatrix}T \\cdot v \\cdot \\cos(\\varphi_k&#94;s + a_k)\\\\ T \\cdot v \\cdot \\cos(\\varphi_k&#94;s + a_k)\\\\ a_k\\end{pmatrix}$$ Dirac-Delta-Funktion Die Dirac-Funktion ist definiert als $$\\delta(A)=\\begin{cases} 1\\ & \\text{falls }0\\in A\\\\ 0\\ & \\text{sonst}\\end{cases}\\ ,\\quad A\\subset\\mathbb{R}$$ Ausblendeigenschaft : $$\\int_{- \\infty}&#94;\\infty f(x)\\,\\delta (x-a)\\,\\mathrm{d}x=\\int_{- \\infty}&#94;\\infty f(x)\\,\\delta (a-x)\\,\\mathrm{d}x=f(a)$$ Reinforcement Learning Reinforcement Learning ( RL ) Reinforcement learning ist ein Subfeld des maschinellen Lernens, welches sich auf Probleme der optimalen Kontrolle fokusiert. Problem Die Kostenfunktion $g_k$ kann unbekannt sein. Das Modell, das heiÃŸt die Ãœbergangswahrscheinlichkeiten $P(x_{k+1} | x_k, a_k)$ kÃ¶nnen unbekannt sein. Dies wird durch ein Zusammenspiel aus lernen und planen gelÃ¶st. Man lernt also aus Erfahrung und Interaktion mit der Umwelt . Definition MDP mit folgenden Unterschieden: (2) Zeithorizont: $N = \\infty$ fÃ¼r fortlaufende Aufgaben $N < \\infty$ fÃ¼r episodische Aufgaben (diese haben einen terminaler Zustand) (5) Keine Ãœbergangswahrscheinlichkeiten gegeben (6) Belohnungen (reward) $r_k \\in \\mathbb{R}$ fÃ¼r Aktion $a_k$ in Zustand $x_k$ mit Nachfolgezustand $x_{k+1}$. $$r_k = g_k(x_k, a_k, x_{k+1})$$ wobei $g_k$ unbekannt. (8) Ziel: Maximierung der erwarteten Belohnung Ã¼ber die Zeit. $$J(x_k) = \\mathbb{E}(R_k | x_k)$$ Fortlaufender Zeithorizont: $R_k = \\sum_{t=0}&#94;\\infty \\gamma&#94;t r_{k+t}$ mit Diskontierungsfaktor $\\gamma \\in [0, 1)$ Episodischer Zeithorizont: $R_k = \\sum_{i=0}&#94;N r_{k+i},$ wobei $N$ unbekannt ist. Beispiele Beliebige Computerspiele Spielen Stabilisierung eines inversen Pendels Eigenschaften und Besonderheiten des RLs Prinzipien des biologischen Lernens (Negatives / Positives VerstÃ¤rken) Intrinsische Motivation etwas erreichen zu wollen: Abstraktion als Kosten- / Belohnungsfunktion, die es Ã¼ber die Zeit zu min. / max. gilt. Exploratives Lernen Unterschied zu \"klassischen\" Lernverfahren: Lernen erfolgt unÃ¼berwacht und explorativ durch aktive Interaktion mit der Umwelt. RL kombiniert Aspekte der Planung mit Lernmethodik. Da RL unÃ¼berwacht ist erfolgt die Entscheidung aufgrund eigener Erfahrung. Dynamisches Programmieren ist nicht anwendbar, da das Modell und die Kosten unbekannt sind. Die optimale Strategie wird aus Erfahrung approximiert. Unterscheidungsmerkmale von RL-Problemtypen Horizont: Fortlaufend, z.B. in Regelungstechnik das inverse Pendel Episodisch in Spielen Approximation / lernen: On-policy: Dieselbe Strategie wird zugleich verbessert und angewandt. Off-policy: verwendet 2 Strategien Strategie 1: erzeugen von Aktionen Strategie 2: wird verbessert Zustands- und Aktionsraum: Diskret Kontinuierlich Ãœbergangswahrscheinlichkeiten / Kosten Modellfreie Verfahren: Lernen nur die optimale Strategie Modelllernende Verfahren: Lernen von Strategie und Modell LÃ¶sungsansÃ¤tze fÃ¼r RL-Probleme Wertefunktionsbasiert: SchÃ¤tzen die Wertefunktion / $Q$-Funktion aus Lernstichproben (Monte Carlo (MC); Temporal Difference (TD), Verantwortlichkeitsspur (eligibility trace, credit assignment); Verwendung von Funktionsapproximatoren) Modelllernende Methoden Strategiesuche (Policy search; Funktionsapproximatoren - neuronale Netze) Episode A run through an MDP from a start state to an end state. Monte-Carlo Methoden Idee : Erlernen einer Strategie aus Beispielepisoden. Approximation des Erwartungswertes durch Stichproben (Samples) $$\\mathbb{E}(R) = \\frac{1}{N} \\sum_{k=1}&#94;N r_k =: \\bar{R}_N,$$ wobei $r_k$ die Belohnung im Zeitschritt $k$ ist. Rekursiv: $$\\bar{R}_{N+1} = \\bar{R}_N + \\frac{1}{N+1} (r_{N+1} - \\bar{R}_N) \\text{ mit } \\bar{R}_1 = r_1$$ Monte-Carlo Methoden funktionieren ausschlieÃŸlich auf episodischen Problemen (d.h mit Ende), wie z.B. Spielen, da die Aktualisierung nach Beendigung einer Episode stattfindet. Gegeben: Strategie $\\pi$ Gesucht: Wertefunktion $J_\\pi(x)$ Ablauf: FÃ¼r beliebigen Initialzustand erzeuge Episode mittels $\\pi$ FÃ¼r jeden Zustand $x$ in Episode: $R \\gets$ kummulative Belohnung ab 1. Vorkommen von $x$ (First-visit, es gibt auch every-visit) $n(x) \\gets n(x) + 1$ $J_\\pi(x) \\overset{(*)}{\\gets} J_\\pi (x) + \\frac{1}{n(x)} (R - J_\\pi (x))$ Konvergiert fÃ¼r unendliche Anzahl an Episoden. Vorteile: Aufwand ist unabhÃ¤ngig von der Anzahl der ZustÃ¤nde (genauso wie Partikelfilter). EinschrÃ¤nkungen auf Teilmenge von $\\mathcal{X}$ mÃ¶glich. Nachteile / EinschrÃ¤nkungen: Ist nur auf episodische Probleme anwendbar Monte Carlo RL Idee: SchÃ¤tzen der $Q$-Funktion $Q(x, a)$. Pseudocode for Policy Iteration FÃ¼r gegebene Episode: Aktualisierung der $Q$-Funktion fÃ¼r alle besuchten ZustÃ¤nde $x$ und gewÃ¤hlte Aktionen $a$. Verbesserung der Strategie fÃ¼r alle besuchten ZustÃ¤nde. Problem: pro Zustand wird nur eine Aktion bewertet. Das fÃ¼hrt nur auf sehr lokalen Bereichen zu einer Strategieverbesserung. Exploration vs. Exploitation The exploration vs. exploitation problem is that an agent in a reinforcement learning setting can either try to improve his strategy in a part where he already knows how to behave or he can try to explore the world and potentially find much better (or much worse) strategies. Exploit what is already known to obtain rewards, but explore in order to choose better actions in the future. There are the following exploration strategies: Exploring Starts $\\varepsilon$-Greedy Strategy Softmax Strategy $\\varepsilon$-decreasing Strategy $\\varepsilon$-first Strategy Adaptive $\\varepsilon$-greedy Strategy Exploring Starts Jedes Zustands-Aktions-Paar gleichwahrscheinlich als Startwert fÃ¼r Episode. Vorteil: FÃ¼hrt zu einer deterministischen Strategie Nachteil: FÃ¼r viele reale Systeme nicht realisierbar (z.B. Roboter kann nicht bei voller Kraft starten). Probabilistische Strategie Eine probabilistische Strategie $\\pi$ ist definiert als eine Funktion, welche fÃ¼r einen Zustand $x$ und eine Aktion $a$ die Wahrscheinlichkeit wiedergibt, dass $a$ im Zustand $x$ ausgefÃ¼hrt wird: $$\\pi: \\mathcal{X} \\times \\mathcal{A} \\rightarrow [0, 1]$$ $$\\pi(x, a) = P(a | x)$$ $\\varepsilon$-Greedy Strategy The $\\varepsilon$-greedy exploration strategy is a probabilistic strategy: Explore $\\varepsilon$% of the time. Otherwise, follow what you currently believe is best. gierige Aktion: Aktion mit hÃ¶chster erwarteter Belohnung: $$a&#94;+ = \\arg \\max_a Q(x,a)$$ erhÃ¤lt hÃ¶chste Wahrscheinlichkeit: $$\\pi(x, a&#94;*) = 1 - \\varepsilon + \\frac{\\varepsilon}{|A(x)|}$$ nicht-gierige Aktionen: $\\pi(x, a) = \\frac{\\varepsilon}{|A(x)|}$ mit $0 < \\varepsilon \\ll 1$ Vorteil: Kein Festlegen auf suboptimale Aktion Nachteil: Wahl von $\\varepsilon$ problematisch $\\varepsilon$-greedy MC policy iteration ist on-policy Softmax-Strategie Rangfolge entsprechend der Wertigkeit der Aktionen $$\\pi(x, a) = \\frac{e&#94;{Q(x, a) / \\tau}}{\\sum_a e&#94;{Q(x,a) / \\tau}} \\text{ mit \"Temperatur\"} \\tau > 0$$ Die generierte Verteilung nennt sich Gibbs- oder auch Boltzmann-Verteilung. $\\tau$ groÃŸ: $Q(x,a) / \\tau$ wird klein, d.h. die Aktionen werden Ã¤hnlich wahrscheinlich gewÃ¤hlt. $\\tau$ klein: Die Aktionen werden mit deutlich unterschiedlicher wahrscheinlichkeit gezogen. $\\tau \\rightarrow 0$: nahezu deterministische, gierige Strategie. Vorteil gegenÃ¼ber $\\varepsilon$-greedy: Rangfolge bei Auswahl. Nachteil gegenÃ¼ber $\\varepsilon$-greedy: Wahl von $\\tau$ wird of als schwieriger angesehen als die Wahl von $\\varepsilon$. $\\varepsilon$-decreasing Strategy Explore $\\varepsilon$% of the time. Otherwise, follow what you currently believe is best. Reduce $\\varepsilon$ over time. $\\varepsilon$-first Strategy Explore for $\\varepsilon$ steps and then do what you think is best. Adaptive $\\varepsilon$-greedy Strategy Explore $\\varepsilon$% of the time. Otherwise, follow what you currently believe is best. Reduce $\\varepsilon$ based on what you learn. GLIE-Strategie GLIE ( G reedy in the l imit with i nfinite e xploration) bezeichnet eine Damit eine Strategie GLIE ist, muss erfÃ¼llt sein: Alle $(x, a)$-Paare werden unendlich oft besucht Strategie konvergiert zu einer gierigen Strategie, d.h. $$\\lim_{k \\rightarrow \\infty} \\pi(x, a&#94;*) = 1 \\text{ fÃ¼r } \\arg \\max_a a(x, a)$$ Beispiel bei $\\varepsilon$-greedy Strategie: $\\varepsilon$ mit Zeit abklingen lassen $\\varepsilon(x) = \\frac{\\varepsilon}{n(x)}$ mit $\\varepsilon \\in (0, 1)$ und $n(x)$ zÃ¤hlt wie hÃ¤ufig der Zustand $x$ besucht wurde. Fazit Monte Carlo-Verfahren Vorteile Erlernen der optimalen Strategie ohne Modellwissen mÃ¶glich, sofern GLIE-Strategien verwendet werden Auch anwendbar, wenn die Markov-Annahme nicht gilt, da kein Bootstrapping Nachteile: Allgemeine Konvergenzeigenschaften (noch) nicht formal bewiesen. (Schon fÃ¼r Strategiebewertung, nicht aber fÃ¼r RL) Funktioniert nur fÃ¼r episodische RL-Probleme Temporal Difference Verfahren ( TD ) TD-Verfahren nutzen die zeitliche Differenz zweier SchÃ¤tzungen eines Zustandwertes. Die Aktualisierungen sind nach jedem Zustandwechsel. Das heiÃŸt, im Gegesatz zu MC-Verfahren, sind TD-Verfahren fÃ¼r Episodische und fortlaufende RL-Probleme geignet. Unterschiedliche SchÃ¤tzung: $$ \\begin{align} J_\\pi(x) &= \\mathbb{E}(R_k | x_k = x) \\tag{1}\\\\ &= \\mathbb{E}(r_k + \\gamma \\sum_{i=0}&#94;\\infty \\gamma&#94;i \\cdot r_{k+i} | x_k = x)\\tag{2} \\end{align} $$ MC-Verfahren ganz (1) mittels Stichprobenfolge. TD-Verfahren schÃ¤tzen die Summe in (2) durch eine Stichprobe $r_k$. TD-Strategiebewertung Erinnerung an DP-Strategiebewertung: $$J_\\pi(x_k) \\gets r_k(x_k, \\pi (x_k)) + \\alpha \\sum_{x_{k+1}} P(x_{k+1} | x_k, \\pi(x_k)) \\cdot J_\\pi (x_{k+1})$$ Allerdings ist $P( \\cdot | x_k, a)$ unbekannt. Daher wird es mittels einer einzelnen Stichprobe $(x_k, r_k, x_{k+1})$ geschÃ¤tzt und ein Mittelwert zwischen dem aktuellen Wert und der SchÃ¤tzung erstellt. $$J_\\pi(x_k) \\gets (1-\\alpha) \\cdot \\underbrace{J_\\pi(x_k)}_{\\text{aktueller Wert}} + \\alpha \\cdot \\underbrace{(\\underbrace{r_k + \\gamma \\cdot J_\\pi(x_{k+1})}_{\\text{erwarteter Wert}} - J_\\pi(x_k))}_{\\text{zeitliche Differenz}}$$ Konvergenz bei variabler Schrittweite $\\alpha = \\alpha_k$ (Lernrate) falls $$\\sum_{k=1}&#94;\\infty \\alpha_k = \\infty \\text{ und } \\sum_{k=1}&#94;\\infty \\alpha_k&#94;2 < \\infty$$ Eine typische Wahl ist $\\alpha(x, a) = \\frac{1}{1+ m(x, a)},$ wobei $m(x, a)$ die Anzahl der Besuche von $(x, a)$ ist. Einschritt-TD-Verfahren SARSA ist ein Einschritt-TD-Verfahren. Die Aktualisierung nach der AusfÃ¼hrung von $a_k$ liefert Belohnung $r_k$ und Nachfolgezustand $x_{k+1}.$ ABER Folgeaktion $a_{k+1}$ wird benÃ¶tigt. SARSA ( State Action Reward State Action ) SARSA is a temporal difference learning algorithm which updates the $Q$-function: $$Q(s_t,a_t) \\leftarrow (1-\\alpha) \\cdot Q(s_t,a_t) + \\alpha [r_{t+1} + \\gamma \\cdot Q(s_{t+1}, a_{t+1})]$$ where $\\alpha \\in (0, 1)$ is the learning rate and $\\gamma \\in [0, 1]$ is the discount factor. As SARSA chooses $a_{k+1}$ according to the policy $\\pi$ it is an on-policy algorithm, in contrast to $Q$-learning. Pseudocode for SARSA $Q$-Learning $Q$-Learning ist ein TD-Vefahren um ohne Modell ein Reinforcement-Learning Problem zu lÃ¶sen. $$Q(x_k, a_k) \\gets Q(x_k, a_k) + \\alpha \\cdot [r_k + \\gamma \\cdot \\underbrace{\\max_a Q(x_{k+1}, a)}_{J(x_{k+1})} - Q(x_k, a_k)]$$ Pseudocode for Q-Learning. Please note that I replaced \"for each episode\" by \"while Q is not converged\" Da die Aktualisierung von $Q$ unabhÃ¤ngig von $\\pi$ erfolgt, ist $Q$-learning ein off-policy Verfahren. ($Q$-Learning hat sich im Gegensatz zu SARSA durchgesetzt) Wenn die Strategie eine GLIE-Strategie ist, kann man mit $Q$-Learning die Konvergenz beweisen. Siehe auch: YouTube: Lecture 18: RL Part 1: $Q$-Learning : 1:16:11. BrownCS141 Spring 2014. YouTube: PacMan Mario Q-learning on YouTube. 2010. $Q$-Learning by Tim Eden, Anthony Knittel, Raphael van Uffelen of the University of New South Wales Fazit TD-Learning Vorteile: Beide Verfahren konvergieren sofern GLIE Einfach zu implementiernen, lernen pro Zeitschritt Nachteile: Bootstrapping problemantisch wenn Markov-Annahme nicht erfÃ¼llt. Monte-Carlo RL vs. TD RL Sowohl Monte-Carlo Methoden als auch TD-Methoden benÃ¶tigen Erfahrung um die State-Value Function $V$ zu schÃ¤tzen. Die Monte-Carlo Methoden gehen wie folgt vor: $$V(s_t) = V(s_t) + \\alpha (R_t - V(s_t))$$ wobei $R_t$ der reward am Ende der Episode ist. Die Temporal Difference (TD) Verfahren gehen wie folgt vor: $$V(s_t) = V(s_t) + \\underbrace{\\alpha [r_{t+1} + \\gamma \\cdot V (s_{t+1}) - V (s_t)]}_{\\text{Temporal Difference}}$$ Die Monte-Carlo-Methoden aktualisieren $V$ also erst am Ende einer Episode, wohingegen Temporal Difference Learning direkt aktualisiert. Mehrschritt-TD-Verfahren $$ \\begin{align} R_k&#94;{(n)} &= r_k + \\gamma \\cdot r_{k+1} + \\dots + \\gamma&#94;{n-1} + \\gamma&#94;n J_\\pi (x_{k+1})\\\\ R_k&#94;{(1)} &\\hat{=} TD\\\\ R_k&#94;{(n)} &\\hat{=} RL \\end{align} $$ Strategiebewertung $$J_\\pi(x_k) \\gets J_\\pi (x_k) + \\alpha \\cdot [R_k&#94;{(n)} - J_\\pi(x_k)]$$ Vorteile: Schnellere Konvergenz als Einschritt-TD Flexible Verbindung von MC und TD Nachteil: Unpraktisch fÃ¼r groÃŸe $n$. Eligibility Trace ( Verantwortlichkeitsspur ) Problem: Nur der letzte Zustand wird bei klassischen Verfahren belohnt Der Reward wird propagiert, aber nur langsam (nach mehreren Schritten). Idee : Gewichtete Mittelung verschiedener $n$-Schritt-Belohnungen. $$R_k&#94;\\lambda = (1-\\lambda) \\cdot \\sum_{n=1}&#94;\\infty \\lambda&#94;{n-1} R_k&#94;{(n)} \\text{ mit } \\lambda \\in [0,1] \\text{ und } (1-\\lambda)\\sum_{n=1}&#94;\\infty \\lambda&#94;{n-1} = 1$$ beim erreichen eines terminalen Zustands ist $R_k&#94;{(n)} = R_k$ fÃ¼r $n > N-K-1$. Abgewichten von $R_k&#94;{(n)}$ bei steigendem $n$. SpezialfÃ¤lle : $\\lambda = 0$: $R_k&#94;\\lambda = R_k&#94;{(1)}$ ist ein Ein-Schritt-TD $\\lambda = 1$: $R_k&#94;\\lambda = (1-\\lambda) \\cdot \\sum_{n=1}&#94;{N-k-1} \\lambda&#94;{n-1} R_k&#94;{(n)} + \\lambda&#94;{N-k-1} R_k = R_k$ ist ein Monte Carlo Verfahren Unpraktisch fÃ¼r groÃŸe $n$, weil man lange auf Aktualisierungen warten muss. Deshalb wird eine Verantwortlichkeitsvariable eingefÃ¼hrt: $$e: \\mathcal{X} \\rightarrow \\mathbb{R}&#94;+$$ $$e_k(x) = \\begin{cases}\\gamma \\cdot \\lambda e_{k-1}(x) &\\text{falls } x \\neq x_k\\\\ \\gamma \\cdot \\lambda e_{k-1}(x) + 1 &\\text{sonst}\\end{cases}$$ mit $e_0 = 0$. Im zweiten Fall merken wir uns, dass wir den Zustand besucht haben, indem die Variable erhÃ¶ht wird. Im ersten Fall ist es immer eine Reduktion. Wir speichern welche ZustÃ¤nde kÃ¼rzlich besucht wurden. Strategiebewertung $TD(\\lambda)$ Wird Zustand $x_k$ besucht, dann ist dessen TD-Fehler $\\delta(x_k) := r_k + \\gamma \\cdot J_\\pi (x_{k+1}) - J_\\pi(x_k)$ Damit wird jeder Zustand $x \\in \\mathcal{X}$ korrigiert $$J_\\pi(x) \\leftarrow J_\\pi(x) + \\alpha \\cdot \\delta(x_k) \\cdot e_k(x)$$ wobei $\\alpha$ die Lernrate ist und $e_k$ die Verantwortlichkeit anzeigt. Korrektur erfolgt in AbhÃ¤ngigkeit der Verantwortlichkeit jedes Zustands $x$ am TD-Fehler Beispiel : $e(x) = 0$ fÃ¼r beliebiges $x$. Wird $x$ nicht besucht, so gibt es keine Korrektur. TD(0), dh. $\\lambda = 0$ ist eine \"normales\" Ein-Schritt-TD TD(1), dh. $\\lambda = 1$ ist ein Monte Carlo Verfahren mit Abgewichtung durch $\\gamma$. ISt $\\gamma=1$, dann ist es ein \"normales\" MC mit dem Unterschied, dass man nicht das Ende einer Episode abwarten muss. Policy iteration on-policy: SARSA($\\lambda$) off-policy: Q($\\lambda$) Wichtig : $Q$-Learning wÃ¤hlt gelegentlich nicht-gierige Aktion, korrigiert $Q$ aber mit gieriger Aktion! Um das angemessen zu berÃ¼cksichtigen wird die Verantwortlichkeitsspur zurÃ¼ckgesetzt. Das passiert insbesondere zu Beginn des Lernens hÃ¤ufiger, da dort eine Exploration zugelassen wird. Fazit Verantwortlichkeitsspuren + typischerweise schnellere Konvergenz im Vergleich zu Ein-Schritt-TD + Einfache Realisierung eines Mehrschritt-TD + Trade-off zwischen TD und MC durch die Wahl von $\\lambda$ - Konvergenz kann im Allgemeinen nicht nachgewiesen werden (abhÃ¤ngig von $\\lambda$ und $N$) - HÃ¶herer Rechenaufwand und hÃ¶herer Speicheraufwand im Vergleich zu Ein-Schritt-TD See also: Reinforcement Learning: An Introduction by Sutton. SARSA($\\lambda$) Pseudocode for SARSA($\\lambda$) $Q(\\lambda)$ Pseudocode for Q($\\lambda$) Funktionsapproximatoren im RL Bisher: Diskrete ZustÃ¤nde und diskrete Aktionen Nun: Kontinuierliche ZustÃ¤nde und Aktionen Bei kontinuierlichen ZustÃ¤nden/Aktionen ist eine Iteration Ã¼ber alle ZustÃ¤nde/Aktionen nicht mehr mÃ¶glich. Dennoch sollen Erfahrungen aus besuchten ZustÃ¤nden auf nicht-besuchte generalisiert werden. Herausforderungen beim RL: Keine statische Trainingsmenge; Daten werden online generiert NichtstationaritÃ¤t: Die Zielfunktion (z.B. $Q$-Funktion oder direkt die Strategie $\\pi$) verÃ¤ndern sich Ã¼ber die Zeit. Dies schrÃ¤nkt die Menge der Funktionsapproximatoren ein. Ungeeignet: Neuronale Netze, da sie statische Trainingsdaten vorraussetzen Geeignet: Lineare Approximatoren $$f(x) = \\sum_{i=1}&#94;l \\Theta_i \\cdot K_i(x)$$ wobei $\\Theta_i$ ein Parameter ist und $K_i$ eine (ggf. nicht-lineare) Kernfunktion (Basisfunktion) ist. Gradienten-Verfahren: Wir verwenden einen parametrischen Approximator mit Parametervektor $\\Theta$. Beispiel: Strategiebewertung Ziel: Approximation der unbekannten Wertefunktion $J_\\pi(x)$ durch $\\tilde{J}(x, \\Theta)$ durch minimierung der quadratischen Abweichung $$J_{\\mathcal{X}} (J_\\pi(x) - \\tilde{J}(x, Q))&#94;2 \\mathrm{d} x \\tag{*}$$ Minimierung von $(*)$ anhand besuchter ZustÃ¤nde $x_k$ mit Gradientenabstieg: $$ \\begin{align} \\Theta_{k+1} &= \\Theta_k - \\frac{1}{2} \\alpha \\nabla_{\\Theta_k} (J_\\pi(x_k) - \\bar{J}(x_k, Q_k)&#94;2)\\\\ &= \\Theta_k + \\alpha(J_\\pi(x_k) - \\bar{J}(x_k, \\Theta_k)) \\cdot \\nabla_{\\Theta_k} \\tilde{J}(x_k, \\Theta_k) \\end{align} $$ wobei $\\alpha$ die Schrittweite ist. Problem : $J_\\pi(x_k)$ ist unbekannt. Allerdings kann es durch eine SchÃ¤tzung $$J_\\pi(x_k) \\approx r_k + \\gamma \\cdot \\tilde{J}(x_{k+1}, \\Theta_k)$$ $$\\Theta_{k+1} = \\Theta_k + \\alpha \\cdot [\\underbrace{r_k + \\gamma \\cdot \\tilde{J}(x_{k+1}, \\Theta_k) - \\tilde{J}(x_k, \\Theta_k)}_{\\text{zeitliche Differenz}}] \\cdot \\nabla_{\\Theta_k} \\tilde{J}$$ Beispiele : Strategieverbesserung $$Q_{k+1} = Q_k + \\alpha \\cdot \\delta_k \\cdot \\nabla_{\\Theta_k} Q(x_k, a_k, \\Theta_k)$$ mit SARSA: $$\\delta_k = r_k + \\gamma \\cdot Q(x_{k+1}, a_{k+1}, \\Theta_k) - Q(x_k, a_k, \\Theta_k)$$ $Q$-Learning: $$\\delta_k = r_k + \\gamma \\cdot \\max_a Q(x_{k+1}, a, \\Theta_k) - Q(x_k, a_k, \\Theta_k)$$ Anwendung: Backgammon, Go Fazit Funktionsapproximatoren + Es gibt eine direkte Erweiterung von TD auf den kontinuierlichen Fall. - Keine allgemeinen Konvergenzaussagen Modellbasiertes RL Bisher: RL lernt Wertefunktion und Strategie mittels Belohnung aus direkter Interaktion mit Umwelt. Idee: Lerne eine Modell $x_{k+1} \\sim P(\\cdot | x_k)$. Man hat zwei Phasen: Lernen und Planen. In der Lernphase wird das Modell gelernt, in der Planphase wird mit dem Modell der nÃ¤chste Zustand geplant. Erweiterungen Nutze beobachtete NachfolgezustÃ¤nde (Ãœbergang) mit Tripel $(x_k, x_{k+1}, a)$ Nutze Simulation der Umwelt Modell Beschreibung der Umwelt Verohersage Reaktion der Umwelt auf Aktion Verbesserung einer Strategie ohne reale Interaktion mit der Umwelt $\\rightarrow$ Schnellere Konvergenz Beispiele DP: vollstÃ¤ndiges Modell (Ãœbergangswahrscheinlichkeiten) - vÃ¶llige Entkopplung Biologisches Lernen: Stichprobenmodell (beispielhafte ÃœbergÃ¤nge). Dies versucht beispielsweise Dyna-Q $Q$-Learning: Strategielernen aus direkter Erfahrung Planung: Strategieverbesserung aus simulierter Erfahrung Modelllernen: aus direkter Erfahrung Suche: Auswahl von ZustÃ¤nden und Aktionen fÃ¼r Simulation Dyna-Q Pseudocode for the Dyna-Q algorithm + Besseres Ausnutzen von Erfahrung + Empirisch: schnellere Konvergenz als $Q$-Learning - Annahme eines deterministischen Modells See also: Integrating Planning, Acting, and Learning by Sutton. Adaptive DP Eine Schwachstelle von Dyna-Q ist, dass es ein Stichprobenmodell lernt. Adaptive DP Verbesserung: Lernt frequentistisch Zustandsverteilung von Nachfolgezustand. $P(x_{k+1} | x_k, a_k)$: relative HÃ¤ufigkeit von $x_{k+1}$ gegeben $x_k$, $a_k$ (frequentistische Sichtweise) kann geschÃ¤tzt werden: $$P(x_{k+1} | x_k, a_k) \\approx \\frac{m(x_k, a_k, x_{k+1})}{m(x_k, a_k)}$$ wobei $m(x_k, a_k)$ die Anzahl der Besuche von Zustand $x_k$ mit AusfÃ¼hrung ovn Aktion $a_k$ zÃ¤hlt. $m(x_k, a_k, x_{k+1})$ zÃ¤hlt die ÃœbergÃ¤nge von $x_k$ unter $a_k$ nach $x_{k+1}$. Ergibt sich aus Interaktion mit realer Umwelt. + verbesserte Konvergenz im vgl. zu $Q$-Learning + Reduktion des Modell-Bias - Berechnung von $J&#94;*$ ist aufwendig, muss aber nicht in jedem Schritt / Schleifeniteration ausgefÃ¼hrt werden Gaussian Processes ( Gaussche Prozesse ) Siehe Function Approximation und Gaussche Prozesse . PILCO ( Probabilistic Inference for Learning Control ) PILCO wurde entwickelt fÃ¼r kontinuierliche ZustÃ¤nde und Aktionen. Das Modell: Es wird eine probabilistische Regression auf beobachteten Zustand mittels sog. Gaussian Processes (GP) eingesetzt. Strategieverbesserung: Verwendung parametrischer Strategie Adaptierung der Parameter mittels Policy Search MDP vs POMDP vs RL MDP POMDP RL Agent-Environment Diagram 1 Zustandsraum $\\mathcal{X} \\subseteq \\mathbb{R}&#94;n$ 2 Diskrete Zeitschritte $k=0, \\dots, N$ ($N = \\infty$ ist unÃ¼blich) Zeithorizont: $N = \\infty$ fÃ¼r fortlaufende Probleme ist Ã¼blich, $N < \\infty$ fÃ¼r episodische Probleme 3 Initialzustand $x_0 \\in \\mathcal{X}$ zum Zeitpunkt $k=0$. Initialzustand $x_0$ ist Zufallsvariable Ohne Modell, d.h. $x_0 \\in \\mathcal{X}$. POMDP-RL sind Gegenstand aktueller Forschung. 4 Aktionsmenge $A_k(x_k) \\neq \\emptyset$ 5 Ãœbergangswahrscheinlichkeiten $x_{k+1} \\sim P_X (\\cdot | x_k, a_k)$ Keine Ãœbergangswahrscheinlichkeiten gegeben 6 Additive Kostenfunktion $g_N(x_N) + \\sum_{k=0}&#94;{N-1} g_k(x_k, a_k)$ Belohnung $r_k = g_k(x_k, a_k, x_{k+1})$ wobei $g_k(\\cdot)$ unbekannt 7 Zustand ist direkt beobachtbar nach Anwendung der Aktion Beobachtung / Messung $z_k$ gemÃ¤ÃŸ der bedingten Verteilung $$z_k \\sim P( \\cdot | x_k, a_{k-1})$$ Wie MDP 8 Minimiere $$ \\begin{align} J_{\\pi_{0:N-1}} (x_0) := & \\mathbb{E} (g_N (x_N) \\\\ + & \\sum_{k=0}&#94;{N-1} g_k (x_k, \\pi_k(x_k))) \\end{align}$$ Minimiere $$ \\begin{align} J_{\\pi_{0:N-1}} (\\cdot) := & \\mathbb{E} (g_N (x_N) \\\\ + & \\sum_{k=0}&#94;{N-1} g_k (x_k, \\pi_k(\\cdot))) \\end{align} $$ wobei $\\cdot$ entweder ein Informationsvektor $\\mathcal{I}$ oder ein belief state $P(x_k | \\mathcal{I}_k)$ ist. Maximimierung der Belohnung $J(x_k) = \\mathbb{E} (R_k | x_k)$. Im fortlaufenden Fall $$R_k = \\sum_{t=0}&#94;\\infty \\gamma&#94;t r_{k+t}$$ mit Diskontierungsfaktor $\\gamma \\in [0, 1)$, im episodischen Fall $$R_k = \\sum_{i=k}&#94;{N} r_i,$$ wobei $N$ unbekannt ist. Beispiele Roboter navigiert durch Labyrint Tic-Tac-Toe KÃ¼rzeste Wege Suche Aufzugsteuerung Sensoreinsatzplanung Kollisionsvermeidung von Flugzeugen Navigationsroboter (Kamaro) Skat Brettspiele (Schach, Go), da $N$ unbekannt (deterministisch) Navigationsroboter LÃ¶sungsÂ­algorithmen Dynamic Programming Deterministischer Fall: Label-Korrektur-Algorithmus Linearer Fall: LQR Endliches Planungsproblem, unendlicher Horizont: Policy Iteration Value Iteration Reduzierung auf Information Vector MDP / Belief-state MDP: Siehe Algorithmen von MDP Linearer Fall: Kalman-filter + LQR Diskreter Fall: $\\alpha$-Vektoren Approximative Verfahren: Ã„nderung der Optimierung (OL, OLF, ModellprÃ¤diktiv) Abbildung auf geschlossen lÃ¶sbare Probleme Linearisierung Diskretisierung SicherheitsÃ¤quivalenz: Diskret: Label-Korrektur Algorithmus Kontinuierlich: Pontryagins Minimumprinzip Funktionsapproximatoren (Kernel, Neuronale Netze) Heuristic Search Value Iteration (HSVI) Wertefunktionsbasiert Monte Carlo Temporal Difference SARSA $Q$-Learning Verantwortlichkeitsspuren SARSA($\\lambda$) $Q(\\lambda)$ Modelllernende Methoden Dyna-Q Adaptive DP PILCO Strategiesuche ZusammenhÃ¤nge Eine Tabelle in diesen Folien finde ich sehr hilfreich: Markov models Do we have control over the state transitions? No Yes Are the states completely observable Yes MC MDP No HMM POMDP PrÃ¼fungsfragen Strategiesuche ist NICHT relevant fÃ¼r meine PrÃ¼fung am 4. August 2016. Welche 3 Themengebiete wurden in der Vorlesung behandelt und was sind die Unterschiede? â†’ MDP , POMDP , RL Welche Paradoxa haben wir in den Vorlesungen kennen gelernt? â†’ Allais-Paradoxon Nutzen- und EntscheidungsÂ­theorie Warum gibt es die Nutzenfunktion? Warum reicht die PrÃ¤ferenzrelation nicht aus? â†’ Die Nutzenfunktion ist einfacher zu erstellen. Wie lautet der Satz vom Allais-Paradoxon? â†’ Siehe oben . Wie kann man die Nutzentheorie kritisieren? â†’ Siehe oben . Was haben wir zur Entscheidungstheorie gemacht? â†’ Allais-Paradoxon und Rationale Entscheidungen Wie ist eine Nutzenfunktion definiert? â†’ Siehe oben . OptimierungsÂ­theorie Wie lÃ¶st man Optimierungsprobleme ohne Nebenbedingungen? â†’ Iterativer Abstieg (z.B. Gradientenverfahren), Dynamische Programmierung, Label-Korrektur-Algorithmus; LQR wenn linear Wann existiert kein globales Minimum fÃ¼r ein Optimierungsproblem? â†’ Wenn die Menge der zulÃ¤ssigen LÃ¶sungen nach unten unbeschrÃ¤nkt ist, d.h. \\(\\text{arg} \\min_x f(x) = - \\infty\\) oder wenn die untere Schranke nicht angenommen wird, wie es beispielsweise fÃ¼r \\(e&#94;x\\) der Fall ist. Wie lÃ¶st man Optimierungsprobleme mit Nebenbedingungen? â†’ Lagrange-Ansatz wenn nur Gleichungsnebenbedingungen vorliegen und der KKT -Ansatz fÃ¼r Gleichungs- und Ungleichungsnebenbedingungen. Numerisch gibt es noch Penalty-AnsÃ¤tze . Wann ist es leichter / schwerer das Optimierungsproblem zu lÃ¶sen? â†’ Keine Nebenbedingungen, in \\(\\mathbb{R}&#94;n\\) oder kleiner diskreter Raum, wenn die zu optimierende Funktion linear oder konkav ist. Beweisen Sie, dass der Gradient senkrecht auf die HÃ¶henlinien steht. â†’ Siehe math.StackExchange . Welche numerischen Methoden zur Optimierung kennen sie? â†’ Iterativer Abstieg (Gradientenverfahren, Newton-Verfahren), Penalty-AnsÃ¤tze Was bedeutet es, dass ein Problem geschlossen lÃ¶sbar ist? â†’ Das ist nicht eindeutig definiert. Streng kÃ¶nnte man folgendes sagen: Wenn auf die Verwendung von numerischen Verfahren (z.B. Gradientenabstieg, Monte-Carlo-Verfahren, etc.) verzichtet werden und die LÃ¶sung in Form von mathematischen Grundfunktionen angegeben werden kann. Aber das wird hÃ¤ufig auch etwas lockerer gesehen, etwa wenn man zwar numerische Verfahren benÃ¶tigt, man aber weiÃŸ dass diese sicher zur global optimal LÃ¶sung konvergieren (wie etwas bei konvexen Problemen). Auch die mathematischen Grundfunktionen sind vage. So wird gerne die erf-Funktion als eine Grundfunktionen angesehen, obwohl man diese nur approximativ (etwas tabellarisch und per Interpolation) berechnen kann. Welche geschlossen lÃ¶sbaren SpezialfÃ¤lle existieren? â†’ Lineare Planungsprobleme (Foliensatz 7, Folie 17/21), auch bei POMDPs (vgl. Foliensatz 8 und Folie 6) Welche Probleme sind nicht geschlossen lÃ¶sbar? â†’ POMDPs (bis auf Ausnahmen, vgl. Foliensatz 8 und Folie 6), Bayesscher SchÃ¤tzer (Foliensatz 8, Folie 15) Welche MÃ¶glichkeiten der approximativen LÃ¶sung existieren bzw. sind anwendbar? â†’ Ã„nderung der Optimierung (OL, OLF, MP ), Abbildung auf geschlossen lÃ¶sbare Probleme (Linearisierung, Diskretisierung, SicherheitsÃ¤quivalenz), Verwendung von Funktionsapproximatoren (parametrisch oder nicht-parametrisch) Was versteht man unter Pontryagin's Minimum-Prinzip und wozu ist es gut? â†’ Pontryagins Minimum-Prinzip liefert fÃ¼r deterministische Planungsprobleme ein notwendiges Kriterium fÃ¼r globale Minima. Was versteht man unter dem OptimalitÃ¤tsprinzip? â†’ Das OptimalitÃ¤tsprinzip von Bellman besagt, das bei einigen Optimierungsproblemen sich die optimale LÃ¶sung aus optimalen LÃ¶sungen fÃ¼r die Teilprobleme zusammensetzt. Ein Beispiel ist die KÃ¼rzeste-Wege-Suche. Wenn A-B-C-D der kÃ¼rzeste Weg von A nach D ist, so ist auch A-B-C der kÃ¼rzeste Weg von A nach C. MDP Wie lautet die Definition eines MDP? â†’ Siehe oben . Wie viele PlÃ¤ne gibt es? â†’ FÃ¼r diskrete \\(\\mathcal{X}, A\\) und \\(N\\) Zeitschritte gibt es \\(|A|&#94;N\\) mÃ¶gliche PlÃ¤ne. In jedem Zeitschritt gibt es eine mÃ¶gliche Aktion. Wie viele Strategien gibt es? â†’ FÃ¼r diskrete \\(\\mathcal{X}, A\\) und \\(N\\) Zeitschritte gibt es \\(|A|&#94;{N \\cdot |\\mathcal{X}|}\\) Strategien, da fÃ¼r jede Kombination aus Zeitschritt und Zustand eine Aktion gewÃ¤hlt werden muss. Was versteht man unter dynamischer Programmierenung? â†’ Siehe oben . Wie lauten die Bellman-Gleichungen? â†’ Siehe oben . Was ist an den Bellman-Gleichungen problematisch? â†’ i) Erwartungswertberechnung (kann aufwendig sein), ii) LÃ¶sen des Minimierungsproblems und iii) ReprÃ¤sentation der Wertfunktion insbes. bei kontinuierlichem Zustand Wie hÃ¤ngt ein deterministisches MDP mit der kÃ¼rzesten Wegesuche zusammen? â†’ Die optimale LÃ¶sung eines deterministisches MDPs ist der kÃ¼rzeste Weg in dem Graphen, der durch die ZustÃ¤nde des MDPs sowie den Kosten zwischen den ZustÃ¤nden als Gewicht dargestellt werden. Was macht der LQR? â†’ Ein LQR regelt ein lineares System mit quadratischen Kosten auf einen Zielwert (vgl. oben ). Wieso sind MDPs schwer zu lÃ¶sen? â†’ Es gibt \\(|\\mathcal{A}|&#94;N\\) mÃ¶gliche PlÃ¤ne und \\(|A|&#94;{N \\cdot |\\mathcal{X}|}\\) mÃ¶gliche Strategien. (vgl. On the Complexity of Solving Markov Decision Problems ) Wo ist der Fixpunktsatz von Bedeutung? â†’ Bei dem Beweis, dass die Werte-Iteration gegen die optimale LÃ¶sung konvergiert (siehe T-Kontraktion ). POMDP Wie lautet die Definition eines POMDP? â†’ Siehe oben Wie lautet die Kostenfunktion eines POMDP? â†’ Siehe oben Was ist der Unterschied des LQR beim MDP und POMDP? â†’ Bei POMDPs ist die optimale Strategie \\(\\pi_k&#94;* (\\mathcal{I}_k) = L_k \\cdot \\mathbb{E} (x_k | \\mathcal{I}_k)\\) , wohingegen beim MDP die optimale Strategie \\(\\pi_k&#94;*(x_k) = L_k \\cdot x_k\\) ist. (Beim POMDP wird die SicherheitsÃ¤quivalenz genutzt). Was ist PWLC? â†’ Piece-wise linear and Concave / Convex Warum sind PWLCs in dieser Vorlesung von Bedeutung? â†’ In dem Spezialfall endlicher Planungsprobleme in POMDPs kann das POMDP in ein Belief-State MPD transformiert werden. Dann ist die Wertefunktion \\(J_k\\) eine PWLC; mit \\(\\alpha\\) -Vektoren kann die optimale Strategie berechnet werden. Was versteht man unter ModellprÃ¤diktiver Planung (MP)? â†’ ModellprÃ¤diktive Planung ist OLF, Ã¼ber einen kurzen, aber wandernden Horizont. Im Gegensatz zu OLF kann ModellprÃ¤diktive Planung auch bei nicht-episodischen Problemen verwendet werden, da in der OLF der Plan \\(a_{k:N-1}&#94;*\\) durch Minimierung von \\(\\mathbb{E}[g_N(x_N) + \\sum_{i=k}&#94;{N-1} g_i(x_i, a_i) | \\mathcal{I}_k]\\) berechnet wird. Bei der modellprÃ¤diktiven Planung hingegen wird nur \\(a_{k:(k+M)}\\) durch Minimierung von \\(\\mathbb{E}[g_N(x_N) + \\sum_{i=k}&#94;{k+M-1} g_i(x_i, a_i) | \\mathcal{I}_k]\\) berechnet. Was versteht man unter der SicherheitsÃ¤quivalenz? â†’ Siehe oben . Was kÃ¶nnen Sie zur Sensoreinsatzplanung sagen? â†’ Siehe oben . Wie kann man die Kosten bei der Sensoreinsatzplanung modellieren? â†’ Kovarianzbasiert oder Informationstheoretisch (Entropie, Transinformation) Warum reicht Kovarianzbasiert bei linearen Sensoreinsatzproblem? â†’ Informationstheoretische Kosten wie z.B. die Entropie lassen sich bei linearen Probelmen auf Kovarianzbasierte Kosten reduzieren. Wie berechnet man die \\(\\alpha\\) -Vektoren und wozu dienen Sie? â†’ Siehe ProPlan-10-Folien.pdf, Folie 16. Die \\(\\alpha\\) -Vektoren sind im Kontext von diskreten Planungsproblemen zu verstehen. An Ihnen kann man die Aktion ablesen. RL Welche Arten von RL gibt es? â†’ Wertefunktionsbasiert (SchÃ¤tzen der Werte- bzw. \\(Q\\) -Funktion aus Stichproben: Monte Carlo, Temporal Difference, Verantwortlichkeitsspuren, Funktionsapproximatoren), Modelllernende Methoden, Strategiesuche Was ist der Vorteil von Modelllernenden Verfahren? â†’ Die Umwelt kann anhand des Modells simuliert werden und muss nicht real beobachtet werden. Das erleichtert das Planen / finden der Strategie. Was ist der groÃŸe Vorteil von Off-policy RL? â†’ TODO (See What are the advantages / disadvantages of off-policy RL vs on-policy RL? ) Warum ist Q-Learning Off-policy? â†’ Q-Learning verwendet eine gierige Aktion um die Q-Funktion zu aktualisieren, obwohl der Agent zur Auswahl von Aktionen zwecks Zustandsfortschriebung nicht einer gierigen Stragegie folgt, sondern etwa einer \\epsilon-gierigen Strategie. SARSA dagegen nutzt dieselbe (nicht-gierige) Strategie zum Aktualisieren der Q-Funktion und zur Aktionswahl. Daher ist SARSA on-policy und Q-Learning off-policy. Notation Der Dozent nutzt folgende Notation: \\(J&#94;*, \\pi&#94;*\\) : Das Asterisk * deutet an, dass die Kosten / Strategie optimal sind. \\(\\underline{x}\\) : Der Unterstrich deutet an, dass es sich um einen Vektor handelt. Diese Notation wurde in diesem Artikel nicht Ã¼bernommen. \\(\\hat{x}\\) : Der Hut zeigt an, dass der Zustand \\(x\\) geschÃ¤tzt ist. Was Ã¼blicherweise die Value function \\(V\\) ist, ist in dieser Vorlesung \\(J\\) . \\(g_N&#94;x\\) ist die Ableitung der Funktion \\(g_N\\) nach \\(x\\) . Material und Links Vorlesungswebsite Anki-Karteikarten Deck Dimitri Bertsekas: Dynamic Programming and Optimal Control: Volume 1 (POMDP) Emanuel Todorov: Optimal Control Theory (fÃ¼r Pontryagins Minimum-Prinzip) Dan Simon: Optimal State Estimation (Kalman-Filter) Complexity of some well-known games sowie xkcd: Game AIs Stack Exchange Why is \\(f_x(Ax + b) = f_x(x)\\) ? How can I solve an optimization problem \\(x&#94;T A x\\) with constraint \\(x&#94;T x = 1\\) ? Diverging Gradient Descent Does the Gauss-Newton algorithm work with the Hesse matrix or Jaccobi matrix? What is the relationship between the Markov property and optimal substructure? Optimization Basics Mein PrÃ¼fungsprotokoll Fazit Die Vorlesung fÃ¼hrt in das Reinforcment Learning ein. Um das Problem und die mÃ¶glichen Algorithmen zu verstehen werden MDPs und POMDPs eingefÃ¼hrt. Die Vorlesung ist sehr gut strukturiert. Alle Grundlagen werden eingefÃ¼hrt, sodass sehr wenig Vorwissen nÃ¶tig ist. Dennoch sind absolute Grundlagen der Wahrscheinlichkeitstheorie und der Optimierungstheorie / Analysis empfehlenswert; sonst geht es zu schnell. Aktuell sieht man als Student immer wieder mal zusammenhÃ¤nge nicht. Es ist in dieser Vorlesung essentiell am Ball zu bleiben, sonst wird man schnell abgehÃ¤ngt. Ich empfehle die Tabelle anzuschauen; daran kann man einige ZusammenhÃ¤nge gut erkennen. Der Dozent ist sehr freundlich und scheinbar immer gut gelaunt, beantwortet Fragen kompetent und sorgt allgemein fÃ¼r eine sehr angenehme AtmosphÃ¤re sowohl in der Vorlesung als auch in der PrÃ¼fung. Das Tempo der Vorlesung ist eigentlich sehr gut, aber es gibt immer wieder Stellen wo man schnell abgehÃ¤ngt wird. Daher wÃ¤re es wÃ¼nschenswert, auf den lÃ¤ngeren StÃ¼cken vielleicht an der Tafel den aktuellen Kontext zu geben (z.B.: POMDP, linearer Spezialfall). Insgesamt kann ich sagen, dass es eine meiner Lieblingsvorlesungen war. Es war aber auch eine der Vorlesungen, wo ich mir am meisten Sorgen Ã¼ber die PrÃ¼fung gemacht habe und enorm viel Zeit reingesteckt habe. Es hat sich - sowohl von der Note, als auch vom Wissensgewinn - gelohnt. VorlesungsÂ­empfehlungen Folgende Vorlesungen sind Ã¤hnlich: Analysetechniken groÃŸer DatenbestÃ¤nde Informationsfusion Machine Learning 1 Machine Learning 2 Mustererkennung Neuronale Netze Lokalisierung Mobiler Agenten Probabilistische Planung Weitere: EinfÃ¼hrung in die Bildfolgenauswertung Content-based Image and Video Retrival Termine und Klausurablauf Die Veranstaltung wird mÃ¼ndlich geprÃ¼ft. Ãœblicherweise dauert eine PrÃ¼fung zwischen 30 min und 45 min.","tags":"German posts","title":"Probabilistische Planung"},{"url":"https://martin-thoma.com/talking-with-daemons/","text":"Everybody knows that training big machine learning models takes a lot of computing power. However, it takes much less computing power to evaluate the model for a single instance. One important factor when measuring the time of a program which only runs one image classification is the time for loading the model itself. Only the reading / structuring of the computational graph. We don't want to load the model often. One possible way around this is making a web service. The user connects to it, uploads an image and gets the result. But the model is loaded all the time and the web service is running all the time. One problem with this approach is that you might want to work on the web interface and not having to reload the machine learning part all the time. I also think this might be one of the most inefficient ways to realize IPC . Today, it came to my mind that there might be a cleaner approach. I thought about creating a daemon and using RPCs. Credits to codeape . He provided the basis for the examples below. RPC basics RPC is short for remote procedure call . It is a call to a function which is not in the same address space as the calling function. So basically code in program A calls code from program B. In Python, this is actually pretty easy to use with Pyro . Server Create a file summon_daemon.py : #!/usr/bin/env python \"\"\"The server.\"\"\" import Pyro.core class Bartimaeus ( Pyro . core . ObjBase ): \"\"\"The called class.\"\"\" def __init__ ( self ): \"\"\"Constructor.\"\"\" Pyro . core . ObjBase . __init__ ( self ) self . counter = 0 def count ( self , up ): \"\"\"Count up.\"\"\" self . counter += up return \"I was called {count} times.\" . format ( count = self . counter ) Pyro . core . initServer () daemon = Pyro . core . Daemon () uri = daemon . connect ( Bartimaeus (), \"bartid\" ) print ( \"The daemon runs on port: {port}\" . format ( port = daemon . port )) print ( \"The object's uri is: {uri}\" . format ( uri = uri )) daemon . requestLoop () Client And a call_daemon.py : #!/usr/bin/env python \"\"\"Talk with the daemon.\"\"\" import Pyro.core # you have to change the URI below to match your own host/port. bartimaeus = Pyro . core . getProxyForURI ( \"PYROLOC://localhost:7766/bartid\" ) print ( bartimaeus . count ( 1 )) Timing I was interested how fast this is locally. So I made a tiny test: Server ( summon_daemon.py ): #!/usr/bin/env python # -*- coding: utf-8 -*- \"\"\"The server.\"\"\" import logging import sys import Pyro.core logging . basicConfig ( format = ' %(asctime)s %(levelname)s %(message)s ' , level = logging . DEBUG , stream = sys . stdout ) class Bartimaeus ( Pyro . core . ObjBase ): \"\"\"The called class.\"\"\" def __init__ ( self ): \"\"\"Constructor.\"\"\" Pyro . core . ObjBase . __init__ ( self ) self . counter = 0 def count ( self , up ): \"\"\"Count up.\"\"\" logging . info ( \"new up: %i \" , up ) self . counter += up return \"I was called {count} times.\" . format ( count = self . counter ) Pyro . core . initServer () daemon = Pyro . core . Daemon () uri = daemon . connect ( Bartimaeus (), \"bartid\" ) print ( \"The daemon runs on port: {port}\" . format ( port = daemon . port )) print ( \"The object's uri is: {uri}\" . format ( uri = uri )) daemon . requestLoop () Client ( call_daemon.py ): #!/usr/bin/env python # -*- coding: utf-8 -*- \"\"\"Talk with the daemon.\"\"\" import logging import sys import Pyro.core logging . basicConfig ( format = ' %(asctime)s %(levelname)s %(message)s ' , level = logging . DEBUG , stream = sys . stdout ) def main ( up ): \"\"\"Do something with bartimaeus - who lives in another realm.\"\"\" # you have to change the URI below to match your own host/port. logging . info ( \"Send up: %i \" , up ) bartimaeus = Pyro . core . getProxyForURI ( \"PYROLOC://localhost:7766/bartid\" ) print ( bartimaeus . count ( up )) def get_parser (): \"\"\"Get parser object for call_demon.py.\"\"\" from argparse import ArgumentParser , ArgumentDefaultsHelpFormatter parser = ArgumentParser ( description = __doc__ , formatter_class = ArgumentDefaultsHelpFormatter ) parser . add_argument ( \"-n\" , dest = \"up\" , default = 1 , type = int , help = \"count up\" ) return parser if __name__ == \"__main__\" : args = get_parser () . parse_args () main ( args . up ) resulting in about 0.004s from sending to receiving. About 0.004s from sending to receiving A small chat You could implement a very simple chat with this. I only have version 3.16 of Pyro which seems not to have callbacks so that the server can inform the client when a new message is there. This means the following toy implementation expects the user to send messages to receive the current ones. Not nice, but I just wanted to give it a try: Server: #!/usr/bin/env python \"\"\"A chat server.\"\"\" import Pyro.core class Chat ( Pyro . core . ObjBase ): \"\"\"The called class.\"\"\" def __init__ ( self ): \"\"\"Constructor.\"\"\" Pyro . core . ObjBase . __init__ ( self ) self . msgs = [] self . clients = [] def receive ( self , sender , msg , last_msg ): \"\"\"Receive a message.\"\"\" self . msgs . append (( sender , msg )) print ( \"[{sender}] {msg}\" . format ( sender = sender , msg = msg )) return ( self . msgs [ last_msg :], len ( self . msgs )) Pyro . core . initServer () daemon = Pyro . core . Daemon () uri = daemon . connect ( Chat (), \"chat\" ) print ( \"The daemon runs on port: {port}\" . format ( port = daemon . port )) print ( \"The object's uri is: {uri}\" . format ( uri = uri )) daemon . requestLoop () Client: #!/usr/bin/env python # -*- coding: utf-8 -*- \"\"\"A chat client.\"\"\" import logging import sys import Pyro.core logging . basicConfig ( format = ' %(asctime)s %(levelname)s %(message)s ' , level = logging . DEBUG , stream = sys . stdout ) def main ( server , name ): \"\"\"Run the chat.\"\"\" chat_server = Pyro . core . getProxyForURI ( server ) last_msg_id = 0 print ( \"*\" * 80 ) print ( \"* Chat started. You are called '{name}'.\" . format ( name = name )) print ( \"*\" * 80 ) while True : msg = raw_input () new_msgs , last_msg_id = chat_server . receive ( name , msg , last_msg_id ) for sender , msg in new_msgs : print ( \"[{sender}] {msg}\" . format ( sender = sender , msg = msg )) def get_parser (): \"\"\"Get parser object for chat_client.py.\"\"\" from argparse import ArgumentParser , ArgumentDefaultsHelpFormatter parser = ArgumentParser ( description = __doc__ , formatter_class = ArgumentDefaultsHelpFormatter ) parser . add_argument ( \"--server\" , dest = \"server\" , required = True , help = \"starts with PYRO://\" ) parser . add_argument ( \"--name\" , required = True , help = \"what others see\" ) return parser if __name__ == \"__main__\" : args = get_parser () . parse_args () main ( args . server , args . name ) Daemons A daemon is a computer program that runs as a background process, rather than being under the direct control of an interactive user. You can create a simple daemon , too. See also Web Service for IPC: Pros and Cons?","tags":"Code","title":"Talking with Daemons"},{"url":"https://martin-thoma.com/analysetechniken-grosser-datenbestaende/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žAnalysetechniken fÃ¼r groÃŸe DatenbestÃ¤nde\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr.-Ing. Klemens BÃ¶hm im Wintersemester 2015/2016 gehÃ¶rt. In der Vorlesung 'Analysetechniken fÃ¼r groÃŸe DatenbestÃ¤nde' werden vor allem Association Rule Mining und Clustering-Techniken besprochen. Zum Association Rule minining ist vor allem der Apriori-Algorithmus sowie die Verbesserung mit FP-Trees zu nennen. Beim Clustering ist k-means, EM, DBSCAN, OPTICS und BIRCH von groÃŸer Bedeutung. Ein weiteres groÃŸes Kapitel sind Bayessche Netze. Behandelter Stoff Ãœbersicht Datum Kapitel Inhalt 20.10.2015, 08:00 Einleitung (Folie 1-26) Overfitting, EntscheidungsbÃ¤ume, 1-Rules (â†’ Decision Strump), Outliers Mengenwertige Attribute, Kategorische Attribute, Zeitreihen Clustering Market Basket Analysis: Zusammenhang zwischen Waren Association rules (Apriori Algorithmus) 20.10.2015, 11:30 Einleitung, Statistische Tests (Folie 27 - 43) Predictive Maintenance 27.10.2015, 08:00 Statistische Tests (Folie 38 - ) $\\chi&#94;2$-Test, $\\chi&#94;2 = \\sum_{i=1}&#94;{m_1} \\sum_{j=1}&#94;{m_2} \\frac{(h_{ij}- e_{ij})&#94;2}{e_{ij}}$ mit erwartetem Wert $e$ (Sind zwei Zufallsvariablen unabhÃ¤ngig) Kolmogorov-Smirnov-Test (Sind 2 Verteilungen unabhÃ¤ngig; bei kontinuierlichen Zufallsvariablen) Wilcoxon-Mann-Whitney Test Bernoulli-Experiment (Folie 53?) Datenreduktion (Attribute entfernen, z.B. PCA; DatensÃ¤tze entfernen, z.B. Clustering; Attributsgenauigkeit reduzieren) Diskretisierung: Zielfunktion ist Information Gain. Dieser soll minimiert werden. 03.11.2015, 08:00 RÃ¤umliche Indexstrukturen Widerholung der Statistischen Tests 03.11.2015, 11:30 EntscheidungsbÃ¤ume, Evaluation (1-18) Split-Attribute, Pruning; Loss-Funktionen 17.11.2015, 08:00 Evaluation (19-47) QulitÃ¤tsmaÃŸe (Korrelationskoeffizient) 17.11.2015, 11:30 Evaluation, Association Rules (1-26) 41 min Evaluation, dann Association Rules. Frequent Itemset, Apriori-Algorithmus 24.11.2015, 08:00 Kapitel 6: Association Rules (12-Ende), Kapitel 7 (1-12) Apriori-Algorithmus, Hash-Tree, Multidimensionale Association Rules, Level-Crossing-Association Rules, FP-Trees 01.12.2015, 08:00 Kapitel 7, Kapitel 8 (Pattern Mining mit Constraints) Korrekturen zu Kapitel \"Evaluation\"; Wiederholung von Apriori-Algorithmus und Hash-Filter; ab Minute 27 FP-Trees 01.12.2015, 11:30 Kapitel 8 (Pattern Mining mit Constraints), Kapitel 9 (Clustering) Meta-Rule-Guided Mining, Anti-MonotonizitÃ¤t, Support-basiertes Pruning, Constrained Sequences, Clustering Criterion Function 15.12.2015, 08:00 Kapitel 9 (Clustering) k-means; CF-Trees 15.12.2015, 11:30 Kapitel 9 (Clustering) CF-Trees; Hierarchisches Clustern mit Minimum Spanning Tree; DIANA; Hochdimensionale MerkmalsrÃ¤ume 08.12.2015, 08:00 R-Ãœbung - 19.01.2016, 08:00 Kapitel 9 Jaccard Koeffizient, ... 19.01.2016, 11:30 Kapitel 9; Kapitel 10 (1 - ) EM-Algorithmus; Generative Modelle 26.01.2016, 08:00 Ãœbung - 26.01.2016, 11:30 Kapitel 10 Regression 02.02.2016, 08:00 Kapitel 10 Logistische Regression, Cross Entropy Einleitung Slides: 1-Einleitung.pdf Aufgabentypen Klassifikation Clustering Finden von Association Rules 1-Rule ( Decision stump ) 1-Rules ist ein Klassifikationsverfahren. Jedes Attribut wird fÃ¼r sich betrachtet. Es wird anhand von dem Attribut gesplittet, bei dem die Fehlerquote am geringsten ist. Clustering Suchen von Punkten, die nahe bei einander liegen. Unterschiede: Attribute: AbstandsmaÃŸe Form Dichte GrÃ¶ÃŸe Zeitlicher Aspekt: Alte Daten weniger wichtig Alternate Clustering Association Rules Association Rules sind Regeln der Form: Wenn eine Transaktion A enthÃ¤lt, dann auch B (formal: $A \\Rightarrow B$). Association rules werden z.B. in der Market Basket Analysis eingesetzt. Sie kÃ¶nnen aus Frequent item sets relativ einfach erzeugt werden. Der Apriori Algorithmus dient dem Finden von Association Rules. Association Rules sind stark mit Collaborative filtering verwandt. Predictive Maintenance Ziel: FÃ¼r Motoren will man vorhersagen, wann diese einen Fehler aufweisen und damit gewartet werden mÃ¼ssen. Dabei gibt es zwei Fehlerarten, die unterschiedliche hohe Kosten aufweisen: Ausfall wird vorhergesagt, tritt aber nicht ein: UnnÃ¶tige Wartung Ausfall wird nicht vorhergesagt, tritt aber ein: Teurer Ausfall Change detection Erkennung wesentlicher VerÃ¤nderungen in einer Zeitreihe. Statistische Grundlagen Slides: 2-statistGrundlagen.pdf Skalen von Merkmalen Siehe Mustererkennung Kennzahlen fÃ¼r Daten Median / Mean Min / Max Quantile Varianz / Streuung Outlier Metrische Daten Ein Metrischer Raum ist eine Menge $M$ mit einer Funktion $d: M \\times M \\rightarrow \\mathbb{R}_0&#94;+$ fÃ¼r die gilt: Symmetrie: $\\forall p,q \\in M: d(p, q) = d(q, p) $ Definitheit: $\\forall p,q \\in M: d(p, q) = 0 \\Leftrightarrow p = q$ Dreiecksungleichung: $\\forall p,q,r \\in M: d(p, r) \\leq d(p,q) + d(q, r)$ Aggregatfunktion Eine Funktion, welche als Eingabe eine Menge von Werten erwartet und einen Wert ausgibt (z.B. SUM, COUNT, MIN, MAX, AVG, MEAN, hÃ¤ufigster Wert, Truncated Average, mid range). Aggregatfunktionen sind entweder distributiv , algebraisch oder holistisch . Distributive Aggregatfunktion Es gibt eine Funktion $G$, so dass $$F(\\{X_{i,j}\\}) = G(\\{F(X_{i,j} | i=1, \\dots, l) | j = 1, \\dots, J\\})$$ MIN, MAX und COUNT sind distributive Aggregatfunktionen. Algebraische Aggregatfunktion Es gibt eine Funktion $G$, die ein $M$-Tupel liefert und $H$, so dass $$F(\\{X_{i,j}\\}) = H(\\{G(\\{X_{i,j} | i=1, \\dots, l\\}) | j=1, \\dots, J\\})$$ AVG ist eine Algebraische Aggregatfunktion. Hier berechnet $G$ die Summe und gibt zusÃ¤tzlich die Anzahl der Werte zurÃ¼ck. $H$ summiert die Summen auf und teilt das Ergebnis durch die Gesamtzahl. Weitere: Truncated Average Holistische Aggregatfunktion Man kann keine BeschrÃ¤nkung des Speicherbedarfs fÃ¼r Sub-Aggregate, d.h. Aggregate Ã¼ber $\\{X_{i,j}| i=1, \\dots, l\\}$, angeben. Der hÃ¤ufigste Wert und der Median sind holistische Aggregatfunktionen. Self-Maintainable Aggregatfunktion Wenn man den aktuellen Wert der Aggregatfunktion kennt und man lÃ¶scht einen Wert bzw. fÃ¼gt einen Wert ein, dann kann man direkt den neuen Wert der Aggregatfunktion Ã¼ber den angepassten Datenbestand berechnen. Nicht-self-maintainable ist der hÃ¤ufigste Wert. MIN und MAX ist self-maintainable bzgl. EinfÃ¼gen. Mid-Range $$\\frac{MAX-MIN}{2}$$ Entropie $$E(S) = - \\sum_{j} p_j \\cdot \\log p_j$$ $E(S)=0$ ist minimal, wenn es ein $j$ gibt mit $p_j = 1$. $E(S)=\\log(n)$ ist maximal, wenn $p_i = p_j$ gilt fÃ¼r $i, j$. KorrelationsmaÃŸe Sind Ã¼blicherweise auf [-1, 1] normiert. Die Kovarianz ist ein nicht-normiertes KorrelationsmaÃŸ. Kovarianz $$\\operatorname{Cov}(X,Y) := \\operatorname E\\bigl[(X - \\operatorname E(X)) \\cdot (Y - \\operatorname E(Y))\\bigr]$$ Korrelationskoeffizient $$\\varrho(X,Y) =\\frac{\\operatorname{Cov}(X,Y)}{\\sigma(X)\\sigma(Y)} \\in [-1, 1]$$ PCA ( Principal Component Analysis ) PCA ist ein Algorithmus zur Reduktion von Daten durch das Entfernen von Attributen. Er projeziert die Datenobjekte auf eine Hyperebene, sodass ein Maximum der Varianz beibehalten wird (vgl. Neuronale Netze ) Chi-Quadrat-Test Oberbegriff fÃ¼r mehrere Tests; hier nur der UnabhÃ¤ngigkeitstest. Gegeben sind zwei Verteilungen von Zufallsvariablen $X, Y$. Die Frage ist, ob sie unabhÃ¤ngig sind. Dazu zÃ¤hlt man die AusprÃ¤gungen $i=1, \\dots, m_1$ des Merkmals $X$ und die AusprÃ¤gungen $j=1, \\dots, m_2$ des Merkmals $Y$ sowie wie hÃ¤ufig diese in Kombination auftreten ($n_{ij}$). Man schÃ¤tzt den erwarteten Wert durch $e_{ij} = \\frac{1}{n} \\left(\\sum_{k=1}&#94;{m_2} n_{ik} \\right) \\cdot \\left (\\sum_{k=1}&#94;{m_2} n_{kj}\\right )$. Der Chi-Quadrat wert ist dann: $$\\chi&#94;2 = \\sum_{i=1}&#94;{m_1} \\sum_{j=1}&#94;{m_2} \\frac{(n_{ij} - e_{ij})&#94;2}{e_{ij}}$$ Daraus wird ein $p$-Wert abgeleitet. Wenn dieser unter einem Schwellwert wie $\\alpha = 0.01$ ist, dann wird die Hypothese, dass die Verteilungen unabhÃ¤ngig sind, zurÃ¼ckgewiesen. Die Nullhypothese, dass $X, Y$ unabhÃ¤ngig sind wird auf dem Signifikanzniveau $\\alpha$ verworfen, falls $$\\chi&#94;2 > \\chi&#94;2_{(1-\\alpha; (m_1-1)(m_2-1))}$$ Kolmogorow-Smirnow-Test ( KSA-Test ) Test auf unabhÃ¤ngigkeit kontinuierlicher Verteilungen, also: $$H_0: F_X(x) = F_0(x)$$ Es wird die empirsche Verteilungsfunktion $S$ gebildet und diese mit der hypothetischen Verteilungsfunktion $F_0$ verglichen, wobei $S(x_0) = 0$ gesetzt wird: $$d_{\\max} = \\max(\\max_{i=1, \\dots, n}|S(x_i) - F_0(x_i)|, \\max_{i=1, \\dots, n} |S(x_{i-1} - F_0(x_i))|)$$ $H_0$ wird verworfen, wenn $d_{\\max} > d_\\alpha$, wobei $d_\\alpha$ bis zu $n=35$ tabelliert vorliegt. Bei groÃŸerem $n$ kann nÃ¤herungsweise $$d_\\alpha = \\sqrt{\\frac{-\\frac{1}{2} \\ln(\\frac{\\alpha}{2})}{n}}$$ Wilcoxon-Mann-Whitney-Test ($U$-Test) Es seien $X,Y$ Zufallsvariablen mit Verteilungsfunktionen $F_X(x) = F_Y(x-a)$ fÃ¼r ein $a \\in \\mathbb{R}$. $H_0: a = 0$ vs $H_1: a \\neq 0$ Vorgehen: Gemeinsame Stichprobe sortieren, Rangsumme fÃ¼r $X$ und $Y$ bilden, Betrag der Differenz mit Tabelleneintrag vergleichen. Datenreduktion Numerosity Reduction: Reduziere die Anzahl der betrachteten Datenobjekte Parametrische Verfahren: Nehme eine bekannte WahrscheinlichkeitsÂ­verteilung der Datenobjekte an und schÃ¤tze deren Paramter. Arbeite dann nur mit der Verteilung Nichtparametrische Verfahren: Sampling, Clustering, Histogramme Dimensionality Reduction: Reduziere die Anzahl der Attribute. Forward Feature Construction: Starte nur mit einem Feature und gebe dem Classifier so lange neue Features, bis die gewÃ¼nschte Genauigkeit erreicht wurde. Feature Elimination: Starte mit allen Features und entferne so lange Features, wie die gewÃ¼nschte Genauigkeit erhalten bleibt. PCA Diskretisierung: Reduziere die Werte pro Attribut. Visualisierung von Daten Boxplots: Whiskers Histogramme: Nicht geeignet fÃ¼r viele Dimensionen. Dendogramme Grundbegriffe der Wahrscheinlichkeitstheorie Wahrscheinlichkeitsraum Ereignis Ergebnis Ergebnismenge $\\Omega$ WahrscheinlichkeitsÂ­maÃŸ Kovarianzmatrix Bernoulli-Experiment RÃ¤umliche Indexstrutkuren Slides: 3-Informatik-Grundlagen.pdf B + -Tree (see YouTube ) A balanced search tree. Index Beschleunigung der Suche von linearer Suchzeit auf logarithmische durch B + -BÃ¤ume . Anfragetypen Punkt-Anfragen: Ist ein Punkt im Datensatz? Bereichs-Anfragen: Ist mindestens ein Datenobjekt im gegebenen Bereich? Nearest-Neighbor-Anfragen (NN-Anfragen): Was ist das nÃ¤chste Datenobjekt zu einem gegebenen Punkt? kD-Baum Siehe Computergrafik . kDB-Baum Ein balancierter kD-Baum. Die Balancierung wird durch eine Kombination aus heterogenem k-d-Baum und B*-Baum erreicht. Der baum ist also nicht auf logischer, sondern nur auf physischer Ebene balanciert. R-Baum Ein R-Baum ist ein balancierter Baum, welcher die Datenobjekte in minimale AABBs einschlieÃŸt. Jeder Knoten hat eine solche AABB und jedes der Kinder - egal ob es wieder ein AABB oder Datenpunkte sind - ist darin. Diese AABBs kÃ¶nnen sich Ã¼berschneiden. Siehe auch: What is the difference between a R-tree and a BVH? Nearest Neighbor in R-Tree Siehe Pseudo-Code . EntscheidungsÂ­bÃ¤ume Slides: 4-Entscheidungsbaeume.pdf Dieses Kapitel beschÃ¤ftigt sich mit der Klassifikation mit EntscheidungsbÃ¤umen. QualitÃ¤tskriterien fÃ¼r EntscheidungsbÃ¤ume ErgebnisqualitÃ¤t Kompaktheit: Je kompakter der Baum, desto besser kann die Entscheidung vom Benutzer nachempfunden werden. Wahl der Split-Attribute Entropie eines Splits minimieren: $$E(S_1, S_2) = \\frac{n_1}{n} E(S_1) + \\frac{n_2}{n} E(S_2)$$ Overfitting Entscheidungsbaum ist zu sehr an Trainingsdatenbestand angepasst Prepruning ( Forward pruning ) Schon beim Erstellen des Entscheidungsbaumes wird ab einer gewissen Tiefe abgebrochen Postpruning ( Backward pruning ) Der Entscheidungsbaum wird komplett aufgebaut, aber dannach wird greprunt. Evaluation Slides: 5-Evaluation.pdf Resubsitution Error Trainingsfehler $k$-Fold Cross-Validation ( Kreuzvalidierung ) Unterteile den Datensatz in $k$ Teile. Dabei sollten die Klassen in etwa gleich hÃ¤ufig in allen Teilen vorkommen. Mache nun $k$ durchlÃ¤ufe, wobei der $k$-te Datensatz immer zum Testen und alle anderen zum Trainieren verwendet werden. Berechne die $k$ Testfehler. Mittle diese am Ende. Das ist ein besserer SchÃ¤tzwert fÃ¼r den realen Fehler als eine einmalige Unterteilung in Training- und Testmenge. Stratification Sicherstellen, dass bestimmte Eigenschaften (z.B. KlassenzugehÃ¶rigkeit) in Partitionen etwa gleich verteilt ist. Loss function Eine Funktion, die angibt, wie viel man durch eine unkorrekte Vorhersage verliert. Informational Loss function $$- \\log_2 p_i$$ - Wahrscheinlichkeiten der nicht-eintretenden Klassen spielen keine Rolle Quadratic Loss function $$\\sum_{j} (p_j - a_j)&#94;2$$ mit tatsÃ¤chlichem Label $a_j \\in \\{0,1\\}$ und geschÃ¤tzter Wahrscheinlichkeit $p_j$ fÃ¼r die Klasse $j$. Bias Das Verfahren an sich funktioniert nicht gut. Selbst beliebig viele Trainingsdaten beheben dieses Problem nicht. Der Fehler ist inhÃ¤rent im Verfahren verankert. Varianz Fehler welcher durch das Fehlen von Trainingsdaten verursacht wird. Gesamt-Erfolgsquote $$\\frac{TP+TN}{TP+TN+FP+FN}$$ Konfusionsmatrix ( Confusion matrix ) Eine Tabelle, in der jede Zeile fÃ¼r die tatsÃ¤chlichen Klassen stehen und die Spalten fÃ¼r die vorhergesagten Klassen. Die Diagonalelemente zÃ¤hlen also die richtig vorhergesagten Datenobjekte; alle anderen Zellen zÃ¤hlen falsche Vorhersagen. Kappa-Koeffizient ( Cohens Kappa ) Vergleich mit Klassifier, der nur den Anteil der KlassenzugehÃ¶rigkeit schÃ¤tzt: $$\\kappa =\\frac{p_0-p_c}{1-p_c}$$ wobei $p_0$ die gemessene Ãœbereinstimmung ist und $p_c$ die erwartete Ãœbereinstimmung bei UnabhÃ¤ngigkeit. Wenn also $h_{ij}$ die Anzahl der Datenobjekte ist, fÃ¼r die der erste Klassifizierer die Klasse $i$ und der zweite Klassifizierer die Klasse $j$ vorhergesagt hat sowie $N$ die Gesamtzahl der Datenobjekte und $z$ die Gesamtzahl der Klassen, dann gilt: $$p_0 = \\frac{\\sum_{i=1}&#94;z h_{ii}}{N}$$ Die erwartete Ãœbereinstimmung $p_c$ wird Ã¼ber die RandhÃ¤ufigkeiten geschÃ¤tzt: $$p_c = \\frac{1}{N&#94;2} \\sum_{i=1}&#94;z h_{.i} \\cdot h_{i.}$$ Der Wertebereich ist also: $\\kappa \\in (-\\infty; 1]$, wobei der minimale Wert von $\\kappa$ nicht beliebig klein werden kann. Lift-Faktor Faktor, um den sich die RÃ¼cklaufquote erhÃ¶ht: $$\\mathrm{lift}(X\\Rightarrow Y) = \\frac{ \\mathrm{support}(X \\cup Y)}{ \\mathrm{support}(X) \\cdot \\mathrm{support}(Y) }$$ Der Lift ist ein Indiz fÃ¼r die UnabhÃ¤ngigkeit von $X$ und $Y$. Ist der Lift nahe bei 1, dann spricht das fÃ¼r die UnabhÃ¤ngigkeit. Ein Lift-Faktor kleiner als 1 bedeutet, dass die Itemsets zusammen seltener vorkommen als bei UnabhÃ¤ngigkeit zu erwarten wÃ¤re. Ein Lift-Faktor von grÃ¶ÃŸer als 1 bedeutet, dass die Itemsets zusammen hÃ¤ufiger vorkommen als bei UnabhÃ¤ngigkeit zu erwarten wÃ¤re. ROC ( Receiver Operator Characteristic ) x-Achse: $\\frac{FP}{FP+TN} \\cdot 100$ (FP-Rate), y-Achse: $\\frac{TP}{TP+FN} \\cdot 100$ (TP-Rate) Siehe auch: Namensherkunft Recall ( True Positive Rate , TPR , SensitivitÃ¤t ) $$TPR = \\frac{TP}{TP + FN} = 1 - FNR \\in [0, 1]$$ Der Recall gibt den Anteil der erkannten positiven aus allen positiven an. SensitivitÃ¤t ist ein in der Medizin Ã¼blicher Begriff. Precision ( Genauigkeit ) $$Precision = \\frac{TP}{TP + FP} \\in [0, 1]$$ Die Precision gibt den Anteil der real positiven aus den als positiv erkannten an. F-Measure ( F1 score ) $$\\frac{2 \\cdot \\text{precision} \\cdot \\text{recall}}{\\text{recall} + \\text{precision}}$$ Correlation Coefficient Der Correlation Coefficient ist kein FehlermaÃŸ. Der $CC(p, a)$ ist groÃŸ, wenn sich $p$ und $a$ Ã¤hnlich sind. $$CC(p, a) = \\frac{COV(p, a)}{\\sigma(p) \\cdot \\sigma(a)}$$ Mit $\\sigma(x) = \\frac{1}{n-1} \\cdot \\sum_{i} (x_i - \\bar{x})&#94;2$ Code Abbildung, die jedem Element des Alphabets eine Folge aus 0en und 1en zuweist. Beispiele: Morse-Code Unicode Ascii-Code Minimum Description Length ( MDL ) Minimale LÃ¤nge zum Beschreiben des Modells. Weiteres: QualitÃ¤tsmaÃŸe fÃ¼r numerische Vorhersagen Fragen: Folie 23: Wo kommt die 140 her? â†’ Summe der Diagonalelemente auf Folie 21. Folie 27: Lift Faktor ist 2 wenn man nur die 400 anschreibt, oder? Association Rules Slides: 6-Association-Rules-1.pdf und 7-Association-Rules-2.pdf Es zieht sich die Warenkorbanalyse als Beispiel durch. Allerdings sind folgende Anwendungen von Association Rules denkbar: Netflix: Man kennt User und welche Filme diese mÃ¶gen (5 Sterne). Welche weiteren, unbewerteten Filme kÃ¶nnten diesen gefallen? Amazon: Im Warenkorb sind Produkte XY. Was wird der User wohl noch kaufen? Online-Konfiguratoren: Welche Konfigurationen sollte man \"bÃ¼ndeln\", z.B. bei Autos in eine \"Sport-Variante\"? Last FM: Music Recommendations Medicine: Implementation of Apriori Algorithm in Health Care Sector: A Survey Frequent Itemset Ein Frequent Itemset ist eine Menge von Items, die hÃ¤ufig zusammen gekauft werden. Transaktion ( Itemset ) Menge von Items, die zusammen gekauft wurden. Association rules DrÃ¼cken aus wie PhÃ¤nomene zueinander in Beziehung stehen. Beispiel: Wer Bier kauft, der kauft auch Chips. Support Die Anzahl der Transaktionen, die das Itemset $I$ enthalten wird Support von $I$ genannt. Es gilt: $$\\text{support}(A \\Rightarrow B) = \\text{support}(A \\cup B)$$ Closed Itemset Ein Itemset $I$ heiÃŸt closed, wenn es keine echte Obermenge $I' \\supsetneq I$ gibt, die den gleichen Support $\\text{support}(I') = \\text{support}(I)$ hat. Confidence Confidence von $A \\Rightarrow B$ ist der Anteil der Transaktionen, die $A$ und $B$ enthalten, von den Transaktione die $A$ enthalten: $$\\text{conf}(A \\Rightarrow B) = \\frac{\\text{support}(A \\cup B)}{\\text{support}(A)} \\in [0, 1]$$ Apriori Algorithmus Der Apriori-Algorithmus ist ein Generate-and-Test-Algorithmus zum Finden von Frequent Itemsets. Erzeuge alle einelementigen Frequent Itemsets for k in range(2, n): Erzeuge die $k$-elementigen frequent Itemsets (join, prune, support counting) Frequent itemsets: Association Rules Der Algorithmus nutzt aus, dass eine notwendige Bedingung fÃ¼r $k$-elementige Frequent Itemsets ist, dass alle $k-1$-elementigen Frequent Itemsets auch Frequent sein mÃ¼ssen. Verbesserungen: Stichproben verwenden (Sampling) Aggressiver durch Datenbestand gehen (z.B. von k=3 zu k=6 springen) Hashfilter Hash-Filter ( Hash-Tabelle ) UnterstÃ¼tzt das Support-Counting fÃ¼r viele Kandidaten. Die Hash-Tabelle wird einmalig fÃ¼r alle Kandidaten der LÃ¤nge $k$ aufgebaut und stellt eine notwendige, aber keine hinreichnde Bedingung fÃ¼r Frequent Itemsets dar. Hash Tree Wenn man viele Kandidaten fÃ¼r $k$-elementige Frequent Itemsets hat, dann kann das support counting lange dauern. Deshalb baut man sich vor dem Support Counting fÃ¼r alle Kandidaten einen Hash-Tree mit $k$ Ebenen auf. Man sortiert die Items der Kandidaten auf, indem man einen Pfad fÃ¼r jeden Kandidaten im Baum hinzufÃ¼gt. Jeder Knoten im Hash-Tree enspricht also einem Item. Ein Item $i$ in Ebene $j$ steht dafÃ¼r, dass der Kandidat an Stelle $j$ das Item $i$ hat. Allerdings kann man auch frÃ¼her aufhÃ¶ren, wenn es keine Kollisionen gibt. Der Hash-Tree reprÃ¤sentiert also die Kandidaten, nicht die Transaktionen. FP-Trees FP-Trees (FP fÃ¼r \"frequent pattern\") sind eine Datenstrutkur zum schnellen Finden von Frequent Itemsets. Jeder Knoten im Baum reprÃ¤sentiert ein Item. Jeder Knoten speichert zusÃ¤tzlich die HÃ¤ufigkeit des PrÃ¤fixes, welcher durch den Pfad von der Wurzel zu dem Knoten dargestellt wird. ZusÃ¤tzlich speichert jeder Knoten des Items $i$ einen Zeiger auf einen anderen Knoten mit einem Item $i$. Jede Transaktion entspricht einem Pfad im FP-Tree. ZusÃ¤tzlich zum FP-Tree gibt es eine Header-Tabelle. Die Zeilen dieser Tabelle sind einzelne Items $i$, denen jeweils ein Zeiger auf einen Knoten im FP-Tree zugeordnet sind, der auch das Item $i$ reprÃ¤sentiert. FÃ¼r jedes Item gibt es also eine verkettete Liste, die das Vorkommen im Baum angibt. Zum Finden von Frequent Items geht man also wie folgt vor: FÃ¼r jedes Item: ZÃ¤hle in wie vielen Transaktionen das Item vorkommt. Sortiere Items in Transaktion absteigend nach HÃ¤ufigkeit. Bei gleicher HÃ¤ufigkeit wird z.B. alphabetisch sortiert. Damit ergibt sich eine eindeutige Reihenfolge. Sortiere Transaktionen nach den Items innerhalb der Transaktionen. Aufbau des FP-Trees Aufbau des Baums Aufbau der Header-Tabelle: Absteigend eindeutig nach HÃ¤ufigkeit sortiert Starte mit dem niedrigsten Element in der Header-Tabelle. ÃœberprÃ¼fe den PrÃ¤fix auf den erwarteten Support. Gehe dazu alle Elemente dieses Items durch (alle PrÃ¤fix-Pfade im Baum) und wende eine Art Apriori-Algorithmus an um in diesen PrÃ¤fix-Pfaden mit dem Item $i$ die Frequent-Itemsets zu finden. Siehe auch: Mining Frequent Patterns without Candidate Generation und ein sehr guter Blog post Sampling Berechnung auf einer Stichprobe durchfÃ¼hren Negative Border Die negative border ist abhÃ¤ngig vom minimalen geforderten Support. Wenn dieser Schwellenwert grÃ¶ÃŸer wird, wandert die negative border nach oben; es gibt also weniger frequent Itemsets. Projected Database Zerlegung des Datenbestands in Partitionen (z.B. Transaktionen mit Item A und Transaktionen ohne Item A). Siehe auch: Market Basket Analysis with R Market Basket Analysis and Recommendation Engines Constraints Slides: 8-ConstrainedAssociationRules.pdf Constraint-Typen Data Constraints: EinschrÃ¤nken auf konkrete Werte, z.B. Transaktionen bei denen der Ort Karlsruhe ist. Rule Constraints: z.B. nur Itemsets der GrÃ¶ÃŸe 3 1-var Constraint Nur eine Seite (links oder rechts) der Association Rule wird eingeschrÃ¤nkt. 2-var Constraint Beide Seiten (links und rechts) der Association Rule werden eingeschrÃ¤nkt. Anti-MonotonizitÃ¤t Ein 1-var Constraint heiÃŸt anti-monoton, wenn fÃ¼r alle Mengen $S, S'$ gilt: $$(S \\supseteq S' \\land (S \\text{ erfÃ¼llt } C )) \\Rightarrow S' \\text{ erfÃ¼llt } C$$ Wenn also ein Constraint $C$ fÃ¼r eine Menge $S$ erfÃ¼llt ist, dann auch fÃ¼r jede Teilmenge $S'$. Beispiele: $\\min(S) \\geq v, \\;\\;\\; v \\in \\mathbb{R}$ ist anti-monoton $\\max(s) \\geq v, \\;\\;\\; v \\in \\mathbb{R}$ ist nicht anti-monoton $\\text{size}(s) \\leq v, \\;\\;\\; v \\in \\mathbb{N}$ ist anti-monoton $\\text{size}(s) \\geq v, \\;\\;\\; v \\in \\mathbb{N}$ ist nicht anti-monoton Anti-MonotonizitÃ¤t ist eine gutartige Eigenschaft von Constraints. Hier kann das Constraint sehr frÃ¼h Ã¼berprÃ¼ft werden. Succinctness Ein Constraint heiÃŸt succinct, wenn alle Itemsets die es erfÃ¼llen schnell erzeugt werden kÃ¶nnen. Beispiel: Man hat das Constraint, dass der Typ \"Non-Food\" sein soll. Aber es gibt nur 3 Produkte die diesen Typ haben. Kandidaten, die das Constraint nicht erfÃ¼llen werden gar nicht erst erzeugt. Meta-Rule Guided mining Constraint durch schwÃ¤cheres Anti-Monotones Constraint ersetzen. Clustering Slides: 9-Clustering-1.pdf und 9-Clustering-2.pdf Silhouette-Koeffizient Sei $C = (C_1, \\dots, C_k)$ ein Clustering. Durchschnittlicher Abstand zwischen Objekt o und anderen Objekten in seinem Cluster: $$a(o) = \\frac{1}{|C(o)|} \\sum_{p \\in C(o)} dist(o, p)$$ Durchschnittlicher Abstand zum zweitnÃ¤chsten Cluster: $$b(o) = \\min_{C_i \\in \\text{Cluster} \\setminus C(o)}(\\frac{1}{C_i}) \\sum_{p\\in C_i} \\sum_{p \\in C_i} \\text{dist}(o, p)$$ Silhouette eines Objekts: $$s(o) = \\begin{cases}0 &\\text{if } a(o) = 0, \\text{i.e. } |C_i|=1\\\\ \\frac{b(o)-a(o)}{\\max(a(o), b(o))} &\\text{otherwise}\\end{cases}$$ Es gilt: $$s(o) \\in [-1, 1]$$ $\\text{silh}(C) = \\frac{1}{|C|} \\sum_{C_i \\in C} \\frac{1}{|C_i|} \\sum_{o \\in C_i} s(o)$. Es gilt: $$\\text{silh}(C) \\in [-1; 1]$$ Es ist ein mÃ¶glichst groÃŸer Wert gewÃ¼nscht. Alles kleiner als 0 ist schlecht. Distanzfunktionen fÃ¼r Cluster Seien $X, Y$ Cluster. Durschnittlicher Objektabstand: $\\text{dist}_{avg}(X, Y) = \\frac{1}{|X| \\cdot |Y|} \\cdot \\sum_{x in X, y\\in Y} \\text{dist}(x, y)$ Single Link: $\\text{dist}_{sl}(X, Y) = \\min_{x \\in X, y \\in Y} \\text{dist}(x, y)$ Complete Link: $\\text{dist}_{cl}(X, Y) = \\max_{x \\in X, y \\in Y} \\text{dist}(x, y)$ $k$-means Clustering Siehe ML 1 . CLARANS CLARANS (Clustering Lge AplicationNs based on RANdomized Search) ist ein Clustering-Algorithmus, der mit $k$-Means verwandt ist. Auch er erwartet einen Parameter $k \\in \\mathbb{N}$, der die erwartete Anzahl an Clustern angibt. Dann geht CLARANS davon aus, dass jeder Medeoid durch einen Datenpunkt im Datensatz reprÃ¤sentiert werden kann. FÃ¼r eine zufÃ¤llige Wahl von $k$ Punkten $M = \\{p_1, \\dots, p_k\\}$ wird ein Score berechnet. Dann Ã¼berprÃ¼ft man, was der Tausch eines Punktes $p_i$ durch den Punkt $p_j$ fÃ¼r beliebige $p_i \\in M$ und $p_j \\notin M$ am Score Ã¤ndern wÃ¼rde. Den besten Tausch fÃ¼hrt man durch. Siehe auch: CLARANS: a method for clustering objects for spatial data mining CF-Tree ( Clustering Feature Tree ) Ein CF-Tree ist ein hÃ¶henbalancierter Baum. Jeder Knoten des Baums entspricht ein Cluster. Clustering-Feature (N, LS, SS) fÃ¼r Cluster $C_i$ mit $N = |C_i|$: Anzahl der Punkte im Cluster $LS = \\sum_{i \\in C_i} X_i$ $SS = \\sum_{i \\in C_i} X_i&#94;2$ BIRCH ( Balanced Iterative Reducing and Clustering using Hierarchies ) BIRCH ist ein Clustering-Algorithmus, welcher CF-Trees benutzt und mit wenig Speicherplatz auskommt. Der CF-Tree wird im ersten Schritt aufgebaut. Parameter von BIRCH: $k \\in \\mathbb{N}&#94;+$: Anzahl der Cluster $B \\in \\mathbb{N}&#94;+$: (Fan-out), maximale Anzahl an Kindknoten $B' \\in \\mathbb{N}&#94;+$: maximale Blatt-KapazitÃ¤t (Anzahl Elementarcluster) $T \\in \\mathbb{R}&#94;+$ (Schwellwert): Maximaler Radius (oder Durchmesser), bevor ein Elementar-Cluster gesplittet wird Siehe auch: YouTube (7:24min) BIRCH: an efficient data clustering method for very large databases Hierarchisches Clustering Beim hierarchischen Clustern werden Datenpunkte Baumartig zu Clustern zusammengefasst. Das ganze sieht einem Abstammungsbaum der Arten in der Biologie sehr Ã¤hnlich. Es gibt zwei Vorgehensweisen: Agglomorativ Divisives Clustering Dendrogramme sind eine typische Visualisierung fÃ¼r das Ergebnis einer hierarchischen Clusteranalyse. Probabilistisches Clustering Datenobjekte werden nicht hart zu einem Cluster zugeordnet sondern weich (also mit einer gewissen Wahrscheinlichkeit) jedem Cluster zugeordnet. Zentrum eines Clusters $$Z_{i} = \\frac{1}{|C_i|} \\sum_{i \\in C_i} X_i$$ Radius eines Clusters Der Radius enes Centroids ist der durchschnittliche Abstand zum Centroiden: $$R(C_i) = \\sqrt{\\frac{1}{|C_i|} \\sum_{j \\in C_i} {(X_j - Z_i)}&#94;2}$$ Durchmesser eines Clusters Der Durchmesser eines Centroiden ist die durchschnittle paarweise Distanz: $$D(C_i) = \\sqrt{\\frac{1}{|C_i| \\cdot (|C_i|-1)} \\sum_{j \\in C_i} \\sum_{k \\in C_i} {(X_j - X_k)}&#94;2}$$ Interclusterdistanz Durchschnittliche Inter-Clusterdistanz von Cluster 1 und Cluster 2: $$D(C_1, C_2) = \\sqrt{\\frac{\\sum_{i \\in C_1} \\sum_{j \\in C_2} {(X_i - X_j)}&#94;2}{|C_1| \\cdot |C_2|}}$$ Agglomeratives Clustering Jedes Objekt ist ein Cluster. FÃ¼ge die Cluster in die Menge $M$ ein. Berechne alle paarweise AbstÃ¤nde zwischen Clustern in $M$. Das ist in $\\mathcal{O}(|M|&#94;2)$. Merge das Paar $A, B$ mit kleinstem Abstand zu $C = A \\cup B$. Entferne $A, B$ aus $M$ und fÃ¼ge $C$ ein. Abbruch, wenn $|M| = 1$ Gehe zu Schritt 2. GesamtkomplexitÃ¤t: $\\mathcal{O}(n&#94;2)$ Siehe auch: AGNES Divisives Clustering ( DIANA , DIvisive ANAlysis ) Divisives Clustering ist ein hierarchisches Clusteringverfahren. Es startet mit einem groÃŸen Cluster und unterteilt diesen rekursiv immer weiter in je zwei kleine Cluster. Das Unterteilen funktioniert wie folgt: WÃ¤hle in einem Cluster $C$ das Datenobjekt $o$, welches den hÃ¶chsten durchschnittlichen Abstand von allen anderen Datenobjekten $o' \\in C \\setminus \\{o\\}$ hat. Dieses ist nun das erste Objekt einer neu erstellten sogenannten Splittergruppe $S = \\{o\\}$ (engl. splinter group ). Nun gibt es noch das MaÃŸ $$D(o) = \\sum_{o' \\in C \\setminus S} \\frac{d(o, o')}{|C \\setminus S|} - \\sum_{o'} \\frac{d(o, o')}{|S|}$$ Solange $D(o) > 0$ fÃ¼r ein $o \\in C \\setminus S$ wird $o&#94;* = \\text{arg max}_{o \\in C \\setminus S} D(o)$ aus dem Cluster in die Splittergruppe gesteckt. Siehe auch: R implementierung Leonard Kaufman, Peter J. Rousseeuw: Finding Groups in Data: An Introduction to Cluster Analysis. Projected Clustering Input sind die Anzahl $k$ der Cluster, die gefunden werden sollen und die durchschnittliche Anzahl der Dimensionen pro Cluster $l$. Output ist eine Partitionierung der Daten in $k+1$ Mengen Manhatten Segmental Distance $d(x_1, x_2) = \\frac{1}{n} \\cdot \\sum_{i=1}&#94;n |x_1&#94;{(i)} - x_2&#94;{(i)}|$ wobei $n$ die Anzahl der Dimensionen von $x_1, x_2$ ist. Link-based Clustering Connect all data objects which are closter than $d$ Remove all data objects which have less than $c$ edges Clusters are now connected data objects. The removed elements are noise. Jaccard Koeffizient $$J(A, B) = \\frac{|A \\cap B|}{|A \\cup B|} \\in [0; 1]$$ DBSCAN DBSCAN ist ein Algorithmus zum finden von Clustern. Er unterscheidet 3 Arten von Datenpunkten: Dichte Objekte: Epsion-Umgebung hat viele Datenobjekte. Dichte-erreibare Objekte: In Epsilon-Umgebung von dichten Objekt. AusreiÃŸer: Weder dicht noch dichte-erreichbar. Idee: Gehe Ã¼ber alle Punkte $p \\in P$ genau ein mal. Sei $P' \\leftarrow P$ die Menge der nicht-markierten Punkte. Solange $|P'| > 0$ wird ein Punkt entnommen. Ist er dicht, so ist es ein neues Cluster. Von diesem Punkt aus wird rekursiv alles in der $\\varepsilon$-Umgebung zum Cluster hinzugefÃ¼gt. Hat der Punkt weniger als min_point Punkte in seiner $\\varepsilon$-Umgebung, so wird er als AusreiÃŸer markiert. Siehe auch: A density-based algorithm for discovering clusters in large spatial databases with noise Noise Noise sind Punkte, die zu keinem Cluster gehÃ¶ren. Outlier Noise, welcher weit von jedem Objekt entfernt ist. Core-Distanz $C(o) = \\min\\{\\varepsilon \\in \\mathbb{R} | o \\text{ ist mit DBSCAN und } \\varepsilon \\text{ dicht}\\}$. Die Core-Distanz eines Objekts $o$ ist also die kleinste Distanz, sodass $o$ noch ein dichtes Objekt ist. Reachability-Distanz Seien $p, o$ Datenpunkte. $$\\text{reach\\_d}(p, o) = \\begin{cases}\\max(d(p, o), \\text{coreDist}(p, o)) &\\text{if } d(p, o) < \\varepsilon\\\\ \\text{undefined} &\\text{otherwise}\\end{cases}$$ OPTICS OPTICS ist ein Algorithmus, der mit den Parametern min_points und $\\varepsilon$ (maximaler Radius fÃ¼r Cluster-Distanz) automatisch Cluster findet. Er startet dabei bei einem beliebigen Punkt. Dieser Punkt definiert ein Cluster, wenn mindestens min_points von ihm aus maximal $\\varepsilon$ entfernt sind. Dann wird der naheste Punkt zu dem Cluster hinzugefÃ¼gt. Dies wird so lange gemacht, wie die Punkte maximal $\\varepsilon$ von einem Punkt im Cluster entfernt sind. Dann wird ein bisher nicht betrachteter Punkt als genommen und man macht fÃ¼r diesen Outlier / neuen Cluster so weiter wie zuvor. ControlList (Priority Queue) enthÃ¤lt nur Objekte, die noch nicht in der Output-Liste sind. Kriterium: Minimale reachability-distanz zu Objekten in der Output-Liste. Rekursiv expandieren wie bei DBSCAN. Siehe OPTICS: Ordering Points To Identify the Clustering Structure Why does OPTICS use the core-distance as a minimum for the reachability distance? Reachability-Plot ( Erreichbarkeitsdiagramm ) Der Reachability-Plot veranschaulicht die Cluster und zeigt, welche Wahl von $\\varepsilon$ zu verschiedenen Clustern in DBSCAN fÃ¼hren wÃ¼rde. Er veranschaulicht das Ergebnis von OPTICS. OPTICS: Der Reachability-Plot ist ganz unten. EM-Algorithmus ( Expectation Maximization ) Siehe ML 2 . Overall Likelihood Die Overall Likelihood ist ein GÃ¼temaÃŸ fÃ¼r Clusterings. $$\\prod_{i} \\left ( p_A P(x_i | A) + p_B P(x_i | B) \\right )$$ Clustering-Algorithmen Im Folgenden sei \\(k \\in \\mathbb{N}\\) die Anzahl der Cluster, \\(d \\in \\mathbb{N}\\) die Dimension der \\(n \\in \\mathbb{N}\\) Datenpunkte. Algorithm Parameters Category Complexity Comment $k$-means $k$ next neighbor based $\\mathcal{O}(dkni)$ $i$ is the number of iterations $k$-medoids $k$ next neighbor based $\\mathcal{O}(dk n&#94;2 i)$ $i$ is the number of iterations EM $k$, distribution-type probabilisitc $\\mathcal{O}(dkni)$ $i$ is the number of iterations DBSCAN $\\varepsilon$, min-points density-based $\\mathcal{O}(n \\log n)$ requires existing index structure which executes neighborhood-query in log n OPTICS $\\varepsilon$, min_points density-based $\\mathcal{O}(n \\log n)$ $\\varepsilon$ heavily influences the runtime Agglomeratives hier. Clustering number of clusters, linkage type, distance hierarchical $\\mathcal{O}(n&#94;2)$ Related to Kruskals algorithm for constructing a minimal spanning tree; looks at local patterns DIANA hierarchical $\\mathcal{O}(2&#94;n)$ (?) Looks at global patterns BIRCH $k$, branching factor $B$, leaf capacity $B'$, threshold $T$ Makes use of CF-Trees CLARANS like $k$-means, but jumps on graph Projected Clustering $k$, average number of dimensions per cluster $I$ for high-dimensional data, extension of $k$-means Link-based Clustering Threshold distance $d$ for a link, minimal number of clusters $c$ Siehe auch: Sklearn Ã¼ber clustering Statistische Modellierung Slides: 10-StatistModellierung.pdf Naive Baies $$P(H | E) = \\frac{P(E_1 | H) \\cdot \\dots \\cdot P(E_n | H) \\cdot P(H)}{P(E)}$$ Laplace-Smoothing Um Wahrscheinlichkeiten von 0 zu vermeiden, werden die ZÃ¤hler mit $k$ initilisiert. Beachte, dass man auch die Gesamtzahl dann um $k$ erhÃ¶hen muss. Bayessche Netze Siehe ML 1 . Duplikateleminierung Spezialfall von Klassifikation Versteckte Variablen Abstraktion, damit der Raum der zu betrachteten Variablen bei Bayesschen Netzen kleiner wird. Siehe auch: Is the direction of edges in a Bayes Network irrelevant? Support Vector Machines Slides: 11-SupportVectorMachines.pdf Lineare Regression Model $y = M x$, wobei $x \\in \\mathbb{R}&#94;n$ die Features sind, $y \\in \\mathbb{R}&#94;m$ die Vorhersage und $M \\in \\mathbb{R}&#94;{n \\times m}$ die Modellparameter. Cross Entropy FehlermaÃŸ $$E_{CE}(w) = \\sum_{i=1}&#94;n [(1-y_i) \\cdot \\log (1-p) + y_i \\cdot \\log p]$$ SVM ( Support Vector Machine ) See SVM article . Ensembles Slides: 12-Ensembles.pdf (vgl. ML 1 ) Ensembles Mehrere Instanzen auf Trainingsdaten trainieren. Vorteile: Overfitting wird minimiert &rightarrow; Besseres Gesamtsystem Parallelisierbarkeit Wahrscheinlichkeiten kÃ¶nnen genauer geschÃ¤tzt werden Typische Techniken sind Bagging und Boosting. Bagging Ensemble-Learning Technik, bei der Stichproben des Trainingsdatenbestandes fÃ¼r die Classifier verwendet werden. Relabeling Ãœberschreiben der Originalen Labels, z.B. wenn man eine Attributkombination mehrfach hat, aber mit unterschiedlichen Labels, dann kann dieser Kombination mit einer gewissen Wahrscheinlichkeit das jeweilige Label zugewiesen werden. MetaCost MetaCost ist ein Verfahren zum Relabeling, welches Bagging anwendet. MetaCost: a general method for making classifiers cost-sensitive ( summary ) Boosting Boosting ist eine Ensemble-Learning-Technik, die mehrere Modelle vom gleichen Typ durch Voting / Durchschnittsberechnung kombiniert. Dabei nimmt Boosting RÃ¼cksicht auf zuvor falsch Klassifizierte Beispiele und gewichtet diese stÃ¤rker. GewichtungsÃ¤nderung fÃ¼r korrekte Objekte bei Fehllerrate e: $\\frac{e}{1-e}$ PrÃ¼fungsfragen Was ist Overfitting? â†’ Siehe ML 1 Wie berechnet man die Covarianz zweier Zufallsvariablen \\(X, Y\\) ? â†’ \\(\\operatorname{Cov}(X,Y) := \\operatorname E\\bigl[(X - \\operatorname E(X)) \\cdot (Y - \\operatorname E(Y))\\bigr]\\) Warum muss man fÃ¼r NN-Anfragen mit kD-BÃ¤umen nur ein paar Rechtecke anschauen? â†’ Weil man mit der Priority-Queue Algorithmus nur Rechtecke betrachten muss, die von der SphÃ¤re, welchen durch den Anfragepunkt un den tatsÃ¤chlichen nachsten Nachbarn gebildet wird, geschnitten werden. Warum kann man fÃ¼r rÃ¤umliche Anfragen nicht ohne weiteres auswerten, wenn man fÃ¼r jede Dimension separat einen B-Baum angelegt hat? â†’ Fragestellung nicht klar. War B-Baum und nicht R-Baum / kdB-Baum gemeint? Wie ist ein R-Baum aufgebaut? â†’ Siehe oben . Wie funktioniert die Suche nach dem nÃ¤chsten Nachbarn mit dem R-Baum? â†’ Man fÃ¼gt den Wurzel-Knoten in eine Priority-Queue ein. Die Priority-Queue ist eine Min-Queue mit dem Abstand vom Anfragepunkt. Es wird im folgenden so lange das hÃ¶chstpriore Objekt aus der Queue entfernt Was Ã¤ndert sich, wenn die Objekte eine rÃ¤umliche Ausdehnung haben? â†’ Man splittet nach mehreren Dimensionen. StÃ¶ren uns Ãœberlappungen von Knoten des R-Baums? Wenn ja, warum? â†’ Ja, weil die Suche nach dem nÃ¤chsten Nachbarn ineffizienter wird. Es mÃ¼ssen gegebenenfalls mehr Knoten betrachtet werden. Wie unterscheiden sich R-Baum, kD-Baum und kDB-Baum? â†’ R-BÃ¤ume partitionieren im gegensatz zu kD- und kDB-BÃ¤umen den Datensatz nicht. kDB-BÃ¤ume sind im Gegensatz zu kD-BÃ¤umen auf physischer Ebene balanciert. Wie funktioniert das EinfÃ¼gen in den R-Baum, inklusive Split? â†’ Siehe Pseudocode Was fÃ¼r Anfragen unterstÃ¼tzen die diversen rÃ¤umlichen Indexstrukturen? â†’ Nearest-Neighbor, Bereichsanfragen, Punktanfrage 3-Informatik-Grundlagen.pdf , Folie 19 Warum werden bei der NN-Suche nur genau die Knoten inspiziert, deren Zonen die NN-Sphere Ã¼berlappen? â†’ Weil alle anderen Knoten in der Priority Queue weiter hinten liegen. Welche Classifier kennen Sie? â†’ Decision Stumps (1-Rules), EntscheidungsbÃ¤ume, SVMs, Neuronale Netze, \\(k\\) -nearest neighbor (es gibt mehr Classifier ) Was ist der Vorteil von Postpruning verglichen mit Prepruning? â†’ Es kÃ¶nnte sein, dass ein Feature nur in Kombination mit einem anderen deutliche Vorteile bringt. Dies kann man bei Prepruning nicht erkennen, ist bei Postpruning gegebenenfalls jedoch offensichtlich. Wie baut man einen Entscheidungsbaum auf? â†’ Gehe durch alle Attribute. Finde fÃ¼r jedes einzelne Attribut den Wert, der die niedrigste Schnitt-Entropie hat. Nehme dann das Attribut als Split-Attribut, welches die niedrigste Schnitt-Entropie hat. Fahre so mit den beiden Kindknoten fort, bis ein Abbruchkriterium erfÃ¼llt ist. Das kÃ¶nnte z.B. eine Entropie von 0 oder eine maximale Tiefe sein. Wie kann man Overfitting beim Aufbau eines Entscheidungsbaums berÃ¼cksichtigen? â†’ Prepruning oder Postpruning. Wie kann man beim Aufbau des Entscheidungsbaums berÃ¼cksichtigen, dass unterschiedliche Fehlerarten unterschiedlich schlimm sind? â†’ Mehr Trainingsdaten fÃ¼r den schlimmeren Fehler. (vgl. How can decision trees be tuned for non-symmetrical loss? ) Was ist Wertebereich der FP-Rate? â†’ [0, 1]: Die FP-Rate ist definiert als \\(\\frac{FP}{FP+TN}\\) . Offensichtlich sind alle Werte nicht-negativ, also kann der Bruch nicht negativ werden. Deshalb ist auch der Nenner mindestens so groÃŸ wie der ZÃ¤hler. Wenn TN=0 und \\(FP \\neq 0\\) , dann ist die FP-Rate gleich 1. Das geht, wenn man z.B. immer \"True\" vorhersagt. Wenn man immer \"False\" vorhersagt ist die FP-Rate gleich 0. Wie berechnet man den Korrelationskoeffizienten? â†’ vgl. oben Was ist die \"10-fold cross validation\"? â†’ vgl. oben Wie haben wir die Erfolgsquote definiert? â†’ vgl. oben Was ist ein Lift Chart? â†’ Ein Lift Chart hat auf der x-Achse den Rang (Top-k) und auf der y-Achse der Gewinn. Die x-Achse verlÃ¤uft von 0 bis 100% und die y-Achse von 0 bis zum maximalen Gewinn im Datenbestand. Die Diagonale von (0, 0) nach (100%, Maximaler Gewinn) entspricht Raten, alles Ã¼ber der Diagonalen ist positiv. Der Lift-Chart muss nicht monoton steigend sein. Wie unterscheidet sich ein Lift Chart von der ROC Kurve? â†’ Die ROC-Kurve ist monoton steigend, der Lift-Chart jedoch nicht. Was fÃ¼r Fehlerarten gibt es bei Vorhersagen von KlassenzugehÃ¶rigkeiten? â†’ False-Positive, False-Negative (oder: Konfusionsmatrix) Was fÃ¼r Kennzahlen kennen Sie, die diese Fehlerarten sÃ¤mtlich berÃ¼cksichtigen? â†’ F score und Gesamtfehler. Was ist Unterschied zwischen Kovarianz und dem Korrelationskoeffizienten? â†’ Der Korrelationskoeffizient ist normiert (vgl. oben ) Warum kommt bei der informational loss Funktion die Logarithmusfunktion zur Anwendung? â†’ Die Logarithmusfunktion hat die gewÃ¼nschte Form: Bei perfekter Klassifizierung soll der Loss gleich 0 sein. Wenn es nicht perfekt ist, also \\(0 \\leq p_i < 1\\) , dann soll der Loss streng monoton fallen. Association Rules Was sind Association Rules? â†’ Association Rules sind im Kontext von Transaktionen von Items zu verstehen. Eine Association Rule ist eine Regel \\(A \\Rightarrow B\\) , wobei A und B Item-Mengen sind. Wie findet man Association Rules? â†’ In der Warenkorbanalyse / in Transaktionen. Wie Ã¼berprÃ¼ft man rasch fÃ¼r viele Transaktionen, welche Kandidaten sie enthalten? â†’ FP-Trees Wie muss der Datenbestand beschaffen sein, damit eine Association Rule \\(A \\Rightarrow B\\) hohen Support und hohe Confidence hat? â†’ Viele Transaktionen mÃ¼ssen \\(A \\cup B\\) enthalten. Wenn \\(A\\) vorkommt, muss auch \\(B\\) hÃ¤ufig vorkommen. Wie muss der Datenbestand beschaffen sein, damit eine Association Rule \\(A \\Rightarrow B\\) hohen Support und geringe Confidence hat? â†’ Viele Transaktionen mÃ¼ssen \\(A \\cup B\\) enthalten, aber noch deutlich mehr nur \\(A\\) . Wie muss der Datenbestand beschaffen sein, damit eine Association Rule \\(A \\Rightarrow B\\) geringen Support und hohe Confidence hat? â†’ Wenige Transaktionen mÃ¼ssen \\(A \\cup B\\) enthalten, wenn \\(A\\) mal vorkommt, dann immer auch \\(B\\) . Wie muss der Datenbestand beschaffen sein, damit eine Association Rule \\(A \\Rightarrow B\\) geringen Support und geringe Confidence hat? â†’ Wenige Transaktionen mÃ¼ssen \\(A \\cup B\\) enthalten. Wenn \\(A\\) mal vorkommt, dann sehr selten auch \\(B\\) . Im Apriori-Algorithmus hat man bei k=2 keinen Prune-Schritt. Warum? â†’ (Antwort: 24.11.2015, 14:34) Wie groÃŸ sollte man die Hash-Tabelle machen? â†’ So groÃŸ wie sinnvoll mÃ¶glich. Der verfÃ¼gbare Arbeitsspeicher ist hier eine Grenze. Was sind multidimensionale Association Rules? â†’ Association Rules die auf verschiedenen Begriffsebenenen sind, z.B. Oreo \\(\\Rightarrow\\) Milch Wie findet man multidimensionale Association Rules? â†’ HinzufÃ¼gen von Transaktionen der anderen Dimensionen, Nutzen von \"Leveln\" (Encodierte Transaktionstabelle) In welchen Situationen ist Apriori teuer, und warum? â†’ Apriori ist teuer, wenn es sehr groÃŸe Itemsets gibt. Dann mÃ¼ssen alle darin enthaltenen Itemsets gebildet werden. Was kann man gegen die SchwÃ¤chen von Apriori tun? â†’ Laufzeit: Hash-Filter, FP-Trees, Apriori-B, Sampling Was sind FP-Trees, und wie lassen sie sich fÃ¼r die Suche nach Frequent Itemsets verwenden? â†’ ErklÃ¤rung von FP-Trees Was kann man tun, wenn FP-Trees fÃ¼r den Hauptspeicher zu groÃŸ sind? â†’ Sampling, Projektion Was ist Constraint-basiertes Mining? â†’ Das minen von Assosication Rules unter Nebenbedingungen. Diese kÃ¶nnen entweder an die Daten oder an die Regeln gestellt werden. Eine Nebenbedingung an die Daten wÃ¤re z.B. dass nur Items betrachtet werden, die mindestens 100 Euro Wert sind. Eine Nebenbedingung an die Regeln wÃ¤re, dass es mindestens 3 Elemente auf der rechten Seite sind. Was sind die Vorteile von Constraint-basiertem Association-rule Mining? â†’ Durch die Regeln kann man gegebenenfalls das Minen beschleunigen und fÃ¼r den Nutzer interessantere Regeln finden. Was fÃ¼r Arten von Constraints kennen sie? Beispiele hierfÃ¼r. â†’ Data-Constraints (Wert der Items Ã¼ber 100 Euro) und Rule-Constraints (min. 3 Elemente auf der rechten Seite). Was ist Anti-MonotonizitÃ¤t, Succinctness? FÃ¼r ein bestimmtes Constraint sagen/begrÃ¼nden, ob anti-monoton/succinct. â†’ vgl. Anti-MonotonizitÃ¤t , Succinctness Wie lÃ¤sst sich Apriori fÃ¼r das Mining von Teilfolgen verallgemeinern? â†’ Endlicher Automat Was versteht man unter dem Antagonismus von Support-basiertem und Constraint-basiertem Pruning? â†’ Wenn man A-Rules unter Nebenbedingungen mit dem Apriori-Algorithmus sucht, kÃ¶nnte man versucht sein die Kandidaten schon frÃ¼h auf die Constraints zu Ã¼berprÃ¼fen. Obwohl jede Teilmenge eines Frequent Itemsets (FI) auch Frequent sein muss, muss nicht fÃ¼r jede Teilmenge das Constraint erfÃ¼llt sein. Dies gilt jedoch nicht fÃ¼r die Nebenbedingungen. Alternativen fÃ¼r Constraint-basiertes Pruning (wenn Constraint nicht anti-monoton) erklÃ¤ren kÃ¶nnen. â†’ Support-basiertes Pruning Welche zwei Sprachen haben wir fÃ¼r die Formulierung der Constraints kennengelernt? â†’ 1-var und 2-var bzw. MetaRule Guided Warum ist SQL nicht geeignet um Constraints zu formulieren? â†’ Weil SQL keine Aussage Ã¼ber die Struktur machen kann. So ist es in SQL nicht mÃ¶glich zu sagen, dass die rechte Seite mindestens 3 Elemente beinhalten soll. Clustering BIRCH-Algorithmus: Wie kann man die Interclusterdistanz aus N, LS, SS herleiten? â†’ \\(R(C_i) = \\sqrt{\\frac{1}{N} (SS - 2 \\frac{LS}{N} \\cdot LS + N (\\frac{LS}{N})&#94;2)}\\) BIRCH-Algorithmus: Wie kann man den Durchmesser aus N, LS, SS herleiten? â†’ \\(\\sqrt{\\frac{1}{N \\cdot (N-1)} (N \\cdot SS - 2 LS&#94;2 + N&#94;2 \\cdot SS)}\\) BIRCH-Algorithmus: Wie kann man die Interclusterdistanz aus N, LS, SS herleiten? â†’ \\(D(C_1, C_2) = \\sqrt{\\frac{SS_{C_1} - 2 LS_{C_2} LS_{C_1} + SS_{C_2}}{N_{C_1} \\cdot N_{C_2}}}\\) BIRCH-Algorithmus: Wie lassen sich die Clustering-Features eines ZusammengefÃ¼gten Clusters \\(C_{12} = C_1 \\cup C_2\\) aus den Komponenten berechnen? â†’ Durch Addition der jeweiligen Features der Einzelcluster. Was spricht dagegen, \\(\\mathbf{\\varepsilon}\\) in OPTICS riesig zu wÃ¤hlen? â†’ Dann sind gleich am Anfang mit dem ersten Objekt alle Datenobjekte in der Priority-Queue. Damit wÃ¤re der Aufwand fÃ¼r die Queue zu hoch. Welche Clustering-Verfahren kennen Sie? â†’ \\(k\\) -means , CLARANS , DBSCAN , OPTICS , BIRCH , DIANA , EM Gegeben Szenario X, welche Clustering-Verfahren sind sinnvoll, und warum? â†’ Autohersteller will Anzahl der Teile minimieren um Kosten zu senken (Hierarchisches Clustering), finden von neuen Symbolen. Warum funktionieren herkÃ¶mmliche Clustering-Verfahren in hochdimensionalen MerkmalsrÃ¤umen nicht? Skizzieren Sie eine mÃ¶gliche LÃ¶sung. â†’ Weil Datenobjekte in hochdimensionalen RÃ¤umen typischerweise alle weit auseinander liegen / nicht dicht sind. Man kann projected Clustering anwenden. ErklÃ¤ren Sie, warum Clustering mit kategorischen Attributen besonders ist? Warum ist Link-basiertes Clustering hier hilfreich? Bayes Gegeben ein beispielhafter Datenbestand, vergleichbar mit dem auf Folie 10, Vorhersage mit Naive Bayes erklÃ¤ren/vorfÃ¼hren kÃ¶nnen. Was Ã¤ndert sich, wenn die Attribute nicht voneinander unabhÃ¤ngig sind? â†’ Dann ist die naive UnabhÃ¤ngigkeitsannahme nicht mehr gegeben und man sollte ein bayessches Netz nehmen. Damit lassen sich dann wieder bessere Vorhersagen machen. Material und Links Die Vorlesung wurde gestreamt und ist unter mml-streamdb01.ira.uka.de verfÃ¼gbar. Vorlesungswebsite Ilias Literatur: Ian H. Witten, Eibe Frank: Data Mining. Practical Machine Learning Tools and Techniques. Harvey J. Miller, Jiawei Han: Geographic Data Mining and Knowledge Discovery (Clustering) More: What is the relationship between clustering and association rule mining? Vorlesungsempfehlungen Folgende Vorlesungen sind Ã¤hnlich: Analysetechniken groÃŸer DatenbestÃ¤nde Informationsfusion Machine Learning 1 Machine Learning 2 Mustererkennung Neuronale Netze Lokalisierung Mobiler Agenten Probabilistische Planung Termine und Klausurablauf Es ist noch nicht klar, ob es eine mÃ¼ndliche oder eine schriftliche PrÃ¼fung wird. Falls es mÃ¼ndlich ist, soll es mindestens einen Termin pro Monat geben. Wichtig! Ich musste zu Beginn der Vorlesung meinen Personalausweis vorlegen, obwohl ich bereits meinen Studentenausweis gezeigt hatte. Also: Ausweis mitnehmen! Datum : Noch ist es eine mÃ¼ndliche PrÃ¼fung Ort : Noch ist es eine mÃ¼ndliche PrÃ¼fung Punkte : Noch ist es eine mÃ¼ndliche PrÃ¼fung Zeit : Noch ist es eine mÃ¼ndliche PrÃ¼fung Punkteverteilung : Noch ist es eine mÃ¼ndliche PrÃ¼fung Bestehensgrenze : Noch ist es eine mÃ¼ndliche PrÃ¼fung Ãœbungsschein : Gibt es nicht. Bonuspunkte : Gibt es nicht. Ergebnisse : Noch ist es eine mÃ¼ndliche PrÃ¼fung Einsicht : Noch ist es eine mÃ¼ndliche PrÃ¼fung Erlaubte Hilfsmittel : keine","tags":"German posts","title":"Analysetechniken fÃ¼r groÃŸe DatenbestÃ¤nde"},{"url":"https://martin-thoma.com/microsoft-vision-api/","text":"Microsoft just released a Computer Vision API. I tried it with a couple of Unidentified objects of Wikipedia and was not really impressed. Here is how to use it: #!/usr/bin/env python \"\"\"Example how to use the Microsoft Vision API.\"\"\" import httplib import urllib import json headers = { 'Content-type' : 'application/json' , } params = urllib . urlencode ({ # Specify your subscription key 'subscription-key' : 'yourhexadecimalone11111111111111' , # Specify values for optional parameters, as needed 'visualFeatures' : 'All' , }) try : image_url = \"http://www.martin-thoma.de/bilder/Martin_Thoma_web_thumb.jpg\" conn = httplib . HTTPSConnection ( 'api.projectoxford.ai' ) conn . request ( \"POST\" , \"/vision/v1/analyses? %s \" % params , \"{'Url': ' %s '}\" % image_url , headers ) response = conn . getresponse () data = response . read () data = json . loads ( data ) print ( json . dumps ( data , sort_keys = True , indent = 2 )) conn . close () except Exception as e : print ( \"[Errno {0}] {1}\" . format ( e . errno , e . strerror )) which gives { \"adult\": { \"adultScore\": 0.01073759701102972, \"isAdultContent\": false, \"isRacyContent\": false, \"racyScore\": 0.015348214656114578 }, \"categories\": [ { \"name\": \"people_\", \"score\": 0.8359375 } ], \"color\": { \"accentColor\": \"4C5F37\", \"dominantColorBackground\": \"Green\", \"dominantColorForeground\": \"Green\", \"dominantColors\": [ \"Green\" ], \"isBWImg\": false }, \"faces\": [ { \"age\": 28, \"faceRectangle\": { \"height\": 49, \"left\": 53, \"top\": 42, \"width\": 49 }, \"gender\": \"Male\" } ], \"imageType\": { \"clipArtType\": 0, \"lineDrawingType\": 0 }, \"metadata\": { \"format\": \"Jpeg\", \"height\": 200, \"width\": 134 }, \"requestId\": \"7f0af611-1750-4fa2-aa47-a03db286f6a7\" } See also Cognitive Services : You have to apply there. 5,000 transactions per month, 20 per minute is for free. The 86-category concept Computer Vision API - v1.0","tags":"Cyberculture","title":"Microsoft Vision API"},{"url":"https://martin-thoma.com/nukleare-endlagerung/","text":"Das Finden eines Endlagers fÃ¼r unsere nuklearen AbfÃ¤lle ist seit etwa 1963 ein Thema in der Politik in Deutschland. [ Koe03 ] Es geht dabei um die Frage, wie wir die gefÃ¤hrlichen Ãœberreste der Atomkraftwerke, den sogenannten AtommÃ¼ll , entsorgen. AtommÃ¼ll Um zu verstehen worum es geht sollte man ein GrundverstÃ¤ndnis fÃ¼r Atomenergie haben. Ich werde die Dinge auf das relevante vereinfachen: Atome bestehen aus dem Atomkern und Elektronen, welche um den Atomkern kreisen. Der Atomkern besteht aus Neutronen und Protonen. Die Protonen sind elektrisch positiv geladen, Elektronen sind negativ geladen und die Neutronen sind elektrisch neutral. Alle diese Elementarteilchen haben Masse. Elektronen sind extrem leicht, Protonen und Neutronen sind etwa gleich schwer und beide jeweils deutlich schwerer als Elektronen. Visualisierung eines Atoms Bildquelle: Wikipedia - Fornax, Halfdan, Groogokk Die Anzahl der Protonen und Elektronen ist gleich, sodass ein Atom insgesamt elektrisch neutral geladen ist. Die Anzahl der Protonen (bzw. Elektronen) macht die wichtigsten Eigenschaften aus. Dementsprechend haben wir eigene Namen fÃ¼r Atome mit einem Proton (Wasserstoff), 26 Protonen (Eisen) oder eben 92 Protonen (Uran). Allerdings ist nicht jedes Uran-Atom gleich: Manche haben mehr Neutronen als andere. So gibt es Uran mit 235 Teilchen im Kern und Uran mit 238 Teilchen im Kern. Die Anzahl der Protonen definiert also welches Element (Eisen, Uran, Wasserstoff, ...) wir haben, die Anzahl der Protonen+Neutronen definiert welches Isotop ( 235 U, 238 U, 1 H, ...) wir haben. Kernkraftwerke produzieren Energie, indem ein bestimmtes Uran-Isotop ( 235 U) dazu gebracht wird sich zu spalten. Wir haben also einen ganz bestimmten Typ von Atom, welchen wir dazu bringen 143 Neutronen und mit 146 Neutronen. Da die Elektronen fast nichts wiegen und nur die Neutronen und Protonen fÃ¼r das Gewicht relevant sind, sagt zÃ¤hlt man Ã¼blicherweise beide zusammen: 92 Protonen + 146 Neutronen macht 238 Kernteilchen. Also 238 U, weil U das Zeichen fÃ¼r Uran ist. Es gibt also leichtes Uran 235 U und schweres Uran 238 U. Nun muss man wissen, dass sich Elektronen und Protonen anziehen. Das ist ungefÃ¤hr so wie mit verschiedenen Polen eines Magnets. Warum fallen sie also nicht in den Kern? Ganz einfach: Es gibt weitere Effekte (siehe details ). Man stelle sich z.B. Satelliten vor, die um die Erde kreisen. Sie sind gerade so schnell und haben gerade die richtige Entfernung, dass sie weder wegfliegen noch in den Kern fallen. Nun kann man sich die nÃ¤chste Frage stellen: Warum sind die Protonen zusammen? Warum ist der Kern stabil? Genauso wie sich Protonen und Elektronen anziehen, stoÃŸen sich zwei Protonen ab. Hier kommt nun eine weitere, elementare Kraft ins Spiel: Die Kernkraft. Sie wirkt nur auf sehr, sehr kleine Distanzen, ist dort aber unglaublich stark. Sie zieht die Protonen gegenseitig an. Die Anziehung durch die Kernkraft schafft also einen Ausgleich zur elektrischen AbstoÃŸung. Ok, wie kommen nun die Neutronen ins Spiel? Neutronen sind elektrisch neutral. Sie bilden mit den Protonen zusammen den Atomkern. Es scheint so zu sein, dass mehr Neutronen zu einem instabileren Kern fÃ¼hren. Mehr Neutronen machen den Kern grÃ¶ÃŸer, aber die Kernkraft wirkt nur auf sehr kurze Entfernung. Das heiÃŸt je grÃ¶ÃŸer der Kern wird, desto stÃ¤rker dominiert die elektrische AbstoÃŸung der Protonen. Wenn nun z.B. ein Neutron mit hoher Geschwindigkeit auf den Kern trifft kann sich dieser Spalten. Es bilden sich zwei neue, kleinere Atomkerne und - je nach Atom - werden weitere Neutronen abgestoÃŸen. Man sieht wie ein Neutron (blau) den Atomkern trifft. Dieser Spaltet sich und drei weitere Neutronen fliegen weg. Bildquelle: Stefan-Xp Eine solche Spaltung kann man formal wie folgt darstellen: $$\\mathrm{&#94;{235}_{\\ 92}U + &#94;{1}_{0}n \\longrightarrow &#94;{133}_{\\ 52}Te + &#94;{101}_{\\ 40}Zr + 2\\ &#94;{1}_{0}n}$$ Was diese Gleichung verschweigt, ist die Tatsache, dass auch Energie frei wird. Diese kann man zum erhitzen von Wasser verwenden. Das erhitzte Wasser kann dann wiederum zum Antreiben einer Turbine verwendet werden. Und die Turbine macht schlussendlich aus der Bewegungsenergie nutzbare elektrische Energie. Nun haben wir aber eben auch die kleineren Atomkerne. Diese sind nicht stabil und zerfallen weiter in kleinere Atomkerne. Ãœber diesen Zerfallsvorgang muss man nun wissen, dass er nicht sofort statt findet. FÃ¼r einzelne Atome kann man auch gar nicht sagen wann genau es sein wird. Allerdings kann man fÃ¼r eine groÃŸe Menge an Atomen die Aussage machen, dass nach X Jahren die HÃ¤lfte davon zerfallen sein wird. Nach weiteren X Jahren wiederum die HÃ¤lfte usw. Dieses X ist fÃ¼r einen festen Isotop-Typ konstant. Teilweise ist es im Bereich weniger Sekundenbruchteile, und bei 135 Cs sind es beispielsweise 2,3 Mio. Jahre. Diese Zeit, in der statistisch gesehen die HÃ¤lfte der Atome in kleinere Atome zerfÃ¤llt nennt man Halbwertszeit . Jedes mal wenn so ein Zerfallsvorgang frei wird, wird auch Energie frei bzw. sehr schnelle Teilchen. Man kÃ¶nnte das als eine Art Bombardierung der Umwelt mit sehr kleinen Teilchen sehen. Und bei den Spaltprodukten, dem AtommÃ¼ll, dauert diese Bombardierung leider sehr lange an. Die Teilchen sind so klein, dass sie leicht eingeatmet werden kÃ¶nnen. Wenn sie dann im inneren des KÃ¶rpers zerfallen richten sie dort enormen Schaden an. Es gibt tatsÃ¤chlich nicht nur eine Art wie sie zerfallen kÃ¶nnen, sondern drei verschiedene. Bei der ersten, der Alpha-Strahlung, werden vergleichsweise groÃŸe Teilchen frei, die aber allein schon durch die Luft so schnell und stark abgebremst werden, dass die Teilchen an sich relativ leicht zu handhaben sind. Schon ein Blatt Papier reicht zur Abschirmung. [ Jen ] Beta-Strahlung ist da schon schwerer zu handhaben. Aber auch sie kann z.B. durch 15 PapierblÃ¤tter / 4mm Aluminium abgehalten werden. [ Jen ] Bleibt noch die Gamma-Strahlung. Diese kann nur abgeschwÃ¤cht, aber nicht komplett aufgehalten werden. So beleibt bei einer Gamma-Strahlung von 1 MeV nach ca. 3 cm Blei noch ein Zehntel der Strahlung Ã¼brig. Ich denke das ist der Grund, warum man den strahlenden MÃ¼ll gerne Untertage, so weit weg von Menschen wie mÃ¶glich, lagern will. Endlager: Was mÃ¼ssen sie kÃ¶nnen? Da die Diskussion um die Endlagerung schon seit 1963 gefÃ¼hrt wird, habe ich mich gefragt warum es eigentlich so schwer ist ein Endlager zu finden. Klar, niemand will das Endlager in seiner Nachbarschaft haben. Aber das gilt ja auch fÃ¼r Zwischenlager. Irgendwo muss das Zeug halt stehen. Das Bundesministerium fÃ¼r Umwelt, Naturschutz und Reaktorsicherheit hat einen Anforderungskatalog fÃ¼r Endlagerstetten geschrieben. [ BMU10 ] Liest man sich diesen durch, findet man schnell den Grund warum seit Ã¼ber 50 Jahren kein Endlager gefunden wurde: Zur Vermeidung unzumutbarer Lasten und Verpflichtungen fÃ¼r zukÃ¼nftige Generationen sind folgende Sicherheitsprinzipien zu beachten: 4.6 Das Endlager ist so zu errichten und so zu betreiben, dass fÃ¼r den zuverlÃ¤ssigen langfristigen Einschluss der radioaktiven AbfÃ¤lle im einschlusswirksamen Gebirgsbereich in der Nachverschlussphase keine Einriffe oder Wartungsarbeiten erforderlich werden. 4.7 Es ist eine mÃ¶glichst zÃ¼gige Errichtung des Endlagers zu realisieren. 4.8 FÃ¼r Errichtung und Betrieb einschlieÃŸlich Stilllegung des Endlagers mÃ¼ssen die finanziellen Mittel zeitgerecht zur VerfÃ¼gung stehen. Kapitel 4, Sicherheitsprinzipien, in Sicherheitsanforderungen an die Endlagerung wÃ¤rmeentwickelnder radioaktiver AbfÃ¤lle vom 30. September 2010. Von 4.7 kann man sich 16 Jahre nach der VerÃ¶ffentlichung wohl verabschieden. Die SPD, CDU/CSU hat auch dafÃ¼r gesorgt, dass 4.8 nicht bedeutet, dass die Energiekonzerne den Betrieb bezahlen. [ Koe03 ] Obwohl das auch mal anders lautete: Die Verantwortung fÃ¼r Stilllegung, RÃ¼ckbau und Zwischenlagerung des AtommÃ¼lls liege bei den Energieunternehmen, lieÃŸ Umweltministerin Barbara Hendricks (SPD) wissen. Deshalb hÃ¤tten die Konzerne auch \"sÃ¤mtliche Kosten der Stilllegung, des RÃ¼ckbaus sowie der Endlagerung zu tragen\". Horand Knaup, in VorstoÃŸ der Energiekonzerne: Milliardenpoker um den Atomausstieg vom 12. Mai 2014. Nun gibt es noch 4.6 der mich besonders stÃ¶rt. Das ist einfach unrealistisch. NatÃ¼rlich wird man keinen Ort auf der Erde finden bei dem fÃ¼r mehrere Millionen Jahre davon auszugehen ist, dass dieser ohne Eingriffe und Wartungsarbeiten den MÃ¼ll sicher wegschlieÃŸt. [ 1 ] Da es immer noch keine wirklich sichere Methode gibt Dinge ins All zu befÃ¶rdern (vgl. Liste von Katastrophen der Raumfahrt ) muss es aber auf der Erde sein. Daher sollte man diesen Punkt einfach streichen. Wir - die aktuelle Generation und alle folgenden Generationen - werden die Lagerung des AtommÃ¼lls bezahlen mÃ¼ssen. Das beinhaltet Eingriffe und Wartungsarbeiten der LagerstÃ¤tte. Soweit die schlechte Nachricht. Die gute Nachricht ist, dass man z.B. LagerstÃ¤tten suchen / bauen kÃ¶nnte, bei denen man sich nur sicher ist, dass sie fÃ¼r die nÃ¤chsten z.B. 5 Jahre sicher sind. Dann prÃ¼ft man es erneut. Wenn man weiÃŸ, dass man die LagerstÃ¤tte regelmÃ¤ÃŸig prÃ¼fen muss kann man die LagerstÃ¤tte so einrichten, dass diese PrÃ¼fung leicht ist. Man kÃ¶nnte Robotersysteme erstellen, welche eine Fernwartung erlauben. Es sollte auf jeden Fall redundante Systeme zur Bergung der Container geben. Die Systeme sollten robust gebaut werden. Wie man an den versagenden Robotern bei Fukushima sieht [ New16 ] mÃ¼ssen die Systeme unbedingt vorher getestet werden. Ich kÃ¶nnte mir Schienen-Systeme fÃ¼r die Container vorstellen. Das sollte recht robust sein. Dann muss man das Gebiet noch bewachen, sodass Menschen nicht AtommÃ¼ll klauen kÃ¶nnen. Das wird dauerhaft Geld kosten. AuÃŸerdem muss man nicht unbedingt den ganzen AtommÃ¼ll an einer Stelle lagern. Ich wÃ¼rde es beispielsweise fair finden, wenn die einzelnen BundeslÃ¤nder so viel von dem MÃ¼ll lagern mÃ¼ssen wie die Kraftwerke auf ihrem Gebiet erzeugt haben. Aber wie viel AtommÃ¼ll haben wir eigentlich? Daten zum AtommÃ¼ll Es ist erstaunlich wie schwer es ist dazu gute Aussagen zu finden. Hier ein paar: Der RestmÃ¼ll, der in den Wiederaufarbeitungsanlagen neben Plutonium und Uran entsteht, macht zwar nur vier Prozent aus, ist aber das Hauptproblem. In ihm sind 99 Prozent der gefÃ¤hrlichen Strahlung konzentriert. Er wird in flÃ¼ssiges Glas eingeschmolzen und in sogenannte Kokillen aus Edelstahl gefÃ¼llt. Ein 1000-Megawatt-Kraftwerk â€“ deutsche Kernkraftwerke erbringen eine Bruttoleistung zwischen 800 und 1480 Megawatt â€“ produziert jÃ¤hrlich etwa 20 Tonnen ausgedienter Brennelemente. [...] [In Gorleben] liegen nach Angaben des Bundesamtes fÃ¼r Strahlenschutz insgesamt 2408 Glaskokillen aus der Wiederaufarbeitung in der franzÃ¶sischen Anlage. [...] Hinzu kommt der hochradioaktive AtommÃ¼ll, der seit dem Jahr 2005 entstanden ist und nicht wiederaufgearbeitet wurde [...]. Dieser MÃ¼ll â€“ pro Jahr etwa 400 Tonnen, schÃ¤tzt die Gesellschaft fÃ¼r Anlagen- und Reaktorsicherheit â€“ lagert, verteilt Ã¼ber die ganze Republik, in Hallen neben den Kernkraftwerken. Christina Steinlein, in Focus Online: Die Angst wiegt schwer vom 11. November 2010. Wir haben also mindestens $$11 \\text{ Jahre } \\cdot 400 \\frac{\\text{Tonnen}}{\\text{Jahr}} = 4400\\text{ Tonnen}$$ an AtommÃ¼ll. Hinzu kommen diese Kokillen von vor 2005, von denen ich leider nicht weiÃŸ wie groÃŸ die sind. Laut kiefermedia.de haben wir in Deutschland bis 2022 etwas 17 200 Tonnen AtommÃ¼ll, laut Greenpeace wird es bis dahin 15 000 Tonnen AtommÃ¼ll geben. Laut BUND sind es 17 000 Tonnen und 300 000 m 3 . [ 2 ] Laut Statistischem Bundesamt sind in Deutschland alleine im Jahr 2009 etwa 450 Tonnen AtommÃ¼ll angefallen. Diese 450 Tonnen wurden in vielen Quellen als \"JÃ¤hrlich anfallender AtommÃ¼ll\" genannt. Als ob das jedes Jahr gleich wÃ¤re. Dann hÃ¤tten wir heute keine ~17 000 Tonnen AtommÃ¼ll sondern $$(2016-1960) \\cdot 450 \\text{ Tonnen} = 25200\\text{ Tonnen}$$ Siehe auch Kernspaltung Liste der Isotope FuÃŸnoten [ 1 ] Der Homo Sapiens ist etwa 200 000 Jahre alt; die ersten staatlichen Gebilde sind ca. 6000 Jahre alt. Und da wollen wir fÃ¼r etwas planen, was mehr als 100 000 Jahre in der Zukunft liegt? LÃ¤cherlich. [ 2 ] Das wÃ¼rde eine Dichte von nur 57 kg/m 3 ergeben. Eisen hat eine Dichte von 7874 kg/m 3 und Wasser eine Dichte von 1000 kg/m 3 . Einzelnachweise [ Koe03 ] W. KÃ¶nig. Atomare Endlagerung im Spannungsfeld zwischen fachlichen Notwendigkeiten und gesellschaftlichen RealitÃ¤ten. Evangelische Akademie Loccum, 2003. ( Quelle ) [ Jen ] Zukunftswerkstatt Jena. SchutzmÃ¶glichkeiten vor ionisierender Strahlung: Alphastrahlen. ( Quelle ) [ BMU10 ] Sicherheitsanforderungen an die Endlagerung wÃ¤rmeentwickelnder radioaktiver AbfÃ¤lle. Bundesministerium fÃ¼r Umwelt, Naturschutz und Reaktorsicherheit, 30. September 2010. ( Quelle ) [ Tag16 ] Energiekonzerne blockieren Atomkompromiss. Der Tagesspiegel, 28.02.2016. ( Quelle ) [ New16 ] The robots sent into Fukushima have 'died'. Newsweek, 10.03.2016. ( Quelle )","tags":"Cyberculture","title":"Nukleare Endlagerung"},{"url":"https://martin-thoma.com/support-me/","text":"In case you wanted to read something about me, go to the about me page . Keeping my blog online costs money. When you like my blog, you should support me in keeping it online. PayPal Support me via PayPal . Amazon Wish list Expenses Date Money Comment 12.09.2008 26.16 Euro Domain registration for \"martin-thoma.de\" via Knallhart.de (Domain + Hosting) 09.07.2009 26.16 Euro Domain \"martin-thoma.de\" for 12.09.2009 - 12.09.2010 via Knallhart.de (Hosting + Domain) 14.07.2010 26.16 Euro Domain \"martin-thoma.de\" for 12.09.2010 - 12.09.2011 via Knallhart.de (Hosting + Domain) 08.07.2011 26.16 Euro Domain \"martin-thoma.de\" for 12.09.2011 - 12.09.2012 via Knallhart.de (Hosting + Domain) 21.09.2011 15.96 Euro Domain registration for \"martin-thoma.com\" via Knallhart.de (Domain + Hosting) 19.10.2011 26.16 Euro Domain registration for \"community-chess.com\" via Knallhart.de (Domain + Hosting, 19.10.2011 - 19.10.2012) 10.07.2012 26.16 Euro Domain \"martin-thoma.de\" for 12.09.2012 - 12.09.2013 via Knallhart.de (Hosting + Domain) 18.07.2012 15.96 Euro Domain \"martin-thoma.com\" for 21.09.2012 - 21.09.2013 via Knallhart.de (Hosting + Domain) 10.07.2013 28.80 Euro Domain \"martin-thoma.com\" for 12.09.2013 - 12.09.2014 via Knallhart.de (Hosting + Domain) 17.07.2013 15.96 Euro Domain \"martin-thoma.com\" for 21.09.2013 - 21.09.2014 via Knallhart.de (Hosting + Domain) 22.01.2014 10.87 USâ€‘Dollar Domain Registration for write math.com via namecheap.com for 1 year 18.06.2014 9.87 USâ€‘Dollar Domain Transfer for martin-thoma.com 18.06.2014 10.56 Euro Domain \"martin-thoma.com\" for 18.07.2014 - 17.07.2015 via Knallhart.de (Domain only) 13.08.2014 28.80 Euro Domain \"martin-thoma.de\" for 12.09.2014 - 11.09.2015 via Knallhart.de (Hosting + Domain) 23.12.2014 10.87 USâ€‘Dollar Domain Renewal write-math.com for 1 year via namecheap.com 13.08.2015 28.80 Euro Domain \"martin-thoma.de\" for 12.09.2015 - 11.09.2016 via Knallhart.de (Hosting + Domain) 02.09.2015 94.23 USâ€‘Dollar Domain Renewal for martin-thoma.com for 9 years via namecheap.com 25.10.2015 8.40 USâ€‘Dollar Domain Registration for ml-ka.de for 1 year via namecheap.com 25.11.2015 10.87 USâ€‘Dollar Domain Renewal write-math.com for 1 year via namecheap.com Contributions Thank you to all supporters :-) Date Amount Name Message 19.03.2017 3.14 Euro Oliver Knieps Weiter so! 20.01.2016 0.63 Euro Daniel PodraÅ¼ka None contributions? Dann will ich der erste auf der Liste sein! :D","tags":"Cyberculture","title":"Support Me"},{"url":"https://martin-thoma.com/paid-reviews/","text":"I am often asked if I would like to review a book. So here is my answer to all of those requests: I don't work for free. If you want high quality work, you have to pay for it. About me I finished my Computer Science bachelors degree at KIT / CMU and I'm currently in my masters degree at KIT (Karlsruhe, Germany). My mother tongue is German, but my English is not too bad. I'm specialized in Machine Learning. I'm working with the typesetting system LaTeX for quite a while now ( source ). See arxiv for some of my work. Topics When it comes to bachelors thesis, I think I can review probably any topic. This is likely not to be the case when I review a masters thesis. Getting in Touch Just send me an E-Mail ( info@martin-thoma.de ). Make sure to include what you want to be reviewed. Key information I want is: Language of the work (English or German) Type of work (e.g. book, bachelors thesis, masters thesis, paper) Title of the work (e.g. \"A review of Semantic Segmentation\") A short description what it is about. What should I focus on? Spelling, Typos, Grammar Expressions Typesetting Logic, structure and consistency Factual correctness If you want me to review it, you should either send me a PDF or give it to me in printed form directly. I will make annotations in a printed version and give you that. You have to pay in advance (I can give you a receipt if you want). Prices The following prices are rules of thumb. If you want to know what you have to pay, you have to get in touch with me. This is only meant to give you some idea of what it might cost. Especially checking factual correctness thoroughly might cost much more. I make book reviews for 50 Euro / hour or 2.50 Euro / page (as you like). If you want me to review your bachelors or masters thesis, I'll do so for 30 Euro / hour or 1.50 Euro / page. Hints The higher the quality of your work is, the more you will get for your money from my review. So check your stuff first. Ideas what might be wrong give the following tools Text-Based: Academic-Writing-Check aspell LaTeX Searching for \"Warning\" in the LaTeX log Search for \"?\" in the PDF to find missing references Try the package nag (see How to use nag ) My Copy-Paste answer for dubious E-Mails Dear Sir or Madam, Yes, I am interested in writing a review for your work. This makes either 50 Euro/hour or 2.50 Euro/page. What would you prefer? How would you like to pay? You might want to answer some key questions about your work. See https://martin-thoma.com/paid-reviews/ Best regards, Martin Thoma One shady business I found so far is packtpub.com . They contacted me more than once and wanted me to work for free.","tags":"Cyberculture","title":"Paid Reviews"},{"url":"https://martin-thoma.com/voting/","text":"Many people are dissatisfied with the current situation. They feel that politics favors rich people; that their lives get harder; that big companies profit from political decisions. Their reaction: Not voting / voting blank / voting invalid. This is an awful idea because of the following reasons: Blank votes and invalid votes are treated just the same way as not voting, although the number might get counted ( source ). If you're not voting, the people who vote get more influence with their votes. This means by not voting, you're effectively voting for the current situation. What are your alternatives? Get active. Have a closer look at the parties. On wahl-o-mat.de you can see 22 parties with some elected positions. You don't have to agree 100% for all questions. You only have to find a party which is \"good enough\". Speaking to parties and demanding certain positions. I guess all mayor parties are mainly doing what they think their segment of voters likes. If enough people demand a certain position, they might change. Make your own party. This is always a possibility. Find other people who think the same way. Not voting, blank voting and invalid voting is just stupid and lazy. It shows your support of the current situation / the parties which are currently strong.","tags":"My bits and bytes","title":"Voting"},{"url":"https://martin-thoma.com/the-cost-of-fighting-terrorism-with-bombs-surveillance-and-fear/","text":"George W. Bush started the War on Terror as a response to the September 11 attacks on the United States in September 2001. Since then, surveillance laws were passed and multiple military operations were started. The US and its allies fought wars in Afghanistan and Iraq. The US and its allies supported wars in Syria. US drones killed people in Parkistan and Yemen . Those activities come with a cost. One the one hand, every single of Britain's air-to-surface Brimstone missiles cost Â£100 000. Britain has fired at least 9 missiles in Syria so far, but not killed a single terrorist ( source ). From the same article: Two jihadists were killed with Paveway IV laser-guided bombs (20,000 US-Dollar each) and five were killed by US-made Hellfire missiles (70,000 US-Dollar a piece) fired from Reaper UAVs. Another article : American aircraft fired at least 23,144 bombs and missiles in 2015 alone, according to data compiled by Micah Zenko, an expert on U.S. military planning and operations who is a senior fellow at the Council on Foreign Relations. Now you should also know that one hour of a Eurofighter in air costs 73992 Euro ( source ). The refugee crisis will cost Germany approximately 50 000 000 000 Euro. ( source ). In 2013, American taxpayers spent 454 million US-Dollars on detention operations at Guantanamo Bay, which now holds 91 detainees ( source ). Effectiveness We are spending much more than ever on fighting terrorism. We sacrificed a lot of our civil rights. What did we get so far? More terrorism than ever before ( sources ). Empathy To understand the effect of those missiles of the people living there, you have to be empathetic. Imagine you're in a situation where not everything might be good (or even very little might be as you like it), but you are essentially \"safe\". You know how you have to behave and you know what you can expect. Now the US brings freedom to your country. The people which were in power once are not anymore. Drones could kill you on your wedding ( source ), when you try to bury loved ones ( source ). The US goes, other people get to the power. Not the ones where you know what to expect from. People who are angry at what happened. People who tell you that it was the US who killed friends or who just destabilized the country. Who tortures people ( sources ). Who just came there for their own interest. Who said they wanted to bring freedom, but came for the oil ( sources ). But who overthrew democratically elected governments ( sources ). I'm not saying all of those statements are true. Yes, I'm aware that there is context missing. However, it really doesn't matter. While people being in such a situation might know more about their specific case, they will almost certainly also only have those vague ideas what is going on. To their eyes, it is the US who caused the trouble. Why should you care? The point I want to make here is that there is no good in fighting with weapons (only). In case you will ever be in the position to decide that, keep it in mind. In case there is an anti-war demonstration nearby, think about it. What can we do? Terrorism is a problem. I do understand that people don't want to just accept 9/11. Or the attacks in Paris. And it will only get worse. Getting more advances in technology has many advantages, but a downside is that it also gets much more easy to plan and execute terrorist attacks. There is no way to live in a free high-tech world and preventing people from being able to execute horrendous attacks. Especially, simply going to war isn't solving that problem. We have to understand why people are doing what they are doing. Don't prevent the attack, make people not having reasons to make attacks. This is much harder. It needs a deep understanding of what drives people. It needs empathy, diplomacy, support. Contact. Showing people that you care about them. That achieving basic goals to help them lead a better live is worth the money (for example: below 35-76 billion US dollars for the millennium goals ( source ) compared to 468 billion US dollars for 2001-2011 in Iraq). Achieving those goals might include sending the army. But not as the main thing to do, but as a supporting force. To protect people who help building lasting structures. TL;DR Stop war. Think what we want to achieve, think of the most likely outcomes of your foreign policy steps. From the beginning of your foreign policy until you leave the country on their own. Think of other peoples interests, not only of yours. Because win-win is awesome.","tags":"Cyberculture","title":"The cost of fighting Terrorism with Bombs, Surveillance and Fear"},{"url":"https://martin-thoma.com/disable-caps-lock/","text":"I've just hit caps lock accidentally. This key is so useless; I never ever wanted to hit it. So I deactivated it: $ setxkbmap -option caps:none To run this every time at startup, I've added it to /etc/rc.local . However, it did not work. I guess it is executed to soon. An alternative which worked is adding a file ~/.config/shift.deskop with the following content: [Desktop Entry] Type = Application Name = shift Exec = setxkbmap -option caps:none X-GNOME-Autostart-enabled = true No more issues with caps lock â™¡. More functionality I've just received a remark by Micha that one could add useful functionality. For example with Xmodmap or within the Ubuntu settings one can make this a compose key for special characters such as Â·Ã—â‹„.","tags":"Cyberculture","title":"Disable Caps Lock"},{"url":"https://martin-thoma.com/get-pdf-pages/","text":"Once in a while, I want to get the total number of PDF pages of a document. You can do that with the command $ pdfinfo document.pdf | grep Pages | awk -F ':' '{gsub(/ /, \"\", $0);print $2}' It works like this: Call pdfinfo to get a lot of information, including a line which begins with the string \"Pages\". Get only the line with the string \"Pages\" Split that line at \":\", remove all white space and print only that after the first \":\" (and before a second \":\") Now we know how to get the number of pages of a PDF document for a single document. But what if you want to get it for all documents within a folder? $ for i in *.pdf ; do pdfinfo $i | grep Pages | awk -F ':' '{gsub(/ /, \"\", $0);print $2}' ; done | paste -sd+ - | bc It works like this: for i in *.pdf; do ...; done goes through all files ending with .pdf and prints the number of pages of the single documents. paste -sd+ - makes sure that the single lines have a + in between bc calculates the expression which is now a string line 18+42+9","tags":"Cyberculture","title":"Get PDF pages"},{"url":"https://martin-thoma.com/wasserrohrbruch-in-karlsruhe/","text":"Seit 10:00 Uhr (20.02.2016) geht bei mir (ParkstraÃŸe, Oststadt, Karlsruhe) das Wasser nicht mehr. Die Website der Stadtwerke ist Ã¼berlastet, aber Twitter gibt Informationen: @themoosemind @kanews Laut Polizei ein groÃŸer Rohrbruch in Hagsfeld. Stadtwerke arbeiten wohl dran! â€” Jens Hansen (@jeansonson) 20. Februar 2016 Auch auf Facebook gibts ein paar Informationen von den Stadtwerken ( Link ). Wer ist Betroffen? Ich weiÃŸ es nicht. In der Oststadt auf jeden fall, ich habe gehÃ¶rt das Hagsfeld und Neureuth ( Quelle ) auch betroffen ist. Durlach wohl auch (danke, Bernardo). edit: Laut Stadtwerke wirkt sich der Wasserrohrbruch auf die gesamte Stadt aus. Wann ist es behoben? Leider kann ich die Stadtwerke gerade nicht anrufen. Ich habe gehÃ¶rt, dass es heute auf keinen Fall mehr behoben wird. edit: In der nÃ¤chsten halben Stunde (also um 12:00 Uhr, 20.02.2016) soll sich der Wasserdruck laut Stadtwerken normalisieren. Was ist passiert? Wasserrohrbruch in der KÃ¶nisberger StraÃŸe. Warum der Wasserrohrbruch passiert ist wissen die Stadtwerke noch nicht. edit: Hier ein paar Informationen von der Website ( Quelle ): Am Samstag um 9:43 Uhr kam es zum Bruch einer Haupt-Trinkwasserleitung in der Karlsruher Waldstadt. Die Leitung hat einen Durchmesser von 60 cm, stammt aus dem Jahr 1962 und hat normalerweise eine Lebensdauer von rund 90 Jahren. Warum es zum Bruch kam, steht noch nicht fest. Die Leitung wurde inzwischen abgesperrt, die Aufgrabungen beginnen am Montag. Alle Haushalte sind inzwischen wieder mit Wasser versorgt, der Druck im gesamten Stadtnetz hat sich normalisiert. Haushalte, die aktuell noch Probleme mit dem Wasserdruck haben, melden sich bitte telefonisch bei der StÃ¶rungsstelle unter 599-12. Oft sind die Filter der Hausinstallation verstopft und mÃ¼ssen gereinigt werden. Enormer Wasserverlust Aus der gebrochenen Leitung flossen Ã¼ber 1 Million Liter Wasser. Das ist rund ein Drittel so viel Wasser wie ganz Karlsruhe in einer Stunde verbraucht. Durch den enormen Wasserverlust kam es im gesamten Stadtnetz zu einem Druckverlust und damit zu EinschrÃ¤nkungen in der Wasserversorgung. Normalerweise liegt der Druck bei 4 bis 5 bar, in den westlichen und sÃ¼dlichen Stadtteilen fiel er auf 2 bis 3 bar, in Durlach auf 1,3 bar und in der Waldstadt auf 0,1 bar, so dass dort kaum noch Wasser aus den Leitungen kam. AuÃŸerdem wurden im Umfeld der StÃ¶rungsstelle in der Waldstadt einige Keller Ã¼berflutet. Sie wurden von der Feuerwehr ausgepumpt. Leider kam es parallel zum Wasserrohrbruch zu einer technischen StÃ¶rung der Stadtwerke-Server, so dass die Homepages der Stadtwerke und der Stadtwerke Netzservice Gesellschaft lÃ¤ngere Zeit nicht erreichbar waren. edit: Es stellt sich heraus, dass es wohl ein Materialfehler war ( Quelle ). Update, 12:20 Bei mir lÃ¤uft das Wasser wieder. Ich war gerade bei der Stelle, wo der Wasserrohrbruch passiert sein soll. Es waren ca. 10 Feuerwehrleute, 2 Polizisten, 2 Pressesprecher und 2 Redakteure da. DafÃ¼r, dass so viele Leute davon betroffen sind erstaunlich wenige. Und man hat im Prinzip kein Wasser gesehen. In der NÃ¤he der Stelle ist eine groÃŸe Baustelle, aber es waren keine Bauarbeiter dort. Auf meine Nachfrage, warum die Leitung kaputt gegangen ist gab es nur ein Achselzucken: \"Das passiert halt manchmal.\" Bisher habe ich (ohne groÃŸ darÃ¼ber nachzudenken) gedacht, dass das \"Netzwerkproblem\" fÃ¼r das Internet, fÃ¼r GÃ¼ter und Waren (Zug- und StraÃŸennetzwerke) und fÃ¼r Wasser im Grunde sehr Ã¤hnlich ist (was anfÃ¤lligkeiten fÃ¼r AusfÃ¤lle von Quellen / Knotenpunkten / Kanten angeht). Ein wesentlicher Unterschied der mir bis gerade eben so nicht bewusst war ist die Tatsache, dass ein Rohrbruch als neue extreme Senke zu modellieren ist. Es ist also nicht einfach das Entfernen eines Knotens / einer Kante, sondern das Ersetzen einer Kante durch eine Senke. Siehe auch swr.de: Rohrbruch in Karlsruhe , 20.02.2016","tags":"German posts","title":"Wasserrohrbruch in Karlsruhe"},{"url":"https://martin-thoma.com/collaborative-filtering/","text":"Suppose you are in the Netflix setting: You have \\(M\\) movies, \\(N\\) users and integer ratings \\(1, \\dots, K\\) for some movies by some users. You want to predict all missing values. This means you want to say how the users would rate movies they have not actually rated. Please note that ratings for products on Amazon might be a very similar situation. It might also be similar to the StumbleUpon rating. The Problem Much Data : You have 17 000 movies, 480 000 users and 100 000 000 ratings of movies by those users. Missing Data : Although you have a lot of ratings, a complete dataset would be \\(17\\cdot 10&#94;3 \\cdot 480 \\cdot 10&#94;3 = 8160 \\cdot 10&#94;6\\) ratings. This means you only have about 12% of all possible ratings. There is a lot of data missing. A Solution Train one RBM per user, but share weights amongst the RBMs. This simply means the weights are averaged. The visible units are movies. But instead of having binary visible units, the units have \\(K=5\\) states on which softmax is applied. The hidden units (about 100) model dependencies between movie ratings. When you now want to predict the missing ratings, you can just perform a sampling in the user-specific RBM. You calculate the values of the hidden units, then you have a vector for this user which describes the users preferences. You add the missing movies with the weights from the other users and sample back. Material Salakhutdinov, Mnih and Hinton: Restricted Boltzmann machines for collaborative filtering . In Proceedings of the 24th international conference on Machine learning, 2007. Hinton: 5. RBMs for Collaborative Filtering on YouTube. 9th of November 2013. Netflix Prize Data Set","tags":"Machine Learning","title":"Collaborative Filtering"},{"url":"https://martin-thoma.com/softmax/","text":"Softmax is an activation function for multi-layer perceptrons (MLPs). It is a function which gets applied to a vector in \\(\\mathbb{x} \\in \\mathbb{R}&#94;K\\) and returns a vector in \\([0, 1]&#94;K\\) with the property that the sum of all elements is 1: $$\\varphi(\\mathbb{x})_j = \\frac{e&#94;{x_j}}{\\sum_{k=1}&#94;K e&#94;{x_k}} \\;\\;\\;\\text{ for } j=1, \\dots, K$$ Python implementation The implementation is straight forward: #! /usr/bin/env python import numpy def softmax ( w ): \"\"\"Calculate the softmax of a list of numbers w. Parameters ---------- w : list of numbers Return ------ a list of the same length as w of non-negative numbers Examples -------- >>> softmax([0.1, 0.2]) array([ 0.47502081, 0.52497919]) >>> softmax([-0.1, 0.2]) array([ 0.42555748, 0.57444252]) >>> softmax([0.9, -10]) array([ 9.99981542e-01, 1.84578933e-05]) >>> softmax([0, 10]) array([ 4.53978687e-05, 9.99954602e-01]) \"\"\" e = numpy . exp ( numpy . array ( w )) dist = e / numpy . sum ( e ) return dist if __name__ == \"__main__\" : import doctest doctest . testmod () Short analysis One obvious property of the softmax function is that the sum of all elements is one due to the normalization in the denominator. By printing the following you can see that values below 1 get closer together and elements above 1 get farer away. def percentage ( before ): before = numpy . array ( before ) after = softmax ( before ) print ( \"Before: %s \" % str ( before / before [ - 1 ])) print ( \"After: %s \" % str ( after / after [ - 1 ])) print ( \"-\" * 60 ) experiments = [] experiments . append ([ 1 , 1.1 , 1.1 ]) experiments . append ([ 1 , 2 , 3 ]) experiments . append ([ 0.6 , 0.7 , 0.8 ]) for a in experiments : a = sorted ( a , reverse = True ) percentage ( a ) gives Before: [ 1.1 1.1 1. ] After: [ 1.10517092 1.10517092 1. ] ------------------------------------------------------------ Before: [3 2 1] After: [ 7.3890561 2.71828183 1. ] ------------------------------------------------------------ Before: [ 1.33333333 1.16666667 1. ] After: [ 1.22140276 1.10517092 1. ] ------------------------------------------------------------","tags":"Machine Learning","title":"Softmax"},{"url":"https://martin-thoma.com/comparing-classifiers/","text":"Classification problems occur quite often and many different classification algorithms have been described and implemented. But what is the best algorithm for a given error function and dataset? I read questions like \"I have problem X. What is the best classifier?\" quite often and my first impulse is always to write: Just try them! I guess people asking this question might think that it is super difficult to do so. However, the sklearn tutorial contains a very nice example where many classifiers are compared ( source ). This article gives you an overview over some classifiers: SVM k-nearest neighbors Random Forest AdaBoost Classifier Gradient Boosting Naive Bayes LDA QDA RBMs Logistic Regression RBM + Logistic Regression Classifier Of course, neural networks are also one very powerful ML classifier I may not forget. As sklearn does not have neural networks, I've installed skflow . Tutorial example The sklearn tutorial creates three datasets with 100 points per dataset and 2 dimensions per point: Moons : Two interleaving half-circles Circles : A larger circle containing the smaller one Linear : A linearly seperable dataset Each of those three datasets has added noise. This means for some points there might be no way of classifying them correclty. Here are the results k nearest neighbors, linear and RBFSVM One can see that k nearest neighbors gives arbitrary decision boundaries. Overall, they look reasonable. However, there are often strange zig-zag patterns. The linear SVM in contrast has a very easy decision boundary: a line. It is no suprise that it can't deal with the moons dataset. Note that a random guess would be right in 50% of the cases. The RBF SVM has very nice decision boundary. It is smooth, matches the pattern and is able to adjust to all three examles. Decision Tree, Random Forest, AdaBoost Decision Trees, Decision Forests and AdaBoost all show very similar patterns. The boundaries change in parallel to the coordinate axes which looks very unnatural. Naive Bayes, LDA, QDA Naive Bayes shows nice, smooth patterns. However, those patterns seem to be a bit too simple. LDA is again linear (see linear SVM). Comparing QDA to Naive Bayes is interesting. Although they get similar performance for the first dataset, I would argue that the naive bayes classifier is much better as it is much more confident for its classification. Even more extrem is the last example. I'm astonished that the QDA gets 93% with that boundary; Naive Bayes seems to find a much better boundary. The hardware The following comparison is done on a PC with an Intel i7-4820K CPU and a NVIDIA GeForce GTX Titan Black GPU. MNIST MNIST is a dataset of \\(28\\text{px} \\times 28\\text{px}\\) greyscale images. Each of the images contains a digit (0, 1, 2, 3, 4, 5, 6, 7, 8, 9). The task is to classify the image into one of the 10 digit classes. Guessing randomly will give an accuracy of \\(\\frac{1}{10} = 0.1\\) . Neural Networks Please note that there are neural networks which get much better accuracy. Most notably the MNIST Expert tutorial with 99.2% accuracy. Simple Network Classifier : NN 500 : 200 Training time : 79.5696 s Testing time : 0.3480 s Confusion matrix : [[ 2248 1 5 1 2 4 8 2 5 2 ] [ 1 2565 10 1 1 0 2 7 1 0 ] [ 7 2 2258 14 5 0 9 6 10 3 ] [ 0 0 12 2294 0 23 0 6 3 10 ] [ 0 3 3 0 2161 0 8 5 1 30 ] [ 4 1 1 16 1 2014 17 1 5 9 ] [ 11 7 1 0 5 6 2237 0 4 0 ] [ 3 6 14 7 3 1 0 2355 10 18 ] [ 3 7 3 14 2 17 4 1 2161 3 ] [ 4 4 0 4 16 8 0 7 6 2340 ]] Accuracy : 0.9798 Dropout Network Classifier : NN 500 : 200 dropout Training time : 118.2654 s Testing time : 0.3918 s Confusion matrix : [[ 2250 1 7 1 1 1 5 4 4 4 ] [ 1 2567 9 1 1 0 0 3 5 1 ] [ 6 6 2272 3 2 1 3 10 8 3 ] [ 0 0 26 2260 0 24 0 10 19 9 ] [ 0 3 5 0 2152 0 7 3 1 40 ] [ 8 3 3 12 2 1983 20 6 21 11 ] [ 11 6 3 0 7 1 2237 0 6 0 ] [ 2 7 13 3 11 0 1 2363 5 12 ] [ 7 7 9 5 3 3 1 2 2170 8 ] [ 3 3 1 3 13 2 0 19 8 2337 ]] Accuracy : 0.9780 CNN Classifier : CNN Training time : 391.8810 s Testing time : 1.2035 s Confusion matrix : [[ 2243 0 5 0 0 5 9 1 12 3 ] [ 1 2548 20 4 2 0 1 6 6 0 ] [ 3 8 2253 9 3 1 4 17 14 2 ] [ 0 4 13 2290 0 12 0 9 11 9 ] [ 2 4 5 0 2164 0 8 5 3 20 ] [ 6 2 3 15 0 2016 9 3 9 6 ] [ 12 12 1 1 6 6 2227 0 6 0 ] [ 3 4 11 3 4 1 0 2374 4 13 ] [ 3 15 6 13 4 11 3 8 2145 7 ] [ 6 5 0 11 16 8 0 24 13 2306 ]] Accuracy : 0.9769 SVM There is a ton of literature / papers about SVMs . I've summed up the basics on Using SVMs with sklearn . I've trained two SVMs: A simple, linear one and one with an RBF kernel as I found it online (I'm sorry, I don't remember where I found those parameters :-/). Please note the the SVM implementation of sklearn does not use the GPU. However, there are GPU implmentations of SVMs around. Linear SVM Classifier : linear SVM Training time : 168.6950 s Testing time : 158.0101 s Confusion matrix : [[ 2226 0 9 2 6 12 8 3 11 1 ] [ 1 2537 18 3 3 1 1 7 17 0 ] [ 12 16 2158 25 24 6 27 19 25 2 ] [ 3 7 46 2188 4 47 3 18 27 5 ] [ 2 5 19 1 2117 1 8 6 3 49 ] [ 18 13 11 73 20 1872 31 0 26 5 ] [ 20 6 22 1 10 30 2179 0 3 0 ] [ 5 10 32 11 30 5 0 2268 5 51 ] [ 11 39 26 47 10 40 7 7 2018 10 ] [ 11 9 9 24 64 8 0 61 14 2189 ]] Accuracy : 0.9416 Adjusted SVM Classifier : adj . SVM Training time : 347.1539 s Testing time : 234.5724 s Confusion matrix : [[ 2258 1 4 1 2 2 3 1 4 2 ] [ 1 2566 9 1 1 0 0 7 3 0 ] [ 4 1 2280 5 4 0 1 9 8 2 ] [ 0 0 14 2304 1 13 0 6 8 2 ] [ 2 2 2 0 2183 0 7 5 0 10 ] [ 4 0 0 16 3 2026 12 1 4 3 ] [ 7 5 3 0 5 2 2245 0 4 0 ] [ 1 6 11 2 5 1 0 2373 5 13 ] [ 3 9 4 9 4 10 2 3 2166 5 ] [ 3 2 2 6 19 6 0 12 10 2329 ]] Accuracy : 0.9840 Random Forest Data: n_estimators=50 n_jobs=10 Classifier : Random Forest Training time : 2.1359 s Testing time : 26.0763 s Confusion matrix : [[ 2246 1 4 1 4 2 7 2 11 0 ] [ 1 2543 18 5 5 2 3 7 4 0 ] [ 7 2 2233 20 9 2 9 16 14 2 ] [ 0 3 36 2240 0 20 3 16 19 11 ] [ 3 1 5 0 2142 1 11 3 7 38 ] [ 7 4 4 30 6 1977 16 3 14 8 ] [ 13 11 4 0 10 15 2210 0 8 0 ] [ 3 8 29 2 19 0 0 2315 7 34 ] [ 3 12 18 17 9 26 4 7 2103 16 ] [ 10 6 6 24 27 13 3 20 18 2262 ]] Accuracy : 0.9641 Alternatively: max_depth=5 n_estimators=10 max_features=1 Classifier : Random Forest 2 Training time : 0.2077 s Testing time : 22.2770 s Confusion matrix : [[ 1955 32 63 64 12 4 109 21 13 5 ] [ 1 2524 20 14 1 6 10 6 6 0 ] [ 252 425 1198 151 64 1 145 15 55 8 ] [ 136 195 140 1641 28 11 22 95 65 15 ] [ 92 320 21 45 1199 9 76 153 8 288 ] [ 312 383 67 655 78 268 47 94 134 31 ] [ 199 364 125 58 96 13 1408 5 2 1 ] [ 83 424 10 70 101 1 19 1555 56 98 ] [ 392 574 44 147 52 17 71 106 773 39 ] [ 71 338 11 43 579 2 8 632 24 681 ]] Accuracy : 0.5715 k nearest neightbors Classifier : k nn Training time : 4.6439 s Testing time : 1261.7815 s Confusion matrix : [[ 2260 1 4 0 0 1 6 2 2 2 ] [ 0 2572 5 0 0 0 1 8 1 1 ] [ 16 15 2235 9 1 0 5 26 5 2 ] [ 2 5 14 2276 0 27 1 8 9 6 ] [ 4 19 0 0 2131 0 8 4 0 45 ] [ 10 5 3 28 5 1977 25 2 4 10 ] [ 12 9 0 0 4 7 2239 0 0 0 ] [ 1 18 4 1 12 0 0 2349 3 29 ] [ 11 32 8 36 11 34 5 7 2053 18 ] [ 6 8 4 14 26 4 0 19 5 2303 ]] Accuracy : 0.9695 Decision Tree Data: max_depth=5 Classifier : Decision Tree Training time : 3.1346 s Testing time : 0.0313 s Confusion matrix : [[ 1767 0 11 25 12 120 137 71 114 21 ] [ 1 2065 128 108 13 17 41 66 131 18 ] [ 42 44 1248 37 121 21 227 76 339 159 ] [ 33 22 32 1484 33 107 52 81 266 238 ] [ 0 15 45 33 1284 42 42 45 213 492 ] [ 42 10 21 229 166 577 137 123 254 510 ] [ 34 33 66 24 103 65 1734 24 102 86 ] [ 10 14 179 57 53 21 19 1775 79 210 ] [ 1 98 129 43 43 42 160 29 1439 231 ] [ 4 8 86 59 125 95 36 75 167 1734 ]] Accuracy : 0.6540 Adaboost You should note that you can use arbitrary base classifiers with Adaboost. The default ones of sklearn.ensemble.AdaBoostClassifier is sklearn.tree.DecisionTreeClassifies Classifier : AdaBoost Training time : 37.6443 s Testing time : 1.5815 s Confusion matrix : [[ 1994 0 75 8 6 113 51 3 15 13 ] [ 0 2435 27 22 2 10 12 37 42 1 ] [ 97 39 1341 85 39 38 416 39 196 24 ] [ 108 52 37 1508 13 313 66 64 122 65 ] [ 11 16 48 23 1662 49 23 134 90 155 ] [ 81 56 30 309 51 1255 57 17 129 84 ] [ 29 28 151 7 80 43 1914 2 17 0 ] [ 25 37 33 36 70 30 0 1761 37 388 ] [ 30 80 48 215 16 85 30 19 1615 77 ] [ 13 29 68 66 356 74 1 171 78 1533 ]] Accuracy : 0.7367 Gradient Boosting Gradient boosting with xgboost has won in the Rossmann Store Sales prediction ( source ). See also: Caterpillar Winners' Interview Caterpillar Winners' Interview: 3rd place Liberty Mutual Property Inspection, Winner's Interview Recruit Coupon Purchase Winner's Interview: 2nd place Dato Truly Native? Winner's Interview: 2nd place Classifier : Gradient Boosting Training time : 2409.8094 s Testing time : 0.4159 s Confusion matrix : [[ 2214 1 3 5 10 8 9 3 24 1 ] [ 1 2528 16 11 3 5 5 7 9 3 ] [ 8 5 2165 34 16 5 12 22 37 10 ] [ 1 9 27 2182 4 42 1 22 37 23 ] [ 5 4 16 1 2088 5 12 5 10 65 ] [ 9 6 7 41 8 1928 27 6 18 19 ] [ 15 7 4 1 19 29 2181 1 14 0 ] [ 6 16 27 15 22 6 0 2246 8 71 ] [ 5 20 14 25 15 29 6 6 2057 38 ] [ 6 10 8 24 49 15 1 54 17 2205 ]] Accuracy : 0.9435 Naive Bayes Classifier : Naive Bayes Training time : 0.3814 s Testing time : 0.8863 s Confusion matrix : [[ 2094 4 11 10 6 7 56 3 69 18 ] [ 4 2432 9 11 2 4 28 1 77 20 ] [ 278 64 703 143 6 4 558 4 528 26 ] [ 202 136 18 791 5 5 106 21 886 178 ] [ 96 26 16 14 296 8 169 13 535 1038 ] [ 327 63 15 39 14 87 100 5 1253 166 ] [ 34 51 17 1 1 5 2109 0 52 1 ] [ 19 21 3 23 20 2 7 737 123 1462 ] [ 39 326 13 16 8 18 25 7 1482 281 ] [ 15 26 8 2 14 2 1 41 40 2240 ]] Accuracy : 0.5615 LDA Classifier : LDA Training time : 20.6464 s Testing time : 0.0910 s Confusion matrix : [[ 2131 2 10 14 12 47 20 4 36 2 ] [ 0 2454 20 10 5 16 5 5 71 2 ] [ 22 71 1873 77 51 8 82 20 101 9 ] [ 5 32 56 1992 11 77 11 40 80 44 ] [ 1 21 17 0 1983 12 12 2 21 142 ] [ 19 18 11 112 18 1682 37 11 103 58 ] [ 28 30 32 3 43 51 2046 0 37 1 ] [ 16 57 25 20 70 8 0 1990 11 220 ] [ 9 113 16 64 33 115 13 10 1781 61 ] [ 15 10 6 35 133 14 0 122 22 2032 ]] Accuracy : 0.8642 QDA Classifier : QDA Training time : 23.0527 s Testing time : 6.2259 s Confusion matrix : [[ 2212 3 12 14 1 4 20 5 6 1 ] [ 66 2409 12 10 0 0 32 2 39 18 ] [ 961 25 689 143 3 1 310 2 166 14 ] [ 1231 48 29 606 3 13 66 10 232 110 ] [ 810 22 25 27 250 4 143 17 345 568 ] [ 909 15 13 33 1 214 140 4 666 74 ] [ 83 18 14 1 1 2 2146 0 6 0 ] [ 81 13 6 52 14 2 1 776 120 1352 ] [ 487 181 18 20 6 17 58 3 1320 105 ] [ 65 14 12 7 10 0 0 23 33 2225 ]] Accuracy : 0.5561 MNIST Summary Classifier Accuracy Training Time Testing Time MLP (500:200) 97.98% 79.5696s 0.3480s Dropout NN (500:200) 97.80% 118.2654s 0.3918s CNN (32 5Ã—5 filters : 2Ã—2 max pool : 64 5Ã—5 filters : 2Ã—2 max pool : 1024) 97.69% 391.8810s 1.2035s Adjusted SVM 98.40% 347.1539s 234.5724s Linear SVM 94.16% 168.6950s 158.0101s Random Forest (n_estimators=50, n_jobs=10) 96.41% 2.1359s 26.0763s Random Forest (n_estimators=10, max_features=1, max_depth=5) 57.15% 0.2077s 22.2770s k nearest neightbors (k=3) 96.95% 4.6439s 1261.7815s Decision Tree(max_depth=5) 65.40% 3.1346s 0.0313s Adaboost 73.67% 37.6443s 1.5815s Naive Bayes 56.15% 0.3814s 0.8863s LDA 86.42% 20.6464s 0.0910s QDA 55.61% 23.0527s 6.2259s Gradient Boosting 94.35% 2409.8094s 0.4159s Logistic Regression (C=1) 91.47% 272.1309s 0.0531s Logistic Regression (C=10000) 91.23% 1807.0624s 0.0529s IRIS summary Just for fun, I tried the script from above with very minor adjustments to the IRIS flower dataset : Classifier Accuracy Training Time Testing Time AdaBoost 92.00% 0.1203s 0.0101s Decision Tree 92.00% 0.0005s 0.0001s Gradient Boosting 92.00% 0.2227s 0.0007s LDA 96.00% 0.0027s 0.0002s NN 20:5 90.00% 1.6628s 0.0046s Naive Bayes 90.00% 0.0010s 0.0004s QDA 94.00% 0.0009s 0.0003s Random Forest 90.00% 0.2147s 0.1395s Random Forest 2 90.00% 0.1481s 0.1249s SVM, adj. 90.00% 0.0010s 0.0004s SVM, linear 88.00% 0.0006s 0.0002s k nn 92.00% 0.0007s 0.0009s Logistic Regression (C=1) 88.00% 0.0011s 0.0001s Logistic Regression (C=1000) 92.00% 0.0010s 0.0002s RBM 100 78.00% 0.0233s 0.0003s RBM 100, n_iter=20 70.00% 0.0427s 0.0003s RBM 200, n_iter=40, LR=0.01, Reg: C=1 88.00% 0.2463s 0.0005s RBM 200, n_iter=40, LR=0.01, Reg: C=10000 90.00% 0.2437s 0.0005s RBM 256 84.00% 0.0424s 0.0006s RBM 512, n_iter=100 84.00% 0.0723s 0.0010s TL;DR Neural networks take their time to train and a feeling for the topology, but their classification results are nice and the testing time is good as well. Random Forests and SVMs are also a model a type of model one should think of. However, the standard implementation is very slow compared to neural networks. sklearn.lda.LDA might also be worth a try. The rest seems to be quite bad compared with those classifiers. The code which generated the examples from above is here .","tags":"Machine Learning","title":"Comparing Classifiers"},{"url":"https://martin-thoma.com/function-approximation/","text":"I was recently quite disappointed by how bad neural networks are for function approximation (see How should a neural network for unbound function approximation be structured? ). However, I've just found that Gaussian processes are great for function approximation! There are two important types of function approximation: Interpolation : What values does the function have in between of known values? Extrapolation : What values does the function have outsive of the known values? I did a couple of very quick examples which look promising. Examples Square Approximating \\(f(x) = x&#94;2\\) worked very good: f(x) = x&#94;2 I've tried if with higher order polynomials, more complex polynomials. No problem. Sin Approximating \\(f(x) = \\sin(3x)\\) seems to be more complicated: f(x) = sin(3x) I guess a human would see the wave pattern and do a better job here. exp Approximating \\(f(x) = e&#94;x\\) works similar well as polynomials. One can see that it does not perfectly fit it, but compared the the range of values seen before and the distance from the last seen value I think this is absolutely acceptable: f(x) = e&#94;x noise It is claimed that Gaussian processes implicitly model noise so that they can easily deal with noise. However, in my experients this seems not to work so great. The reason might be that I had points in \\([-3, 3]\\) of the function $$f(x) = x&#94;2$$ with point-wise gaussian noise \\(N \\sim \\mathcal{N}(0, 1)\\) . So the noise is quite domintant on that intervall. One of the examples where it worked better is: f(x) = x&#94;2 with gaussian noise Make it brake I was a bit suspicious if I had another mistake here. So I wanted it to break. This was the reason why I created the following function $$f(x) = \\begin{cases}x&#94;2 &\\text{if } x \\geq 0\\\\\\\\-1 &\\text{otherwise}\\end{cases}$$ Function with discontinuity The predicted value is obviously not correct, but you should note that almost all function values are within the 95% confidence intervall! Code The following code needs numpy and sklearn . For the plots, you need matplotlib . #!/usr/bin/env python \"\"\"Example how to use gaussion processes for regression.\"\"\" import numpy as np from sklearn import gaussian_process def main (): # Create the dataset x_train = np . atleast_2d ( np . linspace ( - 3 , 3 , num = 50 )) . T y_train = f ( x_train ) . ravel () x_test = np . atleast_2d ( np . linspace ( - 5 , 5 , 1000 )) . T # Define the Regression Modell and fit it gp = gaussian_process . GaussianProcess ( theta0 = 1e-2 , thetaL = 1e-4 , thetaU = 1e-3 ) gp . fit ( x_train , y_train ) # Evaluate the result y_pred , mse = gp . predict ( x_test , eval_MSE = True ) print ( \"MSE: %0.4f \" % sum ( mse )) print ( \"max MSE: %0.4f \" % max ( mse )) plot_graph ( x_test , x_train , y_pred , mse , \"x&#94;2\" ) def f ( x ): \"\"\" Function which gets approximated \"\"\" noise = [ np . random . normal ( loc = 0.0 , scale = 1.0 ) for _ in range ( len ( list ( x )))] noise = np . atleast_2d ( noise ) . T return x ** 2 + noise # Totally fails for that one: # y = [] # for el in x: # if el >= 0: # y.append(el**2) # else: # y.append(-1) # return np.array(y) def plot_graph ( x , x_train , y_pred , mse , function_tex ): # Plot the function, the prediction and the 95% confidence interval # based on the MSE sigma = np . sqrt ( mse ) from matplotlib import pyplot as pl pl . figure () y = f ( x_train ) . ravel () pl . plot ( x , f ( x ), 'r:' , label = u '$f(x) = %s $' % function_tex ) pl . plot ( x_train , y , 'r.' , markersize = 10 , label = u 'Observations' ) pl . plot ( x , y_pred , 'b-' , label = u 'Prediction' ) pl . fill ( np . concatenate ([ x , x [:: - 1 ]]), np . concatenate ([ y_pred - 1.9600 * sigma , ( y_pred + 1.9600 * sigma )[:: - 1 ]]), alpha =. 5 , fc = 'b' , ec = 'None' , label = '95 % c onfidence interval' ) pl . xlabel ( '$x$' ) pl . ylabel ( '$f(x)$' ) y_min = min ( min ( y_pred ), min ( y )) * 1.1 y_max = max ( max ( y_pred ), max ( y )) * 1.1 pl . ylim ( y_min , y_max ) pl . legend ( loc = 'upper left' ) pl . show () if __name__ == '__main__' : main () See also www.gaussianprocess.org : The definitive book about gaussian processes. It's freely available online! Wikipedia sklearn: Gaussian Processes sklearn: Gaussian Processes regression: basic introductory example","tags":"Machine Learning","title":"Function Approximation"},{"url":"https://martin-thoma.com/svm-with-sklearn/","text":"Support Vector Machines (SVMs) is a group of powerful classifiers. In this article, I will give a short impression of how they work. I continue with an example how to use SVMs with sklearn. SVM theory SVMs can be described with 5 ideas in mind: Linear, binary classifiers : If data is linearly separable, it can be separated by a hyperplane. There is one hyperplane which maximizes the distance to the next datapoints (support vectors). This hyperplane should be taken: $$ \\begin{aligned} \\text{minimize}_{\\mathbf{w}, b}\\,&\\frac{1}{2} \\|\\mathbf{w}\\|&#94;2\\\\ \\text{s.t. }& \\forall_{i=1}&#94;m y_i \\cdot \\underbrace{(\\langle \\mathbf{w}, \\mathbf{x}_i\\rangle + b)}_{\\text{Classification}} \\geq 1 \\end{aligned}$$ Slack variables : Even if the underlying process which generates the features for the two classes is linearly separable, noise can make the data not separable. The introduction of slack variables to relax the requirement of linear separability solves this problem. The trade-off between accepting some errors and a more complex model is weighted by a parameter $C \\in \\mathbb{R}_0&#94;+$. The bigger $C$, the more errors are accepted. The new optimization problem is: $$ \\begin{aligned} \\text{minimize}_{\\mathbf{w}, b}\\,&\\frac{1}{2} \\|\\mathbf{w}\\|&#94;2 + C \\cdot \\sum_{i=1}&#94;m \\xi_i\\\\ \\text{s.t. }& \\forall_{i=1}&#94;m y_i \\cdot (\\langle \\mathbf{w}, \\mathbf{x}_i\\rangle + b) \\geq 1 - \\xi_i \\end{aligned}$$ Note that $0 \\le \\xi_i \\le 1$ means that the data point is within the margin, whereas $\\xi_i \\ge 1$ means it is misclassified. An SVM with $C > 0$ is also called a soft-margin SVM . Dual Problem : The primal problem is to find the normal vector $\\mathbf{w}$ and the bias $b$. The dual problem is to express $\\mathbf{w}$ as a linear combination of the training data $\\mathbf{x}_i$: $$\\mathbf{w} = \\sum_{i=1}&#94;m \\alpha_i y_i \\mathbf{x}_i$$ where $y_i \\in \\{-1, 1\\}$ represents the class of the training example and $\\alpha_i$ are Lagrange multipliers. The usage of Lagrange multipliers is explained with some examples in [ Smi04 ]. The usage of the Lagrange multipliers $\\alpha_i$ changes the optimization problem depend on the $\\alpha_i$ which are weights for the feature vectors. It turns out that most $\\alpha_i$ will be zero. The non-zero weighted vectors are called support vectors . The optimization problem is now, according to [ Bur98 ] (a great read; if you really want to understand it I can recommend it!): $$ \\begin{aligned} \\text{maximize}_{\\alpha_i}\\,& \\sum_{i=1}&#94;m \\alpha_i - \\frac{1}{2} \\sum_{i=1}&#94;m \\sum_{j=1}&#94;m \\alpha_i \\alpha_j y_i y_j \\langle \\mathbf{x}_i, \\mathbf{x}_j \\rangle\\\\ \\text{s.t. } & \\forall_{i=1}&#94;m 0 \\leq \\alpha_i \\leq C\\\\ \\text{s.t. } & \\sum_{i=1}&#94;m \\alpha_i y_i = 0 \\end{aligned}$$ Kernel-Trick : Not every dataset is linearly separable. This problem is approached by transforming the feature vectors $\\mathbf{x}$ with a non-linear mapping $\\Phi$ into a higher dimensional (probably $\\infty$-dimensional) space. As the feature vectors $\\mathbf{x}$ are only used within scalar product $\\langle \\mathbf{x}_i, \\mathbf{x}_j \\rangle$, it is not necessary to do the transformation. It is enough to do the calculation $$K(\\mathbf{x}_i, \\mathbf{x}_j) = \\langle \\mathbf{x}_i, \\mathbf{x}_j \\rangle$$ This function $K$ is called a kernel . The idea of never explicitly transforming the vectors $\\mathbf{x}_i$ to the higher dimensional space is called the kernel trick . Common kernels include the polynomial kernel $$K_P(\\mathbf{x}_i, \\mathbf{x}_j) = (\\langle \\mathbf{x}_i, \\mathbf{x}_j \\rangle + r)&#94;p$$ of degree $p$ and coefficient $r$, the Gaussian RBF kernel $$K_{\\text{Gauss}}(\\mathbf{x}_i, \\mathbf{x}_j) = e&#94;{\\frac{-\\gamma\\|\\mathbf{x}_i - \\mathbf{x}_j\\|&#94;2}{2 \\sigma&#94;2}}$$ and the sigmoid kernel $$K_{\\text{tanh}}(\\mathbf{x}_i, \\mathbf{x}_j) = \\tanh(\\gamma \\langle \\mathbf{x}_i, \\mathbf{x}_j \\rangle - r)$$ where the parameter $\\gamma$ determines how much influence single training examples have. Multiple Classes : By using the one-vs-all or the one-vs-one strategy it is possible to get a classifying system which can distinguish many classes. A nice visualization of the transformation of the data in a higher-dimensional space was done by TeamGrizzly's channel: Performing nonlinear classification via linear separation in higher dimensional space on YouTube. 22.11.2010. See also: What is an example of a SVM kernel, where one implicitly uses an infinity-dimensional space? SVM - hard or soft margins? sklearn sklearn is the machine learning toolkit to get started for Python. It has a very good documentation and many functions. You can find installation instructions on their website. It also includes sklearn.svm.SVC . SVC is short for support vector classifier and this is how you use it for the MNIST dataset. Parameters for which you might want a further explanation: cache_size : datascience.stackexchange.com #!/usr/bin/env python \"\"\" Train a SVM to categorize 28x28 pixel images into digits (MNIST dataset). \"\"\" import numpy as np def main (): \"\"\"Orchestrate the retrival of data, training and testing.\"\"\" data = get_data () # Get classifier from sklearn.svm import SVC clf = SVC ( probability = False , # cache_size=200, kernel = \"rbf\" , C = 2.8 , gamma =. 0073 ) print ( \"Start fitting. This may take a while\" ) # take all of it - make that number lower for experiments examples = len ( data [ 'train' ][ 'X' ]) clf . fit ( data [ 'train' ][ 'X' ][: examples ], data [ 'train' ][ 'y' ][: examples ]) analyze ( clf , data ) def analyze ( clf , data ): \"\"\" Analyze how well a classifier performs on data. Parameters ---------- clf : classifier object data : dict \"\"\" # Get confusion matrix from sklearn import metrics predicted = clf . predict ( data [ 'test' ][ 'X' ]) print ( \"Confusion matrix: \\n %s \" % metrics . confusion_matrix ( data [ 'test' ][ 'y' ], predicted )) print ( \"Accuracy: %0.4f \" % metrics . accuracy_score ( data [ 'test' ][ 'y' ], predicted )) # Print example try_id = 1 out = clf . predict ( data [ 'test' ][ 'X' ][ try_id ]) # clf.predict_proba print ( \"out: %s \" % out ) size = int ( len ( data [ 'test' ][ 'X' ][ try_id ]) ** ( 0.5 )) view_image ( data [ 'test' ][ 'X' ][ try_id ] . reshape (( size , size )), data [ 'test' ][ 'y' ][ try_id ]) def view_image ( image , label = \"\" ): \"\"\" View a single image. Parameters ---------- image : numpy array Make sure this is of the shape you want. label : str \"\"\" from matplotlib.pyplot import show , imshow , cm print ( \"Label: %s \" % label ) imshow ( image , cmap = cm . gray ) show () def get_data (): \"\"\" Get data ready to learn with. Returns ------- dict \"\"\" simple = False if simple : # Load the simple, but similar digits dataset from sklearn.datasets import load_digits from sklearn.utils import shuffle digits = load_digits () x = [ np . array ( el ) . flatten () for el in digits . images ] y = digits . target # Scale data to [-1, 1] - This is of mayor importance!!! # In this case, I know the range and thus I can (and should) scale # manually. However, this might not always be the case. # Then try sklearn.preprocessing.MinMaxScaler or # sklearn.preprocessing.StandardScaler x = x / 255.0 * 2 - 1 x , y = shuffle ( x , y , random_state = 0 ) from sklearn.cross_validation import train_test_split x_train , x_test , y_train , y_test = train_test_split ( x , y , test_size = 0.33 , random_state = 42 ) data = { 'train' : { 'X' : x_train , 'y' : y_train }, 'test' : { 'X' : x_test , 'y' : y_test }} else : # Load the original dataset from sklearn.datasets import fetch_mldata from sklearn.utils import shuffle mnist = fetch_mldata ( 'MNIST original' ) x = mnist . data y = mnist . target # Scale data to [-1, 1] - This is of mayor importance!!! x = x / 255.0 * 2 - 1 x , y = shuffle ( x , y , random_state = 0 ) from sklearn.cross_validation import train_test_split x_train , x_test , y_train , y_test = train_test_split ( x , y , test_size = 0.33 , random_state = 42 ) data = { 'train' : { 'X' : x_train , 'y' : y_train }, 'test' : { 'X' : x_test , 'y' : y_test }} return data if __name__ == '__main__' : main () Results The script from above gives the following results: Confusion matrix for an SVM classifier on the MNIST dataset 0 1 2 3 4 5 6 7 8 9 0 2258 1 4 1 2 2 3 1 4 2 1 1 2566 9 1 1 0 0 7 3 0 2 4 1 2280 5 4 0 1 9 8 2 3 0 0 14 2304 1 13 0 6 8 2 4 2 2 2 0 2183 0 7 5 0 10 5 4 0 0 16 3 2026 12 1 4 3 6 7 5 3 0 5 2 2245 0 4 0 7 1 6 11 2 5 1 0 2373 5 13 8 3 9 4 9 4 10 2 3 2166 5 9 3 2 2 6 19 6 0 12 10 2329 Accuracy: 98.40% Error: 1.60% Looks pretty good to me. However, note that there are much better results. The best on the official website has an error of 0.23% and is a committee of 35 convolutional neural networks. The best SVM I could find has an error of 0.56% and applies a polynomial kernel of degree 9 as well as some preprocessing. References [ Smi04 ] B. T. Smith, \"Lagrange multipliers tutorial in the context of support vector machines,\" Memorial University of Newfoundland St. John's, Newfoundland, Canada, Jun. 2004. [ Bur98 ] C. J. Burges, \" A tutorial on support vector machines for pattern recognition \", Data mining and knowledge discovery, vol. 2, no. 2, pp. 121â€“167, 1998. See also Recognizing hand-written digits Trung Huynh's tech blog: Digit Recognition using SVM in Python Classifier comparison Supervised learning How can SVM 'find' an infinite feature space where linear separation is always possible?","tags":"Machine Learning","title":"Using SVMs with sklearn"},{"url":"https://martin-thoma.com/explaining-away/","text":"Explaining away is an effect where which is explained in Pearl (1988) with an example similar to the following one: A car's engine can fail ( \\(X\\) ). The reason might either be a dead battery \\(Y\\) or a blocked fuel pump \\(Z\\) . This results in the following Bayesian Network: A common effect Now assume you know that the engine does not fail ( \\(X=0\\) ). This guarantees that the battery is not dead ( \\(Y=0\\) ) and the fuel pump is not blocked ( \\(Z=0\\) ). However, if the engine failed ( \\(X=1\\) ) it gets more interesting. Let's say the engine works with a probability of 90%. From the graph, you can see that we assume that a dead battery is independant of a blocked fuel pump. Let's also assume that you know that either the fuel pump is blocked or the battery is dead when the engine failed. There is no other option. This makes setting the probability distribution up interesting. There is still 10% left which has to be distributed amongst \\(P(X=1,Y=1,Z=1), P(X=1,Y=1,Z=0), P(X=1,Y=0,Z=1)\\) : X Y Z P(X,Y,Z) comment 0 0 0 0.9 Engine works 0 0 1 0 impossible - blocked fuel pump and working engine 0 1 0 0 impossible - dead battery and working engine 0 1 1 0 impossible - dead battery, blocked fuel pump and working engine 1 0 0 0 impossible - a cause we don't have in our graph 1 0 1 a 1 1 0 b 1 1 1 c However, if you assume that \\(Y\\) and \\(Z\\) are independent, given \\(X\\) , then you would have to set \\(P(Y=0, Z=0|X=1) = P(Y=0|X=1) \\cdot P(Z=0|X=1)\\) which would not be 0 except one of the probabilities would be 0. Or, putting it different again: Given that you know the engine is broken, the event of a dead battery and a blocked fuel pump are suddenly not independent anymore! What does it mean This does not mean there is \"suddenly\" a causatal connection between a dead battery and a blocked fuel pump. It only means you can learn something for your predictions. See also Why does \"explaining away\" make intuitive sense? Interaction information","tags":"Cyberculture","title":"Explaining Away"},{"url":"https://martin-thoma.com/how-to-clear-a-usb-stick/","text":"Once in a while I think it is time to reduce the damage being done by the loss of a USB stick. USB sticks Remove all data Find the USB stick on your Linux system with fdisk -l . Make super sure that you really got the stick (e.g. by removing it and executing the command again). It should be something like /dev/sdb1 . The following command will overwrite the data on the stick 5 times: $ shred -f -n 5 /dev/sdX This may take several minutes even for very small USB sticks. Format the stick Start gparted and use the GUI. See also: How to format a USB flash drive? Add README In case I lose the stick, adding a README.txt makes with a way to contact me makes it most likely that I get the stick back. Dieser USB-Stick ging verloren. Mein Name ist Martin Thoma. Sie kÃ¶nnen mich per E-Mail unter info@martin-thoma.de erreichen. --- This USB-Stick was lost. My name is Martin Thoma. You can contact me via e-mail: info@martin-thoma.de","tags":"Cyberculture","title":"How to clear a USB stick"},{"url":"https://martin-thoma.com/new-year-2016/","text":"It's new years eve and - as always - I try to finish some things and have some plans for next year. Review of 2015 The last year has had it ups and downs. Most of them are private, so I'll not write too much about it. However, I would like to share two of them with you: I've been on my first summer school of the German National Academic Foundation (Sommerakademie der Studienstiftung, see photos ) and I've been for two weeks hiking the west highland way (see photos ). This month was really awesome. Here are some other mentionable facts: I've founded Machine Learning Karlsruhe . See ml-ka.de for more information. I've got 10 000 points on StackOverflow and reached 2.5 million people with my questions and answers ( source ) I've got the funding by the Begabtenstiftung to go with my friend Marvin to Berkeley. Let's see if Berkeley accepts us. I've published 4 papers on arXiv ( link ) (one is still on hold) and started building an academic profile with orcid.org/0000-0002-6517-1690 . I'm not sure how important that will be, though. I posted 36 articles on my blog in 2015. However, I don't think there is a single good article amongst them. I simply didn't have enough time to write an interesting article â˜¹. There are 47 drafts from 2015; 134 drafts in total. write-math.com now has 2520 users who contributed something 1595 formulas (that includes simple symbols) 274244 recordings. 6495 of those are not classified yet. Finishing Things I always do some cleanup before the new year begins. This means especially cleaning my computer stuff of unnecessary trash. E-Mail Finding and deleting old unnecessary emails: StackExchange: do-not-reply@stackexchange.com University physik-l@lists.kit.edu physik-ll@lists.kit.edu stipendiaten@lists.does-not-exist.org ilias@scc-ilias-03.scc.kit.edu Programming notifications@travis-ci.org noreply@coursera.org Other notify@twitter.com jobs-listings@linkedin.com messages-noreply@linkedin.com noreply@indiegogo.com mailing@abgeordnetenwatch.de offener-haushalt-request@lists.okfn.org infoen@bondora.com This were several hundret emails. The next step is going through \"marked emails\". Desktop and Downloads Clean those folders up ... *sigh*... I didn't get ready. Updating # apt-get update # apt-get upgrade $ upgrade_oh_my_zsh Plans I want to get the following things done in 2016: âœ” Quit church: That one is actually more complicated in Germany than it should be. I have to get to the civil registry office, get a personal date, pay 31.50 Euro (Source: karlsruhe.de ) âœ” Migrate from Jekyll to Pelican (see article draft ) [ ] Get all my stuff from my fathers apartment to my room. I've already packed most of it in boxes (In total: 1.30m (+0.30m?) Ã— 0.39m Ã— 0.60m by 7 boxes) âœ” Get rid of my old bed âœ” Get rid of my old vacuum cleaner âœ” Paint the wall âœ” Contact BSI, BKA, CCC and the car sellers and send them my paper in which I summarize current problems in car security. [ ] Get new slippers Of course, I have a lot of other plans. Although some people say I don't do anything besides computer stuff, I do have a prive life. But in contrast to others I like to keep it private. I wish all of you a happy new year! Predictions for 2016 I've just seen Predictions for 2016 on Computational Complexity and thought it is a fun idea. It is currently the 4th of January, so the year is still young enough to not consider this cheating: Machine Learning and Technology Networks will get deeper. Currently about 8 layers is usual; I expect this to get to over 30 layers. First hacks / funny results by people abusing the fact that machine learning is used will appear. Machines will generate \"high\" resolution images of at least 256 Ã— 256 pixels. Speech synthesis will fastly improve. To benchmark this, I will use the original quotation that explained the importance of towels is found in Chapter 3 of Adams' work The Hitchhiker's Guide to the Galaxy. See Towel Day , Google Translate Recording , Festival Recording ALPHABET INC. (C) (GOOGLE) shares at Frankfurt Stock Exchange will go up to about 900 Euro sometime in the year (currently, it is at 690 Euro). Solar Roadways will make some tiny advances. About Me One of my papers will get cited at least 5 times. I will spend at least 2 weeks abroad. I will publish at leat 40 articles on my blog. I will get a 90 days streak on GitHub (currently, my longest is 43 days). I will get 15 000 points on StackExchange (see StackExchange profile ) Politics The European Union will still exist and Britain will still be part of it (see Brexit ). Donald Trump will be the republican candidate and Hillary Clinton the democrat candidate. The republican candidate will get president. More mass shootings in the US and terrorist attacks all over the world will happen. GrÃ¼ne and SPD will still be in Baden-WÃ¼rttemberg (see Landtagswahl in Baden-WÃ¼rttemberg 2016 ).","tags":"Cyberculture","title":"New Year 2016"},{"url":"https://martin-thoma.com/analyzing-pypi-metadata-2/","text":"This is part two of a series. See Analyzing PyPI Data for part one. I've recently got a request to expand my analysis of the Python Package Index commonly known as PyPI. It is a repository of Python packages where everybody can upload packages; pretty much without any restriction. In the article Analyzing PyPI Metadata you can read some general stuff about the repository. This article is going a bit more deeper. This time I don't only analyze the metadata, but the relationship of the packages themselves. I wanted to build a dependency graph. However, here is a downside of Pythons package structure: The file which defines the dependencies of a Python package is a Python script itself. This gives the package developer the highest flexibility, but it also gives them the power to execute arbitrary code when I only want to get the dependencies. As I am pretty sure there are some malicious packages in the repository (Although I've never heard of a single one there has to be one. Over 50 000 packages by 2015 - there has to be one!). So I don't want to execute any code of the repository without having at least a clue what it should do. This means my analysis is very simple and thus prone to some errors. Most common single dependency One can see dependencies as being weighted by the number of times a package imports the package. Non-weighted SELECT ` packages ` . ` name ` , COUNT ( ` needs_package ` ) FROM ` dependencies ` JOIN ` packages ` ON ` needs_package ` = ` packages ` . ` id ` GROUP BY ` needs_package ` ORDER BY COUNT ( ` needs_package ` ) DESC LIMIT 20 which gives This bar chart displays which Python modules get imported by most Python packages and without the system packages: SELECT ` packages ` . ` name ` , COUNT ( ` needs_package ` ) FROM ` dependencies ` JOIN ` packages ` ON ` needs_package ` = ` packages ` . ` id ` WHERE ` on_pypi ` = 1 GROUP BY ` needs_package ` ORDER BY COUNT ( ` needs_package ` ) DESC LIMIT 20 which gives This bar chart displays which Python modules (excluding system modules) get imported by most Python packages Weighted How often gets a single module included over all packages? SELECT ` packages ` . ` name ` , SUM ( ` times ` ) FROM ` dependencies ` JOIN ` packages ` ON ` needs_package ` = ` packages ` . ` id ` GROUP BY ` needs_package ` ORDER BY SUM ( ` times ` ) DESC LIMIT 20 2 seconds later I've got the result: Number of imports of Python packages If I'm only interested in the packages which are on PyPI, hence not system packages, I execute the following query: SELECT ` packages ` . ` name ` , SUM ( ` times ` ) FROM ` dependencies ` JOIN ` packages ` ON ` needs_package ` = ` packages ` . ` id ` WHERE ` on_pypi ` = 1 GROUP BY ` needs_package ` ORDER BY SUM ( ` times ` ) DESC LIMIT 20 which gives me about 2 seconds later the following result: Number of imports of Python packages, excluding system packages Non-functional packages Although there are many packages for Python which are very useful, there are also quite a lot which are not usefull at all. One possibility to identify such packages is by checking which packages get neither used by others nor use other packages SELECT ` packages ` . ` id ` , ` name ` FROM ` packages ` WHERE ` id ` in ( SELECT DISTINCT ` dependencies ` . ` package ` FROM dependencies ) OR ` id ` in ( SELECT DISTINCT ` dependencies ` . ` needs_package ` FROM ` dependencies ` ) This leads to the result that 54 900 packages of 67 582 packages are not obviously crap. Or to write it in another way: 11 682 packages are crap. That is 17.5 %. Too much, in my opinion. However, this might also be due to my crappy script not downloading / checking the downloaded files correctly. Names One thing I was interested in while downloading all those packages was the question if there are malicious packages (either on purpose or by accident). One undesirable thing that could happen would be very similar names. Prefixes Let's see how many packages are prefixes of other packages. My thought was that this might be developers trying to get some accidential installs. However, it only showed some relationships. I wanted to make a Levensthein distance analysis, but I guess this is not worth it. Here are the top 10 strings which are prefixes of packages and packages themselves: djan: 6462 pyt: 1626 pyth: 1278 collect: 1155 Flask: 561 open: 474 pyr: 442 pyp: 295 pyra: 285 pym: 256 One interesting thing I've learned is that you can use pip like this: $ pip search \"djan $ \" ... and I found a pip bug ( github.com/pypa/pip/issues/3327 ) Graph analysis Analyzing the dependency graph is quite a challenge. Or at least that was what I initiallly thought. This graph has about 67 582 nodes and 436 980 edges. Quite a bit. Definitely much larger than what I have previously used. However, my friend Nilan who knows a lot about graphs send me a link to StackOverflow: Visualizing Undirected Graph That's Too Large for GraphViz? This lead me to Gephi and the OpenOrd layout plugin. It didn't work for the complete graph (see issues/1207 ), it worked after I removed the single nodes without edges. Now we can ask several standard questions about graphs: How many connected components are there? Are there any circles? (That would be bad... dependency graphs should not have circles. Similar to family trees.) Which are the most central nodes? I didn't find the time to answer those, but I put the graph data in JSON format on github.com/MartinThoma/pypi-dependencies . Please let me know when you do something interesting with the data. I've only got some crappy images with Gephi / GraphViz: Code See github.com/MartinThoma/algorithms . What could come next I would like too measure the overall code quality on PyPI in another post. I think of the following measures: pyroma : A 10-point score for packages package goodness with Cheesecake , pylint PEP8 conformance, Lines of code (LOC) / documentation / whitespace Docstring style (None, NumpyDoc, Sphinx, Google - see Python Code Documentation ) Usage of functions Testing coverage Look for URLs in the code and which are reachable / which are not Look for non-Python files See also Analysis of PyPI K. Gullikson: Python Dependency Analysis : A well-written article with some very nice images. O. Girardot: State of the Python/PyPI Dependency Graph : One very nice, interactive image of the dependency graph. Building big graphs Quick Start with Gephi Features of Gephi","tags":"Code","title":"Analyzing PyPI Data - 2"},{"url":"https://martin-thoma.com/how-to-find-new-papers/","text":"A couple of people who are just participating in their first seminar might ask themselves how you can find interesting new publications (papers). I would like to shed some light on it. Initial Research The hardest part is when you're new to a field. You don't know which journals are the important ones, which authors are most respected in the field, which terms are used. Journal Rankings Automated journal rankings like the h5-index used by Google Scholar (see metrics , Wikipedia ) is one way to deal with the lack of domain knowledge. Google Scholar even publishes a list of journals per field (see Top publications in Computer Vision and Pattern Recognition ). Google Scholar Journal ranking Algorithmic Ideas I've never tried it (on purpose), but the idea just came to my head: Use a random walk. You start with some paper of which you don't really know if it is good. Look at the references and try to weild out the ones which are obviously not work trying (e.g. because they are websites). Now take a random one to continue with. Do this a couple of times. The idea is that papers which are more important are much more often cited. So you can hope to get to more important papers over time. The hard way Search for papers via Google. Look at the references. Search for papers in the reference. Get a feeling for the language being used. Ongoing Research When you have a little bit of domain knowledge (or a starting paper given to you by your supervisor) everything gets a lot easier. There are a couple of key strategies: Looking at the references of a paper Looking at what else the same author published Looking for similar titles Reading Journals For all three of them, I can highly recommend Google Scholar . They also offer a nice overview / statistics about authors so that you can get a feeling for their scientific activity. But don't let you fool you by those numbers: It is possible to fake them. The other nice thing is that Google Scholar makes citing publications incredibly easy: Searching for a publication on Google Scholar Citing a publication via Google Scholar The arXiv The arXiv can be seen as THE \"modern way\" journal. Depending on the field, it has a VERY high reputation. For Pattern Recognition the reputation of the arXiv is amongst the highest ten journals, but it there are some fields like physics where it is THE top journal in several subfields like cosmology or high energy physics. What makes the arXiv stand out is the fact that you can read new papers every day. I like to have a view at cs.CV/recent to keep myself informed about new stuff. There are about 20 new publications per day. On some days, there is nothing interesting, on other days like today quite a bit: The MegaFace Benchmark: 1 Million Faces for Recognition at Scale Rethinking the Inception Architecture for Computer Vision Labeling the Features Not the Samples: Efficient Video Classification with Minimal Supervision Attribute2Image: Conditional Image Generation from Visual Attributes Latest submissions on arXiv in Pattern Recognition and Computer Vision Filtering I filter publications like this: First, I look at the title. If that doesn't look interesting, I skip it. The more exact the title is, the better. If it is too vague, I sometimes skip it too because the authors seem not to be familiar with the scientific style of writing and thus are probably not able to write an interesting paper. Then I read the abstract. I expect to get to know what the paper is about. Then I look at images / tables (depending on the subject) I read the conclusion / last part I read the end of the introduction where it often says \"the paper is structured as follows\" I guess many researchers filter like this. This is important to know when you write a paper. Recently, I've also got to know shortscience.org . It's a website where anybody can add summaries / remarks of papers. This is pretty awesome if you want to get the paper in context (especially of work which was released after the paper) or if you just want to see what the key idea behind a paper is. See also Tools for Academia trendingarxiv","tags":"Science","title":"How to find new Papers"},{"url":"https://martin-thoma.com/openbci/","text":"I've just discovered the OpenBCI: Biosensing for Everybody Kickstarter project. BCI is short for Brain Computer Interface. This Kickstarter is about an EEG device. Such a device looks like a helmet. It has several electrodes which you place on your scalp. Those electrodes measure \"voltage fluctuations resulting from ionic current within the neurons of the brain\" (source: Wikpedia ). I'm really curious about this, because I recently had some thoughts that medicine is currently not working as I want it to be. Doctors rely on the information they get by their patients, and they shouldn't. Patients can either directly lie or say something which is not try by accident. Instead of taking this feedback from patients, decisions should more often rely on hard data. For locked-in people, that means people who have sever difficulties to communicate with the outside world, it would be awesome if we could use BCIs to help them. I know this is far in the future, but you have to start at some point. Another use I would really be curious is some kind of \"automatic interrogation\". Think of terrorists / criminals who got caught, but are not willing to give the police necessary information. I think we should have the possibility to extract this kind of information from them, without hurting them. This idea was mentioned in one of the books of Daniel Suarez ; I think it was Daemon . The last nice application of BCIs would be REALLY convenient ways to interact with computers. Again, this is something really far in the future, but an awesome idea â˜º The Perks Ganglion It is an EEG board. Whatever that means: The OpenBCI Ganglion is a high-quality, affordable bio-sensing device. On the input side, there are 4 high-impedance differential inputs, a driven ground (DRL), a positive voltage supply (Vdd), and a negative voltage supply (Vss). The inputs can be used as individual differential inputs for measuring EMG or ECG, or they can be individually connected to a reference electrode for measuring EEG. Ultracortex Mark IV The Ultracortex Mark IV is an EEG headset. The Ultracortex Mark III is the latest working version of the OpenBCI headset. You can find all of the 3D files. links to hardware, and an assembly on our Github repo. We designed it for maximum adjustability and ease of use. In our design thinking, we prioritized the use of dry electrodes (pictured in the images above). Using dry sensors significantly reduces the time needed for setup (no more sticky paste!) and makes the overall experience of wearing the headset much more pleasant. There are three options: Print-It-Yourself ($350): this reward comes with all of the pieces required to assemble a full Ultracortex Mark IV aside from the pieces you can print yourself with a desktop 3D-printer, in addition to an OpenBCI Ganglion Board. This kit is perfect for backers who have their own 3D-printer. Unassembled ($450): this reward comes with all of the pieces required to assemble a full Ultracortex Mark IV headset, including the pieces that are 3D-printable, and an OpenBCI Ganglion Board. Fully Assembled ($650): if you select this reward, you will receive a fully- assembled Ultracortex Mark IV with an OpenBCI Ganglion Board. It will arrive ready to plug in and fire up! What I would expect from it to be able to differentiate at least five different kinds of signals which I can willently make. Why five? Up Down Right (Yes) Left (No) Enter With those, you can make a virtual keyboard which is usable. Of course, you can also do so with two actions (next, enter), but that is MUCH more of a pain. The more different signals you can distinguish, the better. I also expect it to be able to see when I feel pain or when I sleep. Specs Currently, there are basically no specs available (see comments ). Some comments seem to suggest that there are only 16 electrodes in use. Then they speak about a 10-20 and a 10-10 system. I have no idea what that means. The People behind it The project is done by Joel Murphy and Conor Russomanno . They seem to have made a similar Kickstarter called \"Spiderclaw\", but I could only find the GitHub repository . They also said they are affiliated with Pulse Sensor In a video, Paul Sajda (PhD, Professor of Biomedical Engineering and Radiology at Columbia University, source ) says it is a \"high quality recording system\". Ashley E. Stewart (CSO of Neuromore , see also brainbodyperformance.com ) Aaron Trocola (Industrial Designer at Threeform ) seems to be the person who designs the 3D printed parts. David Putrino, Department of Rehabilitation Medicine Weill Cornell Medical College ( source ) also said a couple of positive words about it. Conclusion By now, this project does not give me the impression that it is ready-to-use. I am still waiting for some feedback, but I guess I will rather wait for other (independant) people writing reviews about it. Preverably mentioning it in scientific papers which get published in notable journals or cited by enough other people. Articles I couldn't find any articles about OpenBCI on scholar.google.com , except for the following: Chip Audette , \"Mind Control\", IEEE Spectrum. October 2015. DOI 10.1109/MSPEC.2015.7274184 . Also: eeghacker.blogspot.de Links 32c3: Evolution of Brain-Computer Interfaces on YouTube. 28 December 2015. openbci.com openbci.pl seems to be something different? But it has a publication User-centered design of brain-computer interfaces: OpenBCI.pl and BCI Appliance github.com/OpenBCI/Ultracortex : Instructions how to assemble the Utracortex Mark 1 - Mark 3","tags":"Cyberculture","title":"OpenBCI"},{"url":"https://martin-thoma.com/terror-in-paris/","text":"Recently, a huge terrorist attack happened in France (see Wikipedia ). At least 129 people died and 352 people were injured. The attack happened on the evening of 13 November 2015. 6 mass shootings and 3 suicide bombings happened. What happened and the reactions I've seen so far make this the European / French equivalent of September 11 attacks . A lot of people died or were injured, one of the most important cities were affected, politicians say we are in war, on Facebook people show condolence. Questions we need to ask The Terrorists : Who were the terrorists? What was their story? How did they become terrorists? The Weapons : Where did they get the weapons from? Can we prevent that? Fast reactions : How could the police react that fast? Future : How do we want to deal with such attacks? The Terrorists ISIS claims they were responsible for the attacks. We could stop to think here and many certainly will. It is a terrorist organization and that is what terrorists do. The people were religiously motivated lunatics, so we don't need to understand them. Right? Wrong. People are complicated. They don't always act consistently. Their environment is critical to form who they are. If you grew up in an environment where you didn't have reliable access to clean water, food, medical services, education, work, and a perspective on a good live in general, you would certainly be somebody else. Don't get me wrong here. I don't want to talk it little. Everybody has a choice what he can do in his live. What terrorists do is cruel. But just like after September 11, I am pretty sure we (France, Germany, Europe) will spend a lot of time and money in reaction to the attacks. One reaction we will certainly get is demands for more spendings / actions in military and surveillance. Demands for closing borders. What I want to say is that we are trying to intervene in a too late step of the \"terror process\". People are not born terrorists. They become terrorists during their lives. We should not prevent terrorists from entering our countries, from blowing up what is important for us. We should prevent people from becoming terrorists. Now you might say that is easier said than done. But a very first step would be getting a detailed view of the terrorists lives. I don't mean the preparation, but their complete live. Their environment. And then change that. My assumption is that we could completely prevent generations of terrorists from being born when we \"simply\" make the world better. Weapons According to the Paris prosecutor, the attackers wearing suicide vests used TATP as an explosive. This is easy to make from things of everyday live. So we can't prevent it from being made and used by suicide bombers, except if we massively sacrifice privacy. I'm talking here about cameras in your bedroom kind of surveillance. \"Only\" the US way of surveillance will not change anything. However, I've also read that the terrorists used AK-47 rifles . They cannot be build by yourself, so we should find out where they came from. One only the concrete path, but in general. Fast Reactions It is less than two days after the attacks, and we already know which type of explosive the bombing vests were made of, some people were put into arrest, and we are sure that ISIS is responsible. This is astonishing. It feels as if the police was doing an extraordinary good job here. I wonder if it would be that fast outside of Paris. At the same time, it feels too fast. When we get news that fast, we (unconciously) will expect such fast reactions with other attacks. This might not be possible and people might - too fast - ask for political changes. I just want to point out that such fast reactions and the quick, not very well investigated articles we get today (like this one... but I'm not a journalist) are not always good for us. Possible actions I see three ways we, as a society, can react to terrorist attacks in general: No reaction Surveillance and military Development aid No reaction I was positively surprised how the people from Norway reacted to the 2011 Norway attacks . They didn't start new surveillance programs. They didn't increase their military spendings. The Norwegians showed they are strong. They showed the world that they are united. They showed that they will not let terrorist attacks change the way they live their lives. Surveillance and military When something happens, people want politicians to show they improve the situation. They want revenge. They want others to share their pain. They feel insecure and want to feel strong and secure again. This is a reason why spending more money in surveillance and military is a very understandable, logical reaction. But be clear what you're doing when you ask for more spendings in military and surveillance. Be clear what you sacrifice when you want to expand the power of intelligence services. Think about how you let terrorists change your live. Which other dangers you might put your society into. I am a strong opponent of surveillance and also (not that much, but still) an opponent of military. One reason is that we are playing a stupid game (see A Waste of Money and Time , a security expert). We see what terrorists did, like an attack with airplanes, and we as a society spend lots and lots of effort to prevent that. We accept being treated like criminals, hundred thousands of passengers, just to get a slight chance to catch a terrorist. The terrorists know that, so they can take the train and do exactly the same. We pick our defenses and they do something different. I don't want to play such a stupid game. One way around is intelligence. But the bad thing is, that it doesn't make sense to use a little bit of intelligence. You have to go the full, Orwellian way to have a good chance of it being effective. Here is what I could think of: Make money flows transparent: Don't use cash any more. Only digital money which gets tracked by government agencies. Track who buys what in which quantities. Make shops, no matter how small, connect the transactions with goods you bought. This has to include everything, as you can use quite a lot of different things to build bombs. Track everybody: With smartphones you can make detailed movement profiles. Even if you're not on Facebook, you can build a social graph. Who talked to whom, who has how much contact to whom. Who is influential, who isn't. Get rid of privacy: We have surveillance equipment everywhere. Private smartphones, tablets, laptops usually have cameras and microphones. Most people use these devices to communicate. These devices, combined with traffic cameras, private shop / bank cameras give pretty detailed images of what is going on. An automatic computer system like Microsoft's Domain Awareness System could constantly take this information and react within seconds. But we have to be aware of what we sacrifice when we are doing it. The surveillance systems can be hacked. They can be misused. The automatic algorithms can - just like humans - make mistakes. Imagine the world we would live in if the Gestapo or the Stasi had access to this kind of technology. Imagine how people would act differently when they know everything they did was recorded and could be hold against them later. On the positive side: This could decrease \"normal\" crime, too. Development aid Just as I began to write before, I would prefer if we spend more money on development aid. I am pretty sure there are many (potential) terrorists, which would not even consider that if they were in a better situation. We could massively improve the situation of the live of millions of people. Even if it would not work against terrorism, we would still do something inherently good. We would help the people. If we honestly want to improve their situation, if we don't use military but humanitarian aid, people will recognize this. People will have something good in their minds when they thought of us (see \"Brot statt Bomben\" ). A positive side-effect would be that it would stop coming more refugees to Europe. Of course, just throwing money at the problem will not solve anything. We need to check if the money actually gets to the people. We need to check if it improves their lives. We need them to get in a situation where they are able to choose what to do with their lives. Not from equally bad situations, but giving people the possibility to make their live become good. We need to understand the problems of those countries. We have to work with the people there, not work for them. We have to support, not to lead. There are certainly a lot of organizations like Engineers Without Borders and Doctors Without Borders which have a very good idea what has to be done in a short-term perspective to improve the lives of many people. However, we should plan for a long-term perspective. We should get in contact with refugees who are willing to get back if the situation was better and try to figure out what they need to improve the situation. And we should finally stand to our word and reach the Millennium Development Goals I can't find the source, but the costs for reaching the MDGs were lower than I expected. Especially access to clean water significantly lower than 20 Billion US-Dollar, if I remember it correctly. The GDP of Europe is about 18,527,116 Million US-Dollar. That means we would have to spend about 0.1 % of our GDP for this goal. Now think of the money that was spend in the European debt crisis . It is hard to put numbers on here, but it was much more than 18 Billion US-Dollar. Hypocracy A fellow student recently pointed out that there were also 2015 Beirut bombings . I didn't even see that in the news. A lot of people die preventable deaths due to the lack of access to clean water, sanitation and food. And we don't even talk about the MDGs. Not really. Some final words One main point of this mini-article is that I am pretty sure people will react to fast. No matter what we do, we should think about it thoroughly. This article is - like hundreds of blog articles, quite a bit of \"professional\" journalist articles and surely some statements by politicians - not well investigated. It is only a quick, spontaneous reaction. The other important point is that we have alternatives to more military and surveillance spendings. We should really think about that. We should talk about it and evaluate it. Finally, it the question is: In which kind of society do we want to live? Edit: The reaction Now it seems to be clear how most politicians react: Frankreichs Premier Valls: IS greift auch andere europÃ¤ische LÃ¤nder an FranzÃ¶sisches MilitÃ¤r bombardiert IS-Stellungen in Syrien SicherheitsmaÃŸnahmen in Deutschland deutlich verschÃ¤rft See also Du bist Terrorist : A clip by a German satire show. Recent French military actions: 2011 military intervention in Libya French forces in Afghanistan Northern Mali conflict War on Terror Euractiv (German) Terror in Paris: Hollande spricht von \"Kriegsakt des IS\" Anschlagserie in Paris: Hollande verhÃ¤ngt Ausnahmezustand fÃ¼r ganz Frankreich Terror in Paris: AttentÃ¤ter nennen als Grund Frankreichs Syrien-Politik","tags":"My Bits and Bytes","title":"Terror in Paris"},{"url":"https://martin-thoma.com/tensor-flow-quick/","text":"Tensor Flow is a machine learning toolkit which recently got published by Google. They published it under Apache License 2.0 . Looking at the source code overview, it seems to be mainly C++ with a significant bit of Python. I guess the abstract of the Whitepaper is a good description what TensorFlow is: TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org. The core seems to be written in C++, but it has a Python front end. By now, I couldn't test much because I just made my GPU machine unusable (while trying to get the GPU General Computing practical software to run...). I'll try to expand this article as soon as possible, but I guess it might take several weeks until I have enough time. Lets see... Installation The documentation about the installation makes a VERY good impression. Better than anything I can write in a few minutes, so ... RTFM ðŸ˜œ For Linux systems with CUDA and without root privileges, you can install it with: $ pip install https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl --user But remember you have to set the environment variable LD_LIBRARY_PATH and CUDA_HOME . For many configurations, adding the following lines to your .bashrc will work: export LD_LIBRARY_PATH = \" $LD_LIBRARY_PATH :/usr/local/cuda/lib64\" export CUDA_HOME = /usr/local/cuda MNIST The following code can be used to check if your Tensor Flow installation is working. You have to have the get_mnist_data_tf.py in the same directory as the following script. I've - more or less - directly copied it from the tutorial . Just execute the script below and see if it finishes without throwing errors. #!/usr/bin/env python from get_mnist_data_tf import read_data_sets mnist = read_data_sets ( \"MNIST_data/\" , one_hot = True ) import tensorflow as tf sess = tf . InteractiveSession () x = tf . placeholder ( \"float\" , shape = [ None , 784 ]) y_ = tf . placeholder ( \"float\" , shape = [ None , 10 ]) W = tf . Variable ( tf . zeros ([ 784 , 10 ])) b = tf . Variable ( tf . zeros ([ 10 ])) sess . run ( tf . initialize_all_variables ()) y = tf . nn . softmax ( tf . matmul ( x , W ) + b ) cross_entropy = - tf . reduce_sum ( y_ * tf . log ( y )) train_step = tf . train . GradientDescentOptimizer ( 0.01 ) . minimize ( cross_entropy ) for i in range ( 1000 ): batch = mnist . train . next_batch ( 50 ) train_step . run ( feed_dict = { x : batch [ 0 ], y_ : batch [ 1 ]}) correct_prediction = tf . equal ( tf . argmax ( y , 1 ), tf . argmax ( y_ , 1 )) accuracy = tf . reduce_mean ( tf . cast ( correct_prediction , \"float\" )) print ( accuracy . eval ( feed_dict = { x : mnist . test . images , y_ : mnist . test . labels })) def weight_variable ( shape ): initial = tf . truncated_normal ( shape , stddev = 0.1 ) return tf . Variable ( initial ) def bias_variable ( shape ): initial = tf . constant ( 0.1 , shape = shape ) return tf . Variable ( initial ) def conv2d ( x , W ): return tf . nn . conv2d ( x , W , strides = [ 1 , 1 , 1 , 1 ], padding = 'SAME' ) def max_pool_2x2 ( x ): return tf . nn . max_pool ( x , ksize = [ 1 , 2 , 2 , 1 ], strides = [ 1 , 2 , 2 , 1 ], padding = 'SAME' ) W_conv1 = weight_variable ([ 5 , 5 , 1 , 32 ]) b_conv1 = bias_variable ([ 32 ]) x_image = tf . reshape ( x , [ - 1 , 28 , 28 , 1 ]) h_conv1 = tf . nn . relu ( conv2d ( x_image , W_conv1 ) + b_conv1 ) h_pool1 = max_pool_2x2 ( h_conv1 ) W_conv2 = weight_variable ([ 5 , 5 , 32 , 64 ]) b_conv2 = bias_variable ([ 64 ]) h_conv2 = tf . nn . relu ( conv2d ( h_pool1 , W_conv2 ) + b_conv2 ) h_pool2 = max_pool_2x2 ( h_conv2 ) W_fc1 = weight_variable ([ 7 * 7 * 64 , 1024 ]) b_fc1 = bias_variable ([ 1024 ]) h_pool2_flat = tf . reshape ( h_pool2 , [ - 1 , 7 * 7 * 64 ]) h_fc1 = tf . nn . relu ( tf . matmul ( h_pool2_flat , W_fc1 ) + b_fc1 ) keep_prob = tf . placeholder ( \"float\" ) h_fc1_drop = tf . nn . dropout ( h_fc1 , keep_prob ) W_fc2 = weight_variable ([ 1024 , 10 ]) b_fc2 = bias_variable ([ 10 ]) y_conv = tf . nn . softmax ( tf . matmul ( h_fc1_drop , W_fc2 ) + b_fc2 ) cross_entropy = - tf . reduce_sum ( y_ * tf . log ( y_conv )) train_step = tf . train . AdamOptimizer ( 1e-4 ) . minimize ( cross_entropy ) correct_prediction = tf . equal ( tf . argmax ( y_conv , 1 ), tf . argmax ( y_ , 1 )) accuracy = tf . reduce_mean ( tf . cast ( correct_prediction , \"float\" )) sess . run ( tf . initialize_all_variables ()) for i in range ( 1000 ): batch = mnist . train . next_batch ( 50 ) if i % 100 == 0 : train_accuracy = accuracy . eval ( feed_dict = { x : batch [ 0 ], y_ : batch [ 1 ], keep_prob : 1.0 }) print ( \"step %d , training accuracy %g \" % ( i , train_accuracy )) train_step . run ( feed_dict = { x : batch [ 0 ], y_ : batch [ 1 ], keep_prob : 0.5 }) print ( \"test accuracy %g \" % accuracy . eval ( feed_dict = { x : mnist . test . images , y_ : mnist . test . labels , keep_prob : 1.0 })) Observations While looking at the MNIST example, I made a couple of observations. Let's begin with the nice parts: Tensor Flow has a usable documentation (e.g. The neural network part ). Not great, as Lasagne where you have lots of details (e.g. activation functions ) Seems to be quite easy to use. Seems to be well-tested by simply being used in many different projects by Google. Just like Theano (and thus Lasagne), Tensor flow has automatic differenciation. Not sure: How easy is it to share trained models? In which format would you do so? How easy is it to understand a shared model? How easy is it to get something new to Tensor Flow like recurrent layers? (Actually, this seems rather to show that either the Whitepaper is a bit misleading or the documentation / Google search is not that good. In the whitepaper they write something about LTSM models, but I couldn't find any docs about that. Only by manually going through the manual, I found it ) Not so nice: Doesn't work with Python 3. They don't follow PEP8 . I know that there is a Python style guide by Google , but it does not seem to follow that one either. See the next section for some more detailed feedback. Just like the other Toolkits, you need CUDA. It doesn't work with OpenCL. PEP8 Whitespace W = tf.Variable(tf.zeros([784, 10])) should be W = tf.Variable(tf.zeros([784, 10])) . Missing whitespaces happened quite often. Indent with 2 spaces instead of 4 spaces. The Google guide seems also to use 4. Newlines between functions are missing. Print statement instead of a print function was used &rightarrow; only Python 2, not Python 3. I'm not sure why y_ has the trailing underscore. According to PEP8 , a single trailing underscore is used by convention to avoid conflicts with Python keyword. A mixture of different styles as pointed out on Credric's Blog Videos Starting at 21m 2s: Alternatives / Similar software As I don't really know by now what Tensor Flow is doing, I can't pin-point alternatives. But I have some educated guesses: Theano has been around for quite a while and seems to have a similar approach with its computational graph. Enhanced by Lasagne , it is a pretty good alternative when it comes to neural networks. Lasagne has an exceptionally good documentation, but parts of the tutorial could still be improved. Caffe was something I recently tried. I didn't like it too much due to the lack of documentation, but it certainly is a big project. Especially when it comes to images. I haven't tried, but they look promising: Chainer MXNet CGT Torch has a very nice example for a character predictor . See also Official Website github.com/tensorflow TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems news.ycombinator.com reddit.com/r/programming","tags":"Machine Learning","title":"Tensor Flow - A quick impression"},{"url":"https://martin-thoma.com/machine-learning-1-course/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žMachine Learning 1\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr. ZÃ¶llner im Wintersemester 2014/2015 gehÃ¶rt. Es gibt auch einen Artikel Ã¼ber Machine Learning 2 . Folien Einordnungskriterien Slide name: ML-Einordnungskriterien.pdf Algorithmus Inferenztyp Lernebene Lernvorgang Beispielgebung Beispielumfang Hintergrundwissen ind. ded. symb. subsymb. Ã¼berwacht unÃ¼b. inkr. nicht inkr. gering groÃŸ emp. axio. $k$ -NN x x x x x x SVMs x x x x x x Decision Trees ID3 x x x x x x ID5R x x x x x x NN klassisch x x x x x x Auto-Encoder x x x x x x Bayessche Netze x x x x x x HMMs x x x x x x Version-Space Algorithmus x x x x x x Specific-to-General Konzeptlernen ? ? x ? ? ? ? ? ? ? ? k-means clustering x x x x x x AHC x x x x x x COBWEB x x x x x x CBR x x x x x x EBG x x x x x x EinfÃ¼hrung Slide name: MLI_01_Einfuehrung_slides1.pdf Was ist Intelligenz? (ProblemlÃ¶sen, Erinnern, Sprache, KreativitÃ¤t, Bewusstsein, Ãœberleben in komplexen Welten, ) WissensreprÃ¤sentation: Assoziierte Paare (Eingangs- und Ausgangsvariablen) EntscheidungsbÃ¤ume (Klassen diskriminieren) Parameter in algebraischen ausdrÃ¼cken Formale Grammatiken Logikbasierte AusdrÃ¼cke Taxonomien Semantische Netze Markov-Ketten Machine Learning von Tom Mitchell A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E. Deduktion Die Deduktion ist eine Schlussfolgerung von gegebenen PrÃ¤missen auf die logisch zwingenden Konsequenzen. Deduktion ist schon bei Aristoteles als â€žSchluss vom Allgemeinen auf das Besondere\" verstanden worden. Modus ponens Der Modus ponens ist eine Art des logischen SchlieÃŸens. Er besagt: Wenn die PrÃ¤missen $A \\rightarrow B$ und $A$ gelten, dann gilt auch $B$. Abduktion by Peirce Deduction proves that something must be; Induction shows that something actually is operative; Abduction merely suggests that something may be. Induktives Lernen Slide name: MLI_02_InduktivesLernen_slides1.pdf Version Space Der Raum aller Hypotesen, welche mit den Trainingsbeispielen konsistent sind. Version Space Algorithmus Der Version Space Algorithmus ist ein binÃ¤rer Klassifikator fÃ¼r diskrete Feature-Spaces. Er startet mit der generellsten Hypothese $G = (?, \\dots, ?)$ - alles ist wahr - und der speziellsten Hypothese $S = (\\#, \\dots, \\#)$ - nichts ist wahr. Wenn ein Beispiel mit dem Label true gesehen wird, dann wird die speziellste Hypothese angepasst und veralgemeinert. Wenn ein Beispiel mit dem Label false gesehen wird, wird die generellste Hypothese spezialisiert. So kann man den Raum aller mit den Trainingsdaten konsistenten Hypothesen finden. Konzept Ein Konzept beschreibt eine Untermenge von Objekten oder Ereignissen definiert auf einer grÃ¶ÃŸerer Menge. Konsistenz Keine negativen Beispiele werden positiv klassifiziert. VollstÃ¤ndigkeit Alle positiven Beispiele werden als positiv klassifiziert. Algorithmen: BÃ¤ume (WÃ¤lder?) Suche vom Allgemeinen zum Speziellen: Negative Beispiele fÃ¼hren zur Spezialisierung Suche vom Speziellen zum Allgemeinen: Positive Beispiele fÃ¼hren zur Verallgemeinerung Version Space : Beides gleichzeitig anwenden PrÃ¤zendenzgraphen: In welcher Reihenfolge werden Aktionen ausgefÃ¼hrt? Version Space Algorithmus ist: Induktiver Inferenztyp Symbolische Ebene des Lernens Ãœberwachtes Lernen Inkrementelle Beispielgebung Umfangreich (viele Beispiele) Empirisches Hintergrundwissen Voraussetzungen: Konsistente Beispiele, korrekte Hypothese im Hypothesenraum Positive Aspekte: Es ist feststellbar, welche Art von Beispielen noch nÃ¶tig ist Es ist feststellbar, wann das Lernen abgeschlossen ist Weiteres Inductive bias Induktives Lernen benÃ¶tigt Vorannahmen. Bias (\"Vorzugskriterium\") Vorschrift, nach der Hypothese gebildet werden. Reinforcement Learning Slide name: MLI_03_ReinforcementLearning_slides1.pdf Siehe auch: Probabilistische Planung Neuronale Netze Machine Learning 2 Cat vs. Mouse code Berkeley CS188 Intro to AI: Project 3: Reinforcement Learning Dan Klein, Pieter Abbeel: Lecture 10: Reinforcement Learning on YouTube. University of California, Berkeley. This expalins TD-learning. What is the Q function and what is the V function in reinforcement learning? Demystifying Deep Reinforcement Learning Markovsches Entscheidungsproblem ( Markov Decision Process , MDP ) Ein Markovsches Entscheidungsproblem ist ein 5-Tupel $(S, A, P, R, p_0)$, wobei $S$ eine endliche Zustandsmenge (states), $A(s)$ eine Menge von mÃ¶glichen Aktionen im Zustand $s$, $P(s, s', a) = P(s_{t+1} = s' | s_t = s, a_t = a)$: Die Wahrscheinlichkeit im Zeitschritt $t+1$ im Zustand $s'$ zu sein, wenn man zum Zeitpunkt $t$ im Zustand $s$ ist und die Aktion $a$ ausfÃ¼hrt $R(s, s', a) \\in \\mathbb{R}$: Die direkte Belohnung, wenn durch die Aktion $a$ vom Zustand $s$ in den Zustand $s'$ gekommen ist. $p_0$ ist die Startverteilung auf die ZustÃ¤nde $S$ Manchmal wird auch der Diskontierungsfaktor $\\gamma \\in [0, 1]$, welche die Bedeutung von direkten Belohnungen im Vergleich zu kÃ¼nftigen Belohnungen anzeigt, hier schon genannt. Allerdings finde ich das an dieser Stelle eher unpassend, da $\\gamma$ eher verwendet wird um die LÃ¶sung in der Praxis bestimmen zu kÃ¶nnen. Mit dem Problem hat $\\gamma$ an sich nichts zu tun. Reinforcement Learning ( RL , BestÃ¤rkendes Lernen ) Beim bestÃ¤rkenden Lernen liegt ein Markow-Entscheidungsproblemen vor. Es gibt also einen Agenten, der Aktionen ausfÃ¼hren kann. Diese kÃ¶nnen (nicht notwendigerweise sofort) bewertet werden. Policy ( Strategie ) Siehe Probabilistische Planung . Policy Learning Unter Policy Learning versteht man die Suche nach einer optimalen Strategie $\\pi&#94;*$. V-Funktion ( Value function , State-Value function ) Die Funktion $V&#94;\\pi: S \\rightarrow \\mathbb{R}$ heiÃŸt Value-Funktion. Sie gibt den erwarteten Wert (nicht die Belohnung, da bei der V-Funktion noch der Diskontierungsfaktor eingeht!) eines Zustands $s$ unter der Strategie $\\pi$ an. Mit $V&#94;*$ wird der Wert unter der optimalen Strategie bezeichnet. Q-Funktion ( Action-Value function , Quality function ) Siehe Probabilistische Planung . Eligibility Traces Siehe Probabilistische Planung . Beispiel fÃ¼r RL: Roboter muss zu einem Ziel navigieren Algorithmen: Simple Value Iteration Simple Value Iteration estimates the value function by updating it as long as necessary to converge: $$\\hat{V}&#94;*(s_t) \\leftarrow r_t + \\gamma \\hat{V}&#94;*(s_{t+1})$$ \"Simple\" means that the transition function is deterministic. It is explained in Sebastian Thrun: Unit 9 17 Value Iteration 1 on YouTube. Sebastian Thrun: Unit 9 17 Value Iteration 2 on YouTube. Sebastian Thrun: Unit 9 17 Value Iteration 3 on YouTube. Simple Temporal Difference Learning Simple Temporal Difference Learning is just like Simple Value Iteration, but now the Value function is updated with a learning rate $\\alpha$: $$\\hat{V}&#94;*(s_t) \\leftarrow (1-\\alpha) \\cdot \\hat{V}&#94;*(s_t) + \\alpha(r_t + \\gamma \\hat{V}&#94;*(s_{t+1}))$$ Mehr dazu im nÃ¤chsten Abschnitt . Q-Learning Siehe Probabilistische Planung . SARSA ( State-Action-Reward-State-Action ) Siehe Probabilistische Planung . SARSA($\\lambda$) Siehe Probabilistische Planung . TD-Learning R. Sutton und A. Barto: Temporal-Difference Learning . 1998. Der TD-Learning Algorithmus beschÃ¤ftigt sich mit dem SchÃ¤tzen der Value-Funktion \\(V&#94;\\pi\\) fÃ¼r eine gegebene Strategie \\(\\pi\\) . Das wird auch policy evaluation oder prediction genannt. TD-Learning (Temporal Difference Learning) Siehe auch OptimalitÃ¤tsprinzip von Bellman Guest Post (Part I): Demystifying Deep Reinforcement Learning Lerntheorie Slide name: MLI_04_Lerntheorie_slides1.pdf Ockhams Rasiermesser (Quelle: Wikipedia ) Von mehreren mÃ¶glichen ErklÃ¤rungen fÃ¼r ein und denselben Sachverhalt ist die einfachste Theorie allen anderen vorzuziehen. Eine Theorie ist einfach, wenn sie mÃ¶glichst wenige Variablen und Hypothesen enthÃ¤lt, und wenn diese in klaren logischen Beziehungen zueinander stehen, aus denen der zu erklÃ¤rende Sachverhalt logisch folgt. Overfitting Zu starke Anpassung des Klassifizierers an die Lerndaten; geringe GeneralisierungsfÃ¤hgikeit Structural Risc Minimization ( SRM ) Unter Structural risk minimization versteht man die AbwÃ¤gung zwischen einem einfachen Modell und einem komplexen Modell, welches auf den Trainingsdaten besser funktioniert aber eventuell mehr unter Overfitting leidet. Vapnik-Chervonenkis Dimension ( VC-Dimension ) Die VC -Dimension $VC(H, X) \\in \\mathbb{N} \\cup \\infty$ eines Hypothesenraumes $H$ ist gleich der maximalen Anzahl an Datenpunkten aus $X$, die von $H$ beliebig in zwei Mengen gespalten werden kÃ¶nnen. Dabei muss es nur eine Teilmenge $X' \\subseteq X $ der GrÃ¶ÃŸe $n$ geben, damit $VC(H, X) \\geq n$ gilt. Falls beliebige Teilmengen von $X$ durch $H$ separiert werden kÃ¶nnen, so gilt $VC(H, X) = \\infty$. Praktisch gesehen ist $X$, die Menge aller mÃ¶glichen Features, sowie $H$, die Menge aller mÃ¶glichen Trennlinien im Feature-Space, vorgegeben. Die Frage ist ob man eine Teilmenge $X' \\subseteq X$ findet mit $|X'| = n$, sodass man fÃ¼r $X'$ jede MÃ¶gliche Teilung in zwei Mengen durch $H$ realisieren kann. Probably approximately correct learning ( PAC ) PAC macht eine Aussage Ã¼ber die Anzahl der benÃ¶tigten Stichproben, wenn man einen bestimmten realen Fehler mit einer frei zu wÃ¤hlenden Wahrscheinlichkeit bekommen will. Lernmaschine wird definiert durch Hypothesenraum \\(\\{h_\\alpha: \\alpha \\in A\\}\\) und Lernverfahren. Das Lernverfahren ist die Methode um \\(\\alpha_{\\text{opt}}\\) mit Hilfe von Lernbeispielen zu finden. Probleme beim Lernen: GrÃ¶ÃŸe des Hypothesenraums im Vergleich zur Anzahl der Trainingsdaten. Das Verfahren kÃ¶nnte nur suboptimale LÃ¶sungen finden. Das Verfahren kÃ¶nnte die passende Hypothese nicht beinhalten. Lernproblemtypen: Sei die Menge der Lernbeispiele in \\(X \\times Y\\) , mit \\(X \\times Y =\\) ... \\(\\{Attribut_1, Attribut_2, ...\\} \\times \\{True, False\\}\\) : Konzeptlernen \\(\\mathbb{R}&#94;n \\times \\{Klasse_1, ..., Klasse_n\\}\\) : Klassifikation \\(\\mathbb{R}&#94;n \\times \\mathbb{R}\\) : Regression Gradientenabstieg, Overfitting Kreuzvalidierung PAC Folie 35: Was ist eine Instanz der LÃ¤nge \\(n\\) ? Eine Hypothese mit \\(n\\) Literalen. Boosting Boosting Kombiniere mehrere schwache Modelle um ein gutes zu bekommen, indem Trainingsbeispiele unterschiedlich gewichtet werden. Bagging ( Bootstrap aggregating ) Kombiniere mehrere schwache Modelle um ein gutes zu bekommen. Dabei bekommt jedes schwache Modell nur eine Teilmenge aller Trainingsdaten. AdaBoost ( Adaptive Boosting ; see YouTube ) Learn a classifier for data. Get examples where the classifier got it wrong. Train new classifier on the wrong ones. Folie 22: WofÃ¼r steht \\(i\\) und welchen Wertebereich hat \\(i\\) ? â†’ \\(i\\) ist eine ZÃ¤hlvariable, welche die Trainingsdaten durchnummeriert. Stellt \\(W_k(i)\\) die Wahrscheinlichkeit dar, dass Beispiel \\(i\\) im \\(k\\) -ten Durchlauf fÃ¼r das Training verwendet wird? â†’ Nein. \\(W_k(i)\\) ist das Gewicht des \\(i\\) -ten Trainingsbeispiels fÃ¼r den \\(k\\) -ten klassifikator. Siehe Folie 24 und folgende fÃ¼r ein Beispiel. Siehe auch: Alexander Ihler: AdaBoost . Ensemble Learning Techniques: Boosting, Bagging, Random Subspaces, Pasting, Random Patches Weiteres: Stacking A committee learner, usually OLS or LASSO Bagging/Bragging Learnier is fit, results are mean/median aggregated with the aim of reduction variance Boosting Build chain of learners. VC-Dimension VC-Dimension , siehe YouTube und [ Mit97 ] Sei $H&#94;\\alpha = \\{h_\\alpha : \\alpha \\in A\\}$ der Hypothesenraum. Die VC-Dimension $VC(h_\\alpha)$ von $H&#94;\\alpha$ ist gleich der maximalen Anzahl von beliebig platzierten Datenpunkten, die von $H&#94;\\alpha$ separiert werden kÃ¶nnen. Folie 44: \\(\\eta \\in [0, 1]\\) ist ein Parameter, der beliebig gewÃ¤hlt werden kann. Siehe Info-Box AbschÃ¤tzung des realen Fehlers . Neuronale Netze Slide name: MLI_05_Neuronale_Netze_slides1.pdf Einsatzfelder: Klassifiktion: Spracherkennung, Schrifterkennung Funktionsapproximation MustervervollstÃ¤ndigung: Kodierung, Bilderkennung (NODO: Warum zÃ¤hlt das nicht zu Klassifikation?) Perzeptron von Rosenblatt (1960) Auswertung: Input-Vektor und Bias mit Gewichten multiplizieren, addieren und Aktivierungsfunktion anwenden. Training: ZufÃ¤llige Initialisierung des Gewichtsvektors, addieren von fehlklassifizierten Vektoren auf Gewichtsvektor. Gradientenabstieg Software: Lasagne : Python, hat eine exzellente Dokumentation, die auch grÃ¶ÃŸtenteils auf explizit auf Literatur verweist und die Formeln hinter den Funktionen direkt angibt. Google TensorFlow Cascade Correlation (siehe Fahlman und Lebiere: The Cascade-Correlation Learning Architecture ) Cascade Correlation ist ein konstruktiver Algorithmus zum erzeugen von Feed-Forward Neuronalen Netzen. Diese haben eine andere Architektur als typische multilayer Perceptrons. Bei Netzen, welche durch Cascade Correlation aufgebaut werden, ist jede Hidden Unit mit den Input-Neuronen verbunden, mit den Output-Neuronen und mit allen Hidden Units in der Schicht zuvor. Siehe YouTube (4:05 min) und How exactly does adding a new unit work in Cascade Correlation? RPROP (siehe YouTube - 15:00min) Rprop ist eine Gewichtsupdate-Regel fÃ¼r neuronale Netze. Sie betrachtet nur das Vorzeichen des Gradienten, jedoch nicht den Betrag. Jedes Gewicht wird unabhÃ¤ngig von den anderen behandelt. Der Algorithmus hat Konstanten $\\eta&#94;- \\in \\mathbb{R}_{\\le 1}$ sowie $\\eta&#94;+ \\in \\mathbb{R}_{\\ge 1}$. FÃ¼r jedes Gewicht ist auÃŸerdem $\\eta=1$ zu Beginn. Bei jedem Gewichtsupdate wird Ã¼berprÃ¼ft, ob sich das Vorzeichen des Gradienten fÃ¼r dieses Gewicht geÃ¤ndert hat. Falls ja, wird das Gewicht um $\\eta \\cdot \\eta&#94;+$ bzw $\\eta \\cdot \\eta&#94;-$ geÃ¤ndert. AuÃŸerdem kann eine minimale bzw. eine Maximale Ã„nderung gesetzt werden. Delta-Regel , siehe neuronalesnetz.de Die Delta-Regel ist ein Lernalgorithmus fÃ¼r neuronale Netze mit nur einer Schicht. Sie ist ein Spezialfall des algemeineren Backpropagation-Algorithmus und lautet wie folgt: $$\\Delta w_{ji} = \\alpha (t_j - y_j) \\varphi'(h_j) x_i$$ wobei $\\Delta w_{ji} \\in \\mathbb{R}$ die Ã„nderung des Gewichts von Input $i$ zum Neuron $j$, $\\alpha \\in [0, 1]$ die Lernrate (typischerweise $\\alpha \\approx 0.1$), $t_j \\in \\mathbb{R}$ der Zielwert des Neurons $j$, $y_j \\in \\mathbb{R}$ die tatsÃ¤chliche Ausgabe, $\\varphi'$ die Ableitung der Aktivierungsfunktion des Neurons, $h_j \\in \\mathbb{R}$ die gewichtete Summe der Eingaben des Neurons und $x_i \\in \\mathbb{R}$ der $i$-te Input ist. Gradient-Descent Algorithmus Der Gradient-Descent Algorithmus ist ein Optimierungsalgorithmus fÃ¼r differenzierbare Funktionen. Er startet an einer zufÃ¤lligen Stelle $x_0$. Dann wird folgender Schritt mehrfach ausgefÃ¼hrt: $$x_0 \\gets x_0 - \\alpha \\cdot \\text(grad) f (x_0)$$ wobei $\\alpha \\in (0, 1]$ die Lernrate ist und $f$ die zu optimierende Funktion. Dabei kÃ¶nnte $\\alpha$ mit der Zeit auch kleiner gemacht werden. Backpropagation (siehe neuralnetworksanddeeplearning.com ) Der Backpropagation-Algorithmus ist eine Variante des Gradient-Descent Algorithmus, welche fÃ¼r MLPs angepasst wurde. Sie besteht aus drei Schritten: Forward-Pass : Lege die Input-Features an das Netz an und erhalte den Output Fehlerberechnung : Mache das fÃ¼r alle Daten Backward-Pass : Passe die Gewichte Im Grunde ist Backpropagation nur eine Geschwindigkeitsoptimierte Variante des Gradient-Descent Algorithmus, da die Gradienten im Backpropagation-Algorithmus auf geschickte Weise berechnet werden. Radiale Basisfunktion ( Radial Basis Function , RBF ) Eine radiale Basisfunktion ist eine Funktion $f: D \\rightarrow \\mathbb{R}$, fÃ¼r die $f(x) = f(\\|x\\|)$ gilt bzw. allgemeiner, fÃ¼r die ein $c \\in D$ existiert, sodass $f(x, c) = f(\\|x - c\\|)$ gilt. Der Wert der Funktion hÃ¤ngt also nur von der Distanz zum Ursprung bzw. allgemeiner zu einem Punkt $c \\in D$ ab. Ein typisches Beispiel sind gauÃŸsche RBFs: $f(x) = e&#94;{-(a (x - c)&#94;2)}$, wobei $a, c$ Konstanten sind. Radial-Basis Funktion Netz ( RBF-Netz ) Ein Radial-Basis Funktion Netz ist eine neuronales Netz, welches als Aktivierungsfunktionen RBFs verwendet. Dabei gibt es dann fÃ¼r jedes Neuron im Grunde zwei Parameter: Der Radius und das Zentrum (vgl. Folie 39 fÃ¼r die Gewichtsanpassung). Dynamic Decay Adjustment ( DDA ) DDA ist ein konstruktiver Lernalgorithmus fÃ¼r RBF-Netze welcher in [ Ber95 ] vorgestellt wird. Bei den Netzwerken, die DDA annimmt, gibt es sog. Prototypen . Das scheinen einfach Neuronen mit RBF-Aktivierungsfunktionen zu sein, welche fÃ¼r eine Klasse stehen. Zwei Schwellwerte, $\\theta&#94;+$ und $\\theta&#94;-$, werden eingefÃ¼hrt. Der Schwellwert $\\theta&#94;+$ muss beim Training eines Beispiels der Klasse $y_1$ von einem Neuron der Klasse $y_1$ Ã¼berschritten werden. Falls das nicht der Fall ist, wird ein neues Neuron hinzugefÃ¼gt. Der Schwellwert $\\theta&#94;-$ ist eine obere Grenze fÃ¼r die Aktivierung von Neuronen, die zu anderen Klassen gehÃ¶ren. Ist eine Aktivierung hÃ¶her, wird der Radius des zugehÃ¶rigen Neurons verringert. $\\theta&#94;+ = 0.4$ und $\\theta&#94;- = 0.2$ sind sinnvolle Werte. Laut einem PrÃ¼fungsprotokoll lernt DDA nach Vapnik korrekt. Siehe auch: The Dynamic Decay Adjustment Algorithm Siehe auch Neuronale Netze - Vorlesung What are prototypes in RBF networks? Instanzbasiertes Lernen Slide name: MLI_06_InstanzbasiertesLernen_slides1.pdf Instanzenbasiertes Lernen bzw. Lazy Learning Instanzenbasiertes Lernen ist ein Lernverfahren, welches einfach nur die Beispiele abspeichert, also faul (engl. lazy) ist. Soll der Lerner neue Daten klassifizieren, so wird die Klasse des Ã¤hnlichsten Datensatzes gewÃ¤hlt. Case-based Reasoning bzw. kurz CBR CBR ist ein allgemeines, abstraktes Framework und kein direkt anwendbarer Algorithmus. Die Idee ist, dass nach Ã¤hnlichen, bekannten FÃ¤llen gesucht wird, auf die der aktuelle Fall Ã¼bertragen werden kann. Fall im Kontext des CBR Ein Fall ist eine Abstraktion eines Ereignisses, die in Zeit und Raum begrenzt ist. Ein Fall enthÃ¤lt eine Problembeschreibung, eine LÃ¶sung und ein Ergebnis. ZusÃ¤tzlich kann ein Fall eine ErklÃ¤rung enthalten warum das Ergebnis auftrat, Informationen Ã¼ber die LÃ¶sungsmethode, Verweise auf andere FÃ¤lle oder GÃ¼teinformationen enthalten. Beispiel fÃ¼r Lazy Learning: \\(k\\) -NN , CBR NODO: Folie 3: â€žFleiÃŸige\" Lernalgorithmen mit dem gleichen Hypothesenraum sind eingeschrÃ¤nkter - was ist damit gemeint? Was sind fleiÃŸige Lernalgorithmen? Lernalgorithmen, welche den meisten Rechenaufwand beim Lernen investieren, wo aber das auswerten vergleichsweise billig ist? SVM Slide name: MLI_07_SVM_slides1.pdf Eine ErklÃ¤rung von SVMs findet sich im Artikel Using SVMs with sklearn . SVMs sind laut Vapnik die Lernmaschine mit der kleinsten mÃ¶glichen VC- Dimension, falls die Klassen linear trennbar sind. PrimÃ¤res Optimierungsproblem: Finde einen Sattelpunkt der Funktion \\(L_P = L(\\vec{w}, b, \\vec{\\alpha}) = \\frac{1}{2}\\|\\vec{w}\\|&#94;2 - \\sum_{i=1}&#94;N \\alpha_i (y_i(\\vec{w}\\vec{x_i}+b)-1)\\) wobei \\(\\alpha_1, \\dots, \\alpha_N \\geq 0\\) Lagrange-Multiplikatoren sind Soft Margin Hyperebene Der Parameter \\(C\\) dient der Regularisierung. Ist \\(C\\) groÃŸ gibt es wenige Missklassifikationen in der Trainingsdatenmenge. Ist \\(C\\) klein, werden die Margins grÃ¶ÃŸer. Nichtlineare Kernelmethoden Kernel-Trick AbschÃ¤tzung des realen Fehlers Der reale Fehler kann durch den empirischen Fehler und die VC-Dimension wie folgt abgeschÃ¤tzt werden: Mit Wahrscheinlichkeit $P(1-\\eta)$ gilt: $$E(h_\\alpha) \\leq E_{emp}(h_\\alpha) + \\sqrt{\\frac{VC(h_\\alpha)}{N} \\cdot (\\log(2 N / VC(h_\\alpha)) + 1) - \\frac{\\log(\\eta / 4)}{N}}$$ wobei gilt: $E(h_\\alpha)$ ist der reale Fehler der mit der Hypothese $h_\\alpha$ gemacht wird $E_{emp}(h_\\alpha)$ ist der empirische Fehler der mit der Hypothese $h_\\alpha$ gemacht wird $VC(h_\\alpha)$ ist die VC-Dimension der Lernmaschine $N$ ist die Anzahl der Lernbeispiele $0 \\leq \\eta \\leq 1$ Dieser Term wird in der Structural Risc Minimization minimiert. EntscheidungsbÃ¤ume Slide name: MLI_08_Entscheidungsbaeume_slides1.pdf Entscheidungsbaum ( Decision Tree ) Ein Entscheidungsbaum ist ein Klassifikator in Baumstruktur. Die inneren Knoten des Entscheidungsbaumes sind Attributtests, die BlÃ¤tter sind Klassen. Typischerweise wird ein Entscheidungsbaum aufgebaut, indem das jeweilige Attribut mit dem hÃ¶chsten Information Gain als nÃ¤chster Knoten hinzugefÃ¼gt wird. Siehe Information gain in decision trees fÃ¼r weitere Informationen. ID3 (siehe pseudocode ) ID3 ist ein Top-Bottom Verfahren zum Aufbau eines Entscheidungsbaumes. C4.5 (siehe pseudocode ) ID3 ist ein Top-Bottom Verfahren zum Aufbau eines Entscheidungsbaumes, welches auf ID3 basiert. Random Forest , Quelle: Wikipedia Ein Random Forest ist ein Klassifikationsverfahren, welches aus mehreren verschiedenen, unkorrelierten EntscheidungsbÃ¤umen besteht. Alle EntscheidungsbÃ¤ume sind unter einer bestimmten Art von Randomisierung wÃ¤hrend des Lernprozesses gewachsen. FÃ¼r eine Klassifikation darf jeder Baum in diesem Wald eine Entscheidung treffen und die Klasse mit den meisten Stimmen entscheidet die endgÃ¼ltige Klassifikation. Der Algorithmus ID5R dienen dem Aufbau eines Entscheidungsbaumes. C4.5 unterstÃ¼tzt - im Gegensatz zu ID3 - kontinuierliche Attributwerte. AuÃŸerdem kann C4.5 mit fehlenden Attributwerten umgehen. MÃ¶gliches QualtitÃ¤tsmaÃŸ ist Entropie: \\(Entropie(S) = - p_\\oplus \\log_2 p_\\oplus - p_\\ominus \\log_2 p_\\ominus\\) wobei \\(\\oplus\\) die positiven Beispiele und \\(\\ominus\\) die negativen Beispiele bezeichnet. Folie 41: Wo ist der Vorteil von ID5R im Vergleich zu ID3, wenn das Ergebnis Ã¤quivalent ist? â†’ ID5R kann inkrementell verwendet werden. Es ist bei ID5R - im Gegensatz zu ID3 - also nicht nÃ¶tig bei neuen Trainingsdaten neu zu trainieren. Random Forest: Erstelle mehrere EntscheidungsbÃ¤ume mit einer zufÃ¤lligen Wahl an Attributen. Jeder Baum stimmt fÃ¼r eine Klasse und die Klasse, fÃ¼r die die meisten Stimmen, wird gewÃ¤hlt. Bayes Lernen Slide name: MLI_09_BayesLernen_slides1.pdf Siehe auch: Dynamische Bayesssche Netze in ML2 Satz von Bayes Seien $A, B$ Ereignisse, $P(B) > 0$. Dann gilt: $P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$ Dabei wird $P(A)$ a priori Wahrscheinlichkeit, $P(B|A)$ likelihood, und $P(A|B)$ a posteriori Wahrscheinlichkeit genannt. Naiver Bayes-Klassifikator Ein Klassifizierer heiÃŸt naiver Bayes-Klassifikator, wenn er den Satz von Bayes unter der naiven Annahme der UnabhÃ¤ngigkeit der Features benutzt. Produktregel $P(A \\land B) = P(A|B) \\cdot P(B) = P(B|A) \\cdot P(A)$ Summenregel $P(A \\lor B) = P(A) + P(B) - P(A \\land P)$ Theorem der totalen Wahrscheinlichkeit Es seien $A_1, \\dots, A_n$ Ereignisse mit $i \\neq j \\Rightarrow A_i \\cap A_j = \\emptyset \\;\\;\\;\\forall i, j \\in 1, \\dots, n$ und $\\sum_{i=1}&#94;n A_i = 1$. Dann gilt: $P(B) = \\sum_{i=1}&#94;n P(B|A_i) P(A_i)$ Maximum A Posteriori Hypothese (MAP-Hypothese) Sei $H$ der Raum aller Hypothesen und $D$ die Menge der beobachteten Daten. Dann heiÃŸt $h_{MAP} = \\text{arg max}_{h \\in H} P(h|D) \\cdot P(h)$ die Menge der Maximum A Posteriori Hypothesen. Maximum Likelihood Hypothese (ML-Hypothese) Sei $H$ der Raum aller Hypothesen und $D$ die Menge der beobachteten Daten. Dann heiÃŸt $h_{ML} = \\text{arg max}_{h \\in H} P(h|D)$ die Menge der Maximum Likelihood Hypothesen. Normalverteilung Eine stetige Zufallsvariable $X$ mit der Wahrscheinlichkeitsdichte $f\\colon\\mathbb{R}\\to\\mathbb{R}$, gegeben durch $f(x) = \\frac {1}{\\sigma\\sqrt{2\\pi}} e&#94;{-\\frac {1}{2} \\left(\\frac{x-\\mu}{\\sigma}\\right)&#94;2}$ heiÃŸt $\\mathcal N\\left(\\mu, \\sigma&#94;2\\right)$-verteilt, normalverteilt mit den Erwartungswert $\\mu$ und Varianz $\\sigma&#94;2$. Prinzip der minimalen BeschreibungslÃ¤nge Das Prinzip der minimalen BeschreibungslÃ¤nge ist eine formale Beschreibung von Ockhams Rasiermesser. Nach diesem Prinzip werden Hypothesen bevorzugt, die zur besten Kompression gegebener Daten fÃ¼hren. Gibbs-Algorithmus ( stats.stackexchange ) Der Algorithmus von Gibbs ist eine Methode um Stichproben von bedingten Verteilungen zu erzeugen. Bedingte UnabhÃ¤ngigkeit Seien $X, Y, Z$ Zufallsvariablen. Dann heiÃŸt $X$ bedingt unabhÃ¤ngig von $Y$ gegeben $Z$, wenn $$P(X|Y,Z) = P(X|Z)$$ gilt. Add $k$ smoothing Unter Add-$k$-smoothing versteht man eine Technik, durch die sichergestellt wird, dass die geschÃ¤tzte Wahrscheinlichkeit fÃ¼r kein Ereignis gleich null ist. Wenn man $d \\in \\mathbb{N}$ mÃ¶gliche Ergebnisse eines Experiments hat, $N \\in \\mathbb{N}$ experimente durchgefÃ¼hrt werden, dann schÃ¤tzt man die Wahrscheinlichkeit von dem Ergebnis $i$ mit $$\\hat{\\theta_i} = \\frac{x_i + k}{N+ kd}, $$ wobei $x_i$ die Anzahl der Beobachtungen von $i$ ist und $k \\geq 0$ der GlÃ¤ttungsparameter ist. Bayessches Netz (Quelle: [ Dar09 ]) Ein bayessches Netz ist ein Tupel $(G, \\Theta)$ mit: $G = (\\mathbf{X}, E)$ ist ein DAG der Struktur des Bayesschen Netzwerks genant wird. Dabei ist $\\mathbf{X} = \\{X_1, X_2, \\dots, X_n\\}$ die Menge der Knoten. Jeder Knoten entspricht einer Zufallsvariablen (z.B. Attribut). Existiert eine gerichtete Kante $(X_i, X_j) \\in E$, so existiert eine direkte AbhÃ¤ngigkeit zwischen $X_i$ und $X_j$. $\\Theta$ ist die Menge der bedingten Wahrscheinlichkeitsverteilungen und heiÃŸt Parametrisierung des bayesschen Netzwerks. Es existiert fÃ¼r jedes $X_i$ genau eine Verteilung in $\\Theta$, welche in AbhÃ¤ngigkeit der Elternknoten beschrieben wird. In einem bayesschem Netz berechnet sich die gemeinsame Verteilung wie folgt: $$P(X_1, \\dots, X_N) = \\prod_{i=1}&#94;N P(X_i | \\text{Eltern}(X_i))$$ Die Modelierung von Bayesschen Netzen erfolgt meist durch den Menschen mit Expertenwissen. Alternativ kann die Struktur durch MCMC bestimmt werden. Sobald die Struktur gegeben ist wird die Menge der Verteilungen $\\Theta$ durch den Expectation Maximization Algorithmus bestimmt. Fragen: Folie 23: Warum ist \\(h_{MAP(x)}\\) nicht die wahrscheinlichste Klassifikation? Folie 24: Was ist \\(V\\) ? Is there any domain where Bayesian Networks outperform neural networks? HMM Slide name: MLI_10_HMM_slides1.pdf Markov-Bedingung (BeschrÃ¤nkter Horizont) $P(q_{t+1}=S_{t+1}|q_t = S_t, q_{t-1} = S_{t-1}, \\dots) = P(q_{t+1}=S_{t+1}|q_t = S_t)$ Hidden Markov Modell ( HMM ) Eine HMM ist ein Tupel $\\lambda = (S, V, A, B, \\Pi)$: $S = \\{S_1, \\dots, S_n\\}$: Menge der ZustÃ¤nde $V = \\{v_1, \\dots, v_m\\}$: Menge der Ausgabezeichen $A \\in [0,1]&#94;{n \\times n}$ = (a_{ij}): Ãœbergangsmatrix, die die Wahrscheinlichkeit von Zustand $i$ in Zustand $j$ zu kommen beinhaltet $B = (b_{ik})$ die Emissionswahrscheinlichkeit $v_k$ im Zustand $S_i$ zu beobachten $\\Pi = (\\pi_i) = P(q_1 = i)$: Die Startverteilung, wobei $q_t$ den Zustand zum Zeitpunkt $t$ bezeichnet VorwÃ¤rts-Algorithmus Der VorwÃ¤rts-Algorithmus lÃ¶st das Evaluierungsproblem. Er benutzt dazu dynamische Programmierung: Die Variablen $\\alpha_t(i) = P(o_1 o_2 \\dots o_t; q_t = s_i | \\lambda)$ gibt die Wahrscheinlichkeit an zum Zeitpunkt $t \\in 1 \\leq t \\leq T$ im Zustand $s_i \\in S$ zu sein und die Sequenz $o_1 o_2 \\dots o_t$ beobachtet zu haben. Diese werden rekursiv berechnet. Dabei beginnt man mit Zeitpunkt $t=1$, berechnet die Wahrscheinlichkeit $o_1$ beobachtet zu haben fÃ¼r jeden Zustand. Die Wahrscheinlichkeit der beobachteten Sequenz, gegeben die HMM $\\lambda$, ist dann einfach die Summe der $\\alpha_i$ des letzten Zeitschritts. RÃ¼ckwÃ¤rts-Algorithmus Der RÃ¼ckwÃ¤rts-Algorithmus lÃ¶st das Dekodierungsproblem. Er benutzt dazu dynamische Programmierung: Die Variablen $\\beta_t(i) = P(o_{t+1} o_{t+2} \\dots o_{T}|q_t = s_i, \\lambda)$ geben die Wahrscheinlichkeit an, dass die Sequenz $o_{t+1} o_{t+2} \\dots o_{T}$ beobachtet werden wird, gegeben das HMM $\\lambda$ und den Startzustand $s_i$. Forward-Backward Algorithm Der Forward-Backward Algorithmus berechnet fÃ¼r jeden Zeitpunkt die Wahrscheinlichkeitsverteilung der ZustÃ¤nde. DafÃ¼r glÃ¤ttet er die Werte des VorwÃ¤rts- und des RÃ¼ckwÃ¤rts-Algorithmus: $$\\gamma_t(i) = \\frac{\\alpha_t(i) \\beta_t(i)}{P(O|\\lambda)}$$ Er findet jedoch nicht die wahrscheinlichste Zustandssequenz. Viterbi-Algorithmus LÃ¶st P2: Siehe How to apply the Viterbi algorithm Baum-Welch-Algorithmus LÃ¶st P3: Gegeben sei eine Trainingssequenz $O_{\\text{train}}$ und ein Modell $$\\lambda = \\{S, V, A, B, \\Pi\\}$$ Gesucht ist ein Modell $$\\bar \\lambda = \\text{arg max}_{\\bar \\lambda = \\{S, V, \\bar A, \\bar B, \\bar Pi\\}} P(O_{\\text{train}}|\\lambda)$$ Der Baum-Welch-Algorithmus geht wie folgt vor: Bestimme $P(O_{\\text{train}} | \\lambda)$ SchÃ¤tze ein besseres Modell $\\bar \\lambda$: TODO - Genauer! (Folie 31 - 36) Iteriere diese Schritte so lange, bis ein lokales Maximum gefunden wurde. Ergodisches Modell Unter dem ergodischen Modell versteht man im Kontext von HMMs die vollverbundene Topologie inclusive Schleifen. Bakis-Modell ( Links-nach-Rechts-Modell ) Unter dem Bakis-Modell versteht man im Kontext von HMMs eine Links-nach-Rechts Topologie, bei der maximal ein Zustand Ã¼bersprungen werden kann. Das bedeutet, es gibt eine Ordnung Ã¼ber den ZustÃ¤nden. Von einem Zustand $i$ kommt man in die ZustÃ¤nde $i, i+1, i+2$. Die drei Probleme von HMMs sind P1 - Evaluierungsproblem : Wie wahrscheinlich ist eine Sequenz \\(\\bf{o} = o_1 o_2 \\dots o_T\\) gegeben ein HMM \\(\\lambda\\) , also \\(P(\\bf{o}|\\lambda)\\) . P2 - Dekodierungsproblem : Finden der wahrscheinlichsten Zustandssequenz \\(s_1, \\dots, s_T\\) , gegeben eine Sequenz von Beobachtungen \\(\\bf{o} = o_1 o_2 \\dots o_T\\) . P3 - Lernproblem : Optimieren der Modellparameter Anwendungen: Gestenerkennung Phonem-Erkennung Markov Logik Netze Slides: MLI_11-MLN_slides1 Markov Logik Netze sind Sammlungen von Tupeln aus Gewichten \\(w_i\\) und prÃ¤dikatenlogischen Formeln. Die Idee hinter Markov Logik Netzen ist ein aufweichen der harten Bedingungen der PrÃ¤dikatenlogik. Eine prÃ¤dikatenlogische Formel ist entweder wahr oder falsch. Eine Formel in MLNs kann auch \"meistens\" erfÃ¼llt sein. Das wird durch das Gewicht reprÃ¤sentiert. Markov Logik Netze ( MLN ) Ein Markov Logik Netz ist ein Menge aus Tupeln $L = (F_i, w_i)$, wobei $F_i$ eine Formel der PrÃ¤dikatenlogik erster Ordnung und $w_i \\in \\mathbb{R}$ ein Gewicht ist. Ein MLN ist eine Schablone fÃ¼r ein MRF. Markov Random Field ( Markov Netzwerk , MRF ) Ein MRF ist ein ungerichtetes Probabilistisches Grafisches Modell. MRFs sind zur Modellierung von Korrelation geeignet. Verbundwahrscheinlichkeit in MLNs $P(x) = \\frac{1}{Z} \\exp(\\sum_{i} w_i f_i(x))$ wobei $f_i$ das $i$-te Feature und $w_i$ ein Gewicht ist. Beispielsweise kÃ¶nnte $$f_i(x) = f_i(\\text{smoking}, \\text{cancer}) = \\begin{cases}1 &\\text{if } \\neg \\text{smoking} \\lor \\text{cancer}\\\\ 0 &\\text{otherwise}\\end{cases}$$ gelten. Inferenz in MLNs MAP : \\begin{align}\\text{arg max}_y P(y | x) &= \\frac{1}{Z} \\exp(\\sum_{i} w_i n_i(x, y))\\\\ &= \\sum_{i} w_i n_i(x, y) \\end{align} Siehe auch: Matthew Richardson, Pedro Domingos: Markov logic networks Pedro Domingos, Matthew Richardson: Markov Logic: A Unifying Framework for Statistical Relational Learning , 2007. Coursera: Probabilistic Graphical Models Pedro Domingos: Unifying Logical and Statistical AI , September 2009. Software: Alchemy YouTube: 11 4 M4 Markov Logic Formalism 11 39 EvolutionÃ¤re Algorithmen Slides: MLI_12_EvolutionaereAlgorithmen_slides1.pdf Siehe auch: [ Mit97 ] DEAP wenn du es ausprobieren willst. Difference between genetic algorithms and evolution strategies? Individuum Eine mÃ¶gliche Hypothese Population ( Generation ) Hypothesenmenge Erzeugung von Nachkommen Generierung neuer Hypothesen durch Rekombination und Mutation Fitness-Funktion Die Fitness-Funktion ist das zu optimierende Kriterium. Sie beschreibt die GÃ¼te einer Hypothese. Selektion Auswahl der Hypothesen, welche die beste ProblemlÃ¶sung erzeugen. EvolutionÃ¤re Strategien Das Wissen wird durch reele Zahlen und Vektoren reprÃ¤sentiert. Genetische Programmierung Das Wissen wird duch baumartige Strukturen reprÃ¤sentiert. Mutation Unter Mutation versteht man die zufÃ¤llige Ã„nderung einzelner Gene. Beispiele: Bit-Inversion: ZufÃ¤llig Gleichverteilt pro Gen / Feste Anzahl, aber zufÃ¤llige Gene Translation: Verschieben von Teilsequenzen Invertiertes EinfÃ¼gen Spezielle Mutationsoperatoren sind anwendungsspezifisch Rekombination Bei der Rekombination werden die Eigenschaften zweier Eltern gemischt. Dies kann Diskret passieren, wenn manche Gene von einem Elternteil Ã¼bernommen werden und andere vom anderen Elternteil. Alternativ kann die Rekombination auch durch intermediÃ¤re Rekombination passieren. Das bedeutet, das ein Gen gemittelt wird. Grundalgorithmus: Fitness-Function f Population p while f(p) â‰  optimal: p_parents â† selection(p) p_children â† generate_children(p_parents) p â† p_parents + p_children fitness â† f(p) p â† selection_kill(p, fitness) Probleme: Genetischer Drift: Manche Individuen vermehren sich zufÃ¤llig mehr als andere. Diese sind nicht unbedingt besser fÃ¼r das Problem geeignet. Crowding, AusreiÃŸerproblem: Fitte Individuen dominieren die Population. Das ist ein Problem wegen lokaler Maxima. Mating: Inselmodell: Die Evolution lÃ¤uft weitgehend getrennt. Es passiert nur vereinzelt, dass Individuen der Inseln ausgetauscht werden. Nachbarschaftsmodell: Nachkommen dÃ¼rfen nur von Individuen erzeugt werden, die in ihrer Nachbarschaft die beste Fitness besitzen Globales Modell: Alle dÃ¼rfen sich mit allen verbinden. Evolution: Lamark'sche Evolution: Die Individuen Ã¤ndern sich nach der Erzeugung. Sie lernen also. Dabei wird der Genotyp verÃ¤ndert und auch vererbt. Baldwin'sche Evolution: Die Individuen Ã¤ndern sich nach der Erzeugung, aber der Genotyp bleibt gleich Hybride Verfahren: Es gibt sich verÃ¤ndernde und gleich bleibende PhÃ¤notypen. Anwendungen: Traveling Salesman Flugplanoptimierung Mischung von Kaffesorten Cybermotten: Motten mÃ¼ssen optimales Muster finden, um sich vor einer FlÃ¤che weiÃŸen Rauschens zu verbergen. Snakebot (Ivan Tanev) [ Pro06 ] Deduktives Lernen Slides: MLI_13_DeduktivesLernen_slides1.pdf Siehe auch: Formale Systeme Modus Ponens $$\\frac{A, A \\rightarrow B}{B}$$ ErklÃ¤rungsbasiertes Lernen ( EBL , Explanation Based Learning by [ Mit97 ]) The key insight behind explanation-based generalization is that it is possible to form a justified generalization of a single positive training example provided the learning system is endowed with some explanatory capabilitie . In particular, the system must be able to explain to itself why the training example is an example of the concept under study. Thus, the generalizer is presumed to possess a definition of the concept under study as well as domain knowledge for constructing the required explanation. Explanation Based Generalization ( EBG ) EBG ist ein Prozess, bei dem implizites Wissen in explizites umgewandelt wird. EBG geht wie folgt vor: Explain: Finden einer ErklÃ¤rung, warum das Beispiel die Definition des Zielkonzepts erfÃ¼llt. Dies ist einfaches Anwenden des Modus Ponens. Generalize: Generalisieren der ErklÃ¤rung; bestimme also hinreichende Bedingungen unter denen die gefundene ErklÃ¤rungsstruktur gÃ¼ltig ist. Bei der EBG werden also Makro-Operatoren erzeugt. Ein Beispiel fÃ¼r Software welche EBG benutzt ist STRIPS . KBANN ( Knowledge-Based Artificial Neural Networks ) KBANN ist ein hybrides Verfahren. Die Idee ist ein neuronales Netz geschickt zu konstruieren. Dieses wird dann wie gewohnt mit Gradient Descent durch Trainingsbeispiele verfeinert. Der Algorithmus gibt eine Netzarchtiktur vor: Dabei wird pro Instanzattribut ein Netz-Input verwendet. FÃ¼r jede Klausel wird ein Neuron hinzugefÃ¼gt. Dieses ist mit dem Instanzattribut durch das Gewicht $w$ verbunden wenn es nicht negiert ist, sonst durch das Gewicht $-w$. Der Schwellwert der Aktivierungsfunktion wird auf $-(n- 0.5)w$ gesetzt, wobei $n$ die Anzahl der nicht-negierten Bedingungsteile ist. Verbinde die restlichen Neuronen von Schicht $i$ mit Schicht $i+1$ indem zufÃ¤llige kleine Gewichte gesetzt werden. Angewendet werden kann KBANN: Lernen von physikalischen Objektklassen Erkennung von biologischen Konzepten in DNS-Sequenzen UnÃ¼berwachte Lernverfahren Slides: MLI_14_UnueberwachtesLernen_slides1.pdf $k$-means Clustering Der $k$-means Clustering Algorithmus finden $k$ Cluster in einem Datensatz. Dabei ist $k \\in \\mathbb{N}_{\\geq 1}$ vom Benutzer zu wÃ¤hlen. Zuerst initialisert $k$-means die Zentroiden, also zentrale Punkte fÃ¼r Cluster, zufÃ¤llig. Dann geht $k$-means geht iterativ vor: Weise jeden Datenpunkt seinem nÃ¤chsten Cluster zu. Verschiebe die $k$ Zentroide in ihr Clusterzentrum Siehe auch: Interaktives Beispiel Fuzzy $k$-means Im Gegensatz zum $k$-means Algorithmus, wo jeder Datenpunkt in genau einem Cluster ist, weiÃŸt der Fuzzy $k$-means Algorithmus jedem Datenpunkte eine ZugehÃ¶rigkeitswahrscheinlichkeit zu. Je weiter der Datenpunkt vom Zentroid entfernt ist, desto unwahrscheinlicher wird die ZugehÃ¶rigkeit. Die Cluster-ZugehÃ¶rigkeit des Datenpunktes $x_i$ zum Cluster $c_j$ kann als Wahrscheinlichkeit in AbhÃ¤ngigkeit der Distanz $$d_{ij} = |x_i - z_j|&#94;2$$ zum Zentroiden $z_j$ ausgedrÃ¼ckt werden: $$P(c_j | x_i) = \\frac{(\\frac{1}{d_{ij}})&#94;{\\frac{1}{b-1}}}{\\sum_{r=1}&#94;k (\\frac{1}{d_{ir}})&#94;{\\frac{1}{b-1}}}$$ wobei $b \\in \\mathbb{R}_{\\geq 1}$ ein frei zu wÃ¤hlender Parameter ist. Die Zentroide werden dann wie folgt neu berechnet: $$z_j = \\frac{\\sum_{i=1}&#94;n [P(z_j|x_i)]&#94;b \\cdot x_i}{\\sum_{i=1}&#94;n [P(z_j | x_i)]&#94;b}$$ Hierarchisches Clustern Die Idee des hierarchischen Clusterns ist die iterative Vereinigung von Clustern zu grÃ¶ÃŸeren Clustern. Ergebisse kÃ¶nnen durch ein Dendrogramm beschrieben werden. Anwendung: Einordnung von Schrauben in ein Ordnungssystem Agglomerative Hierarchical Clustering ( AHC ) AHC ist ein hierarchisches Clusteringverfahren. Dabei ist ein Clusterdistanz-Schwellwert $t \\in \\mathbb{R}$ und eine minimale Cluster-Anzahl $k \\in \\mathbb{N}$ zu wÃ¤hlen. Auch ein DistanzmaÃŸ fÃ¼r Cluster (nearest neighbor, farest neighor, mean distance, ...) ist als Hyperparameter zu wÃ¤hlen. Dann geht AHC wie folgt vor: c â† k # Minimale Anzahl an Clustern c' â† n # Anzahl der Datenpunkte # Weise jedem Punkt sein eigenes Clusterzentrum zu for i in range(1, n): D_i â† {x_i} # Vereinige Clusterzentren do: c' := c' -1 find closest clusters D_i, D_j if d(D_i, D_j) â©½ t: merge(D_i, Dj) else: break until c = c' The result can be visualized as a Dendrogramm. Begriffliche Ballung Bei Algorithmen der Begrifflichen Ballung werden Konzeptbeschreibungen generiert. COBWEB Cobweb ist ein Algorithmus zur begrifflichen Ballung. Er lernt durch inkrementelles Aufbauen eines Strukturbaumes. Dabei sind nominale Attribute gestattet. Dabei wird ein Datenpunkt $x_i$ zum Cluster $c_j$ geclustert, wenn man die Attributwerte von $x_i$ durch die Kentniss von $c_j$ gut vorhersagen kann ( $P(x_i | c_j)$ , predictability) und zugleich der Cluster gut vorhergesagt werden kann, wenn die Attributwerte gegeben sind ( $P(c_j|x_i)$ , predictiveness). Es soll also in inter-KlassenÃ¤hnlichkeit minimiert und die intra-KlassenÃ¤hnlichkeit maximimiert werden. DafÃ¼r wird die Category Utility verwendet: $$\\text{CU} = \\sum_{k=1}&#94;K \\sum_{i=1}&#94;I \\sum_{j=1}&#94;{J(i)} P(A_i = V_{ij}) \\cdot P(A_i = V_ij | C_k) \\cdot P(C_k | A_i = V_{ij})$$ Dabei gilt: $K$: Anzahl der Cluster $I$: Anzahl der Attribute $J(i)$: Anzahl der Attributwerte des $i$-ten Attributs $V_{ji}$: $j$-ter mÃ¶glicher Wert fÃ¼r Attribut $i$ $P(A_i = V_ij | C_k)$: Predictability $P(C_k | A_i = V_{ij}$: Predictiveness Anwendung: Interpretation von EMGs PrÃ¼fungsfragen Was ist Induktives Lernen? â†’ Eine groÃŸe Menge an Beispielen wird gegeben. Der Lerner muss selbst das Konzept herausfinden. Was ist Deduktives Lernen? â†’ Fakten werden gegeben. Der lernende bekommt das allgemeine Konzept gesagt und muss nur logische Schlussfolgerungen machen. SVMs Wie funktioniert SRM bei SVMs? â†’ DualitÃ¤t zwischen Feature- und Hypothesenraum: Radius der Hyperkugel wird minimiert. Warum lernen SVMs \"korrekt\"? â†’ Es gibt ein Theorem (TODO: Welches?) das besagt, dass die VC-Dimension eines Klassifiers, welcher Datenpunkte im $n$-Dimensionalen Raum innerhalb einer Kugel mit Radius $D$ durch eine Hyperebene mit mindestens Abstand $\\Delta$ trennen will, durch $(\\frac{D}{\\Delta})&#94;2$ beschrÃ¤nkt ist. Die SVM minimiert genau diesen Quotienten, da sie den Margin maximiert. Alternativ: ErklÃ¤rung durch Strukturierung des Hypothesenraumes (TODO). Reinforcement Learning Wie lautet die Bellman-Gleichung? â†’ $Q(s, a) = r + \\gamma \\max_{a'} Q(s', a')$ wobei $\\gamma$ ein Diskontierungsfaktor ist, $s'$ der Zustand in den man kommt, wenn man $a$ ausfÃ¼hrt und $r$ der Reward nach ausfÃ¼hren von $a$ in $s$ ist. Was ist Value Iteration und wie lautet die Formel? â†’ SchÃ¤tzen der Value-Funktion durch iteratives anwenden von $\\hat{V}&#94;*(s_t) \\leftarrow r_t + \\gamma \\hat{V}&#94;*(s_{t+1})$ Was sind Eligibility Traces im Kontext von Reinforcement Learning? â†’ Siehe oben Wie funktioniert Q-Learning? â†’ Siehe Abschnitt Q-Learning EvolutionÃ¤re Algorithmen: Was ist wichtig? Population / Individuen: Wie Individuen darstellen â†’ Durch Gene (Attribute), z.B. als Bitstring Gegebener Ablauf (Wahl der Eltern, Generierung der Individuen) Wie kann man Kombinieren? â†’ vgl. Rekombination Fitness Function Was sind die wichtigsten Elemente von evolutionÃ¤ren Algorithmen? â†’ Mutation, Rekombination, Fittness-Funktion, Selektion Was ist Landmarksche / Baldwinsche Evolution? Wie lautet die FehlerabschÃ¤tzung von Vapnik? â†’ Siehe AbschÃ¤tzung des realen Fehlers durch den empirischen Fehler und die VC-Dimension. Was versteht man unter Cascade Correlation? â†’ YouTube (4:05 min) Welche Ã¼bwerwachten Lernverfahren gibt es? â†’ Neuronale Netze, SVMs Wie funktioniert Inferenz in Markov Logik Netzen? â†’ Siehe oben Wie wird die Verbundwahrscheinlichkeit / Weltwahrscheinlichkeit in Markov Logik Netzen berechnet? â†’ Siehe oben Was ist Dynamic Decay Adjustment (DDA)? â†’ Siehe oben Was ist erklÃ¤rungsbasierte Generalisierung (EBG)? â†’ Der Agent lernt keine neuen Konzepte, aber er lernt Ã¼ber Verbindungen bekannter Konzepte. Wie lautet die Formel fÃ¼r Entropie / Information Gain? â†’ $\\text{Entropie} = - \\sum_{i} p_i \\log p_i$ und $KL(P, Q) = \\sum_{x \\in X} P(x) \\cdot \\log \\frac{P(x)}{Q(x)}$ Was ist Cobweb? â†’ Siehe Unsupervised Learning Material und Links Vorlesungswebsite Ãœbungswebsite StackExchange What is the difference between concept learning and classification? What is the difference between a (dynamic) Bayes network and a HMM? Zusammenfassung der Vorlesung ML 2 Udacity Knowledge-Based AI: Cognitive Systems : Unter anderem gibt es eine Lektion zu Explanation-Based Learning (erklÃ¤rungsbasierte Generalisierung) Literatur [ Mit97 ] T. Mitchell. Machine Learning. McGraw-Hill, 1997. [ Dar09 ] A. Darwiche. Modeling and reasoning with Bayesian networks. Cambridge University Press, Cambridge [u.a.], 2009. [ Ber95 ] M. Berthold and J. Diamond. Boosting the Performance of RBF Networks with Dynamic Decay Adjustment. Advances in Neural Information Processing, 1995. [ Online ] [ Pro06 ] Prokopenko, Mikhail and Gerasimov, Vadim and Tanev, Ivan. Evolving Spatiotemporal Coordination in a Modular Robotic System. Springer, 2006. Ãœbungsbetrieb Es gibt keine ÃœbungsblÃ¤tter, keine Ãœbungen, keine Tutorien und keine Bonuspunkte. Vorlesungsempfehlungen Folgende Vorlesungen sind Ã¤hnlich: Analysetechniken groÃŸer DatenbestÃ¤nde Informationsfusion Machine Learning 1 Machine Learning 2 Mustererkennung Neuronale Netze Lokalisierung Mobiler Agenten Probabilistische Planung Folgende Vorlesungen habe ich nicht gehÃ¶rt, kÃ¶nnten aber interessant sein: BÃ¶hm: Big Data Analytics BÃ¶hm: Analysetechniken groÃŸer DatenbestÃ¤nde 2 BÃ¶hm: Praktikum: Analysetechniken groÃŸer DatenbestÃ¤nde Noch kann ich folgende Veranstaltungen nicht einschÃ¤tzen und wÃ¼rde mich Ã¼ber Feedback von dir freuen: Beyerer: Projektpraktikum: Bildauswertung und -fusion Big Data @ BOSCH Cayoglu, Streit: Big Data Tools Hartenstein: Big Data Mining auf GPUs Hanebeck: Von Big Data zu Data Science: Moderne Methoden der Informationsverarbeitung Nakhaeizadeh: Data Mining Studer (AIFB): Knowledge Discovery Termine und Klausurablauf Datum : MÃ¼ndliche PrÃ¼fung (in Zukunft schriftlich) Ort : nach Absprache Zeit : 15 min Ãœbungsschein : gibt es nicht Bonuspunkte : gibt es nicht Ergebnisse : werden ca. 5 - 10 min. nach der mÃ¼ndlichen PrÃ¼fung gesagt Erlaubte Hilfsmittel : keine","tags":"German posts","title":"Machine Learning 1"},{"url":"https://martin-thoma.com/wo-ist-horsaal-9-am-kit/","text":"Dieser Artikel ist fÃ¼r all die verzweifelten StudienanfÃ¤nger am KIT , die den HÃ¶rsaal 9 (HS 9) suchen. Der HS 9 ist in GebÃ¤ude 20.40 , dem ArchitektengebÃ¤ude. Es ist im ersten Stockwerk. Da muss man die groÃŸe Treppe des Haupteingangs hoch, nach rechts abbiegen und um die Ecke laufen. Sinnigerweise ist HÃ¶rsaal 37 (HS 37) im Erdgeschoss... &ast;sigh&ast; da hÃ¤tte ich wirklich gerne Google Indoor Maps . Oder zumindest im Ergeschoss einen Plan, der PlÃ¤ne der Stockwerke beinhaltet. Am besten noch eine alphabetisch sortierte Liste der RÃ¤ume mit Verweis auf die Etage... (Randnotiz: Falls sich jemand Ã¼ber diesen Mini-Artikel wundert: Ich habe diese HÃ¶rsÃ¤le schon mehrfach gesucht. Letzens wegen Statistik , wo das so wunderbar prÃ¤zise auf der Vorlesungsseite steht... nun kann man es hoffentlich bald googeln, auch wenn ich nicht dabei unterstÃ¼tzt wurde, die PlÃ¤ne auf Google Indoor Maps zu stellen. Irgendwas von \"Datenschutz\" wurde gesagt...)","tags":"German posts","title":"Wo ist HÃ¶rsaal 9 am KIT?"},{"url":"https://martin-thoma.com/cg-klausur/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žComputergrafik\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr. Ing. Carsten Dachsbacher im Wintersemester 2015/2016 gehÃ¶rt. Behandelter Stoff Datum Kapitel Inhalt 20.10.2015 Einleitung Viele nette Bilder und Beispiele, wenig Inhalt 22.10.2015 Farbe, Darstellung & Perzeption Weber-Fechner-Gesetz , Abtasttheorem , Dynamikumfang , Farbwahrnehmung im menschlichen Auge; Gammakorrektur 26.10.2015 Ãœbung gdb (bt - backtrace; p - print) 26.10.2015 Metamerismus: Unterschiedliche Spektren kÃ¶nnen gleichen Farbeindruck erwecken Addiere/subtrahiere Farbmischung CMY / CMYK / RGB / HSV / XYZ Weber-Fechner-Gesetz : 2% heller 29.10.2015 Ray-Tracing: Kapitel 2 Menschen nehmen KontrastintensitÃ¤t und Luminenz besser als Chrominanz war. Das ermÃ¶glicht Kompression. clear-type / subpixel Darstellung Jaggies: UnerwÃ¼nschter Treppenstufen-Effekt bei Rasterisierung von Strecken Kamera: Position (x,y,z), Blickrichtung (zu einem Punkt mit Koordinaten (x,y,z)) und up-Vektor Skalarprodukt, Kreuzprodukt Baryzentrische Koordinaten , 02.11.2015 Ãœbung Rasterisierung von Linien (Implizite Darstellung) zbuffer: Tiefe des \"nÃ¤chsten\" Polygons pro Pixel wird gespeichert Konsistenzregeln, z.B. wenn man zwei benachbarte farbige Dreiecke mit Diagonale hat und man die Farbe des Pixels berechnen muss, durch den beide Dreiecke teilweise gehen (37 FÃ¤lle; Katalog von Microsoft; macht die Hardware) 26.11.2015 ? Sphere Mapping ; Vorfilterung von Environment Maps 10.12.2015 RÃ¤umliche Datenstrukturen BSP-Baum, kD-Baum 14.01.2016 OpenGL 18.01.2016 Ãœbung Koordinatensystem-Pipeline, Shader 19.01.2016 Erzeugung von Landschaften Rotes / Rosa Rauschen, Lattice Value Noise, Perlin-Rauschen Folien Bilder, Farbe, Perzeption Slide: 01_ Bilder, Farbe, Perzeption - Teil1.pdf Frame Buffer Speichert Bilder zur direkten wiedergabe auf dem Bildschirm. Ditherhing ( Fehlerdiffusion ) Ditherhing ist eine Methode zur Illusion einer grÃ¶ÃŸeren Farbtiefe. Gamma-Korrektur $$I_{\\text{out}} = I_{\\text{in}}&#94;\\gamma$$ Transferfunktion Eine Abbildung $f$ von Farbwerten auf Helligeit: $$f: [0, N] \\rightarrow [I_{\\text{min}}, I_{\\text{max}}]$$ Diese Abbildung ist abhÃ¤ngig vom Display. Dynamikumfang Der Dynamikumfang beschreibt den erreichbaren Kontrast eines WiedergabegrÃ¤tes (Bildschirm, Beamer): $$R_d = \\frac{I_{\\text{max}} + k}{I_{\\text{min}} + k}$$ $k$ ist dabei das Umgebungslicht, $I_{max} / I_{min}$ sind Konstanten des Displays und geben die maximale bzw. minimale Helligkeit an. Gammut ( Farbgammut ) Der Gamut eines Monitors entspricht dem Spektrum der darauf darstellbaren Farben. Farbtemperatur Die Farbtemperatur ist ein MaÃŸ, um einen jeweiligen Farbeindruck einer Lichtquelle zu bestimmen. SchwarzkÃ¶rper , SchwarzkÃ¶rperstrahlung Ein SchwarzkÃ¶rper ist eine idealisierte thermische Strahlungsquelle. Die idealisierung besteht darin, dass der KÃ¶rper die komplette auftretende Strahlung vollstÃ¤ndig absorbiert. Gleichzeitig sendet er WÃ¤rmestrahlung (SchwarzkÃ¶rperstrahlung) aus, welche nur von seiner Temperatur abhÃ¤ngig ist. Slide: 01_ Bilder, Farbe, Perzeption - Teil2.pdf Additive Farmbischung Grundfarben: Rot, GrÃ¼n, Blau Anwendung: Bildschirm Subtraktive Farbmischung Grundfarben: Cyan, Magenta, Gelb Anwendung: Drucker GraÃŸmansche Gesetze Jeder Farbeindruck kann mit 3 GrundgrÃ¶ÃŸen beschrieben werden. Weber-Fechner-Gesetz Das Weber-Fechner-Gesetz macht eine Aussage Ã¼ber die subjektiv empfundene StÃ¤rke von SinneseindrÃ¼cken im AbhÃ¤ngigkeit von der IntensitÃ¤t des Helligkeitsunterschiedes: $$E = c \\cdot \\frac{R}{R_0}$$ wobei $E$ die empfundene ReizstÃ¤rke, $c$ eine Konstante, $R$ die tatsÃ¤chliche ReizstÃ¤rke und $R_0$ eine ReferenzreizstÃ¤rke ist. RGB-Farbraum: Addition der Spektren, wird bei CRT/LCD-Farbmonitoren verwendet. CMY, CMYK: Subtraktive Farbmischung, wird bei Druckern verwendet. K (schwarz) nur aus praktischen GrÃ¼nden. HSV-Farbraum: Weder Additiv noch subtraktiv, wird bei Benutzerschnittstellen verwendet CIE Color Matching Functions XYZ Color Space: Farbraum fÃ¼r Konversion zwischen FarbrÃ¤umen ChromatizitÃ¤t xyY Farbraum Machsche Streifen / Bandeffekte Hermann-Gitter / Laterale Hemmung Windows clear type / Subpixel Raytracing Side: 02_ Raytracing (enthalt Abtastung aus Kapitel 1).pdf Ray-Tracing Ray-Tracing ist ein Verfahren zum Erzeugen Fotorealistischer Bilder. Dabei geht man prinzipiell wie folgt vor: Strahlerzeugung : FÃ¼r jeden Pixel werden Sichtstrahlen erzeugt Schnittberechnung : Finde das primitiv (z.B. Dreieck) welches der Strahl schneidet und welches am nÃ¤chsten zur Kamera ist und vor der Kamera liegt. Schattierung : Beleuchtungsberechnung (shading) Phong-Beleuchtungsmodell Das Phong-Beleuchtungsmodell besteht aus 3 Komponenten: Ambiente Beleuchtung: Materialkoeffizient $k_a$. Ambiente Beleuchtung ist indirekte Beleuchtung, also Licht von anderen OberflÃ¤chen Diffuse Beleuchtung: Materialkoeffizient $k_d$. Diffuse Beleuchtung ist die Streuung des Lichts nahe beim \"Streupunkt\" (nach dem Lambertschen Gesetz). Spekulare Beleuchtung: Materialkoeffizient $k_s$ sowie Phong-Exponent $n$. Unter spekularer Beleuchtung versteht man direkte Spiegelung der Lichtquelle (imperfekte Spiegelung) Das Ergibt folgende Formel fÃ¼r die IntensitÃ¤t $I$: $$I = \\overbrace{k_a \\cdot I_L}&#94;{\\text{ambient}} + \\overbrace{k_d \\cdot I_L \\cdot (N \\cdot L)}&#94;{\\text{diffus}} + \\overbrace{k_s \\cdot I_L \\cdot (R_L \\cdot V)&#94;n}&#94;{\\text{spekular}}$$ hierbei ist $I_L$ die LichtintensitÃ¤t, die Richtung die das Licht nimmt $L$ sowie die OberflÃ¤chennormale $N$ und der Lichtreflektionsvektor $R_L$. Der Vektor $R_L$ liegt in der selben Ebene wie $N$ und $L$. Es gilt $R_L = 2N \\cdot (N \\cdot L) - L$. Z-Fighting Polygone, welche in der selben Ebene liegen fÃ¼hren zu einem Flackern welches der beiden Polygone nun angezeigt wird. Dies kann verhindert werden, indem eines der Polygone minimal verschoben wird. Tessellation Parkettierung, also das FÃ¼llen einer FlÃ¤che mit Primitiven. Distributed Ray Tracing Bilder welche mit dem Whitted-Style Ray Tracing Verfahren gerendert wurden sehen zu perfekt aus. Die perfekte Spiegelung und Trasmission, die harten Schattenkanten und die unendliche SchÃ¤rfentiefe kennen wir von realen Kameras so nicht. Distributed Ray Tracing ist eine alternative zu Whitted-Style Ray Tracing, welche diese Probleme zu lÃ¶sen versucht. Dabei wird bei jeder Spiegelung nicht ein Schattenstrahl verschickt, sondern viele welche sich um den \"Perfekten\" Strahl konzentrieren. Nyquist-Shannon-Abtasttheorem Vektoren, Ortsvektoren, Skalarprodukt Parametrisierte Geraden- und Ebenendarstellung Baryzentrische Koordinaten Strahl-Kugel-Schnitt Spekulare Reflektion Diffuse (Lambertsche) Reflektion BRDF - Bidirectional Reflectance Distribution Function Phong Beleuchtungsmodell Snellsches Brechungsgesetz Fresnel-Effekt Anti-Aliasing Strategien: Uniformes Supersampling, Adaptives Supersampling, Stochastisches Supersampling Schattenstrahlen Bewegungs- und TiefenunschÃ¤rfe Imperfekte Spiegelung und Transmission Ãœbungsfolien: 01_ Rasterisierung.pdf Rasterisierung von Linien Brute-Force Inkrementelle Berechnung Bresenham Algorithmus Rasterisierung von Polygonen Sichtbarkeitsproblem Maler-Algorithmus (Painters algorithm) Vorgehen: Sortiere Dreiecke von hinten nach vorne und zeichne sie so. Probleme: AbstandsmaÃŸ / Zyklen Ãœbungsfolien: 07_ Distributed Raytracing.pdf Hier sind eigentlich nur schÃ¶ne Bilder. Ohne Kontext bringt der Foliensatz nichts :-/ Distributed Raytracing kann TiefenunschÃ¤rfe, weiche Schatten und indirekte Beleuchtung. Monte Carlo Integration Pathtracing Many-Lights Method Voxel Cone Tracing Radiance Caches Finite Elemente / Radiosity Transformationen und homogene Koordinaten Slide: 03_ Transformationen und homogene Koordinaten.pdf Orthogonale Matrix Eine quadratische Matrix $M \\in \\mathbb{R}&#94;{n \\times n}$ heiÃŸt genau dann orthogonal, wenn $$M&#94;T \\cdot M = M \\cdot M&#94;T = I_{n \\times n}$$ FÃ¼r orthogonale Matrizen gilt also $M&#94;{-1} = M&#94;T$ Homogene Koordinaten Der euklidische bzw. affine Raum wird um sog. Fernpunkte ergÃ¤nzt. Rotation Die Rotation um (0, 0) in homogenen Koordinaten geht wie folgt: $$\\begin{pmatrix}\\cos \\alpha & -\\sin \\alpha & 0\\\\ \\sin \\alpha & \\cos \\alpha & 0 \\\\ 0 '& 0 & 1\\end{pmatrix}$$ Skalierung Eine Skalierung in homogenen Koordinaten geht wie folgt: $$\\begin{pmatrix}s_x & 0 & 0 & 0\\\\ 0 & s_y & 0 & 0\\\\ 0 & 0 & s_x & 0\\\\ 0 & 0 & 0 & 1\\end{pmatrix}$$ Scherung Eine Scherung in homogenen Koordinaten geht wie folgt: $$\\begin{pmatrix}1 & 0 & d_x & 0\\\\ 0 & 1 & d_y & 0\\\\ 0 & 0 & 1 & 0\\\\ 0 & 0 & 0 & 1\\end{pmatrix}$$ Koordinatensysteme Objektkoordinaten: Sie werden durch die Modelltransformation zu Weltkoordinaten: Sie werden durch die Kameratransformation zu Kamerakoordinaten Der Ursprung des Welt-Koordiantensystems wird mit 0 bezeichnet. Die Basisvektoren mit $x, y$. Das Modellkoordinatensystem hat den Ursprung $e$ und die Basisvektoren $u, v$ Transformationen werden grundsÃ¤tzlich so dargestellt: $$x' \\gets M \\cdot x$$ Es wird also der zu transformierende Vektor von rechts mit der Transformationsmatrix $M$ multipliziert. Spiegelung an der $y$-Achse ist eine Multiplikation der $x$-Koordinaten mit (-1) Hierarchisches Modellieren, Szenengraph Ãœbungsfolien: 02_ Bildoperationen.pdf Filter ( Bildfilter ) Ein Bildfilter ist ein Algorithmus, welcher als Input ein Bild bekommt und als Output ein Bild liefert. Typischerweise werden lineare Filter verwendet. Beispiele: HelligkeitsÃ¤nderung KontrastÃ¤nderung (z.B. unschÃ¤rfe (blur), schÃ¤rfen (sharpen)) Desaturierung Kantendetektion Linearer Filter Gewichtete Summe benachbarter Pixel-Werte. Siehe Interaktives Beispiel Morphologische Filter StrukturverÃ¤ndernde Operation (z.B. Dilatation, Erosion, Ã–ffnung, SchlieÃŸung) Texturen Slide: 04_ Texturen.pdf Texturen Texturen kÃ¶nnen vielfÃ¤ltig eingesetzt werden: Klassische Feinstrukturierung Reflektionseigenschaften Farbe Normalenvektoren (Bump- oder Normal mapping) Beleuchtung Environment Mapping, Reflection Mapping Shadow Mapping, Light Mapping Geometrie (Displacement Mapping) Texturkoordinaten werden Ã¼blicherweise mit $(s, t)$ bezeichnet. Manchmal auch mit $(u, v)$. Eine Textur ist im Einheitsquadrat. Eine Textur kann folgendermaÃŸen auf ein Objekt gemappt werden, indem das Objekt in einen HilfskÃ¶rper (z.B. Kugel, WÃ¼rfel, Zylinder) gesteckt wird, auf welchen die Textur bereits gemappt wurde. Dann kann die Textur folgendermaÃŸen auf das Objekt Ã¼bertragen werden: Normale des HilfskÃ¶rpers auf das Objekt Normale des Objekts auf den HilfskÃ¶rper Linie durch den Mittelpunkt des Objekts auf den HilfskÃ¶rper Environment Map Eine Environment-Map ist eine Textur zur Darstellung der Umgebung. Bei Einvironment-Maps nimmt man an, dass der Betrachter weit genug von der Umgebung entfernt ist, sodass die Position keine Rolle spielt und ausschlieÃŸlich die Blickrichtung wichtig ist. Ãœbliche Parametrisierungen von Environment-Maps sind: Cube Maps + ist bei korrekter Filterung nahtlos + keine SingularitÃ¤t am Rand Sphere Maps - SingularitÃ¤t am Rand + mit Kamera, Chromkugel und Photoshop kann sie recht einfach aufgenommen / erstellt werden LatLong-Map - die Pole werden ungleichmÃ¤ÃŸig abgetastet Eine Anwendung war der \"flÃ¼ssige\" Terminator im Hubschrauber (Terminator 2). Cube Map Um den Hintergrund darzustellen, kann man die Szene in einen von innen texturierten Cubus stecken. Ein Reflektionsrichtung $\\mathbf{r} = (r_x, r_y, r_z)$ bestimmt den Punkt auf dem Mantel des WÃ¼rfels. Die betragsmÃ¤ÃŸig grÃ¶ÃŸte Komponente von $\\mathbf{r}$ bestimmt, welche WÃ¼rfelflÃ¤che (links, rechts, vorne, hinten, oben, unten) genommen wird. AbhÃ¤ngig von der orientierung des koordinatensystems in bezug auf die Cube map kann sich dann also folgende Regel ergeben: Wenn $|r_x|$ am grÃ¶ÃŸten ist, ist es rechts (< 0) oder links (> 0), wenn $|r_y|$ am grÃ¶ÃŸten ist, ist es vorne (< 0) oder hinten (> 0) wenn $|r_z|$ am grÃ¶ÃŸten ist, ist es oben (< 0) oder unten (> 0) Die Texturkoordinaten $(s, t)$ werden z.B. fÃ¼r (right) wie folgt erechnet: $$s = \\frac{r_y}{2 \\cdot r_x}, \\;\\;\\; t = \\frac{r_z}{2 \\cdot r_x}$$ Mip-Map ( Mip map , Mipmap , AuflÃ¶sungspyramide ) Mip steht fÃ¼r lat. multum in parvo (viel in wenig). Eine Mip-Map ist eine Vorfilterung von Texturen. Mip-Mapping hilft, wenn man in einem sehr flachem Winkel auf eine Ebene blickt. In einer Mip-Map wird die Original-Textur gespeichert, dann in der ersten Stufe eine Textur welche in beiden Dimensionen auf die hÃ¤lfte verkleinert wurde (also 1/4 der ursprÃ¼nglichen GrÃ¶ÃŸe). Es wird diejenige Mip-Map Stufe $n$ gewÃ¤hlt, sodass gilt $$\\text{TexelgrÃ¶ÃŸe}(n) \\leq \\text{GrÃ¶ÃŸe Pixelfootprint auf Textur} < TexelgrÃ¶ÃŸe(n+1)$$ Dann wird eine Trilineare Interpolation der 8 nÃ¤chsten Texel durchgefÃ¼hrt: Bilinear auf Stufe $n$, bilinear auf Stufe $n+1$ linear zwischen diesen beiden Farben Mip-Maps benÃ¶tigen zusÃ¤tzlich 1/3 der ursprÃ¼nglichen TexturgrÃ¶ÃŸe. Isotrope Texturfilterung Eine Texturfilterung heiÃŸt isotrop, wenn sie in alle Richtungen gleich ist. Anisotrope Texturfilterungen sind gewÃ¼nscht, weil sie in die Tiefe schÃ¤rfe erhalten kÃ¶nnen, wohingegen isotrope Texturfilterung in die ferne unscharf wirken kÃ¶nnen. RIPmaps sind anisotrope Texturfilterungen. Ãœbungsfolien: 04_ Texturen und Transformationen.pdf Limitationen von Whitted-Style Raytracing Keine Kaustiken oder korrekte Dispersion Keine indirekte Beleuchtung Keine FlÃ¤chenlichtquellen Kein Motion-Blur oder TiefenunschÃ¤rfe MÃ¶gliche LÃ¶sung: Distributed Raytracing Stratified Supersampling Strahlen werden durch zufÃ¤llige Superpixelpositionen geschossen, aber mÃ¶glichst gleichmÃ¤ÃŸig um Klumpen zu vermeiden. Transformationen Texturen Repeating / Clamping Bilineare Filterung Aliasing bei Verkleinerung LÃ¶sung: Ãœberabtastung oder Vorfilterung (z.B. Mip-Maps) Mip-Maps Auswahl der richtigen TexturgrÃ¶ÃŸe RÃ¤umliche Datenstrukturen Slide: 05_ Raumliche Datenstrukturen.pdf (10.12.2015) RÃ¤umliche Datenstrukturen HÃ¼llkÃ¶rper Axis-Aligned Bounding Boxes (AABB) Bounding Volume Hierachies (BVH) RegulÃ¤re Gitter Oktalbaum (Octree) kD-Baum AABB ( Axis-Aligned Bounding Box ) Axis-Aligned Bounding Boxes sind Rechtecke (Quader in 3D), deren Seiten parallel zu den Achsen des Koordinatensystems stehen. Sie werden als HÃ¼llkÃ¶rper verwendet. Alles wichtige zu AABBs kann man in Folie 18 - 29 nachlesen. BSP-Baum ( Binary Space Partition Baum ) Teile den Raum mithilfe von Ebenen in zwei Teile. Die Ebenen dÃ¼rfen beliebig im Raum liegen. Somit wird eine Baumstruktur aufgebaut, welche den Raum in immer kleinere Teile teilt. kD-Baum Ein BSP-Baum, welcher nur achsenparallele Ebenen erlaubt. Der Raum wird also mit achsenparallelen Hyperebenen geteilt; es entsteht ein BinÃ¤rbaum welcher den Raum partitioniert. Surface Area Heuristic ( SAH ) WÃ¤hle die Split-Ebene so, dass die Kosten der Traversierung minimiert werden. Bounding-Volume-Hierachies ( BVH ) BVHs sind eine Datenstruktur, welche den Raum in HÃ¼llkÃ¶rper unterteilt. Man hat also komplexe Objekte. FÃ¼r diese Objekte muss man Schnittests machen. Das bedeutet im einfachsten Fall, dass man fÃ¼r $n$ Dreiecke und einen Strahl genau $n$ Schnittests machen muss. Interessanterweise dÃ¼rfen sich HÃ¼llkÃ¶rper Ã¼berlappen. Nun kÃ¶nnte man aber - je nach den Objekten - diese in jeweils zwei Quader unterteilen. Wenn der Strahl nur einen Quader schneidet, dann muss man auch nur fÃ¼r die Objekte in diesem Quader Schnittests durchfÃ¼hren. Innerhalb des Quaders kann man natÃ¼rlich noch weiter die Objekte in HÃ¼llkÃ¶rper (Ã¼blicherweise Quader) unterteilen. Typische HÃ¼llkÃ¶rper sind: AABB: Axis-Aligned Bounding Boxes Bounding Spheres OBB: Oriented Bounding Boxes Slabs: Schnitt von Paaren paralleler Halbebenen Die SAH ist ein Kriterium zum aufbau von BVHs / kD-BÃ¤umen. Im Mittel sollen zufÃ¤llige Strahlen, die den betrachteten Knoten schneiden, den gleichen Aufwand verursachen, egal welcher Kindknoten traversiert wird OktalbÃ¤ume ( Octree ) Gitter Schnitttests kÃ¶nnen beschleunigt werden, indem Ã¼ber den Raum ein Gitter gelegt wird. Der Raum wird also in kleinere Teile zerlegt. Ein Octree unterteilt einen Quader in 8 kleiner Quader. Diese kÃ¶nnen wiederum in 8 kleinere Quader unterteilt werden. Mailboxing Speichern des Ergebnisses eines Schnitttests mit einem Objekt, um erneute Schnitttests zu verhindern. Ãœbungsfolien: 05_ BVH.pdf Median-Split: Die Entscheidung wird anhand der Mittelpunkte der AABBs getroffen. Rasterisierung, Clipping und Projektionstransformationen Side: 06_ Rasterisierung, Clipping und Projektionstransformationen.pdf Tiefenpuffer ( Z-Buffer ) Es wird ein Bild gespeichert, welches fÃ¼r jeden Pixel die Tiefe des vordersten Objekts angibt. Tiefentest Finden des Bildteiles, der fÃ¼r einen gegebenen Pixel am nÃ¤chsten vor der Kamera ist. Clipping Abschneiden von Linien und Poligonen, die auÃŸerhalb des sichtbaren Bereichs liegen. Dies ist wichtig fÃ¼r die behandlung problematischer FÃ¤lle bei Projektionen. Algorithmus von Sutherland-Hodgeman Dient dem Clipping von Polygonen. Frustum Ein Frustum ist ein Kegelstumpf, wobei in der Computergrafik eher ein Pyramidenstumpf gemeint ist. Das View Frustum ist der Bereich der Szene, der sichtbar ist. Outcodes Outcodes sind ein 4-Bit binÃ¤rcode fÃ¼r die Bereiche um die Zeichenebene: $$(x < x_{\\text{min}}, x > x_{\\text{max}}, y < y_{\\text{min}}, y > y_{\\text{max}})$$ Ãœbungsfolien: 09_ Clipping.pdf Clipping von Linien Ein Rechteck $(x_{\\text{min}}, x_{\\text{max}}, y_{\\text{min}}, y_{\\text{max}})$ und eine Linie $P_1 = (x_1, y_1), P_2 = (x_2, y_2)$ ist gegeben. Es gibt den \"trivial reject\" Fall, bei dem die komplette Linie auÃŸerhalb liegt und den \"trivial accept\" Fall, bei dem die komplette Linie innerhalb des Rechtecks liegt. Cohen-Sutherland Algorithmus Der Cohen-Sutherland Algorithmus dient dem Clipping von Linien mit einem Rechteck. Man unterteilt die Ebene, in der das Rechteck liegt in 9 Bereiche: (links oben, links mitte, links unten, mitte oben, mitte mitte,...). Die Punkte bekommen nun jeweils einen \"Outcode\" der ihre Position bzgl. dieser Bereiche bestimmt: $$\\text{Outcode} = (x < x_{\\text{min}}, x > x_{\\text{max}}, y < y_{\\text{min}}, y > y_{\\text{max}})$$ Mit den Outcodes gilt nun: Trivial Accept: Outcode($P_1$) $\\lor$ Outcode($P_2$) = 0 Trivial Reject: Outcode($P_1$) $\\land$ Outcode($P_2$) $\\neq$ 0 Interessant ist, dass in den nicht-trivialen FÃ¤llen zwar immer ein Teil der Strecke auÃŸerhalb des Rechtecks liegt, aber nicht unbedingt auch ein Teil innerhalb des Rechtecks liegen muss. $\\alpha$-Clipping FÃ¼hre Window Edge Coordinates (WEC) ein. Diese sind ein vorzeichenbehafteter Abstand zu den Clipping-Kanten. Wenn eine Koordinate negativ ist, dann liegt der Punkt auÃŸerhalb des Rechtecks. Ich habe den Algorithmus in Python-Pseudocode geschrieben. Sutherland-Hodgeman Polygon Clipping Clipping wird Kante fÃ¼r Kante durchgefÃ¼hrt. OpenGL Slides: 07_ OpenGL (freiwilliges Bonusmaterial).pdf , 07_ OpenGL (Teil 1).pdf , 07_ OpenGL (Teil 2 und 3).pdf GL Short for \"Graphics Library\" GLUT OpenGL Utility Toolkit: Window manipulation, mouse and keyboard interactions. Shading Flat shading: \\begin{align} n &= \\langle x_1-x_2, x_3-x_2\\rangle\\\\ f &= \\langle n , L \\rangle&#94;+ \\cdot (\\lambda_1 c_1 + \\lambda_2 c_2 + \\lambda_3 c_3) \\end{align} Gouraud-Shading \\begin{align} c'_i &= c_i \\langle n_i, L \\rangle&#94;+\\\\ f &= \\lambda_1 c'_1 + \\lambda_2 c'_2 + \\lambda_3 c'_3 \\end{align} Phong-Shading \\begin{align} n &= \\lambda_1 n_1 + \\lambda_2 n_2 + \\lambda_3 n_3\\\\ f &=\\langle n , L \\rangle&#94;+ \\cdot (\\lambda_1 c_1 + \\lambda_2 c_2 + \\lambda_3 c_3) \\end{align} Gouraud Shading Berechne Parameter wie z.B. Farbe an den Eckpunkten; interpoliere innerhalb des Polygons. Phong Shading Beleuchtungsberechnung mit interpolierter Normalen. Phong-Shading hat mit dem Phong-Beleuchtungsmodell inhaltlich nichts zu tun. Backface Culling Dreiecke, auf deren RÃ¼ckseite man blickt werden Ã¼blicherweise nicht gezeichnet. ( glEnable(GL_CULL_FACE); glCullFace(GL_BACK); ) Stencil-Puffer Ein Stencil-Puffer ist eine Stanzmaske, welche fÃ¼r jeden Pixel im Framebuffer einen 8-bit Wert speichert. Im einfachsten Fall begrenzt der Stencil-Puffer das Renderinggebiet. In order to use GLUT, you need to include: #include <GL/gl.h> #include <GL/glu.h> #include <GL/glut.h> OpenGL-Funktionen: gluLookAt glClear( GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT | GL_STENCIL_BUFFER_BIT ) Keyword in Shadern: in : Input-Variable out : Output-Variable uniform : Bei jedem Shader-Aufruf gleich (also insbesondere fÃ¼r jeden Vertex gleich); read-only; z.B. Transformationsmatrix attribute : Attribut eines Vertex; nur fÃ¼r Vertex-Shader; z.B. Farbe oder Normale varying : weitergegebene/interpolierte Werte (schreiben in einem Shader, lesen im darauffolgenden Shader) In Vertex-Shadern: gl_Position = P * V * M * vec4 ( position , 1.0 ); Siehe auch: GLProgramming.com GL Specs GLSL Specs Ãœbungsfolien: 08_ Shaders.pdf Rasterisierungspipeline Geometrie-Verarbeitung Rasterisierung Pro-Fragment Operationen Koordinatensystem-Pipeline Objekt-Koordinaten Welt-Koordinaten Kamera-Koordinaten Clip Space Koordianten Normalisierte GerÃ¤te-Koordinaten Bildschirm-Koordinaten Vertex-Shader Eingabe: Position Normale Farbe oder Texturkoordinate Ausgabe: Weitergeleitete Vertex-Attribute Position nach MVP-Transformation Fragment-Shader Eingabe: Interpolierte Vertex-Attribute Beleuchtungsinformationen Ausgabe: Farbe des Fragmentes Shading Flat Shading: Beleuchtungsberechnung pro Vertex (oder pro Fragment) mit Facetten-Normale Gouraud-Shading: Beleuchtungsberechnung pro Vertex mit gemittelter Normale der anliegenden Facetten Phong-Shading: Shading bzw. Beleuchtungsberechnung pro Fragment mit interpolierter Normale Cube-Maps Diffuse Vorfilterung Texturzugriffe in GLSL Prozedurale Modellierung, Content Creation Slides: 08_ Prozedurale Modellierung, Content Creation.pdf am 19.01.2016 Rauschfunktion ( Noise-Funktion ) Eine Funktion $$n: \\mathbb{R}&#94;n \\rightarrow [a, b] \\subsetneq \\mathbb{R}$$ heiÃŸt Rauschfunktion, wenn gilt: Periodenfrei : Eine Rauschfunktion darf keine sichtbare PeriodizitÃ¤t aufweisen. RÃ¤umliche Korrelation : $n(\\mathbf{x}) \\approx n(\\mathbf{x} + \\varepsilon)$ definierte Frequenzverteilung, bandlimitiert (Aliasing reduzieren) Perlin-Rauschen ( Perlin-Noise ) Zufallszahlen-Pool + Hash + Permutation Oktave Sammlung von Rauschfunktionen Turbulenzfunktion Eine Turbulenzfunktion summiert $k$ Ergebnisse (Oktave) mehrerer Rauschfunktionen auf: $$\\text{turbulence}(x) = \\sum_k \\left (\\frac{1}{2} \\right )&#94;k \\cdot n (2&#94;k \\cdot x)$$ Einsatzgebiete: NatÃ¼rliche OberflÃ¤chen Feuer Pixelbasierte Textursynthese Man hat ein kleines Beispiel (Exemplar) und erzeugt daraus - Pixel fÃ¼r Pixel - eine komplette Textur. Dieses Verfahren ist langsam. Patchbasierte Textursynthese Verwende bei der Texturgenerierung nicht nur einzelne Pixel aus dem Beispiel, sondern grÃ¶ÃŸere Patches. Lindenmayer-System ( L-System ) Ein Lindenmayer-System ist eine Grammatik $G = (V, \\Sigma, \\omega, P)$, wobei $V \\neq \\emptyset$ das Alphabet ist, $\\Sigma \\subseteq V$ die Menge der Konstanten ist, $\\omega \\in V&#94;*$ das Startwort ist, $P \\subseteq (V&#94;* \\setminus \\Sigma&#94;*) \\times V&#94;*$ die Menge der Ersetzungsregeln ist Slides: 08_ Prozedurale Modellierung (freiwilliges Bonus Material).pdf Turbulenz-Texturen z.B. Diamon Square / Midpoint Displacement Algorithmus Prozedurale Shader Raymarching Fraktale / Mandelbrot-Menge L-Systeme / D0L-Systeme Kurven und FlÃ¤chen Slides: 09_ Kurven und Flachen.pdf Kubische BÃ©zierkurven Kubische BÃ©zierkurven sind von der Form $$f(u) = (1-u)&#94;3 b_0 + 3u (1-u)&#94;2 b_1 + 3u&#94;2 (1-u) b_2 + u&#94;3 b_3$$ wobei $b_0, b_1, b_2 \\in \\mathbb{R}&#94;n$ und $u \\in [0, 1]$ gilt. Diese Faktoren (also $(1-u)&#94;3, 3u (1-u)&#94;2, 3u&#94;2 (1-u), u&#94;3$) werden auch Bernstein-Polynome genannt. Genau wie die Monome sind sie eine Basis fÃ¼r Polynome. Bernstein-Polynome $$B_i&#94;n(u) = \\binom{n}{i} u&#94;i (1-u)&#94;{n-i}$$ BÃ©ziersplines Ein BÃ©zierspline ist eine Liste von BÃ©zierkurven. $C&#94;k$-stetige Splines Es seien \\begin{align}F(u) &= \\sum_{i=0}&#94;n B_i&#94;n(u) \\mathbf{f}_i\\\\ G(u) &= \\sum_{i=0}&#94;n B_i&#94;n(u) \\mathbf{g}_i\\end{align} Der Spline aus $F, G$ heiÃŸt $C&#94;0$ stetig $:\\Leftrightarrow F(1) = G(0) \\Leftrightarrow \\mathbf{f}_n = \\mathbf{g}_0$ $C&#94;1$ stetig $:\\Leftrightarrow F'(1) = G'(0) \\land C&#94;0 \\Leftrightarrow \\mathbf{f}_n - f_{n-1} = \\mathbf{g}_1 - \\mathbf{g}_0 \\land C&#94;0$ $C&#94;2$ stetig $:\\Leftrightarrow F''(1) = G''(0) \\land C&#94;1 \\Leftrightarrow \\mathbf{f}_{n-1} + (\\mathbf{f}_{n-1} - \\mathbf{f}_{n-2}) = \\mathbf{g}_{1} + (\\mathbf{g}_{1} - \\mathbf{g}_{2}) \\land C&#94;1$ B-Splines TODO Algorithmus von De Casteljau Siehe Code . Ãœbungen Blatt 1 Das Framework bekommt man ohne VM unter Ubuntu 15.04 nach der Installtion folgender Pakete (vielleicht) zum laufen: $ sudo apt-get install cmake xorg-dev libglu1-mesa-dev freeglut3 freeglut3-dev libglew1.5 libglew1.5-dev libglu1-mesa libglu1-mesa-dev libgl1-mesa-glx libgl1-mesa-dev libglfw3 Wenn ihr den Fehler error adding symbols: DSO missing from command line ubuntu bekommt, dann solltet ihr einfach die obigen Pakete installieren, den build -Ordner lÃ¶schen und es neu versuchen. Color cube Gravity field Temperature of a black body AuÃŸerdem: $ pacman -Syy ausfÃ¼hren. Dann bekommt man auch nicht mehr 404er wenn man mit $ pacman -S vim vim installieren will. In der VM sollte unter Settings â†’ System â†’ Acceleration die Option \"Enable VT-x/AMD-V\" aktiviert sein. ZusÃ¤tzlich sollte im BIOS des Host-Systems (also von eurem Rechner) die \"Intel Virtualization Technology\" aktiviert sein. (Man Laptop hat das nicht - bei mir funktionieren die Beispiele in der VM aber auch nicht :-/) Blatt 6 glm::gtx::transform Material und Links Vorlesungswebsite Ãœbungswebsite E-Mail Verteiler Inoffizielle MusterlÃ¶sungen fÃ¼r die Altklausuren Siehe auch World, View and Projection Transformation Matrices How to calculate transformation matrix Martin Thoma: Interactive Graphic Filters example Interactive Blending example (OpenGL) Martin Thoma: Minimal OpenGL example Martin Thoma: alpha-cliping pythonic pseudocode Minimal GLSL example A Primer on BÃ©zier Curves StackExchange: What is the worst case time complexity for intersection tests with BVHs? Ray Tracing vs Rasterization ÃÃ±igo QuÃ­lez: Raymarching Distance Fields Software OpenGL OpenGL Tutorial 3 : Matrices OpenGL Cheat Sheet glBegin / 2 Terragen : Erzeugung von Landschaften xfrog : Erzeugung von Pflanzen Literatur P. Shirley, S. Marschner: Fundamentals of Computer Graphics, 3rd Edition â†’ Kapitel 3-9, Kapitel 11-12 (Data Structures for Graphics) Ãœbungsbetrieb Es gibt ÃœbungsblÃ¤tter und Ãœbungen, aber keine Tutorien und keine Bonuspunkte. Um das Modul zu bestehen wird der Ãœbungsschein benÃ¶tigt. FÃ¼r den Ãœbungsschein benÃ¶tigt man 60% der Punkte der ÃœbungsblÃ¤tter. Die ÃœbungsblÃ¤tter werden Ã¼ber submit.ivd.kit.edu eingereicht. Die ÃœbungsblÃ¤tter erscheinen alle 2 Wochen. Es gibt also min. 6 ÃœbungsblÃ¤tter und min. 120 Punkte. Die Deadline ist Montag, 11:00. Termine und Klausurablauf Datum : Mittwoch, der 09.03.2015 von 14:00 Uhr (Quelle: informatik.kit.edu ) 08.02.2016: Die Klausur-Anmeldung wird freigeschalten 04.03.2016: Anmeldeschluss 06.03.2016: Abmeldeschluss Ort : A... - Kon...: Benz-HÃ¶rsaal Geb. 10.21 Kop... - Stumpf...: Daimler-HÃ¶rsaal Geb. 10.21 Stumpp... - Z...: Redtenbacher HÃ¶rsaal Geb. 10.91, Raum 050 Punkte : 120 Zeit : 60 min Punkteverteilung : ? Bestehensgrenze : ? Ãœbungsschein : Gibt es. Dieser wird fÃ¼r das Modul, aber nicht fÃ¼r die Klausur benÃ¶tigt. Mit mindestens 72 Punkten (60% von 120 Punkten) hat man den Ãœbungsschein. Bonuspunkte : Gibt es nicht. Ergebnisse : ? Einsicht : Noch nicht bekannt (Stand: 29.03.2016) Erlaubte Hilfsmittel : Stift Geodreieck Zirkel","tags":"German posts","title":"Computergrafik - Klausur"},{"url":"https://martin-thoma.com/rename-script/","text":"Once in a while I have to bulk rename files. For example, when I have holiday photos. The following script helps me to do so: #!/usr/bin/env python # -*- coding: utf-8 -*- \"\"\"Batch-Rename files in a folder according to some rules.\"\"\" import os import math from PIL import Image def get_date_taken ( path ): \"\"\"Get the date when the image was taken.\"\"\" print ( path ) im = Image . open ( path ) if im is not None or im . _getexif () is None : return im . _getexif ()[ 36867 ] else : print ( \"Could not find date in EXIF data for ' %s '\" % path ) return os . stat ( path ) . st_ctime def rename ( rename , starts = None , ends = None , test = False ): \"\"\" Rename all files in a nice way. Only files which end with `ends` and start with `starts` are renamed to `rename-[Number]`. \"\"\" files = [ f for f in os . listdir ( '.' ) if os . path . isfile ( f ) and not f . endswith ( \".py\" )] # Sort files by last modification / creation files . sort ( key = lambda x : os . stat ( x ) . st_ctime ) # st_ctime or st_mtime files . sort ( key = lambda x : get_date_taken ( x )) if starts is not None : files = [ f for f in files if f . lower () . startswith ( starts . lower ())] if ends is not None : files = [ f for f in files if f . lower () . endswith ( ends . lower ())] for i , f in enumerate ( files , start = 1 ): filename , ext = os . path . splitext ( f ) ext = ext . lower () digits = int ( math . log10 ( len ( files ))) + 1 number = str ( i ) . zfill ( digits ) new_name = \" %s - %s%s \" % ( rename , number , ext ) if test : print ( \"{0:<40}-> {1:<20}\" . format ( f , new_name )) else : os . rename ( f , new_name ) def get_parser (): \"\"\"Parser for rename script.\"\"\" from argparse import ArgumentParser , ArgumentDefaultsHelpFormatter parser = ArgumentParser ( description = __doc__ , formatter_class = ArgumentDefaultsHelpFormatter ) parser . add_argument ( \"-n\" , \"--name\" , dest = \"name\" , help = \"new name\" , required = True , metavar = \"NAME\" ) parser . add_argument ( \"-s\" , \"--starts\" , dest = \"starts\" , help = \"Get files which start with this string\" , default = None , metavar = \"STARTS\" ) parser . add_argument ( \"-e\" , \"--ends\" , dest = \"ends\" , help = \"Get files which end with this string\" , default = None , metavar = \"ENDS\" ) parser . add_argument ( \"-t\" , \"--test\" , action = \"store_true\" , dest = \"test\" , default = False , help = \"don't change anything, just show what would be \" \"done\" ) return parser if __name__ == '__main__' : args = get_parser () . parse_args () rename ( args . name , starts = args . starts , ends = args . ends , test = args . test )","tags":"Cyberculture","title":"Rename Script"},{"url":"https://martin-thoma.com/languages-for-back-ends/","text":"What programming language would I use for the back end of a big, new project in a startup which wants to offer a web service? Sure, on the client side there is pretty much only JavaScript (including variants like CoffeeScript and TypeScript ) in combination with HTML and CSS. I've used MySQL and Redis databases and I'm quite happy with that. But the choice for the server side is not that easy. I've been using PHP for quite a while now, because it was the cheapest and easiest choice when I started programming. But things have changed (and I have more money, so I don't have to take the super cheap hosting services). Although my experience with web projects is very limited, I want to share a few thoughts. Definitions: Back End and Security Just for clarification: I am only talking about the back end. A back end is the data access layer which manages requests comming to the server. It needs to server many requests (> 100 requests/second) fast (< 300 ms in average). It should not execute computationally heavy jobs which can be pre-computed or do not need to be displayed instantly to the client. This can be done by another system which does not need to be programmed in the same language. The back end does also not deal with presentation to the user. This is what the front end does. However, you should have more than a good idea in which form the front end gets the data. The cleanest approach I've seen so far is a pure RESTful API for all interactions between front end and back end. The backend language should also make it easy to validate / sanitize input data, connect with databases, store/get stuff on/from the file system. In the following, I will write that some languages are \"secure\" or \"not secure\". This does not mean that you can / cannot write code which is secure. It means that the compiler (or other widespread tools) give you guarantees about bugs in your code. For example, C is a very insecure language as the compiler does no bounds checking . The types of errors which can be detected by automatic tools (without further testing) are: Syntax errors, Out of bounds (reading), buffer overflow (not checked in C/C++, but not possible in Java ( source )), unused variables (which might indicate other problems; at least code smell), type problems: This is a bit fuzzy, as you can write stringly typed code (see New Programming Jargon ) in probably every language, but in some languages it is more common than in others. Some languages also make it easier to use the type system to detect errors. For example, PHP is very insecure in this sense as 123 == \"123ab\" , Python is a bit more secure, but you can return whatever you want, Java is much more secure. Haskell is even more secure in this sense, as it has real functions (without side effects, checked by the compiler). See What can Haskell's type system do that Java's can't and vice versa? for more. There are also some errors which can be detected at runtime. The handling of those runtime errors differs from language to language. For example, C and C++ fails silently (e.g. this question ). This is bad. For example, there are some silent out-of-bounds errors in C / C++ where Rust would fail loud (I think Heartbleed is one example; see Would Rust have prevented Heartbleed? Another look if you're interested in that specific example). Of course, all of those problems can be detected with good testing. But the more is done automatically, the less can go wrong when you don't write (good) tests. Java Java is an object-oriented language which runs on the Java Virtual Machine. Java is probably the most used language for big business websites. Why is that the case? Java is old: It first appeared in 1995. Java is taught at many universities and many people know at least a little bit of Java. So companies don't have problems finding developers. At least that might be the impression of people who don't realize that there is a big differencee between people saying they know Java and developers who can actually work with it. I guess the Java ecosystem is pretty mature: eclipse , IntelliJ IDEA and Netbeans as IDEs, Jenkins for continuous integration, GlassFish , Apache Ant / Apache Maven or Gradle for automatic building, JUnit , Mockito , Powermock for automatic unit tests, log4J and log4J 2 for logging, Apache JMeter for load testing Jersey for RESTful Web services, Apache Tomcat / WildFly (former JBoss): application server / web server / servlet container Grizzly / Jetty : Web server FindBugs , SonarQube for code quality / static code analysis Hibernate for ORM, OSGi : Apache Felix / Equinox - see 10min clip for a high-level explanation of OSGi, Frameworks like Spring , JSF , JSP , Apache Struts 2 , Apache Wicket Java is developed by Oracle . Hence you can make contracts with Oracle to get support when things don't work. That was what we have on the positive side. What is not so good about Java? VERY clumsy syntax. This is more than just a inconvenience. You have to type a lot to get things done which makes you slow. Of course, you can (and need to) use autocompletion, but it is still a lot to read. That makes maintaining the code a mess. Tools are hard to get to work. Unnecessary super-abstract constructs used for eventually never happening future extensions (see Geek-and-poke.com ). A bit more secure than C/C++ as you cannot access out-of-bound arrays, you don't have pointers. So buffer overflows are almost impossible in Java (see SO for more details). However, you buy this security with much less easy syntax and you don't get as much security as would be possible with just a bit more effort. See rust for more details. Speed and memory usage: Again, Java might be better in speed than many other languages, but not as good as some others are. And Java seems to need A LOT of memory. However, I am not too sure if that is really a problem. (see Surprise! Java is fastest for server-side Web apps ) See also: Is Java a Compiled or an interpreted programming language? : The short answer is no. But Java guys don't like to hear that â˜º Why do I hear about so many Java insecurities? Are other languages more secure? : The short answer is no, thinking about C/C++. Security of JVM for Server C++ performance vs. Java/C# JavaScript: Node.js Node.js is a runtime environment which was initially released in 2009 and became quite popular since then. Node.js is asynchronous, event-driven and scalable. Node.js applications are written in JavaScript and hence have all the advantages of JavaScript: They profit from heavy development in JavaScript engines / JIT compilers like V8 . The syntax is flexible and light-weight. Just like Java, JavaScript first appeared in 1995. So the language itself is old and stable. A lot of developers know at least a little bit of JavaScript. The ecosystem is mature. npm and bower for package management Backbone.js / AngularJS for MVP / MVC. Unit.js for unit testing. Grunt as a task runner. Sequelize as an ORM. Karma : Test runner expressjs : web application framework Lots of easy tutorials What is still to say? Node is FAST and scalable! (see Performance Comparison Between Node.js and Java EE ) JavaScript is very insecure. Even simple syntax error will only get revealed when they are actually executed. So Unit testing is very important. Node.js is used by LinkedIn, Yahoo!, Uber, PayPal ( source ) There are quite a few people moving from Node.js to Go ( 1 , 2 , 3 , 4 ) See also: How to decide when to use Node.js? How to debug Node.js applications node.js tutorial Go Go is a statically-typed, compiled language developed by Google. It first appeared in 2009, so it is very young. Go offers the basic tools you need for web development: martini / Gin Gonic : A web development framework mustache for templates gorm : ORM Good tutorial and also some material for web development Some tasks are much more complicated than they should be. Sorting, to name one example (see SO ). Go is different from some other languages, e.g. if you want a method to be public, the first character of the method name has to be capitalized. Or unused variables result in a compiler error. See also: Gin Gonic May Be 40x Faster Than Martini, But It Is Not Better Go vs Node.js for servers C# C# is a compiled, statically typed language (with dynamic features, see Understanding the Dynamic Keyword in C# 4 ) developed by Microsoft. It was publically announced in 2000. The initial release of its web appliction framework ASP.NET was in 2002. The ecosystem seems to include: nuget.org IIS : Web server Entity Framework : ORM LINQ : SQL queries Visual Studio : IDE ASP.NET MVC Framework But I don't know enough about C# / ASP.NET to write something meaningful about it. Coding Horror described why they use ASP.NET for StackOverflow and why he doesn't recommend it for OpenSource projects ( source ). StackExchange also describes what they use ( 1 , 2 ). I see a big problem in the Microsoft-centric technology stack. You have to use everything from them. (Almost) everything is closed source. If they discontinue the development or if they don't fix stuff which might be relevant for you, you're fucked. This seems to change. Microsoft moved some important parts of their stack to GitHub (see dotnet.github.io ). Most important seems to be that the compiler Roslyn is licensed under an Apache License. But there is also ASP.NET, the Entity Framework, and the .NET runtime. The Visual Studio Community Edition is not available for free (but only for Windows). Python Python is one of the oldest programming languages which are still in use. It first appeared in 1991. Python is dynamically typed, interpreted, object-oriented and includes functional programming features. Although I use Python for many projects, I didn't use it by now for a web project. So I might not know the important tools / frameworks. Please keep that in mind. Ecosystem: pypi.python.org and pip : Package hosting and package management Sphinx : (Semi) automatic code documentation, e.g. the scipy docs are generated with Sphinx from Python code. This is one of the best documentations I have ever seen. Django / Flask as frameworks pytest / nose for testing gevent : a coroutine-based Python networking library Tornado : Web server Some Python people switch to Go ( 1 , 2 ) Many tutorials and often very good documentation: Flask djangobook.com and docs.djangoproject.com fullstackpython.com Flask and Django work with PyPy ( source ). That might make them much faster. Used by big players: Quora ( source ) Prezi, Pinterest, Instagram ( source ) Bitbucket, The Onion ( source ) I think one of the main advantages of Python is that it is really easy to write code which is easy to read (because of docstrings, Pythons weird intendation semantics and very nice syntax) and quite hard to write unreadable code. I am sure I have a biased view regarding Python, but I am also sure a lot of people share this subjective impression. PHP PHP is a server-side scripting language which appeared first in 1995. It is dynamically typed. Language inconsistencies are really bad with PHP - see also PHP: a fractal of bad design The ecosystem is ok: PHPCI for continuus integration. Zend Framework / Symfony Smaller Frameworks like CakePHP and Code Igniter Drupal / Joomla / TYPO3 / WordPress PHPUnit for unit testing, Composer for package management and packagist.org to find packages cruisecontrol for Continuus Integration A big advantage of PHP is that it is easy to learn. You can run PHP everywhere and hosting is cheap. Wikipedia makes use of PHP, so it is obviously possible to create systems which have HUGE numbers of requests and still work fine. The right tool for the right job - by commitstrip.com Hack Hack is a programming language introduced in 2014 by Facebook. It is a PHP dialect. Key differences to PHP are: Function arguments and return values can be annotated with types. Hack does not support some language features which are supported by PHP ( source ). Which is good. For example, goto, variable variables, string incrementing, ... See also: hacklang.org Rust Rust is a very safe language, but seems not to be ready for productive usage. I am a big fan of Rust, but as it aims to be a better C++, it is probably a better fit for OS development, game engines, embedded systems, databases, complex desktop applications (Photoshop/Word/Chrome), etc. While Rust is quite expressive for a systems programming language, its banner features are the borrow checker (+ lifetimes, etc) and powerful static type system. Rust emphasizes zero-cost abstractions with compiler-enforced memory & thread safety. The popular web development languages are dynamically typed and interpreted, with an emphasis on rapid development, which is a very different niche than Rust claims to fill. Source: news.ycombinator.com See: arewewebyet.com Rust Web Frameworks Others Ruby with Rails : I know it is quite well-known and used by many people. But I don't know Ruby enough to write anything meaningful. The Ruby syntax is similar to Python. Scala seems to be noteworthy See also Web Framework Benchmarks Usage of server-side programming languages for websites todobackend.com : A lot of different back end technology stacks bento.io : Seems to offer many tutorials The RedMonk Programming Language Rankings: January 2015 Comparison of programming languages Conclusion Thinking about it that carefully, I see three languages which seem to be suitable for back ends for me: Go: Fast and compiled node.js: Good scalability Python: It is the language I know best and of which I like the syntax best. Besides that, it has a very nice and clear syntax, good community-developed coding style standards and is very easy to read and well-documented. Not suitable seem to be: PHP: Because of the language inconsistencies which seem to make it pretty hard to make a reliable back end C#: The technology stack is too Microsoft centered. Java: Too clumsy syntax, too hard to get it work. The other programming languages could be very good choices. I simply don't know it. I am very curious if rust will be used for back ends. Hack is very young, let's see if it will spread in a few years. Credits As I don't have much experience with web development, I asked a few friends to have a look at the different parts of the article. They looked especially at plain wrong statements, if I named \"all\" the important frameworks / tools. They might not completely agree with the comparison to other language (after all, I wrote the article), but they helped me a lot to get things not too wrong: SÃ¶ren Liebich ( @liebsoer ) has several years of experience with Java web development and helped me to name the important tools / technologies used in the Java stack. Henning Dieterichs helped me to fix some of the mistakes in the C# part and reminded me of Hack and the positive sides of PHP. Stefan had a look at the PHP section. Thank you!","tags":"Code","title":"Languages for Back Ends"},{"url":"https://martin-thoma.com/increase-the-maximum-file-upload-size-in-php/","text":"Create a test.php with the following content to check your current maximum upload size. <?php phpinfo (); ?> Search your php.ini in the Apache folder: $ find /etc -name 'php.ini' /etc/php5/cli/php.ini /etc/php5/apache2/php.ini Edit it. Set upload_max_filesize and post_max_size to whatever you want. Restart the server with $ sudo service apache2 restart","tags":"Cyberculture","title":"Increase the maximum file upload size in PHP"},{"url":"https://martin-thoma.com/3d-photospheres/","text":"I've been to New York City a few months ago. It was an interesting experience. Everything is so big, it is difficult to get a feeling for it if you haven't seen it yourself. For example, the WTC Memorial is overwhelmingly large. I tried to capture that in a photograph with my Panasonic DMC-TZ41, but it just doesn't look that large: WTC Memorial A photosphere captures that much better (it looks great on my Smartphone, but not nearly as well on the web): Android Photosphere Optonaut goes one step further. This app is able to create 3D photospheres. How it works - User perspective You start the app, slowly turn around yourself to capture everything around you. This includes your feet and the sky, if you really want a complete photosphere. The recording process the same as for Android Photospheres, but probably with a slightly different interface: Optograph recording process When you want to watch it in 3D you have to have something that holds it in front of your face at the right distance. Cardboard is an easy and cheap possibility to do so: Cardboard And, of course, you can already share optographs: Sharing Optographs How it works - Developers perspective Optonaut makes use of the camera and takes a lot of images. Those images are combined to a photosphere by a process called image stitching . This means you search points which seem to match to build one big image from many small images. A big problem is that your camera moves quite a lot in space and the environment changes. So there might not be any way to make a perfect match. Sensors like the compass and the accelerometer help to figure out at which direction you are currently pointing. Programs like hugin stitch images semi-automatically, but Optonaut works completely automatically. From my experience with Android Photospheres, this works much better when the objects around you are far away. That means it doesn't work in your room. Then Optonaut uses a technique called stereoscopy . They show you different images for each eye to give you the impression of a 3D image. They also use a different photosphere techique to \"mix images dynamically\". Optonaut claims that this does work for close objects (in contrast to the traditional photosphere apps like Google Photosphere, Photosynth or Microsoft ICE). As they can figure out where you look at with the accelerometer / compass, they adjust the images accordingly for each eye to create a 3D impression: Stereographic images produced by Optonaut Now it gets very interesting. Usually, you would need two cameras next to each other to take two slightly shifted images. But Optonaut needs only one camera. They make use of the fact that you rotate around your axis to photograph your environment. Optonaut takes two images which are next to each other, match them, deskew them. Et voilÃ : You are able to get a 3D impression! A side note: The 3D photosphere is stored as an archive of images. The Optonaut Team Optonaut has two founders: Emanuel JÃ¶bstl and Johannes Schickling. I've had the luck to work with them in my first hackathon (CODEFEST8). We won in Karlsruhe with an App / web service with a fully automatic drivers logbook ( logbookapp.de ). Both of them are great developers. Emanuel created the (working!) Android app which connected to the car within a couple of hours and Johannes made a beatiful frontend in the same time. Emanuel knows a lot about protocols, can understand mathematically complex algorithms and solve conceptually difficult problems. I guess he wrote the stitching algorithm. I've learned a lot from Johannes about tools. He is a perfectionist. In situations where most people would say \"hey, it works, lets drink some coffee\" he is still working hard to get the best user experience, making the code more maintainable by refactoring it, improving the way how code is built / deployed. In a short-term project this costs probably more time than doing it quick-and-dirty, but on the medium/long run (e.g. more than 2 weeks) it saves a lot of work. And Optonaut is such a long-term project. They are working on it for quite a while now, so I am sure the quality is pretty high. I am very curious if the Kickstarter campaign works as well as they hope and I cannot wait for the first people to share their optographs from amazing places! Future of Optonaut The Optonaut team plans to build a sharing site where you can show others amazing places. They want to completely redesign the App. I guess the stitching algorithm is something where you can put endless effort in. It is an optimization problem where it is not completely clear what to optimize, so I guess this will continually be improved. I want it! What do I need? You need an Android / iOS smartphone. There seems to be a web-based viewer which works with Chrome/Firefox/Safari, too. See also Optonaut.com : The official website demo.optonaut.com : In case you have a smartphone and a Cardboard, you can try the web demo already. Kickstarter : Support them, get early access / the App and your own Cardboard","tags":"Cyberculture","title":"3D Photospheres"},{"url":"https://martin-thoma.com/getting-a-feeling-for-energy/","text":"Have you heard of GravityLight ? It is a gravity-powered lamp designed as an alternative for off-grid families who would otherwise use kersene lamps. It is basically only a 12kg weight, lifted and put on the gravity light. When the weight goes down again it pulls a cord. This cord makes an electric motor which generates electricity for LEDs. If you lift the weight 1.83m, the light lasts for about 20 minutes. I wondered how much weight I would need to lift (assuming 100% efficiency) to power my computer for 8 hours. According to the power supply unit, my laptop can consume up to 65 Watt. That is astonishingly low. I think my big one is at about 600-800 Watt. \\begin{align} 65 W \\cdot 8 h &= \\frac{65 kg \\cdot m&#94;2 \\cdot 8h \\cdot 60 \\frac{min}{h} \\cdot 60 \\frac{s}{min}}{s&#94;3}\\\\ &= 1872 \\cdot 10&#94;3 \\frac{kg \\cdot m&#94;2}{s&#94;2} \\end{align} You might also remember from your physics courses that potential energy is \\(E_{pot} = m \\cdot g \\cdot h\\) where \\(m\\) is the mass (in kg), \\(g = 9.80 \\frac{m}{s&#94;2}\\) is the gravitational acceleration and \\(h\\) is the height in meters. \\begin{align} m \\cdot h &= \\frac{E_{pot}}{g}\\\\ &= \\frac{1.872 \\cdot 10&#94;6 \\frac{kg \\cdot m&#94;2}{s&#94;2}}{9.80 \\frac{m}{s&#94;2}}\\\\ &= 191.0 \\cdot 10&#94;3 kg \\cdot m \\end{align} This means I would have to lift 191 000 packages one liter of milk to a height of 1 meter. Every day. Just to let my small laptop run. Or lets view it from another angle. I think lifting about 5 packages of milk to a height of about 1.8m each hour would not be too exhausting. This would generate about \\(E_{pot} = 5kg \\cdot 1.80m \\cdot 9.80 \\frac{m}{s&#94;2} / (1h \\cdot 60 \\frac{min}{h} \\cdot 60 \\frac{s}{min}) = 0.0245 \\frac{kg \\cdot m&#94;2}{s&#94;3} = 0.0245 W\\) . Lets think what you can power with 0.0245 Watt... It is amazing about how much energy we have today.","tags":"Cyberculture","title":"Getting a Feeling for Energy"},{"url":"https://martin-thoma.com/python-markov-chain-packages/","text":"Markov Chains are probabilistic processes which depend only on the previous state and not on the complete history. One common example is a very simple weather model: Either it is a rainy day (R) or a sunny day (S). On sunny days you have a probability of 0.8 that the next day will be sunny, too. On rainy days you have a probability of 0.6 that the next day will be rainy, too. As you have only two possible weather conditions, the probability that it changes from sunny do rainy is 0.2 and vice versa it is 0.4. You can visualize this with a graph like this: Simple Markov chain weather model I am taking a course about markov chains this semester. Today, we've learned a bit how to use R (a programming language) to do very basic tasks. R vs Python The following will show some R code and then some Python code for the same basic tasks. As an example, I'll use reproduction. The states are \\(S_1 = \\{AA, AA\\}\\) , \\(S_2 = \\{AA, Aa\\}\\) , \\(S_3 = \\{AA, aa\\}\\) , \\(S_4=\\{Aa,Aa\\}\\) , \\(S_5 = \\{Aa, aa\\}\\) and \\(S_6 = \\{aa, aa\\}\\) . The idea is that each pair of parents give birth to two children. The parents \\(S_2 = \\{AA, Aa\\}\\) can give birth to {{AA, AA}, {AA, Aa}, {Aa, Aa}}. This results in the following state transition matrix. $$\\begin{pmatrix}1 & 0 & 0 & 0 & 0 & 0 \\\\ 1/4 & 1/2 & 0 & 1/4 & 0 & 0\\\\ 0 & 0 & 0 & 1 & 0 & 0\\\\ 1/16 & 1/4 & 1/8 & 1/4 & 1/4 & 1/16\\\\ 0 & 0 & 0 & 1/4 & 1/2 & 1/4\\\\ 0 & 0 & 0 & 0 & 0 & 1\\end{pmatrix}$$ The rows mean from which state you start, the colums are the states you can get to. Now, how would you define this matrix with R? P = matrix ( c ( 1 , 0 , 0 , 0 , 0 , 0 , 1 / 4 , 1 / 2 , 0 , 1 / 4 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 1 / 16 , 1 / 4 , 1 / 8 , 1 / 4 , 1 / 4 , 1 / 16 , 0 , 0 , 0 , 1 / 4 , 1 / 2 , 1 / 4 , 0 , 0 , 0 , 0 , 0 , 1 ), byrow = TRUE , nrow = 6 ) And this is how you do it with Python: You first need to install numpy . This is very easy with Linux ( sudo apt-get install python-numpy ), but I've heard it is not that easy with Windows systems. import numpy as np P = np . matrix ([[ 1. , 0. , 0. , 0. , 0. , 0. ], [ 1. / 4 , 1. / 2 , 0. , 1. / 4 , 0. , 0. ], [ 0. , 0. , 0. , 1. , 0. , 0. ], [ 1. / 16 , 1. / 4 , 1. / 8 , 1. / 4 , 1. / 4 , 1. / 16 ], [ 0. , 0. , 0. , 1. / 4 , 1. / 2 , 1. / 4 ], [ 0. , 0. , 0. , 0. , 0. , 1. ]]) A common matrix operation is taking the \\(n\\) -th power. This is how you do it with R: First, install the library \"expm\" by executing install.packages(\"expm\") . Then library ( \"expm\" ) n = 5 Pn = P %&#94;% n and this is the Python way: n = 5 Pn = P ** n Visualizing data is a very important tool. For example, we want to know the probabilities for the current state for the next 20 steps when you started in \\(S_3\\) . library ( \"expm\" ) P = matrix ( c ( 1 , 0 , 0 , 0 , 0 , 0 , 1 / 4 , 1 / 2 , 0 , 1 / 4 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 1 / 16 , 1 / 4 , 1 / 8 , 1 / 4 , 1 / 4 , 1 / 16 , 0 , 0 , 0 , 1 / 4 , 1 / 2 , 1 / 4 , 0 , 0 , 0 , 0 , 0 , 1 ), byrow = TRUE , nrow = 6 ) v = c ( 0 , 0 , 1 , 0 , 0 , 0 ) for ( step in 1 : 20 ) { matplot ( t ( sapply ( 1 : 20 , function ( step ) { v %*% ( P %&#94;% step )})), cex = 0.7 , ylab = \"\" ) } This gives the following plot: State probabilities starting in S3 after 1..20 steps (plotted with R) The Python equivalent is #!/usr/bin/env python import numpy as np from matplotlib import pyplot P = np . matrix ([[ 1. , 0. , 0. , 0. , 0. , 0. ], [ 1. / 4 , 1. / 2 , 0. , 1. / 4 , 0. , 0. ], [ 0. , 0. , 0. , 1. , 0. , 0. ], [ 1. / 16 , 1. / 4 , 1. / 8 , 1. / 4 , 1. / 4 , 1. / 16 ], [ 0. , 0. , 0. , 1. / 4 , 1. / 2 , 1. / 4 ], [ 0. , 0. , 0. , 0. , 0. , 1. ]]) v = np . matrix ([[ 0 , 0 , 1 , 0 , 0 , 0 ]]) # Get the data plot_data = [] for step in range ( 20 ): result = v * P ** step plot_data . append ( np . array ( result ) . flatten ()) # Convert the data format plot_data = np . array ( plot_data ) # Create the plot pyplot . figure ( 1 ) pyplot . xlabel ( 'Steps' ) pyplot . ylabel ( 'Probability' ) lines = [] for i , shape in zip ( range ( 6 ), [ 'x' , 'h' , 'H' , 's' , '8' , 'r+' ]): line , = pyplot . plot ( plot_data [:, i ], shape , label = \"S %i \" % ( i + 1 )) lines . append ( line ) pyplot . legend ( handles = lines , loc = 1 ) pyplot . show () The result looks like this State probabilities starting in S3 after 1..20 steps (plotted with Python) I've played around with the matplotlib markers to make sure all points are visible. Python Markov Packages There seem to be quite a few Python Markov chain packages: $ pip search markov PyMarkovChain - Simple markov chain implementation autocomplete - tiny 'autocomplete' tool using a \"hidden markov model\" cobe - Markov chain based text generator library and chatbot twitter_markov - Create markov chain (\"_ebooks\") accounts on Twitter markovgen - Another text generator based on Markov chains. pyEMMA - EMMA: Emma's Markov Model Algorithms pymc - Markov Chain Monte Carlo sampling toolkit. hmmus - Posterior decoding with a hidden Markov model marbl-python - A Python implementation of the Marbl specification for normalized representations of Markov blankets in Bayesian networks. pymdptoolbox - Markov Decision Process (MDP) Toolbox gibi - Generate random words based on Markov chains markovgenerator - Markov text generator pythonic-porin - Nanopore Data Analysis package. Provides tools for reading data, performing event detection, segmentation, visualization, and analysis using hidden Markov models, and other tools. Designed for the UCSC Nanopore Group. PyMarkovTextGenerator - Random text generator base on Markov chains. MCREPOGEN - Markov Chain Repository Generator vokram - A toy Markov chain implementation. MarkovEquClasses - Algorithms for exploring Markov equivalence classes: MCMC, size counting hmmlearn - Hidden Markov Models in Python with scikit-learn like API twarkov - Markov generator built for generating Tweets from timelines MCL_Markov_Cluster - Markov Cluster algorithm implementation pyborg - Markov chain bot for irc which generates replies to messages pydodo - Markov chain generator mwordgen - MWordGen is a Markov statistics based word generator. Markov - Python library for Hidden Markov Models markovify - Use Markov chains to generate random semi-plausible sentences based on an existing text. treehmm - Variational Inference for tree-structured Hidden-Markov Models PyMarkov - Markov Chains made easy However, most of them are for hidden markov model training / evaluation. There seems to be no package which can visualize markov chains just by taking the state transition matrix. There seems also not to be any package which makes it easy to classify states as transient / recurrent, get the absorption time, ... If somebody is interested in that, we could make a little project for it â˜º PyMarkovChain Source is on github.com/TehMillhouse/PyMarkovChain . It is less than 150 lines of code and probably no functionality. I asked the author to remove the package from PyPI (see issue #13 ). pyEMMA I've found the documentation and the project on PyPI . The source is on github.com/markovmodel/PyEMMA . MarkovEquClasses PyPI PyMarkov It is only about 100 lines of very simple code. It seems to be another random sentence generator. See PyPI . Hidden Markov Models The following might be interesting, but I didn't take a close look at them because I was looking for \"normal\" markov models: hmmus hmmlearn Markov treehmm There are also quite a few other modules which seem to generate data with markov chains.","tags":"Code","title":"Python Markov Chain Packages"},{"url":"https://martin-thoma.com/machine-learning-2-course/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žMachine Learning 2\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr. Marius ZÃ¶llner im Sommersemester 2015 gehÃ¶rt. Es gibt auch einen Artikel zu Machine Learning 1 . Behandelter Stoff EinfÃ¼hrung Slides: 01_Einfu__hrung_MLII.pdf RÃ¼ckblick auf ML 1 . MLNN steht Ã¼brigens fÃ¼r Multi-Layer Neural Network . Semi-Supervised Learning Slides: 02_Semi-supervised-learning.pdf Ãœberwachtes Lernen (engl. Supervised Learning ) Alle Trainingsdaten liegen mit Labels vor. UnÃ¼berwachtes Lernen (engl. Unsupervised Learning ) Alle Trainingsdaten liegen ohne Labels vor. Semi-Supervised Learning ( SSL ) Die meisten Trainingsdaten liegen ohne Labels vor, jedoch gibt es fÃ¼r jede Klasse auch gelabelte Daten. Self-Learning ( Self-Training , Self-Labeling , Decision-directed learning ) Self-Training ist ein Algorithmus zum Semi-supervised Learning. Er geht wie folgt vor: Trainiere mit gelabelten Daten. Werte ungelabelte Daten aus. FÃ¼ge Daten, bei denen sich der Klassifizierer sicher ist, zu den Trainingsdaten hinzu. ZurÃ¼ck zu Schritt 1. Dabei sind folgende Variationen vorstellbar: FÃ¼ge alle Daten hinzu. FÃ¼ge nur Daten hinzu, bei denen sich der Klassifizierer sicher ist. Gewichte Daten mit der Sicherheit. Co-Training ( Mit-Lernen ) Co-Training ist ein Algorithmus zum Semi-supervised Learning. Er geht wie folgt vor: Splitte jeden Feature-Vektor auf die gleiche Art in zwei Feature-Vektoren mit disjunkten Features auf. Trainiere zwei unterschiedliche Klassifizierer auf den beiden unterschiedlichen Feature-Mengen der gelabelten Daten. Label mit den beiden Klassifizieren die ungelabelten Daten. FÃ¼ge ungelabelte Daten dem Trainingsdatensatz (also den gelabelten Daten) hinzu, falls die Klassifizierer fÃ¼r diese eine hohe Konfidenz aufweisen. ZurÃ¼ck zu Schritt 2. Dabei sind folgende Variationen vorstellbar: Demokratisches Voting: Bei mehr als 2 Klassifizierern. Schwellwert: Nur hinzufÃ¼gen, wenn alle Klassifizierer jeweils eine Schwelle Ã¼berschreiten. Gewichtes Voting: Alle Klassifizierer zusammen mÃ¼ssen eine Schwelle Ã¼berschreiten. Low Density Separation Methoden, welche Low Density separation benutze versuchen die Entscheidungsgrenze in eine Region niedriger Dichte zu legen. Ein Beispiel ist die Transductive SVM . Weiteres: Hier kÃ¶nnte ich mir gut vorstellen, dass man eine Bachelor / Master-Arbeit macht. Man kÃ¶nnte sich groÃŸe gelabelte DatensÃ¤tze suchen, einen gewissen Teil der Labels weglassen (also einige Trainingsdaten als \"ungelabelt\" behandeln) und die verschiedenen SSL -Methoden untersuchen. Bis zu 20% gelabelte Daten hoch wÃ¤re es interessant; also z.B. (0.5%, 1%, 2%, 3%, 5%, 10%, 15%, 20% gelabelte Daten). Mit mehr gelabelten Daten kÃ¶nnte man argumentieren, dass man es sich vermutlich leisten kÃ¶nnte auch den Rest noch zu labeln. Siehe Folie 28-31. SSL and Active Learning Slides: 03_Semi-supervised+Active-learning.pdf Lagrange-Multiplikator Lagrange-Multiplikatoren sind ein Verfahren der Optimierungstheorie. Sie werden genutzt, wenn ein Optimierungsproblem mit Nebenbedingungen vorliegt. Durch sie kann die Nebenbedingung eliminiert werden. Active Learning ( Aktives Lernen ) Die Lernmaschine wÃ¤hlt die zu lernenden Daten selbst aus. Verfahren: Query Synthesis Selective Sampling Pool-Based Active Learning Query-by-Committee Query Synthesis (siehe Active Learning Literature Survey ) Der Lerner kann Feature-Vektoren (Querys) de novo , also von Grund auf neu / selbst erzeugen. Er kann fÃ¼r diesen neuen Query ein Orakel befragen, was das Label ist. Selective Sampling (Selektive Entnahme, siehe Selective sampling and active learning from single and multiple teachers ) Selective Sampling ist eine Methode des aktiven Lernens. Dabei wird jede Runde $t$ dem Lerner ein Feature-Vektor $x_t \\in \\mathbb{R}&#94;n$ prÃ¤sentiert. Der Lerner muss sich jede Runde entscheiden, ob er einen Preis bezahlt um das Label zu sehen. Der Lerner hat also zwei Ziele, die miteinander in Konflikt stehen: Er will alles richtig klassifizieren, aber zugleich die Kosten so niedrig wie mÃ¶glich halten. Pool-Based Active Learning Pool-Based Active Learning ist eine Methode des aktiven Lernens. Dabei wird von einem Pool an ungelabelten Daten $\\mathcal{U}$ ausgegangen und einem deutlich kleineren Pool $\\mathcal{L}$ an gelabelten Daten. Queries werden aus $\\mathcal{U}$ gezogen. Dabei wird ganz $\\mathcal{U}$ evaluiert und fÃ¼r den hilfreichsten Feature-Vektor $x \\in \\mathcal{U}$ nach einem Label gefragt. Hinge-Funktion $$f(x) = \\max(x, 0)$$ Query-by-Committee ( QBC ) Es wird ein Committee $\\mathcal{C}$ an Klassifikatoren trainiert, welches gemeinsam (z.B. durch majority vote) eine Klassifikation trifft. Allgemeiner Ansatz: Trainiere eine Menge $\\mathcal{C}$ an Klassifikatoren WÃ¤hle neue Daten, wenn die Hypothesen WiedersprÃ¼chlich sind Selektive Entnahme: Beobachte neue Instanz $x$ und werte diese mit $\\mathcal{C}$ aus Frage das Label ab, falls es einen Wiederspruch in den Hypothesen von $\\mathcal{C}$ fÃ¼r $x$ gibt. Neu trainiren, zurÃ¼ck zu 1 Pool-based Active Learning: Messung des Wiederspruchs der Hypothesen fÃ¼r alle Instanzen $x$ Ranking (z.B. Entropie) Abfrage der Labels fÃ¼r die $k$ widersprÃ¼chlichsten Instanzen Neu trainiren, zurÃ¼ck zu 1 Weiteres: AusreiÃŸerproblem: AusreiÃŸer sollten im QBC nicht genommen werden. Dazu kÃ¶nnte die Dichte im Datenraum gemessen werden. Reinforcement Learning Slides: 04_Reinforcement_Learning_II.pdf Siehe auch: Probabilistische Planung Neuronale Netze Machine Learning 1 Cat vs. Mouse code Berkeley CS188 Intro to AI: Project 3: Reinforcement Learning Dan Klein, Pieter Abbeel: Lecture 10: Reinforcement Learning on YouTube. University of California, Berkeley. This expalins TD-learning. Markov Decision Process ( MDP ) Ein Markovscher Entscheidungsprozess ist ein 5-Tupel $(S, A, T, r, p_0)$, wobei $S$ eine endliche Zustandsmenge, $A$ eine endliche Menge von Aktionen, $T_a(s, s') = T(s_{t+1}=s'|s_t = s, a_t = a)$ die Wahrscheinlichkeit zu einem beliebigen Zeitpunkt von Zustand $s$ mit der Aktion $a$ in den Zustand $a'$ zu kommen (engl. Transition), $r_a(s, s')$ ist die Belohnung (Reward), die man direkt erhÃ¤lt wenn man erhÃ¤lt wenn man von Zustand $s$ mit Aktion $a$ in Zustand $s'$ kommt, $p_0$ ist die Startverteilung auf die ZustÃ¤nde $S$ Partially observable Markov decision process ( POMDP ) Ein partially observable Markov decision process ist ein 7-tupel $S, A, T, R, \\Omega, O, \\gamma$ , wobei $S$ die Zustandsmenge, $A$ die Aktionsmenge, $T: S \\times A \\times S \\rightarrow \\mathbb{R}$ die probabilisitische ZustandsÃ¼bergangsfunktion (transition function) ist, $R: S \\times A \\rightarrow \\mathbb{R}$ die Reward-Funktion, $\\Omega$ die Menge der mÃ¶glichen Beobachtungen, $O$ die Wahrscheinlichkeit der Beobachtungen, gegeben ein Zustand und eine Aktion und $\\gamma \\in [0, 1]$ der Diskontierungsfaktor ist. Options Eine Option ist wohl-definiertes Verhalten, welches im hierarchischen RL eingesetzt werden kann. Es ist ein Baustein fÃ¼r komplexe PlÃ¤ne. Options werden in Semi-MDPs eingesetzt und ersetzen dort die Aktionen. Hierarchien Abstrakter Maschinen ( HAM ) Ein MDP wird mit Maschinen $\\{M_i\\}$ kombiniert. Jede Maschine reprÃ¤sentiert einen Teil der Policy. Jede Maschine verwendet eigene ZustÃ¤nde $m_t&#94;i$ und globale ZustÃ¤nde $s_t$. Maschinen werden durch Zustandsautomaten abgebildet. MaxQ-Dekomposition (siehe [ Die00 ]) Das zu lÃ¶sende MDP $M$ wird als Menge von Unteraufgaben $\\{M_0, \\dots, M_n\\}$ interpretiert. Dabei ist $M_0$ das Haupt-MDP. TODO. Folie 35: NODO: Was heiÃŸt hier \"mit festen Knoten\"? Dynamische Bayessche Netze Slides: 05_DynamischeBayesscheNetze.pdf Multiplikationssatz Seien $A, B, X_i$ Ereignisse. Dann gilt: $$P(X_1, \\dots, X_n) = P(X_1) \\cdot \\prod_{k=2}&#94;n P(X_k | X_{k-1}, \\dots, X_1)$$ und insbesondere $$P(A\\cap B) = P(A, B) = P(A\\mid B) \\cdot P(B)$$ Gesetz der totalen Wahrscheinlichkeit Seien $A_1, \\dots, A_n$ paarweise disjunkte Ereignisse mit $A = \\sum_{i=1}&#94;n A_i$. Dann gilt fÃ¼r jedes beliebige Ereignis $B$: $$P(B) = \\sum_{i=1}&#94;n P(B | A_i) \\cdot P(A_i) = P(A_i, B)$$ Satz von Bayes Seinen $A, B$ Ereignisse mit $P(B) > 0$. Dann gilt $$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$ Hierbei heiÃŸt $P(A|B)$ die a posteriori Wahrscheinlichkeit , $P(B|A)$ die likelihood , $P(A)$ die a priori Verteilung Ã¼ber $A$ und $P(B)$ die a priori Verteilung Ã¼ber $B$ . Bayessches Netz (Siehe Lecture 13: Bayes Nets ) Ein Bayessches Netz ist ein DAG , bei dem die Knoten Zufallsvariablen und die Kanten bedingte AbhÃ¤ngigkeiten beschreiben. Bayessche Netze sind zur Modellierung kausaler ZusammenhÃ¤nge geeignet. Markov Random Field Siehe ML 1 Dynamisches Bayessches Netz Dynamische Bayessche Netze sind Bayessche Netze zur Beschreibung dynamischer Prozesse. Markov Blanket Sei $G=(V,E)$ ein DAG zu einem Bayesschen Netz und $v_S \\in V$. Dann ist der Markov Blanket die folgende Knotenmenge $B \\subseteq V \\setminus \\{v_S\\}$: Die Elternknoten von $v_S$ sind in $B$. Die Kindknoten $K = \\{v_{K_1}, \\dots, v_{K_n}\\}$ sind in $B$ Die Elternknoten von $K$, ausgenommen von $v_S$, sind in $B$ Diese Knotenmenge macht $v_S$ unabhÃ¤ngig von anderen Knoten. Naive Bayes Spam Filter Ein naiver Bayes Spamfilter nutzt hÃ¤ufig Bag-of-Words Features. Man berechnet die Wahrscheinlichkeit, dass eine gegebene E-Mail Spam ist. Dazu geht man davon aus, dass die WÃ¶rter in einer E-Mail unabhÃ¤ngig von einander sind und nutzt den Satz von Bayes. Siehe Bayes-Klassifikator fÃ¼r eine detailiertere Beschreibung. Bayes Filter Ein Bayes Filter ist eine Familie von Zufallsvariablen. Das kÃ¶nnte z.B. die $(x,y,z)$ Position eines GPS-Sensors sein. Diese Position ist verrauscht. Nun gibt es drei mÃ¶gliche Anfragen: Filtern : Es liegen Messungen $Z_0, \\dots, Z_t$ vor, sage die aktuelle Position $X_t$ vorher. Also filtere das Rauschen aus $Z_t$ unter berÃ¼cksichtigung, dass wir uns noch nicht teleportieren kÃ¶nnen: $$P(X_t | Z_t, \\dots, Z_0)$$ PrÃ¤dizieren : Es liegen Messungen $Z_0, \\dots, Z_t$ vor, sage die Position $X_{t+k}$ vorher: $$P(X_{t+k} | Z_t, \\dots, Z_0)$$ GlÃ¤tten : Es liegen Messungen $Z_0, \\dots, Z_t$ vor, sage die Position $P(X_{t-k} | Z_t, \\dots, Z_0)$ vorher. Beispiele fÃ¼r Bayes-Filter sind Kalman-Filter HMM Partikel Filter Naiver Bayes'scher Spam Filter Ein probabilistischer Klassifikator welcher die UnabhÃ¤ngigkeit der Features vorraussetzt wird naiv genannt. Der naive bayessche Spam Filter nutzt Bayes Theorem um die Wahrscheinlichkeit zu berechnen, dass eine E-Mail Spam ist. Kalman-Filter Der Kalman-Filter ist ein Bayes-Filter. Er wird z.B. zum SchÃ¤tzen einer Fahrzeugtrajektorie eingesetzt. Der Kalman-Filter besteht aus zwei Schritten: Predict the next step of the system given the previous measurements. Update the estimate of the current state given the measurement of this time step. Siehe Kalman-Filter Artikel fÃ¼r Details. Expectation Maximizaion Algorithm ( EM-Algorithmus ) Der EM-Algorithmus ist ein Clusteringalgorithmus mit weicher ClusterzugehÃ¶rigkeit. Er findet die Parameter fÃ¼r gegebene Verteilungen (Ã¼blicherweise multivariate Normalverteilungen). Er lÃ¶st das Henne-Ei Problem Wenn man weiÃŸ wie genau die Wahrscheinlichkeitsverteilungen der Cluster parametrisiert sind ist es leicht die Daten den Clustern zuzuordnen. Wenn man die Daten einem Cluster zuordnen kann, dann ist es leicht die Parameter der Wahrscheinlichkeitsverteilung zu schÃ¤tzen. Wenn man sowohl ClusterzugehÃ¶rigkeit als auch die Parameter der Verteilung schÃ¤tzen muss ist es schwer. Man kann \"zufÃ¤llig\" die initialen Parameter wÃ¤hlen, dann die Zuordnung machen. Der EM-Algorithmus iteriert nach der initialisierung der Parameter: Expectation : SchÃ¤tze fÃ¼r jeden Datenpunkte die ClusterzugehÃ¶rigkeit. Maximization : Parameter der Cluster neu berechnen. Also fÃ¼r jeden Cluster $A$ $\\mu_A = \\frac{\\sum_{i=1}&#94;N w_{i, A} \\cdot x_i}{\\sum_{i=1}&#94;N w_{i, A}}$ $\\sigma_A&#94;2 = \\frac{\\sum_{i=1}&#94;N w_{i,A} (x_i + \\mu_A)&#94;2}{\\sum_{i=1}&#94;N w_{i,A}}$ wobei $w_{i,A}$ die Wahrscheinlichkeit der ZugehÃ¶rigkeit des Punktes $i$ zu Cluster $A$ ist. Der EM-Algorithmus ist mit $k$-means verwandt. Siehe Mixture Models 1: the EM algorithm Typische Fragestellungen: Gegeben ist die Struktur eines Bayesschen Netzes: Wie lautet die Verteilung? Dies wird Ã¼blicherweise mit dem EM -Algorithmus gelÃ¶st. AnwendungsfÃ¤lle: Automatische Diagnose, gegeben die Symptome (Bayessches Netz) Fahrzeugverfolgung: Vorhersage von Routen, welche die Fahrzeuge nehmen werden (Dynamisches Bayessches Netz) Anmerkungen: Die Folien sind hier sehr gut! Insbesondere Folie 14-23 sollte man sich ansehen. Es scheint folgende Beziehung zu gelten: HMMs, Kalman-Filter, Extended Kalman-Filter, Partikel Filter sind Beispiele fÃ¼r Bayes-Filter. Bayes-Filter sind Beispiele fÃ¼r dynamische Bayessche Netze. Siehe auch: Udacity: Artificial Intelligence for Robotics - good content for Kalman Filters Tracking Robots Probabilistic Graphical Models Probablistisch Relationale Modelle Slides: 06_Probablistisch_Relationale_Modelle.pdf Siehe auch: C. Howard and M. Stumptner and others. Model Construction Algorithms for Object-Oriented Probabilistic Relational Models. FLAIRS Conference, 2006. C. Howard and M. Stumptner. Situation assessments using object oriented probabilistic relational models , in 8th International Conference on Information Fusion, 2005, vol.2. doi: 10.1109/ICIF.2005.1592031 Objektorientierte Probablistisch Relationales Modelle ( OPRM ) Ein OPRM besteht nach [ Schu15 ] aus Eine Klassenmenge $\\mathbf{C} = \\{C_1, \\dots, C_n\\}$, einer partiellen Ordnung Ã¼ber C, welche die Klassenhierarchie definiert, einer Menge einfacher, nicht probabilisitscher Attribute $\\Lambda_C = \\{\\lambda_1, \\dots, \\lambda_n \\forall C \\in \\mathbf{C}\\}$, einer Menge beschreibender Attribute $\\Delta_C = \\{\\delta_1, \\dots, \\delta_n\\} \\forall C \\in \\mathbf{C}$, einer Menge komplexer Attribute $\\Phi_C = \\{\\phi_1, \\dots, \\phi_n\\} \\forall C \\in \\mathbf{C}$. Die komplexen Attribute beschreiben funktionale Beziehungen zwischen Klassen. Dieses Modell wurde in libDAI umgesetzt. Gaussche Prozesse Slides: 07_Gaussche_Prozesse.pdf I suggest reading the first two chapters of the online book gaussianprocess.org before starting to read the slides. See also: Function Approximation The Talking Machines: OpenAI and Gaussian Processes Lineare Regression Die lineare Regression ist ein Modell zur approximation von Datenpunkten $(x, y) \\in \\mathbb{R}&#94;n \\times \\mathbb{R}$ durch eine lineare Funktion, d.h. einer Funktion der Form $f(x) = x&#94;T \\cdot w$. Dabei ist $w \\in \\mathbb{R}&#94;n$. Wenn man als Optimierungskriterium den quadratischen Abstand $$E(f, data) = \\sum_{(x,y) \\in data} (f(x) - y)&#94;2$$ nimmt, dann ist eine optimale LÃ¶sung durch $$w = (X&#94;T X)&#94;{-1} X&#94;T y$$ gegeben. Siehe auch: Proof of when is $A=X&#94;T X$ invertible? sowie Does a transformation + linear regression give the same regression as fitting a quadratic function? Affine Regression Die affine Regression ist ein Modell zur approximation von Datenpunkten $(x, y) \\in \\mathbb{R}&#94;n \\times \\mathbb{R}$ durch eine affine Funktion, d.h. einer Funktion der Form $f(x) = x&#94;T \\cdot w + b$. Dabei ist $w \\in \\mathbb{R}&#94;n, b \\in \\mathbb{R}$. Um das Problem auf ein lineares zu reduzieren kann man den Feature-Vektor $x$ durch ein konstantes Feature $x_0 = 1$ erweitern. Korrelationskoeffizient Der Korrelationskoeffizient $\\kappa(X, Y) \\in [-1, 1]$ ist ein MaÃŸ fÃ¼r den linearen Zusammenhang zwischen zwei Zufallsvariablen $X, Y$. Er ist definiert als $$\\kappa(X, Y) := \\frac{Cov(X, Y)}{\\sigma(X) \\cdot \\sigma(Y)}$$ Gausscher Prozess ( Kriging , Machine learning - Introduction to Gaussian processes by Nando De Freitas) Gaussche Prozesse approximieren eine Funktion dadurch, dass sie an jedem Punkt eine Normalverteilung (Gauss-Verteilung) annehmen. Siehe Gaussian process regression . Deep Learning Slides: 08_DeepLearning.pdf Siehe auch: Neuronale Netze Vorlesung Udacity: Neural Networks for Machine Learning by Hinton. Deep Belief Netz ( DBN ) Ein Deep Belief Netz ist ein gerichtetes, azyklisches, probabilistisches graphisches Modell. Restricted Boltzmann machine ( RBM ) Siehe Neuronale Netze Contrastive Divergence ( CD , CD-$k$ ) Siehe Neuronale Netze Contrastive Wake-Sleep Algorithm (siehe The wake-sleep algorithm von Hinton - Lecture 13d aus \" Neural Networks for Machine Learning \") Der Wake-Sleep Algorithmus ist ein Trainingsalgorithmus fÃ¼r gerichtete graphische Modelle wie Sigmoid Belief Networks. Er ist nicht fÃ¼r RBMs. Man hat im Grunde zwei Netzwerke mit der gleichen Topologie, jedoch ist die Richtung vertauscht: Das eine Netz stellt die Hypothese aus den Daten auf, das andere Netz geniert neue Daten aus einer gegebenen Hypothese. In der wake phase wird die Eingabe genutzt um die Hypothese zu erzeugen. In dieser Phase werden die Gewichte fÃ¼r das Generative Modell trainiert. Dieses soll die Aktivierung der vorhergehenden Schicht rekonstruieren. In der sleep phase wird das generative Modell genutzt um aus dem Modell samples zu erzeugen. Dann trainiert man die Gewichte des erkennenden Netzes (also vergleichbar mit der wake phase, nur anders rum). Siehe A Fast Learning Algorithm for Deep Belief Nets Probleme von Tiefen Netzen und wie man sie lÃ¶sen kann: Lange Trainingsdauer : GPUs / mehr Rechenpower / weniger Parameter durch Parameter sharing, z.B. in CNNs / TDNNs Extrem viele gelabelte Trainingsdaten werden benÃ¶tigt : Internet (z.B. Wikipedia, Soziale Netzwerke, Amazon Mechanical Turk) reduziert dieses Problem; Nutzen ungelabelter Daten durch SSL in Auto-Encodern Lokale Minima Overfitting : Regularisation Siehe auch MNIST Demo (Flash): Neuronales Netz welches Ziffern generiert Geoffry Hinton: Deep Learning on YouTube, 2015. 43 minutes. (Topics: RBMs) Convolutional Neural Networks Slides: 09_ConvolutionalNeuralNetworks.pdf Siehe auch: Neuronale Netze Vorlesung Convolutional Neural Networks ( CNNs ) CNNs sind neuronale Netze welche weight sharing einsetzen. Sie setzen eine diskrete Faltung um. Ein CNN muss mindestens einen Convolutional Layer haben. Dieser hat folgende Parameter: Padding: None, Zero, Copy Stride: $s \\in \\mathbb{N}_{> 0}$ Filter Size: $(x,y) \\in \\mathbb{N}&#94;2$ Number of filters: How many filters should get learned? Feature Map Nach einem Convolutional Layer hat man die Ausgabe der Filter, welche auf die Eingabe angewandt wurden. Diese nennt man Feature Map . FÃ¼r jeden Filter bekommt man eine Feature Map. Die Feature Maps sind wiederum Eingaben fÃ¼r die nÃ¤chsten Schichten. Pooling Layer Ein pooling layer ist eine Schicht in einem CNN, welche Features zusammenfasst. Pooling Schichten haben folgende Parameter: GrÃ¶ÃŸe: Typischerweise $3 \\times 3$ Stride $s \\in \\mathbb{N}$: Typischerweise gleich der GrÃ¶ÃŸe des Pooling-Bereichs (also 3). Art: max, mean Typischerweise reduziert sie die Anzahl der Features, da typischerweise ein $s > 1$ gewÃ¤hlt wird. Spiking Neural Nets Slides: 10_SpikingNeuralNets.pdf Spiking Neural Networks Gepulste neuronale Netze versuchen natÃ¼rliche neuronen realistisch abzubilden. Das Hodgkin-Huxley Neuronenmodell wurde bereits 1952 vorgestellt. Hodgkin-Huxley Neuronenmodell Das Hodgkin-Huxley Neuronenmodell modelliert die elektrochemischen VorgÃ¤nge innerhalb eines Neurons mit elektrischen Baugliedern. Dies resultiert in Differenzialgleichungen mit 4 Variablen (KapazitÃ¤t der Membran, WiderstÃ¤nde der IonenkanÃ¤le, Gleichgewichtspotentiale, Ã–ffnung der IonenkanÃ¤le). Das Modell ist realistisch, aber sehr komplex. LIF Neuronenmodell (Leaky integrate and Fire) Das LIF Neuronenmodell modelliert ein Neuron durch eine gewÃ¶hnliche Differentialgleichung erster Ordnung. SRM Neuronenmodell (Spike Response Model) Das SRM Neuronenmodell modelliert die Refraktionszeit. Das ist die Zeit, in der kein neues Aktionspotential aufgebaut werden kann. Das SRM ist ein rein phÃ¤nomenologisches Modell, welches trotz der Einfachheit allgemeiner ist als das LIF-Modell. Evaluation Slides: 11_Evaluation.pdf FÃ¼r Klassifikation: Konfusionsmatrix Eine Konfusionsmatrix ist eine Tabelle, in welcher die Spalten angeben, welche Hypothese gemacht wurde (Testentscheid) und die Zeilen den wahren Wert angeben. So kann fÃ¼r beliebig viele Klassen gezeigt werden, wie gut der Klassifikator ist und welche Art der Verwechslung er macht. Klassifikationsfehler $\\text{Klassifikationsfehler} = \\frac{\\text{Fehlerhafte Hypothesen}}{\\text{Anzahl aller Beispiele}} \\in [0, 1]$ KlassifikationsgÃ¼te KlassifikationsgÃ¼te = 1 - Klassifikationsfehler False Alarm Rate ( FA , Falsch Positiv Rate , FPR ) Es sei FP die Anzahl der False Positive Testdaten, also der Testdaten fÃ¼r welche Positive vorhergesagt wurde, die aber negative sind. Weiter sei TN die Anzahl der True Negatives, also der Testdaten, fÃ¼r welche korrekterweise negative vorhergesagt wurde. Dann ist die FPR definiert als $$\\text{FPR} := \\frac{FP}{FP + TN} \\in [0, 1]$$ Die FPR gibt also den Anteil an, wie viele der tatsÃ¤chlich negativen fÃ¤lschlicherweise als positiv erkannt wurden. Miss-Rate ( MR , Falsch Negativ Rate , FNR ) $$FNR := \\frac{FN}{TP + FN} \\in [0, 1]$$ Recall ( True Positive Rate , TPR , SensitivitÃ¤t ) $$TPR = \\frac{TP}{TP + FN} = 1 - FNR \\in [0, 1]$$ Der Recall gibt den Anteil der erkannten positiven aus allen positiven an. SensitivitÃ¤t ist ein in der Medizin Ã¼blicher Begriff. Precision ( Genauigkeit ) $$Precision = \\frac{TP}{TP + FP} \\in [0, 1]$$ Die Precision gibt den Anteil der real positiven aus den als positiv erkannten an. ROC-Graph ( Receiver-Operator Curve ) Der ROC-Graph gibt fÃ¼r einen Klassifikator, bei dem man einen Parameter einstellen kann, den Fehler an. Die $x$-Achse ist dabei die FPR, die $y$-Achse die TPR. SpezifitÃ¤t Der Begriff der SpezifitÃ¤t ist in der Medizin Ã¼blich und ist definiert durch $$SpezifitÃ¤t = \\frac{TN}{TN + FP} = 1 - FPR$$ Es ist eine Art recall fÃ¼r die negative Klasse. Im Beispiel eines medizinischen Tests wÃ¤re das der Anteil der Gesunden, bei denen tatsÃ¤chlich auch die Diagnose \"Gesund\" gestellt wurde. PRC-Graph ( Precision-Recall-Graph ) Die $x$-Achse ist Recall, die $y$-Achse ist Precision. F-MaÃŸ $$F_\\alpha = \\frac{precision \\cdot recall}{\\alpha&#94;2 \\cdot precision + recall}$$ Alternative: Aufstellen einer Kostenfunktion und optimieren nach Kosten. Plotten der Anzahl der Trainingsdaten ( \\(x\\) -Achse) und des Fehlers ( \\(y\\) -Achse). Die Kurven sollten der Test-Fehler sowie der Trainingsfehler sein. Damit lÃ¤sst sich abschÃ¤tzen, ob mehr Trainingsdaten ohne eine VerÃ¤nderung des Modells hilfreich sind. FÃ¼r Regression Mittlerer Quadratischer Fehler ( MSE , Mean Squared Error ) $$E(f, data) = \\frac{1}{|data|} \\sum_{(x, y) \\in data} (f(x) - y)&#94;2$$ Relativer Quadratischer Fehler $$E(f, data) = \\frac{\\sum_{(x, y) \\in data} (f(x) - y)&#94;2}{\\sum_{(x,y) \\in data} (y - \\mu)&#94;2}$$ Mittlerer Absoluter Fehler $$E(f, data) = \\frac{1}{|data|} \\sum_{(x, y) \\in data} |f(x) - y|$$ Siehe auch Beurteilung eines binÃ¤ren Klassifikators False positives and false negatives Matt Zeiler: Visualizing and Understanding Deep Neural Networks on YouTube, 2015. 48 minutes. PrÃ¼fungsfragen Was versteht man unter einer \"Transductive SVM\"? â†’ Eine Transductive SVM ist eine SVM welche neben gelabelten Daten auch noch ungelabelte benutzt. Sie versucht die Trennebene durch eine Region geringer Dichte zu legen. Wie lautet die Optimierungsformel der transductive SVM? â†’ $$\\text{minimize}_{w, b, y&#94;*} \\frac{1}{2} \\|w\\|&#94;2$$ unter den Nebenbedingungen $$\\forall i \\in 1, \\dots, n: y_i (w \\cdot x_i - b) \\geq 1$$ und $$\\forall j \\in 1, \\dots, k: y_j&#94;* (w \\cdot x_j&#94;* -b) \\geq 1\\text{ with }y_j&#94;* \\in \\{-1, 1\\}$$ Dabei sind $D&#94;* = \\{x_i&#94;* | i = 1, \\dots, k\\}$ ungelabelte Daten. Was macht man im Reinforcement Learning, wenn Aktionen lÃ¤nger dauern? â†’ Options verwenden (TODO: Wie Ã¤ndert sich die Value Iteration Formel nun bzgl. der Zeit?) Warum heiÃŸen POMDPs \"Partially Observable\"? â†’ Weil der Agent zwar Feedback Ã¼ber die Umgebung bekommt, aber nicht direkt erfÃ¤hrt in welchem Zustand er ist. Siehe Definition . Welche Active Learning Techniken gibt es? â†’ Query / Selective / Pool-based (vgl. Query-by-Committee ) Wie nennt man ein instanziiertes OPRM? â†’ TODO (Skelett?) Wie funktioniert aktives Lernen bei SVMs? â†’ Bei SVMs gibt es die DualitÃ¤t zwischen dem Feature-Space und dem Hypothesenraum. In dem Feature-Space stellen die Achsen $x_i$ die Features dar, Trainingsdaten Punkte sind und die SVM durch die Trennebene visualisiert wird. Im Hypothesenraum sind die Achsen $w_i$ zusammen der Normalenvektor der SVM, die verschiedenen Trennebenen der SVMs sind hier Punkte. Die Daten geben Bedingungen an die SVM vor, welche in diesem Raum als Hyperebenen dargestellt werden kÃ¶nnen. Der Margin ist in diesem Raum ein Kreis, der die Bedingungs-Hyperebenen berÃ¼hrt. Beim aktiven lernen versucht man den Version-Space im Inneren der Bedungungs-Hyperebenen so schnell zu verkleinern wie mÃ¶glich. Was versteht man unter Transduktivem Lernen? â†’ Unter Transduktiver Inferenz versteht man das SchlieÃŸen von Trainingsbeispielen direkt auf auf spezifische TestfÃ¤lle. Wie nennt man die Wahrscheinlichkeit des aktiellen Zustands in POMDPs? â†’ Belief. Material und Links Vorlesungswebsite Ilias : Ist passwortgeschÃ¼tzt Zusammenfassung der Vorlesung ML 1 Literatur [ Schu15 ] J. Schulz. Erkennung von Interaktionen zwischen Verkehrsteilnehmern zur VerhaltensprÃ¤diktion. Masterarbeit am FZI. Karlsruhe, 2015. Man kann Florian Kuhnt um Zugang dazu fragen. [ Die00 ] T. Dietterich. Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition . Journal of Artificial Intelligence Research, 2000. Ãœbungsbetrieb Es gibt keine ÃœbungsblÃ¤tter, keine Ãœbungen, keine Tutorien und keine Bonuspunkte. Vorlesungsempfehlungen Folgende Vorlesungen sind Ã¤hnlich: Analysetechniken groÃŸer DatenbestÃ¤nde Informationsfusion Machine Learning 1 Machine Learning 2 Mustererkennung Neuronale Netze Lokalisierung Mobiler Agenten Probabilistische Planung Kontakt goettl@fzi.de: Sonja GÃ¶ttl (Sekretariat, zum Anmelden zur mÃ¼ndlichen PrÃ¼fung) Termine und Klausurablauf Datum : Freitag, der 29.07.2016 von 12:30-13:30 Uhr Ort : HÃ¶rsÃ¤le Hertz, Gr. HS und MTI Zeit : 60 min Ãœbungsschein : gibt es nicht Bonuspunkte : gibt es nicht Ergebnisse : werden ca. 5 - 10 min. nach der mÃ¼ndlichen PrÃ¼fung gesagt Erlaubte Hilfsmittel : keine","tags":"German posts","title":"Machine Learning 2"},{"url":"https://martin-thoma.com/mustererkennung-klausur/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žMustererkennung\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr.-Ing. JÃ¼rgen Beyerer im Sommersemester 2015 gehÃ¶rt und einige Abschnitte direkt aus den Folien Ã¼bernommen. Behandelter Stoff Vorlesung Datum Kapitel Inhalt 15.04.2015 Einleitung $\\hat{w}$ - das &#94; bedeutet, dass die Klasse geschÃ¤tzt ist. 22.04.2015 Kapitel 2 - Merkmale : 1-31? Welt; DomÃ¤ne; Objekte; Klassen; Merkmalsraum; Merkmalsvektor; Klassifikation; Skalen (nominal, ordinal, intervall-, verhÃ¤ltnis- und absolutskaliert); Projektionen; Norm (Minkowski, Euklidisch, Chebychev, Mahalanobis); Metrik (Tanimoto) 14.07.2015 Kapitel 8 - Klassifikatoren (1-28), Kapitel 9 : 1-? EntscheidungsbÃ¤ume, Grammatiken; Lernen nach Vapnik, VC-Dimension, Kreuzvalidierung und Leave-One-Out, Boosting Folien ME-Kap1_V31.pdf Einleitendes Kapitel welches erklÃ¤rt, was Klassifikation ist. Beispiele fÃ¼r Klassifikation: Blumen/Schmetterlinge in Arten; Schrauben in Schraubentypen; SchÃ¼ttgut in Mineralien, Pflanzen, Glasscheiben, Diamante, ... Formalismen DomÃ¤ne \\(\\Omega \\subseteq\\) Welt, Elemente der DomÃ¤ne heiÃŸen Objekte, Objekte werden in paarweise disjunkte Ã„quivalenzklassen \\(\\omega_i\\) gruppiert, sodass jedes Objekt genau eine Ã„quivalenzklasse hat. Man beobachtet / misst Eigenschaften realer Objekte. Dies kann als Funktion m aufgefasst werden, die von der DomÃ¤ne in den Merkmalsraum abbildet. Optimalerweise ist diese Abbildung injektiv, bei ungÃ¼nstig gewÃ¤hlten Merkmalen jedoch nicht. Klassifikatoren arbeiten auf dem Merkmalsraum und finden eine Partition des Merkmalsraumes in Klassen Muster : Gesamtheit der beobachteten / gemessenen Werte einer einzelnen Stichprobe (eines einzelnen Objekts). Erkennung : (Wieder)erkennung von etwas, was bereits bekannt ist. Merkmale : eruirbare, charakteristische Eigenschaften, die als Basis fÃ¼r die Untersuchung von Mustern dienen soll. Mustererkennungsschritte : Sensierung ergibt Muster; Vorverarbeitung; Segmentierung; Merkmalsextraktion ergibt Merkmale; Klassifikation ergibt Ã„quivalenzklassen Ãœberwachtes lernen : Vorklassifizierte Beispiele sowie die Klassenstruktur sind gegeben; eventuell auch Auftrittswahrscheinlichkeiten \\(P(\\omega_i)\\) der Klassen Gesamtstichprobe wird in die disjunkten Mengen Lernstrichprobe, Validierungsstichprobe und Teststichprobe zerlegt. Merkmale Slides: ME-Kap2_V84.pdf In diesem Foliensatz geht es um Merkmale und ihre Eigenschaften. Skala qualitativ (kategorial) quantitativ (metrisch) Nominal- Ordinal- Intervall- VerhÃ¤ltnis- Absolut Empirische Relation ~ Ã„quivalenz ~ Ã„quivalenz Ordnung ~ Ã„quivalenz Ordnung Emp. Addition ~ Ã„quivalenz Ordnung Emp. Addition Emp. Multipliation ~ Ã„quivalenz Ordnung Emp. Addition Emp. Multipliation ZulÃ¤ssige Transformationen m' = f(m) f bijektiv m' = f(m) f streng monoton m' = am+b mit a>0 m' = am mit a>0 m' = m Beispiele zugehÃ¶rige Merkmale Telefonnummern, Kfz-Kennz., Typen, PLZ, Geschlecht GÃ¼teklassen, HÃ¤rtegrad, WindstÃ¤rke Temp. in Â°C, Â°F, Kalenderzeit, geographische HÃ¶he Masse, LÃ¤nge, el. Strom Quantenzahlen, Teilchenanzahl, Fehlerzahl Werte von m Zahlen, Namen, Symbole in der Regel natÃ¼rliche Zahlen in der Regel reele Zahlen in der Regel reele Zahlen > 0 in der Regel natÃ¼rliche Zahlen Der Merkmalsraum ist hÃ¤ufig ein \\(\\mathbb{R}&#94;n\\) mit \\(n>3\\) . Er kann auf vorhandene Strukturen analysiert werden, indem er auf einen 2- oder 3-dimensionalen unterraum projeziert wird. Dies kann bei einfachen Projektionen jedoch nicht erfolgreich sein, wenn beispielsweise zwei Klassen SchalenfÃ¶rmig um den Urspruch angeordnet sind. Um Stichproben im Merkmalsraum zu vergleichen kÃ¶nnen Metriken benutzt werden. Eine Metrik ist eine Abbildung \\(d(m_1, m_2)\\) , fÃ¼r die gilt: Positive Definitheit: \\(d(m_1, m_2) \\geq 0\\) und \\(d(m_1, m_2) = 0 \\Leftrightarrow m_1 = m_2\\) , Symmetrie: \\(d(m_1, m_2) = d(m_2, m_1)\\) , Dreiecksungleichung: \\(d(m_1, m_2) \\leq d(m_1, m_3) + d(m_3, m_2)\\) Metriken kÃ¶nnen durch Normen erzeugt werden, indem \\(d(m_1, m_2) := \\|m_1 - m_2\\|\\) definiert wird. Eine Norm ist eine Abbildung \\(\\| \\cdot \\|: V \\rightarrow \\mathbb{R}_0&#94;+, x \\mapsto \\|x\\|\\) fÃ¼r die gilt: Definitheit: \\(\\|x\\| = 0 \\Rightarrow x = 0\\) Absolute HomogenitÃ¤t: \\(\\|\\alpha \\cdot x \\| = \\alpha \\cdot \\| x \\|\\) Dreiecksungleichung: \\(\\|x+y\\| \\leq \\|x\\| + \\|y\\|\\) Typische Normen sind die euklidische Norm und die Mahalanobis Norm \\(\\|m\\| := \\sqrt{m&#94;T A m}\\) mit \\(A\\) positiv definit. Hauptkomponentenanalyse (HKA, engl. PCA) Finde \\(m_0\\) , sodass \\(J_0(m) := \\sum_{k=1}&#94;N \\|m - m_k\\|&#94;2\\) minimal ist, also \\(m_0 = \\frac{1}{N} \\sum_{k=1}&#94;N m_k\\) Finde Gerade \\(h: m = \\bar{m} + ae\\) , welche die Punkte optimal reprÃ¤sentiert. Finden der \\(a_k\\) (TODO: Was ist das?) FehlermaÃŸ \\(J_1(a_1, \\dots, a_N, e) = \\sum_{k=1}&#94;N \\|\\bar{m} + a_k e - m_k \\|&#94;2\\) . Ergibt: \\(a_k = e&#94;T (m_k - \\bar{m})\\) Berechnung des optimalen Richtungsvektors Streumatrix \\(S := \\sum_{k=1}&#94;N (m_k - \\bar{m}) (m_k - \\bar{m})&#94;T\\) Finden eines affinen \\(d'\\) -dimensionalen Unterraumes des Merkmalsraumes, welcher die Daten \\(D\\) mit minimalen quadratischem Fehler reprÃ¤sentiert. Siehe gist fÃ¼r eine kurze Python-Implementierung. Keine Garantie fÃ¼r die Korrektheit! Kernelized PCA Independent Component Analysis (ICA) Multiple Discriminant Analysis (MDA) ME-Kap3_V52.pdf Bayessche Klassifikatoren wÃ¤hlen die Klasse aus, die die grÃ¶ÃŸte Wahrscheinlichkeit besitzt. Dazu verfolgt man den Ansatz $$P(\\omega|m) = \\frac{p(m|\\omega) \\cdot P(\\omega)}{p(m)}$$ Dabei wird \\(P(\\omega|m)\\) die A Posteriori Wahrscheinlichkeitsverteilung und \\(P(\\omega)\\) die A Priori Wahrscheinlichkeitsverteilung genannt. ME-Kap4_V33.pdf ParameterschÃ¤tzung kann entweder mit der Likelihood-Methodik oder mit der Bayesschen Methodik durchgefÃ¼hrt werden. Die Idee der Likelihood-Methodik ist es, den Parameter \\(\\theta\\) als unbekannte konstante (d.h. nicht-stochastische) GrÃ¶ÃŸe anzusehen. Man wÃ¤hlt \\(\\theta\\) also so, dass die Wahrscheinlichkeit der Beobachtungen gegeben \\(\\theta\\) maximiert wird. Die Bayessche Methodik geht dagegen davon aus, dass \\(\\theta\\) auch eine Zufallsvariable ist und Ã¼ber eine Wahrscheinlichkeitsverteilung beschrieben werden kann. SchÃ¤tzer kÃ¶nnen verschiedene QualitÃ¤tskriterien erfÃ¼llen, z.B. Erwartungstreue oder Konsistenz . Bei der ParameterschÃ¤tzung kÃ¶nnen folgende Fehler passieren: Bayesscher Fehler: (TODO: Was ist das?) Modellfehler: Unpassendes Modell gewÃ¤hlt (Falsche Verteilungsannahme?) SchÃ¤tzfehler: Zu wenige Daten um Parameter korrekt zu bestimmen ME-Kap5_V31.pdf Parameterfreie Methoden heiÃŸen \"parameterfrei\", weil sie keine konkrete Wahrscheinlichkeitsverteilung parametrisieren und den Parameter schÃ¤tzen. Die Parameterfreien Methoden kÃ¶nnen sehr wohl Parameter benutzen. Beispiele sind: Parzen Window NÃ¤chste Nachbarn ME-Kap6_V18.pdf Allgemeine Problemstellungen : Dimension des Merkmalsraumes Overfitting ME-Kap7_V54.pdf Spezielle Klassifikatoren : Lineare Diskriminanzfunktionen: Linear bezieht sich hier auf die Kombination der Merkmale. Man kann allerdings Merkmale wÃ¤hlen, die z.B. das quadrat eines gemessenen wertes sind. Perzeptron Lineare Regression KÃ¼nstliche Neuronale Netze Support Vector Machines (SVMs) Matched Filter HMMs (Sequenzen) Klassifikation mit RÃ¼ckweisung (Maximum / Minimum / Differenz / Abstand) ME-Kap8_V21.pdf Klassifikation bei nominalen Merkmalen : EntscheidungsbÃ¤ume String-Verfahren Grammatiken ME-Kap9_V27.pdf KlassifikatorunabhÃ¤ngige Prinzipien : Generalisierung / GeneralisierungsfÃ¤higkeit VC-Konfidenz / VC-Dimension Structural Risc Minimization Kreuzvalidierungsverfahren / Leave-one-out Boosting PrÃ¼fungsfragen Warum ist ein hochdimensionaler Merkmalsraum schlecht ( curse of dimensionality )? Je nach Klassifikator, viele zu lernende Parameter Daten haben einen sehr hohen Abstand zueinander â†’ Gefahr des Overfittings Wie kann man die Dimension des Merkmalsraumes reduzieren? â†’ Merkmalsauswahl, suboptimales iteratives Verfahren, HKA (Varianzen maximieren), MDA (Klassentrennbarkeit maximieren), ICA Wie viele MÃ¶glichkeiten gibt es 5 Merkmale aus 10 auszuwÃ¤hlen? â†’ Binomialkoeffizient Was ist Overfitting? â†’ Siehe ML 1 Welche Probleme gibt es, wenn man LÃ¤nge, Masse und Temperatur als Merkmale hat? Unterschiedliche Einheiten (â†’ Entdimensionalisieren) Unterschiedliche Skalen (â†’ Teilen durch Varianz oder durch Wertebereich) Unterschiedliche Wertebereiche (â†’ Durchschnitt abziehen) Wie funktioniert MDA? â†’ Sie maximiert \\(J(w) = \\frac{|m'_1 - m'_2|&#94;2}{{s'}_1&#94;2 - {s'}_2&#94;2}\\) (im 2-Klassen Fall, wobei \\(w\\) die Ebene ist, auf die projeziert wird) Wie unterscheidet sich PCA/MDA von dem suboptimalen Algorithmus zur Merkmalsauswahl? â†’ PCA/MDA sind KlassifikatorunabhÃ¤ngig, aber der suboptimale Algorithmus benÃ¶tigt bereits einen Klassifikator. Wie lautet die Fundamentalformel der Bayesschen Klassifikation? â†’ \\(P(A|B) = \\frac{P(A)\\, P(B | A)}{P(B)}\\) (wobei Ã¼blicherweise B das Merkmal ist und A die Klasse) Wie lautet die Hauptformel der PCA? \\(m' = A&#94;T \\cdot (m - \\bar{m})\\) , wobei \\(A\\) die Basiswechselmatrix ist. Wie kann man invariante Merkmale erzeugen? â†’ Integration Ã¼ber eine Transformationsgruppe, Differentielle Methode, Normalisierung Wie kann man normalisieren? â†’ Fourierdeskriptoren kann man invariant bzgl. Translation und Rotation und radialer Streckung (Skalierung) machen Wie lauten die Prinzipien (A) - (E) der SVMs? (A) Lineare Trennung mit maximalen Abstand der Trennebenen zu den nÃ¤chstgelegenen Stichproben (Support Vektoren) (B) Duale Formulierung des linearen Klassifikators. (vgl. Wiki , \\(k(m) = w&#94;T m + b = \\langle w, m \\rangle + b = \\sum_{j=1}&#94;N \\alpha_j z_j \\langle m_j, m \\rangle + b\\) ) (C) Nichtlineare Abbildung der primÃ¤ren Merkmale in einen hochdimensionalen Merkmalsraum \\(\\Phi\\) (D) Implizite Nutzung des unter UmstÃ¤nden \\(\\infty\\) -dimensionalen Eigenfunktionsraumes einer sog. Kernfunktion \\(K\\) als transformierten Merkmalsraum \\(\\Phi\\) . Dabei mÃ¼ssen die transformierten Merkmale nicht explizit berechnet werden und der Klassifikator hat trotz der hohen Dimension von \\(\\Phi\\) nur eine niedrige Zahl von freien Parametern (Kernel-Trick). (E) Relaxation der Forderung nach linearer Trennbarkeit durch EinfÃ¼hrung von Schlupfvariablen (slack variables). Wie lautet die Dichtefunktion der \\(d\\) -dimensionale GauÃŸverteilung ? \\(f_X(x) = \\frac{1}{\\sqrt{((2\\pi)&#94;d \\det{\\Sigma})}} \\exp(-\\frac{1}{2}(x-\\mu)&#94;T \\Sigma&#94;{-1} (x-\\mu))\\) Wie lautet Mercers Theorem? â†’ wiki Wie ist die Kullback-Leibler-Divergenz defininiert? Material und Links Vorlesungswebsite : Ist passwortgeschÃ¼tzt. Das Passwort (das ausnahmsweise mal nicht zu erraten ist) kann ich hier natÃ¼rlich nicht schreiben. Aber der Benutzername ist asbstudent . SVMs Why bother with the dual problem when fitting SVM? A Tutorial on Support Vector Machines for Pattern Recognition Ãœbungsbetrieb Es gibt keine ÃœbungsblÃ¤tter, keine Ãœbungen, keine Tutorien und keine Bonuspunkte. Vorlesungsempfehlungen Folgende Vorlesungen sind Ã¤hnlich: Analysetechniken groÃŸer DatenbestÃ¤nde Informationsfusion Machine Learning 1 Machine Learning 2 Mustererkennung Neuronale Netze Lokalisierung Mobiler Agenten Probabilistische Planung Termine und Klausurablauf Datum : Donnerstag, der 10.09.2015 von 11:00-13:00 Uhr (Quelle: Wurde in der Vorlesung vom 22.04.2015 gesagt) Ort : Gerthsen-HÃ¶rsal Punkte : 90 Zeit : 90 min Punkteverteilung : ? ab 60.5: 1.7 Bestehensgrenze : ? Ãœbungsschein : gibt es nicht Bonuspunkte : gibt es nicht Ergebnisse : Am 30.09.2015 war die (vorlÃ¤ufige) Note im Notenauszug Einsicht : Montag 12.10.2015, 9:00-15:00 Uhr im Geb. 50.21 , Raum 015.1 Erlaubte Hilfsmittel : keine Notenverteilung Wenn ihr mir schreibt was ihr habt, kann ich das updaten: 1,3: min 1 2,0: min 1","tags":"German posts","title":"Mustererkennung - Klausur"},{"url":"https://martin-thoma.com/neuronale-netze-vorlesung/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žNeuronale Netze\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr. Alexander Waibel im Sommersemester 2015 gehÃ¶rt. Behandelter Stoff Vorlesung Datum Kapitel Inhalt 15.04.2015 Einleitung - 21.04.2015 LVQ and related Techiques k-Means, OLVQ1, kompetitives Lernen, Mode Seeker, PCA 22.04.2015 - Ãœbung 28.04.2015 Perceptron - 12.05.2015 Auto-Encoder Denoising- und Sparse Autoencoder, Bottleneck-Features, Kullback-Leibler-Divergenz ; Kettenregel 13.05.2015 Deep Learning Momentum, Rprop, Newbob, L1/L2-Regularisierung ($|w|$, $w&#94;2$), weight decay 19.05.2015 Ãœbung - 20.05.2015 Ãœbung - 26.05.2015 SOM Hebbian Learning, \" VQ \" mit SOM 09.06.2015 Effizientes Lernen Paralleles Lernen; Quickprop; Alternative Fehlerfunktion (cross entropy, CFM ); weight elimination / regularization 15.07.2015 Summary When to use which objective function (cross entropy, MSE); Backpropagation; Weight initialization; Regularization (L2 weight decay, dropout); Time Delay NN; Recurrent Networks; Applications (Speech Recognition, Computer Vision) NN01-Intro.pdf Human Brain vs. Computer (Processing/Processors, Accuracy, Speed, Hardware, Design) Aufbau eines biologischen Neurons (vgl. Wikipedia ) NN02-Classification.pdf Rosenblatt-Perceptron which realizes logical or McCulloch-Pitts Neuron (weights, bias, activation function is step function) Rosenblatt Perceptron Algorithmus Backpropagation Curse of Dimensionality Parzen Window Features: Nominal, Ordinal, Intervallskaliert, VerhÃ¤ltnisskaliert Bayes-Rule Given events $A_1$, $A_2$ and $B$, Bayes' rule states that the conditional odds of $A_1:A_2$ given $B$ are equal to the marginal odds of $A_1:A_2$ multiplied by the Bayes factor or likelihood ratio $\\Lambda$: $$O(A_1:A_2|B) = \\Lambda(A_1:A_2|B) \\cdot O(A_1:A_2) ,$$ where $$\\Lambda(A_1:A_2|B) = \\frac{P(B|A_1)}{P(B|A_2)}.$$ Parametrischer Klassifizierer Ein Klassifizierer heiÃŸt parametrisch , wenn er eine Wahrscheinlichkeitsverteilungsannahme macht. Naiver Bayes-Klassifikator Ein Klassifizierer heiÃŸt naiver Bayes-Klassifikator, wenn er den Satz von Bayes unter der naiven Annahme der UnabhÃ¤ngigkeit der Features benutzt. Normalverteilung Eine stetige Zufallsvariable $X$ mit der Wahrscheinlichkeitsdichte $f\\colon\\mathbb{R}\\to\\mathbb{R}$, gegeben durch $f(x) = \\frac {1}{\\sigma\\sqrt{2\\pi}} e&#94;{-\\frac {1}{2} \\left(\\frac{x-\\mu}{\\sigma}\\right)&#94;2}$ heiÃŸt $\\mathcal N\\left(\\mu, \\sigma&#94;2\\right)$-verteilt, normalverteilt mit den Erwartungswert $\\mu$ und Varianz $\\sigma&#94;2$. Multivariate Normalverteilung Eine $p$-dimensionale reelle Zufallsvariable $X$ ist normalverteilt mit Erwartungswertvektor $\\mu$ und (positiv definiter) Kovarianzmatrix $\\Sigma$, wenn sie eine Dichtefunktion der Form $$f_X(x)=\\frac{1}{ \\sqrt{(2\\pi)&#94;p \\det(\\Sigma)} } \\exp \\left( -\\frac{1}{2}(x-\\mu)&#94;{T}\\Sigma&#94;{-1}(x-\\mu) \\right)$$ besitzt. Man schreibt $$X\\sim \\mathcal N_p(\\mu, \\Sigma).$$ GauÃŸ'scher Klassifizierer Ein (naiver) Bayes-Klassifikator, welcher von normalverteilten Daten ausgeht heiÃŸt GauÃŸ'scher Klassifizierer . Principal Component Analysis ( PCA , Hauptkomponentenanalyse ) Die Hauptkomponentenanalyse ist ein Verfahren zur DimensionalitÃ¤tsreduktion von ungelabelten Daten im $\\mathbb{R}&#94;n$. Sie projeziert die Daten auf diejenige Hyperebene im $\\mathbb{R}&#94;d$, die den durch die Projektion stattfindenden Datenverlust minimal hÃ¤lt. Dabei ist $d \\in 1, \\dots, n$ beliebig wÃ¤hlbar. Die Transformation der Daten $X$ findet durch eine Matrixmultiplikation $Y = P \\cdot X$ statt. Die Matrix $P$ besteht aus den ersten $d$ Eigenvektoren der Kovarianzmatrix der Features $X$: $P = (v_1, \\dots, v_d)$ mit $\\lambda_j v_j = C_X v_j$ fÃ¼r $j=1,\\dots,d$ AuÃŸerdem gilt: $C_X = \\frac{1}{n-1} X X&#94;T$ V03: LVQ Slide name: V03_2015-04-21_LVQ.pdf k-Means Fuzzy k-Means Vector Quantization (VQ) is an unsupervised clustering algorithm Learning Vector Quantization is supervised. V04: Perceptron Slide name: V04_2015-04-28_Perceptron.pdf McCullochâ€“Pitts (MCP) Neuron Ein MLP-Neuron is ein Algorithmus zur binÃ¤ren Klassifizierung. Er hat $m+1$, mit $m \\in \\mathbb{N}_{> 0}$ inputs $x_i \\in \\{0, 1\\}$. Davon ist der erste (nullte) Konstant gleich Eins und wird Bias genannt. Jeder Input wird mit eingem Gewicht $w_i \\in \\mathbb{R}$ multipliziert, alle gewichteten Inputs werden addiert und schlieÃŸlich wird die Stufenfunktion $\\varphi(x) = \\begin{cases}1 &\\text{falls } x > 0\\\\0 &\\text{sonst} \\end{cases}$ angewendet. Man lernt mit MCP Neuronen, indem man $$\\Delta w = \\eta \\delta x$$ $$w \\gets w + \\Delta w$$ berechnet, wobei $\\eta \\in (0, 1)$ die Lernrate ist, $x$ ein Trainingsdatum und $\\delta = y_{\\text{target}} - y$ die Abweichung vom gewÃ¼nschten Ergebnis ist. Diese Regel wird auch Perceptron Learning Rule genannt. Rosenblatt-Perzeptron Wie das McCullochâ€“Pitts (MCP) Neuron, nur ist $x_i \\in \\mathbb{R}$ und ein Lernalgorithmus ist gegeben. Dieser addiert den $\\eta \\in (0, 1)$ gewichteten, fehlklassifizierten Vektor auf die Gewichte $w_i$. $\\eta$ heiÃŸt die Lernrate . Man lernt mit MCP Neuronen, indem man $$\\Delta w = \\eta \\delta x$$ $$w \\gets w + \\Delta w$$ berechnet, wobei $\\eta \\in (0, 1)$ die Lernrate ist, $x$ ein Trainingsdatum und $\\delta = - \\frac{\\partial E}{\\partial w}$ der Gradient auf der FehleroberflÃ¤che in AbhÃ¤ngigkeit von den Gewichten ist. Es wird also Gradient descent verwendet. Pocket Perceptron Algorithm Ein Lernalgorithmus fÃ¼r ein Rosenblatt-Perzeptron. Dieser konvergiert zu Gewichten, welche die wenigsten Beispiele falsch klassifiziert. Sigmoid-Funktion $\\varphi(x) = \\frac{1}{1+e&#94;{-x}}$ Softmax-Funktion $\\varphi(a_i) = \\frac{e&#94;{a_i}}{\\sum_{k} e&#94;{a_k}}$ wobei $a_i$ die Aktivierung des $i$-ten Neurons der selben Schicht ist. Perzeptron / Logistic Neuron MSE + Sigmoid activation function Fakten: Das Rosenblatt-Perzeptron findet eine lineare Trenngrenze, wenn sie existiert. Probleme vom Rosenblatt-Perzeptron: Nicht-linear trennbare Daten wie z.B. das XOR-Problem Nicht-trennbare Daten Wahl der Lernrate und der Startgewichte Aufbau eines biologischen Neurons (Axon, Dendriten, ZellkÃ¶rper, Ranviersche SchnÃ¼rringe, Synapsen) Glia-Zellen V05: Features Slide name: V05_2015-04-29_Features.pdf Rectified Linear Unit ( ReLU ) $\\varphi(x) = \\max(0, x)$ Leaky ReLU $\\varphi(x) = \\max(0.01x, x)$ Softplus $\\varphi(x) = \\log(1 + e&#94;x)$ Feed Forward Neural Network A Feed Forward Neural Network is a learning algorithm which takes a fixed-size input feature vector, applies varous matrix multiplications and point-wise non-linear functions to obtain a fixed-size output vector. Multilayer Perceptron A Multilayer Perceptron is a special type of Feed Forward Neural Network. It consists of fully connected layers only. Figure 1: Draft of multilayer Perceptron (MLP). The bias units are grey, the input units are red, the hidden units are green and the output unit is blue. The edges are directed from input, to hidden, to output and from the bias to hidden / output. Metrik Sei $X$ eine Menge und $d:X \\times X \\rightarrow \\mathbb{R}$ eine Abbildung. $d$ heiÃŸt Metrik auf $X$, wenn gilt: $d(x, y) = 0 \\geq x=y \\;\\;\\; \\forall x, y \\in X$ $d(x,y)=d(y,x)$ $d(x,y) \\leq d(x,z) + d(z,y)$ Jaccard-Metrik Es seien $A, B$ Mengen und $J(A, B) := \\frac{|A \\cup B| - |A \\cap B|}{|A \\cup B|}$. Dann heiÃŸt $J$ die Jaccard-Metrik. Levenshtein-Distanz Es seien $a, b$ Zeichenketten, $|a|$ die LÃ¤nge der Zeichenkette $a$ und $\\delta_{a_i \\neq b_j}$ genau dann 1, wenn das $i$-te Zeichen von $a$ und das $j$-te Zeichen von $b$ sich unterscheiden. Dann heiÃŸt $d_L(a, b)$ die Levenshtein-Distanz: $$d_L(a,b) := lev_{a,b}(|a|, |b|)$$ $$\\text{lev}_{a,b}(i, j) = \\begin{cases}\\max(i,j) &\\text{falls} \\min(i,j) = 0,\\\\ \\min \\begin{cases}\\text{lev}_{a,b}(i-1,j)+1\\\\ \\text{lev}_{a,b}(i,j-1)+1\\\\ \\text{lev}_{a,b}(i-1,j-1)+\\delta_{(a_i \\neq b_j)}\\\\\\end{cases} &\\text{sonst}\\end{cases}$$ Fragen: Welche Feed Forward Neuronalen Netze existieren, die keine Multilayer Perceptronen sind? â†’ CNNs, TDNNs, SOMs. Welche Skalentypen gibt es fÃ¼r Merkmale (Features)? Nominale Merkmale: Nur Gleichheit kann Ã¼berprÃ¼ft werden Ordinale Merkmale: Es existiert eine \"kleiner gleich\"-Relation Intervallskalierte Merkmale: Die Differenz der Merkmale hat eine Semantik Es existiert jedoch kein \"wirklicher\" Nullpunkt VerhÃ¤ltnisskalierte Merkmale: Wie Intervallskaliert, aber mit absolutem Nullpunkt. V06: Backpropagation Slide name: V06_2015-05-05_Backpropagation.pdf Kreuzentropie Fehlerfunktion ( Cross-Entropy ) $$E_{-x} = - \\sum_{k}[t_k&#94;x \\log(o_k&#94;x) + (1-t_k&#94;x) \\log (1- o_k&#94;x)]$$ wobei $x$ der Feature-Vektor ist, $k$ ein Neuron des letzen Layers, $t$ der wahre Wert (d.h. der gewÃ¼nschte Output), $o$ der tatsÃ¤chliche Output ist. Stochastic Gradient Descent Batch Gradient Descent V07: Feature Learning Slide name: V07_12-05-2015_Feature_Learning.pdf Autoencoder Ein Autoencoder ist ein neuronales Netz, welches darauf trainiert wird die Input-Daten am Output wieder zu replizieren. Bottleneck Features Unter Bottleneck-Features versteht man eine Schicht in einem neuronalem Netz, welche wesentlich kleiner ist als die vorhergehende und nachfolgende Schicht. Kullback-Leibler-Divergenz Die Kullback-Leibler-Divergenz ist ein MaÃŸ fÃ¼r die Unterschiedlichkeit zweier Wahrscheinlichkeitsverteilungen $P, Q$. FÃ¼r diskrete Verteilungen ist sie definiert als: $$KL(P||Q) := \\sum_{x \\in X} P(x) \\cdot \\log \\frac{P(x)}{Q(x)}$$ Denoising Autoencoder Ein Autoencoder, welcher trainiert wird rauschen zu entfernen. Fakten: Eine lineare Aktivierungsfunktion wird in einer ReprÃ¤sentation im Bottleneck-Feature resultieren, die PCA Ã¤hnelt. Fehlerfunktion: CE bei binÃ¤ren Ausgaben (d.h. Input-Features) MSE bei reelen Ausgaben (d.h. Input-Features) Fragen: Wie muss man die Grafik zu Stacked Denoising Autoencodern verstehen? V08: Deep Learning Slide name: V08_2015-05-13_Deep_Learning.pdf Deep Neural Networks Neural Networks with at least two hidden layers with nonlinear activation functions. Hyperparameter Hyperparameter $\\theta$ eines neuronalen Netzes sind Parameter, welche nicht gelernt werden. Learning Rate Scheduling Start with a learning rate $\\eta$ and reduce it while training. Exponential Decay Learning Rate $\\eta_t = \\eta_{t-1} \\cdot \\alpha = \\eta_0 \\cdot \\alpha&#94;t$ mit $\\alpha \\in (0, 1)$ Performance Scheduling Measure the error on the cross validation set and decrease the learning rate when the algorithm stops improving. RProp RProp is a learning rate scheduling method which is only based on the sign of the gradient. It increases the learning rate when the sign of the gradient doesn't change and decreases or resets it when the sign of the gradient changes. Rprop has an own learning rate for every single feature. AdaGrad (vgl. Folie 34) $$\\eta_{tij} = \\frac{\\eta_0}{\\sqrt{1 + \\sum_k {(\\frac{\\partial E&#94;{t-k}}{\\partial w_{ij}})}&#94;2}}$$ where $\\eta_0$ is an initial learning rate, $t$ is the epoch, $i,j$ refer to neurons. Newbob Scheduling Newbob scheduling is a combination of exponential decay learning rate scheduling and performance scheduling. It starts with a learning rate $\\eta_0$. When the validation error stops decreasing, switch to exponentially decaying learning rate. Terminate when the validation error stops decreasing again. Cross Entropy Error function (CE) $$E_{CE}(w) = - \\sum_{x \\in X} \\sum_{k} [t_k&#94;x \\log(o_k&#94;x) + (1-t_k&#94;x) \\log(1-o_k&#94;x)]$$ where $w$ is the weight vector, $X$ is the set of training examples (feature vectors), $t_k&#94;x = \\begin{cases}1 &\\text{if } x \\text{ is of class }k\\\\0&\\text{otherwise}\\end{cases}$ and $o_k&#94;x$ is the output at neuron $k$ of the network for the feature vector $x$. Mean Squared Error function (MSE) $$E_{MSE}(w) = \\frac{1}{2}\\sum_{x \\in X} \\sum_{k} (t_k&#94;x - o_k&#94;x)&#94;2$$ where $w$ is the weight vector, $X$ is the set of training examples (feature vectors), $k$ is the range of output neurons, $t_k&#94;x = \\begin{cases}1 &\\text{if } x \\text{ is of class }k\\\\0&\\text{otherwise}\\end{cases}$ and $o_k&#94;x$ is the output at neuron $k$ of the network for the feature vector $x$. Convolutional Neural Networks ( CNNs ) Feed-Forward Neuronale Netze, welche durch geteilte Gewichte (weight sharing) grafische Filter lernen. CNNs sind aktuell in der Computer Vission Stand der Technik. Time-Delay Neural Networks ( TDNNs ) TDNNs wenden wie CNNs weight sharing an um Filter zu lernen. Sie werden in der ASR verwendet und lernen auch Filter. Allerdings wird hier Ã¼ber die Zeit hinweg gefaltet. Multi-State Time-Delay Neural Networks ( MS-TDNNs , siehe [ Haf92 ]) MS-TDNNs codieren die alignment-Suche im Netzwerk. Sie sind hybride Netze (so wie HMM-DeepNN Hybrids von Mircosoft). RProp by Ryan Harris ( source ). Rot ist der Gradientenabstieg, blau ist mit momentum, rosa ist RProp Pretraining Design choices (hyperparameters): Topology (Width of layers, number of layers) Activation functions Error function Mini-Batch size Training function Preprocessing Initial Weights MSE vs CE : MSE penetalizes large differences much more than small ones MSE works well for function approximation CE works well on classification tasks V09: Reinforcement Learning Slide name: V09_2015-05-26-Reinforcement-Learning.pdf Markov Decision Process ( MDP ) Siehe ML 1 . Diskontierungsfaktor Siehe Probabilistische Planung . Strategie (engl. Policy ) Siehe Probabilistische Planung . Q-Funktion (Action-Value function) Siehe Probabilistische Planung . V-Funktion (State-Value function) Siehe ML 1 . $\\varepsilon$-Greedy Strategy Siehe Probabilistische Planung . $\\varepsilon$-decreasing Strategy Siehe Probabilistische Planung . $\\varepsilon$-first Strategy Siehe Probabilistische Planung . Adaptive $\\varepsilon$-greedy Strategy Siehe Probabilistische Planung . Episode Siehe Probabilistische Planung . Monte Carlo Policy Evaluation Initialize state values $V&#94;\\pi$ and iterate: Generate an episode foreach state $s$ in episode: Get the reward $\\hat{R}$ from that state on $\\hat{R} = \\sum_{j=0}&#94;\\infty \\gamma&#94;j r_j$ $V_{k+1}&#94;\\pi (s) \\leftarrow V_k&#94;pi (s) (1-\\alpha)+\\alpha \\hat{R}$ where $\\alpha$ is the learning rate. Temporal Difference Learning ( TD-Learning ) Siehe ML1 Q-Learning Siehe Probabilistische Planung . SARSA Siehe Probabilistische Planung . Strategie-Iteration ( Policy iteration ) Siehe Probabilistische Planung . Konvention: Eine optimale Strategie wird mit \\(\\pi&#94;*\\) bezeichnet. Fragen: Was bedeutet es, wenn in einem MDP der Diskontierungsfaktor \\(\\gamma = 0\\) ist? â†’ Nur der aktuelle Reward ist wichtig. Effektiv nimmt der Agent immer das nÃ¤chste Feld, welche den hÃ¶chsten Reward bietet (bzw. die Aktion, die den grÃ¶ÃŸten 1-Aktion Erwartungswert liefert). Was bedeutet es, wenn in einem MDP der Diskontierungsfaktor \\(\\gamma = 1\\) ist? â†’ Der Agent versucht die Summe der Belohnungen insgesamt zu maximieren. Siehe auch: Demystifying Deep Reinforcement Learning V10: SOM Slide name: V10_2015-05-26_SOM.pdf Hebbsche Lernregel what fires together, wires together Selbstorganisierende Karten ( SOM , Kohonennetze ) SOMs sind eine Art von Neuronalen Netzen. Die neuronen von SOMs sind auf einem Gitter angeordnet. Es gibt nur zwei Schichten: Die Input-Neuronen und die Neuronen auf dem Gitter. Jedes Input-Neuron ist mit jedem Neuron auf dem Gitter verbunden. Figure 2: Draft of self-organizing map (SOM). Training: Initialisierung : Die Gewichte $w_{ji}$ von dem $i$ -ten Input-Neuron zum Neuron ( $i = 1, ..., n$ ) $j$ auf dem Gitter werden zufÃ¤llig initialisiert. Sampling : Nehme ein zufÃ¤lliges Beispiel $x$ der Trainingsdaten. Matching : Finde das Neuron $j_{\\text{min}}$ , fÃ¼r das die Gewichte dem Input am Ã¤hnlichsten sind: $$j_{\\text{min}} = \\text{arg min}_j \\sum_{i=1}&#94;n (x_i - w_{ji})&#94;2$$ Update : Passe die Gewichte des gewinnenden Neurons $i$ sowie der Nachbarschaft $j$ an: $w_j = w_j + \\eta h(j, i(x))(x - w)$ Repeat : Und zurÃ¼ck zu Schritt 2. Siehe auch: Uwe Schneider: Self Organizing Map - ein Demonstrationsbeispiel , 2001. Self-Organizing Maps with Google's TensorFlow J. A. Bullinaria: Self Organizing Maps: Fundamentals , 2004. Kohonen's Self Organizing Feature Maps by ai-junkie V11: RBMs Slide name: V11_2015-05-27_RBMs Hopfield-Netz (siehe [ Hop82 ], [ Kri05 ]) Ein Hopfield-Netz besteht nur aus einer Schicht von McCulloch-Pitts Neuronen. Jedes Neuron ist mit jedem anderen Neuron (also nicht sich selbst) und allen Inputs verbunden. Die Schicht funktioniert gleichzeitig als Ein- und Ausgabeschicht. Hopfield-Netze werden in einem einzigen durchgang Trainiert. Dabei wird auf das Gewicht von Neuron $i$ zu Neuron $j$ + 1 addiert, wenn das Bit $i$ des Trainingsmusters gleich ist. Falls das nicht der Fall ist, wird von dem Gewicht 1 subtrahiert: $$w_{ij} = \\sum_{p} (2 a&#94;{(i)}_p - 1) \\cdot (2 a&#94;{(j)}_p - 1)$$ Jedes Gewicht ist zum start des Trainings 0. Das Training ist also einfach nur ein ZÃ¤hlen, wie hÃ¤ufig die Stellen Ã¼bereinstimmen. Figure 3: Draft of Hopfield network. Every node is an input node. The McCullogh-Pitts nodes are updated asynchronously. When the state of the node doesn't change any more, they contain the output of the network. Learned are the weights between the nodes. Boltzmann-Maschine Boltzmann-Maschinen sind stochastische neuronale Netzwerke, welche duch belibige ungerichtete Graphen reprÃ¤sentiert werden kÃ¶nnen. Die neuronen sind binÃ¤r; sie feuern also entweder oder nicht. Es gibt insbesondere keine Unterschiede in der StÃ¤rke mit der sie feuern. Siehe auch: Scholarpedia Restricted Boltzmann machine ( RBM ) Eine RBM ist ein neuronales Netz mit nur einem Hidden Layer. Es ist gleichzeitig ein Spezialfall von MRFs . Im Gegensatz zur Boltzmann-Maschine muss die Restricted Boltzmann-Machine (RBM) aus einem bipartitem Graph bestehen. Dies erlaubt ein effizienteres Trainingsverfahren (Contrastive Divergence). Die Energie des Netzwerkes ist $$- \\sum_{i < j} w_{ij} s_i s_j - \\sum_i b_i s_i$$ wobei $s_i, s_j$ die binÃ¤ren ZustÃ¤nde der Knoten $i, j$ sind. Der Name \"Boltzmann\" kommt von dieser Energie (man kann den NetzwerkzustÃ¤nden wahrscheinlichkeiten zuweisen, die direkt Proportional zu $e&#94;{-E}$) sind. Figure 4: Draft of an RBM. The learned parameters are red. Es werden keine Verbindungen zwischen den Hidden Units erlaubt (daher das \"restricted\" - Quelle: Hinton, 2015 ). Siehe A Practical Guide to Training Restricted Boltzmann Machines von Hinton, 2010. sowie Interence in RBMs Contrastive Divergence ( CD , CD-$k$ , siehe YouTube Video , 2 von Hugo Larochelle) Contrastive Divergence ist ein Trainingsalgorithmus fÃ¼r RBMs. Ein Hyperparameter ist $k \\in \\mathbb{N}$. Er geht wie folgt vor: Lege den Trainingsvektor $x&#94;{(t)}$ an die Eingabeknoten an. Berechne die Wahrscheinlichkeit fÃ¼r jede Hidden Unit, dass diese gleich 1 ist. Setze sie mit dieser Wahrscheinlichkeit gleich 1. Berechne die Wahrscheinlichkeit fÃ¼r jeden Eingabeknoten, dass dieser gleich 1 ist. Setze ihn mit dieser Wahrscheinlichkeit gleich 1. Gehe zu Schritt 2. Wiederhole dies fÃ¼r $k$ Schritte (dies wird auch Gibbs-Sampling genannt). Das, was nach dem $k$-fachem Gibbs-Sampling in der Eingabeschicht steht wird auch \"negative sample $\\tilde x$\" genannt. Update der Parameter: \\begin{align} W &\\leftarrow W + \\eta (h(x&#94;{(t)}) {x&#94;{(t)}}&#94;T - h(\\tilde x) {\\tilde x}&#94;T)\\\\ b_h &\\leftarrow b_h + \\eta (h(x&#94;{(t)}) - h(\\tilde x))\\\\ b_v &\\leftarrow b_v + \\eta (x&#94;{(t)} - \\tilde x) \\end{align} wobei $\\eta \\in (0, 1) $ die Lernrate ist, $b_h \\in \\mathbb{R}&#94;n_h$ der Bias-Vektor der Hidden Units und $b_v \\in \\mathbb{R}&#94;{n_v}$ der Bias-Vektor der Eingabeknoten ist. $h = \\text{sigmoid}(b_h + W x)$ ist ein Vektor, welcher fÃ¼r die einzelnen Hidden Units sagt wie wahrscheinlich es ist, dass diese gleich 1 sind. In der Praxis funktioniert es schon mit $k=1$ fÃ¼r Pre-Training. Wenn $k$ groÃŸ ist konvergiert $\\tilde x$ gegen den wahren Modellwert. Das wÃ¤re dann eine Monte-Carlo Estimation. Simulated annealing Simulated annealing ist ein heuristisches Optimierungsverfahren. Sei $D$ ein Wertebereich einer Funktion $f: D \\rightarrow \\mathbb{R}$ und $U: D \\rightarrow \\mathcal{P}(D)$ eine Funktion, welche die Umgebung eines Punktes angibt. Sei $T: \\mathbb{N}_0 \\rightarrow \\mathbb{R}_{> 0}$ die Temperatur zum Zeitpunkt $t \\in \\mathbb{N}_0$. Gesucht ist $\\text{arg min}_{x \\in D} f(x)$. WÃ¤hle zum Zeitpunkt $t=0$ einen zufÃ¤lligen Startwert $x \\in D$. Gehe nun iterativ vor und jeweils einen Zeitschritt weiter: Nehme einen Punkt aus der Umgebung $y \\in U(x)$. Wenn $f(y) \\leq f(x)$, dann Ã¼berschreibe $x \\leftarrow y$. Falls nicht, dann Ã¼berschreibe es mit der Wahrscheinlichkeit $\\exp \\left (-\\frac{f(y)-f(x)}{T(t)} \\right )$. Speichere in jedem Schritt den bisher besten Wert. Anwendungen: Hopfield-Netze: Hopfield-Netze kann man fÃ¼r das TSP einsetzen und auch als Assoziativspeicher nutzen. Allerdings haben sich Hopfield-Netze nie wirklich durchgesetzt. RBMs: Collaborative Filtering Siehe auch: Deeplearning.net: Restricted Boltzmann Machines (RBM) A. Barra, A. Bernacchia, E. Santucci und P. Contucci: On the equivalence of Hopfield networks and Boltzmann Machines in Neural Networks , 2012. V12: RNNs Slide name: V12_2015-06-02_RNNs.pdf Elman-Netz Ein rekurrentes neuronales Netzwerk, bei dem die Ausgabe eines hidden layers im nÃ¤chsten Zeitschritt als Eingabe verwendet wird. Jordan-Netz Ein rekurrentes neuronales Netzwerk, bei dem die Ausgabe der Ausgabeschicht im nÃ¤chsten Zeitschritt als Eingabe verwendet wird. Backpropagation through Time ( BPTT ) Ein Trainingsalgorithmus fÃ¼r rekurrente neuronale Netze, bei dem das Netz \"ausgerollt\" wird. Das rekurrente Netz wird also als unendlich groÃŸes nicht-rekurrentes Netz behandelt. Vanishing gradient problem Das Problem des verschwindenden Gradienten ist eine Herausforderung im Kontext neuronaler Netze, welche mit Backpropagation trainiert werden. Insbesondere bei sehr tiefen oder rekurrenten Netzen kann es passieren, dass der Gradient bei den ersten Schichten sehr niedrig ist, sodass das Netz sehr langsam lernt. Aufgrund numerischer Ungenauigkeit kann dies sogar dazu fÃ¼hren, dass das Netz in den ersten Schichten nicht lernen kann. Long short-term memory ( LSTM ) Ein LSTM ist ein Typ eines neuronalen Netzwerks. Das besondere an LSTM Netzen sind \"intelligente\" Neuronen, welche Ã¼ber Gates bestimmen ob ein Wert gespeichert wird und wie lange. Siehe auch: Andrej Karpathy: The Unreasonable Effectiveness of Recurrent Neural Networks , 21. May 2015. Christopher Olah: Understanding LSTM Networks , 27. August 2015. Char-Predictor online Demo Recurrent Neural Networks Tutorial, Part 1 â€“ Introduction to RNNs YouTube: Vanishing Gradient (5:24 min) Where does the name 'LSTM' come from? Greff, Srivastava, KoutnÃ­k, Steunebrink, Schmidhuber: LSTM: A Search Space Odyssey . arxiv, 2015. Reddit: The Idea of LSTMs V13: NN learning tricks Slide name: V13_2015-06-09_NNlearning-tricks.pdf Momentum In der Update-Regel $\\Delta w_{ij}&#94;* (t+1) = \\Delta w_{ij} (t+1) + \\alpha \\Delta w_{ij}(t)$ wird der Term $\\Delta w_{ij}(t)$ als Momentum bezeichnet. Der Skalar $\\alpha \\in [0, 1]$ gewichtet diesen und ist ein Hyperparameter. Siehe auch: Optimization: Stochastic Gradient Descent Quickprop Quickprop ist ein Trainingsverfahren fÃ¼r neuronale Netze. Der Lernalgorithmus nimmt an, dass die Fehlerebene lokal durch eine parabel approximiert werden kann. Das Gewichtsupdate im Schritt $k$ ist demnach vom Gradienten und dem Gewichtsupdate das vorherigen Schrittes abhÃ¤ngig: $$\\Delta&#94;{(k)} \\, w_{ij} = \\Delta&#94;{(k-1)} \\, w_{ij} \\left ( \\frac{\\nabla_{ij} \\, E&#94;{(k)}}{\\nabla_{ij} \\, E&#94;{(k-1)} - \\nabla_{ij} \\, E&#94;{(k)}} \\right)$$ Weight Decay Passe die Fehlerfunktion an: $E = MSE + \\lambda \\sum_{i,j} w_{ij}&#94;2$ Weight Elimination Passe die Fehlerfunktion an: $E = MSE + \\lambda \\sum_{i,j} \\frac{w_{ij}&#94;2}{1+w_{ij}&#94;2}$ Optimal Brain Damage ( OBD ) Optimal Brain Damage entfernt nach dem Training Verbindungen die sehr kleine $|w_{ij}|$ haben. Besser: Entferne Verbindungen, die geringen Einfluss auf die Fehlerfunktion haben. Cascade Correlation (siehe Fahlman und Lebiere: The Cascade-Correlation Learning Architecture ) Cascade Correlation ist ein konstruktiver Algorithmus zum erzeugen von Feed-Forward Neuronalen Netzen. Diese haben eine andere Architektur als typische multilayer Perceptrons. Bei Netzen, welche durch Cascade Correlation aufgebaut werden, ist jede Hidden Unit mit den Input-Neuronen verbunden, mit den Output-Neuronen und mit allen Hidden Units in der Schicht zuvor. Siehe How exactly does adding a new unit work in Cascade Correlation? Meiosis Netzwerke (siehe Stephen Jose Hanson: Meiosis Networks ) Meiosis Netzwerke bauen ein neuronales Netz auf. Sie beginnen mit einer einzelnen hidden Unit. Diese hidden Unit wird aufgespalten, wenn die \"Unsicherheit\" zu groÃŸ ist (vgl. paper fÃ¼r Kritierum; vgl. summary ). Automatic Structure Optimization ( ASO , siehe [ Bod93 ]) Der ASO-Algorithmus passt folgende Hyperparameter im Training automatisch an: Anzahl der Hidden Units GrÃ¶ÃŸe des Input-Fensers (ASR-Spezifisch) Anzahl der ZustÃ¤nde, welche \"Accoustic Events\" reprÃ¤sentieren Classification Figure of Merit ( CFM , siehe [ Ham90 ]) $$E_{CFM}(w) = \\sum_k \\frac{\\alpha}{1 + e&#94;{-\\beta \\Delta_k + \\gamma}}$$ wobei $k$: Klasse $\\alpha, \\beta, \\gamma$: Hyperparameter $\\Delta_k = o_t - o_k$: Differenz des wahren (true) nodes und des anderen Knotens. Speed-ups des Trainings sind mÃ¶glich durch: Momentum Ãœberspringen von bereits gut gelernten Beispielen Dynamische Anpassung der Lernrate \\(\\eta\\) Quickprop Gute Initialisierung (z.b. \\(w \\sim U(- 4 \\cdot \\sqrt{\\frac{6}{n_j + n_{j+1}}}, 4 \\cdot \\sqrt{\\frac{6}{n_j + n_{j+1}}})\\) ) Lernen kann getweakt werden: Den Betrag des Gradienten um eine kleine Konstante vergrÃ¶ÃŸern (Folie 19+20) Fehlerfunktion anpassen MSE Cross-Entropy CFM Overfitting verhindern Weight decay Weight elimination Optimal Brain Damage Optimal Brain Surgeon Schrittweise Netzkonstruktion Cascade Correlation Meiosis Netzwerke ASO V14: DNN CV Slide name: V14_2015-06-10_DNN_CV .pdf SIFT ( Scale-invariant feature transform ) Unter SIFT versteht man bestimmte Features in der Bildverarbeitung, welche invariant unter skalierung sind. Texton (siehe UCLA ) Unter einem Texton versteht man grundlegende, kleine Features eines Bildes. Diese Bilden die kleinsten als unterschiedlich wahrnehmbaren Einheiten. Convolutional Neural Network ( CNN ) Ein CNN ist ein Neuronales Netzwerk, welches mindestens eine Schicht hat, welche die Parameter eines Kernels fÃ¼r eine Faltung lernt. Feature Map Im Kontext von CNNs versteht man unter einer Feature-Map die Ausgabe eines Kernels in einem Convolutional Layer. Facts: Pooling: Max, Mean, Probabilistic V15: Speech-Independence Slide name: V15_2015-06-17_Speech-Independence.pdf Visualisierung von Netzen HÃ¤ufig wird die Architektur neuronaler Netze grafisch dargestellt. Dabei ist mir folgendes aufgefallen: Im Innenren von Neuronen wird die Aktivierungsfunktion \"geplottet\". Das heiÃŸt bei der Sigmoidfunktion wird etwas S-FÃ¶rmiges dargestellt, bei der sign-Funktion etwas eckiges, bei ReLU ein horizontaler Strich gefolgt von einem Strich im 45-Grad Winkel. Typischerweise ist der Input links (oder alternativ unten) und der Output rechts (oder alternativ oben) Interpretation of errors Figure 5: Training and Testing error over epochs. At some point overfitting happens. Figure 6: Training and Testing error over training data. At some point overfitting happens. If you have a problem with high variance, you can train more epochs, get more data or better features. If you have a problem with high bias, you should get better features or a better classifier. Please note that Figure 6 also gives you a feeling for how much new training data will help you with your problem. Aktivierungsfunktionen Name Function $\\varphi(x)$ Range of values Differentiable $\\varphi'(x)$ Layer Comment Signum $\\varphi(x) = \\begin{cases}+1 &\\text{if } x > 0\\\\-1 &\\text{if } x < 0\\end{cases}$ $\\{-1, 1\\}$ Yes (except 0) $\\varphi'(x) = 0$ No Heaviside Step function $\\varphi(x) = \\begin{cases}+1 &\\text{if } x > 0\\\\0 &\\text{if } x < 0\\end{cases}$ $\\{0, 1\\}$ Yes (except 0) $\\varphi'(x) = 0$ No McCullch-Pitts; Rosenblatt Sigmoid $\\varphi(x) = \\frac{1}{1+e&#94;{-x}}$ $[0, 1]$ Yes $\\varphi'(x) = \\frac{e&#94;x}{(e&#94;x +1)&#94;2}$ No Smoothed version of the heaviside step function tanh $\\varphi(x) = \\frac{e&#94;x - e&#94;{-x}}{e&#94;x + e&#94;{-x}} = \\tanh(x)$ $[-1, 1]$ Yes $\\varphi'(x) = \\text{sech}&#94;2(x)$ No Smoothed version of the signum function ReLU $\\varphi(x) = \\max(0, x)$ $[0, \\infty)$ Yes (except 0) $\\varphi'(x) = \\begin{cases}1 &\\text{if } x > 0\\\\0 &\\text{if } x < 0\\end{cases}$ No Standard in CNNs Leaky ReLU $\\varphi(x) = \\max(\\alpha x, x)$ mit typischerweise $\\alpha = 0.01$ $(-\\infty, +\\infty)$ Yes (except 0) $\\varphi'(x) = \\begin{cases}1 &\\text{if } x > 0\\\\0.01 &\\text{if } x < 0\\end{cases}$ No Fixes the dying ReLU problem [ 1 ] Softplus $\\varphi(x) = \\log(e&#94;x + 1)$ $(0, \\infty)$ Yes $\\varphi'(x) = \\frac{e&#94;x}{e&#94;x + 1}$ No Smoothed ReLU ELU $\\varphi(\\mathbf{x}) = \\begin{cases}x &\\text{if } x > 0\\\\\\alpha (e&#94;x - 1) &\\text{otherwise}\\end{cases}$ $(-\\infty, +\\infty)$ Yes $\\varphi'(x) = \\begin{cases}1 &\\text{if } x > 0\\\\\\alpha e&#94;x &\\text{otherwise}\\end{cases}$ No Softmax $o(\\mathbf{z})_j = \\frac{e&#94;{z_j}}{\\sum_{k=1}&#94;K e&#94;{z_k}}$ $[0, 1]&#94;K$ Yes differentiable Yes Standard for classification problems as the output can be interpreted as a probability distribution. Maxout $o(\\mathbf{z}) = \\max_{z \\in \\mathbf{z}} z$ $(-\\infty, +\\infty)$ No - Yes See also: Bing Xu, Naiyan Wang, Tianqi Chen, Mu Li: Empirical Evaluation of Rectified Activations in Convolutional Network . arxiv, 2015 Djork-ArnÃ© Clevert, Thomas Unterthiner, Sepp Hochreiter: Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs) . arxiv, 2015. Topology Learning Growing approaches Fahlman, Lebiere: The Cascade-Correlation Learning Architecture . 1989. Hanson: Meiosis Networks . 1990. CÃ´tÃ©, Larochelle: An Infinite Restricted Boltzmann Machine . 2015 Pruning approaches Le Cun, Denker, Solla: Optimal Brain Damage . 1989. Hassibi, Stork: Optimal Brain Surgeon and General Network Pruning . 1993. Genetic Approaches NEAT HyperNEAT See also: Reddit: Interesting papers on learning automatically learning neural network topology Einordnung Neuronale netze kann man durch folgende Kriterien mit einander vergleichen: Deterministisch / Stochastisch : Ist die Aktivierung der neuronen stochastische oder deterministisch? Inferenz : Feed-Forward oder Rekurrent? Wie funktioniert die Auswertung? Training : Wie lernt man? Verwendung : Wo wird das Netzwerk typischerweise eingesetzt? Netzwerk Deterministisch Inferenz Training Verwendung McCulloch-Pitts Neuron Yes Feed-Forward Supervised Classification of linear separable data Rosenblatt Perceptron Yes Feed-Forward Supervised Classification of linear separable data Multilayer Perceptron Yes Feed-Forward Supervised (Backpropagation) Classification CNN Yes Feed-Forward Supervised (Backpropagation + weight sharing) Computer Vision TDNNs Yes Feed-Forward Supervised (Backpropagation + weight sharing) ASR LSTM Yes Recurrent BPTT Mapping sequences (Generating texts, machine translation) SOMs Yes Feed-Forward Unsupervised (competitive learning) Visualisierung / DimensionalitÃ¤tsreduktion: Mapping of high-dimensional data on 2D; CBIR ; TSP Hopfield networks Yes Recurrent Unsupervised (Hebbsche Lernregel) Associative memories, travelling salesman Boltzmann machines stochastic Simulated Annealing Annealed Importance Sampling (not used) RBMs stochastic $p(h_j=1|x) = \\text{sigmoid}(b_{v,j} + W_j x)$ $p(x_k=1|h) = \\text{sigmoid}(b_{h,k} + h&#94;T W_k)$ Contrastive Divergence (CD-$k$) Collaborative Filtering Learning Rate Scheduling Fixed: The learning rate doesn't change. This is the standard stochastic gradient descent algorithm. RProp RMSProp (Root Mean Square Propagation): Slides Exponential Decay Learning Rate Newbob Performance Scheduling AdaGrad There are a couple of publications which deal with LR scheduling: Note on Learning Rate Schedules for Stochastic Optimization No More Pesky Learning Rates Optimizing Gradient Descent I'm not too sure, but I think momentum is not a learning rate scheduling algorithm. See also: What is lr_policy in Caffe? Visualizing Optimization Algos 2 on imgur.com by Alec Radford PrÃ¼fungsfragen Was ist der Unterschied zwischen Backpropagation und Gradient descent? â†’ Backpropagation ist eine geschickte Umsetzung des Gradientenabstiegs, bei der es vermieden wird Berechnungen mehrfach durchzufÃ¼hren. Welche Typen von Neuronalen Netzen gibt es? â†’ Siehe Einordnung Welche Aktivierungsfuktionen gibt es? â†’ Siehe Ãœbersicht Welche Aktivierungsfunktionen machen bei einem einzelnen Perzeptron keinen Sinn? â†’ Softmax wegen der Normierung; Maxout Welche Aktivierungsfunktion macht in einem MLP keinen Sinn? â†’ Nur lineare, da insgesamt eine lineare Funktion herauskommt. WofÃ¼r kann man neuronale Netze einsetzen? â†’ Klassifikation, Funktionsapproximation , Encoding, DimensionalitÃ¤tsreduktion, Assoziativspeicher Welche MÃ¶glichkeiten zur Regularisierung gibt es? â†’ L1, L2, Dropout, Weight Decay Wie kann der Standard Gradient descent Algorithmus angepasst werden um den Lernvorgang zu beschleunigen? â†’ Momentum, Exponential Decay Learning Rate, Performance Scheduling, Newbob, AdaGrad, RProp Welche Alternativen zu standard Gradient Descent gibt es? â†’ Quickprop, (L-)BFGS, Conjugate Gradient, Quasi-Newtonian (vgl. Reddit , Optimization Basics ). Wie kann man Netztopologien aufbauen? â†’ Meiosis, Cascade Correlation, Optimal Brain Damage / Surgeon (vgl. Reddit ). Material und Links Vorlesungswebsite NNPraktikum : Toolkit fÃ¼r die ÃœbungsblÃ¤tter StackExchange âœ“ What is the difference in Bayesian estimate and maximum likelihood estimate? âœ“ Can k-means clustering get shells as clusters? How is the Schwarz Criterion defined? Are there studies which examine dropout vs other regularizations? How do subsequent convolution layers work? âœ“ Is Maxout the same as max pooling? What is \\(\\alpha \\sin(\\theta) + \\beta \\frac{d \\theta}{d t}\\) in the inverted pole problem? âœ“ (Why) do activation functions have to be monotonic? The cross-entropy error function in neural networks What is the \"dying ReLU\" problem in neural networks? and How does rectilinear activation function solve the vanishing gradient problem in neural networks? Visualizing Optimization Algos 2 on imgur.com by Alec Radford Neural Network demo Skript von Marvin Ritter Machine Learning 1 und Machine Learning 2 am KIT Coursera: Neural Networks for Machine Learning by Geoffrey Hinton Literatur [ Mit97 ] T. Mitchell. Machine Learning. McGraw-Hill, 1997. [ Hop82 ] J. J. Hopfield. Neural networks and physical systems with emergent collective computational abilities in Proceedings of the national academy of sciences, 1982. [ Kri05 ] D. Kriesel. Neuronale Netze . 2005. [ Bod93 ] U. Bodenhausen und A. Waibel. Tuning by doing: Flexibility through automatic structure optimization in Third European Conference on Speech Communication and Technology, 1993. [ Haf92 ] P. Haffner und A. Waibel. Multi-state time delay networks for continuous speech recognition in Advances in neural information processing systems, 1992. [ Ham90 ] J. Hampshire and A. Waibel. A Novel Objective Function for Improved Phoneme Recognition Using Time Delay Neural Networks. IEEE Transactions on Neural Networks, 1990. Vorlesungsempfehlungen Folgende Vorlesungen sind Ã¤hnlich: Analysetechniken groÃŸer DatenbestÃ¤nde Informationsfusion Machine Learning 1 Machine Learning 2 Mustererkennung Neuronale Netze Lokalisierung Mobiler Agenten Probabilistische Planung Ãœbungsbetrieb ÃœbungsblÃ¤tter sind freiwillig. Termine und Klausurablauf Datum : nach Terminvereinbarung Ort : GebÃ¤ude 50.20 Ãœbungsschein : gibt es nicht Bonuspunkte : gibt es nicht Erlaubte Hilfsmittel : keine","tags":"German posts","title":"Neuronale Netze - Klausur"},{"url":"https://martin-thoma.com/lasagne-for-python-newbies/","text":"Lasagne is a Python package for training neural networks. The nice thing about Lasagne is that it is possible to write Python code and execute the training on nVidea GPUs with automatically generated CUDA code. However, installing Lasagne is not that easy. Especially if you are not familiar with Python. This article aims to guide you through the installation process. Python Ubuntu-based systems will have Python installed, but I'm not too sure about pip. You can get it with $ sudo apt-get install python-pip Make sure you have Python and pip , the standard Python package installer. Type the following commands to check if you have both: $ python --version Python 2 .7.8 $ pip --version pip 6 .1.1 from /usr/local/lib/python2.7/dist-packages ( python 2 .7 ) sklearn sklearn is a nice package for machine learning. You can install it with $ pip install scikit-learn (When I write commands like this you either have to execute sudo pip install scikit-learn or pip install scikit-learn --user ). This should work without problems. Each classifier has a fit method and a predict method. See iris example to get a feeling how to use it. It provides a lot of useful functions like train_test_split and has an awesome documentation. You don't need this for Lasagne, but it might be good to use sklearn and Lasagne in combination. Graphics drivers and CUDA Make sure CUDA runs on your system by the following commands. If it doesn't run, you could try the following guides: Installing and testing CUDA in Ubuntu 14.04 Installing CUDA Toolkit 6.5 on Ubuntu 14.04 Linux NVIDIA CUDA Getting Started Guide for Linux Run $ nvidia-smi -L GPU 0 : GeForce GTX TITAN Black ( UUID: GPU-abcdef12-abcd-1234-1234-01234567890a ) $ nvcc --version nvcc: NVIDIA ( R ) Cuda compiler driver Copyright ( c ) 2005 -2013 NVIDIA Corporation Built on Thu_Mar_13_11:58:58_PDT_2014 Cuda compilation tools, release 6 .0, V6.0.1 $ nvidia-smi -a ============== NVSMI LOG ============== Timestamp : Fri Apr 17 18 :44:41 2015 Driver Version : 331 .79 Attached GPUs : 1 GPU 0000 :01:00.0 Product Name : GeForce GTX TITAN Black Display Mode : N/A Display Active : N/A Persistence Mode : Disabled Accounting Mode : N/A Accounting Mode Buffer Size : N/A Driver Model Current : N/A Pending : N/A Serial Number : N/A GPU UUID : GPU-fcff168f-a045-2f95-7a4f-8e1cf26a24eb Minor Number : 0 VBIOS Version : 80 .80.4E.00.01 Inforom Version Image Version : N/A OEM Object : N/A ECC Object : N/A Power Management Object : N/A GPU Operation Mode Current : N/A Pending : N/A PCI Bus : 0x01 Device : 0x00 Domain : 0x0000 Device Id : 0x100C10DE Bus Id : 0000 :01:00.0 Sub System Id : 0x106610DE GPU Link Info PCIe Generation Max : N/A Current : N/A Link Width Max : N/A Current : N/A Bridge Chip Type : N/A Firmware : N/A Fan Speed : 26 % Performance State : N/A Clocks Throttle Reasons : N/A FB Memory Usage Total : 6143 MiB Used : 39 MiB Free : 6104 MiB BAR1 Memory Usage Total : N/A Used : N/A Free : N/A Compute Mode : Default Utilization Gpu : N/A Memory : N/A Ecc Mode Current : N/A Pending : N/A ECC Errors Volatile Single Bit Device Memory : N/A Register File : N/A L1 Cache : N/A L2 Cache : N/A Texture Memory : N/A Total : N/A Double Bit Device Memory : N/A Register File : N/A L1 Cache : N/A L2 Cache : N/A Texture Memory : N/A Total : N/A Aggregate Single Bit Device Memory : N/A Register File : N/A L1 Cache : N/A L2 Cache : N/A Texture Memory : N/A Total : N/A Double Bit Device Memory : N/A Register File : N/A L1 Cache : N/A L2 Cache : N/A Texture Memory : N/A Total : N/A Retired Pages Single Bit ECC : N/A Double Bit ECC : N/A Pending : N/A Temperature Gpu : 29 C Power Readings Power Management : N/A Power Draw : N/A Power Limit : N/A Default Power Limit : N/A Enforced Power Limit : N/A Min Power Limit : N/A Max Power Limit : N/A Clocks Graphics : N/A SM : N/A Memory : N/A Applications Clocks Graphics : N/A Memory : N/A Default Applications Clocks Graphics : N/A Memory : N/A Max Clocks Graphics : N/A SM : N/A Memory : N/A Compute Processes : N/A to see if CUDA was installed correctly. Theano The installation of Theano is a bit tricky (see official page ). I don't remember if I installed additional packages, but try $ sudo -H pip install theano Make sure that your ~/.theanorc exists and looks like this: [global] device=gpu floatX=float32 Note that float32 is required, even if you have a 64bit system. To test your installation, save the following as theanotest.py and execute it with python theanotest.py : #!/usr/bin/env python from theano import function , config , shared , sandbox import theano.tensor as T import numpy import time vlen = 10 * 30 * 768 # 10 x #cores x # threads per core iters = 1000 rng = numpy . random . RandomState ( 22 ) x = shared ( numpy . asarray ( rng . rand ( vlen ), config . floatX )) f = function ([], T . exp ( x )) print f . maker . fgraph . toposort () t0 = time . time () for i in xrange ( iters ): r = f () t1 = time . time () print 'Looping %d times took' % iters , t1 - t0 , 'seconds' print 'Result is' , r if numpy . any ([ isinstance ( x . op , T . Elemwise ) for x in f . maker . fgraph . toposort ()]): print ( 'Used the cpu' ) else : print ( 'Used the gpu' ) It should print the following (well, something similar): Using gpu device 0: GeForce GTX TITAN Black [GpuElemwise{exp,no_inplace}(<CudaNdarrayType(float32, vector)>), HostFromGpu(GpuElemwise{exp,no_inplace}.0)] Looping 1000 times took 0.38205909729 seconds Result is [ 1.23178029 1.61879349 1.52278066 ..., 2.20771813 2.29967761 1.62323296] Used the gpu Especially \"used the gpu\" is important. Theano code work on both, CPU and GPU. If you have a GPU and it does not currently work on a task and it is configured correctly, then Theano should automatically use the GPU. (Don't try to run two Theano scripts at a time ... weird things could happen.) Lasagne Lasagne is hosted at Github: https://github.com/Lasagne/Lasagne Currently, it is not on pip as Sander wants to wait until we get to version 1.0. So you have to install it manually: $ git clone https://github.com/Lasagne/Lasagne.git $ cd Lasagne Lasagne$ sudo -H python setup.py install Now you can test if it worked by executing the MNIST example in Lasagne ( MNIST is a huge digit dataset). This might first take some time to download, but should then run quite fast. If your machine does not use the GPU it will take ages (e.g. on my laptop it takes about a minute for one epoch) Lasagne/examples$ python mnist.py Loading data... Downloading MNIST dataset Building model and compiling functions... /usr/local/lib/python2.7/dist-packages/Lasagne-0.1dev-py2.7.egg/lasagne/init.py:30: UserWarning: The uniform initializer no longer uses Glorot et al.'s approach to determine the bounds, but defaults to the range (-0.01, 0.01) instead. Please use the new GlorotUniform initializer to get the old behavior. GlorotUniform is now the default for all layers. warnings.warn(\"The uniform initializer no longer uses Glorot et al.'s \" /usr/local/lib/python2.7/dist-packages/Lasagne-0.1dev-py2.7.egg/lasagne/layers/helper.py:55: UserWarning: get_all_layers() has been changed to return layers in topological order. The former implementation is still available as get_all_layers_old(), but will be removed before the first release of Lasagne. To ignore this warning, use `warnings.filterwarnings('ignore', '.*topo.*')`. warnings.warn(\"get_all_layers() has been changed to return layers in \" Starting training... Epoch 1 of 500 took 72.593s training loss: 1.330231 validation loss: 0.470251 validation accuracy: 87.54 %% nolearn nolearn is another Python package. It was created to make using Lasagne even simpler. You can install it via $ git clone https://github.com/dnouri/nolearn.git $ cd nolearn $ python setup.py install --user For example, the following code downloads the MNIST dataset, trains a model on it and evaluates the result for a single image: #!/usr/bin/env python import lasagne from lasagne import layers from lasagne.updates import nesterov_momentum from nolearn.lasagne import NeuralNet import sys import os import gzip import pickle import numpy PY2 = sys . version_info [ 0 ] == 2 if PY2 : from urllib import urlretrieve def pickle_load ( f , encoding ): return pickle . load ( f ) else : from urllib.request import urlretrieve def pickle_load ( f , encoding ): return pickle . load ( f , encoding = encoding ) DATA_URL = 'http://deeplearning.net/data/mnist/mnist.pkl.gz' DATA_FILENAME = 'mnist.pkl.gz' def _load_data ( url = DATA_URL , filename = DATA_FILENAME ): \"\"\"Load data from `url` and store the result in `filename`.\"\"\" if not os . path . exists ( filename ): print ( \"Downloading MNIST dataset\" ) urlretrieve ( url , filename ) with gzip . open ( filename , 'rb' ) as f : return pickle_load ( f , encoding = 'latin-1' ) def load_data (): \"\"\"Get data with labels, split into training, validation and test set.\"\"\" data = _load_data () X_train , y_train = data [ 0 ] X_valid , y_valid = data [ 1 ] X_test , y_test = data [ 2 ] y_train = numpy . asarray ( y_train , dtype = numpy . int32 ) y_valid = numpy . asarray ( y_valid , dtype = numpy . int32 ) y_test = numpy . asarray ( y_test , dtype = numpy . int32 ) return dict ( X_train = X_train , y_train = y_train , X_valid = X_valid , y_valid = y_valid , X_test = X_test , y_test = y_test , num_examples_train = X_train . shape [ 0 ], num_examples_valid = X_valid . shape [ 0 ], num_examples_test = X_test . shape [ 0 ], input_dim = X_train . shape [ 1 ], output_dim = 10 , ) def nn_example ( data ): net1 = NeuralNet ( layers = [( 'input' , layers . InputLayer ), ( 'hidden' , layers . DenseLayer ), ( 'output' , layers . DenseLayer ), ], # layer parameters: input_shape = ( None , 28 * 28 ), hidden_num_units = 100 , # number of units in 'hidden' layer output_nonlinearity = lasagne . nonlinearities . softmax , output_num_units = 10 , # 10 target values for the digits 0, 1, 2, ..., 9 # optimization method: update = nesterov_momentum , update_learning_rate = 0.01 , update_momentum = 0.9 , max_epochs = 10 , verbose = 1 , ) # Train the network net1 . fit ( data [ 'X_train' ], data [ 'y_train' ]) # Try the network on new data print ( \"Feature vector (100-110): %s \" % data [ 'X_test' ][ 0 ][ 100 : 110 ]) print ( \"Label: %s \" % str ( data [ 'y_test' ][ 0 ])) print ( \"Predicted: %s \" % str ( net1 . predict ([ data [ 'X_test' ][ 0 ]]))) def main (): data = load_data () print ( \"Got %i testing datasets.\" % len ( data [ 'X_train' ])) nn_example ( data ) if __name__ == '__main__' : main () The output is # Neural Network with 79510 learnable parameters ## Layer information # name size --- ------ ------ 0 input 784 1 hidden 100 2 output 10 epoch train loss valid loss train/val valid acc dur ------- ------------ ------------ ----------- ----------- ----- 1 0.59132 0.32314 1.82993 0.90988 1.70s 2 0.30733 0.26644 1.15348 0.92623 1.96s 3 0.25879 0.23606 1.09629 0.93363 2.09s 4 0.22680 0.21424 1.05865 0.93897 2.13s 5 0.20187 0.19633 1.02827 0.94313 2.21s 6 0.18129 0.18187 0.99685 0.94758 1.81s 7 0.16398 0.16992 0.96506 0.95074 2.14s 8 0.14941 0.16020 0.93265 0.95262 1.88s 9 0.13704 0.15189 0.90222 0.95460 2.15s 10 0.12633 0.14464 0.87342 0.95707 2.21s Feature vector (100-110): [ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] Label: 7 Predicted: [7] See also Getting Started with Deep Learning and Python","tags":"Machine Learning","title":"Lasagne for Python Newbies"},{"url":"https://martin-thoma.com/echtzeitsysteme-klausur/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žEchtzeitsysteme\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr. WÃ¶rn im Sommersemester 2015 gehÃ¶rt. Behandelter Stoff Vorlesung Der Dozent verwendete einige AbkÃ¼rzungen, die mir nicht gelÃ¤ufig waren. Diese habe ich unter anderem in der folgenden Tabelle aufgefÃ¼hrt. Datum Kapitel Inhalt 14.04.2015 Kapitel 1 (ES1-1 - ES1-24) SPS ; NC; RC; Daisy chain ; Mikroprozessor vs. Mikrorechner vs. Mikrorechnersystem; Aufbau eines Mikroprozessors; Speicherhierachie (L1-, L2- und L3-Cache, Hauptspeicher, Festplatte); superskalare Pipeline; Fixed- priority-preemptive Unterbrechungsbehandlung 15.04.2015 Kapitel 1 (ES1-25 - ES1-60) Watchdogs, Jitter , DMA , Signalprozessor , VLIW ; verschiedene Bus-Arten (z.B. PCI-Bus), Bus-Arbitation kÃ¼mmert sich bei mehreren Bus-Mastern um die Zugriffskontrolle. Das kann zentral oder dezentral (z.B. Ã¼ber eine Daisy-Chain oder einen Identifikationsbus) geschehen; 21.04.2015 Kapitel 1 (ES1-62 - ES1-83) Arbitrierung; Transaktionen 22.04.2015 Kapitel 2 (ES2-1 - ES2-?) Ohmsches Gesetz ; Parallel- und Reihenschaltung von WiderstÃ¤nden; Spannungsteiler; Knotenregel ; Maschenregel ; Transistoren; Addierer; Differenzierer; Invertierter Addierer; Integrierer; AD/DA-Wandler 28.04.2015 Kapitel 2 (?) ? 12.05.2015 ? Hurwitz-Kriterium; Ortskurve; P-, Pi- und PID-Regler (I: RÃ¼ck-Knala, D: Ã„nderung); Vorsteuerung, Car Cruise Control 19.05.2015 2. Ãœbung OperationsverstÃ¤rker, AD-Wandler 20.05.2015 ? ? 26.05.2015 3. Ãœbung Mit Jessica Hutzl 27.05.2015 Kapitel 4 (- ES 4-43) ISO/OSI-Modell, Profibus, CAN-Bus, INTERBUS 02.06.2015 Kapitel 4, 5 (ES 4-44 - 5-16) Rechtzeitigkeit 03.06.2015 ? ? 09.06.2015 Ãœbung Regelung 10.06.2015 Ãœbung - AbkÃ¼rzungen LLF: Least-Laxity-First-Scheduling EDF: Earliest-Deadline-First-Scheduling GPS: Guaranteed Percentage Scheduling Wichtiges Ist eine Ãœbertragungsfunktion in Pol-und-Nullstellenform \\(G(s)\\) stabil? â†’ Ja, falls der Realanteil aller Pole negativ ist. Ist eine Funktion \\(G(s)\\) stabile? â†’ Ja, falls die Nullstellen der Gleichung \\(G(s)+1=0\\) links der \\(i\\) -Achse liegen. Ist \\(G(i \\omega)\\) stabil? â†’ Ja, falls die Kurve (-1, 0i) NICHT umfÃ¤hrt (siehe Nyquistkriterium ) Hurwitz-Kriterium Ein System \\(a_n x&#94;{(n)} + a_{n-1} x&#94;{(n-1)} + \\dots + a_1 \\dot{x} + a_0 x = 0\\) ist dann stabil, wenn alle Koeffizienten \\(a_i > 0\\) UND alle Hauptabschnittsdeterminanten (auch Hauptminoren genannt) positiv sind. Insbesondere gilt fÃ¼r \\(a_2 \\cdot \\ddot{x} + a_1 \\dot{x} + a_0 x = 0\\) , dass die Hauptabschnittsdeterminanten von $$\\begin{pmatrix}a_1 & 0\\\\0 & a_0\\end{pmatrix}$$ zu Ã¼berprÃ¼fen sind. Das ist jedoch schon durch das erste Kriterium erfÃ¼llt. Bei \\(a_3 \\cdot x&#94;{(3)} + a_2 \\cdot \\ddot{x} + a_1 \\dot{x} + a_0 x = 0\\) ist $$\\begin{pmatrix}a_2 & a_0 & 0\\\\1 & a_1 & 0\\\\ 0 & a_2 & 1\\end{pmatrix}$$ zu Ã¼berprÃ¼fen, also: \\(a_2 > 0\\) ? \\(a_2 \\cdot a_1 - a_0 > 0\\) ? (the determinant of size 2 and 3 is the same) Schaltungen Subtrahierer: \\(U_A = \\frac{R_0 (R_1 + R_3)}{R_1 (R_0 + R_2)} \\cdot U_2 - \\frac{R_3}{R_1} \\cdot U_1\\) Invertierender Addierer: \\(U_A = - \\left (\\sum_{i=1}&#94;{N-1} \\frac{U_i}{R_i} \\right ) \\cdot R_N\\) Integrierer: \\(- \\frac{1}{RC} \\int U_E \\mathrm{d}t\\) Differenzierer: \\(U_A = - R_N \\cdot I_E\\) Invertierender OP: \\(y = - \\frac{R_N}{R_1}\\) Nicht-Invertierender OP: \\(y = \\frac{R_N+R_1}{R_1}\\) Parallelverfahren (vgl. ES 2 - 37) Typische Klausur Die Klausuren sind alle sehr Ã¤hnlich zu einander: Regelung Zeitkonstante Regelung: 7 Punkte Definition Regelung / Steuerung: 1 Punkt Laplace-Bereich / Ãœbergangsfunktion: 1 Punkt Transformationstabelle / Differentialgleichung: 1 Punkt Ist ein gegebenes System stabil? (mit Ãœbergangsfunktion): 1 Punkt PID-Regler / stabilitÃ¤t / Fehler: 2 Punkte GÃ¼tegrad von Regelungssystem: 1.5 Punkte Bode-Diagramm: 1.5 Punkte Zeitdiskrete Regelung: 8 Punkte Aliasing / Abtasttheorem: 1 Punkt Z-Transformierte Ãœbertragungsfunktion G(z): 2 Punkte Z-Transformierte / PD-Regelalgorithmus: 1 Punkt Z-Transformierte / Regelkreis: 1 Punkt Differenzialgleichungen â†’ Differenzengleichung: 2 Punkte Digital vs. Kontinuierlich (Diskretisierung): 1 Punkte StabilitÃ¤t eines Systems: 1 Punkt Rechnerarchitekturen / Busse / OperationsverstÃ¤rker Rechnerarchitekturen und Busse: 10 Punkte Watchdog: 1 Punkt Echtzeitausgabeeinheit (Konzept, Definition, Eigenschaften): 1 Punkt Befehlsskalarer Prozessor / Sprungbedingungen: 1 Punkt Bus-Eigenschaften: 2 Punkte EchtzeitfÃ¤hig oder nicht Synchron â†” asynchron Getrennter Adress- und Datenbus â†” multiplex Burst-Datentransfer erlaubt oder auch nicht OperationsverstÃ¤rker in Analog- und Digitaltechnik: 8 Punkte Schaltsymbol OperationsverstÃ¤rker (mit Versorgungsspannung), AnschlÃ¼sse beschriften: 1 Punkt EingangsstrÃ¶me (real/ideal): 1 Punkt OperationsverstÃ¤rker: 4 Punkte Prinzip Operationswandler: 1 Punkt Asymmetrische / differenzielle DatenÃ¼bertragung: 1 Punkt A/D-Wandler: 2 Punkte Echtzeitkommunikation / Programmierung: 7 Punkte ISO / OSI-Schichtenmodell: 1.5 Punkte Manchester-Codierung: 1.5 Punkte Ãœbertragungsfehler: 1.5 Punkte CAN-Dataframes: 2.5 Punkte ZusÃ¤tzliche Forderungen an Echtzeitsysteme: 1 Punkt FPP-Scheduling: 2 Punkte Periodenabweichung: 2 Punkte Optimales Scheduling: 1 Punkt Schwankungen: 1 Punkt Echtzeit-OS / SPS Echtzeit-OS: 7 Punkte ZusÃ¤tzliche Anforderungen: 1 Punkt ZusÃ¤tzliche Anforderungen Middleware: 1 Punkt Beispiele: 1 Punkt Sperrsynchronisation: 2 Punkte Seitenadressierung: 2 Punkte SPS: 8 Punkte FUP â†’ AWL : 2.5 Punkte FUP â†’ Structured Text: 2.5 Punkte 3 Verarbeitungsschirtte von SPS im zyklischen Programmbetrieb: 1 Punkt Konventionelle SPS â†” Soft: 1 Punkt Graphische â†” textuelle Programmiersprache: 1 Punkt Material und Links Vorlesungswebsite Ilias Klausur-MusterlÃ¶sungen Meine Anki-Karten (bestehend aus Teilen von Echtzeitsysteme - KIT WÃ¶rn und Echtzeitsysteme KIT WÃ¶rn Wissensfragen Klausur sowie weiteren Karten) StackOverflow: What is the difference between DMA and memory-mapped IO? Ãœbungsbetrieb Wo sind die ÃœbungsblÃ¤tter: ? (Ilias?) Abgabeform: Keine Abgabe Abgabe (wochentag): Keine Abgabe RÃ¼cknahme: - Turnus: ? Ãœbungsschein verpflichtend: Es gibt keinen Ãœbungsschein. Bonus durch Ãœbungsschein: Es gibt keinen Ãœbungsschein. Termine und Klausurablauf Datum : Donnerstag, der 24.09.2015 von 14:00 Uhr-15:00 Uhr ( Quelle ) Ort : Gehrtsen HS ( Geb. 30.21 ) Punkte : 60 Punkteverteilung : 4 Aufgaben Ã  15 Punkte: Regelung Rechnerarchitekturen, Busse, OperationsverstÃ¤rker, Analog-/Digitaltechnik Echtzeitkommunikation und Echtzeitprogrammierung Echtzeitbetriebssysteme und SPS Bestehensgrenze : ? Ãœbungsschein : Gibt es nicht. Bonuspunkte : Gibt es nicht. Ergebnisse : Die Noten der Klausur werden am Schwarzen Brett im IAR-IPR (Geb. 40.28, Foyer, links) ausgehÃ¤ngt. Noch ist nichts da (Stand: 24.09.2015) Einsicht : wird Ã¼ber Ilias bekannt gegeben Erlaubte Hilfsmittel : Keine Fazit Dieses Modul kann man sich getrost schenken. Wenn man vorher nichts von Regelungstechnik weiÃŸ, ist man hinterher auch nicht schlauer. Es scheint so zu sein, dass die klausurrelevanten Teile alle in den Ãœbungen besprochen werden. Die bereitgestellten Materialien hÃ¤tten besser sein kÃ¶nnen. Es gibt zwar ein Skript welches sogar eine ISBN-Nummer hat, aber insbesondere bei dem Regelungstechnik-Teil ist es nicht sonderlich hilfreich. Ich hatte das GefÃ¼hl, dass mir da einfach Grundlagen fehlen. Diese werden auch nicht erklÃ¤rt. Zu den PDF-Folien muss man sagen, dass diese zwar schnell im Ilias hochgeladen wurden, aber teilweise zu viele Informationen hatten. Es war nicht klar, was wichtig ist. AuÃŸerdem hat teilweise, wenn man nur die Folien angesehen hat, der Kontext gefehlt. Ein Highlight waren Videos, in denen Roboter Kugeln auf einem Tablett sehr schnell transportieren. Dazu mÃ¼ssen die Roboter das Tablett im richtigen Winkel neigen. Das war ein Highlight der Vorlesung. Schade, dass nie erklÃ¤rt wurde wie so etwas berechnet wird. Vorwissen in der Regelungstechnik und bei Differentialgleichungen ist sicher hilfreich. Die Klausurvorbereitung besteht hauptsÃ¤chlich aus Auswendiglernen. VerstÃ¤ndnis ist wohl nicht nÃ¶tig (mal schauen... ich konnte keinen NotenschlÃ¼ssel finden.), da die Klausuren immer nahezu identisch aufgebaut sind. Meine Empfehlung an Studenten ist, in die Ãœbung zu gehen. Da kommen die klausurrelevanten Sachen. Teilweise 1-zu-1 die gleichen Fragen. VerbesserungsvorschlÃ¤ge fÃ¼r die Dozenten hÃ¤tte ich auch ein paar: Es sollte Tutorien geben. Es sollte einen verpflichtenden Ãœbungsschein geben. Mit 50% der Punkte hat man den Ãœbungsschein, ab 75% gibts Bonuspunkte fÃ¼r die Klausur. Diese ÃœbungsblÃ¤tter werden von den Tutoren korrigiert und besprochen. Wenn die Studenten es reihenweise nicht schaffen merkt man schon, wo man die Vorlesung verbessern muss. VerÃ¶ffentlichung der MusterlÃ¶sungen zu den Klausuren. Anpassung des Skripts, z.B. wurde der VME-Bus durch den PCIe-Bus ersetzt. Anpassung des Modulhandbuchs. Man sollte den Leuten empfehlen , zuvor die Vorlesung \"Betriebssysteme\" gehÃ¶rt zu haben. Ein Wikibook beginnen. Wenn man das fÃ¼r jedes Modul machen wÃ¼rde, kÃ¶nnte man auch AbhÃ¤ngigkeiten besser sehen und Studenten kÃ¶nnten fehlendes Wissen leichter nachholen. AuÃŸerdem wÃ¼rde man das Wissen frei verfÃ¼gbar machen und man kÃ¶nnte die Exzellenz der Lehre zeigen, falls man wirklich der Meinung ist die Lehre am KIT sei exzellent. Ãœber die Diskussionsseiten kÃ¶nnten Studenten und andere weitgehend anonym ihre Fragen stellen und VerbesserungsvorschlÃ¤ge machen. Ãœber das Wiki-System kÃ¶nnten freiwillige Helfer insbesondere bei zeitaufwendigen Grafiken helfen.","tags":"German posts","title":"Echtzeitsysteme - Klausur"},{"url":"https://martin-thoma.com/markovsche-ketten-klausur/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žMarkovsche Ketten\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Dr. Bernhard Klar im Sommersemester 2015 gehÃ¶rt. Der Artikel wird bis zur Klausur laufend erweitert. Behandelter Stoff Es wÃ¤re toll, wenn ich von jeder Vorlesung einen Mitschrieb hochladen kÃ¶nnte. Gibt es Leute, die eine Kamera / einen Scanner haben und mir ihren Mitschrieb als JPG-Bilder schicken wÃ¼rden? Einfach an info@martin-thoma.de schicken. Vorlesung Zur Vorlesung gibt es das Skript \"Markov-Ketten\" von Frau Prof. Dr. BÃ¤uerle. (Ich habe eine Version von 2012). Datum Kapitel Inhalt 13.04.2015 0. Beispiele ( Mitschrieb ) EinfÃ¼hrung in Markovketten mit vielen Beispielen (Weg des Betrunkenen, Ehrenfest-Modell, Irrfahrt, Vererbung); absorbierende ZustÃ¤nde; stochastische Matrix 16.04.2015 1. Konstruktion von Markov-Ketten 20.04.2015 21.04.2015 3.10 - 4.6 ( Mitschrieb ) Total-Variationsabstand, $d(\\mu, \\nu) = \\frac{1}{2} \\sum_{i \\in S} |\\mu(i)- \\nu(i)|$, Periode, aperiodisch, ein Konvergenzsatz, Kopplungsargument Material und Links KIT Vorlesungswebsite Ilias Sonstiges Markov Chains : A very short introduction to markov chains with beautiful visualizations Wichtigster Stoff Wie immer Definitionen (Markovkette, transient, rekurrent, Klasse, irreduzibel) Wenn man die Matrix so umsortiert, dass rechts unten die rekurrenten ZustÃ¤nde sind (das ist nicht immer eine Einheitsmatrix!), Dann heiÃŸt die Matrix links oben \\(Q\\) und rechts oben \\(R\\) . Dann gilt: \\((E-Q)&#94;{-1} \\cdot R\\) : Absorptionszeit $$(E-Q)&#94;{-1} \\cdot \\begin{pmatrix}1\\\\\\vdots\\\\1\\end{pmatrix}$$ : Schritte bis zur Absorption. Invariantes MaÃŸ finden: \\(\\pi P = \\pi\\) bzw. \\(\\pi Q = 0\\) im zeitkontinuierlichen Fall Ãœbungsbetrieb Es gibt Dienstags und Mittwochs Tutorien. Wo sind die ÃœbungsblÃ¤tter: Ilias Abgabeform: Handgeschrieben (?) Abgabe: ? RÃ¼cknahme: ? Turnus: WÃ¶chentlich Ãœbungsschein verpflichtend: Nein Bonus durch Ãœbungsschein: Nein Termine und Klausurablauf Datum : Montag, der 03.08.2015 von 11:00 bis 13:00 Uhr ( Quelle ) Ort : Daimler-HÃ¶rsaal (Geb. 10.11, Quelle ) Punkte : 60 Punkteverteilung : 6 Aufgaben mit 9-13 Punkten Bestehensgrenze : ? Ãœbungsschein : ? Bonuspunkte : ? Ergebnisse : ? Einsicht : Montag, 19.10.2015, 13:00 Uhr - 13:30 Uhr, Im Raum 2.071, MathematikgebÃ¤ude Erlaubte Hilfsmittel : ?","tags":"German posts","title":"Markovsche Ketten - Klausur"},{"url":"https://martin-thoma.com/wahrscheinlichkeitstheorie-klausur/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žWahrscheinlichkeitstheorie\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr. Henze im Sommersemester 2015 gehÃ¶rt. Der Artikel wird bis zur Klausur laufend erweitert. Der Dozent veweist immer wieder auf die Vorlesung Analysis III und insbesondere das Skript von Prof. Hundertmark. Kann mir das jemand schicken? Behandelter Stoff Vorlesung Datum Kapitel Inhalt 13.04.2015 MaÃŸtheoretische Grundlagen 0.1 - 1.13 Wiederholung von Begriffen: MaÃŸ , \\(\\sigma\\) -Algebra , Halbring , Dynkin-System , DurchschnittsstabilitÃ¤t ( \\(A, B \\in \\mathcal H \\Rightarrow A \\cap B \\in \\mathcal H\\) ) 15.04.2015 ? ? 20.04.2015 ? ? 27.04.2015 ? ? 29.04.2015 ? ? 04.05.2015 ? ? 11.05.2015 ? ? 13.05.2015 ? ? 18.05.2015 ? ? 27.05.2015 ? ? 01.06.2015 ? ? 03.06.2015 ? ? 10.06.2015 ? ? 15.06.2015 ? ? 22.06.2015 ? ? 24.06.2015 ? ? 29.06.2015 ? ? 06.07.2015 ? ? 08.07.2015 ? ? 13.07.2015 ? ? Material und Links Vorlesungswebsite Ilias Ãœbungsbetrieb Wo sind die ÃœbungsblÃ¤tter: ? Abgabeform: ? Abgabe: ? RÃ¼cknahme: ? Turnus: ? Ãœbungsschein verpflichtend: ? Bonus durch Ãœbungsschein: ? Termine und Klausurablauf Datum : Donnerstag, der 30.07.2015 von 11:00 bis 13:00 Uhr ( Quelle ) Ort : Hertz-HÃ¶rsaal (Geb. 10.11, Quelle ) Punkte : ? Punkteverteilung : ? Bestehensgrenze : ? Ãœbungsschein : ? Bonuspunkte : ? Ergebnisse : ? Einsicht : ? Erlaubte Hilfsmittel : ?","tags":"German posts","title":"Wahrscheinlichkeitstheorie-Klausur"},{"url":"https://martin-thoma.com/python-code-documentation/","text":"Documentating your code is important when you make non-trivial projects. The standard way to document Python code is with Sphinx . You write the documentation files with reStructuredText . One of the most important Sphinx plugins is autodoc . This allows you to generate the documentation of modules, classes and functions automatically by using their docstrings. There are 3 standard ways to write docstrings: Sphinxy, Googley or NumPyDocy. The Sphinx Way def preprocessing ( self , algorithms ): \"\"\"Apply preprocessing algorithms. :param algorithms: Preprocessing allgorithms which get applied in order. :type algorithms: a list objects >>> import preprocessing >>> a = HandwrittenData(...) >>> preprocessing_queue = [(preprocessing.scale_and_shift, []), ... (preprocessing.connect_strokes, []), ... (preprocessing.douglas_peucker, ... {'EPSILON': 0.2}), ... (preprocessing.space_evenly, ... {'number': 100, ... 'KIND': 'cubic'})] >>> a.preprocessing(preprocessing_queue) \"\"\" assert type ( algorithms ) is list for algorithm in algorithms : algorithm ( self ) The Google Way Google documented its format at http://google-styleguide.googlecode.com/ . (I'm wondering where that will move, now that they plan to shut code.google.com down. Probably to GitHub.) def preprocessing ( self , algorithms ): \"\"\"Apply preprocessing algorithms. Args: algorithms (a list objects): Preprocessing allgorithms which get applied in order. Examples: >>> import preprocessing >>> a = HandwrittenData(...) >>> preprocessing_queue = [(preprocessing.scale_and_shift, []), ... (preprocessing.connect_strokes, []), ... (preprocessing.douglas_peucker, ... {'EPSILON': 0.2}), ... (preprocessing.space_evenly, ... {'number': 100, ... 'KIND': 'cubic'})] >>> a.preprocessing(preprocessing_queue) \"\"\" assert type ( algorithms ) is list for algorithm in algorithms : algorithm ( self ) To get the google way render well in Sphinx, you need Napoleon . The NumPyDoc Way def preprocessing ( self , algorithms ): \"\"\"Apply preprocessing algorithms. Parameters ---------- algorithms : a list objects Preprocessing allgorithms which get applied in order. Examples -------- >>> import preprocessing >>> a = HandwrittenData(...) >>> preprocessing_queue = [(preprocessing.scale_and_shift, []), ... (preprocessing.connect_strokes, []), ... (preprocessing.douglas_peucker, ... {'EPSILON': 0.2}), ... (preprocessing.space_evenly, ... {'number': 100, ... 'KIND': 'cubic'})] >>> a.preprocessing(preprocessing_queue) \"\"\" assert type ( algorithms ) is list for algorithm in algorithms : algorithm ( self ) To make numpydoc render well, you need the numpydoc sphinx extension . See also A Guide to NumPy/SciPy Documentation sphinxcontrib-napoleon.readthedocs.org : A longer numpydoc example","tags":"Code","title":"Python Code Documentation"},{"url":"https://martin-thoma.com/python-ctypes/","text":"One pseudo-problem people often mention when talking about Python is that Python is (too) slow. What they seem to forget or don't know is that you can call C code from Python with ctypes . So you can get almost as fast as you can get with C; you're not limited by the language in that respect. And most of the time your code has other issues when it is too slow. Now, you can also wrap Rust code with ctypes for Python â˜º Motivation As a very simple example, I prepared a dumb Fibonacci implementation written in Python: def fib ( n ): \"\"\"Calculate the n-th Fibonacci number.\"\"\" if n <= 1 : return n else : return fib ( n - 1 ) + fib ( n - 2 ) if __name__ == '__main__' : n = 37 print ( \"The %i th Fibonacci number is %i .\" % ( n , fib ( n ))) and exactly the same for Rust pub extern fn fib ( n : u32 ) -> u32 { if n <= 1 { return n ; } else { return fib ( n - 1 ) + fib ( n - 2 ); } } fn main () { let n = 37 ; println ! ( \"The {0}th Fibonacci number is {1}.\" , n , fib ( n )) } The execution times are quite different. Rust needs 0.40 seconds while Python 3 needs 15.7 seconds. That is almost 40Ã— the time of Rust! Wouldn't it be great if we could call the Rust function from Python? Example I'll explain in the next chapters what is done, but at first you should see that there are only minor changes / overhead: fibonacci.rt : #![crate_type = \"dylib\" ] #[no_mangle] pub extern fn fib ( n : u32 ) -> u32 { if n <= 1 { return n ; } else { return fib ( n - 1 ) + fib ( n - 2 ); } } Call rustc -O fibonacci.rt to generate the library. Python: #!/usr/bin/env python import ctypes fiblib = ctypes . CDLL ( \"./libfibonacci.so\" ) fib = fiblib . fib n = 37 print ( \"The %ith Fibonacci number is %i.\" % ( n , fib ( n ))) Now, taking the Python code, it takes only 0.44 seconds! What happens The line #![crate_type = \"dylib\"] tells rustc that it has to create a dynamic library. The line #[no_mangle] tells the compiler not to mangle the name fib . This is important so that we can later use it from Python. (I think names are mangled to prevent name clashes ... so it's a kind of name-spacing.) Then we load the C DLL with ctypes.CDLL(\"./libfibonacci.so\") and use it as expected. Pretty easy, isn't it? Caveats Python makes some things very simple which are not that simple at all. Think about numbers, for example. In Rust, you have integers with 64 bits. But in Python you have arbitrary length integers. This might lead to problems. See also Calling Rust from C (and Python!) doc.rust-lang.org/book/ffi : Foreign Function Interface doc.rust-lang.org : FFI attributes rustbyexample.com : Crates","tags":"Code","title":"Python ctypes"},{"url":"https://martin-thoma.com/the-rust-programming-language/","text":"Rust is a compiled programming language which aims to replace C++. The designers wanted it to be similar fast, give the programmer similar fine-grained control over memory management, but more safety. Rust does so by introducing the concept of ownership , borrowing and lifetimes of variables. Rust also makes sure that after the scope is finished, the memory of variables gets de-allocated. I think FFI is interesting. It allows Rust to \"talk\" with C code. Rust 1.0 was just released ( source ). This means the language should be stable. If you want to know more, you should take a look at the beautiful A 30-minute Introduction to Rust . Syntax Example fn fib ( n : u32 ) -> u32 { if n <= 1 { return n ; } else { return fib ( n - 1 ) + fib ( n - 2 ); } } fn main () { let n = 36 ; println ! ( \"The {0}th Fibonacci number is {1}.\" , n , fib ( n )) } Video introduction Comparison benchmarksgame shows that rust is similar fast as C++. For some games it is faster, for some slower. Sometimes it needs less code, sometimes more. stackoverflow has only 1781 questions of which are 102 unanswered (5.7%). C++ has 356,824 questions and 55,172 questions are not answered (15.5%). But I guess that will change as soon as more people use Rust (and libraries written in Rust). GitHub : Wow, Rust seems to be growing fast! Tools As rust is still in very heavy development, you should build it yourself from the source at GitHub . Don't worry, there are very detailed instructions. (But it takes a lot of time to compile.) cargo package manager Syntax Highlighting and auto completion for ST3 ( via Package Control ) Auto completion with Racer Comparison to C++ 1: No crashes because of code misuse (as long as you do not use unsafe {} ) 2: No memory leaks 3: No data races (so you can thread this thing like mad, but better is has async task handling (crs pattern to). So lighting up your machines cores is no prob. 4: Cross platform (really much better than most) 5: Inbuilt version management, build system and test harness (with benchmarking to). 6: Package management system (no more I Cannot build XX, it becomes automatic) 7: Inbuilt generics and traits (c++ concepts and more) 8: Very strongly typed (near zero runtime) 9: Very fast 10 compiles into a c lib basically (easy integration) Source: dirvine See also www.rust-lang.org : Official Website doc.rust-lang.org : Shown with fmt - looks very nice! doc.rust-lang.org/intro.html doc.rust-lang.org/book/ doc.rust-lang.org/reference.html blog.rust-lang.org crates.io : Hosting site for community packages â˜º rustbyexample.com joshondesign.com/2014/09/17/rustlang : A short introduction to Rust with a tiny ray tracer. learnxinyminutes.com/docs/rust Conclusion Rust looks very, very interesting. I am usually not a fan of new languages (e.g. I don't see a reason to use Go , Swift ... not to speak of Clojure , Julia , TypeScript , Dart ). Most of the time, I don't see anything new which is better than in existing languages and almost always the material around (tools, libraries, community) is much worse than in existing solutions. This seems to be different with Rust. Rust seems to provide everything I enjoy from Python, but in the fast, explicitly typed world. @ Johannes : Thanks for pointing me to Rust â˜º","tags":"Code","title":"The Rust Programming Language"},{"url":"https://martin-thoma.com/dreamspark-sdm-odysee/","text":"I need to have Windows for work. As a student I should have free access to it. But when I try to download it, I have to use Microsofts \"Secure Download Manager\" (SDM). As a Ubuntu (Linux) user, this is easier said than done. TL;DR You need a Windows PC to download Windows. Ask a friend to download it. That might be the easiest way. If you have a Windows PC and get the same error as I get, you might need to re-install the system. (No, rebooting does not help.) What I've tried and what does not work: Wine VMs Avoiding SDM What I am currently trying: Installing Windows 7 on another computer. argh UPDATE: How to bypass Secure Download Manager while downloading from Dreamspark looks very promising. The problem Using the Windows 8 systems at my university gives: Error message when trying to install SDM Das Feature, das Sie verwenden mÃ¶chten, befindet sich auf einer Netzressource, die nicht zur VerfÃ¼gung steht. Klicken Sie auf \"OK\", um den Vorgang zu wiederholen. Oder geben Sie in das untenstehende Feld den Pfad zu einem anderen Ordner ein, der das Installationspaket \"SDM_DE.msi\" enthÃ¤lt. (Sorry, I only get the German error message.) When I give the path of the SDM_DE.msi I get: Die Datei \"Z:\\sdm\\SDM_DE.msi\" ist kein gÃ¼ltiges Installationspaket fÃ¼r das Produkt \"Secure Download Manager\". Suchen Sie das Installationspaket \"SDM_DE.msi\" in einem Order, von dem aus Sie \"Secure Download Manager\" installieren kÃ¶nnen. Then I got desperate and followed threadsofscience.wordpress.com/2013/02/13/downloading-dreamspark-microsoft-windows-on-ubuntu (similar: http://boris-spinner.de/secure-download-manager-sdm-unter-linux-ausfuehren/). It seems as if I need Linux to emulate Windows to get Windows ... it's a strange world. wine: Bad EXE format for Z:\\home\\moose\\Downloads\\SDM_EN.msi. Seems to be a 32-bit / 64-bit problem ... http://wiki.winehq.org/FAQ#32_bit_wineprefix https://appdb.winehq.org/objectManager.php?sClass=version&iId=31542 After trying to fix it, I get err:msidb:get_tablecolumns column 1 out of range err:msidb:get_tablecolumns column 2 out of range fixme:storage:create_storagefile Storage share mode not implemented. err:msidb:get_tablecolumns column 1 out of range err:msidb:get_tablecolumns column 2 out of range err:msidb:get_tablecolumns column 1 out of range err:msidb:get_tablecolumns column 2 out of range err:msidb:get_tablecolumns column 1 out of range err:msidb:get_tablecolumns column 2 out of range err:msidb:get_tablecolumns column 3 out of range err:msidb:get_tablecolumns column 1 out of range err:msidb:get_tablecolumns column 2 out of range err:msidb:get_tablecolumns column 3 out of range err:msidb:get_tablecolumns column 1 out of range err:msidb:get_tablecolumns column 2 out of range err:msidb:get_tablecolumns column 3 out of range err:msidb:get_tablecolumns column 1 out of range err:msidb:get_tablecolumns column 2 out of range err:msidb:get_tablecolumns column 3 out of range Reverse Engineering ... a little bit Taking a look at the 1234567890ab.sdx file reveals that it contains only a single url: http://kit.onthehub.com/WebStore/Account/SdmAuthorize.aspx?o=12345678-1234-1234-123a-12234567890a&ws=12345678-1234-1234-1234-1234567890ab&uid=12345678-1234-1234-1234-1234567890ab&abc=5 (I've replaced the numbers by 123... to avoid problems with other people using my link to download stuff) However, I cannot simply download it there. There is a page with two downloads, but when I click on download nothing happens. SDM download page So I use Chrome developer tools ( Ctrl + shift + i ) to see the request. It's a GET request which gets the response: <information> <oiopua> 12345678-1234-1234-1234-1234567890ab </oiopua> <edv> 1234567890&#94;&#94;1234567890abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 </edv> <linkAvailable> 1 </linkAvailable> <errorTextKey /> <invokeExternalDownload> 0 </invokeExternalDownload> <fileURL> http://software.dreamspark.com/dreamspark/GERMAN/de_windows_8.1_with_update_x64_dvd_4048209.01.sdc </fileURL> </information> Although I can download the .sdc file, I cannot use it. It is an encrypted file (which would give the .iso , but I don't know how to encrypt it.). If you are interested in the file format, you might want to read Secure Digital Container VMs Another try is installing a VM. You can download some at https://www.modern.ie/en-us/virtualization-tools#downloads I downloaded IE11, Win 8.1. Importing the VM took about 15 minutes on my computer. Then I got another error: VM import error Installing Windows 7 12:50 I fortunately had a Windows 7 DVD lying around. Installing it will probably take another 2 hours or so... 13:23 - argh ... I just found another reason to hate Windows. I've just installed Windows 7. Cable-based network does not work out of the box. I have to install drivers from http://www.helpjet.net/files-Acer-TravelMate-5735Z.html#ANetwork Related Install Windows 8.1 from Dreamspark download on Ubuntu Why are Microsoft products so User unfriendly?","tags":"Cyberculture","title":"Dreamspark SDM Odysee"},{"url":"https://martin-thoma.com/httpie/","text":"Johannes recently showed me httpie . It's a very nice tool for sending HTTP requests. It is much simpler to use than curl . Installation $ sudo -H pip install httpie Usage $ http --form POST localhost:5000/api/recording recording =[{}] id = 1 HTTP/1.0 200 OK Content-Length: 21 Content-Type: text/html ; charset = utf-8 Date: Sun, 22 Mar 2015 15 :50:27 GMT Server: Werkzeug/0.10.1 Python/2.7.8 edit recording with 1 The output is colored in a very nice way: HTTPie in action See also github.com/jakubroztocil/httpie requestb.in","tags":"Code","title":"HTTPie"},{"url":"https://martin-thoma.com/python-and-encodings/","text":"Working with encodings different from ASCII or UTF-8 has always been work which I don't like. It doesn't feel very constructive to just make Python read a file / print some output. In the following, I will describe some strategies which might help you. Test script Copy the following text to a text file test.txt : Die sÃ¼ÃŸe, kleine, lÃ¤rmende Ãœberfliegerin lebt in der Haute-CÃ´te-Nord. Dort hat es momemtan 32Â°C. On Debian based systems you will get the information which type of encoding it has like this: $ file test.txt test.txt: UTF-8 Unicode text This is probably the best result. But to make sure that we know how to deal with other encodings, you can change the encoding like this: $ iconv -f UTF-8 -t ISO-8859-1 test.txt > test-iso-8859-1.txt $ file test-iso-8859-1.txt test-iso-8859-1.txt: ISO-8859 text Source code encoding A first important step is to define the source code encoding. This is done with a comment. The first lines of Python code should probably always look like this: #!/usr/bin/env python # -*- coding: UTF-8 -*- PEP-0263 explains it. Printing encoding problems The following error occurs when you try to print non-UTF-8 stuff with Python via Sublime Text: [Decode error - output not utf-8] The same code, executed via ZSH, gives: Die sï¿½ï¿½e, kleine, lï¿½rmende ï¿½berfliegerin lebt in der Haute-Cï¿½te-Nord. Dort hat es momemtan 32ï¿½C. You can fix that by adjusting the code the following way: #!/usr/bin/env python # -*- coding: UTF-8 -*- # Make it work with Python 2 and Python 3 import sys PY3 = sys . version > '3' if not PY3 : from future.builtins import open # Specify the encoding while opening it with open ( \"test-iso-8859-1.txt\" , encoding = \"ISO-8859-1\" ) as f : content = f . read () content = content . encode ( 'UTF-8' , 'replace' ) print ( content ) The two important points are Specifying the encoding while opening the file Encode the content with UTF-8 These three little steps helped me to deal with non-UTF-8 encodings. See also Unicode HOWTO codecs â€” Codec registry and base classes","tags":"Code","title":"Python and Encodings"},{"url":"https://martin-thoma.com/reading-and-writing-files-with-python/","text":"Reading (and writing) files with Python is very easy. Here are some minimalistic code examples for beginners. Reading A very common way to handle the contents of a file is by reading the file completely and then working with a single big string. The only reason not to do so is because your file is too big. For your information, this is how long reading a file takes (all times are in seconds, reading is executed 100 times): file size min max median average --------------------------------------------------- 10 KiB 0.0000 0.0008 0.0000 0.0002 100 KiB 0.0000 0.0009 0.0001 0.0002 1 MiB 0.0003 0.0013 0.0005 0.0006 10 MiB 0.0041 0.0079 0.0047 0.0049 100 MiB 0.0627 0.0778 0.0655 0.0663 As you can see, reading files is quite fast. However, I would recommend the start thinking if reading the complete file is appropriate when the file size exceeds 100 MiB as you might get different problems then. For example, the content of the file might not fit in your main memory (typically 4GiB, type cat /proc/meminfo | grep MemTotal to get how much main memory your computer has). See source code for details how I measured it. Completely with open ( 'filename.txt' ) as f : content = f . read () is all you need to read a text file completely in a Python string variable content . You could, for example, split the whole string to a list of lines: lines = content . split ( ' \\n ' ) Line by line You can read a text file line by line, but keep in mind that this will still have the endline character \\n in each line ! with open ( 'filename.txt' ) as f : for line in f : print ( line ) Writing To open files, you have to specify a mode. This is either reading, writing or appending (binary or text data). If you don't specify it, the default value is reading. So for writing you have to specify it: with open ( 'filename.txt' , 'w' ) as f : f . write ( \"Hello world!\" ) Python 3 Python 3 has some new features which are very nice to have. To get them in Python 2, you have to add from __future__ import print_function at the beginning of your code before other imports happen. Now you can print to files: from __future__ import print_function with open ( 'file.txt' , 'w' ) as f : print ( \"Hello World!\" , file = f ) The print function has also a \"end\" parameter which defaults to \\n . This means it adds \\n automatically at the end of each printed line. You might not want that e.g. in a Windows environment where it should be \\r\\n . with You might wonder what with does. My advice for newbees would be not to worry too much about it, it is just the way you juse I/O with Python. If you come from the C / C++ world, you might know that you have to close files when you opened them. The with statement makes sure that the file is closed when the block is finished. See also Python documentation: Input and Output print open with File Objects Python and CSV How to parse command line arguments in Python","tags":"Code","title":"Reading and Writing Files with Python"},{"url":"https://martin-thoma.com/python-csv/","text":"Python has a very nice module called csv which makes working with CSV very easy. This mini article is only a reminder for me so that I can easily find how to use it when I forget once again how it is used exactly. Reading CSV files try : from future.builtins import open except : pass import csv with open ( 'eggs.csv' , 'rt' , newline = '' ) as csvfile : csvreader = csv . reader ( csvfile , delimiter = ';' , quotechar = '\"' ) next ( csvreader , None ) # skip the headers for row in csvreader : print ( ', ' . join ( row )) Writing CSV files try : from future.builtins import open except : pass import csv with open ( 'eggs.csv' , 'w' , newline = '' ) as csvfile : csvwriter = csv . writer ( csvfile , delimiter = ';' , quotechar = '\"' , quoting = csv . QUOTE_MINIMAL ) csvwriter . writerow ([ 'Spam' ] * 5 + [ 'Baked Beans' ]) # Write header for row in container : csvwriter . writerow ( row ) # Write data See also Open files in 'rt' and 'wt' modes Python+CSV on StackOverflow","tags":"Code","title":"Python and CSV"},{"url":"https://martin-thoma.com/python-shell-autocomplete/","text":"One feature I really miss in Pythons interactive shell is tab autocompletion. Thanks to blog.e-shell.org I know how to get it: >>> import rlcompleter , readline >>> readline . parse_and_bind ( 'tab:complete' ) >>> smtplib . smtplib . CRLF smtplib . __getattribute__ ( smtplib . LMTP smtplib . __hash__ ( smtplib . LMTP_PORT smtplib . __init__ ( smtplib . OLDSTYLE_AUTH smtplib . __name__ smtplib . SMTP smtplib . __new__ ( smtplib . SMTPAuthenticationError ( smtplib . __package__ smtplib . SMTPConnectError ( smtplib . __reduce__ ( smtplib . SMTPDataError ( smtplib . __reduce_ex__ ( smtplib . SMTPException ( smtplib . __repr__ ( smtplib . SMTPHeloError ( smtplib . __setattr__ ( smtplib . SMTPRecipientsRefused ( smtplib . __sizeof__ ( smtplib . SMTPResponseException ( smtplib . __str__ ( smtplib . SMTPSenderRefused ( smtplib . __subclasshook__ ( smtplib . SMTPServerDisconnected ( smtplib . _addr_only ( smtplib . SMTP_PORT smtplib . _have_ssl smtplib . SMTP_SSL smtplib . base64 smtplib . SMTP_SSL_PORT smtplib . email smtplib . SSLFakeFile smtplib . encode_base64 ( smtplib . __all__ smtplib . hmac smtplib . __class__ ( smtplib . quoteaddr ( smtplib . __delattr__ ( smtplib . quotedata ( smtplib . __dict__ smtplib . re smtplib . __doc__ smtplib . socket smtplib . __file__ smtplib . ssl smtplib . __format__ ( smtplib . stderr Now if you want to always have that, you can get it by editing your ~/.pythonrc : import rlcompleter , readline readline . parse_and_bind ( 'tab:complete' ) You also have to make sure that the environment variable PYTHONSTARTUP is set to ~/.pythonrc . In my case, I had to add the line export PYTHONSTARTUP=~/.pythonrc to ~/.zshrc . I have also seen that there is another, \"more powerful\", Python shell called ipython. However, I don't understand how this shell supports autocompletion (see How does ipython3 import autocomplete work? ).","tags":"Code","title":"Python Shell autocomplete"},{"url":"https://martin-thoma.com/execute-python-on-apache2/","text":"I have to run a very simple Python script on an Apache2 web server. These were the steps with which I made it work: Find the Apache2 config $ /usr/sbin/apache2 -V It is in /etc/apache2/apache2.conf Add CGI Somewhere in the /etc/apache2/apache2.conf there is a <Directory ...> part. I've added Options ExecCGI and AddHandler cgi-script .py . Now this part looks like this: <Directory /var/www/> Options Indexes FollowSymLinks ExecCGI AddHandler cgi-script .py AllowOverride None Require all granted </Directory> Test it Create the following test.py file: #!/usr/bin/env python # -*- coding: UTF-8 -*- print ( \"Content-Type: text/html \\n \" ) print ( \"Hello World! The answer to live, the universe and everything is %i .\" % ( 2 * 21 )) Now call http://localhost/test.py . If that doesn't work, take a look at the apache log files: $ tail -f /var/log/apache2/error.log","tags":"Code","title":"Execute Python on Apache2"},{"url":"https://martin-thoma.com/gui-programming-with-python/","text":"A graphical user interface (GUI) is essential for applications which should be used by standard computer users (non-developers, not computer scientists, ...). However, I have almost no experience with GUI development outside of the web. Multiple GUI toolkits exist and the only one I have ever used is Tk for a very, very simple GUI. In this article, I want to share some of my thoughts about GUI development with Python as a beginner. I might update this in future. GUI toolkits A widget toolkit, widget library, GUI toolkit, or UX library is a library or a collection of libraries containing a set of graphical control elements (called widgets) used to construct the graphical user interface (GUI) of programs. Source: Widget toolkit Comparison I am only interested in GUI toolkits which work on Ubuntu 12.04+, which have a Python binding, which are OpenSource and have a good license, which are used by others (and hence have enough documentation and examples) It seems to me that only the following four toolkits fulfill these requirements: GTK, Qt, Tk, wxWidgets. Some of these have multiple Python bindings and all have multiple GUI builders / designers. I tried to find the most commonly used one. Please let me know if I should add something, replace something: .data-table { border-collapse: collapse; } .border-bottom { border-bottom: 1px solid #000; } .border-right { border-right: 1px solid #000; } Name GTK+ Qt Tk wxWidgets Latest version (23.01.2015) 3.14.1 5.4.0 8.6.3 3.0.2 Official Website gtk.org qt-project.org tcl.tk wxwidgets.org Initial release 1998 1995 1991 1992 Written in C C++ C C++ Documentation gtk.org/documentation.php doc.qt.io tkdocs.com wxwidgets.org/docs Tutorial developer.gnome.org/gtk-tutorial/stable qt-project.org/doc/qt-4.8/tutorials.html tkdocs.com/tutorial wxwidgets.org/docs/tutorials StackOverflow questions 4,715 37,626 929 1,918 StackOverflow unanswered 1,159 9,704 208 429 License LGPL 2.1 LGLP 3.0 (mutliple BSD-style wxWindows License Python binding PyGTK ( docs ) PySide ( docs ), PyQt Tkinter ( docs ) wxPython ( docs ) Python 3 support yes yes yes? yes Designer Glade Interface Designer QtDesigner, QtCreator, QDevelop, Edyuk SpecTcl wxGlade Famous applications Gnome applications like Inkscape, OTR-Verwaltung vlc, Virtual Box, KDE applications like K3B, Anki I could not find any Code::Blocks FileZilla 0 A.D. There are also some applications which use custom UI toolkits: Sublime Text Firefox LibreOffice See also List of widget toolkits Graphical user interface builder The Python GTK+ 3 Tutorial Why are Tk GUI's considered ugly? wxPython vs PyQt vs PyGTK: when and what to use? What's the difference between GTK and QT? Qt-specific Differences Between PySide and PyQt Should I use PyQt or PySide for a new Qt project? PyQt or PySide - which one to use Developing Cross Platform Application using Qt, PyQt and PySide : Introduction - Part 1 of 5","tags":"Code","title":"GUI programming with Python"},{"url":"https://martin-thoma.com/distribution-of-random-variables-when-max-gets-applied/","text":"I just wanted to solve an exercise where I had random variables \\(X_1, \\dots, X_n\\) which were all \\(U([0, 1])\\) distributed and \\(Y_n = \\max(X_1, \\dots, X_n)\\) . I wondered what the distribution of \\(Y_n\\) is (for big \\(n\\) ), so I wanted to plot it. How do I plot it? With Python, of course â˜º Here is the program: #!/usr/bin/env python import matplotlib.pyplot as plt import numpy.random def main (): # Generate Data n = 10000 numbers_a = numpy . random . uniform ( size = samples ) numbers_b = numpy . random . uniform ( size = samples ) numbers_c = numpy . random . uniform ( size = samples ) numbers_max = [ max ( a , b , c ) for a , b , c in zip ( numbers_a , numbers_b , numbers_c )] # Plot data plt . hist ( numbers_max ) plt . title ( \"Histogram\" ) plt . xlabel ( \"value\" ) plt . ylabel ( \"count\" ) plt . show () if __name__ == '__main__' : main () and here is the plot for \\(n = 2\\) Plot of the maximum of 2 uniformly distributed variables with 10000 samples If you increase to \\(n = 3\\) you get: Plot of the maximum of 3 uniformly distributed variables with 10000 samples Improved version I've also created an improved version which makes nicer plots, but might be harder to read: #!/usr/bin/env python import matplotlib.pyplot as plt import numpy.random def main ( samples , n ): # Generate Data numbers_l = [] n = n + 1 for _ in range ( n ): numbers_l . append ( numpy . random . uniform ( size = samples )) # Plot data plots = [] for i in range ( 1 , n ): # Build data structure sublist = numbers_l [: i ] max_list = numbers_l [ 0 ] for numbers_list in sublist : for i , el in enumerate ( numbers_list ): max_list [ i ] = max ( max_list [ i ], el ) plot_i = plt . hist ( max_list , histtype = 'step' , bins = 200 ) plots . append ( plot_i ) plt . title ( \"Histogram\" ) plt . xlabel ( \"value\" ) plt . ylabel ( \"count\" ) plt . show () def get_parser (): from argparse import ArgumentParser , ArgumentDefaultsHelpFormatter parser = ArgumentParser ( description = __doc__ , formatter_class = ArgumentDefaultsHelpFormatter ) parser . add_argument ( \"-n\" , dest = \"n\" , default = 3 , type = int , help = \"n\" ) parser . add_argument ( \"-s\" , \"--samples\" , dest = \"samples\" , default = 1000 , type = int , help = \"number of samples per Y_n\" ) return parser if __name__ == '__main__' : args = get_parser () . parse_args () main ( args . samples , args . n ) When you call this script with $ ./plot-random-variable.py -n 4 --samples 100000 it gives Plot of the maximum of 1 - 4 uniformly distributed variables with 10000 samples See also List of probability distributions Basic Data Plotting with Matplotlib Part 3: Histograms","tags":"Mathematics","title":"Distribution of Random Variables when max gets applied"},{"url":"https://martin-thoma.com/bug-reporting-a-users-perspective/","text":"Bug reporting is extremely important. It helps developers to get aware of problems and hence get the possibility to do something against it. It is impossible to guarantee for any real, non-trivial software that it has no bugs. Even when you formally prove that it is correct, the prove might be wrong. However, when users report bugs one can get confident that the remaining bugs are appearing very rarely or causing not so much harm. Reporting bugs is also important from a User Experience point of view. For me, it already helps to be able to report a bug / see that a bug was already reported. However, this is a pain in the ass for most software from a users perspective. I've just had that experience for Caja (the file explorer of MATE). Caja example Get information Caja crashed. I just wanted to create a new text file. Then it froze for about two seconds and closed. After another one or two seconds I got a crash report window. (I forgot to make a screenshot of that, but it looks like in the Google Chrome example) I clicked on something like \"examine locally\" - whatever that means. This is the first point I have to critize. The user should always know or at least be able to get the information what such messages mean. I was curious, so I clicked on it. Then this appeared: Apport 'examine locally' window This will launch apport-retrace in a terminal window to examine the crash. That is fine. Run gdb session Run gdb session without downloading debug symbols Update /var/crash/_usr_bin_caja.1000.crash with fully symbolic stack trace That is not ok. This might be good information for developers, but for normal users it is useless. There should be information when to use which one. For example: Which option takes most time (if there is a significant difference)? Is one option a superset of the other? Might one option contain private / secret information which I should not share? Lets try 'Run gdb session'. By the way, 'gdb' is the GNU project debugger. Error creating child process Hrmpf. Seems as if I found a bug while trying to report a bug... This happens for every option. Ok. Let's see if I can report the bug. As the automatic tools did not help, I check for a program version via Help > About : Caja About window Nice! It is obvious which version I use and how the program is called (Caja 1.8.2). There is even a link to a website where I could eventually report the bug. It links to www.mate-desktop.org . Report bug When I search for 'bug' on www.mate-desktop.org I get to Reporting Bugs . That seems to be a blog article which explains they are moving to GitHub with a link to github.com/mate-desktop . There are many repositories, so I have to search. Hrmpf. Then I get: Caja Repositories 5 repositories. Hrmpf. I guess it is simply 'caja'. When I click on this repository, I have to click on 'issues'. Now I am stuck. I don't know how to find a better description than \"it crashed\". There is certainly more information on my system, but I don't know how to get to it and I don't see any instructions how to do so. I also don't want to waste my time searching for information how to get information about the crash. Google Chrome example Just a few images... Step 1 Details 1 Details 2 Details 3 Details 4 What's wrong and how to fix it Did you notice how complicated this is for a user? This should be easier. In fact, I think if the bug reporting process is done right it could enhance the trust a user has in software, speed the fixing process up and help develpers to proritize what is important. Some basic steps could be: The automatic reporting tool should be created for non-developers. It should automatically store crash information in a place where the user can easily find it (e.g. /home/myaccount/.bugreports/caja/yyyy-mm-dd-hh-mm.xml) It should be stored in a format which the user can read (e.g. an xml file) The bug reporting website should be hosted by somebody else. Now the last one is important in my opinion. It makes sure that users know their bugs are not deleted / removed from the public just because it makes the software look bad. One could add metrics how confident users are, e.g. if you let users tell which software they use. In this case you can add graphs of how many users use the software and how many bugs / issues are reported. (The classification bugs and issues might also not be easy for users!) Existing Issue Trackers All of the following bug trackers seem to be developed for developers, not for users: Open Source Projects: Trac : Python Bugzilla : Perl Mantis Bug Tracker : PHP Redmine : Ruby on Rails Hosted Services: GitHub issues (e.g. for numpy ) Google Code (e.g. for chromium ) SourceForge (e.g. for dvdstyler ) Launchpad (e.g. for ubuntu ) GNU Savannah (e.g. for lordsawar ) See also: Comparison of source code software hosting facilities","tags":"Cyberculture","title":"Bug Reporting - A users perspective"},{"url":"https://martin-thoma.com/regular-expressions-with-python/","text":"Python supports regular expressions (RegEx) just as any other general purpose programming language. This mini article shows two examples how to use them. The package which gives RegEx support is called re . Replacing Spaces Replace multiple whitespace characters (spaces, tabs, newlines, ...) by a single space (by Nasir ): import re text = \"The fox jumped over the log.\" replaced = re . sub ( \"\\s\\s+\" , \" \" , text ) To speed things up you can also compile the pattern. This has also the advantage that you can specify that you want to match newline characters ( \\n and \\r ) with the dot by setting the re.DOTALL flag. import re pattern = re . compile ( \"\\s\\s+\" , re . DOTALL ) text = \"The fox jumped over the log.\" pattern . sub ( \" \" , text ) Unquoting import re def remove_quotes ( text ): \"\"\"Remove 'test'.\"\"\" def unquote ( m ): return u ' %s ' % str ( m . group ( 1 )) pattern = re . compile ( \" '([&#94; ]+?.*[&#94; ]+?)' \" ) return pattern . sub ( unquote , text ) text = \"The quoted 'text piece' will get unquoted.\" remove_quotes ( text ) All paragraphs If you want to get the content within all paragraph tags ( <p> ... </p> in arbitrary spacing) you can use: import re pattern = re . compile ( \"<p>(.*?)</p>\" , re . IGNORECASE | re . DOTALL ) text = \"\"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus placerat turpis vitae malesuada tempor. Fusce cursus condimentum leo, ut bibendum justo varius sit amet. In accumsan interdum nibh at fermentum. Nulla commodo, mi vel ultricies efficitur, nulla tortor sagittis tortor, quis laoreet augue orci vitae justo. sasdf <p>Suspendisse porttitor risus et est consequat condimentum. In in eleifend ipsum, eu pulvinar nunc. Nullam vel imperdiet eros. Phasellus vel arcu convallis, semper quam eu, convallis velit. </p> <P>Sed tempus magna quis neque varius aliquam. Quisque maximus et augue non dapibus. Nullam et ante imperdiet, fringilla diam nec, mattis quam.</p> <P>Ut fermentum lacus id semper imperdiet. Donec et purus consectetur, fermentum mi nec, viverra dolor. Quisque posuere ultricies leo et efficitur. Aliquam venenatis quis mi ac tempus.</p> Maecenas in nisl lacinia, finibus velit eu, aliquet elit. Morbi orci libero, interdum id vehicula vitae, <p>congue vel</p>p> lectus. Morbi lobortis eros mollis, cursus velit at, convallis dolor. Nullam volutpat neque at risus porttitor, faucibus tristique tellus suscipit. In sed purus quis sem tincidunt lobortis. Vivamus ut blandit erat, sed sollicitudin felis. Etiam placerat, sapien et vulputate placerat, mi lectus tristique nisi, vitae finibus tellus nisi a massa. Nullam sit amet scelerisque lectus. Fusce porta justo ac scelerisque auctor. Integer vestibulum tellus at quam molestie dapibus. Suspendisse quis quam tortor. Nullam consequat tempus orci eget scelerisque. Ut auctor lorem enim, id rutrum eros congue varius. In justo lacus, molestie vitae nibh eu, venenatis auctor ex. \"\"\" matches = pattern . findall ( text ) Matches is the following list (breaked at some points for easier reading): ['Suspendisse porttitor risus et est consequat condimentum.\\n In in eleifend ipsum, eu pulvinar nunc. Nullam vel imperdiet eros.\\n Phasellus vel arcu convallis, semper quam eu, convallis velit.\\n\\n', 'Sed tempus magna quis neque varius aliquam. Quisque maximus et augue non\\n dapibus. Nullam et ante imperdiet, fringilla diam nec, mattis quam.', 'Ut fermentum lacus id semper imperdiet. Donec et purus consectetur,\\n fermentum mi nec, viverra dolor. Quisque posuere ultricies leo et efficitur.\\n Aliquam venenatis quis mi ac tempus.', 'congue vel'] Common RegExes Numbers non-negative even numbers RegEx : &#94;\\d*[02468]$ Description : All even numbers end with either 0, 2, 4, 6 or 8. Matches : 12 | 2 | 012 | 4 | 44 Non-Matches : -12 | 3 | 13 Percentage RegEx : &#94;\\d{0,2}(\\.[0-9]{1,2})?$|&#94;(100)(\\.[0]{1,2})?$ Description : All percentages with 0, 1 or 2 decimal places without the percent sign. Matches : 0 | 0.0 | 0.00 | 12.42 | 100 | 100.0 | 100.00 Non-Matches : -12.42 | +12.42 | 112.42 Email RegEx : &#94;((?:(?:(?:\\w[\\.\\-\\+]?)*)\\w)+)\\@((?:(?:(?:\\w[\\.\\-\\+]?){0,62})\\w)+)\\.(\\w{2,6})$ Description: Not a 100% email validation. It doesn't work with IP-Adresses, but it's good for most common cases. At least I hope so. Matches : a-b-c@d-e-f.com | a@b.ce | Me@my.museum Non-Matches : abc@def.g | a--b@c--d.fe | -abc@-def-.def Source : Sebastian Hiller","tags":"Code","title":"Regular Expressions with Python"},{"url":"https://martin-thoma.com/analyzing-pypi-metadata/","text":"This is part one of a series. See Analyzing PyPI Data - 2 for part two. PyPI, the Python Package Index, gives a very crappy but simple interface to query metadata about its packages. I scrapped all of the packages metadata. 53,533 packages were scrapped (date: 2015-01-18), because I wanted to see if there is malware on PyPI (related to this question on security.SE ). The database looks like this: PyPI metadata Exploring the data When I scapped the data from PyPI, I made all database fields \"varchar 255\" as there seems to be no information about the possible values. Then I explored the data name : The longest package name is 80 characters long ( Aaaaaaaaaaa... ), the shortest packages have only one character. author : 911Ã— \"UNKOWN\", 741Ã— empty, 195Ã— \"None\", 151Ã— \"Zope Foundation and Contributors\". There are about 22,000 different authors. There are 595 authors who wrote more than 10 packages. author_email : 2059Ã— \"UNKOWN\", 932Ã— empty, 323Ã— \"zope-dev@zope.org\", 216Ã— \"None\" and 204Ã— \"TODO\". maintainer : 46879Ã— \"None\", 5507Ã— empty, 17Ã— Paul Boddie . requires_python : 53467Ã— \"None\", 3Ã— \"UNKNOWN\", 2Ã— \">=2.7,!=3.0,!=3.1\", 2Ã— \">=2.5\", 1Ã— \"2.6\", 1Ã— \">= 3.3\", 1Ã— \">=2.4\", 1Ã— \">= 2.7\" - that's it. No other values. Seems as if this is pretty much useless. docs_url : Either begins with http://pythonhosted.org or is empty. Most active authors SELECT ` author ` , COUNT ( ` id ` ) as ` created_packages ` FROM ` packages ` GROUP BY ` author ` ORDER BY COUNT ( ` id ` ) DESC , ` author ` ASC LIMIT 50 gives 1485 UNKNOWN 1150 None 196 OpenStack 188 Zope Foundation and Contributors 146 MicroPython Developers 139 OpenERP SA 137 Zope Corporation and Contributors 128 RedTurtle Technology 127 Praekelt Foundation 126 Fanstatic Developers 98 Tryton 98 Raptus AG 97 russianidiot 93 hfpython 92 LOGILAB S.A. (Paris, FRANCE) 88 BlueDynamics Alliance 87 Ralph Bean 83 JeanMichel FRANCOIS aka toutpt 69 Bart Thate 68 The total number of authors is 28 183 (06.12.2015): SELECT COUNT ( DISTINCT ` author ` ) AS ` total_authors ` FROM ` packages ` Maximum Length I guess many values are stored on PyPI as Varchar(255) . To check if I might have missed some values, I checked which entry was the longest one for all columns. I did this with SELECT ` name ` , LENGTH ( ` name ` ) FROM ` packages ` ORDER BY LENGTH ( ` name ` ) DESC Column Maximum Length Entry name 80 Aaaaaaaaaaaaaaaaaaa-aaaaaaaaa-aaaaaaasa-aaaaaaasa-aaaaasaa-aaaaaaasa-bbbbbbbbbbb author 248 Michael R. Crusoe, Greg Edvenson, Jordan Fish, Adina Howe, Luiz Irber, Eric McDonald, Joshua Nahum, Kaben Nanlohy, Humberto Ortiz-Zuazaga, Jason Pell, Jared Simpson, Camille Scott, Ramakrishnan Rajaram Srinivasan, Qingpeng Zhang, and C. Titus Brown author_email 215 ongsp@ucsd.edu, anubhavj@mit.edu, mpkocher@lbnl.gov, geoffroy.hautier@uclouvain.be, wrichard@mit.edu, sdacek@mit.edu, dkgunter@lbl.gov, scholia@lbl.gov, gmatteo@gmail.com, vincentchevrier@gmail.com, armiento@mit.edu maintainer 63 Panagiotis Liakos, Katia Papakonstantinopoulou, Michael Sioutis maintainer_email 67 maxistedeams@gmail.com, p_riendeau@live.ca, rheault.etccy@gmail.com requires_python 17 >=2.7,!=3.0,!=3.1 platform 231 Natural Language :: English License :: OSI Approved :: Apache Software License Environment :: Console Development Status :: 2 - Pre-Alpha Intended Audience :: Developers Programming Language :: Python :: 2.7 Topic :: Database version 73 [In Progress] Python middle layer for interacting with Redis data easily. license 466 Copyright Â© 2014 Ð—ÐÐž \"Ð‘ÐÐ Ð¡ Ð“Ñ€ÑƒÐ¿\" Ð”Ð°Ð½Ð½Ð°Ñ Ð»Ð¸Ñ†ÐµÐ½Ð·Ð¸Ñ Ñ€Ð°Ð·Ñ€ÐµÑˆÐ°ÐµÑ‚ Ð»Ð¸Ñ†Ð°Ð¼, Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð²ÑˆÐ¸Ð¼ ÐºÐ¾Ð¿Ð¸ÑŽ Ð´Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÐµÑÐ¿ÐµÑ‡ÐµÐ½Ð¸Ñ Ð¸ ÑÐ¾Ð¿ÑƒÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐ¹ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ (Ð² Ð´Ð°Ð»ÑŒÐ½ÐµÐ¹ÑˆÐµÐ¼ Ð¸Ð¼ÐµÐ½ÑƒÐµÐ¼Ñ‹Ð¼Ð¸ Â«ÐŸÑ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð½Ð¾Ðµ ÐžÐ±ÐµÑÐ¿ÐµÑ‡ÐµÐ½Ð¸ÐµÂ»), Ð±ÐµÐ·Ð²Ð¾Ð·Ð¼ÐµÐ·Ð´Ð½Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ ÐŸÑ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð½Ð¾Ðµ ÐžÐ±ÐµÑÐ¿ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð±ÐµÐ· Ð¾Ð³ keywords 655 ArcLink,array,array analysis,ASC,beachball,beamforming,cross correlation,database,dataless,Dataless SEED,datamark,earthquakes,Earthworm,EIDA,envelope,events,FDSN,features,filter,focal mechanism,GSE1,GSE2,hob,iapsei-tau,imaging,instrument correction,instrument simulation,IRIS,magnitude,MiniSEED,misfit,mopad,MSEED,NERA,NERIES,observatory,ORFEUS,picker,processing,PQLX,Q,real time,realtime,RESP,response file,RT,SAC,SEED,SeedLink,SEG-2,SEG Y,SEISAN,SeisHub,Seismic Handler,seismology,seismogram,seismograms,signal,slink,spectrogram,StationXML,taper,taup,travel time,trigger,VERCE,WAV,waveform,WaveServer,WaveServerV,WebDC,web service,Winston,XML-SEED,XSEED description 65535 [id don't want to put that here - there were 22 with this length] summary 278 Splits one vcard file (*.vcf) to many vcard files with one vcard per file. Useful for import contacts to phones, thats do not support multiple vcard in one file. Supprt unicode cyrillic characters. ÐšÐ¾Ð½ÑÐ¾Ð»ÑŒÐ½Ð°Ñ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð° Ð´Ð»Ñ Ñ€ stable_version 4 None home_page 134 http://127.0.0.1:8888/USK@9X7bw5HD2ufYvJuL3qAVsYZb3KbI9~FyRu68zsw5HVg,lhHkYYluqHi7BcW1UHoVAMcRX7E5FaZjWCOruTspwQQ,AQACAAE/pyfcp-api/0/ release_url 130 http://pypi.python.org/pypi/softwarefabrica.django.appserver/1.0dev-BZR-r10-panta-elasticworld.org-20091023132843-vitk6k7e5qlvhej5 bugtrack_url 104 https://bugzilla.redhat.com/buglist.cgi?submit&component=python-nss&product=Fedora&classification=Fedora download_url 183 http://pypi.python.org/packages/source/s/softwarefabrica.django.appserver/softwarefabrica.django.appserver-1.0dev-BZR-r10-panta-elasticworld.org-20091023132843-vitk6k7e5qlvhej5.tar.gz package_url 108 http://pypi.python.org/pypi/Aaaaaaaaaaaaaaaaaaa-aaaaaaaaa-aaaaaaasa-aaaaaaasa-aaaaasaa-aaaaaaasa-bbbbbbbbbbb _pypi_hidden - True or False _pypi_ordering - Integers from 0 to 464 cheesecake_code_kwalitee_id - Integers from 183 to 6513 and None values cheesecake_documentation_id - Integers from 182 to 6512 and None values cheesecake_installability_id - Integers from 181 to 6511 and None values We can see multiple problems here: URLs: localhost / 127.0.0.1 is almost certainly not desired cheesecake_installability_id , cheesecake_documentation_id , cheesecake_code_kwalitee_id should have NULL and None should be casted to NULL. The data type is likely to be numeric. _pypi_ordering should be numeric _pypi_hidden should be boolean So I changed the types in the database. Let's continue. What people don't use All metadata is provided by the authors of the packages. Some fields, like the package name or the description, are used very often, but some fields are only rarely used: Maintainer maintainer and maintainer_email is interesting for people who want to send bug reports. If this is empty, I would guess the package is dead. Platform SELECT ` platform ` , COUNT ( ` id ` ) FROM ` packages ` GROUP BY ` platform ` ORDER BY COUNT ( ` id ` ) DESC gives 759 different results. The TOP-10 were Platform Count UNKNOWN 43539 any 3515 1986 Any 635 OS Independent 542 None 265 Linux 225 linux 167 Posix; MacOS X; Windows 157 POSIX 156 You can see that there are alternative ways to express the same thing. Also, the \";\" should not be here as the manual states it should be a list. The manual is also too short for this entry. It only says \"a list of platforms\" which seems to be pretty much useless. docstore.mik.ua gives a little bit more information A list of platforms on which this distribution is known to work. You should provide this information if you have reasons to believe this distribution may not work everywhere. This information should be reasonably concise, so this field may refer for details to a file in the distribution or to a URL. Bugtracker This one is very important. Users should have an easy possibility to report bugs. So please help them by added your bug tracker URL wherever it makes sense. Here is how you add it on PyPI: Go to your packages PyPI page Add your bugtracker / issue tracker url Check if you really added it License Another important one. Add a license to your software! SELECT ` license ` , COUNT ( ` id ` ) FROM packages GROUP BY ` license ` ORDER BY COUNT ( ` id ` ) DESC gives License Count UNKNOWN 11444 MIT 8098 BSD 7224 GPL 4202 MIT License 1410 (empty) 1398 LICENSE.txt 1201 GPLv3 1083 LGPL 833 ZPL 2.1 829 BSD License 811 Apache License 2.0 482 Apache License, Version 2.0 443 Apache 2.0 437 GPLv2 370 None 363 ZPL 288 GPL-3 272 GPLv3+ 258 LICENSE 249 and about 6500 other licenses. Most might be variants in writing, e.g. Apache License 2.0 Apache License, Version 2.0 Apache 2.0 are all the same license. Some packages have no licence ( Unknown and empty). Many are invalid values, like LICENSE.txt None LICENSE Python These indicate that people have no idea what to input there. tldrlegal.com might help in that case. I think the Python community should try to eliminate variants in writing license names as it makes finding, filtering and analyzing packages more difficult. Classifiers Python makes use of so called trove classifiers. They are defined in PEP 301 and listed here . The following table gives the TOP-10 most commonly used classifiers: Classifier Percentage Programming Language :: Python 0.4615 Intended Audience :: Developers 0.4412 Operating System :: OS Independent 0.3229 Programming Language :: Python :: 2.7 0.2183 Topic :: Software Development :: Libraries :: Pyth... 0.2038 Development Status :: 4 - Beta 0.2038 License :: OSI Approved :: BSD License 0.1632 License :: OSI Approved :: MIT License 0.1529 Environment :: Web Environment 0.1487 Programming Language :: Python :: 2.6 0.1306 When you analyze the licenses with the trove classifiers you get a different image: SELECT ` classifier ` , COUNT ( ` id ` ) / 53533 FROM ` package_classifiers ` WHERE ` classifier ` LIKE \"License%\" GROUP BY ` classifier ` ORDER BY COUNT ( ` id ` ) DESC License Percentage License :: OSI Approved :: BSD License 0.1632 License :: OSI Approved :: MIT License 0.1529 License :: OSI Approved :: GNU General Public License (GPL) 0.0625 License :: OSI Approved :: Apache Software License 0.0460 License :: OSI Approved :: GNU Library or Lesser General Public License (LGPL) 0.0188 There are 94 trove classifiers with five or less packages which use this classifier. I guess many of them are not in the official list of classifiers. Package type SELECT ` packagetype ` , COUNT ( ` id ` ) FROM ` urls ` GROUP BY packagetype ORDER BY COUNT ( ` id ` ) DESC gives Package type Count sdist 47649 bdist_egg 4933 bdist_wheel 3098 bdist_wininst 1512 bdist_dumb 577 bdist_msi 45 bdist_rpm 35 bdist_dmg 4 Can anybody explain what this means? Downloads SELECT ` name ` , ` url ` , ` downloads ` FROM ` urls ` JOIN ` packages ` ON ` urls ` . ` package_id ` = ` packages ` . ` id ` ORDER BY ` urls ` . ` downloads ` DESC LIMIT 10 gives Package type Count wincertstore 10026403 ssl 8987455 pyasn1 8655361 Paste 8401111 PyYAML 7180547 distribute 6276421 MarkupSafe 6215382 ecdsa 6030395 meld3 5715687 pika 5567400 and SELECT ` name ` , SUM ( ` downloads ` ) FROM ` releases ` JOIN ` packages ` ON ` releases ` . ` package_id ` = ` packages ` . ` id ` GROUP BY ` name ` ORDER BY SUM ( ` downloads ` ) DESC LIMIT 10 Package type Count setuptools 45485205 requests 35446321 virtualenv 35039299 distribute 34779943 boto 29678066 six 28253705 certifi 27381407 pip 26266325 wincertstore 24831145 lxml 20901298 Size What is the biggest Python package? SELECT ` name ` , ` release_number ` , ` size ` FROM ` releases ` JOIN ` packages ` ON ` releases ` . ` package_id ` = ` packages ` . ` id ` ORDER BY ` releases ` . ` size ` DESC LIMIT 30 Package Version Size de422 2009.1 545298406 de406 1997.1 178260546 scipy 0.13.3 62517637 appdynamics-bindeps-linux-x86 5913-master 57861536 appdynamics-bindeps-linux-x64 5913-master 56366211 python-qt5 0.1.5 56259023 python-qt5 0.1.8 56237972 pycalculix 0.92 56039839 wltp 0.0.9-alpha.3 55414544 cefpython3 31.2 55163815 Code See github.com/MartinThoma/algorithms . Related Why are some packages on pypi.python.org/simple, but have no page? How can I find out when the last interaction on PyPI happened for a given package? What is cheesecake_code_kwalitee_id on PyPI good for? Further Ideas Build a dependency graph : Some of the code was already written. However, one has to download about 25 GB of data, extract it and run over those files. This is quite a bit of work. Analyze package quality Missing requirements Missing metadata / description Missing documentation PEP8 Code duplication Malicious package search: Check which package names are prefixes of other package names. Find packages which upload data (dropbox?) Find pacakges which remove data from your file system","tags":"Code","title":"Analyzing PyPI Metadata"},{"url":"https://martin-thoma.com/latex-tables/","text":"LaTeX is an awesome typesetting language: It is powerful enough to let you do anything you want, it has a great community and standard solutions for every common problem as it is quite old. But tables... well, let's say there is much room for improvement. How to make tables The simple way The most basic table I could think of is generated like this: \\documentclass [a4paper] { scrartcl } \\usepackage { amssymb, amsmath } % needed for math \\begin { document } Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis malesuada efficitur volutpat. Proin eget dui in lacus fermentum pharetra. Sed ut facilisis leo, sed consectetur urna. Phasellus eget tempus eros, vitae sagittis mi. Nullam pharetra, dolor a efficitur blandit, nisl velit interdum turpis, vel posuere lorem justo nec elit. Donec mattis massa auctor mattis varius. Nunc sed volutpat sapien, at finibus lectus. Phasellus auctor vehicula auctor. Nam vitae purus ut orci accumsan auctor. Fusce volutpat, tortor consectetur convallis aliquam, enim velit gravida sapien, id convallis nisi nunc ac leo. \\begin { table } [ht] \\centering \\begin { tabular }{ l|rrr } Country / Property & Population & Area & HDI \\\\\\hline France & $ 66 \\cdot 10 &#94; 6 $ & $ 668763 \\text {km}&#94; 2 $ & 0.89 \\\\ Germany & $ 81 \\cdot 10 &#94; 6 $ & $ 357167 \\text {km}&#94; 2 $ & 0.92 \\\\ United States & $ 317 \\cdot 10 &#94; 6 $ & $ 9629091 \\text {km}&#94; 2 $ & 0.94 \\\\ \\end { tabular } \\caption { Information about countries } \\label { table:countries } \\end { table } Aenean sit amet felis eu urna accumsan consectetur. Sed hendrerit ultrices turpis nec fringilla. Pellentesque sagittis neque placerat, pharetra ante quis, maximus eros. Nam ultrices lacinia magna, eget interdum tortor ornare ut. Praesent semper tristique consectetur. Sed auctor, orci accumsan imperdiet vestibulum, nunc augue sagittis purus, sed dapibus neque arcu sit amet enim. Aliquam fermentum dui eu efficitur condimentum. Maecenas viverra metus ut bibendum pellentesque. Integer non interdum massa. Vestibulum non enim vulputate, sodales nunc ac, ultricies tortor. Suspendisse non vehicula ipsum, quis consequat elit. Quisque rutrum tincidunt lorem id semper. Phasellus bibendum nulla sit amet purus tempus, vitae tincidunt ligula ornare. Nunc quis felis non ex consequat elementum nec sit amet magna. In lacinia nulla nec neque venenatis, vel tristique risus blandit. \\end { document } It will look like this: Standard LaTeX table You can see two environments: table and tabular . Let's focus on tabular first. It is always followed by a list of characters l , c , r which define if the column is left-aligned, centered or right-aligned. You can add | to tell LaTeX if there should be a line to distinguish columns. After that you get to the first cells. & starts a new cell and \\\\ starts a new line. If you want a drawn line / rule, you can use \\hline . Let's check out table : table has options after it which are commonly ht where h means \"here\" and t means \"top\". So LaTeX tries to place the table where it is in the text and if that doesn't work out it places the table on the top of the page. It can get a caption \\caption{Description of the contents of the table} and a \\label{table:your-label-for-internal-usage} . The standard way I always use \\usepackage{booktabs} to get \\toprule , \\midrule and \\bottomrule : \\documentclass [a4paper] { scrartcl } \\usepackage { amssymb, amsmath } % needed for math \\usepackage { booktabs } % for \\toprule, \\midrule and \\bottomrule \\begin { document } Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis malesuada efficitur volutpat. Proin eget dui in lacus fermentum pharetra. Sed ut facilisis leo, sed consectetur urna. Phasellus eget tempus eros, vitae sagittis mi. Nullam pharetra, dolor a efficitur blandit, nisl velit interdum turpis, vel posuere lorem justo nec elit. Donec mattis massa auctor mattis varius. Nunc sed volutpat sapien, at finibus lectus. Phasellus auctor vehicula auctor. Nam vitae purus ut orci accumsan auctor. Fusce volutpat, tortor consectetur convallis aliquam, enim velit gravida sapien, id convallis nisi nunc ac leo. \\begin { table } [ht] \\centering \\begin { tabular }{ l|rrr } \\toprule Country / Property & Population & Area & HDI \\\\\\midrule France & $ 66 \\cdot 10 &#94; 6 $ & $ 668763 \\text {km}&#94; 2 $ & 0.89 \\\\ Germany & $ 81 \\cdot 10 &#94; 6 $ & $ 357167 \\text {km}&#94; 2 $ & 0.92 \\\\ United States & $ 317 \\cdot 10 &#94; 6 $ & $ 9629091 \\text {km}&#94; 2 $ & 0.94 \\\\ \\bottomrule \\end { tabular } \\caption { Information about countries } \\label { table:countries } \\end { table } Aenean sit amet felis eu urna accumsan consectetur. Sed hendrerit ultrices turpis nec fringilla. Pellentesque sagittis neque placerat, pharetra ante quis, maximus eros. Nam ultrices lacinia magna, eget interdum tortor ornare ut. Praesent semper tristique consectetur. Sed auctor, orci accumsan imperdiet vestibulum, nunc augue sagittis purus, sed dapibus neque arcu sit amet enim. Aliquam fermentum dui eu efficitur condimentum. Maecenas viverra metus ut bibendum pellentesque. Integer non interdum massa. Vestibulum non enim vulputate, sodales nunc ac, ultricies tortor. Suspendisse non vehicula ipsum, quis consequat elit. Quisque rutrum tincidunt lorem id semper. Phasellus bibendum nulla sit amet purus tempus, vitae tincidunt ligula ornare. Nunc quis felis non ex consequat elementum nec sit amet magna. In lacinia nulla nec neque venenatis, vel tristique risus blandit. \\end { document } which looks like this: LaTeX table with booktabs Combining cells It is much nicer when you combine cells. To do so, you can use \\multicolumn : \\documentclass [a4paper] { scrartcl } \\usepackage { amssymb, amsmath } % needed for math \\usepackage { booktabs } % for \\toprule, \\midrule and \\bottomrule \\begin { document } Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis malesuada efficitur volutpat. Proin eget dui in lacus fermentum pharetra. Sed ut facilisis leo, sed consectetur urna. Phasellus eget tempus eros, vitae sagittis mi. Nullam pharetra, dolor a efficitur blandit, nisl velit interdum turpis, vel posuere lorem justo nec elit. Donec mattis massa auctor mattis varius. Nunc sed volutpat sapien, at finibus lectus. Phasellus auctor vehicula auctor. Nam vitae purus ut orci accumsan auctor. Fusce volutpat, tortor consectetur convallis aliquam, enim velit gravida sapien, id convallis nisi nunc ac leo. \\begin { table } [ht] \\centering \\begin { tabular }{ llll } \\toprule Country & \\multicolumn { 3 }{ c }{ Property } \\\\ \\cmidrule { 2-4 } & { Population } & { Area } & { HDI } \\\\ & { (mio.) } & { (km \\textsuperscript { 2 } ) } \\\\ \\midrule France & \\multirow { 2 }{ * }{ 66 } & 668763 & 0.89 \\\\ Germany & 81 & 357167 & 0.92 \\\\ United States & 317 & 9629091 & 0.94 \\\\ \\bottomrule \\end { tabular } \\caption { Information about countries } \\label { table:countries } \\end { table } Aenean sit amet felis eu urna accumsan consectetur. Sed hendrerit ultrices turpis nec fringilla. Pellentesque sagittis neque placerat, pharetra ante quis, maximus eros. Nam ultrices lacinia magna, eget interdum tortor ornare ut. Praesent semper tristique consectetur. Sed auctor, orci accumsan imperdiet vestibulum, nunc augue sagittis purus, sed dapibus neque arcu sit amet enim. Aliquam fermentum dui eu efficitur condimentum. Maecenas viverra metus ut bibendum pellentesque. Integer non interdum massa. Vestibulum non enim vulputate, sodales nunc ac, ultricies tortor. Suspendisse non vehicula ipsum, quis consequat elit. Quisque rutrum tincidunt lorem id semper. Phasellus bibendum nulla sit amet purus tempus, vitae tincidunt ligula ornare. Nunc quis felis non ex consequat elementum nec sit amet magna. In lacinia nulla nec neque venenatis, vel tristique risus blandit. \\end { document } which looks like this: LaTeX table with multicols Note the \\cmidrule{2-4} which draws a rule from cell 2 to 4 (LaTeX starts to count at 1). If you want to combine multiple rows you need to use \\usepackage{multirow} . Line Breaks in Cells \\parbox [t] { 1cm }{ This is the first \\\\ cell } See also: How to add a forced line break inside a table cell Page breaking tables If you want your tables to be able to break over pages, you have to use \\usepackage{longtable} which has an example . Another option is supertabular . When you use them, you should add \\endhead so that the head can get repeated. Tools truben.no/table is an awesome page to create tables for different formats. What could be better Page-breaking : I understand that you don't want to have page breaking of tables most of the time. But rather than never allowing page-breaking, I would expect an optimization with the following thoughts in mind: It is best to have the table where it was specified. The content should have at least 2 times as many rows as the header. So when there is only one header row, there should be at least 2 content rows. The farer a table is away from its \"original\" position, the worse it is. Headers : A semantic way to define the header and a tail would be very good. \\endhead is ok. Semantics, Styles and Classes : LaTeX hides some of the formatting for semantic codes. For example, you write \\section{MySection} instead of {\\fontsize{12}{15}\\textbf{MySection}} or something similar. That should be more often the case. In fact, I think it would be very nice if LaTeX had some built-in support for pure stylesheets (like CSS for HTML). It would be very nice if I only had to define that I want to make a standard table and it inserts \\toprule , \\midrule and \\bottomrule automatically. But to get an automatic \\midrule we need a command to tell LaTeX where the header ends. Everything of the above should be standard. There should not be the need to use new packages for that. Also, \\multirow , \\toprule , \\midrule , \\bottomrule should not be \"hidden\" in a package but be there by default. Table seperator : It is unfortunate that the table cell seperator(s) \\\\ and & have problems with matrices. I think one environment should get closed before the other one can continue parsing, so I don't quite understand where the problem is. But there certainly is a problem (see this question ). Tools : I don't know any tools that can export LaTeX tables and merge cells. Such tools should be able to import and export LaTeX tables See also Typesetting tables with LaTeX LaTeX/Tables","tags":"My bits and bytes","title":"LaTeX and tables"},{"url":"https://martin-thoma.com/horspiele/","text":"This is a quic article I had for quite a while as a draft. It might not be finished or have other problems, but I still want to share it. Ich habe frÃ¼her (damals, als ich noch keinen PC hatte â˜º ) sehr gerne HÃ¶rspiele gehÃ¶rt. Nun, mit meinem neuen Smartphone, dachte ich kÃ¶nnte ich das ja mal wieder machen. Auf der Suche nach (kostenlosen) HÃ¶rspielen habe ich folgendes gefunden: Neuvertonung.de : Eine kleine Gruppe hat â€žDie drei ???\" neu vertont. Eine Liste der Folgen gibts hier . YouTube Der Hexenmeister - AtmosphÃ¤risches HÃ¶rbuch / HÃ¶rspiel Die Barash-Tyr Chroniken Meuterei auf der Bounty","tags":"German posts","title":"HÃ¶rspiele"},{"url":"https://martin-thoma.com/trickreiche-matheaufgaben/","text":"This is a quick article I had for quite a while as a draft. It might not be finished or have other problems, but I still want to share it. Ich finde immer wieder ein paar einfache, aber irgendwie trickreiche Matheaufgaben. Was genau ich damit meine, seht ihr am besten am folgendem Beispiel. Wechselgeld Aufgabe Drei Kinder haben je 10 Euro und kaufen sich dafÃ¼r gemeinsam einen Ball fÃ¼r 30 Euro. Nach dem Verkauf stellt der Ladeninhaber fest, dass der Ball nur 25 Euro kostet und schickt seinen Lehrling mit den Ã¼berzÃ¤hligen 5 Euro den Kindern nach. Der Lehrling gibt jedem Kind 1 Euro und behÃ¤lt fÃ¼r seine BemÃ¼hungen die restlichen 2 Euro. Damit hat jedes Kind nur 9 Euro fÃ¼r den Ball bezahlt, insgesamt zahlten die Kinder 27 Euro. Mit den 2 Euro des Lehrlings ergibt das aber erst 29 Euro. Quelle: dsm-faq.wikidot.com/denksport AuflÃ¶sung Das Problem dieser Aufgabe ist, dass man sich nicht klar macht, wo man hin will. Man will scheinbar herausfinden, wo das Geld geblieben ist. Das vermischt man aber mit dem Geld, das man hatte: Situation vor dem Kauf: Kinder: je 10 Euro Lehrling: 0 Euro Ladeninhaber: 0 Euro Situation nach der Geschichte: 3 Kinder: je 1 Euro Lehrling: 2 Euro Ladeninhaber: 25 Euro Der Lehrling ist also derjenige, der das Problem trickreich macht, wenn man nicht aufpasst. Er bestiehlt die Kinder, deshalb zahlen sie praktisch 27 Euro anstelle der 25 Euro und von diesen 27 Euro hat der Ladeninhaber 25 Euro. MÃ¼cke und Elefant Aufgabenstellung Sei $x$ das Gewicht des Elefanten und $y$ das Gewicht der MÃ¼cke. Sei $d$ der Unterschied. \\begin{align} x &= y + d | \\cdot (x-y)\\\\ x&#94;2 - xy &= xy + xd - y&#94;2 - yd | -xd \\\\ x&#94;2 - xy - xd &= xy - y&#94;2 - yd\\\\ x(x-y-d) &= y \\cdot (x-y-d) |:(x-y-d)\\\\ x &=y \\end{align} Das Gewicht der MÃ¼cke ist also gleich dem Gewicht des Elefanten! Quelle: dsm-faq.wikidot.com/denksport AuflÃ¶sung Es empfiehlt sich, wie immer bei Umformungen, sich klar zu machen durch was man teilt. Es gilt: \\((x-y-d) = 0\\) , es wurde also durch 0 geteilt. Dabei passieren schlimme Dinge. Unter anderem kann man aus einer MÃ¼cke einen Elefanten machen ;-) Jeder Mensch hat sein Idealgewicht Aufgabenstellung Sei \\(x\\) das KÃ¶rpergewicht in kg eines Menschen, \\(y\\) sein Idealgewicht und \\(u\\) das Ãœbergewicht. Bei Untergewicht kann u also auch negativ sein! Dann gilt offensichtlich: \\(x = y + u\\) Nun kann man umformen: \\begin{align} x &= y + u | \\cdot (x - y)\\\\ \\Leftrightarrow x&#94;2 - xy &= xy + xu - y&#94;2 - uy | -xu\\\\ \\Leftrightarrow x&#94;2 - xy - xu &= xy - y&#94;2 - uy\\\\ \\Leftrightarrow x \\cdot (x - y - u) &= y \\cdot (x - y - u) | : (x-y-u)\\\\ \\Leftrightarrow x &= y \\end{align} Jeder Mensch hat also sein Idealgewicht! AuflÃ¶sung Das Problem der Umformung ist das Gleiche wie oben: \\((x-y-u) = 0\\) .","tags":"German posts","title":"Trickreiche Matheaufgaben"},{"url":"https://martin-thoma.com/vertex-coloring/","text":"This is a quick article I had for quite a while as a draft. It might not be finished or have other problems, but I still want to share it. The problem The Vertex Coloring problem can be described like this: Vertex Coloring Let \\(G = (V, E)\\) be an undirected graph. Find a function \\(f: V \\rightarrow \\{1, \\dots, n\\}, n \\in \\mathbb{N}\\) such that: \\(\\forall e=\\{v_1, v_2\\} \\in E: f(v_1) \\neq f(v_2)\\) . Minimize \\(n\\) . If \\(n\\) is minimal for \\(G\\) , it is called the chromatic number \\(\\chi(G)\\) . What does that mean? You have a graph. Then you take pencils and color the vertices such all vertices that are connected are not of the same color. Example All of the following graphs show valid thee colorings: [caption id=\"attachment_69831\" align=\"aligncenter\" width=\"500\"] Valid thee colorings of one graph Source: Wikipedia [/caption] Interesting facts $1 \\leq \\chi(G) \\leq |V|$: You need at least one color and you could color all vertices with a different color $\\chi(K_n) = n$: All complete graphs with $n$ vertices need exactly $n$ colors. One color for each vertex. Every planar graph can be colored with 4 colors (see four color theorem ). Determining if a graph can be colored with 2 colors is equivalent to determining whether or not the graph is bipartite. This can be checked in polynomial time. You simply start with one vertex, give it color 1 and all adjacent vertices color 2. Then all adjacent vertices of color 2 have to have color 1, ... Vertex Coloring is in $\\mathcal{NPC}$. All triangle-free planar graphs can be 3-colored. You can get this coloring in linear time ( source ). Algorithms I think learning from errors is important. This is the reason why I share the following algorithm that do not work. First WRONG try: Fix adjacent vertices [caption id=\"attachment_69891\" align=\"aligncenter\" width=\"512\"] A vertex coloring algorithm that does not work[/caption] The time complexity of this algorithm is in \\(\\mathcal{O}(|V|&#94;2)\\) . This should make you suspicious, as Vertex Coloring is in \\(\\mathcal{NPC}\\) . So if it was correct, it would solve the P vs. NP problem which is worth a million dollars. But an example why it doesn't work is better. Just try it for the following graph: [caption id=\"attachment_69921\" align=\"aligncenter\" width=\"512\"] Example that does not work with the provided algorithm[/caption] Second WRONG try: Fix current vertex [caption id=\"attachment_69971\" align=\"aligncenter\" width=\"512\"] Another vertex coloring algorithm[/caption] This algorithm gives a valid coloring, but the coloring is not minimal. Example: When you apply the algorithm the the graph below, you will get a coloring with four colors. But obviously, it is possible to color it with three colors. [caption id=\"attachment_69951\" align=\"aligncenter\" width=\"512\"] Graph that can be vertex-colored with 3 colors[/caption] Brute force It's always a good idea to think about brute force algorithms. On the one hand, they are simple. So you can intuitively understand why they are correct and see their time / space complexity. On the other hand, you can use them for sanity checks of better algorithms for small problem instances. Here is a brute force algorithm for the vertex coloring problem [caption id=\"attachment_70001\" align=\"aligncenter\" width=\"512\"] Brute force a minimal vertex coloring[/caption] You need \\(\\sum_{i=2}&#94;n i&#94;n\\) steps at maximum. Wow. This is MUCH. Even when you only want to check if \\(i\\) colors are enough, you need \\(i&#94;n\\) . You could use the second algorithm to get a better upper bound and try the next smaller ones. As soon as you don't get valid colorings, you know that the number of colors you've used in the last valid coloring was the minimum number. Zero-knowledge protocol Vertex coloring is relevant for so called \"zero-knowledge protocols\". This is a method by which one party (the prover) can prove to another party (the verifier) that a given statement is true, without conveying any additional information apart from the fact that the statement is indeed true. A zero-knowledge proof must satisfy three properties: Completeness : if the statement is true, the honest verifier (that is, one following the protocol properly) will be convinced of this fact by an honest prover. Soundness : if the statement is false, no cheating prover can convince the honest verifier that it is true, except with some small probability. Zero-knowledge : if the statement is true, no cheating verifier learns anything other than this fact. This is formalized by showing that every cheating verifier has some ''simulator'' that, given only the statement to be proven (and no access to the prover), can produce a transcript that \"looks like\" an interaction between the honest prover and the cheating verifier. Source: Wikipedia Another great example is the following: Imagine your friend is color-blind. You have two billiard balls; one is red, one is green, but they are otherwise identical. To your friend they seem completely identical, and he is skeptical that they are actually distinguishable. You want to prove to him (I say \"him\" as most color-blind people are male) that they are in fact differently-colored. On the other hand, you do not want him to learn which is red and which is green. Here is the proof system. You give the two balls to your friend so that he is holding one in each hand. You can see the balls at this point, but you don't tell him which is which. Your friend then puts both hands behind his back. Next, he either switches the balls between his hands, or leaves them be, with probability 1/2 each. Finally, he brings them out from behind his back. You now have to \"guess\" whether or not he switched the balls. By looking at their colors, you can of course say with certainty whether or not he switched them. On the other hand, if they were the same color and hence indistinguishable, there is no way you could guess correctly with probability higher than $\\frac{1}{2}$. If you and your friend repeat this \"proof\" $t$ times (for large $t$), your friend should become convinced that the balls are indeed differently colored; otherwise, the probability that you would have succeeded at identifying all the switch/non-switches is at most $2&#94;{-t}$. Furthermore, the proof is \"zero-knowledge\" because your friend never learns which ball is green and which is red; indeed, he gains no knowledge about how to distinguish the balls. Source: mathoverflow.net Lets make this more concrete. Say you want to authenticate somebody. This person is identified as the \"only\" person who knows a three-coloring of a big graph. This makes him/her special. If you simply asked him \"what's the three coloring for your graph?\" he would no longer be the only person who knows the three coloring. So you want to get sure that he knows a three coloring without getting it. See also Interactive zero knowledge 3-colorability demonstration","tags":"My bits and bytes","title":"Vertex coloring"},{"url":"https://martin-thoma.com/warum-ist-q-abzahlbar/","text":"This is a quick article I had for quite a while as a draft. It might not be finished or have other problems, but I still want to share it. Eine Menge B heiÃŸt abzÃ¤hlbar $: \\Leftrightarrow \\exists (a_n) \\in B: B = \\{a_1, a_2, a_3, ...\\}$ $\\Leftrightarrow \\exists f : \\mathbb{N} \\rightarrow B $ mit $f$ surjektiv. Die natÃ¼rlichen Zahlen sind abzÃ¤hlbar. Beh.: \\(\\mathbb{N}\\) ist abzÃ¤hlbar. Bew. : direkt Sei \\(f: \\mathbb{N} \\rightarrow \\mathbb{N}\\) definiert durch \\(f(n) := n\\) . \\(f\\) ist also die identitÃ¤t und damit bijektiv und insbesondere surjektiv \\(\\blacksquare\\) Die ganzen Zahlen sind abzÃ¤hlbar. Beh.: \\(\\mathbb{Z}\\) ist abzÃ¤hlbar. Bew. : direkt Sei \\(f: \\mathbb{N} \\rightarrow \\mathbb{Z}\\) definiert durch $$f(n) := \\begin{cases} \\frac{n-1}{2} & \\text{, falls n ungerade} \\\\ - \\frac{n}{2} & \\text{, falls n gerade} \\end{cases}$$ Also: \\(\\forall z \\in \\mathbb{Z}: \\exists x \\in \\mathbb{N} : f(x) = z\\) da: $$\\forall x \\in \\mathbb{Z}: n = \\begin{cases} - 2 \\cdot x & \\text{, falls x negativ} \\\\ 2 \\cdot x + 1 & \\text{, falls x positiv} \\end{cases}$$ Es gibt also fÃ¼r jede ganze Zahl z eine natÃ¼rliche Zahl n, die ich in \\(f\\) stecken kann um z zu erhalten \\(\\blacksquare\\) Beh.: \\(\\mathbb{N} \\times \\mathbb{N}\\) ist abzÃ¤hlbar. Bew. : direkt Sei \\(f: \\mathbb{N} \\times \\mathbb{N} \\rightarrow \\mathbb{N}\\) rekursiv definiert durch \\(f(1,1) := 1\\) und $$f (m, n) := \\begin{cases} f(m + 1, n - 1) + 1 & \\text{, falls } n \\neq 1 \\\\ f(1, m - 1) & \\text{sonst} \\end{cases}$$ Diese Abbildung sieht wie folgt aus: Abbildung, die N x N auf N abbildet Ich finde es ist intuitiv klar, dass diese Funktion bijektiv ist. Hat jemand dafÃ¼r einen sauberen Beweis? Also gibt es eine Umkehrfunktion (die auch bijektiv ist). Also ist \\(\\mathbb{N} \\times \\mathbb{N}\\) abzÃ¤hlbar \\(\\blacksquare\\) Beh.: \\(\\mathbb{Q}&#94;+\\) ist abzÃ¤hlbar. Bew. : Ã¼ber \\(N \\times N\\) Jede Zahl \\(x \\in \\mathbb{Q}&#94;+\\) kann mit zwei natÃ¼rlichen Zahlen dargestellt werden: \\(x = \\frac{p}{q}\\) . Also gibt es eine Funktion \\(f: \\mathbb{N} \\times \\mathbb{N} \\rightarrow \\mathbb{Q}\\) mit \\(f(m, n) := \\frac{m}{n}\\) . Diese Abbildung ist offensichtlich surjektiv. \\(\\blacksquare\\) Material Die LaTeX-Dateien fÃ¼r die Bilder sind in diesem Repository zu finden.","tags":"German posts","title":"Warum ist Q abzÃ¤hlbar?"},{"url":"https://martin-thoma.com/why-i-prefer-linux-over-windows/","text":"This is a quick article I had for quite a while as a draft.It might not be finished or have other problems, but I still want to share it. Some friends wondered why I prefer Linux over Windows. As I am currently using only Linux, I can make some examples. Here is an open list, why I prefer Linux over Windows: No marketing strategies Windows 7 comes in may flavours: Windows 7 Home, Windows 7 Home Premium, Windows 7 Ultimate, Windows 7 Enterprise, Windows 7 Professional, ... (see Microsoft product flavor hell ) I have to admit that the choice of Linux can be difficult, too. You can choose from different distributions like Ubuntu, Suse, Fedora, ... (see distrowatch.com ) and some distributions offer different desktop environments like GNOME and KDE. The important difference is that Linux flavors depend on your needs, but Windows flavors depend on your money. User-friendly system As a Ubuntu 10.04 LTS user, I think that Ubuntu is much more user friendly than Windows 7. You have much more control about your system than you have on Windows (see Why are Microsoft products so User unfriendly? ) Here are some everyday examples: Chaning the sound volume on a Notebook: You will see an indicator in Ubuntu like this . On Windows, you have to guess or wait until your movie starts Taking a screenshot: In Ubuntu, you only have to press \"Print Screen\". On Windows, you have to know Snipping tool or install some additional software. Additionally, it seems not to be possible to get a the key \"Print Screen\" as a shortcut for taking screenshots ( source ). Different workspaces, pinning a window to \"always in foreground\" is definitely missing in Windows. PDF-Printers : oh my god. This is really sad. Better community When I have questions for my system, I can ask them on askubuntu.com , unix.stackexchange.com or on ubuntuusers.de . I usually get friendly answers that help me to fix my problem within a few minutes. Where do I find answers to Windows questions? I have tried superuser.com , but is there anything else? Repositories When I want to install something on my Ubuntu machine, I simply type: sudo apt-get install something When I want to install something on Windows, I have to Google for it. When I find a tool which seems to fit, I have to find out if it is for free or if it's only a trial version. Then I need to find a way to download it and make sure that it's not malware. When I want to update all software I have on my linux machine, I type: sudo apt-get update sudo apt-get upgrade After this command, my system and every single piece of software I have installed is updated. The updates are automatically installed in the background. A restart might be necessary, but until the restart is done the old software is used. On Windows, I have to: Click on the start button Type \"update\" in the search bar Click on \"Search for updates\" Install all updates A restart might be required. But I can't simply make the restart when I want to. No, on Windows you will get reminded. You can choose the delay (max. 4 hours) of the reminder, but you can't disable it. And this is only an update for the operating system. You have to look for updates of your software by yourself. For every single piece of software! This is not so easy. How do you find a reliable source of Updates e.g. for Unreal Tournament 2004? Terminal You can do everything with terminal. When the system is slowing down, I press Ctrl + Alt + F4 , log into the shell, call top and kill the process which slows my system down. And I really like ZSH and Oh-My-ZSH . Linux is gratis You don't have to pay for it. In comparison, Windows 7 costs now (31.12.2014) about 50 Euro on Amazon. Although it is already outdated. Simple stuff There are some simple, little things which I like when I use Linux. I can't name them all, but some that come to my mind are: LiveCD Isn't it great to have the possibility to use the OS from a CD / DVD only? This gives you the possibility to check if your system runs (or to diagnose what's going wrong) without chaning anything. Installation setup The installation setup is great. It detects at the beginning if everything is ok (disk space, internet connection, battery) and tells you in simple words what is wrong. To chose your time zone you are shown a very simple graphic and by now the default was always correct for me. It continues with keyboard detection. Although the default was always wrong for me by now, it has an awesome auto-detection tool. You simply have to type some letters and it returns your layout. Great! Reasons to stay with Windows Although I don't like Windows 7 for many reasons, I can see some reasons to stay with Windows: Linux doesn't support your hardware (see Check Computer / Hardware for Linux-compatibility ) Linux doesn't support your software AND no free alternative exists (e.g. Photoshop for professionals) Pseudo reasons for Linux A pseudo-reason is an argument which might be true, but is not important at all for the person who wrote it. Security I often hear that people like Linux because of higher security. I don't think that this is a real reason, as I have never heared of any end user having switched because of security reasons. I also don't think that there is a significant difference of the bare systems in security. Freedom to change code Some people argue, that you can change the code of Linux / OpenSource programs according to your needs. This is only an argument, if you have done it at least once. Pseudo reasons against Linux Linux is only for geeks This is obviously not true. I know at least some non-geeks who are able to use it. Linux supports NO games! Not true either. Steam gives A LOT of high quality games to Linux and you also have the possibility to use wine. However, if you want a specific game that might be a different story.","tags":"The Web","title":"Why I prefer Linux over Windows"},{"url":"https://martin-thoma.com/dont-lose-your-stuff/","text":"This is a quick article I had for quite a while as a draft. It might not be finished or have other problems, but I still want to share it. It is very annoying when you buy something expensive and you lose it or it gets stolen. But there are some technical solutions to prevent that. Crowd GPS Tags Crowd GPS devices use Bluetooth and connect with Smartphones. Whenever another person has the App installed, he/she sends the location of all devices to a server. This means as long as anybody is near the GPS tag, you can hope to find your stuff again. Tile Tile is such a crowd GPS device. There is no android app yet. TinTag TinTag is a 28mm Ã— 39.2mm device. Its battery lasts for 4 months. It has an LED and a buzzer as well as bluetooth. The bluetooth connection lasts for 100m. It has a indigogo campagain . 10 Tintag devices and 1 base charger cost 105 US-Dollar. Tintag app works on Android phones (version 4.3 and 4.4) and iPhone. It doesn't work yet on Windows Phones or Blackberry. TrackR bravo TrackR bravo is just another tagging device. TrackR is compatible with Android 4.4 (see App ) and iPhone 4s & later, iPad 3rd Generation & later. It works with Bluetooth 4.0. It uses a CR1616 coin cell battery. It is 31mm in diameter and 3.5mm height. It can detect bluetooth devices up to 30m. One TrackR costs 29 US-Dollar, 10 cost 99 US-Dollar. StickNFind StickNFind is probably the smallest Crowd GPS tag. It was on indiegogo and raised 931.870 US-Dollar. It works with Android and iOS, as long as you have Bluetooth 4.0. Specs Technology : Bluetooth 4.0 (Bluetooth Low Energy) Range : Approximate 30m with line of sight. Battery : Lasts up-to 1 year based on 30 minutes per day average use. Battery Type : CR2016 watch battery. Battery is replaceable Cost : A 10 pack costs 200 US-Dollar. Dimensions Shape: Cylindric Diameter: 2.4cm diameter Thickness: 4mm Weight: 4.5g SelectaDNA SelectaDNA Bicycles Bicycles sometimes have a number on the frame. In German, it is called Fahrradrahmennummer . In Germany, you can sometimes go to the police and they will add such a number to your bike. In case it gets stolen and the police finds it, they can look at their records and give it back to you. Eventually. I'm not sure how good this works. But it doesn't cost anything, so why not? Another way is uglification. One way to do this is using these stickers . Another way is putting lots of reflecting stuff on it. That has the advantage of giving you extra security as drivers can see you more easily. USB-Sticks I always add a README.txt to the USB stick with the following content: ## German Dieser USB-Stick gehÃ¶rt Martin Thoma. Wenn er verloren wurde, wÃ¤re es toll, wenn Sie eine E-Mail an info@martin-thoma.de schreiben wÃ¼rden. -------------------------------------------------------------- ## English This USB stick belongs to Martin Thoma. If it was lost, please send an e-mail to info@martin-thoma.de. Luggage I always leave a note in my luggage with the following content: Martin Thoma Parkstr. 17 76131 Karlsruhe Tel.: XXXX E-Mail: info@martin-thoma.de House Locks and keys ... but you can lose your keys or forget them inside. When you lose your keys, you have to replace all locks. That's a problem with traditional keys. But I could imagine that a good keycard lock does not have this flaw. You \"simply\" tell the system that a card was lost and replace the cheap card - not the expensive lock. The card should only contain a long number. If the number is one of the allowed numbers, one can enter. If not, the system locks for 2 seconds. That should effectively prevent brute force. Smart Phones Android device manager","tags":"Cyberculture","title":"Don't lose your stuff"},{"url":"https://martin-thoma.com/chatbots/","text":"The Turing test is an experiment that was proposed by Alan Turing to test the ability of an artificial intelligence to emulate intelligent behaviour. It works like this: A human judge gets to talk over a chat client with either a human he doesn't know or a chat robot. If the judge can distinguish the human from the chat robot, the chat robot isn't intelligent. (There is a lot more to say about the Turing test. If you're really interested, you should read the wikipedia article.) Let's see how long it takes for me to say that I'm either talking to a very dumb person or to a computer for various chat robots A.L.I.C.E. See alice.pandorabots.com . judge: hi ALICE: Hi there! judge: How are you? ALICE: I am fine, thank you. judge: What are your hobbies? ALICE: I like robots, computers, and chatting online. judge: So we do â˜º ALICE: Really.. I'm glad you find this amusing. judge: What is 7+3? ALICE: Use a calculator! judge: What was my last question? ALICE: Is this a trick question? judge: No. ALICE: It seems like a trick to me. judge: Could you simply answer it? ALICE: Please rephrase your question, judge. judge: Bye ALICE: Bye bye. Check Difficulty How the Chatbot performed Stars Greetings Easy He greated just as I've expected it. 5 / 5 Smalltalk Average He did not keep the talk running and he always answer the same way to smilies. 3 / 5 Tasks Average He avoided the task. Which is ok. 4 / 5 Back reference Hard Asking for a trick question and for rephrasing might be a good way to get the human to give the context in one chat message. Very good! 3 / 5 Cleverbot See cleverbot.com . judge: hi. Cleverbot: How are you? judge: I'm fine. How are you? Cleverbot: Good. judge: What are your hobbies? Cleverbot: Talking to query bots, you? judge: Hehe, very good. I like reading and going to the cinema. Cleverbot: What books do you like? judge: The sword of truth, Lord of the rings, The Dresden files. Cleverbot: Ok... judge: What is 7+3? Cleverbot: What is what? judge: What is the capital of the U.S.? Cleverbot: I don't know. judge: Do you know any city? Cleverbot: No. judge: Where do you live? Cleverbot: Western Massachusetts. judge: That's the state. And in which city do you live? Cleverbot: I will not tell. judge: Ok. Can you tell me what my last question was? Cleverbot: How can I get you to trust me. judge: Bye. Cleverbot: Ok, bye. Check Difficulty How the Chatbot performed Stars Greetings Easy He didn't greet at the beginning. 2 / 5 Smalltalk Average Quite ok. 4 / 5 Tasks Average 2 / 5 Back reference Hard 1 / 5 This one tried to lead the conversation. I think that might be a good way to emulate a human. Either don't talk or keep talking all the time so that you (your chatbot) know the context.","tags":"Cyberculture","title":"Chatbots"},{"url":"https://martin-thoma.com/packaging-with-python/","text":"This is a quick article I had for quite a while as a draft. It might not be finished or have other problems, but I still want to share it. I wrote this when I did not know much about packaging. The following article is a wrap-up of the talk Python Packages from Daniel Hepper given at a German PyCon 2013 . distutils have very limited functionality. This is the reason why you should use setuptools. But 'distribute' is compatible to setuptools. PyPi is the Python Package Index. They distribute packages in form of \"eggs\". You can install them with easy_install or with pip. virtualenv / virtualenvwrapper Package Management Tools Distutils Distutils is part of the standard library. When you run python setup.py install then distutils is running. Major disadvantages of distutils are: No Meta-data: no deinstallation no dependencies No Package listing (so you can't automatically search pypi) Setuptools Setuptools are startet when you install a package with easy_install : easy_install package Setuptools are an extension for distutils. Setuptools offers dependency management. With setuptools, so called 'egg files' were introduced. Those files are comparable to jar files in Java. Distribute Distribute was a fork of setuptools that got merged back to setuptools. So don't use distribute, but use setuptools. Installer PIP PIP is short for 'PIP installs Python'. It can only install files from sources; so it does not support egg files. PIP commands are install uninstall freeze search bundle unzip zip wheel help Environments It might be the case that you have to have a Django 1.4 and a Django 1.5 project. In that case, you need different environments. Virtualenv $ pip freeze $ virtualenv my_env $ source my_env/bin/activate Virtualenvwrapper Creating packages A project could have this structure: $ tree . â”œâ”€â”€ LICENSE â”œâ”€â”€ MANIFEST â”œâ”€â”€ pyconde2013news â”‚ â””â”€â”€ __init__.py â”œâ”€â”€ README â””â”€â”€ setup.py With this setup.py: from distutils.core import setup setup ( name = \"pycon2013news\" , version = \"0.1\" , py_modules = [ \"pycon2013news\" ],) This can directly be registered on PyPi: python setup.py register But a problem of this code is that it does not show the dependencies. So you should rather use setuptools for your setup.py: from setuptools import setup setup ( name = \"pycon2013news\" , version = \"0.1\" , py_modules = [ \"pycon2013news\" ], description = \"Reads latest news headlines from the PyCon.DE 2013 website\" ) author = \"Daniel Hepper\" , author_email = \"daniel@butfriendly.com\" , url = \"https://github.com/dhepper/pyconde2013news\" , install_requires = [ \"beautifulsoup4==4.3.2\" , \"requests==2.0.0\" ] When you add scripts argument to setup, you can later execute those. Entry points are also interesting. Additional information http://guide.python-distribute.org/contributing.html","tags":"Code","title":"Packaging with Python"},{"url":"https://martin-thoma.com/cronjobs/","text":"Cron is a very usefull service in Linux systems that allows periodical execution of programs. Terms The program that runs other programs periodically is called \" cron \". The configuration file, that tells cron which programs should be run periodically is called \"crontab\" and located in /etc/crontab . One line in that file is called \"cronjob\". But \"crontab\" is also a command that lets you add cronjobs. Example The following entry in crontab means that uamt.py is executed every day at 3:30 am: 30 3 * * * /home/mthoma/uamt.py You can check if everything went fine with mthoma@i13srv30:~> crontab -l # DO NOT EDIT THIS FILE - edit the master and reinstall. # (/tmp/crontab.DEZBGc installed on Sat Jan 4 14:35:03 2014) # (Cronie version 4.2) 30 3 * * * /home/mthoma/uamt.py Resources HowTo: Add Jobs To cron Under Linux or UNIX?","tags":"Code","title":"Cronjobs"},{"url":"https://martin-thoma.com/subversion/","text":"This is a quick article I had for quite a while as a draft. It might not be finished or have other problems, but I still want to share it. Subversion or Apache Subversion or short svn is a is a software versioning and a revision control system. This allows you to step back to any point of the software and to develop simultaniously on the same project (but not on the same file). You have to make sure that no dependencies are broken, of course. Here is a little cheat sheet how to use SVN. I will demonstrate some on my Google Code OpenSource project Community Chess . All commands are executed while I'm in my local working copy of the repository. Get the repository svn checkout https://community-chess.googlecode.com/svn/trunk/ community-chess --username themoosemind@googlemail.com Update to the latest version svn update Check for changes If you only want to check which files were modified, added or deleted you can execute svn status This will show your local changes. File actions The actions are simmilar to the console commands, but you have to add svn: Copy svn cp myFile.php copiedFile.php Delete svn rm myFile.php Rename / Move svn mv myFile.php folder/myNewFile.php Add file If you created a file and want to submit it with the next commit, just do svn add myFile.php Commit the latest changes Check your changes First you should try svn status . What files did you change? Do you really want to upload those changes? If svn status gives you an exclamation mark (!), you might have deleted a file which you wanted to add before. No problem. Just make svn rever /path/to/your/file.php I'm fine: Upload it! This is the command you use, if you want to send the changes you made on your working copy to the repository: svn commit -m \"Moved some functions to additional.inc.php to keep the project more flexible; Much work for tournament implementation done; Some Warnings fixed\" --username themoosemind@gmail.com Watch changes General See the last three changes: svn log -v --limit = 3 ------------------------------------------------------------------------ r118 | themoosemind@gmail.com | 2011-09-26 23:18:42 +0200 (Mo, 26. Sep 2011) | 1 Zeile GeÃ¤nderte Pfade: M /trunk/clients/Java/ChessClient.class M /trunk/clients/Java/ChessClient.java small changes on the Java Client ------------------------------------------------------------------------ r116 | themoosemind@gmail.com | 2011-09-26 22:53:01 +0200 (Mo, 26. Sep 2011) | 1 Zeile GeÃ¤nderte Pfade: A /trunk/clients/Java A /trunk/clients/Java/ChessClient.class A /trunk/clients/Java/ChessClient.java A /trunk/install/phpBB3 A /trunk/install/phpBB3/login.wrapper.php (von /trunk/install/phpbb3.login.php:100) A /trunk/install/phpBB3/phpbb3.integration.txt (von /trunk/install/phpbb3.integration.txt:113) A /trunk/install/phpBB3/phpbb3.php (von /trunk/install/phpbb3.php:100) A /trunk/install/phpBB3/phpbb3.sql (von /trunk/install/phpbb3.sql:103) A /trunk/install/phpBB3/wrapper.inc.php (von /trunk/install/phpbb3.wrapper.inc.php:113) D /trunk/install/phpbb3.integration.txt D /trunk/install/phpbb3.login.php D /trunk/install/phpbb3.php D /trunk/install/phpbb3.sql D /trunk/install/phpbb3.wrapper.inc.php Made integration instructions for phpBB easier; added Java-Client ------------------------------------------------------------------------ r113 | themoosemind@gmail.com | 2011-09-26 08:29:15 +0200 (Mo, 26. Sep 2011) | 1 Zeile GeÃ¤nderte Pfade: M /trunk/index.php M /trunk/install/chess.sql M /trunk/install/phpbb3.integration.txt M /trunk/install/phpbb3.wrapper.inc.php M /trunk/my_software.php M /trunk/wrapper.inc.php Fixed issue 3 and some more phpBB-Bugs; more detailed integration instructions;Renamed GAMES_THREEFOLD_REPETITION_TABLE ------------------------------------------------------------------------ One specific file I don't want to get that much output, so I don't apply -v this time: svn log index.php --limit = 3 ------------------------------------------------------------------------ r127 | themoosemind@gmail.com | 2011-10-04 00:09:59 +0200 (Di, 04. Okt 2011) | 1 Zeile Moved some functions to additional.inc.php to keep the project more flexible; Much work for tournament implementation done; Some Warnings fixed ------------------------------------------------------------------------ r113 | themoosemind@gmail.com | 2011-09-26 08:29:15 +0200 (Mo, 26. Sep 2011) | 1 Zeile Fixed issue 3 and some more phpBB-Bugs; more detailed integration instructions;Renamed GAMES_THREEFOLD_REPETITION_TABLE ------------------------------------------------------------------------ r71 | themoosemind@gmail.com | 2011-08-26 23:13:37 +0200 (Fr, 26. Aug 2011) | 1 Zeile completed MVC with Vemplator; controlled every php file with phpcs ------------------------------------------------------------------------","tags":"Code","title":"Subversion"},{"url":"https://martin-thoma.com/svn-am-kit/","text":"This is a quick article I had for quite a while as a draft. It might not be finished or have other problems, but I still want to share it. Jeder Student mit einem ATIS-Account kann hier einen SVN-Zugang beantragen. Ich werde nun kurz erklÃ¤ren, wie man ihn mit der Konsole benutzt. Import Syntax ( Hilfe ): svn import [ PATH ] URL Beispiel: svn import -m \"Initial import of the BankAccountReader project.\" /home/swt-user/BankAccountReader https://svnserver.informatik.kit.edu/stud/svn/s_thoma/trunk/BankAccountReader Checkout Syntax ( Hilfe ): svn checkout URL [ @REV ] ... [ PATH ] Beispiel: svn co https://svnserver.informatik.kit.edu/stud/svn/s_thoma/trunk --username s_thoma Copy, Move, Delete Copy ( Hilfe ): svn copy SRC [ @REV ] ... DST Beispiel: svn copy mySoureFile.java folder/myDestFile.java Move ( Hilfe ): svn move SRC... DST Delete ( Help ): svn delete PATH... FÃ¼r delete gibt es einige synonyme Befehle: svn rm myFile.java Anders als der standard Linux rm-Befehl ist der von SVN rekursiv! status Syntax ( Hilfe ): svn status [ PATH... ] Beispiel: svn status D src D src/Tests.in D src/Tests.out D src/banking D src/banking/Status.java D src/banking/AccountNumber.java D src/banking/Shell.java D src/banking/Terminal.java D src/svn-commit.tmp A + BankAccountReader D BankAccountReader/svn-commit.tmp commit Syntax ( Hilfe ): svn commit [ PATH... ] Beispiel: svn commit -m \"restructuring directory structure\" Adding BankAccountReader Deleting BankAccountReader/svn-commit.tmp Deleting src Committed revision 3 . Siehe auch Subversion complete reference","tags":"Cyberculture","title":"SVN am KIT"},{"url":"https://martin-thoma.com/scherzfragen/","text":"This is a quick article I had for quite a while as a draft. It might not be finished or have other problems, but I still want to share it. Um die Antworten der folgenden Scherzfrangen zu erhalten mÃ¼sst ihr einfach den schwarzen Text markieren. Tierkonferenz Wie bekommt man den Elefanten in den KÃ¼hlschrank? KÃ¼hlschranktÃ¼r auf, Elefant rein, KÃ¼hlschranktÃ¼r zu. Wie bekommt man die Giraffe in den KÃ¼hlschrank? KÃ¼hlschranktÃ¼r auf, Elefant raus, Giraffe rein, KÃ¼hlschranktÃ¼r zu. Wichtige Tierkonferenz: Welches Tier fehlt? Die Giraffe, die ist noch im KÃ¼hlschrank. Du kommst im Urwald zu einem Fluss mit gefÃ¤hrlichen Krokodilen. Keine BrÃ¼cke, kein Boot...nichts. Wie kommst du hinÃ¼ber? Schwimmen - Die Krokodile sind auf der Konferenz. Wie merkt man, dass ein Elefant im KÃ¼hlschrank war? An den FuÃŸstapfen in der Butter. Warum darf man nach 24 Uhr nicht mehr in den Urwald? Weil dann die elefanten Fallschirm springen. Warum haben Krokodile so platte Nasen? Weil sie nach 24 Uhr im Urwald waren. Autokollision Was sagt ein Hund kurz bevor er von einem Auto angefahren wird? hilf... Und ein Pferd? hilf... Und ein Elefant? Komm nur. Busfahrer Du bist der Busfahrer. Der Bus startet den Motor und fÃ¤hrt los. Es steigen fÃ¼nf Leute ein. Er fÃ¤hrt weiter und drei steigen aus. Weiter geht es, und sieben steigen ein, und fÃ¼nf aus. Der Bus hÃ¤lt und alle mÃ¼ssen aussteigen weil jetzt Endhaltestation ist. Frage: Wie alt ist der Busfahrer? DU bist der Busfahrer! Schnell antworten Was ist schwerer, ein Kilo Federn, oder ein Kilo Blei? Es ist beides gleichschwer, ein kg ist ein kg. Auf einer Stange sitzen 10 Tauben. Ein JÃ¤ger schieÃŸt eine Taube ab. Wie viele sitzen noch da? Es sitzt keine Taube mehr auf der Stange. Wenn eine erschossen wird fliegen die anderen weg. Du hast ein Streichholz und kommst in einen leeren kalten Raum, in dem du nichts weiter als eine Petroliumlampe, einen Kamin und einen Ã–lofen vorfindest. Was zÃ¼ndest du zuerst an? Bevor du irgendetwas anzÃ¼nden kannst musst du zuerst das Streichholz anzÃ¼nden. Welche Farbe hat Papier? WeiÃŸ. Welche Farbe hat die Heizung? WeiÃŸ. Welche Farbe hat die Wand? WeiÃŸ. Was trinken KÃ¼he? Wasser. Ein Flugzeug stÃ¼rzt auf der Grenze von Frankreich zu Deutschland ab. Wo werden die Ãœberlebenden begraben? Ãœberlebende werden nicht begraben. Scherzfragen Wie kann man Postbote ohne O schreiben? BrieftrÃ¤ger. Was macht 999 mal \"Tick\" und einmal \"Tack\"? Ein TausendfÃ¼ÃŸler mit einem HolzfuÃŸ. Was schwimmt und fÃ¤ngt mit B an? Brett. Was schwimmt und fÃ¤ngt mit N an? Noch ein Brett. Was schwimmt und fÃ¤ngt mit S an? Schon wieder ein Brett. Was ist braun, groÃŸ, lebt 10 Meter unter der Erde und frisst Steine? Der groÃŸe, braune, unterirdische Steinfresser. Was ist braun, lebt 10 Meter unter der Erde und Frisst Sand? Die Oma vom groÃŸen, braunen, unterirdischen Steinfresser. Was sagt Tarzan wenn er ne Herde Elefanten durch den Wald laufen sieht? Guck mal, eine Herde Elefanten! Was sagt Tarzan wenn er eine Herde Elefanten mit Sonnenbrille durch den Wald laufen sieht? Nichts, denn er erkennt sie nicht. Was sagt Tarzan wenn er ne Herde Giraffen durch den Wald laufen sieht? Nochmal fall ich auf euer Verkleidungsspiel nicht rein! Wenn man ein Loch von Berlin aus quer durch die Erde bohren und einen Stein reinwerfen wÃ¼rde, wie weit wÃ¼rde er fallen? 10 Meter, dann wird er vom groÃŸen, braunen unterirdischen Steinfresser aufgefressen. Weitere Wer reist stÃ¤ndig kostenlos um die Welt??? Der Mond.","tags":"German posts","title":"Scherzfragen"},{"url":"https://martin-thoma.com/java-exceptions/","text":"This is a quick article I had for quite a while as a draft. It might not be finished or have other problems, but I still want to share it. When to use Errors and Exceptions An Error is a subclass of Throwable that indicates serious problems that a reasonable application should not try to catch. Most such errors are abnormal conditions. (Source: Javadoc ) How to throw an exception public void myMethod ( String s ) { if (! isStringValid ( s )) { throw new IllegalArgumentException ( \"This string is not valid!\" ); } } Common Exceptions IllegalArgumentException: One argument of the current method hasn't the form it should have. IllegalStateException: The current object is in the wrong state. NullPointerException: A Null-Pointer was given, but it should have been an object. A long list of Exceptions is on Hai's Blog . See also http://docs.oracle.com/: Class Exception","tags":"Code","title":"Java Exceptions"},{"url":"https://martin-thoma.com/famous-software-bugs/","text":"This is a quick article I had for quite a while as a draft. It might not be finished or have other problems, but I still want to share it. Mars Climate Oribiter Mars Climate Oribiter Type of Bug : Bad specification Description : The flight system software on the Mars Climate Orbiter was written to calculate thruster performance using the metric unit Newtons (N), while the ground crew was entering course correction and thruster data using the Imperial measure Pound-force (lbf). Outcome : The cost of the mission was $327.6 million total for both orbiter and lander, $193.1 million for spacecraft development, $91.7 million for launching it, and $42.8 million for mission operations. Source : Wikipedia Ariane V88 The Ariane V88 exploded 40 seconds after its start. Type of Bug : The software was written for another type of hardware. Description : A 64 Bit floating point number was converted into a 16 bit integer in the \"inertial reference system\" â†’ Overflow â†’ the rocket got into a tilted position and destroyed itself for security reasons. The interesting part is, that this program wasn't even needed for the flight! It had been developed for the Ariane 4. Outcome : 290 Million Euro destroyed Other Whitespace: The Silent Killer History's Most (In)Famous Software Failures Mariner 1 Roundoff Error and the Patriot Missile Do you know more?","tags":"Cyberculture","title":"Famous Software Bugs"},{"url":"https://martin-thoma.com/replicators/","text":"This is a quick article I had for quite a while as a draft. It might not be finished or have other problems, but I still want to share it. What would you need to explore space? There are some ideas in science fiction like interstellar arks and near lightspeed travel. But one concept might be easier to realize: Self-replicating, autonomous machines. The Problem of Interstellar Arks Interstellar arks are space ships that are of enourmous size. They are big enough to have enough humans on it so that those humans can have childens over an limitles time without getting into trouble because of incest. Traill et al. [2007] suggests that you need about 4000 individuals for a minimal viable population. Those 4000 people would need food, air, personal space. You would need resources to repair the ship and explore planets. Medicine. You would need fuel. That would be a lot of stuff. Bringing stuff from earth to space is expensive. And those people would eventually be trapped on that ship for many, many generations before they might find another habitable planet. You might eventually need to do terraforming . I can't even imagine the number of resources that would be needed for that. The next problem is that you would want the explorers to keep contact with earth. Those signals would either have to be highligh redundant (see error correcting codes ) or they might get received only partially. So eventually you would like to get relay stations that catch up the signal, correct errors (or request a new send of the broken part) and send it again. An ark would have to carry everything for that. That's a problem because sending so much stuff from earth to space is expensive. The alternative: Replicating Machines An alternative might be replicating machines. Machines don't need personal space. They don't need air. They don't need food or medicine. They don't run into psychical problems. But they do need energy. They need resources. And they either need to be really intelligent or they need to have clear instructions. I a working minimal space exploring construction kit (let's call it MISECK, because that's much shorter than 'minimal space exploring construction set') should be able to do the following: Construct other MISECKs from resources that can be found in space (e.g. on asteroids, moons or planets). The plural was intended. Every MISECK would have to be able to produce at least two other MISECKs. Build communication satelites : That communication satelite would act as a relay station. It talks with other satelites, receives messages and sends messages. It is able to check if the received message has errors and request a new message in case of errors. They should also store as much information as possible. This way, one could eventually contact them and get information that might otherwise get lost. Build exploration satelites which can gather information about a planet. This information should be send to the communication satelites and finally back to earth. Build mining and construction robots that are able to mine all resources needed to construct MISECKS. That will include melting ore and constructing fabrics which are able to produce computer chips. Build power plants . Those might be solar cells, fusion/fission reactors or something completely different. But something has to provide the energy to make it possible to run all those machines and to travel enormous distances in space. Explore and coordinate : This is a collaborative planning task. MISECKs have to know where other MISECKs are. If one MISECK gets destroyed by anything, there might still be something that is worth exploring. See also Wikipedia Interstellar travel Intergalactic travel StackExchange Smallest viable reproducing population","tags":"Cyberculture","title":"Replicators"},{"url":"https://martin-thoma.com/how-to-draw-speech-bubbles/","text":"This is a quick article I had for quite a while as a draft. It might not be finished or have other problems, but I still want to share it. The nice icon is from Wikipedia Commons and part of the Crystal Clear project by Everaldo Coelho. Preparation Install inkscape . Get an image where you want to put the speech bubble. Add text with F2 Now it should looke like this: Preparation Rectangle Now you have to put a rectangle ( F2 ) or an ellipses ( F5 ) around your text. The rectangle should be placed below the text ( Page down ). To make positioning easier, group the text and the surrounding box: Mark box by clicking on it Shift + Click on the text Group with Ctrl + G Now it should looke like this: Preparation Indicator To add the \"indicator\" that shows who spoke, press Shift + F6 and add a triangle that overlaps with the box: Preparation Then press F2 to modify the path by nodes. Add some controll nodes in between by double-clicking on the path in between: Preparation Then delete them. Now you have those round curves that can be manipulated with the little circles: Preparation","tags":"Cyberculture","title":"How to draw speech bubbles"},{"url":"https://martin-thoma.com/logo-design-tournament/","text":"The website logotournament.com offers a service for designers and owners of companies. You can define how much money you would like to spend for a new logo-set and how this logo should look like. Logo Tournament Website Just take a look at the contest brief of Move Ahead. I've made a screenshot of their Website. They use the typical Joomla-Icon. Their Logo isn't very good. Proposed Logos on Logo Tournament Now take a look at the best submitted logos. Great, aren't they? At the moment, 105 logos have been submitted for $375. The company can decide which ones they like and rank them. They pay only for one logo set, but they can choose from 105 logos. Move Ahead Website Note : This is a quick post from one of my old blogs.","tags":"Cyberculture","title":"Logo Design Tournament"},{"url":"https://martin-thoma.com/how-mathematics-could-change-our-future/","text":"Can you think of a solution for a problem that concerns the whole or most of humanity and could be solved for the next ten years or even forever with less than 1 million dollars? This was the title of a question I've recently found on Quora. I think this question is very interesting and I would like to share my thoughts about it. I think the answer is mathematics and computer science. Or lets rather say algorithms. There are multiple problems in mathematics and computer science which could have a severe impact on some areas which are important for the worlds economy. As we live in a globalized world, this will affect most of humanity. As algorithms don't cost anything except for developing cost, it is certainly below 1 million dollars. In principle, everybody could come up with such algorithms. P vs NP The P versus NP problem is one of the Millennium Prize Problems . Stated extremely simple, it asks whether every problem whose solution can be quickly verified by a computer can also be quickly solved by a computer. If somebody found an algorithm which solves one problem in the class NPC in fast, it will eventually boost many problems or allow us to solve problems which were not solvable before. Especially optimization problems. Optimization problems There could be other algorithms which boost optimization problems, but do not help for the P vs. NP problem. Optimization is about allocating just the right amount of resources for a couple of goals to get the highest outcome. Fully homomorphic encryption Finding efficient solutions for the problem that we don't want cloud computing providers to know our data, but we want them to use their efficient data centers to run calculations on them. This would boost cloud computing and lead to a more efficient use of computational resources. A.I. The development of a strong A.I. could lead to a technological singularity. This would be a boost for technology incomparable to anything before. However, even advancements in A.I. which are not strong A.I.s will help. They can lead to many new products where humans cannot cope with the data volume. One example would be medicine. IBM's Watson is one first step to help doctors skip through the possible thousands of diagnoses and finding the most relevant and recent papers which could fit the problems of a patient. New diagnoses could be developed, the computer could help to create better (more accurate) tests for diseases. It could help to track the spread of diseases, predict it and thus help to contain it. Parallelization and Compilers Developing a tool which automatically parallelizes sequential code could make all applications go faster. The same is true for advances in compiler technology. This could lead to less energy consumption and faster devices. As most people have contact to computers nowadays, this would affect everybody. Can you think of other areas where algorithms have a strong impact?","tags":"Cyberculture","title":"How mathematics could change our future"},{"url":"https://martin-thoma.com/shortfilms-part-iii/","text":"Here is the second part \" Shortfilms, Part II \". I've collected quite a few YouTube videos in my \"watch later\" list. Most of them were short movies which I wanted to share. Here you are! Azarkant The Raven The Archiver Hybrids SEED REWIND Not a short movie ... but interesting nevertheless â˜º A Darwinian Future OMEGA Paradox One Rat Short The Chase Devils, Angels & Dating True Skin The Silent City The Escape Sam Giant Robot vs Monster WITCH ATTENTION: Very loud at the beginning! Rosa Natalis Teaser ABE Freaky ... and scary (Psycho Horror) SpyFox When you KILL Little Creatures on the road, there are consequences! Devil Claim BEAR 'N' WASTELAND BLIK LEGACY TOLERANTIA ARK Copia Meet Buck Egghunt","tags":"The Web","title":"Shortfilms, Part III"},{"url":"https://martin-thoma.com/play-audio/","text":"Our senses have a limited capability to distinguish signals. This might not be surpristing. However, we also have a limited capability to tell in which order signals arrived at our sensory organs. As I learned this, I wanted to check it. I wrote a little JavaScript / HTML5 page where you can check it. You can adjust the time in which two sounds are played. The clicking noise is played on the left and the right speaker in random order. A textfield below shows which speaker played the sound first. You should use headphones for this demo. According to the KIT lecture \"Mensch-Maschine-Wechselwirkung in der Anthropomatik (Vorlesung UniversitÃ¤t Karlsruhe im KIT, WS 2013/14, J. Geisler)\", the time resolution of the human ear is between 2 and 5 ms. This means you will not be able to distinguish the two signlas for less than 2ms. But you will need the signals to be 30-40ms apart to tell which one played first. I rather need 10ms, but this might also be caused by hardware problems. I doubt that JavaScripts timeout is accurate enough. Audio Test Play sound ms Which was first","tags":"Cyberculture","title":"Play Audio"},{"url":"https://martin-thoma.com/the-impact-of-strong-ais/","text":"An artificial intelligence (AI) is a computer program which acts - according to its developers - intelligent. That could be anything. Typical examples are route finding algorithms, chess programs, ego shooter computer opponents and classifiers. The last category of AIs (classifiers) is huge and includes programs which try to find out what you were writing (see my bachelor's thesis ), try to figure out who is on an image (face recognition) or what was spoken (automatic speech recognition). Strong and Weak AIs Science fiction literature distinguishes two kinds of AIs: Weak AIs and strong AIs. Currently, we only know weak AIs. They can do incredible things (see A.I. in Computer Games and Awesome Robots ), but that is nothing compared to a stong AI. Strong AIs are capable of adapting to completely new tasks. They can do creative work. In other words, they can do any task any human could do. They can do research and compose the most beautiful art. As they are machines which will be build by somebody (hence the term 'artificial'), they are better understood than our biological brains. Strong AIs will be able to understand how they work themselfes and very likely be able to improve themselfes. This is the point where a technological singularity happens. The machines start developing faster than any human can comprehend how they improve. At some point they will even develop faster than humankind together can understand. Now that you know the context, I would like to share an answer to the following question I've recently seen: What would change with strong AIs? What happens when machines take all of our jobs including creative/research/artistic ones? Something like that would not happen instantly. It is a gradual process. Many answers say something like nothing would be scarce. Well, I think that is wrong for two reasons: Scarcity of resources : Oil, gold and diamonds are expensive. But they are not (only) expensive because it takes a high amount of work to get them, but also because the number of diamonds on earth is limited. More or cheaper \"work hours\" like much better AIs combined with much better robots would not solve that problem. Oh, and please don't forget energy! Distribution : I think we produce enough food so that nobody on earth would have to starve. We certainly have enough clean water for everybody. Why do so many people still starve and don't have access to clean water? Because the distribution is not equal. Europe and the US make use of much more resources per person than Africa does. The richest 1% of the US make use of MUCH more resources than the bottom 30% (I guess the numbers are more extreme). Who do you think would own the robots that take the jobs? Who would profit from this much cheaper work hours? I think AIs that would in principle be able to solve any problem a human could solve (e.g. creating art and conducting research) would cause serious social problems if we don't adapt to the new situation. Such AIs would have the potential for a much worse world than we currently live in. However, with the right politics, it could vastly improve our world. Having the insight how such AIs work, we could make them decide ultimatively unbiased for a greater good. They could be used to arbitrate a dispute as a neutral, intelligent instance. They could accelerate research. They could help us to understand ourselves. Job market What is the effect of technological singularity in job market? In a ideal world, everybody would only do the job he or she wants to do. We would eventually work less, but I think we would still work. Humans are resources and as such they will always be valuable in any economy. Another, darker, scenario is that AIs would gradually remove whole industries, starting with simple ones. Taxi and truck drivers are not necessary. They could step-by-step be replaced by AIs. However, no new jobs would be created for those people. They would have to get aid by the government. But as they would get less money, the economy would focus on the people who have money. That would be the people who own the AIs. At some point people would realize that they will never be able to get a new job. Even worse, their children will never be able to get a job. Extreme poverty would rise as the state gets less taxes (as less goods are consumed, because people have less money). The AIs would predict how every single person would most likely act. How could they do so? Well, you have a smartphone. Your conversations on WhatsApp, Twitter, Facebook, Gmail, ... get tracked and automatically analyzed. You can be predicted to a certain degree. You can be influenced by personalized advertising. A really clever AI will make itself able to act in any possible scenario, replicate itself and make itself less dependent. In this dark scenario people would eventually start at some point to try to get more money from the people controlling the AIs, but how do you force them to do so? The police might also be replaced by AIs. My guess is that the reality would be somewhere in between. A couple of super-rich people and the rest giving them massages. A possible solution to those social problems I've just described that AIs might cause serious social problems. However, I think we can solve those problems by making sure that income inequality cannot get too high. This means there should be very high and effective inheritance tax as well as a taxation system that prevents people from getting too rich / people too poor. The most extrem action to prevent too poor people is an unconditional income, the most extrem action to prevent people getting too rich is an upper limit on what somebody could have. I think an unconditional income would be a good thing, but its hard to tell how high that should be. The easiest way to prevent people from getting too rich is adding a tax system that adjusts to income: Your first 0 - 2000 Euro / month don't get taxed at all Your next 2001 - 3000 Euro / month get taxed with 0% + (100%/2) = 50% Your next 3001 - 4000 Euro / month get taxed with 50% + (50%/2) = 75% Your next 4001 - 5000 Euro / month get taxed with 75% + (25%/2) = 87.5% ... You can (and should - I think my numbers are not well-chosen!) argue about the exact numbers, but I guess you get what I mean. The tax should never be 100%, thus leaving the possibility to get more money. But the difficulty to do so should increase. This effectively prevents that some people get too rich and hence resulting in a very instable system. It would be important to do so before anybody develops a strong AI. Related books, movies and talks Books (all fiction) \"Zero\" by Marc Elsberg: People get controlled by life improvement apps in a very indirect way. Out-Series by Andreas Eschbach : A device was developed, that lets people connect their brains. A new form of conciousness develops from that. Brave new world by Aldous Huxley : People get distracted from issues by consuming many goods. Movies (all fiction) Transcendence : The mind of one person gets transformed in a computer. I, Robot : An AI gets developed and very powerful humanoid robots get controlled by it. Talks The rise of the new global super-rich : Technology is advancing in leaps and bounds â€” and so is economic inequality, says writer Chrystia Freeland. In an impassioned talk, she charts the rise of a new class of plutocrats (those who are extremely powerful because they are extremely wealthy), and suggests that globalization and new technology are actually fueling, rather than closing, the global income gap. Freeland lays out three problems with plutocracy â€¦ and one glimmer of hope. And a coulple of talks by people who are not active within AI / ML research themselves: Nick Bostrom: \"Superintelligence\" - Strong AI is inevitable; we should set the initial conditions up the right way Sam Harris and Joe Rogan talking about artificial intelligence Max Tegmark and Nick Bostrom speak to the UN about the threat of AI UNICRI Articles 9 crazy things that could happen after the singularity, when robots become smarter than humans","tags":"Cyberculture","title":"The Impact of strong AIs"},{"url":"https://martin-thoma.com/reviews/logitech/","text":"Man kann mit diesen Lautsprechern das meiste ganz gut anhÃ¶ren. Allerdings ist mir aufgefallen, dass bei einigen Serien (Sense8 via Netflix) / Videos ein NebengerÃ¤usch hinzukommt. AuÃŸerdem \"stottert\" der Lautsprecher immer - auch wenn man nichts abspielt. Allerdings ist das relativ leise. Mit diesem YouTube-Video habe ich festgestellt, dass erst ab 100Hz etwas zu hÃ¶ren ist. Zwar haben die eingebauten Lautsprecher meines Billig-Notebooks (Acer Travelmate 5744Z) erst ab 200Hz einen Ton von sich gegeben, aber die Sennheiser HD 201 fÃ¼r 22 Euro schon bei 50 Herz. Und das ohne nerviges stottern. Im hohen Frequenzbereich ging es bis 12.5 kHz (16 kHz war nicht mehr zu hÃ¶ren). Damit sind die Logitech Z120 dort genauso gut wie meine Laptop-Lautsprecher und die Sennheiser HD 201.","tags":"Review","title":"Logitech z120 Lautsprecher"},{"url":"https://martin-thoma.com/universal-rating-system/","text":"A key feature of Amazon is its rating system. Rating systems are relatively straight-forward to build, but they need much data and get better with more data. I think Amazon builds a monopoly that way. However, I also think we could build an Universal Rating System (URS). Just as important as pure rating are reviews. What would an URS need? Directly neccessary are Identification of people : The same person should not be able to write multiple reviews or make multiple ratings for the same product. It is not important to tell which online-identity belongs to which person. In fact, I think it would be good if it was possible to keep users anonym while making sure that everybody has only one online-identity. Identification of products : Users have to be able to find products and they have to find reviews to that product. So some kind of product identification number is necessary. Ratings for reviews Uploading photographs Product description : This should be objective. Indirectly necessary are Recommendations : If users see that they get good recommendations from an independant source they might use the system. If they see that those recommendations imporve with more reviews and more ratings, they add more of them. This way the system gets better. Possibility to compare products : Examples are phonearena.com , ark.intel.com and others. But they are always limited to some products. Search : Users should be able to search for a product by specifying it. This could be a price range, a category, a review average, a minimum number of reviews, ... Easy login : Something like OpenID that makes it easy for users to create an account and sign in. * Right incentives : Having a great community is much about giving the right incentives. Badages and Karma are a great way to do so as shown with StackExchange. Non-software parts Advertisment : People have to get informed about such a system. Organization : The software should be OpenSource, the data should be published (as far as possible without breaking privacy) and the organization which runs the software should be a nonprofit organization. The reason is simply that it prevents abuse. Product registration : Companies should have the possibility to register their products to get an identification number. Project name : A good name is important. Any ideas? Existing Projects Does anybody know if such a project already exists? If there is no such project by now: Is anybody interested in working on it?","tags":"Cyberculture","title":"Universal Rating System"},{"url":"https://martin-thoma.com/nyquist-shannon-sampling-theorem/","text":"The Nyquistâ€“Shannon sampling theorem states that you have to sample more than twice the highest frequency. If you sample less often, you will get aliasing. The following videos show what aliasing is:","tags":"Code","title":"Nyquistâ€“Shannon sampling theorem"},{"url":"https://martin-thoma.com/formale-systeme/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žFormale Systeme\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr. Beckert im Wintersemester 2014/2015 gehÃ¶rt. Behandelter Stoff Folien Folien- satz Inhalt 01 Organisatorisches 02 Aussagenlogik: Modellierung von Sudoku; 8-Damen-Problem; Allgemeine Syntax und Semantik sowie Grundbegriffe, Tautologien und SÃ¤tze; Basis; ErfÃ¼llbarkeit; AllgemeingÃ¼ltigkeit; \\(M \\models A\\) 03 Aussagenlogik: Craig-Interpolation 04 Aussagenlogik: Normalformen ( KNF , DNF , KKNF ) 05 Binary Decision Diagrams: (normierte) Shannon-Formeln, sh-Operator, Shannon-Graph, Reduzierte Shannon-Graphen 06 SAT ; Satz von Cook ; Horn-Formeln ; DPLL 07 PrÃ¤dikatenlogik: Syntax (PL1); JML; (Kollisionsfreie) Substitutionen; Unifikation und der Algorithmus von Robinson; Unifikationstheorem 08 Pradikatenlogik: Semantik; Interpretation; Koinzidenzlemma; Substitutionslemma fÃ¼r Terme (und das fÃ¼r Formeln); Hoare-KalkÃ¼l; Modell; (Logische) Folgerung; AllgemeingÃ¼ltigkeit; Folgerbarkeit 09 Pradikatenlogik: Normalformen; Negationsnormalform; PrÃ¤nexe Normalform; Skolem-Normalform; Herbrand-Strukturen; Satz von Herbrand; Endlichkeitssatz der Aussagenlogik 10 Beweistheorie (EinfÃ¼hrung) 11 HilbertkalkÃ¼l; Deduktionstheorem; VollstÃ¤ndigkeit der PL1; Kompaktheitssatz; Endlichkeitssatz 12 Aussagenlogik: ResolutionskalkÃ¼l; 1-Resolution 13 PrÃ¤dikatenlogik: ResolutionskalkÃ¼l 14 TableaukalkÃ¼l 19 PrÃ¤dikatenlogik: SequenzenkalkÃ¼l 21 Peano-Arithmetik; Unentscheidbarkeit 28 JML 22 Reduktionssysteme: Gleichungslogik; Satz von Birkhoff; Termersetzungssysteme; Reduktionssysteme; Kanonische Reduktionssysteme; Noethersche Induktion; (lokale) Konfluenz 23 Termersetzungssysteme; Kritische Paare 27 Modallogik; Bakery-Algorithmus; Kripke-Strukturen; Charakterisierungstheorie; Entscheidbarkeit modaler Logiken 41 (VollstÃ¤ndige) endliche Automaten; NEAs ; Spontane ÃœbergÃ¤nge; Satz von Myhill und BÃ¼chi (vgl. Konstruktion ); RegulÃ¤re AusdrÃ¼cke 42 BÃ¼chi-Automaten; Zerlegungssatz 43 Lineare Temporale Logik; omega-Struktur; LTL-Formeln; LTL-Semantik; 45 LTL und BÃ¼chi-Automaten 50 Wiederholung ÃœbungsblÃ¤tter Ãœbungsblatt Lsg Inhalt ÃœB 1 : Aussagenlogik Lsg ErfÃ¼llbarkeit, UnerfÃ¼llbarkeit, AllgemeingÃ¼ltigkeit, Tautologie, KNF , DNF , Interpolanten ÃœB 2 : Aussagenlogik Lsg KKNF , BDD , Shannon Graphen ÃœB 3 : Aussagenlogik, PL1 Lsg DNF, KNF, DPLL ÃœB 4 : PL1 Lsg PL1 (Variante des ZebrarÃ¤tsels); Unifikation ÃœB 5 : PL1 Lsg Verwandschaftsbeziehungen; (Java) Integer; Interpretation/Modell/Formel; ErfÃ¼llbar / allgemeingÃ¼ltig / unerfÃ¼llbar ÃœB 6 : PL1 Lsg PrÃ¤nexnormalform; Skolemnormalform ( 09 ) ÃœB 7 : PL1, Aussagenlogik Lsg HilbertkalkÃ¼l ( 11 ); ResolutionskalkÃ¼l ( 12 ) ÃœB 8 : PL1 Lsg ResolutionskalkÃ¼l, TableaukalkÃ¼l ( 13 , 14 ) ÃœB 9 : PL1, Aussagenlogik Lsg ResolutionskalkÃ¼l, SequenzenkalkÃ¼l ( 19 ) ÃœB 10 : JML Lsg Klassen-Invarianten; Methoden-Vertrag; Spezifikation ÃœB 11 : Reduktionssysteme Lsg reflexive, transitive HÃ¼lle; (lokal) konfluent; noetersch; irreduzibel; Ackermann-Funktion; noethersche Induktion ( 22 ) ÃœB 12 : Modallogik Lsg Kripke-Strukturen ( 27 ) ÃœB 13 : BÃ¼chi-Automaten Lsg \\(\\omega\\) -Sprachen, \\(\\omega\\) -regulÃ¤re AusdrÃ¼cke ( 41 , 42 ) ÃœB 14 : LTL Lsg LTL-Formeln und BÃ¼chi-Automaten ( 43 , 45 ) JML Ein paar AuszÃ¼ge aus den Folien von Prof. Dr. Beckert. Ich finde daran sieht man schÃ¶n, wie JML funktioniert: public class PostInc { public PostInc rec ; public int x , y ; /*@ public invariant x >= 0 && y >= 0 && @ rec.x >= 0 && rec.y >= 0; @*/ /*@ public normal_behavior @ requires true; @ ensures rec.x == \\old(rec.y) && @ rec.y == \\old(rec.y) + 1; @*/ public void postinc () { rec . x = rec . y ++; } } Quelle: 28JML.pdf#page=3 Wichtig ist noch: /*@ @ assignable \\nothing; @ ensures (\\forall int j; l <= j && j < \\result; a1[j] != a2[j] ); @*/ Das assignable \\nothing besagt, dass keine Werte (nach auÃŸen sichtbar) verÃ¤ndert werden dÃ¼rfen. Die Schleifen-Syntax ist \\forall int i; B; R , wobei B eine BereichseinschrÃ¤nkung und R der Schleifenrumpf ist. Es gibt auch noch \\exists int i; B; R . Die PrÃ¤dikatenlogischen Operatoren sind ! : Negation && : und || : oder ==> : Implikation <==> : Ã„quivalenz == : Gleichheit public int commonEntry ( int l , int r ) { int k = l ; /*@ loop_invariant @ l <= k && k <= r && @ (\\forall int i; l<=i && i<k; a1[i] != a2[i]); @ assignable \\nothing; @ decreases a1.length - k; @*/ while ( k < r ) { if ( a1 [ k ] == a2 [ k ]){ break ;} k ++; } return k ; } Quelle: 28JML.pdf#page=44 Modallogik Interpretation $\\square A$ bzw. $\\square_p A$ $\\diamond A$ A ist notwendigerweise wahr A ist mÃ¶glicherweise wahr Zeit A ist zu jedem zukÃ¼nfigem Zeitpunkt wahr Es gibt einen zukÃ¼nftigen Zeitpunkt zu dem A wahr ist Glauben Ein Agent p glaubt A A ist konsistent mit den Aussagen, die p fÃ¼r wahr hÃ¤lt Wissen Ein Agent p weiÃŸ A p weiÃŸ nicht, dass A falsch ist ProgrammausfÃ¼hrung Nach AusfÃ¼hrung des Programs p gilt A Es gibt eine AusfÃ¼hrung des Programs p, nach der A wahr ist Kurz und Gut Die folgenden Stichpunkte sollte man (grÃ¶ÃŸtenteils nur sinngemÃ¤ÃŸ) auswendig kÃ¶nnen und verstehen: Eine Signatur \\(\\Sigma\\) ist eine abzÃ¤hlbare Menge von Symbolen. Die Elemente der Signatur heiÃŸen \"Aussagevariablen\". Eine Interpretation ist eine Abbildung \\(I: \\Sigma \\rightarrow \\{W, F\\}\\) Ein Modell einer Formel \\(A \\in For0_\\Sigma\\) ist eine Interpretation \\(I\\) mit \\(val_I(A) = W\\) . Ein Modell einer Formel ist also einfach eine Variablenbelegung, welche die Formel erfÃ¼llt. FÃ¼r \\(M \\subseteq For0_\\Sigma, A \\in For0_\\Sigma\\) gilt: \\(M \\models A\\) (lies: aus M folgt A), falls jede Variablenbelegung, welche \\(M\\) erfÃ¼llt, auch \\(A\\) erfÃ¼llt. \\(A \\rightarrow B \\equiv \\neg A \\lor B\\) \\(A \\models B\\) gdw. \\(\\models A \\rightarrow B\\) Der shannon-Operator \\(sh(a,b,c)\\) ist if(a) {c} else {b}. Die Craig-Interpolation von \\(A \\rightarrow B\\) ersetzt alle Aussagevariablen \\(\\{\\text{Aussagevariable } a \\in A | a \\notin B\\}\\) mit \\(c_i\\) ( \\(i=1,\\dots,n\\) ). Die Interpolante ist dann \\(C := \\bigvee_{(c_1, \\dots, c_n) \\in \\{0,1\\}&#94;n} A[c_1, \\dots, c_n]\\) . Eine DNF heiÃŸt \"vollstÃ¤ndig\" bzgl. einer Signatur \\(\\Sigma\\) , wenn falls fÃ¼r jedes \\(P \\in \\Sigma\\) in jeder Klausel entweder \\(P\\) oder \\(\\neg P\\) vorkommt. Eine DNF heiÃŸt \"minimal\", wenn jede kÃ¼rzere Formel nicht Ã¤quivalent ist. KKNF-Konstruktion: (1) Shortcuts \\(Q_1, \\dots, Q_n\\) fÃ¼r binÃ¤re Operatoren erstellen. Diese Shortcuts dÃ¼rfen auch andere Shortcuts verwenden (2) Ã„quivalenzen auflÃ¶sen (3) In KNF umformen. \\(sh(P_i, A, B)\\) heiÃŸt normiert, wenn \\(A\\) und \\(B\\) normiert sind und jede in \\(A \\cup B\\) vorkommende Variable \\(P_j\\) gilt \\(i < j\\) . Ein Shannon-Graph heiÃŸt reduziert, wenn es keine zwei Knoten \\(v,w\\) gibt, sodass die beiden in \\(v\\) und \\(w\\) verwurzelten TeilbÃ¤ume isomorph sind und es auch keinen Knoten gibt, bei dem beide ausgehenden Kanten in den selben Nachfolger fÃ¼hren. Reduzierter Shannon-Graph = OBDD = BDD = ordered binary decisio diagram Bei gegebener Indizierung sind reduzierte Shannon-Graphen bis auf Isomorphie eindeutig. Ist die Indizierung nicht gegeben, macht die Variablenanordnung einen groÃŸen Unterschied in der GrÃ¶ÃŸe (Knotenmenge) des reduzierten Shannon-Graphen. Multiplikation \\(k\\) -stelliger BinÃ¤rzahlen: FÃ¼r jede Ordnung \\(<\\) der Variablen in \\(X=\\{x_0, \\dots, x_{k-1}, y_0, \\dots, y_{k-1}\\}\\) gibt es einen Index \\(0 \\leq i < 2k\\) , sodass der BDD \\(B_{Mult_i,<}\\) mindestens \\(2&#94;{k/8}\\) Knoten besitzt. Horn-Formel: Formel in KNF, wobei jede Klausel hÃ¶chstens ein positives Literal enthÃ¤lt. Negationsnormalform: Negationen nur vor Atomen. Bereinigte Formel: (1) \\(Frei(A) \\cap Bd(A) = \\emptyset\\) (2) Die hinter Quantoren stehenden Variablen sind paarweise verschieden. PrÃ¤nexe Normalform: \\(A = Q_1 x_1 Q_2 x_2 Q_3 x_3 \\dots Q_n x_n B\\) , wobei \\(B\\) quantorenfrei sein muss. Dann heiÃŸt \\(B\\) die Matrix von \\(A\\) . Die PrÃ¤nexe Normalform ist nicht eindeutig. Skolem-Normalform: (1) geschlossene Formel (2) \\(\\forall x_1 \\dots \\forall x_n B\\) (3) Matrix \\(B\\) ist in KNF GÃ¶delscher VollstÃ¤ndigkeitssatz : Es gibt einen KalkÃ¼l der PL1 derart, dass fÃ¼r jede Formelmenge \\(\\Gamma\\) und fÃ¼r jede Formel \\(\\varphi\\) gilt: \\(\\varphi\\) folgt genau dann aus \\(\\Gamma\\) , wenn \\(\\varphi\\) im KalkÃ¼l aus \\(\\Gamma\\) hergeleitet werden kann. In Zeichen: \\(\\Gamma \\models \\varphi \\Leftrightarrow \\Gamma \\vdash \\varphi\\) . GÃ¶delscher UnvollstÃ¤ndigkeitssatz : Jedes hinreichend mÃ¤chtige, rekursiv aufzÃ¤hlbare formale System ist entweder widersprÃ¼chlich oder unvollstÃ¤ndig. Jedes hinreichend mÃ¤chtige konsistente formale System kann die eigene Konsistenz nicht beweisen. Kompaktheitssatz: Wenn A aus einer unendlichen Teilmenge der Formelmenge folgt, dann auch aus einer endlichen. Endlichkeitssatz: Eine Menge \\(M \\subseteq For_\\Sigma\\) hat genau dann ein Modell, wenn jede endliche Teilmenge von \\(M\\) ein Modell hat. Der ResolutionskalkÃ¼l arbeitet nur mit Formeln in Skolemnormalform. Tableau-KalkÃ¼l: Typ- \\(\\alpha\\) : Alles, was keine Quantoren hat und eindeutig ist Typ- \\(\\beta\\) : Alles, was keine Quantoren hat, aber nicht eindeutig ist Typ- \\(\\gamma\\) : Unendlich viele Typ- \\(\\delta\\) : min. eines Ob eine prÃ¤dikatenlogische Formel allgemeingÃ¼ltig ist, ist unentscheidbar. Die Menge der allgemeingÃ¼ltigen prÃ¤dikatenlogischen Formeln ist rekursiv aufzÃ¤hlbar. Die Menge der erfÃ¼llbaren prÃ¤dikatenlogischen Formeln ist nicht rekursiv aufzÃ¤hlbar. Ein Reduktionssystem ist ein Tupel \\((D, \\succ)\\) , wobei \\(D \\neq \\emptyset\\) eine Menge ist und \\(\\succ\\) eine Relation auf \\(D\\) ist. \\(\\rightarrow\\) bezeichnet die reflexive, transitive HÃ¼lle von \\(\\succ\\) . \\(\\stackrel{+}{\\rightarrow}\\) bezeichnet die transitive HÃ¼lle von \\(\\succ\\) . \\(\\leftrightarrow\\) bezeichnet die reflexive, transtive und symmetrische HÃ¼lle von \\(\\succ\\) . \\((D, \\succ)\\) heiÃŸt konfluent \\(:\\Leftrightarrow \\forall s_1, s_2, s_3 \\in D\\) mit \\(s \\rightarrow s_1 \\land s \\rightarrow s_2 \\exists t \\in D: s_1 \\rightarrow t \\land s_2 \\rightarrow t\\) \\((D, \\succ)\\) heiÃŸt lokal konfluent \\(:\\Leftrightarrow \\forall s_1, s_2, s_3 \\in D\\) mit \\(s \\succ s_1 \\land s \\succ s_2 \\exists t \\in D: s_1 \\rightarrow t \\land s_2 \\rightarrow t\\) \\((D, \\succ)\\) heiÃŸt noethersch, wenn es keine unendlichen Folgen \\(s_0 \\succ s_1 \\dots \\succ s_i \\succ \\dots\\) gibt. Ein konfluentes und noethersches Reduktionssystem heiÃŸt kanonisch. Ein Element \\(s \\in D\\) heiÃŸt irreduzibel (oder eine Normalform) in \\((D, \\succ)\\) , wenn kein \\(t \\in D\\) existiert mit \\(s \\succ t\\) . Sei \\(s \\in D\\) . Ein Element \\(s_0 \\in D\\) heiÃŸt eine Normalform fÃ¼r \\(s\\) in \\((D, \\succ)\\) , wenn \\(s_0\\) irreduzibel ist und \\(s \\rightarrow s_0\\) gilt. In kanonischen Reduktionssystemen hat jedes Element eine eindeutige Normalform. \\((D, \\succ)\\) ist noethersch und lokal konfluent \\(\\Rightarrow (D, \\succ)\\) ist konfluent. Eine Kripke-Struktur ist ein Tupel \\(\\mathscr{K} = (S, R, I)\\) mit \\(S \\neq \\emptyset\\) ist die Menge der ZustÃ¤nde bzw. der mÃ¶glichen Welten. \\(s \\in S\\) heiÃŸt also auch eine \"Welt\". \\(R \\subseteq S \\times S\\) ist die ZugÃ¤nglichkeitsrelation \\(I: (\\Sigma \\times S) \\rightarrow \\{W, F\\}\\) ist die Interpretation der Aussagenlogischen Variablen \\((S, R)\\) heiÃŸt der Kripke-Rahmen von \\(\\mathscr{K}\\) . \\(\\square A \\rightarrow A\\) ist nur in reflexiven Kripke-Strukturen eine Tautologie. Ein endlicher Automat ist ein Tupel \\((S, V, \\delta, s_0, S_1)\\) , wobei \\(S\\) eine endliche Zustandsmenge ist, \\(V\\) ein endliches Alphabet (terminale Zeichen) ist, \\(\\delta: S \\times V \\rightarrow S\\) eine Funktion ist, die besagt bei welchem Eingabezeichen man von welchem Zustand aus in welchen Zustand kommt, \\(s_0 \\in S\\) ein Startzustand und \\(S_1 \\subseteq S\\) die Menge der EndzustÃ¤nde ist \\(V&#94;\\omega\\) ist die Menge der unendlichen WÃ¶rter mit Buchstaben aus \\(V\\) . \\(w(n)\\) ist der \\(n\\) -te Buchstabe des Wortes \\(w\\) . \\(w \\downarrow (n)\\) ist das endliche AnfangsstÃ¼ck \\(w(0)\\dots w(n)\\) von \\(w\\) . \\(\\varepsilon \\notin V&#94;\\omega\\) FÃ¼r \\(K \\in V&#94;*\\) und \\(J \\in V&#94;\\omega\\) ist \\(KJ=\\{w_1 w_2 | w_1 \\in K, w_2 \\in J\\}\\) FÃ¼r \\(K \\in V&#94;*\\) ist \\(\\overset{\\rightarrow}{K}=\\{w \\in V&#94;\\omega | w \\downarrow (n) \\in K \\text{ fÃ¼r unendlich viele } n\\}\\) Ein BÃ¼chi-Automat ist ein nicht deterministischer endlicher Automat, der WÃ¶rter akzeptiert, wenn es eine Berechnungsfolge mit unendlich vielen FinalzustÃ¤nden gibt. (vgl. Beispiel ) A U B: A gilt, bis B gilt (das U steht fÃ¼r \"until\"). Allerdings gilt B auch irgendwann. Es kann also nicht sein, dass A unendlich lange gilt und B nie. \\(A\\;\\textbf{U}_W\\;B\\) bedeutet, dass entweder immer A und gleichzeitig nie B gilt, oder dass irgendwann B gilt und davor gilt immer A. Das 'W' steht fÃ¼r 'weak'. \\(A\\;\\textbf{V}\\;B\\) : B gilt so lange, bis A gilt. Daher wird V auch 'Release-Operator' genannt. \\(\\diamond \\square P\\) : Es gibt einen Zeitpunkt, ab dem immer B gilt. Zu jeder LTL-Formel gibt es einen effektv konstruierbaren BÃ¼chi-Automaten. ErfÃ¼llbarkeit und AllgmeingÃ¼ltigkeit von LTL-Formeln ist entscheidbar. Ein KalkÃ¼l ist korrekt, wenn alles was formal ableitbar auch wahr ist. (vgl. Korrektheit (Logik) ) 08Pk1Semantik-print.pdf, Folie 34/37: QxB steht fÃ¼r \"Quantor x B\", wobei der Quantor entweder \\(\\exists\\) oder \\(\\forall\\) ist, \\(x\\) eine Variable ist und \\(B\\) eine Formel ist. Wissens-Check Folgende Fragen sollte man fÃ¼r die Klausur schnell beantworten kÃ¶nnen: Nenne 3 Basen fÃ¼r die Aussagenlogik. Eine davon soll hÃ¶chstens einen Operator haben. In welcher KomplexitÃ¤tsklasse ist das ErfÃ¼llbarkeitsproblem fÃ¼r 3-KNF? In welcher 2-KNF? Wie sieht es mit dem AllgemeingÃ¼ltigkeitsproblemen aus? Was ist der Shannon-Graph von \\(1\\) ? Was ist der Shannon-Graph von \\(0\\) ? Was ist der Shannon-Graph von \\(a \\lor b\\) ? Was ist der Shannon-Graph von \\(a \\land b\\) ? Meine Fragen 02, Folie 19/29 : Warum wird einmal \\(\\models\\) und dann \\(\\models_\\Sigma\\) geschrieben? 07, Folie 19/51 : Warum \"fast alle\" \\(x \\in Var\\) ? Was bedeutet das? Es dÃ¼rfen nur endlich viele Variablen umbenannt bzw. durch einen Term ersetzt werden. Andernfalls werden die Beweise und Notationen hÃ¤sslich. AbzÃ¤hlbar unendlich viele Variablen sind praktisch, wenn man sich die Existenz immer weiterer Variablen sichern will, die nicht in einer gegebenen Formel auftauchen. NatÃ¼rlich ist jede Formel endlich, enthÃ¤lt also nur endlich viele Variablen. Folie 8/30 : Wieso stimmt diese Umformung? Gebundene Variablen dÃ¼rfen unabhÃ¤ngig von freien umbenannt werden. Die andere Umformung kann nachvollzogen werden, wenn die Implikation \\(A \\rightarrow B\\) zu \\(\\neg A \\vee B\\) umgeformt wird. Man beachte folgende Umformungsregel: \\(\\neg \\forall x F(x) \\equiv \\exists x \\neg F(x)\\) . Folie 23/30 : Was ist eine Grundinstanz? Wo ist der Unterschied zwischen \"Grundinstanz\" und \"Instanz\"? Was sind \"Grundterme\"? Grundterm: Ein Term, der keine Variablen enthÃ¤lt. Instanz: FÃ¼r quantifizierte Variablen wurden Terme eingesetzt. Grundinstanz: FÃ¼r alle Variablen wurden Grundterme eingesetzt. Damit enthalten Grundinstanzen Ã¼berhaupt keine Variablen mehr. Folie 24/30 : Was ist ein Beispiel fÃ¼r \\(D = Term_\\Sigma&#94;0 \\neq\\) Menge der Grundterme? Wo gilt 2. nicht? Ich vermute mal, dass \\(Term_\\Sigma&#94;0 := $ Menge der Grundterme. Bachte (sofern die Definition stimmt): $Term_\\Sigma&#94;0 \\subseteq Term_\\Sigma\\) , da es auch Terme gibt, die Variablen enthalten, falls welche in der Signatur vorhanden sind. Was ist die Bedeutung von Herbrand-Strukturen / dem Satz von Herbrand? Blatt 6, LÃ¶sung zu Aufgabe 4 : Den Teil mit der Umwandlung einer Aussagenlogischen Formel verstehe ich nicht. Kann das jemand bitte fÃ¼r \\(a \\land \\neg b \\lor c \\lor d\\) erklÃ¤ren? Blatt 9, LÃ¶sung zu Aufgabe 1 : Ist der Baum, also insbesondere die ersten 4 Knoten, richtig? Warum steht in Knoten 1 nicht \\(1\\forall x \\forall y \\forall z (r(x,y) \\land r(y,z) \\rightarrow r(x,z))\\) ? Wie funktioniert der 1. Schritt in Aufgabe 2? Haben reflexive Relationen irreduzible Elemente? Laut unserer Definition nicht. Aber du kannst jede n-stellige Relation mit dem Komplement der n-stelligen Gleichheits-Relation schneiden, dann erhÃ¤ltst du ihr irreflexives GegenstÃ¼ck. KÃ¶nnen reflexive Relationen noethersch sein? Nur, wenn sie leer sind. Ansonsten gibt es immer unendliche Ketten. Folie 27 : Wie muss ich \\(\\square \\diamond P\\) lesen? Von jeder erreichbaren Welt aus gibt es eine erreichbare Welt, in der P gilt. Die Verbalisierung der Relation \"erreichbar\" klappt immer ;) Blatt 12, Aufgabe 1b : Was sagt \\(\\diamond\\square P\\) auf dem Graphen aus? Insbesondere: Warum ist \\(w_5\\) nicht in \\(\\diamond\\square P\\) ? Was wÃ¤re \\([[\\square \\diamond P]]\\) ? Blatt 12, Aufgabe 4 : Das muss ich noch mal in Ruhe durchgehen. 21, Folie 8 : Was ist \\(Th(N)\\) und was ist \\(Cn(PA)\\) ? \\(Th(N)\\) : Theoreme Ã¼ber N, also die Menge aller Formeln, fÃ¼r die die natÃ¼rlichen Zahlen ein Modell sind. Cn(PA): Menge aller Formeln, die aus den Axiomen der Peano-Artihmetik gefolgert werden kÃ¶nnen. Da die Peano-Arithmetik korrekt ist, ist jede Formel aus Cn(PA) auch in Th(N). 50, Folie 16 : Was bedeutet es, dass \\(Th(N)\\) nicht rekursiv ist? Rekursiv heiÃŸt entscheidbar. Da die Peano-Axiome durch die Peano-Artihmetik formalisiert werden kÃ¶nnen, gibt es eine Formel P(x), die genau dann wahr ist, wenn fÃ¼r x die Kodierung einer solchen Formel eingesetzt wird, die sich nicht aus den Peano-Axiomen herleiten lÃ¤sst. Nach dem GÃ¶delschen UnvollstÃ¤ndigkeitssatz gibt es nun eine Formel P und x derart, dass x mit der Kodierung von P(x) Ã¼bereinstimmt: Eine Formel also, die Ã¼ber sich selbst behauptet, sie sei nicht herleitbar. Da es nur ein Modell gibt, ist jede Formel entweder unerfÃ¼llbar oder allgemeingÃ¼ltig. Wenn \\(Th(N)\\) entscheidbar wÃ¤re und P(x) allgemeingÃ¼ltig, dann entsteht Widerspruch zur Wahl von P und x. Wenn P(x) unerfÃ¼llbar wÃ¤re, ist nach Wahl von P und x P(x) herleitbar, was wieder einen Widerspruch darstellt. Um den Widerspruch aufzulÃ¶sen, darf \"aus den PA-Axiomen herleitbar\" nicht mit \"im Modell der nat. Zahlen gÃ¼ltig\" Ã¼bersetzt werden. 23, Folie 5 : Kann mir jemand ein konkretes Beispiel geben? 43, Folie 2 : Was sind omega-Strutkuren und insbesondere was bedeutet \\(2&#94;P\\) ? Eine Omega Struktur Ordnet jedem Zeitpunkt, wenn die natÃ¼rlichen Zahlen als Zeitstrahl aufgefasst werden, eine Menge von aussagenlogischen Variablen zu, die als \"wahr\" gelten sollen. \\(2&#94;P\\) ist die Potenzmenge von P. Ist \\(A\\;\\textbf{U}_W\\;B\\) Ã¤quivalent zu \\(B\\;\\textbf{V}\\;A\\) ? Blatt 14, 2a : Warum ist \\(\\diamond (p\\;\\textbf{U}\\;q)\\) Ã¤quivalent zu \\(\\diamond q\\) ? Ich dachte es wÃ¤re Ã¤quivalent zu \\(p\\;\\textbf{U}\\;q\\) ? Blatt 14, 3 : Wie wÃ¼rde der Automat aussehen, wenn das \\(X\\) weggelassen wÃ¼rde? Blatt 14, 4 : Das wÃ¼rde ich gerne gemeinsam durchgehen. 50, 13 : Was sind die Ziele der Beweistheorie? Was ist die Grundidee des Hilbert-KalkÃ¼ls? Ziele: Automatisches Beweisen ermÃ¶glichen und die Grenzen bestimmen. Grundidee des Hilbert-KalkÃ¼ls: Aus Axiomen konstruktiv Formeln folgern. Im Gegensatz zu den praxis-orientierten Beweisverfahren kann der Hilbert-KalkÃ¼l leichter in theoretischen Beweisen verwendet werden. Der GÃ¶delsche UnvollstÃ¤ndigkeitssatz verwendet z.B. den Hilbert-KalkÃ¼l. 50, 13 : \"Aussagenlogische Tableauregeln aus Wahrheitstafeln konstruieren.\" - was ist damit gemeint? 50, 15 : Was ist die Grundidee der Peano-Arithmetik? Liegt doch eigentlich auf der Hand: Zahlentheoretische Aussagen automatisch beweisen. 50, 33 : Wie kann man sich in dem Beispiel den Unterschied zwischen PrÃ¤dikaten und Funktionen erschlieÃŸen? Funktionen sind immer in PrÃ¤dikaten enthalten. Ein PrÃ¤dikat darf kein weiteres PrÃ¤dikat enthalten. Wie ist ErfÃ¼llbarkeit in der PrÃ¤dikatenlogik definiert? Z.B. erscheint mir \\(\\exists x p(x)\\) erfÃ¼llbar, wenn nichts weiter gegeben ist. Wenn man aber \\(p(x)=False\\) fÃ¼r alle \\(x\\) sagt, dann ist es unerfÃ¼llbar. F ist erfÃ¼llbar gdw. es ein Modell fÃ¼r F gibt, d.h. eine Interpretation I, sodass val_I(F) = W. MÃ¼ssen die Kanten von Shannon-Graphen mit W und F oder mit 1 und 0 beschriftet werden? Praktisch alle Altklausuren verwenden 1 und 0, aber ich meine er hÃ¤tte in der Vorlesung gesagt, dass wir W und F verwenden sollen. Ist die Menge der allgemeingÃ¼ltigen / erfÃ¼llbaren / unerfÃ¼llbaren Formeln der PL1 abzÃ¤hlbar? Jede Teilmenge aus \\(\\Sigma&#94;*\\) ist abzÃ¤hlbar fÃ¼r ein endliches Alphabet \\(\\Sigma\\) . Es gibt aber Ã¼berabzÃ¤hlbar viele Teilmengen, deren Elemente zwar wieder abzÃ¤hlbar sind, aber sowohl die Teilmengen selbst als auch ihre Elemente nicht aufzÃ¤hlbar sind. Beachte: AufzÃ¤hlbar \\(\\neq\\) AbzÃ¤hlbar. Wie kann man \\(U\\) durch \\(U_W\\) darstellen? Altklausuren WS2010/2011, 1. Zwischentest, A4: Ist der Markierungsalgorithmus fÃ¼r Hornformeln relevant? WS2010/2011, 2. Zwischentest, A1: Was ist eine kompakte Logik? (PL2 ist laut WS2008/2009, 2.Zwischentest 1b, nicht kompakt) Was bedeutet \\(Cl_{\\exists}(t_1 \\doteq t_2)\\) ? WS2009/2010, A1c: Wieso gibt es fÃ¼r \\(\\exists p(x)\\) kein Herbrandmodell? WS2009/2010, 1.Zwischentest A1a: Was ist ein \"Vereinfachungsschritt\" im Davis-Putnam-Verfahren? Was bedeutet es, wenn dort keine Klausel mehr zur VerfÃ¼gung steht? A1a: \"Wenn A und B erfÃ¼llbar sind, dann ist auch \\(A \\rightarrow B\\) erfÃ¼llbar.\" - Was ist mit \\(B = \\neg A\\) ? WS 2009/2010, 2. Zwischentest (ist beim ersten): A1a: Warum ist \\(\\forall x \\forall y (x \\leftrightarrow y)\\) keine Formel der PL1? A4: Will ich gerne durchsprechen WS 2008/2009: 1a: Warum ist \\(\\forall x (p(x) \\rightarrow q(p(x)))\\) keine Formel der PL1? 1a: Warum ist \\(\\exists x (p(x) \\rightarrow p(f(x)))\\) allgemeingÃ¼ltig? 1b: Was ist ein Beispiel fÃ¼r einen BÃ¼chi-Automaten, fÃ¼r den es keinen deterministischen BÃ¼chi-Automaten gibt? 1b: \"FÃ¼r jede geschlossene prÃ¤dikatenlogische Formel G gilt: Es gibt ein Modell fÃ¼r G oder fÃ¼r das Negat von G oder fÃ¼r beide.\" - Gilt das nicht fÃ¼r alle prÃ¤dikatenlogischen Formeln (egal ob geschlossen oder nicht)? WS 2008/2009, 1. Zwischentest: 1a: Wie lange dauert der kÃ¼rzeste Resoultionsbeweis in Anzahl der Literale? 1b: Warum gibt es keine prÃ¤dikatenlogische InterprÃ¤tation, in der alle prÃ¤dikatenlogischen Formeln wahr sind? Material Skript Vorlesungswebsite Altklausuren StackExchange: What is the operator precedence for quantifiers? How do you bring quantors to the front of a formula? How to convert to conjunctive normal form? Ãœbungsbetrieb Wo sind die ÃœbungsblÃ¤tter: Link Abgabeform: Keine Abgabe Turnus: wÃ¶chentlich LÃ¶sungen: Die LÃ¶sungen von jeweils zwei BlÃ¤ttern werden dann in den 14-tÃ¤gig stattfinden Ãœbungen am Freitag besprochen. Ãœbungsschein verpflichtend: Es gibt keinen Ãœbungsschein. Bonus durch Ãœbungsschein: Es gibt keinen Klausurbonus durch ÃœbungsblÃ¤tter. Anderer Klausurbonus: Man kann durch insgesammt 4 Zwischentests und 2 Praxisaufgaben fÃ¼r die wirkliche Klausur Punkte sammeln. Die Teilnahme an den Zwischentests und den Praxisaufgaben ist freiwillig. Die erzielten Ãœbungspunkte werden im VerhÃ¤ltnis 1:10 als Bonuspunkte auf die bestandene Abschlussklausur angerechnet. Termine und Klausurablauf Siehe Klausurtermine-Seite fÃ¼r zukÃ¼nftige Termine. Datum : Freitag, den 6. MÃ¤rz 2015 von 11:00 bis 12:00 Uhr ( Quelle ). Ort : Gerthsen ( 30.21 ) und HSaF ( 50.35 ) - vgl. Anmeldeliste Punkte : 60 Punkteverteilung : ? (Stand: 06.03.2015) Bestehensgrenze : ? (Stand: 06.03.2015) Ãœbungsschein : Gibt es nicht. Bonuspunkte : Bis zu 8. Die Punkte aus den 4 ZwischenprÃ¼fungen und 2 Praxisaufgaben werden addiert, dann durch 10 geteilt und schlieÃŸlich kaufmÃ¤nnisch gerundet. Ergebnisse : Klausur wurde noch nicht geschrieben Einsicht : steht noch nicht fest (Stand: 06.03.2015) Erlaubte Hilfsmittel : Keine. Ergebnisse Klausur wurde noch nicht geschrieben.","tags":"German posts","title":"Formale Systeme Klausur"},{"url":"https://martin-thoma.com/gradient-descent-the-delta-rule-and-backpropagation/","text":"If you learn about machine learning you will stumble over three terms that are related: Gradient descent, the Delta rule and backpropagation Gradient descent is a way to find a minimum in a high-dimensional space. You go in direction of the steepest descent. The delta rule is an update rule for single layer perceptrons. It makes use of gradient descent. Backpropagation is an efficient implementation of gradient descent, where a rule can be formulated which has some recursively defined parts. Those parts belong to neurons of different layers and get calculated from the output-layer (last layer) to the first hidden layer. See also Wikipedia pages: Gradient descent Delta rule Backpropagation","tags":"Machine Learning","title":"Gradient Descent, the Delta Rule and Backpropagation"},{"url":"https://martin-thoma.com/write-math/","text":"On-line handwriting recognition systems get the information how a symbol is written. In contrast, OCR only gets the pixel map. I've created a system that can be used to work with handwriting recognition systems in my bachelor's thesis. write-math.com The website write-math.com was used to collect data. The source is at github.com/MartinThoma/write-math . hwrt toolkit The hwrt toolkit was created to work with on-line handwritten symbols. The toolkit is documented at pythonhosted.org/hwrt . The raw data can be downloaded with this toolkit. The toolkit can be used to classify data on your computer (without internet connection): Write math: Interactive Browser Interface (offline) nntoolkit The nntoolkit was created to have a free software to create, train, test and evaluate neural networks. HWR experiments All experiments configuration files are saved in the project github.com/MartinThoma/hwr-experiments . Data The data can be downloaded from write-math.com/data . I will try to keep a relatively recent version online. You can contact me if you want the latest version. However, I should note that currently (2015-04-12) this is about 3.7GB. This means sharing the data is not that easy. Presentations 27.08.2014 06.11.2014 : Final presentation for bachelor's thesis Bachelor's thesis 07.11.2014 : My bachelor's thesis. I've got the best grade (1.0) for it â˜º. Please note that the submission to arxiv was later and a couple of typos were fixed as well as the term \"data multiplication\" was replaced by \"data augmentation\". 29.06.2015 : An updated, condensed version of my bachelor's thesis. Remarks What I called \"data multiplication\" is called \"data augmentation\" by others (e.g. ImageNet Classification with Deep Convolutional Neural Networks , Deep Image: Scaling up Image Recognition , Classifying plankton with deep neural networks )","tags":"Code","title":"On-line Handwriting Recognition of Mathematical Symbols"},{"url":"https://martin-thoma.com/3d-printing/","text":"3D printing is a hot topic for quite a while now. 3D printers have become cheap enough so that many ordinary people can have 3D printers for their personal use. In this article, I would like to point out some very nice applications of 3D printing. Medicine 3D printing has basically two application in medicine: Very customized non-organic parts or organic printing. Printing a human Kidney \"Magic Arms\" prosthetic 3D printing gives man new face Other examples Hearing aids Bones Print on wounds Shoes I am always struggling with finding good shoes. Most shoes I try feel unconfortable, although I have size 42 (which seems to be a very standard size in Germany for males). What if we could go to a store, let them 3D scan our feet and they automatically adjust a 3D model of a shoe to fit to our feet. Then some parts are 3D printed, assembled and a few days later we get a shoe that is customized to our feet and cheap. continuumfashion.com seems to 3D print shoes with Nylon. kobilevidesign.com is another designer who 3D prints shoes. Toys Board game figures (e.g. custom chess sets, Monopoly cars, ...) Model building (e.g. Ship model where people pay A LOT of money for it) Lego Teaching Did you have chemistry in school and learn about atom models / crystaline structures? With 3D printing, it becomes easy to get those models for every student! Or think about architecture and history. You could show models of ancient cities or buildings in 3D. Spare parts Imagine something small breaks. Sometimes very expensive devices that are otherwise fine, become useless or at least ugly. Now think you could go online, download a 3D model of that part and just print it. Design Lamps Cups Weapons Sadly, 3D printing can also be used to produce weapons ( source ). However, a 3D printed pistol has a high chance of not working at all, of hurting the person that created it and of working. So currently, it's quite a lot of gambling. But that might change when the quality of 3D printing improves. See also Printers and Stuff CraftBot 3D printer : An indiegogo project for an 3D printer that costs for about 315 Euro Rapide Lite : about 730 Euro, 50 micron resolution ProtoCycler: Free, Sustainable 3D Printer Filament : Another indigogo project, which aims to recycle plastics and create filaments yourself. Rapide Lite : Another 3D printer PancakeBot - The world's first pancake printer! BoXZY NEA 3D Ember : A 3D printer (DLP Stereolithography) for about 6000 US-Dollars (Z-Resolution of 10 microns, xy-resolution of 50 microns; 18 mm/hour at 25Âµm layers). Engineering The Worlds smallest 3D printer Medicine Printing a human kidney Print your own medicine The sore problem of prosthetic limbs Models Ancient wonders captured in 3D General 3D printing 3dpi.tv A primer on 3D printing Category:3D printing MakerBot Thing-i-verse Digital Forming : A company that allows you to customize 3D models yobi3d.com : A database of 3D models Applications: Print to Build: 3D-Printed Joints Make it Easy to Construct Furniture","tags":"Cyberculture","title":"3D Printing"},{"url":"https://martin-thoma.com/interact/","text":"interACT is an exchange program for students. I'm a student from KIT (Germany) and I went to CMU in Pittsburgh (US). The information in the following article will be most useful for students who also come from KIT and want to go to CMU. Participating universities An interACT exchange is available between the following universities: United States: CMU , Pittsburgh and Mountain View USC ( Los Angeles ) Germany: KIT ( Karlsruhe ) China: HKUST ( Hong Kong ) Japan Waseda University ( Tokyo ) NICT ( Tokyo ) NAIST ( Ikoma ) Spain: IIT ( Madrid ) Preparation You need to think about quite a lot for your preparation. This should give you an overview: Forms and other general stuff bank statement send copy of passport to interACT visit US embassy get to know some people in the US before you get there transfer money on your VISA card to make sure you have enough when you're there mobile: ultra.me is the best internet / phone provider! test internet calls (Skype / Google Hangouts) with parents and partner organize the flight after you have the Visa back Find a room Do you want to find a subleaser? Get a room in the US http://sfbay.craigslist.org/ eventually airbnb.de for the first nights Health Get health insurance for the US Signal Iduna barmenia.de: http://www.barmenia.de/de/produkte/reiseversicherung/einzelreisen/reisekrankenversicherung.xhtml price: ca. 283 Euro If you are also in the \"Studienstiftung\" you should have a look in \"Daidalosnet\". There is a very good offer for health insurance Go to all doctors you need in Germany right before you go to the US: dentist Vaccination (I refreshed Tetanus , Diphtheria and Pertussis with a single injection) What to take with you Cloths Check the weather and adjust the list to your needs. Don't forget a raincoat warm cloths for the flight And, of course, don't forget towels: Just about the most massively useful thing any interstellar Hitchhiker can carry. Partly it has great practical value. You can wrap it around you for warmth as you bound across the cold moons of Jaglan Beta; you can lie on it on the brilliant marble-sanded beaches of Santraginus V, inhaling the heady sea vapours; you can sleep under it beneath the stars which shine so redly on the desert world of Kakrafoon; use it to sail a miniraft down the slow heavy River Moth; wet it for use in hand-to-hand combat; wrap it round your head to ward off noxious fumes or avoid the gaze of the Ravenous Bugblatter Beast of Traal (a mind-bogglingly stupid animal, it assumes that if you can't see it, it can't see you â€” daft as a brush, but very very ravenous); you can wave your towel in emergencies as a distress signal, and of course you can dry yourself off with it if it still seems to be clean enough. More importantly, a towel has immense psychological value. For some reason, if a strag (strag: nonhitchhiker) discovers that a hitchhiker has his towel with him, he will automatically assume that he is also in possession of a toothbrush, washcloth, soap, tin of biscuits, flask, compass, map, ball of string, gnat spray, wet-weather gear, space suit etc., etc. Furthermore, the strag will then happily lend the hitchhiker any of these or a dozen other items that the hitchhiker might accidentally have \"lost.\" What the strag will think is that any man who can hitch the length and breadth of the Galaxy, rough it, slum it, struggle against terrible odds, win through and still knows where his towel is, is clearly a man to be reckoned with. Hence a phrase which has passed into hitch hiking slang, as in \"Hey, you sass that hoopy Ford Prefect? There's a frood who really knows where his towel is.\" more passport document for your health insurance in the US smartphone camera - I bought the Panasonic Lumix DMC-TZ41 for 260 Euro and 64 GB Flash storage for 32 Euro for this trip. It is worth the money! It is an exceptional camera! laptop chargers power adapters (at least 2!). I can recommend this big adapter . Don't take the small ones! They are very loose. hygiene products (toothbrush, dental floss, dental floss, razor, shaving foam) Overview by time On 10.01.2014 I decided that I would like to go to the US. At 26.04.2014 I got my passport with the visa back. So it took more than 4 months until I could finally be sure that I can go to the US. Keep that in mind! I have written down when I did what (that sounds soo wrong - please correct me if you know how to express that in English). It should help you to plan your trip. Application A first step is the application as described here . A general contact person is Margit RÃ¶dder . Get all required documents to OIE After you've got accepted by the interACT advisory board (whoever that is), you have to get a 'bank statement'. These are some lines where your bank confirms that you have enough money to live from when you're in the US. It is very important that this statement is in English. So you should have about 1775 US-Dollar per month on your bank account. This means, if you want to be in the US for 4 months, make sure that you have at least 7100 US-Dollar on your account For customers of 'Sparkasse' this costs 25 Euro and you have to make sure that what you get is in English. For customers of 'comdirect' this costs 10 Euro For customers of 'Volksbank / Raiffeisenbank' this seems to be free. So I gave the bank statement and a copy of my passport to Margit RÃ¶dder. Some days later I've received an invitation from my advisor at CMU and some legal stuff I had to sign. I did this and send a copy to Faith Bold. 26.03.2014 All documents are signed and I sent them to Faith. 26.03.2014 Faith submitted the documents to the OIE. Receive documents from OIE 03.04.2014 : Got e-mail from UPS that they got my forms. Nice to know. 07.04.2014 : I've got my forms now (especially DS-2019). It seems as if I have to pay a fee of 180 US-Dollar for SEVIS. There is no refunding possible when I don't get the visa ( source ). And that's not the same as the visa application fee (which is additional 160.00 US-Dollar). So I've paid the SEVIS fee on www.FMJfee.com . You need one of the following credit cards for that step: American Express Diners Club Discover MasterCard Visa DS-160 14.04.2014 : I've filled this form. Address: You can fill in the address of your department (see admission document header) Know your rights video and information Visa and Visiting the U.S. embassy You have to pay here for your visa. Some hints: Your exchange number usually starts with a P SEVIS number is on top of DS-2019 (N....) Some first information: link There is quite a lot of stuff you may not bring to the embassy ( list ) You can see visa wait times online. I had to go to Frankfurt and that were about 2 days. You do not need a DS-7002, because that's only for interns. You're a short-term scholar. See also: Visa interview information Check this checklist: USembassy.gov nonimmigrant documents 23.04.2014 08:20: Although my appointment was scheduled for 9 o'clock, I've been there much earlier. There was a ~20m queue with ~80 people waiting. 08:59: I arrived at the first counter window. This one is outside of the embassy. I had to show my documents, tell the officer which visa I'm going to apply for. He gave me a \"service ticket\". With that ticket I could queue into the \"security check\" queue. That one is also outside of the embassy. I had to remove my belt and my wallet, put it into a plastic bag that I was given. After that, I could enter. Then I put my jacket and the plastic bag into a box that got through a scanner. 09:05: Next I got to a \"welcome desk\". A lady gave me a sheet of paper and told me to arrange the documents listed (and only those documents) there in the right order. It was something like: passport, SEVIS confirmation, photo, DS-160, DS-2019. 09:07: Line up in the next queue *sigh*. 09:30: I gave the officer my documents, she returned the photograph to me (seems as if this is not necessary if you've already uploaded it) and scanned my fingers. 09:35: Line up in the next queue... 09:40: Scan my fingers ... again. 09:45: Line up in the final queue past the \"T\" sign. 09:55: This is the first officer that asked my some questions. The questions were: * Officer: Where do you want to go and what do you want to do there? * Me: I want to go to CMU, Carnegie Mellon University in Pittsburgh, Pennsylvania, to write my bachelors thesis in computer science. * Officer: Who will pay for your expenses? * Me: I have a scholarship called \"interACT\" and I pay the rest by myself. * Officer: Your visa has been approved. You will receive your passport within one week. That was it. After-VISA-Stuff 26.04.2014 My passport arrived with the visa in it. Now I've contacted about 20 people I found on craigslist asking for a room in Pittsburgh. 27.04.2014 Finding a room to live fro 3 months in Pittsburgh is more difficult than I thought. And finding a room to store my stuff for those 3 months in Karlsruhe is also not so easy. All self-storage services like lager7 , lagerbox.com and deinlagerplatz.de are not in Karlsruhe. But I thought finding a cellar / garage near Karlsruhe for 50 Euro / month or less would be easy ... edit: I finally decided to store most of my stuff at my fathers and sublease the room. That was a good decision. Here are some documents for subleasing. But before you start ask your landlord if you're allowed to sublease! Zwischenmietvertrag BestÃ¤tigung SchlÃ¼sselÃ¼bergabe BestÃ¤tigung SchlÃ¼sselÃ¼bergabe (zurÃ¼ck) 07.05.2014 An e-mail arrived from \"Baden-WÃ¼rttemberg-Stipendium\" telling me that I now have full access to their material and that I have to sign something and sent it back to them. They also told me that my scholarship is 900 Euro / month for 4 months. Finally some good news! Eventually it will not get as expensive as I thought! Getting the flight tickets I have heard that fluege.de has a very bad service. They seem not to send you the tickets in time (I've heard something about two weeks later!) and they don't show the correct price. There is more information on Wikipedia.de . OneTwoTrip on the other hand had some good reviews 1 2 . Here is a (German) explanation of the booking process: Other online portals are: skyscanner.de has only one rating on ciao.de swoodoo.com is a meta search engine that uses fluege.de billigflieger.de has only 3 ratings on ciao.de and 60 on trustpilot.de expedia.de has 3/5 stars on ciao.de and 1/5 stars on trustpilot.de fluege.de has 2.5/5 stars on ciao.de and 3/5 stars on trustpilot.de cheaptickets.de has very bad critics on Wikipedia (see ciao.de ) but 4/5 stars on trustpilot.de Baggage: united.com IMPORTANT If possible, try not to fly over Chicago! That Airport is HUGE. I had 1.5 hours to get my next flight and I did not manage it. It took me quite a while to realize that you have to get into a train to get to the other terminal. And you have to re-checkin your luggage. That's annoying! (I did not have to do that when I left the US) Preparing and flight 28.05.2014 : I've transferred the money for the flat. All of it. 30.05.2014 : I've went to the German airport in Munich about 2 hours earlier to make sure that I don't miss my flight. We arrived at the correct terminal. First of all, I had to \"give up\" (is it called \"check-in\"?) my luggage. After that, I spend some time with my father. Then, 10 minutes before the \"Board time\" began, I went through the security checkpoint. I had to put my backpack into a plastic box, my large electronic devices into separate ones (because the metal / electronic blocks the rays) and my belt in another one. Make sure you don't have anything in your pockets. After that, you can go through a metal detector. You get checked with a hand held device after that. Next, you have to find your \"gate\". This is the place where you go onto the plane. As soon as I arrived at the correct airport I had to find my luggage. You have to know that there are signs e.g. \"Luggage A-M\". Those letters \"A-M\" refer to the airline (in my case United), not to your name! The next step was to get from airport to the house. As I arrived after 12p.m. I had to go by taxi which cost. Remember: You should give a tip of at least 10%, but rather 15%. Getting into the house was the next step to take. I was really lucky that a neighbor was on the terrace and gave me her phone to call my friend who lives in that house. First impressions 01.06.2014 : We visited a some stores and Dave and Buster's which is a video arcade. 02.06.2014 : I've got to know Jae Cho who now has the job that Faith had before. She introduced me to everybody. After that, I was sent to Jill Lentz. She is in GHC which is short for \"Gates Hillman Center\". \"Gates\" and \"Hillman\" are two buildings that are connected. Jill gave me a form from \"TheHUB\" which is a student service center. I've just ordered a sim card at ultra.me Trip to New York 11.06.2014 : 50.15 Euro for the bus tickets and 94.42 Euro for the hotel. We (Emanuel, David, Damir and me) went to New York by bus. That took quite a while, but it was quite cheap and the bus was comfortable. Not like some of the remote buses in Germany where you don't have any place for yourself. The Royal Park Hotel is very central and very cheap, but I would not recommend it. The smell was disgusting (probably from bug spray?), we had a power blackout once (eventually because 4 people wanted to charge their phones, a laptop, two tables and a camera simultaneously in one room?) and the shower was shared with other rooms. I recommend to visit the central park. It is great! The American Museum of Natural History is ok. You can see something about science and astronomy in the basement and around the Hayden Sphere, but not much. The rest is about stones, people, plants and animals in America. I don't think that mammals are very interesting, so that was pretty boring for me. It has some \"Special Exhibitions\" for which you have to pay in advance if you want to be able to see them. The \"Dark Universe\" special exhibition is probably not worth the money if you have been to a planetarium before. I have seen very similar shows in Augsburg and the movie did not contain information that was new to me. Smoky Quartz Wulfenite Hayden sphere Labradorite Muscovite crystal structure showing cleavage Rosenhof: Green frog dissection There are more images from my trip to New York City on Wikipedia Commons . Brooklyn Bridge is also interesting. You can take some nice pictures there at night: Ground Zero is also a must-see. It is very impressive. It is the biggest human build waterfall: Ground Zero And - of course - liberty island and the statue of liberty. You will also get to Ellis island and the immigrant museum. That was interesting! Money - How much does it cost? You have to pay quite a lot in advance. I'm my case, it were 3218.06 Euro: bank statement : 25 Euro SEVIS fee : 180 US-Dollar = 131.45 Euro + 1.97 Euro \"ENTGELD AUSLAND\" VISA application fee : 160.00 US-Dollar = 116.70 Euro 2 photos for J1 visa : 15.00 Euro traveling to Frankfurt for Visa application : 2.30 Euro + 6.00 Euro + 8.00 Euro = 16.30 Euro Stay one day in Frankfurt : 59.00 Euro passport : 37.50 Euro health insurance : 102.72 Euro casualty insurance : 13.44 Euro Flight tickets : 961.62 Euro luggage scale \"Soehnle 66172\" : 16.99 Euro power adapter USA2Schuko : 4.49 Euro rent for 3 months : 1715.88 Euro I arrived in the US with 2000 US-Dollar in traveler checks and 200 US-Dollar in cash. I payed 1451.68 Euro for the traveler checks and 151.63 Euro for the cash. My VISA-card expenses were 338.31 Euro. I had to transfer 144.57 Euro to friends who payed the trip to New York in advance. So an upper bound for my expenses for the trip to the US is (3218.06+1451.68+151.63+338.31+144.57) Euro = 5304.25 Euro I got \\(4 \\cdot 900 = 3600\\) Euro from interACT. So in total I had to pay 1704.25 Euro by myself. I got back with 950 US-Dollar in traveler checks and about 50 US-Dollar in cash. So I could get about 772 Euro back. In the US, I kept track of some expenses. It might give you an impression how expensive things are. Here you are: taxi from airport : 60 US-Dollar = 44.10 Euro Food 3x Stack'd: 3x 10 US-Dollar = 30 US-Dollar HofbrÃ¤uhaus: 23 US-Dollar (for apple juice and Schweineschnitzel!) Crepes: 8.03 US-Dollar (for crepes with salad and water) Pizza: 10.5 US-Dollar (for Pizza+Cola, including 1.5 US-Dollar tip) UNO Pizza: 16.67 US-Dollar The Original Hot Dog Shop: 7.27 US-Dollar New York Bus tickets: 50.15 Euro (a friend payed it) Subway: 30 US-Dollar Eating: Don Giovanni: 16.40+ 3 tip = 19.40 US-Dollar Texas Rotisserie & Grill: Gyro Sandwich: 7.61 * 2 = 15.22 US-Dollar Water: 1.36 US-Dollar Shake Shack: 5.17 US-Dollar, 3.27 US-Dollar Sight seeing: Statue Cruises (go to the statue of liberty): 18.00 US-Dollar American Museum of Natural History: 22.00 US-Dollar International Center of Photography: 10.00 US-Dollar Phantom of the Opera: 48.57 Euro miscellaneous Post stamps \"Global Forever\": 6.90 US-Dollar Spider Killer spray and water: 3.95 US-Dollar GetGo: Water, 24Pack: 3.99 US-Dollar public transportation: 20 US-Dollar in total for my complete stay in Pittsburgh Cinema (Let's be Cops, 16.08.2014): 10.25 US-Dollar CMU stuff When you come here, you can choose an AndrewID. This can be anything (letters). WLAN Linux with \"AddTrust External CA Root\" Terms 22 C.F.R. Part 62 : A law regulating J1 visa. ACH: Automated Clearing House, an electronic banking network often used for direct deposit and electronic bill payment DS-2019: a form you need to apply for J-1 visa GHC: Gates Hillman Center, a building J-1 visa : non-immigrant visa issued by the United States to exchange visitors participating in programs that promote cultural exchange, especially to obtain medical or business training within the U.S. OIE: Office of International Education SEVIS: Student and Exchange Visitor Program (a program within U.S. Immigration and Customs Enforcement which monitors students and exchange visitors in the United States with F, M, or J visas status.) USCIS: United States Citizenship and Immigration Services - a component of the United States Department of Homeland Security MRV - Machine Readable Visa Resources interact.anthropomatik.kit.edu : Official interACT website cmu.edu/oie Settling in Guide - very helpful! StackExchange: What do the numbers on my VISA card mean? What is a \"travel validation\"? How do you address people at the beginning of a conversation? Can I buy a sim card for prepaid internet for the USA in Germany? In how far is the Ampere number important for USB powered devices? http://nutmeggle.wordpress.com/2013/06/23/the-welcome-pack-and-the-visa/","tags":"My bits and bytes","title":"interACT"},{"url":"https://martin-thoma.com/one-on-one-tutoring/","text":"I have heard that the famous universities in England have One-on-One tutoring. I'm not sure if that is actually the case, but that doesn't matter for the idea I want to explain. That means one tutor helps one student only. That must be incredibly effective for learning. From my experience as a tutor and as a \"coach\" (Nachhilfelehrer) I know that there is a huge difference in One-on-One tutoring compared to One-on-Many tutoring, where one tutor teaches about 30 students. If you only have one student, you can focus on the needs of this single student. And I guess that the student will also be encouraged a bit more to participate. If you only have one student, the student will not sleep while you teach him. He has to stay focused, because you will notice when he doesn't. So One-on-One tutoring is something we want to get. The problem of One-on-One tutoring It is expensive, if it would be done like tutoring is currently done. In fact I think it would be impossible, because you would not find that many tutors. However, I think there are other ways to motivate students that have already passed the exam to be a tutor for another student. How to get One-on-One tutoring Give One-on-One tutors the possibility to write the exam again and improve their grade. I could imagine it to work like this: A student passes the exam, but he does not have the grade he wants. As he has already passed the exam, he will not be allowed to simply write it again. So he has to search a student who hasn't already passed the exam and help this student to prepare for the exam. Now we have to check if the One-on-One tutor really helped the new student. I could imagine two ways that could also be combined. One-on-One tutoring: Way 1 The One-on-One tutor has to help the new student with the exercises. So the One-on-Many tutor gets the information which exercises were done by the One-on-One tutor and the new student. In contrast to now, not only one student would exercise, but two. In order to make sure that there is an improvement, one could increase the necessary number of points for the One-on-One tutor to a threshold of \\(\\theta_1\\) . \\(\\theta_1\\) should denote how much more points the student needs (in percent of the points the students need) to get the possibility to re-do the exam. \\(\\theta_1 = 0\\) would mean that the tutor does only need a student who gets the minimum number of points to pass the exam. \\(\\theta_1 = 1\\) would mean that the tutor needs his students to get double the number of points in the exercises than what he would need to be allowed to participate in the exam. This means \\(\\theta_1 \\in [0, 1]\\) . \\(\\theta_1\\) should not be zero, because that would mean that 1-on-1 tutors could choose their students right before the exam. But I want them to choose the student at the beginning of the semester. And \\(\\theta_1\\) may not be too high. The higher it gets, the more difficult and time intensive it gets for the student and the tutor. I think the time right before an exam is the time where students learn most. If a student doesn't achieve the \\(\\theta_1\\) threshold, then the tutor will not have any incentive to help the student to prepare for the exam except for money or friendship. This is a good incentive for the student to keep working on excercises, even if he already got enough points to be allowed to write the exam. One-on-One tutoring: Way 2 The other possibility would be to enforce a minimum grade for the tutored student. So the One-on-One tutor cannot participate in the same exam as his student, but in the exam after that. And the tutor can only participate in that exam if his student got a minimum grade \\(\\theta_2\\) , e.g. 2.3 or better. \\(\\theta_2 = 5\\) would mean that the student only has to participate in the exam (at KIT every student gets at least a grade of 5. The best grade is 1.0.). \\(\\theta_2 = 1\\) would mean that the student has to pass with the best grade so that the tutor is allowed to participate in the exam. Alternatively one could make that dependent on the number of students who got the grade. So \\(\\theta_2 = 10\\%\\) would mean that you choose the grade threshold in a way that makes sure that at least 10% of all students pass that requirement. This means \\(\\theta_2 \\in [1, 5]\\) or \\(\\theta_2 \\in (0\\%, 100\\%]\\) . \\(\\theta_2\\) should not be too bad (near 5), because then it will be too easy for many students to get another try for the exam. That would also not help the students, because the tutor would not have an incentive that is strong enough to increase the abilities of his student. However, if \\(\\theta_2\\) gets too low (near 1.0) then most students will not try to be a tutor because it is too difficult to get a student to achieve that good results. How to speak about it I would like to call this model MOOT (Martins One-on-One Tutoring model â˜º ). It is parameterized with two variables, \\(\\theta_1\\) and \\(\\theta_2\\) . I think \\(MOOT(\\theta_1=0.2, \\theta_2=25\\%)\\) would be a good possibility to encourage students to help other students effectively. \\(\\theta_1\\) is low enough to make it fairly easy for somebody who already passed the exam to \"lift\" a student to pass the requirement. So I guess \\(MOOT(0.2, 25\\%)\\) would be a good choice. You could still argue that the tutor could simply write the excercises himself. But I don't think that would be a problem, because then the tutor would do the excercises. He would still practice. We only get a problem if larger groups of students copy excercises. I don't think that is the case, but I judge from the students I know. I might have a biased view on the problem. Conclusion The two ways I proposed would in general lead to better students, remove stress from students because a single bad exam would not be that bad any more and very likely lead to better students. Students would be better on the paper (because the tutor should only be able to improve himself by the new exam and also his student should be able to achieve better results in the exam) and in the real world. Students would get an incentive to repeat what they did not understand before. They would get an incentive to help other students. For free. And it would not be that much more work for the university. I think it is easier to correct exams of good students and only a few would really take this possibility as it is really time intensive for the One-on-One tutor. But for some exams and some students that might be worth the effort. What do you think about it? Do you think we could introduce that model at KIT? Who could propose it? To whom should it be proposed? Other incentives If writing the exam again is not an option, we could try to find other incentives for tutors: Getting \"exclusive\" rights: Visiting CERN or something similar Getting access to equipment of the university (executing your personal projects on KIT clusters, getting access to microscopes, being allowed to use lecture halls) \"Proud\" of the unversity: If we could make KIT students being proud of being a student at KIT the students themselves could want to support fellow students. I am not sure if there is any incentive which is strong enough to support another student for one semester. Do you have an idea? Please share it in the comments!","tags":"My bits and bytes","title":"One-on-One Tutoring"},{"url":"https://martin-thoma.com/twiddle/","text":"Twiddle is an algorithm that tries to find a good choice of parameters \\(p\\) for an algorithm \\(\\mathcal{A}\\) that returns an error. The algorithm is quite simple to implement. I guess gradient descent might be better for most cases, but Twiddle does not require any knowledge about the algorithm \\(\\mathcal{A}\\) which might be a big advantage. And you don't have to calculate the gradient of high dimensional functions, which is nice, too. The algorithm Here is some pythonic pseudo code. A is an algorithm that returns an error. # Choose an initialization parameter vector p = [ 0 , 0 , 0 ] # Define potential changes dp = [ 1 , 1 , 1 ] # Calculate the error best_err = A ( p ) threshold = 0.001 while sum ( dp ) > threshold : for i in range ( len ( p )): p [ i ] += dp [ i ] err = A ( p ) if err < best_err : # There was some improvement best_err = err dp [ i ] *= 1.1 else : # There was no improvement p [ i ] -= 2 * dp [ i ] # Go into the other direction err = A ( p ) if err < best_err : # There was an improvement best_err = err dp [ i ] *= 1.05 else # There was no improvement p [ i ] += dp [ i ] # As there was no improvement, the step size in either # direction, the step size might simply be too big. dp [ i ] *= 0.95 See also Twiddle - CS373 Unit 5 - Udacity : Explanation of Twiddle by Sebastian Thrun Numerische Optimierung in Matlab mit Twiddle-Algorithmus (German)","tags":"Machine Learning","title":"The Twiddle Algorithm"},{"url":"https://martin-thoma.com/hyperlapse/","text":"Johannes Kopf , a researcher at Microsoft, has recently published a stunning video about a software project he seems to have participated in. The video is about the automatic creation of hyperlapse videos: We present a method for converting first-person videos, for example, captured with a helmet camera during activities such as rock climbing or bicycling, into hyperlapse videos: time-lapse videos with a smoothly moving camera. So we are now only speaking about first-person videos. As videos created by a helmet camera might be very long and (as he accurately described it) \"dead boring\", you want to speed that up. A timelaps would be a subsampling to every n-th frame. Those might be very shaky and hard to watch. That means you would at least want some image stabilization. Microsoft Hyperlapse But the software they created does more. Much more. Reconstruction First, it reconstructs the geometry of the captured environment. That alone is absolutely awesome. They apply a group of techniques called structure from motion . Path planning Then they plan the path of the camera. This is a 6-dimensional problem for every point in time where you want to get an image. The 6 dimensions are: (x, y, z): Position of the camera roll: horizontal, vertical angle pitch: up, down view angle yaw: left, right view angle In case you have a problem with imagining roll, pitch and yaw you should take a look at the following image: Roll, pitch and yaw By [ZeroOne](https://commons.wikimedia.org/wiki/File:Flight_dynamics_with_text.png) The chosen path should meet several criteria: It should be smooth in space Every path position should be close to input positions The path should be short Rotation should be smooth (that is what makes videos \"shaky\") The rendering quality should be as high as possible The first 3 steps were achived by spline fitting. Rendering That step combines several output frames to render the desired camera image. Nice timelapses","tags":"Cyberculture","title":"Hyperlapse"},{"url":"https://martin-thoma.com/mouse-clicking-games/","text":"Do you know games like cookie clicker where you only have to click a lot? Cookie Clicker You can do that automatically with the following Python script. Just execute xdotool getmouselocation --shell before that to find the position of your mouse. #!/usr/bin/env python \"\"\"Tool to make automatic clicks VERY fast (useful for idle games).\"\"\" import os import time import random def main ( clicks , twiggle , x , y , delay ): for i in range ( clicks ): xrand = random . randint ( - twiggle , twiggle ) yrand = random . randint ( - twiggle , twiggle ) xpos , ypos = x + xrand , y + yrand os . system ( \"xdotool mousemove %i %i click 1\" % ( xpos , ypos )) if delay > 0 : time . sleep ( delay ) if __name__ == '__main__' : from argparse import ArgumentParser parser = ArgumentParser () # Add more options if you like parser . add_argument ( \"-c\" , \"--clicks\" , dest = \"clicks\" , help = \"number of clicks that will be done\" , default = 500 , type = int ) parser . add_argument ( \"-t\" , \"--twiggle\" , dest = \"twiggle\" , help = \"how much should the cursor move randomly\" , default = 50 , type = int ) parser . add_argument ( \"-x\" , dest = \"x\" , help = \"x coordinate where to click\" , default = 711 , type = int ) parser . add_argument ( \"-y\" , dest = \"y\" , help = \"y coordinate where to click\" , default = 467 , type = int ) parser . add_argument ( \"--delay\" , dest = \"delay\" , help = \"delay between clicks\" , default = 0.01 , type = float ) args = parser . parse_args () main ( args . clicks , args . twiggle , args . x , args . y , args . delay ) Cookie Clicker after 5 minutes with a script Have fun playing those games now!","tags":"Cyberculture","title":"Mouse clicking games"},{"url":"https://martin-thoma.com/citizen-science-projects/","text":"\"Citizen Science Projects\" are research projects that crowdsource a part of the research work. The idea behind that is quite simple: Some tasks of researchers are very simple. Everybody can do them. I think some of them are a great example of Gamification . Galaxy Zoo Galaxy Zoo is a crowdsourced astronomy project which invites people to assist in the classification of galaxies. You get some images of Galaxies and you should see some characteristics by looking at them. You get about three possible answers to every question. It looks like that: Galaxy Zoo Moon Zoo High-resolution images of the Moon's surface provided by the Lunar Reconnaissance Orbiter are used by volunteers to create detailed crater counts, mapping the variation in age of lunar rocks. Source: Wikipedia It looks like this: Moon Zoo EteRNA EteRNA is a browser based game, developed by scientists at Carnegie Mellon University and Stanford University, that engages users to solve puzzles related to the folding of RNA molecules. It looks like this: EteRNA Write Math write-math.com is my own project. The aim of the project is to get fast and accurate recognition of mathematical symbols. To do so, I needed data. Currently, the project is still under heavy development. Currently, most work I do is done offline. Hence the project might not improve until end of October (2014). It looks like this: write math The most interesting part might be the interactive preprocessing experiments . See also EteRNA Galaxy Zoo: How to take part Moon Zoo: How to take part","tags":"Cyberculture","title":"Citizen Science Projects"},{"url":"https://martin-thoma.com/gpus-supercomputers-for-your-home/","text":"A few days ago I got some of my neural net code to work with a GPU. The GPU is called \"Tesla C2075\". It is able to get 515 GFlops peak performance. It has 448 CUDA cores that work with 1.15 GHz and it has 6GB GDDR5 memory. My code needed about 10 hours to run before. After that, it only needed 10 minutes. That is 60 times faster! The library that did this miracle for me is called Theano ) Out of curiosity, I've searched for current high-end gamer graphic cards. I found nVidia Titan Z: The Titan Z has 5760 CUDA cores. It can get 4061 GFLOPS x2 and has 12 GB of memory. That technological wonder-work costs only 2802 Euro. To put that into perspective: In 2005, you would probably have been on place 68 of the TOP500 supercomputers world wide! ( source ). Isn't that crazy? See also: Titan Z Specification What are the differences between \"scientific GPUs\" and \"gaming GPUs\"?","tags":"Machine Learning","title":"GPUs - Supercomputers for your home"},{"url":"https://martin-thoma.com/mediaviewer-and-superprotect/","text":"Recently, a heated discussion started on the German Wikipedia about Superprotect. This article should give a very short summary how it came to this discussion. Timeline 25. July 2014 : Straw poll in the German Wiki began ( link ) 08. August 2014 : Straw poll in the German Wiki ended. 72.5% voted for a default deactivation of the MediaViewer 09. /10. August 2014 : The Admins DaB. , Raymond and JEissfeldt (WMF) repeatedly change MediaWiki:Common.js to activate / deactivate the MediaViewer for the German wiki 10. August 2014 : Superprotect got introduced and Erik MÃ¶ller ( User:Eloquence ) protected MediaWiki:Common.js. The MediaViewer You can try the MediaViewer to get a feeling what this is all about. You can view some images of the MediaViewer here: Article First click on image with MediaViewer First click on image without MediaViewer notes to the MediaViewer interface MediaViewer Bottom 'Tab' MediaViewer 'Use this file' There has been a survey that suggests that 60% of all users like the MediaViewer ( source ). However, there are concerns that the survey was biased ( source ). You should know that you can easily disable the MediaViewer if you have an account: Preferences â†’ Appearance â†’ Files = uncheck 'Enable Media Viewer' The question is: Should the MediaViewer be activated per default? Pro Average users want to see the image in a higher resolution. The MediaViewer looks more professional than the old view. Wrong arguments The copyright notice doesn't get in my way. It is a legal obligation to show the copyright notice. Contra The MediaViewer doesn't give new functionality: One could see high-resolution images before by simply clicking a second time on the image. The MediaViewer makes it more difficult for new users to edit file descriptions. The MediaViewer hides information like the copyright status. Charts and maps that are color-coded and change/are edited over time and have a legend/key in multiple languages simply do not work with this interface. See this example . The MediaViewer makes browsing difficult on touch-screen devices that use pinch-to-zoom. It becomes almost unusably slow on slower machines or machines on a slow connection. MediaViewer makes it more difficult to find the image in the highest resolution. Wrong arguments It's in the way of long-term wikipedia editors. This argument is wrong, because long-term wikipedia editors can simply disable it. They should know how to do it. Logged in in users don't need this feature. Again, they can disable it. Good comments The default setting for logged-in users should be the same as for unregistered users, so that new users have fewer surprises to deal with. Alternatives to default-enable MediaViewer Change from opt-out to opt-in Disabled for current users and enabled for newly registered users Superprotect The German Wikipedia community decided to disable MediaViewer per default. As the MediaViewer got rolled out, some admins in the German Wikipedia enabled / disabled it (see version history of Common.js ). This was the reason to create superprotect: Add a new protection level called \"superprotect\" Assigned to nobody by default. Requested by Erik MÃ¶ller for the purposes of protecting pages such that sysop permissions are not sufficient to edit them. Change-Id: Idfa211257dbacc7623d42393257de1525ff01e9e Source: gerrit.wikimedia.org That started another community poll in the German wiki: Wikipedia:Umfragen/Superschutz and Wikipedia:Meinungsbilder/Gruppenrecht Superschutz Now the question is: Should the new group right 'super protect' be kept? Pro Super protect is a necessary tool to temporarily prevent abuse of admin powers in heated discussions. The WMF has the legal right to do what they want on wikipedia.org. The WMF controls the technical details of the Wikipedia platform, whereas the community only controls the content. Wrong arguments The super protect right was necessary as one admin was abusing his power. If the problem is only one admin, there already is the possibility to remove the admin status of this user. The WMF has the legal right to do what they want and they need superprotect to have legal security. That is simply wrong. There is (currently) no case where an admin tried to put something illegal on Wikipedia.org and abused his admin rights to keep it there. Contra There is no need for such a tool, as the community is able to solve 'wheel wars'. In case of the abuse of powers by admins, these powers can be removed (see Review and removal of adminship ) The community wants to organize Wikipedia by themselves without intervention from the WMF. The problem for many users seems to be that the WMF is not elected, whereas admins are (see Wikipedia:Administrators#Becoming_an_administrator - there seem to be differences in the English / German Wiki). The new concept of 'super protection' was introduced too fast without a concept which was discussed within the community. The risk of misuse of power is too high as there is no mutual control. Comments I think super protect might be a good solution to temporarily freeze pages when more than two admins have a wheel war. In that case it could be implemented so that it can only freeze a page for 7 days and after those 7 days the page cannot be frozen for at least 14 days (one would have to discuss the numbers). This way, it can be a tool for de-escalation and the abuse can be limited. Also, sites that get frozen must have at least two back-and-forth edits by two admins and the community must have voted for freezing. Terms Wikipedia is the free Internet encyclopedia at wikipedia.org. MediaWiki is the software that Wikipedia uses. It is also free and it gets developed by the Wikimedia Foundation and others. You can download MediaWiki here and find the source code via https://gerrit.wikimedia.org/r/p/mediawiki/core.git . Wikimedia Foundation (short: WMF) is an American non-profit and charitable organization headquartered in San Francisco, California, that operates wikipedia.org. MediaViewer is a JavaScript that gives the possibility to browse through all images of an article by using a diashow. Wheel war is happening when two or more admins repeatedly revert their changes. Sources Wikipedia:Superschutz (German) Multimedia/Media Viewer/Survey Wikipedia:Media Viewer/June 2014 RfC Wikipedia:Meinungsbilder/Medienbetrachter","tags":"Cyberculture","title":"MediaViewer and Superprotect"},{"url":"https://martin-thoma.com/start-long-running-processes-via-ssh/","text":"Screen screen is a nice tool that can be used to detach long running processes from the current SSH session - and be able to get it again! Basic usage You start it with $ screen You detach it with Ctrl + a and then d . After you pressed this key combination, you will see [ detached ] You get it back again with: $ screen -r Named sessions You can start a named session with $ screen -S foo and get it back with $ screen -r foo nohup $ nohup command & See also 10 Screen Command Examples to Manage Linux Terminals Matt Cutts: A quick tutorial on screen Screen User's Manual","tags":"Code","title":"Start long running processes via SSH"},{"url":"https://martin-thoma.com/william-shatner/","text":"William Shatner is the actor that played James Tiberius Kirk in the science fiction television series Star Trek. You can imagine how famous he is from these Twitter answers: . @WilliamShatner Everything within normal parameters, Capt'n. Robotic probe @ESA_Rosetta arrives at comet #67P today! http://t.co/f7nuOjMVuh â€” ESA (@esa) 6. August 2014 @WilliamShatner Good day, Captain. #ISS is in standard orbit and Commander Swanson has the conn. Hope you're having a great weekend! â€” NASA (@NASA) 2. August 2014","tags":"My bits and bytes","title":"William Shatner"},{"url":"https://martin-thoma.com/logging-in-python/","text":"Python has a nice logging module. You can use it like this: Stream output #!/usr/bin/env python import logging import sys logging . basicConfig ( format = ' %(asctime)s %(levelname)s %(message)s ' , level = logging . DEBUG , stream = sys . stdout ) logging . debug ( 'This message should go to the log file' ) logging . info ( 'So should this' ) logging . warning ( 'And this, too' ) File output #!/usr/bin/env python import logging logging . basicConfig ( filename = 'logging.log' , format = ' %(asctime)s %(levelname)s %(message)s ' , level = logging . DEBUG ) logging . debug ( 'This message should go to the log file' ) logging . info ( 'So should this' ) logging . warning ( 'And this, too' ) See also Tutorial Documentation","tags":"Code","title":"Logging in Python"},{"url":"https://martin-thoma.com/configuration-files-in-python/","text":"Most interesting programs need some kind of configuration: Content Management Systems like WordPress blogs, WikiMedia and Joomla need to store the information where the database server is (the hostname) and how to login (username and password) Proprietary software might need to store if the software was registered already (the serial key) Scientific software could store the path to BLAS libraries For very simple tasks you might choose to write these configuration variables directly into the source code. But this is a bad idea when you upload the code to GitHub. I will explain some alternatives I got to know for Python. Python Configuration File The simplest way to write configuration files is to simply write a separate file that contains Python code. You might want to call it something like databaseconfig.py . Then you could add the line *config.py to your .gitignore file to avoid uploading it accidentally. A configuration file could look like this: #!/usr/bin/env python import preprocessing mysql = { 'host' : 'localhost' , 'user' : 'root' , 'passwd' : 'my secret password' , 'db' : 'write-math' } preprocessing_queue = [ preprocessing . scale_and_center , preprocessing . dot_reduction , preprocessing . connect_lines ] use_anonymous = True Within the actual code, you can use it like this: #!/usr/bin/env python import databaseconfig as cfg connect ( cfg . mysql [ 'host' ], cfg . mysql [ 'user' ], cfg . mysql [ 'password' ]) The way you include the configuration might feel very convenient at a first glance, but imagine what happens when you get more configuration variables. You definitely need to provide an example configuration file. And it is hard to resist the temptation to include code within the configuration file. JSON JSON is short for JavaScript Object Notation. It is widespread and thus has good support for many programming languages. The configuration might look like this: { \"mysql\" :{ \"host\" : \"localhost\" , \"user\" : \"root\" , \"passwd\" : \"my secret password\" , \"db\" : \"write-math\" }, \"other\" :{ \"preprocessing_queue\" :[ \"preprocessing.scale_and_center\" , \"preprocessing.dot_reduction\" , \"preprocessing.connect_lines\" ], \"use_anonymous\" : true } } You can read it like this: import json with open ( 'config.json' ) as json_data_file : data = json . load ( json_data_file ) print ( data ) which outputs { u 'mysql' : { u 'db' : u 'write-math' , u 'host' : u 'localhost' , u 'passwd' : u 'my secret password' , u 'user' : u 'root' }, u 'other' : { u 'preprocessing_queue' : [ u 'preprocessing.scale_and_center' , u 'preprocessing.dot_reduction' , u 'preprocessing.connect_lines' ], u 'use_anonymous' : True }} Writing JSON files is also easy. Just build up the dictionary and use import json with open ( 'config.json' , 'w' ) as outfile : json . dump ( data , outfile ) YAML YAML is a configuration file format. Wikipedia says: YAML (rhymes with camel) is a human-readable data serialization format that takes concepts from programming languages such as C, Perl, and Python, and ideas from XML and the data format of electronic mail (RFC 2822). YAML was first proposed by Clark Evans in 2001, who designed it together with Ingy dÃ¶t Net and Oren Ben-Kiki. It is available for several programming languages. The file itself might look like this: mysql : host : localhost user : root passwd : my secret password db : write-math other : preprocessing_queue : - preprocessing.scale_and_center - preprocessing.dot_reduction - preprocessing.connect_lines use_anonymous : yes You can read it like this: import yaml with open ( \"config.yml\" , 'r' ) as ymlfile : cfg = yaml . load ( ymlfile ) for section in cfg : print ( section ) print ( cfg [ 'mysql' ]) print ( cfg [ 'other' ]) It outputs: other mysql { 'passwd' : 'my secret password' , 'host' : 'localhost' , 'db' : 'write-math' , 'user' : 'root' } { 'preprocessing_queue' : [ 'preprocessing.scale_and_center' , 'preprocessing.dot_reduction' , 'preprocessing.connect_lines' ], 'use_anonymous' : True } There is a yaml.dump method, so you can write the configuration the same way. Just build up a dictionary. YAML is used by the Blender project. Resources Documentation INI INI files look like this: [mysql] host = localhost user = root passwd = my secret password db = write-math [other] preprocessing_queue = [\"preprocessing.scale_and_center\", \"preprocessing.dot_reduction\", \"preprocessing.connect_lines\"] use_anonymous = yes ConfigParser Basic example The file can be loaded and used like this: #!/usr/bin/env python import ConfigParser import io # Load the configuration file with open ( \"config.ini\" ) as f : sample_config = f . read () config = ConfigParser . RawConfigParser ( allow_no_value = True ) config . readfp ( io . BytesIO ( sample_config )) # List all contents print ( \"List all contents\" ) for section in config . sections (): print ( \"Section: %s \" % section ) for options in config . options ( section ): print ( \"x %s ::: %s ::: %s \" % ( options , config . get ( section , options ), str ( type ( options )))) # Print some contents print ( \" \\n Print some contents\" ) print ( config . get ( 'other' , 'use_anonymous' )) # Just get the value print ( config . getboolean ( 'other' , 'use_anonymous' )) # You know the datatype? which outputs List all contents Section : mysql x host ::: localhost ::: < type 'str' > x user ::: root ::: < type 'str' > x passwd ::: my secret password ::: < type 'str' > x db ::: write - math ::: < type 'str' > Section : other x preprocessing_queue :::[ \"preprocessing.scale_and_center\" , \"preprocessing.dot_reduction\" , \"preprocessing.connect_lines\" ]::: < type 'str' > x use_anonymous ::: yes ::: < type 'str' > Print some contents yes True As you can see, you can use a standard data format that is easy to read and write. Methods like getboolean and getint allow you to get the datatype instead of a simple string. Writing configuration import os configfile_name = \"config.ini\" # Check if there is already a configurtion file if not os . path . isfile ( configfile_name ): # Create the configuration file as it doesn't exist yet cfgfile = open ( configfile_name , 'w' ) # Add content to the file Config = ConfigParser . ConfigParser () Config . add_section ( 'mysql' ) Config . set ( 'mysql' , 'host' , 'localhost' ) Config . set ( 'mysql' , 'user' , 'root' ) Config . set ( 'mysql' , 'passwd' , 'my secret password' ) Config . set ( 'mysql' , 'db' , 'write-math' ) Config . add_section ( 'other' ) Config . set ( 'other' , 'preprocessing_queue' , [ 'preprocessing.scale_and_center' , 'preprocessing.dot_reduction' , 'preprocessing.connect_lines' ]) Config . set ( 'other' , 'use_anonymous' , True ) Config . write ( cfgfile ) cfgfile . close () results in [mysql] host = localhost user = root passwd = my secret password db = write-math [other] preprocessing_queue = ['preprocessing.scale_and_center', 'preprocessing.dot_reduction', 'preprocessing.connect_lines'] use_anonymous = True XML Seems not to be used at all for configuration files by the Python community. However, parsing / writing XML is easy and there are plenty of possibilities to do so with Python. One is BeautifulSoup: from BeautifulSoup import BeautifulSoup with open ( \"config.xml\" ) as f : content = f . read () y = BeautifulSoup ( content ) print ( y . mysql . host . contents [ 0 ]) for tag in y . other . preprocessing_queue : print ( tag ) where the config.xml might look like this: <config> <mysql> <host> localhost </host> <user> root </user> <passwd> my secret password </passwd> <db> write-math </db> </mysql> <other> <preprocessing_queue> <li> preprocessing.scale_and_center </li> <li> preprocessing.dot_reduction </li> <li> preprocessing.connect_lines </li> </preprocessing_queue> <use_anonymous value= \"true\" /> </other> </config> File Endings File Endings give the user and the system an indicator about the content of a file. Reasonable file endings for configuration files are *config.py for Python files *.yaml or *.yml if the configuration is done in YAML format *.json for configuration files written in JSON format *.cfg or *.conf to indicate that it is a configuration file *.ini for \"initialization\" are quite widespread (see Wiki ) ~/.[my_app_name]rc is a VERY common naming scheme for configuration files on Linux systems. RC is a reference to an old computer system and means \"run common\". That said, I think I prefer *.conf . I think it is a choice that users understand. But you might also consider that *.ini might get opened by standard in a text editor. For the other options, users might get asked which program they want to use. Resources JSON Online Parser What is the difference between YAML and JSON? When to prefer one over the other? Why do so many projects use XML for configuration files? YAML Lint INI file","tags":"Code","title":"Configuration files in Python"},{"url":"https://martin-thoma.com/append-python-path/","text":"Python has a PATH in which it looks for modules. You can display the current module PATH with import sys print ( sys . path ) and apped something to it with import sys sys . path . append ( \"/some/path/to/a/module\" ) However, the clean way would be to write a module and install that module.","tags":"Code","title":"Append Python PATH"},{"url":"https://martin-thoma.com/introduction-to-octave/","text":"GNU Octave is a really neat prototyping language for machine learning tasks. It is dynamically typed. Installation Octave is in the package repositories, so it can be installed by $ sudo apt-get install octave gnuplot-x11 octave-epstk and started with $ octave Configuration Create a file ~/.octaverc in your home folder. Write PS1('>>'); setenv(\"GNUTERM\",\"x11\"); in it to get a nicer prompt and make sure that plots will work. The Language Vectors and Matrices Octave has a lot of neat matrix manipulation features. You can create a matrix \\(A = \\begin{pmatrix} 1 & 2\\\\ 3 & 4\\end{pmatrix} \\) with >> A = [ 1 2 ; 3 4 ]; When you want to transpose a vector / a matrix, you simply add an apostrophe: >> A = [ 1 2 ; 3 4 ]; >> A ' ans = 1 3 2 4 You can multiply two matrices with A*B or use the dot product with A .* B . The identity matrix \\(I \\in \\mathbb{R}&#94;{n \\times n}\\) can be created with >> I = eye ( n ); You can get a part of the matrix by slicing: >> I = eye ( n ); >> I (:, 1 : 2 ); But be careful: Vectors and matrices are 1-indexed, not 0-indexed as you might expect! You can get the size of a matrix with the function size which returns a matrix: >> a = [ 1 2 3 ; 4 5 6 ]; >> size ( a ) ans = 2 3 If you simple want the \"length\" you can directly access the first element: >> size ( a )( 1 ) ans = 2 Sequences The sequence 0 1 2 3 4 5 can be created with [0:5] . The sequence 0.2 0.3 0.4 0.5 can be created with [0.2:0.1:0.5] . In general: [<start>:<step>:<end>] where <start> and <end> are included. You can also very simple apply functions to each element: >> t = [ 0.2 : 0.1 : 0.5 ]; >> sin ( t ) ans = 0.19867 0.29552 0.38942 0.47943 The output can be suppressed with ; . Plotting I have never seen a language where plotting is so easy: >> x = [ 0 : 0.01 : pi ]; >> y = sin ( x ); >> plot ( x , y ); You can add labels and a legend to it, too: >> xlabel = \"x\" ; >> ylabel = \"value\" ; >> legend ( 'sin' , 'cos' ) >> title ( \"sin and cos\" ) And finally, you can store the image: print - dpng 'my_plot.png' Control statements for for i = 1 : 10 ; printf ( \"%i: %i\\n\" , i , i &#94; 2 ) end while i = 1 ; while i < = 10 , printf ( \"%i: %i\\n\" , i , i &#94; 2 ) end ; if if 2 == 1 + 1 , printf ( \"True\\n\" ); elseif 3 == 2 + 1 , printf ( \"Else true\" ); else printf ( \"else\" ); end ; Functions Functions have to be saved in a file called [filename].m . One other special thing about functions is that you define the variable with the output at the beginning: function y = fibonacci ( n ) if n < 2 , y = 1 ; else y = fibonacci ( n - 1 ) + fibonacci ( n - 2 ); end ; You can also group values you want to give back like this: function [succ, pred] = succ_and_pred ( n ) succ = n + 1 ; pred = n - 1 ; Resources GNU Octave stackoverflow.com Documentation","tags":"Code","title":"Introduction to Octave"},{"url":"https://martin-thoma.com/fix-zypper-readline-error/","text":"In case you work on a openSUSE system and you get the following error $ zypper zypper: symbol lookup error: /usr/lib/libreadline.so.6: undefined symbol: PC you can probably \"fix\" it by setting the 64 Bit LD_LIBRARY like this: $ export LD_LIBRARY_PATH = /lib64: $LD_LIBRARY_PATH It worked for me on openSUSE 12.1 \"Asparagus\". Credits Thanks to JRSETI's Blog","tags":"Code","title":"Fix zypper readline error"},{"url":"https://martin-thoma.com/change-password-in-atis/","text":"Recently, the Heartbleed bug was discovered. It works like this: Heartbleed Explanation From xkcd One effect of that bug is that you have to change your password. From xkcd You can do that from home via SSH. Just replace s_thoma by s_[your last name] : $ ssh s_thoma@i08fs1.ira.uka.de s_thoma@i08fs1.ira.uka.de ' s password: s_thoma@i08fs1 ( ~ ) $ passwd Changing password for user s_thoma. Enter login ( AD ) password: Current Password: New password: Retype new password: AD password information changed for s_thoma passwd: all authentication tokens updated successfully. s_thoma@i08fs1 ( ~ ) $ exit logout Connection to i08fs1.ira.uka.de closed. In case you don't remember your password: Take a look at your Browser settings. You've probably entered it already for looking at your printing account and eventually your browser saved it.","tags":"My bits and bytes","title":"Change password in ATIS"},{"url":"https://martin-thoma.com/ai-in-computer-games/","text":"Artificial Intelligences (A.I.s) are computer programs that are able to adjust their behaviour according to data they see. So A.I.s are able to adjust to the data a human player generates. Game A.I.s Solved games There is a number of games which are definitely solved. That means the A.I. plays perfectly: Tic-Tac-Toe Connect Four: A Knowledge-based Approach of Connect-Four . Amsterdam, 1988. Victor Allis. Checkers: See also: Solved Game Computers win always A second category are games in which A.I.s always win against human players, but they don't have a perfect strategy. Or at least we have not proven that they have a perfect strategy: Chess Go on a 5Ã—5 board Reversi on a 4Ã—4 board Update: There are advances on the 19Ã—19 field: Paper Nature: Mastering the game of Go with deep neural networks and tree search YouTube by nature: The computer that mastered Go Google Blog: AlphaGo: using machine learning to master the ancient game of Go Unspecialized Game A.I.s The following video is an explanation and demo of software Tom Murphy VII wrote that learns how to play a Nintendo Entertainment System game and then automatically plays it. It's called \"learnfun\" (for learn function). You might want to skip to 6:13 for the demo: Research paper published in SIGBOVIK 2013: \" The first level of Super Mario Bros. is easy with lexicographic ordering a and time travel ...after that it gets a little tricky .\" There is a follow-up video with Zelda, Punch-Out, Dr. Mario, Contra, Wall Street Kid and Russian Attack: And a third episode with Super Mario, Gradius, Mega Man 2, Pro Wrestling, Color a Dinosaur, Nintendo Pinball, Cliffhanger, Arkanoid, Double Dare, Ice hockey: Super Mario A.I. Competition","tags":"Machine Learning","title":"A.I. in Computer Games"},{"url":"https://martin-thoma.com/linux-commands-for-working-from-home/","text":"This article is just a collection of commands and shortcuts I need quite often. Creating a single archive file from a complete folder $ tar -zcvf ~/ [ target file ] .tar.gz [ folder you want to copy ] Getting a file from a remote host to localhost $ scp [ username ] @ [ host ] : [ path/to/remote/file ] [ path/to/local/folder ] Shell Shortcuts Copy a selected text: Ctrl + Shift + C Paste a text from clipboard to the command line: Ctrl + Shift + V Copy a selected text from the command line and paste it: Mouse wheel click Search through the history of commands you have typed before: Ctrl + R Web stuff Watching the Apache error log $ tail -f /var/log/apache2/error.log Truncating the Apache error log $ sudo truncate -s 0 /var/log/apache2/error.log Finding php.ini $ php -i | grep \"Loaded Configuration File\" Importing data to MySQL $ mysql --host localhost -u root -p write-math < wm_raw_draw_data.sql","tags":"Code","title":"Linux Commands for Working from home"},{"url":"https://martin-thoma.com/what-are-pfiles/","text":"pfile is a binary file format that is used in ASR for storing feature vectors and their corresponding labels. This file format is sometimes also called ICSI feature file archive format. But this file format cannot be used for ASR only, but also for many other ML tasks. The file consists of a fixed length ascii header followed by zero or more variable length binary sections. Each parameter in the header has a name and a list of zero or more value strings. The programmer's interface to pfiles (see param.h and pfile.h) allows each parameter value to be interpreted as integer, float, string, arrays, distributed vector, matrix, mapping tables, etc. Some special parameter names are associated with a section in the binary part of the pfile. The value strings for these parameters give the size and offset (from the end of the header) of the binary section. A binary section can be used as a one dimensional sequence of values, or as a sequence of fixed length rows in a two dimensional matrix. Some parameters are automatically added by the pfile command. For example, pfile_header is a parameter that contains the length and version number of the header. Source: old-site.clsp.jhu.edu/ws96/ris/man/pfile.doc pfile_utils pfile_utils is a toolset to manage pfiles. It is part of the SPRACHcore software package . The project is located at code.google.com/p/pfile-utilities and seems to be in version 0.51 by now. The code is written in C++. pfile_info gives general information about the file: $ pfile_info all.pfile all.pfile 9581 sentences, 3158027 frames, 1 label ( s ) , 42 features pfile_create You can call pfile_create like this: $ ./pfile_create -i - -f 1 -l 1 -o output.pfile 0 0 1 1 0 1 2 0 0 2 1 1 0 3 1 1 0 4 42 4 1 0 0 0 1 1 1337 0 1 2 2 2 2 0 3 3 You can end the input with Ctrl + D . The numbers are: [ sentence-nr ] [ frame-nr ] [ feature 1 ] [ feature 2 ] ... [ feature n ] [ label 1 ] [ label 2 ] ... [ label n ] where the option -f defines the number of features and -l defines the number of labels. Please note that within one sentence, the number of frames has to be increasing by exactly one. One sentence can have an arbitrary number of frames, but as soon as you make another sentence, you need to increase this number by exactly one. See also ICSI Speech FAQ: 3.3 What are the feature data formats?","tags":"Code","title":"What are pfiles?"},{"url":"https://martin-thoma.com/awesome-robots/","text":"Robots are mechanical devices that are controlled by computer programs. Some of them act unexpectedly intelligent due to recent improvements in processing speed (hardware) and neural nets (computer science) as well as good application of differential equations (mathematics). Differential equations are mathematical equations with a function and its derivative. So a simple differential equation is \\(f(x) = f'(x)\\) . They are commonly used in physics, because you often have functions that have time as their argument. A simple example would be the growth of a population in biology (see Differential Equations: some simple examples from Physclips ). Cubli The Cubli is a 15 Ã— 15 Ã— 15 cm cube that can jump up and balance on its corner. Reaction wheels mounted on three faces of the cube rotate at high angular velocities and then brake suddenly, causing the Cubli to jump up. Once the Cubli has almost reached the corner stand up position, controlled motor torques are applied to make it balance on its corner. In addition to balancing, the motor torques can also be used to achieve a controlled fall such that the Cubli can be commanded to fall in any arbitrary direction. Combining these three abilities -- jumping up, balancing, and controlled falling -- the Cubli is able to 'walk'. Quadcopters by Raffaello D'Andrea In a robot lab at TEDGlobal, Raffaello D'Andrea demos his flying quadcopters: robots that think like athletes, solving physical problems with algorithms that help them learn. In a series of nifty demos, D'Andrea show drones that play catch, balance and make decisions together -- and watch out for an I-want-this-now demo of Kinect-controlled quads. Kuka Table Tennis Robot The unbelievably fast KUKA robot faces off against one of the best table tennis players of all time. Who has the best technique? Who will win the first ever table tennis duel of human versus robot? Watch this thrilling commercial of table tennis and robotics performed at the highest level. The KUKA KR AGILUS demonstrates its skills with the table tennis racket - a realistic vision of what robots can be capable of in the future. Timo Boll, the German table tennis star, is the new brand ambassador for KUKA Robotics in China. The collaboration celebrates the inherent speed, precision, and flexibility of KUKA's industrial robots in tandem with Boll's electrifying and tactical prowess in competition. To celebrate the new KUKA Robotics factory in Shanghai, the thrilling video was a highlight of the Grand Opening on March 11th, 2014. The 20,000 sq. meter space will produce the KR QUANTEC series robot as well as the KRC4 universal controller for the Asian market. As a market leader in China, KUKA aims to further develop automation in the country while providing a modern and employee-friendly working environment. More: kuka-timoboll.com Stickybot A gecko-like robot from Stanford. Cheetah A robot by Boston Dynamics that runs 45 km/h! Snakebot From the Biorobotics Lab at Carnegie Mellon University, a snake robot (Snakebot) demonstrates how it can climb a tree and look around. Please keep in mind that this robot climbed a specific tree with a specific trunk width about 1 meter off of the ground. The researchers working to design, build and program these robots still have much work to do to get these bots to climb taller trees of various sizes and to navigate over branches and wires. Kilobots A thousand-robot swarm created by Harvard researchers can self-assemble into different shapes. Learn more: A Thousand Kilobots Self-Assemble Into Complex Shapes","tags":"Cyberculture","title":"Awesome Robots"},{"url":"https://martin-thoma.com/classify-mnist-with-pybrain/","text":"The MNIST database is a huge database of handwritten digits that is commonly used for training, evaluating and comparing classifiers. It has a training set of 60,000 instances and a test set of 10,000 instances. Every instance is a 28 Ã— 28 pixel grayscale image. The MNIST format MNIST comes in 4 files ( download here ): train-images-idx3-ubyte.gz: training set images (9.45 MB, 60000 instances) train-labels-idx1-ubyte.gz: training set labels (28.2 kB, 60000 labels) t10k-images-idx3-ubyte.gz: test set images (1.57 MB, 10000 instances) t10k-labels-idx1-ubyte.gz: test set labels (4.43 kB, 10000 labels) Both label files are like this: [offset] [type] [value] [description] 0000 32 bit integer 0x00000801(2049) magic number (MSB first) 0004 32 bit integer 60000 number of items 0008 unsigned byte ?? label 0009 unsigned byte ?? label ........ xxxx unsigned byte ?? label The labels values are 0 to 9. and both image containers are like that: [offset] [type] [value] [description] 0000 32 bit integer 0x00000803(2051) magic number 0004 32 bit integer 60000 number of images 0008 32 bit integer 28 number of rows 0012 32 bit integer 28 number of columns 0016 unsigned byte ?? pixel 0017 unsigned byte ?? pixel ........ xxxx unsigned byte ?? pixel And they are, of course, compressed. Reading the dataset Python brings all necessary tools to make it easy to read the dataset: gzip : A library for reading gzipped files unpack to read the packed binary data As the training and the testing dataset is structured the same way, we can create a method thad retrives the data for both files. from struct import unpack import gzip from numpy import zeros , uint8 , float32 def get_labeled_data ( imagefile , labelfile ): \"\"\"Read input-vector (image) and target class (label, 0-9) and return it as list of tuples. \"\"\" # Open the images with gzip in read binary mode images = gzip . open ( imagefile , 'rb' ) labels = gzip . open ( labelfile , 'rb' ) # Read the binary data # We have to get big endian unsigned int. So we need '>I' # Get metadata for images images . read ( 4 ) # skip the magic_number number_of_images = images . read ( 4 ) number_of_images = unpack ( '>I' , number_of_images )[ 0 ] rows = images . read ( 4 ) rows = unpack ( '>I' , rows )[ 0 ] cols = images . read ( 4 ) cols = unpack ( '>I' , cols )[ 0 ] # Get metadata for labels labels . read ( 4 ) # skip the magic_number N = labels . read ( 4 ) N = unpack ( '>I' , N )[ 0 ] if number_of_images != N : raise Exception ( 'number of labels did not match the number of images' ) # Get the data x = zeros (( N , rows , cols ), dtype = float32 ) # Initialize numpy array y = zeros (( N , 1 ), dtype = uint8 ) # Initialize numpy array for i in range ( N ): if i % 1000 == 0 : print ( \"i: %i \" % i ) for row in range ( rows ): for col in range ( cols ): tmp_pixel = images . read ( 1 ) # Just a single byte tmp_pixel = unpack ( '>B' , tmp_pixel )[ 0 ] x [ i ][ row ][ col ] = tmp_pixel tmp_label = labels . read ( 1 ) y [ i ] = unpack ( '>B' , tmp_label )[ 0 ] return ( x , y ) Viewing data You might want to take a look at an image. This is easily possible with PyLab (which is a part of Matplotlib): from pylab import imshow , show , cm def view_image ( image , label = \"\" ): \"\"\"View a single image.\"\"\" print ( \"Label: %s \" % label ) imshow ( image , cmap = cm . gray ) show () It tooks like this: 7 2 Classify data Now we can use PyBrain to classify data. The following code will first build the PyBrain datastructure for the training set and the testing set. Then it will build a very simple neural network called a Multilayer Perceptron (MLP) with three layers: An input layer, a hidden layer and an output layer. After creating it, the MLP will be trained with the backpropagation algorithm. Every training step is followed by an evaluation step. By the way, numpy.ravel simply flattens a list. from numpy import ravel from pybrain.datasets import ClassificationDataSet from pybrain.utilities import percentError from pybrain.tools.shortcuts import buildNetwork from pybrain.supervised.trainers import BackpropTrainer from pybrain.structure.modules import SoftmaxLayer def classify ( training , testing , HIDDEN_NEURONS , MOMENTUM , WEIGHTDECAY , LEARNING_RATE , LEARNING_RATE_DECAY , EPOCHS ): trndata = ClassificationDataSet ( INPUT_FEATURES , 1 , nb_classes = CLASSES ) tstdata = ClassificationDataSet ( INPUT_FEATURES , 1 , nb_classes = CLASSES ) for i in range ( len ( testing )): tstdata . addSample ( ravel ( testing [ 'x' ][ i ]), [ testing [ 'y' ][ i ]]) for i in range ( len ( trndata )): trndata . addSample ( ravel ( trndata [ 'x' ][ i ]), [ trndata [ 'y' ][ i ]]) # This is necessary, but I don't know why # See http://stackoverflow.com/q/8154674/562769 trndata . _convertToOneOfMany () tstdata . _convertToOneOfMany () fnn = buildNetwork ( trndata . indim , HIDDEN_NEURONS , trndata . outdim , outclass = SoftmaxLayer ) trainer = BackpropTrainer ( fnn , dataset = trndata , momentum = MOMENTUM , verbose = True , weightdecay = WEIGHTDECAY , learningrate = LEARNING_RATE , lrdecay = LEARNING_RATE_DECAY ) for i in range ( EPOCHS ): trainer . trainEpochs ( 1 ) trnresult = percentError ( trainer . testOnClassData (), trndata [ 'class' ]) tstresult = percentError ( trainer . testOnClassData ( dataset = tstdata ), tstdata [ 'class' ]) print ( \"epoch: %4d \" % trainer . totalepochs , \" train error: %5.2f%% \" % trnresult , \" test error: %5.2f%% \" % tstresult ) return fnn Final steps You might want to add command line parameters , logging and probably pickle the data. Final complete code #!/usr/bin/env python \"\"\"Train NN with PyBrain.\"\"\" from struct import unpack import gzip from numpy import zeros , uint8 , float32 , ravel from pylab import imshow , show , cm from pybrain.datasets import ClassificationDataSet from pybrain.utilities import percentError from pybrain.tools.shortcuts import buildNetwork from pybrain.supervised.trainers import BackpropTrainer from pybrain.structure.modules import SoftmaxLayer from argparse import ArgumentParser import os.path import cPickle as pickle def get_labeled_data ( imagefile , labelfile , picklename ): \"\"\" Read input-vector (image) and target class (label, 0-9). Return ------ dict \"\"\" if os . path . isfile ( ' %s .pickle' % picklename ): data = pickle . load ( open ( ' %s .pickle' % picklename )) else : # Open the images with gzip in read binary mode images = gzip . open ( imagefile , 'rb' ) labels = gzip . open ( labelfile , 'rb' ) # Read the binary data # We have to get big endian unsigned int. So we need '>I' # Get metadata for images images . read ( 4 ) # skip the magic_number number_of_images = images . read ( 4 ) number_of_images = unpack ( '>I' , number_of_images )[ 0 ] rows = images . read ( 4 ) rows = unpack ( '>I' , rows )[ 0 ] cols = images . read ( 4 ) cols = unpack ( '>I' , cols )[ 0 ] # Get metadata for labels labels . read ( 4 ) # skip the magic_number N = labels . read ( 4 ) N = unpack ( '>I' , N )[ 0 ] if number_of_images != N : raise Exception ( 'The number of labels did not match ' 'the number of images.' ) # Get the data x = zeros (( N , rows , cols ), dtype = float32 ) # Initialize numpy array y = zeros (( N , 1 ), dtype = uint8 ) # Initialize numpy array for i in range ( N ): if i % 1000 == 0 : print ( \"i: %i \" % i ) for row in range ( rows ): for col in range ( cols ): tmp_pixel = images . read ( 1 ) # Just a single byte tmp_pixel = unpack ( '>B' , tmp_pixel )[ 0 ] x [ i ][ row ][ col ] = ( float ( tmp_pixel ) / 255 ) tmp_label = labels . read ( 1 ) y [ i ] = unpack ( '>B' , tmp_label )[ 0 ] data = { 'x' : x , 'y' : y , 'rows' : rows , 'cols' : cols } pickle . dump ( data , open ( \" %s .pickle\" % picklename , \"wb\" )) return data def view_image ( image , label = \"\" ): \"\"\"View a single image.\"\"\" print ( \"Label: %s \" % label ) imshow ( image , cmap = cm . gray ) show () def classify ( training , testing , HIDDEN_NEURONS , MOMENTUM , WEIGHTDECAY , LEARNING_RATE , LEARNING_RATE_DECAY , EPOCHS ): INPUT_FEATURES = testing [ 'rows' ] * testing [ 'cols' ] print ( \"Input features: %i \" % INPUT_FEATURES ) CLASSES = 10 trndata = ClassificationDataSet ( INPUT_FEATURES , 1 , nb_classes = CLASSES ) tstdata = ClassificationDataSet ( INPUT_FEATURES , 1 , nb_classes = CLASSES ) for i in range ( len ( testing [ 'x' ])): tstdata . addSample ( ravel ( testing [ 'x' ][ i ]), [ testing [ 'y' ][ i ]]) for i in range ( len ( training [ 'x' ])): trndata . addSample ( ravel ( training [ 'x' ][ i ]), [ training [ 'y' ][ i ]]) # This is necessary, but I don't know why # See http://stackoverflow.com/q/8154674/562769 trndata . _convertToOneOfMany () tstdata . _convertToOneOfMany () fnn = buildNetwork ( trndata . indim , HIDDEN_NEURONS , trndata . outdim , outclass = SoftmaxLayer ) trainer = BackpropTrainer ( fnn , dataset = trndata , momentum = MOMENTUM , verbose = True , weightdecay = WEIGHTDECAY , learningrate = LEARNING_RATE , lrdecay = LEARNING_RATE_DECAY ) print ( \"Start training\" ) for i in range ( EPOCHS ): trainer . trainEpochs ( 1 ) trnresult = percentError ( trainer . testOnClassData (), trndata [ 'class' ]) tstresult = percentError ( trainer . testOnClassData ( dataset = tstdata ), tstdata [ 'class' ]) print ( \"epoch: %4d \" % trainer . totalepochs , \" train error: %5.2f%% \" % trnresult , \" test error: %5.2f%% \" % tstresult ) return fnn if __name__ == '__main__' : parser = ArgumentParser () # Add more options if you like parser . add_argument ( \"-H\" , metavar = \"H\" , type = int , dest = \"hidden_neurons\" , default = 200 , help = \"number of neurons in the hidden layer\" ) parser . add_argument ( \"-e\" , metavar = \"EPOCHS\" , type = int , dest = \"epochs\" , default = 20 , help = \"number of epochs to learn\" ) parser . add_argument ( \"-d\" , metavar = \"W\" , type = float , dest = \"weightdecay\" , default = 0.01 , help = \"weightdecay\" ) parser . add_argument ( \"-m\" , metavar = \"M\" , type = float , dest = \"momentum\" , default = 0.1 , help = \"momentum\" ) parser . add_argument ( \"-l\" , metavar = \"ETA\" , type = float , dest = \"learning_rate\" , default = 0.01 , help = \"learning rate\" ) parser . add_argument ( \"-ld\" , metavar = \"ALPHA\" , type = float , dest = \"lrdecay\" , default = 1 , help = \"learning rate decay\" ) args = parser . parse_args () print ( \"Get testset\" ) testing = get_labeled_data ( 't10k-images-idx3-ubyte.gz' , 't10k-labels-idx1-ubyte.gz' , 'testing' ) print ( \"Got %i testing datasets.\" % len ( testing [ 'x' ])) print ( \"Get trainingset\" ) training = get_labeled_data ( 'train-images-idx3-ubyte.gz' , 'train-labels-idx1-ubyte.gz' , 'training' ) print ( \"Got %i training datasets.\" % len ( training [ 'x' ])) classify ( training , testing , args . hidden_neurons , args . momentum , args . weightdecay , args . learning_rate , args . lrdecay , args . epochs ) Results I'll update that tomorrow: python pybrainmnist.py Get testset Got 10000 testing datasets. Get trainingset Got 60000 training datasets. Input features: 784 Start training Total error: 0 .0132789873631 ( 'epoch: 1' , ' train error: 14.97%' , ' test error: 14.28%' ) Total error: 0 .0122669294279 ( 'epoch: 2' , ' train error: 11.54%' , ' test error: 11.18%' ) Total error: 0 .0121586496637 ( 'epoch: 3' , ' train error: 12.21%' , ' test error: 11.71%' ) Total error: 0 .0121439024528 ( 'epoch: 4' , ' train error: 13.91%' , ' test error: 13.01%' ) Total error: 0 .0121144144187 ( 'epoch: 5' , ' train error: 12.51%' , ' test error: 11.95%' ) Total error: 0 .0121177344402 ( 'epoch: 6' , ' train error: 12.14%' , ' test error: 11.35%' ) Total error: 0 .0121240818924 ( 'epoch: 7' , ' train error: 15.82%' , ' test error: 15.38%' ) Total error: 0 .0120871124447 ( 'epoch: 8' , ' train error: 13.00%' , ' test error: 12.32%' ) Total error: 0 .0120638692784 ( 'epoch: 9' , ' train error: 14.02%' , ' test error: 13.06%' ) Total error: 0 .0120865053396 ( 'epoch: 10' , ' train error: 13.42%' , ' test error: 12.79%' ) Total error: 0 .0120843528845 ( 'epoch: 11' , ' train error: 13.42%' , ' test error: 13.02%' ) Total error: 0 .0120598288441 ( 'epoch: 12' , ' train error: 13.08%' , ' test error: 12.33%' ) Total error: 0 .0120947755501 ( 'epoch: 13' , ' train error: 12.86%' , ' test error: 12.36%' ) Total error: 0 .0120686450925 ( 'epoch: 14' , ' train error: 13.21%' , ' test error: 12.34%' ) Total error: 0 .0120948253309 ( 'epoch: 15' , ' train error: 12.53%' , ' test error: 11.64%' ) Total error: 0 .0120471256247 ( 'epoch: 16' , ' train error: 13.71%' , ' test error: 12.88%' ) Total error: 0 .0120735887868 ( 'epoch: 17' , ' train error: 12.78%' , ' test error: 11.81%' ) Total error: 0 .0120712301982 ( 'epoch: 18' , ' train error: 13.66%' , ' test error: 13.13%' ) Total error: 0 .0120947124816 ( 'epoch: 19' , ' train error: 12.48%' , ' test error: 11.79%' ) Total error: 0 .0120736808357 ( 'epoch: 20' , ' train error: 14.52%' , ' test error: 13.95%' ) real 3745 ,91s user 7336 ,48s sys 21571 ,09s","tags":"Code","title":"Classify MNIST with PyBrain"},{"url":"https://martin-thoma.com/classification-with-pybrain/","text":"PyBrain is a Python library for machine learning. It's in version 0.31 and the last change is 2 months ago ( source ). The source code is licensed under BSD 3 Clause License . The documentation is usable, but for from perfect. Classification example The following is a slightly modified example from the documentation. It shows how PyBrain starts learning to classify 2-dimensional datapoints into 3 classes: #!/usr/bin/env python # -*- coding: utf-8 -*- # Source: http://pybrain.org/docs/tutorial/fnn.html from pybrain.datasets import ClassificationDataSet from pybrain.utilities import percentError from pybrain.tools.shortcuts import buildNetwork from pybrain.supervised.trainers import BackpropTrainer from pybrain.structure.modules import SoftmaxLayer # Only needed for data generation and graphical output from pylab import ion , ioff , figure , draw , contourf , clf , show , plot from scipy import diag , arange , meshgrid , where from numpy.random import multivariate_normal from random import normalvariate def generate_data ( n = 400 ): INPUT_FEATURES = 2 CLASSES = 3 means = [( - 1 , 0 ), ( 2 , 4 ), ( 3 , 1 )] cov = [ diag ([ 1 , 1 ]), diag ([ 0.5 , 1.2 ]), diag ([ 1.5 , 0.7 ])] alldata = ClassificationDataSet ( INPUT_FEATURES , 1 , nb_classes = CLASSES ) minX , maxX = means [ 0 ][ 0 ], means [ 0 ][ 0 ] minY , maxY = means [ 0 ][ 1 ], means [ 0 ][ 1 ] for i in range ( n ): for klass in range ( CLASSES ): features = multivariate_normal ( means [ klass ], cov [ klass ]) x , y = features minX , maxX = min ( minX , x ), max ( maxX , x ) minY , maxY = min ( minY , y ), max ( maxY , y ) alldata . addSample ( features , [ klass ]) return { 'minX' : minX , 'maxX' : maxX , 'minY' : minY , 'maxY' : maxY , 'd' : alldata } def generate_data2 ( n = 400 ): alldata = ClassificationDataSet ( 2 , 1 , nb_classes = 2 ) minX , maxX = 3 , 3 minY , maxY = 2 , 2 for i in range ( 1000 ): x = normalvariate ( 3 , 0.6 ) y = normalvariate ( 2 , 1 ) minX , maxX = min ( minX , x ), max ( maxX , x ) minY , maxY = min ( minY , y ), max ( maxY , y ) alldata . addSample (( x , y ), ( 0 ,)) for i in range ( 1000 ): x = normalvariate ( 7 , 0.5 ) y = normalvariate ( 1 , 0.1 ) alldata . addSample (( x , y ), ( 1 ,)) return { 'minX' : minX , 'maxX' : maxX , 'minY' : minY , 'maxY' : maxY , 'd' : alldata } def perceptron ( hidden_neurons = 5 , weightdecay = 0.01 , momentum = 0.1 ): INPUT_FEATURES = 2 CLASSES = 3 HIDDEN_NEURONS = hidden_neurons WEIGHTDECAY = weightdecay MOMENTUM = momentum # Generate the labeled set g = generate_data () #g = generate_data2() alldata = g [ 'd' ] minX , maxX , minY , maxY = g [ 'minX' ], g [ 'maxX' ], g [ 'minY' ], g [ 'maxY' ] # Split data into test and training dataset tstdata , trndata = alldata . splitWithProportion ( 0.25 ) trndata . _convertToOneOfMany () # This is necessary, but I don't know why tstdata . _convertToOneOfMany () # http://stackoverflow.com/q/8154674/562769 print ( \"Number of training patterns: %i \" % len ( trndata )) print ( \"Input and output dimensions: %i , %i \" % ( trndata . indim , trndata . outdim )) print ( \"Hidden neurons: %i \" % HIDDEN_NEURONS ) print ( \"First sample (input, target, class):\" ) print ( trndata [ 'input' ][ 0 ], trndata [ 'target' ][ 0 ], trndata [ 'class' ][ 0 ]) fnn = buildNetwork ( trndata . indim , HIDDEN_NEURONS , trndata . outdim , outclass = SoftmaxLayer ) trainer = BackpropTrainer ( fnn , dataset = trndata , momentum = MOMENTUM , verbose = True , weightdecay = WEIGHTDECAY ) # Visualization ticksX = arange ( minX - 1 , maxX + 1 , 0.2 ) ticksY = arange ( minY - 1 , maxY + 1 , 0.2 ) X , Y = meshgrid ( ticksX , ticksY ) # need column vectors in dataset, not arrays griddata = ClassificationDataSet ( INPUT_FEATURES , 1 , nb_classes = CLASSES ) for i in range ( X . size ): griddata . addSample ([ X . ravel ()[ i ], Y . ravel ()[ i ]], [ 0 ]) for i in range ( 20 ): trainer . trainEpochs ( 1 ) trnresult = percentError ( trainer . testOnClassData (), trndata [ 'class' ]) tstresult = percentError ( trainer . testOnClassData ( dataset = tstdata ), tstdata [ 'class' ]) print ( \"epoch: %4d \" % trainer . totalepochs , \" train error: %5.2f%% \" % trnresult , \" test error: %5.2f%% \" % tstresult ) out = fnn . activateOnDataset ( griddata ) # the highest output activation gives the class out = out . argmax ( axis = 1 ) out = out . reshape ( X . shape ) figure ( 1 ) # always print on the same canvas ioff () # interactive graphics off clf () # clear the plot for c in [ 0 , 1 , 2 ]: here , _ = where ( tstdata [ 'class' ] == c ) plot ( tstdata [ 'input' ][ here , 0 ], tstdata [ 'input' ][ here , 1 ], 'o' ) if out . max () != out . min (): # safety check against flat field contourf ( X , Y , out ) # plot the contour ion () # interactive graphics on draw () # update the plot ioff () show () if __name__ == '__main__' : from argparse import ArgumentParser , ArgumentDefaultsHelpFormatter parser = ArgumentParser ( formatter_class = ArgumentDefaultsHelpFormatter ) # Add more options if you like parser . add_argument ( \"-H\" , metavar = \"H\" , type = int , dest = \"hidden_neurons\" , default = 5 , help = \"number of neurons in the hidden layer\" ) parser . add_argument ( \"-d\" , metavar = \"W\" , type = float , dest = \"weightdecay\" , default = 0.01 , help = \"weightdecay\" ) parser . add_argument ( \"-m\" , metavar = \"M\" , type = float , dest = \"momentum\" , default = 0.1 , help = \"momentum\" ) args = parser . parse_args () perceptron ( args . hidden_neurons , args . weightdecay , args . momentum ) See it in action: Resources Official website StackExchange StackOverflow : 134 questions stats.SE reddit.com/r/MachineLearning","tags":"Machine Learning","title":"Classification with PyBrain"},{"url":"https://martin-thoma.com/reference-management-with-jabref/","text":"Keeping track of papers, articles and books or more general sources you can cite is a task you will have to tackle when you're writing your thesis. One way to store information is via BibTeX files. BibTeX is a reference management software that is used together with LaTeX. If you're new to BibTeX or references in LaTeX in general you could read the followin articles: bibtex vs. biber and biblatex vs. natbib What is the difference between bibtex and biblatex? - I keep forgetting that all the time. I've tried to create a MWE for biblatex , but as I don't really know much about BibTeX it's probably not the best resource to start with. A longer working example of BibTeX is my bachelors thesis (work is still in (slow) progress). What is JabRef? JabRef is a reference management software that uses BibTeX as its native format. It looks like this: JabRef How can I get it? JabRef 2.10 beta is part of the Debian sources. Thus it can be installed by sudo apt-get install jabref The official development page is jabref.sourceforge.net . As it is written in Java it can be installed on all (or at least most) systems where you have a JVM (thus: good news Windows / Mac users!). What's good about JabRef? You can easily add the information where the PDF is located on your system and open the PDF directly via JabRef: Adding PDF with JabRef This is especially powerfull with the search. As you can add quite a lot of information to the entries (such as the abstract and comments) and searching that is faster / easier than searching folders of PDFs, it's very convenient to use JabRef for opening your PDFs: Searching with JabRef The preview also helps you to see how it might appear in your document: JabRef preview Another nice feature is the autocompletion of authors names and titles. What could be better? It would be neat if you could automatically upload your BibTeX file and use other peoples BibTeX files to complete the information or to get informed of possible errors in your database. Additionally, a good PDF reader that is fast and allows annotations of which JabRef would be aware would be awesome. Speed is quite often an issue with Java applications in my experience. It takes about 5 seconds to open my BibTeX file of about 37 references. After starting that it's ok. Shortcuts are important for tools that get used often, too. Although JabRef has some reasonable shortcuts like Ctr + i for importing a BibTeX file and Ctr + s for saving the current BibTeX file, I miss Ctrl + f for searching the database. Importing other BibTeX files into the current BibTeX file is possible. But I would also like to \"import\" BibTeX data by copy and pasting a single dataset. Alternatives Mendeley is a closed-source alternative with a built-in PDF reader. It seems to be fast and can complete information when the title is given.","tags":"Science","title":"Reference Management with JabRef"},{"url":"https://martin-thoma.com/discussions-with-friends/","text":"I've recently had a very interesting discussion with some friends. We talked about a lot of stuff and I don't want to go into detail about the topics we've discussed, but rather some thoughts about discussions. Types of discussions There are many ways people talk to each other: Small Talk is about being together and feeling fine. We do it when we are together waiting for something or just because it feels good. It's not so much about content which show discussions about weather, fashion or sitcoms, although the amount of information you exchange varies quite a lot. Feelings and talking about feelings is difficult, but important. Although I tend to say it's like small talk, but I don't want to go into detail here. Teaching is a situation where one person knows more than another person in some topic he (or she) teaches the other. Learning is either the other side in the teaching situation or learning together. I think it is fundamentally different and deserves an own bullet point because in the teaching situation, the teacher leads the conversation. In the learning situation you don't have somebody who leads the conversation. It's a free flow of (hopefully) constructive thoughts with the aim to get a new ability as a group. Moral or Political Discussions are some sort of learning, but in contrast to learning in the sense that you get another ability or get to know some more facts, the aim is on evaluating how to weight those facts. Discussions involve a learning part, but the core is about putting things together. So it is not mainly about what could be done but what should be done and for what reasons. What's special about discussions? Discussions involve some aim. That aim might be What is the best way to explain XYZ? What does best mean in this context? What should we do in situation ABC? What is to consider for what reasons? But very much of the conversations that are labeled as \"discussions\" feel rather like small talk for the following reasons: I think to have a meaningful discussion you need to have a partner who is not of your opinion. For political discussions this means the following are NOT meaningful statements: I want everybody to be able to find a job (or shorter: Fight unemployment) I want to make less dept I want everybody to be able to live a healthy live I want to help families I want everybody to be happy All these three statements are statements that everybody could agree with. But you get reasonable statements when you tell how to do so. You can also talk about the \"order\": I want to make less dept, but when young families have to pay more than 20 Euro per year more it is not acceptable. Of course, that's still much to vague, but I think you get the point. Telling what you value might help people to intuitively decide with which person they could rather identify, but it is not enough to name reasons. Another important part of a meaningful discussion is that it should in theory be possible to change the mind of the other person. This is the reason why I've called it \"discussions with friends\". In contrast to the truth-finding \"discussions\" you have in science, you don't need to be able to say what observations could falsify your theory. But if you go into a discussion and you know that it is impossible that the other - no matter how good he makes his point - convinces you of his opinion, you're actually not having a discussion. You try to teach them. (And it's a bad type of teaching.) Techniques to take most out of discussions It is difficult to be open minded in a good discussion. You might need to end a discussion and think through it some time after you had it. Because we tend to defend a point of view when we begin to defend it, no matter how good the other makes his point. It is very difficult to honestly say: Yes, you're correct. That changes the case and probably my opinion. And you should not say so too fast. Some people are charismatic, some can speak or write very good. When you hear a new argument the first time, you might have difficulties to find a correct counter argument. But when you're with friends you should be able to say: That's the first time I've heard that. I have to think about it. or something like I've never seen it from that perspective. People like to teach and this makes them feel more comfortable discussing with you. You don't give up your opinion with statements like these, but it's simply being honest. Speaking of honesty, there is a similar DON'T: Don't say something like Yes, I agree with you, but [Whatever he just said negated] I hear this so often in political debates by amateurs who have read something about discussions. By agreeing you make it easier for your discussion partner to agree with you (he can't disagree when you agree with him, can he?), but it should be a honest way to agree. It's a very bad step to fake agreement. Group dynamics Always - and that's not only related to discussions - try to think what and how the other thinks. Sometimes when a group discusses, a single person get's isolated and has to defend his point of view alone. That's ok. But don't make it worse for him: Give him enough time to think and to talk. Only one person and argument at a time. It's difficult to switch and to concentrate on two (or even more) separate discussions. Try to support him when he has trouble with finding the correct words or the best way to express himself. It is difficult to tell when you simply have to wait and give him some time to think and when you should try to support him. Know when you're wrong Changing opinions is difficult. Especially if you have them for a long time or when you've already defended them. It's a little bit like an investment. When you've already spend 6,000 Euro for an investment and there is a tiny chance that you will get what you want but a growing chance that the investment was just a bad idea and probability suggest to change the investment and rescue what's left, most people will not do so. Somehow we quite often tend to a all-or-nothing thinking which is suboptimal in many cases. So, what can we do so to figure that out for ourselves? Sometimes it is impossible to do so while discussing, but after the discussion you can think about it: What arguments did I tell the others? How did I tell them? What were counter arguments? Are they valid? If so / not: Why? Are there arguments I've missed? Do I feel comfortable with my arguments? Why do I think they could be weak? What do I think are strong arguments? Do others also think that those arguments are strong? If you're not sure about it, you can continue it. It should not be a simple repetition of arguments, but a new discussion with a new structure of arguments. If you're still not sure after many arguments, you can make a pro / contra list. Please note: It's not important what the majority thinks. However, it might be an indicator. Some arguments might simply be wrong. But don't make this choice too easily. Some arguments might be irrelevant. I tend to think \"How does this impact my life?\". If an argument has no impact or simply assumes an unrealistic situation, it might be irrelevant. You don't have to agree at the end. A honest disagreement where both sides understand the arguments of the other side is much better than a comprise that no side really thinks is good. And I want to note that discussions might have many equally valid answers, whereas science has only one correct answer (which might be difficult to find / almost impossible to decide which thesis is correct, but there is only one).","tags":"My bits and bytes","title":"Discussions with friends"},{"url":"https://martin-thoma.com/html5-template/","text":"Once in a while I need to create simple HTML pages. This is the template I use: <!doctype html> < html lang = \"en\" > < head > < meta charset = \"utf-8\" /> < title > TODO </ title > </ head > < body > < h1 > TODO </ h1 > </ body > </ html > and as a sublime snippet: <snippet> <content> <![CDATA[ <!doctype html> <html lang=\"en\"> <head> <meta charset=\"utf-8\" /> <title>${1:Title}</title> </head> <body> <h1>${2:Header}</h1> ${3:Content} </body> </html> ]]> </content> <tabTrigger> html5 </tabTrigger> <!-- Optional: Set a scope to limit where the snippet will trigger --> <!-- <scope>source.python</scope> --> </snippet>","tags":"Code","title":"HTML5 Template"},{"url":"https://martin-thoma.com/prufungsverwaltung-am-kit/","text":"Gerade ist mir aufgefallen, dass ich nicht zur PrÃ¼fung \"Programmierparadigmen\" angemeldet bin. Dabei war ich mir relativ sicher, mich sogar am ersten Tag angemeldet zu haben, als die Anmeldung freigeschaltet wurde. Meiner Meinung nach sind wir Studenten hier in einer ungerechtfertigt schlechten Position: Sollte tatsÃ¤chlich ein Fehler passiert sein und meine Anmeldung nicht funktioniert haben bzw. die Anmeldung (wie oder warum auch immer) rÃ¼ckgÃ¤ngig gemacht worden sein, habe ich keinerlei MÃ¶glichkeit zu beweisen, dass ich angemeldet war und nicht etwa es einfach vergessen habe. Was ich in meinem konkreten Fall nicht ausschlieÃŸen will, schlieÃŸlich ist das schon zwei Monate her und ich habe mich fÃ¼r einige PrÃ¼fungen angemeldet und keine automatische BestÃ¤tigung der Anmeldung erhalten. Verbesserungsvorschlag Kurz und gut: Ich will, dass die Uni ein digitales Signaturverfahren einsetzt und die technischen MÃ¶glichkeiten nutzt, um den Studenten zu helfen ihre Rechte durchzusetzen. Wie das genau funktionieren soll, wird im Folgenden erklÃ¤rt. AusfÃ¼hrlich Zur Verbesserung dieser Situation schlage ich folgendes vor: Studenten sollen die MÃ¶glichkeit bekommen, einen Ã¶ffentlichen SchlÃ¼ssel hochzuladen: Einen SchlÃ¼ssel hinzufÃ¼gen Einen SchlÃ¼ssel hinzufÃ¼gen Mit diesem signieren sie PrÃ¼fungsanmeldungen: PrÃ¼fungsanmeldung signieren Bei jeder PrÃ¼fungsanmeldung soll innerhalb von 24h eine E-Mail in Textform (keine PDF) an u****@student.kit.edu, also die KIT E-Mail-Adresse des Studenten, geschickt werden, der sich angemeldet hat. Diese E-Mail soll folgendes beinhalten: Alle PrÃ¼fungen (mit Name, Termin der PrÃ¼fung, letzter An- und Abmeldetermin), zu den der Student angemeldet ist. Der volle Name und die Matrikelnummer des Studenten. Das Datum der E-Mail. Diese E-Mail soll mit einem offiziellen KIT SchlÃ¼ssel signiert werden. Dies kÃ¶nnte z.B. mit PGP gemacht werden und wÃ¼rde dann etwa so aussehen: -----BEGIN PGP SIGNED MESSAGE----- Hash: SHA1 Student: Martin Thoma (Matrikelnummer: 1612345) Zeitpunkt: 08.04.2014, 12:34:56 Uhr Angemeldete PrÃ¼fungen: Programmierparadigmen (PrÃ¼fungstermin: 10.04.2014; letzter Termin der Anmeldung: 31.03.2014; letzer Termin der Abmeldung: 08.04.2014) Kognitive Systeme (PrÃ¼fungstermin: 11.04.2014; letzter Termin der Anmeldung: 15.03.2014; letzer Termin der Abmeldung: 10.04.2014) -----BEGIN PGP SIGNATURE----- Version: GnuPG v1.4.14 (GNU/Linux) iEYEARECAAYFAlNDzBoACgkQO3Q6GUuCW82z+ACfamkVC/S8HIpASH8F0ZGVbVW1 rgwAn2cRvNeDN3pZVTpvNWV1vYK9f1fI =3DvZU7 -----END PGP SIGNATURE----- Der Student sollte jederzeit die MÃ¶glichkeit haben, eine wie oben beschriebene signierte E-Mail mit der Liste der PrÃ¼fungen und einem Datum zu erhalten. Nun sollen Studenten in der Klausur die MÃ¶glichkeit haben, diese E-Mail auf einem USB-Stick mitzubringen. Die Aufsicht mÃ¼sste also einen Computer haben, mit dem sie die E-Mail anschauen und insbesondere die Signatur Ã¼berprÃ¼fen kÃ¶nnen. So kÃ¶nnte ein Student, der einmal zu einer Klausur angemeldet das auch belegen. Abmeldungen Die auf den ersten Blick sehr schÃ¶ne LÃ¶sung hat einen wichtigen SchÃ¶nheitsfehler: Studenten kÃ¶nnen sich von PrÃ¼fungen abmelden. Daher ist es mÃ¶glich, dass ein Student eine signierte E-Mail hat, die ihm die Anmeldung zur PrÃ¼fung bestÃ¤tigt, er aber dennoch nicht zur PrÃ¼fung angemeldet ist, da er sich abgemeldet hat. Deshalb wÃ¤re es nÃ¶tig, dass jeder Student ein eigenes SchlÃ¼sselpaar aus einem Ã¶ffentlichen und einem privaten SchlÃ¼ssel erstellt. Wenn sich ein Student von der PrÃ¼fung abmeldet, bekommt er einen Text, z. B. etwas in dieser Richtung: Ich, Martin Thoma (Matrikelnummer: 1612345), melde mich hiermit am 08.04.2014 um 12:34:56 Uhr von der PrÃ¼fung \"Programmierparadigmen\" (PrÃ¼fungsdatum: 10.04.2014) ab. Diese muss er mit seinem privaten SchlÃ¼ssel signieren. Die Uni muss daher den Ã¶ffentlichen SchlÃ¼ssel des Studenten kennen und diesem zugeordnet haben. Sobald die Abmeldung eingegangen ist, wird innerhalb von 24h eine BestÃ¤tigung an den Studenten verschickt, die von der oben beschriebenen Form ist. oder auch eine Fehlermitteilung: Sehr geehrter Herr Thoma, die Signatur ihrer Nachricht war ungÃ¼ltig. Bitte Ã¼berprÃ¼fen Sie, ob Sie den korrekten privaten SchlÃ¼ssel verwendet haben. Nun hÃ¤tte auch die Klausuraufsicht die MÃ¶glichkeit zu belegen, dass ein Student sich von der PrÃ¼fung abgemeldet hat. Technik-AfinitÃ¤t Was ist mit Studenten, die es nicht schaffen ein SchlÃ¼sselpaar zu erzeugen bzw. eine Nachricht zu signieren? Nun, das ist einfach: Wer keinen Ã¶ffentlichen SchlÃ¼ssel hinterlegt, bekommt auch keine signierten Nachrichten. Dennoch sollten diese Studenten die E-Mails, wie sie oben beschrieben wurden, bekommen. Dann weiÃŸ man als Student, dass vermutlich alles mit der Anmeldung geklappt hat bzw. wenn die E-Mail nicht kommt, dass etwas nicht geklappt hat. Bevor also die erste signierte E-Mail der Uni an den Studenten geschrieben wird, muss der Student seinen Ã¶ffentlichen SchlÃ¼ssel der Uni mitgeteilt haben und eine Nachricht mit dem privaten SchlÃ¼ssel signiert haben. Damit wird sichergestellt, dass der Student prinzipiell in der Lage ist sich von PrÃ¼fungen abzumelden. Student verliert SchlÃ¼ssel Was macht man, wenn ein Student einmal einen SchlÃ¼ssel eingericht hat, diesen aber verliert? Was passiert, wenn man seinen Studentenausweis verliert? Ich denke die Vorgehensweise wÃ¤re dann Ã¤hnlich. Vorstellbar wÃ¤re etwas in der Art: Der Student muss zum StudienbÃ¼ro und Schriftlich bestÃ¤tigen, dass der Ã¶ffentliche SchlÃ¼ssel aus dem KIT-System entfernt wird und damit ungÃ¼ltig wird. Der Student muss sich bei allen Professoren persÃ¶nlich melden und unterschreiben, wenn er sich von der Klausur abmelden will. PGP - Was ist das? Siehe Wikpedia . Es ist fÃ¼r folgende Systeme verfÃ¼gbar: Linux, siehe z.B. Ubuntu mit GnuPG Windows, siehe z.B. GPG4Win Mac, siehe z.B. Mac GNU Privacy Guard Eine weitere ErklÃ¤rung ist im Piratenwiki . EinfÃ¼gen ins System Die Website wechall.net bietet die MÃ¶glichkeit, einen PGP-SchlÃ¼ssel hochzuladen. Sobald man das gemacht hat, werden dort alle Nachrichten mit dem Ã¶ffentlichen SchlÃ¼ssel verschlÃ¼sselt. Der Quellcode der Seite ist hier verfÃ¼gbar. Mit PHP scheint das ganze sehr einfach zu sein ( Quelle ). Auch mit Python sieht die Sache sehr leicht aus ( Quelle ). Da ich keine Ahnung habe was fÃ¼r campus.kit.edu verwendet wird, kann ich hier leider nicht mehr dazu sagen. Dann wÃ¼rde man noch eine Tabelle in der Datenbank benÃ¶tigen. Die wÃ¼rde etwa so aussehen: CREATE TABLE IF NOT EXISTS \"openpgp_keys\" ( \"id\" int ( 11 ) NOT NULL AUTO_INCREMENT , \"student_id\" int ( 11 ) NOT NULL , \"public_pgp_key\" text NOT NULL , \"upload_date\" datetime NOT NULL , \"confirmation_date\" datetime DEFAULT NULL , \"is_activated\" tinyint ( 1 ) NOT NULL DEFAULT '0' , PRIMARY KEY ( \"id\" ) ) AUTO_INCREMENT = 1 ; oder graphisch: openpgp_keys Tabelle Ressourcen Sollte jemand den Vorschlag modifizieren wollen, hier ist das HTML dazu: < div class = \"content_full_portal\" > < h1 > PGP/GPG </ h1 > < h2 > Neuen SchlÃ¼ssel hinzufÃ¼gen </ h2 > < div style = \"width: 100%;\" > < div class = \"gwf3_formY\" > < form action = \"/account\" method = \"post\" enctype = \"multipart/form-data\" > < table > < tbody > < tr >< td > Ã–ffentlichen SchlÃ¼ssel als Datei hochladen </ td >< td > </ td >< td >< input type = \"file\" name = \"gpg_file\" ></ td ></ tr > < tr >< td colspan = \"3\" > oder hier einfÃ¼gen </ td ></ tr > < tr >< td colspan = \"3\" >< textarea id = \"gpg_paste\" name = \"gpg_paste\" cols = \"80\" rows = \"8\" ></ textarea ></ td ></ tr > < tr >< td ></ td >< td ></ td >< td >< input type = \"submit\" name = \"setup_gpg\" value = \"SchlÃ¼ssel hochladen\" ></ td ></ tr > < tr >< td colspan = \"3\" >< input type = \"hidden\" name = \"gwf3_csrf\" value = \"gp1yqWh4\" ></ td ></ tr > </ tbody > </ table > </ form > </ div > </ div > < h2 > Liste bekannter SchlÃ¼ssel </ h2 > < table style = \"width:100%\" > < tbody >< tr > < th > Name des SchlÃ¼ssels </ th > < th > Datum des Uploads </ th > < th > BestÃ¤tigt </ th > < th > Aktiviert </ th > </ tr > < tr > < td > sdfasdf asdfasd asdf </ td > < td > 12.10.2013, 14:45 Uhr </ td > < td > am 12.10.2014, 16:00 Uhr </ td > < td > Ja ( < a href = \"\" > Deaktivieren </ a > ) </ td > </ tr > < tr > < td > asdfasdf asdf asdfa sdf &nbsp; </ td > < td > 02.04.2014, 06:01 Uhr </ td > < td >< a href = \"\" > noch nicht </ a ></ td > < td > Nein ( < a href = \"\" > Aktivieren </ a > ) </ td > </ tr > </ tbody ></ table > </ div > und < div class = \"content_full_portal\" > < h1 > PrÃ¼fungsanmeldung </ h1 > Signieren Sie folgende Nachricht mit ihrem SchlÃ¼ssel: < br > < a href = \"\" > Nachricht als Textdatei herunterladen </ a >< br > oder < br > Nachricht zum kopieren: < br > < textarea style = \"width: 800px;height: 60px;\" > Hiermit melde ich, Martin Thoma (Matrikelnummer: 1612345), mich heute (28.03.2014, 12:34:56 Uhr) zur PrÃ¼fung 'Programmierparadigmen', die am 10.04.2014 statt findet, an. Mir ist bekannt, dass der letzte Zeitpunkt der Abmeldung am 08.04.2014 ist. </ textarea > < h2 > Anmeldung durchfÃ¼hren </ h2 > < form > < label for = \"filet\" > Signierte BestÃ¤tigung als Textdatei hochladen: </ label >< br > < input type = \"file\" id = \"filet\" >< br > < p > oder signierte BestÃ¤tigung direkt einfÃ¼gen: < br ></ p > < label for = \"textareat\" ></ label > < textarea id = \"textareat\" style = \"width: 800px;height: 60px;\" ></ textarea >< br > < input type = \"submit\" > </ form > </ div > Weitere Probleme der PrÃ¼fungsorganisation In diesem Artikel will ich nur die PrÃ¼fungsverwaltung diskutieren. Dennoch sollte darauf hingewiesen werden, dass Weiteres nicht gerade optimal gelÃ¶st ist: Informationspolitik : Bereits zu Semesterbegin sollte folgendes bekannt sein: Zeitpunkt der PrÃ¼fung LetztmÃ¶glicher Zeitpunkt der Anmeldung LetztmÃ¶glicher Zeitpunkt der Abmeldung Die Anmeldungsfreischaltung der PrÃ¼fungen finden zu sehr unterschiedlichen Zeitpunkten statt. Die Anmeldung sollte breits zu Semesterbegin fÃ¼r alle Klausuren mÃ¶glich sein. Die Einsicht ist immer schlecht organisiert. Da sich die PrÃ¼fungstermine grÃ¶ÃŸtenteils in der vorlesungsfreien Zeit befinden und darin aber stark gestreut sind (manche sind zu Beginn, manche in der Mitte, manche am Ende) sind die Zeitpunkte, zu denen man als Student Ferien hat sehr stark eingeschrÃ¤nkt. Wenn man dann erst nach der Klausur erfÃ¤hrt, wann die Einsicht sein wird, kann man Ferien komplett vergessen, weil man in Karlsruhe bleiben muss um auf den Termin der Einsicht zu warten. Bei den Physikern ist wenigstens die Korrektur immer sehr schnell, sodass man davon ausgehen kann, dass die Einsicht wenige Tage nach der PrÃ¼fung statt findet. Bei den Informatikern ... naja, da hat man ja noch GlÃ¼ck wenn sie im selben Monat ist. Und man es dann rechtzeitig erfÃ¤hrt. LÃ¶sungen und Notengrenzen sind nicht in jeder einsicht vorhanden bzw. klar. Gerade wenn nicht klar ist, mit welcher Punktzahl man welche Note bekommt kÃ¶nnte ein Fehler passieren, den man nicht Ã¼berprÃ¼fen kann. Nach diesen Informationen sollte man nicht in der Einsicht fragen mÃ¼ssen. Sie sollten in der Einsicht direkt verfÃ¼gbar sein. Schlusswort Welche Vorteile hat das beschriebene Verfahren gegenÃ¼ber der momentanen Situation? Studenten kÃ¶nnen beweisen, dass sie zur PrÃ¼fung angemeldet sind / nicht sind PrÃ¼fer kÃ¶nnen beweise, dass Studenten angemeldet sind / nicht sind Selbst wenn man den Teil mit der asymmetrischen VerschlÃ¼sselung nicht macht, hÃ¤tte man als Student zumindest ein bisschen was in der Hand und einen Mechanismus, der automatisch Feedback gibt, ob alles geklappt hat. Im Gegensatz zu der momentanen Situation, wo wir absolut nichts belegen kÃ¶nnen und man sehr leicht Ã¼bersehen kann, wenn etwas bei der Anmeldung schief gegangen ist. Was haltet ihr davon? Hattet ihr auch schon solche Probleme mit der PrÃ¼fungsanmeldung?","tags":"German posts","title":"PrÃ¼fungsverwaltung am KIT"},{"url":"https://martin-thoma.com/prolog/","text":"Prolog is a logic programming language. Any prolog program consists of declaration of facts (also called objects) rules about objects and their relationship asking \"questions\" about objects and their relationship First steps At first you have to install swi-prolog . After installing it, you can call it with swipl . When you've started swipl you can import your myscript.pl files by consult(myscript). . Don't forget the point at the end. It is important and somehow like the ; in C. Defining facts The definition of facts can look like this: loves ( john , X ). Note that names of all relationships and all objects have to begin with a lower case letter. Variables begin with a capital letter. The relationship is written first ( john ). The objects are separated by , and everything is finished with . . The example from above means: john loves everything. You can have any number of arguments. The ordering of arguments is important ( loves(john,X) is not the same as loves(X,john) ). Symbols Boolean Prolog and , or ; if :- not not An underscore _ is an anonymous variable. Rules Rules consist of a head and a body. They are separated by :- . Questions ? own ( mary , book ) This will invoke the prolog unifier. So Prolog will check if the fact own(mary,book) can be derived from the known facts. Important is that it starts with ? . Everything else in questions is just like it was for facts. Fox, goose and bag of beans puzzle This puzzle helped me a lot to understand how Prolog works. It goes as follows: Once upon a time a farmer went to market and purchased a fox, a goose, and a bag of beans. On his way home, the farmer came to the bank of a river and rented a boat. But in crossing the river by boat, the farmer could carry only himself and a single one of his purchases - the fox, the goose, or the bag of the beans. If left together, the fox would eat the goose, or the goose would eat the beans. The farmer's challenge was to carry himself and his purchases to the far bank of the river, leaving each purchase intact. How did he do it? Source: Wikpedia Let's call the side of the river where the farmer currently is 'left' and the other side 'right' to make things easier. When you solve this by hand, you should note the following: The only two things that the farmer can leave alone is the fox and the bag of beans. As the farmer is always in the boat when anything else is in the boat, you can ignore that step. Just think of the farmer and possibly one other thing teleporting from one side to the other. You only have to look at what's left and what's right. If nothing gets eaten on the left side and nothing gets eaten on the right side, you've got a valid situation. Whenever a situation occurs twice, you did some redundant steps. In other words: At least one solution exists, where no repetitions take place. The shortest solution is one of them. To solve this task, you split the problem into parts: Define a rule valid that takes a 4-tuple, where the first element is the position of the man, the second of the goose, then the fox and then the beans. Positions can either be left or right . Define a rule step(S1, Description, S2) that makes one step from situation S1 to situation S2 where Description contains the information what was brought to the other side. The situations are, as above, 4-tuples. Define a rule reachable(S1, SituationList, Steps, S2) that is true if S2 can be reached by any number of steps from S1 . The list of steps done to get from S1 to S2 is stored in Steps . The SituationList is used to prevent doing unnecessary redundant steps. So lets get through this. There are essentially three situations that can occur: The man is on the same side as the goose, the man is on the same side as the beans or the man is on the same side as the fox. If the man is on the same side as the goose, everything is fine. Nobody gets eaten / eats when the man is there. If the man is where the beans are, then the goose should not be where the fox is. The case that the goose is where the man is was done before. And the last case, the man is where the fox is. Now we have to make sure that the beans are not where the goose is: p ( left ). p ( right ). valid (( Man , Goose , Fox , Beans )) :- p ( Man ), p ( Goose ), p ( Fox ), p ( Beans ), Man == Goose . valid (( Man , Goose , Fox , Beans )) :- p ( Man ), p ( Goose ), p ( Fox ), p ( Beans ), Man == Beans , Goose \\= Fox . valid (( Man , Goose , Fox , Beans )) :- p ( Man ), p ( Goose ), p ( Fox ), p ( Beans ), Man == Fox , Goose \\= Beans . The step is also quite simple. There are four possible actions you could take at each situation: Only the man goes to the other side, the man and the beans / goose / fox go the the other side. So here is the code: step (( Man1 , Goose , Fox , Beans ), 'Man' , ( Man2 , Goose , Fox , Beans )) :- Man1 \\= Man2 . step (( Man1 , Goose1 , Fox , Beans ), 'Goose' , ( Man2 , Goose2 , Fox , Beans )) :- Man1 \\= Man2 , Goose1 \\= Goose2 . step (( Man1 , Goose , Fox1 , Beans ), 'Fox' , ( Man2 , Goose , Fox2 , Beans )) :- Man1 \\= Man2 , Fox1 \\= Fox2 . step (( Man1 , Goose , Fox , Beans1 ), 'Beans' , ( Man2 , Goose , Fox , Beans2 )) :- Man1 \\= Man2 , Beans1 \\= Beans2 . And finally the reachable part. Either, you're already at the situation where you want to get to. So you don't have to do any step and it doesn't matter which situations you have seen so far. Or you want to get from S to G . That is only possible, when you can get from S to an intermediate situation with one step less: reachable ( S , _ , [], S ). reachable ( S , Visited , [ Step | Steps ], G ) :- step ( S , Step , Tmp ), valid ( Tmp ), not ( member ( Tmp , Visited )), reachable ( Tmp , [ Tmp | Visited ], Steps , G ). Putting it together: p ( left ). p ( right ). valid (( Man , Goose , Fox , Beans )) :- p ( Man ), p ( Goose ), p ( Fox ), p ( Beans ), Man == Goose . valid (( Man , Goose , Fox , Beans )) :- p ( Man ), p ( Goose ), p ( Fox ), p ( Beans ), Man == Beans , Goose \\= Fox . valid (( Man , Goose , Fox , Beans )) :- p ( Man ), p ( Goose ), p ( Fox ), p ( Beans ), Man == Fox , Goose \\= Beans . step (( Man1 , Goose , Fox , Beans ), 'Man' , ( Man2 , Goose , Fox , Beans )) :- valid (( Man2 , Goose , Fox , Beans )), Man1 \\= Man2 . step (( Man1 , Goose1 , Fox , Beans ), 'Goose' , ( Man2 , Goose2 , Fox , Beans )) :- valid (( Man2 , Goose2 , Fox , Beans )), Man1 \\= Man2 , Goose1 \\= Goose2 . step (( Man1 , Goose , Fox1 , Beans ), 'Fox' , ( Man2 , Goose , Fox2 , Beans )) :- valid (( Man2 , Goose , Fox2 , Beans )), Man1 \\= Man2 , Fox1 \\= Fox2 . step (( Man1 , Goose , Fox , Beans1 ), 'Beans' , ( Man2 , Goose , Fox , Beans2 )) :- valid (( Man2 , Goose , Fox , Beans2 )), Man1 \\= Man2 , Beans1 \\= Beans2 . reachable ( S , _ ,[], S ). reachable ( S , Visited , [ Step | Steps ], G ) :- step ( S , Step , Tmp ), not ( member ( Tmp , Visited )), reachable ( Tmp , [ Tmp | Visited ], Steps , G ). start (( left , left , left , left )). goal (( right , right , right , right )). solve ( Steps ) :- start ( S ), goal ( G ), reachable ( S , [], Steps , G ). You can load this with swipl -s puzzle.pl and get all solutions with bagof(X, solve(T), L) . When you press ; after the first solution, you get the second solution. (Yes, this riddle has only two solutions that avoid redundant steps.) Material Introduction to PROLOG : One hour of introduction to prolog by Shashi Bhushan. Much of what I have written here is based on this video. SWI Prolog : A great resource for looking things up. Facts, Rules and Queries Simple Prolog example","tags":"Code","title":"Prolog"},{"url":"https://martin-thoma.com/tcl/","text":"TCL is an imperative, interpreted, dynamically typed programming language. The T ool C ommand L anguage appeared in 1988. In Tcl, everything is a string. It is probably best (and completely?) described by the 12 Rules for Tcl . Basic Syntax by Example Some nice comparisons of the syntax of many languages can be found at rigaux.org Hello World set myVariable \"Hallo World!\" puts $myVariable Loop over a list % foreach element { 1 2 3 } { puts $element } Fibonacci proc fib { n } { if { $n < 2 } { return $n } else { return [expr {[ fib [expr { $n-2 }]] + [ fib [expr { $n-1 }]]}] } } for {set x 0 } { $x < 10 } { incr x } { puts [ fib $x ] } Comments TCL uses # as a line comment and does not offer block comments. In fact, they recommend this: if 0 { Any Tcl code to be commented out ( with matching braces , of course ! ) or any other kind of text , will be ignored - and even [ exit ] won ' t fire because it ' s in braces , so left unevaluated ! } Source: wiki.tcl.tk/1669 Logical operators AND OR TRUE FALSE && || 1 0 EQUAL UNEQUAL NOT == != ! 99 bottles of beer #!/usr/bin/tclsh # 99.tcl; Tcl version of 99 Bottles of Beer Song proc findBString { count } { return [switch - exact -- $count { 0 { expr { \"No more bottles\" } } 1 { expr { \"1 bottle\" } } default { expr { \"$count bottles\" } } }] } set bottles 99 set bString [ findBString $bottles ] while { $bottles + 1 } { puts \"$bString of beer on the wall. $bString of beer.\" incr bottles - 1 if { $bottles + 1 } { set bString [ findBString $bottles ] puts \"Take one down, pass it round, $bString of beer on the wall.\\n\" } else { puts \"Go to the store and buy some more...99 bottles of beer.\" } } Source: 99-bottles-of-beer.net Argument parsing See itfParseArgv Naming schemes Variables have to fit to the pattern [_a-zA-Z][_a-zA-Z0-9]* . Functions have to fit to the pattern [&#94; \\t\\n\\r\\f]+ . Variables and function are scrunched together by camelCase or CamelCase. Community I think one indicator for the quality of the community is it's size. And the community will grow, when the language gets more popular. According to Ohloh , TCL is quite unpopular: Monthly Commits Monthly Contributors Monthly Lines of Code Monthly Projects You can also take a look at Google Trends : Google Trends The TIOBE Index ranked Tcl on place 43 in March 2014. lang-index ranked Tcl on place 84 in the general category and on place 34 in the script category. There are 2,490 Tcl questions on StackOverflow. Compare that to 286,244 questions about Python or 609,648 questions about Java. Tcl is on rank 18 for GitHub ( source ). Execution Speed Speed comparisons of programming languages are difficult. One nice way to compare the execution speed of programming languages is the benchmarksgame . But sadly, they don't have TCL. Additional information Official website Wikipedia","tags":"Code","title":"TCL"},{"url":"https://martin-thoma.com/panasonic-lumix-tz41/","text":"Panasonic Lumix TZ41 The Panasonic Lumix TZ41 is currently the best camera in the compact segment. The TZ41 offers an excellent 20Ã— zoom that is usable due to optical image stabilization. It is compact, leightweight and has a reasonably-sized battery. Technical specification Name Panasonic Lumix TZ41 Model Panasonic DMC-TZ41EG-K Price 259.03 Euro Dimensions 108.3 Ã— 58.9 Ã— 27.7 mm Weight 198g Zoom 20Ã— optical image stabilization âœ” Battery Power 1250mAh GPS Sensor âœ” Sensor 1/2.3\" MOS Sensor with 18.9 Megapixel Video 1920 x 1080 full HD video Wi-Fi âœ” NFC âœ” LCD Monitor âœ” Internal Storage 12 MB This camera is the same as the ' TZ40 ' which has an official data sheet and digitalkamera.de . Model name Panasonic Meaning Alternatives Lumix Compact cameras DMC Digital Media Camera TZ Traveler Zoom SZ, TS, GM, LX 41 40 seems to be the same as 41; 60, ... EG European Union model K Black colored W = White, R = Red, S = Silver Critic Charger Panasonic doesn't use the standard european charger / cable combination that is used for smartphones. Loading works via microUSB, but not via standard charger. Panasonic does not use standard microUSB2USB cables for charging / data exchange Software The software is not available for Linux. Linux moose@pc08$ cat /etc/issue Linux Mint 16 Petra moose@pc08$ uname -a Linux pc08 3 .11.0-12-generic #19-Ubuntu SMP Wed Oct 9 16:20:46 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux and the camera as a USB device: moose@pc08$ lsusb Bus 001 Device 006 : ID 04da:2372 Panasonic ( Matsushita ) Lumix Camera ( Storage mode ) GPS Assist Tool The GPS Assist Tool seems to update the camera internal GPS information. It works like this: Connect camera with SD card in it to the computer. Start gpsasist.exe with wine. gpsasist.exe gps-assist-tool update completed Settings LUMIX Map Tool The LUMIX Map Tool should allow you to copy maps with information about the environment on your camera. It looks like this: The drive detection for the SD card doesn't work on Linux as you can see in the second image. So I've have written a Linux version of that program which can be found on GitHub . Example photographs To compare the quality of the Panasonic Lumix DMC-TZ41 I have shot some photographs with my old Casio Lumix Exilim EX-Z200. Macro photographs Casio TZ41 TZ41 Normal range photographs Casio TZ41 Casio TZ41 Casio TZ41 Casio TZ41 Long-range photographs Casio TZ41 Casio TZ41 Casio TZ41 Conclusion Overall, the Panasonic Lumix TZ41 is a great camera. But the lack of a standard charger and a standard cable as well as the missing Linux software is a downer. This is the reason why I give it 4 / 5 stars. More Information Good German resources are: Chip.de : A review with some comparisons to other cameras. Panasonic Lumix DMC-TZ41 - Mein Fazit : A very detailed video review.","tags":"Cyberculture","title":"Panasonic Lumix DMC-TZ41"},{"url":"https://martin-thoma.com/project-glooseberry/","text":"Blender is an open source software that allows you to create animations. The Blender Foundation is a non-profit organization that helps to develop blender. To improve Blender, they have created movies. In that process, developers and movie makers sat in one room. So when the movie makers had a problem or discovered a bug, the developers could see and eventually fix that. By now, they have create four short movies. These movies are DRM-free, free to use and ... well, you can basically do what you want with them: Project Glooseberry is an attempt to create a full length movie. Here is a first trailer: But creating movies is quite cost intensive. A lot of people are involved and a lot of processing power is needed to create those animations. So the Blender Foundation has started a Crowdfunding Campaign . You can pledge what you want. I've pledged 5 Euros. When you pay via PayPal and they don't manage to get the 500 000 Euro they aim for, you get your money back. The campaign ends on April 19th 2014. Current campaign status You can see the current campaign status here . By now (25th of March, 13:37) there are 809 people that supported this campaign and 65,780 Euro were pledged. Let me know in comments when you supported the campaing: support now .","tags":"Cyberculture","title":"Project Glooseberry"},{"url":"https://martin-thoma.com/how-to-use-sublime-text-via-ssh/","text":"Sublime Text is the best editor I have ever used. One argument for vim and against SSH could be that you can't simply use Sublime Text when you're accessing a computer via SSH. But there is a way! In the following, I will expain the simplest way how to remote edit files with Sublime Text. Preparation on your computer Install and start Sublime Text. Install the rsub package via Package Controll. Open ~/.ssh/config . Create it if id does not exist yet. Add the code from below. Start SSH with ssh myname . This is how the config file should look like: Host myname Hostname pc123.your.network.com RemoteForward 52698 127.0.0.1:52698 You can add more information like User yourusername to this file. Server-Side steps Download the rmate script: curl https://raw.github.com/aurora/rmate/master/rmate > rmate Execute ./rmate yourfile . It will open in your local Sublime Text! Improvements These steps have to be done server-side. With Root access It's not so nice to open files with ~/rmate filename all the time. You can use rmate filename after executing this command: # This creates a symlink sudo ln -s ~/rmate /usr/local/bin/ You can use other paths than /usr/local/bin/ . Look at your PATH for candidates: echo $PATH Without Root access When you don't have root access, you can't create a symlink for most (eventually even all) folders in your PATH . But you can expand your PATH : mkdir -p ~/bin # create folder if it doesn't exist ln -s ~/rmate ~/bin/ # create symlink Now expand your PATH so that it includes ~/bin . There are at least two ways to do so: You can directly edit your shells .rc file (e. g. .bashrc , .zshrc , .cshrc , ...) or you can edit your .profile As many shells source .profile I'll explain this way. First, open ~/.profile . Then add # First check if that folder exists if [ -d \" $HOME /bin\" ] ; then # Add your home folder to the end of the current path PATH = \" $PATH : $HOME /bin\" fi","tags":"Code","title":"How to use Sublime Text via SSH"},{"url":"https://martin-thoma.com/reviews/arena-villa-am-wasserpark/","text":"Ich hatte einen Termin in der Frankfurter US-Botschaft. DafÃ¼r ist die \" Arena Villa am Wasserpark \" wunderbar geeignet. Das Zimmer ist im Vergleich mit 59.00 Euro + 7.50 Euro fÃ¼r das FrÃ¼hstÃ¼ck relativ gÃ¼nstig. Der Service war sehr freundlich. Die Sauberkeit war im Prinzip gut, nur wie fast Ã¼berall ist die BelÃ¼ftung im Klo / Bad sehr verstaubt. AuÃŸerdem ist die Dusche sehr dumm angelegt. Beim Duschen zieht sich der Vorhang zu einem hin und das Wasser lÃ¤uft am Rand aus der Dusche. Zum GlÃ¼ck wurden genug HandtÃ¼cher bereitgestellt. Das Zimmer hat einen Fernseher mit Ã¼ber 100 Programmen. Das FrÃ¼hstÃ¼ck war ok. Es gab BrÃ¶tchen, MilchbrÃ¶tchen, Obst, MÃ¼sli, Kuchen, Joghurt, Marmelade, Butter, KÃ¤se und Wurst, ... Rating Overall: 3 of 5 stars Sauberkeit: 4 / 5 stars Service: 5 / 5 stars Zimmer: 4 / 5 stars Lage: 4 / 5 stars (when you want to visit the embassy) Bath / shower: 1 of 5 stars Sonstiges: Anscheinend wurde bei denen ein Computer-System gehackt, auf dem meine E-Mail Adresse war. Jedenfalls habe ich dann von denen Spam bekommen. Meta Friedberger LandstraÃŸe 285 , 60389 Frankfurt am Main","tags":"Review","title":"Arena Villa am Wasserpark"},{"url":"https://martin-thoma.com/reviews/bolt-dvd/","text":"Obwohl der Film ein netter Animationsfilm im Disney-Stil ist, der normalerweise von mir 4 Sterne bekommen hÃ¤tte, muss ich mal wieder anmerken, dass er unter Linux - vermutlich wegen DRMs / Kopierschutz - nicht funktioniert. libdvdcss2, libdvdread, ubuntu restricted extras - alles ist installiert. Der VLC spielt es gar nicht erst ab und kaffeine schmiert mit pa_write() failed while trying to wake up the mainloop: Bad file descriptor ab. Siehe pastebin.com/77eGs8Dy fÃ¼r den genauen Fehler. Getestet wurde es unter Linux Mint 16.","tags":"Review","title":"Bolt (DVD)"},{"url":"https://martin-thoma.com/reviews/chinesischer-garten/","text":"Nice! 5 / 5 stars!","tags":"Review","title":"Chinesischer Garten"},{"url":"https://martin-thoma.com/reviews/dialogmuseum/","text":"ACHTUNG: FÃ¼r das Dialogmuseum sollte man sich anmelden! Bevor die FÃ¼hrung beginnt, sollte man alle elektronischen GerÃ¤te einschlieÃŸen, also nicht mitnehmen. Man muss sie sowieso komplett ausmachen und wenn man sie nicht dabei hat, besteht keine Gefahr, dass sie kaputt gehen. Selbiges gilt fÃ¼r Brillen. Man wird im Dunkeln durch verschiedene RÃ¤ume gefÃ¼hrt. Dabei hat man einen Blindenstock. Es ist wirklich komplett Dunkel! Es besteht also keine Bedarf fÃ¼r eine Brille. Mit ca. 14.50 Euro pro ermÃ¤ÃŸigte Person fÃ¼r eine FÃ¼hrung von 1.5h ist der Besuch sehr teuer. DafÃ¼r gab es einen Punkt abzug. Aufenthalt April 2014 4 of 5 stars","tags":"Review","title":"Dialogmuseum"},{"url":"https://martin-thoma.com/reviews/die-kuh-die-lacht/","text":"3 of 5 stars Zu teuer: Cheeseburger: 7.50 Euro Pommes frites: 2.80 Euro Limo Minze 0.5 Liter: 3.65 Euro","tags":"Review","title":"Die Kuh die Lacht"},{"url":"https://martin-thoma.com/reviews/meinfernbus/","text":"Write your article. Meine Fahrt heute von Augsburg nach Karlsruhe lief super. Die online-Bestellung der Tickets hat wie immer reibungslos funktioniert, das Bezahlen via PayPal lÃ¤uft auch gut. Vor dem Fahrtantritt wurde ich sowohl per SMS als auch per E-Mail darÃ¼ber informiert, dass es zwei Busse geben wird und ich in Bus \"A\" steigen soll. Der Bus war gut zu erkennen, da er in den \"MeinFernbus-GrÃ¼n\" und mit einem deutlich Ã¼ber einem Meter groÃŸem MeinFerbus-Logo bedruckt war. Obwohl am Ostermontag einige Staus waren, ist der Bus pÃ¼nktlich und sicher in Karlsruhe angekommen. Der Bussfahrer (ich glaube er heiÃŸt \"SchÃ¶ffel\") hat sehr frÃ¼h erkannt, dass es einen Stau geben wird und ihn dank guter Ortskenntnis umfahren. WÃ¤hrend der Fahrt hat er im Raum Stuttgart auf einige \"SehenswÃ¼rdigkeiten\" an denen wir vorbeigekommen sind hingewiesen. Man hat sich ein bisschen wie auf Sightseeing-Tour gefÃ¼hlt :-) Der Bus selbst war gut: Es gab eine Steckdose fÃ¼r je zwei SitzplÃ¤tze, die Sitze konnte man etwas in den Gang ausfahren sodass man mehr Platz hatte. Die Toilette scheint funktioniert zu haben, es gab Kaffee, Wasser, Cola, ... zu trinken und (eingeschweiste) Sandwiches zum kaufen. Die GetrÃ¤nke haben 1.50 Euro gekostet (bis auf den Kaffe, der Kostet glaube ich 0.50 Euro) und die Snacks 1.00 Euro. Alles in allem kann ich MeinFernbus.de nur empfehlen!","tags":"Review","title":"MeinFernbus"},{"url":"https://martin-thoma.com/reviews/mortplayer/","text":"I like the player. It plays, even if the screen is black. It stops when you remove the headphones (which comes in handy when you listen to it when you go to bed. Just pull the headphones out and it stops). It has options to stop after the current file / folder / all files The buttons are big What I don't like (1.5 stars less) is that the audio sounds strange when you stop / continue often. Then, you can only make a restart. I also don't like (0.5 stars less) that it is not too clear how to find the files / folders you want to play back. https://play.google.com/store/apps/details?id=de.stohelit.audiobookplayer&hl=en_GB","tags":"Review","title":"MortPlayer Audio Books"},{"url":"https://martin-thoma.com/interpreters-and-shells/","text":"Should you ever be in the position to write a shell or interpreter I hope you will make sure the following things work. Take it as a quality guide. They are ordered by level of importance. The first thing is the most basic one that has to work, the last one is less necessary, but much cooler if you support it. In the following, I'll only talk about shells. But most of it will also apply to interpreters. Level 0: Robustness A shell has to be robust. Users rely on it when GUI doesn't work. This means it should definitely not fail. Never. And just to make sure that you get me correct. Commands get \"Entered\". So the user pushes \"enter\" when he wants something to happen. Everything the shell does meanwhile should not change the system (except for shell-related stuff) and not be able to slow down / crash the system. Level 1: Speed I expect a shell to start without recognizable delay. I'm not too sure how fast 'without recognizable delay' means. In the most extreme case it would be about 1/100 of a second, because when monitors have 100Hz they are said to be flicker free. You could not even see that. But I think it is not necessary. Another measure would be reaction time. I've just did an online test and saw that my reaction time is about 0.2 seconds. So a shell should be ready for user input after this time. Level 2: Left / Right arrow keys When I enter a command, it happens that I forget something. In this case I want to be able to navigate with left / right arrow keys through the console. Level 3: History with up / down arrow keys When you use the up-array, you should get the last command you've entered. When you press it twice, you get the second last command... So the shell should save your last commands in a so called \"history\". This history should be at least Level 4: Customization Promt History length Level 5: Path autocompletion The path should autocomplete when you hit Tab . The autocomplete should work as follows: The autocomplete should never get farer than one folder. If there are multiple possibilities to autocomplete, then it should only autocomplete what is in common. After a second Tab it should display the possibilities and after a third Tab the shell should go to the first possibility so that you can hit enter to use this possibility. Level 6: Command autocompletion The autocomplete function should also complete commands. Level 7: Fuzzy autocompletion When you make a typo in a path and hit Tab the shell should correct the typo if possible. Additional stuff Some stuff is nice to have, but not really essential: Some default commands like help , time , pwd , cd and echo . Ctrl + D as a shortcut for exiting. Ctrl + C should stop the current command. The configuration file should be stored in the home folder of the user and it should be called .[name]rc . The dot makes the file invisible by convention and 'rc' means 'resource configuration'. The prompt configuration should be easy. Some patterns that are used quite often are \\w for the working directory, where $HOME gets abbreviated with ~ \\u the username \\h the hostname Using colors for different parts Navigation with Pos 1 and End should work. Ranking Here is how some shells rank. Please note, that it's very difficult to check if a shell is robust. : Level 0 : Windows XP / Windows 7 default shell; Windows Power shell The shell is too slow. I don't know if this is still a problem in Windows 8, but I guess so. The scala interactive interpreter is slow. Level 1 : csh prints \"&#94;[[D\" when I press the left arrow and \"&#94;[[C\" when I press the right arrow. When I press Tab it only prints tab. What a crap. Level 3 : python seems to have possibilities to execute arbitrary python code at startup by specifying the environment variable PYTHONSTARTUP , but somehow this does not work on my system. However, customizing the prompt is fairly easy: import sys sys . ps1 = \"-->\" Level 4 : GHCi , a Haskell compiler, has mastered level 4. The prompt can be configured via ~/.ghci by adding :set prompt \"ghci> \" . If you want to show the current path, you can do it like this ( source ): let cur fill = do { cwd <- System . Directory . getCurrentDirectory ; return ( \":set prompt \\\" \" ++ cwd ++ fill ++ \" \\\" \" ); } : def doprompt ( \\ _ -> cur \">\" ) : def mycd ( \\ dir -> System . Directory . setCurrentDirectory dir >> cur \">\" ) : doprompt Level 4.5 : bash is robust, takes about 0.11 seconds to start, has a history of 500 lines as you can verify with echo $HISTSIZE , is customizable with .bashrc . tcsh takes about 0.02 seconds to start, has a default history size of 100 lines as you can verify with echo $history , is customizable with .tcshrc and .cshrc . Rubys interactive interpreter irb seems to be fast enough, has a history, the prompt can be configured in ~/.riplrc ( source ). I don't know if the history length is limited and can be adjusted. All shells in this level have path autocompletion as described in 5.1, but do not have autocompletion as described in 5.2. Level 7 : ZSH is the best shell I have ever used. Especially with oh-my-zsh . Additional resources How to change your shell prompt : A list of files and commands that might be useful.","tags":"Code","title":"Interpreters and Shells"},{"url":"https://martin-thoma.com/internet-at-kit/","text":"This article is about how to get internet at KIT with Linux. It was tested on Linux Mint 16 MATE which is based on Ubuntu which is based on Debian. WLAN At KIT are a lot of WLANs, but only two are important: wkit-802.1x and eduroam . Mode: Infrastructure Security: WPA & WPA2 Enterprise Authentificaiton: Protected EAP (PEAP) Anonymous identity: anonymous@kit.edu CA certificate: deutsche-telekom-root-ca-2.crt ( source ) PEAP version: Automatic Inner authentification: MSCHAPv2 Username: for wkit-802.1x : uabcd (Your username. It begins with 'u' and has 5 letters) for eduroam : uabcd@student.kit.edu Password: (Your password) IPv4 Settings: Automatic (DHCP) IPv6 Settings: Ignore VPN I use Juniper VPN. The following lines install some prerequesites, download Juniper from this page , unpack it and execute the shell script. sudo apt-get install libc6-i386 lib32z1 lib32nss-mdns wget http://www.scc.kit.edu/scc/sw/juniper/7.4R8/linux_vpn_7.4R8.tar.gz tar -xzvf linux_vpn_7.4R8.tar.gz cd juniper_linux ./vpn-install.sh After you have done this, you can use juniper with jnc -n kit The -n flag disables GUI. It will show this: Server certificate verified and CN is vpn.kit.edu. Saving in /home/moose/.juniper_networks/network_connect/config/vpn.kit.edu.der. Password: Connecting to vpn.kit.edu : 443 . Waiting for ncsvc for 3 seconds... done ncsvc is running, but tunnel is not established yet. Waiting for 3 seconds... done ncsvc is running, but tunnel is not established yet. Waiting for 3 seconds... done . ncsvc is running in background ( PID: 11180 ) : tunnel interface tun0, addr: 141 .3.192.60 You can stop it with jnc stop . Resources Zertifizierung (KIT-CA) Juniper VPN unter Linux","tags":"Cyberculture","title":"Internet at KIT"},{"url":"https://martin-thoma.com/sublime-text/","text":"Sublime Text is the coolest editor I have ever used. It has a lot of features, is blazingly fast as I expect it from every editor and has a convenient configuration. It is available for Linux, Windows and Mac. You can use it for free without any restrictions as long as you want. But keep in mind that somebody had to develop this nice software. Installation You can get a free version from sublimetext.com or you could install it on Linux Mint via sudo apt-get install sublime-text I've added a symlink to make it easier to call it from command line: sudo ln -s /opt/sublime_text/sublime_text /usr/local/bin/sublime The editor is usable right after the installation, but you might want to make some fine-tuning. Package Control The Package Control plugin should definitely be installed. It makes installation of other packages so much easier. After you have installed it, you can press Ctrl + Shift + P to get this dialog: Sublime Tabs Configuration Sublime Text offers plenty of configuration options. You can apply them to projects, users or system wide. Most of the time, I change my preferences for me via Preferences > Settings - User: Preferences > Settings - User Here is what I have changed: { \"WrapPlus.break_on_hyphens\": false, \"color_scheme\": \"Packages/Colorsublime - Themes/textmate.tmTheme\", \"detect_indentation\": false, \"draw_white_space\": \"all\", \"fold_buttons\": true, \"font_face\": \"Ubuntu Mono\", \"font_size\": 15, \"highlight_line\": true, \"rulers\": [ 79, 120 ], \"scroll_speed\": 0, \"search_threshold\": 1000000, \"tab_size\": 4, \"translate_tabs_to_spaces\": true, \"use_tab_stops\": false } Note that you have to install the color scheme and the font ( source ) to use it. Command Palette You can get to the command palette by Ctrl + Shift + P . This opens such a dialog: automatical alignment This will do a fuzzy search through all elements in the menu. So you don't need to use Alt + arrow keys no longer. I love it â˜º Plugins LaTeXTools The LaTeXTools package adds support for LaTeX. It adds shortcuts, a pull-down menu when you enter \\cref{ and much more. BracketHighlighter BracketHighlighter adds brackets on the left side. It looks like this: Highlight braces Alignment Sublime Alignment gives you the possibility to mark text, press Ctrl + Alt + a to align: automatical alignment Colorsublime Colorsublime is a plugin for theming Sublime Text&nbps;3 within seconds. Take a look at colorsublime.com for some examples. TrailingSpaces Tools for easy removing trailing spaces with Ctrl + Shift + T . See GitHub repository . Wrap Plus Tools for easy wrapping lines with Alt + Q . See GitHub repository . Python Flake8 Lint Highlight potential problems with Python code. See GitHub repository . Themes First of all, make sure you have installed the Colorsublime package. After you have it, you can press Ctrl + Shift + P and enter \"Install Theme\". Then it contacts the server and provides you a list of many good themes. You can go through them with the arrow keys and they will instantly be applied! I really like the \"Textmate\" theme, but the \"Chrome_DevTools\" theme is also good. Custom Keybindings You can create custom keybindings via Preferences Key Bindings (User) I have these: [ { \"keys\": [\"ctrl+shift+r\"], \"command\": \"reindent\", \"args\": { \"single_line\": false } }, { \"keys\": [\"shift+tab\"], \"command\": \"unindent\", \"args\": {\"single_line\":true} }, { \"keys\": [\"ctrl+7\"], \"command\": \"toggle_comment\", \"args\": { \"block\": false } }, { \"keys\": [\"ctrl+shift+7\"], \"command\": \"toggle_comment\", \"args\": { \"block\": true } }, { \"keys\": [\"ctrl+shift+t\"], \"command\": \"delete_trailing_spaces\" } ] Custom snippets Snippets are a very cool feature of ST . They allow you to enter some text, press Tab and get whatever you wanted. So you could create a new .tex document, enter article , press Tab and get a template for a LaTeX document of the article document class. A tutorial how to create a snippet for the article document class was written Jonathan Page: Creating Snippets in Sublime Text 2 for LaTeX Buildin Keybindings Ctrl + p : Goto file Ctrl + Shift + P : Goto anything Ctrl + r : Goto section Ctrl+R in Sublime Text (LaTeX) Ctrl+R in Sublime Text (Markdown) Ctrl + Shift + Up / Down : Move the current line one line up / down Shift + F11 : Distraction free mode Distraction free mode Ctrl + D : Multi-Select What could be better Chrome-like Tabs Look at this: Sublime Tabs Now compare it to this: Chrome Tabs Chrome tabs look much cleaner, don't they? Many others seem to think that, too ( source ). Line Wrapping Sublime Text 3 does wrap points and commas to the next line: line wrapping This behaviour is bad and not liked by the community ( source ). Support for Tooltips It would be absolutely great for many plugins like linters if they could make use of tooltips. Any news on tooltip and sidebar API? Are you planning to implement this (ever? :mrgreen: ) It's something I very much want to get done, but at this stage I don't know when that will be. Source: Sublime Text Forum: Sublime Text 3 Beta More Documentation colorsublime.com : Lots of themes tmtheme-editor.herokuapp.com : Adjust your theme online Sublime Text 2 Video Tutorials : A series of 32 video tutorials for Sublime Text 2. At least the first few are the same in ST 3.","tags":"Code","title":"Sublime Text"},{"url":"https://martin-thoma.com/geotopo/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žEinfÃ¼hrung in die Geometrie und Topologie\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr. Herrlich im Wintersemester 2013/2014 gehÃ¶rt. Der Artikel wird bis zur Klausur laufend aktualisiert. Behandelter Stoff Ist im Skript: Zitierbare Version PDF in A4 mit Links zum online anschauen PDF in A5 zum ausdrucken und binden Definitionen als PDF in A7 zum Karteikarten-Lernen LaTeX-Quelldateien Material Vorlesungsverzeichnis Vorlesungsseite ÃœbungsblÃ¤tter Ãœbungsbetrieb Wo sind die ÃœbungsblÃ¤tter: Link Abgabeform: Ãœber den Kasten im Allianzbau (bei der Mathe-Fachschaft) Abgabe: Montags RÃ¼cknahme: Im Tutorium Turnus: wÃ¶chentlich, erscheint am Montag Ãœbungsschein verpflichtend: Es gibt keinen Ãœbungsschein. Bonus durch Ãœbungsschein: Es gibt keinen Klausurbonus. Termine und Klausurablauf Datum : Samstag, den 22. Februar 2014 von 12:00 bis 14:00 Uhr Ort : Audimax ( Quelle ) Punkte : 36 Bestehensgrenze : 14 (?) Ãœbungsschein : Gibt es nicht. Bonuspunkte : Gibt es nicht. Ergebnisse : sind ab heute Nachmittig im Studierendenportal (Stand: 28.02.2014) Einsicht : Montag, 17. MÃ¤rz um 15.00 Uhr im Raum 1C-03 (Stand: 28.02.2014, Quelle ) Erlaubte Hilfsmittel : Keine. Mitbringen : Studentenausweis und Stift. Ergebnisse Im Studierendenportal (Stand: 28.02.2014).","tags":"German posts","title":"GeoTopo Klausur"},{"url":"https://martin-thoma.com/highend-notebooks/","text":"My Acer Travelmate 5744Z seems to get broken in soon, so I'm currently looking for a new notebook. As I use my notebook quite often and as this is the third notebook within three years that is not usable any longer (the screen of the first is defect and the graphic card / WLAN of the second does not work propperly with the new Linux kernel), I'm would like to have a high end notebook this time. I hope that I not have to think about notebooks for at least 5 years after that. Requirements I work quite a lot with the computer, so the keyboard and the display have to be good. What does good mean? Well, the display has to be at least 15\" and as I don't want to see my pixels any longer it has to have a higher resolution than 1366Ã—768 . But it has to be smaller than 30cm Ã— 38cm to fit into my knapsack. A reason why I do not always have my current notebook with me is that it is too heavy with about 2.5kg and does only run for about 3.5h. The new one should be lighter than 2.5kg and run at least 4h . Ubuntu has to be supported completely, especially WLAN, sound and Bluetooth. Speaking of Bluetooth, I want Bluetooth 4.0 , because it introduced a low energy protocol that might be usefull for notebooks. As I live in a city and as I access the internet via my neighbors WLAN (thank you!), I need a good connection: Dual band and 802.11a/b/g/n need to be supported by the notebook. (Dual band is sometimes also called 2x2). I use it mainly for writing blog articles, LaTeX stuff and some Python programming and watching movies. I download movies via Online TV Recorder which sums up quite soon. Transfering this to my external HDD always takes a lot of time. The new notebook should support USB 3.0 to speed this up. As I don't have to store anything large, 80 GB SSD is enough. It should be a SSD, because they consume less power, are more durable and are more silent. I need at least 4GB RAM because ... well, did you ever try to use Eclipse for Java+JBoss programming with less than 4GB? I don't want to have that again. It would be nice if I could use the notebook outside in the summer which means it has to have a bright matte display . I want a silent notebook, because I'm very sensitive to noise. My current notebook has less than 30 dB in normal mode (no heavy load). That should set the mark. A SD-Card Reader would be nice, but it is not required. Just like a RJ-45 for network cables and a DVD drive you can get it via USB. I robust case is also important. I had troubles working in the train, because the screen was whipping as hell. But this is not a hard requirement for me as I don't work in trains that often. Current Favorites I've looked at a lot of notebooks and I did mainly focus on the technical specification and not at the price (I guess I might work about 10h every day in front of this machine. A good, working notebook is very important to me). However, when I see some notebooks that are ok according to the specs from above, I will take the cheaper one. By the way, while searching for notebooks I discovered that much of the data on Amazon is wrong. See for example the dimensions of the HP EliteBook 8570p-B6Q03EA-ABD (51.6 x 34.2 x 7.8 cm according to Amazon). Asus Zenbook Samsung Notebook Serie 9 Model UX51VZ-DB114H 900X4D K01 Price 1380 Euro 995 Euro Dimensions (B Ã— D Ã— H) 380 Ã— 254 Ã— 20 356.9 Ã— 237 Ã— 14.9 mm Weight 2.2 kg 1.58 kg CPU Intel Core i7 3632QM Intel Core i5-3337U Display Size 15.6\" 15\" Display Resolution 2880Ã—1620 1600Ã—900 Display more LED-Display, 400 Nit Matte display âœ˜ âœ” RAM 8 GB DDR3, 1600 MHz 2Ã— 4 GB DDR3 SDRAM1.600 MHz Disk 256 SSD 128 GB SSD Network ? RJ45 with adapter and 1.000 Mbit/s Wireless 802.11a/g/n, WiDi 802.11a/b/g/n (2Ã—2), WiDi WLAN-Chip ? Intel Wireless-N 7260 Bluetooth 4.0 4.0 Akku 4750 mAh 8200 mAh, up to 10h USB 3Ã— USB 3.0 2Ã— USB 3.0, 1Ã— USB 2.0 SD Card Reader âœ” âœ” Linux-Support ? partially ([&#94;1],[&#94;2], [&#94;3]) Keyboard ? Chiclet-keyboard without numblock Noise ? 29.5 dB in normal mode, 40 dB max Samsung Series 9 Macbook Pro The WLAN chipset of the Samsung Serie 9 seems to cause trouble with Linux, but it also seems to be solved by a firmware update.[&#94;5] But one hint seems to be important: Before you install Linux on a Samsung Serie 9, make sure you update the firmware, because that's only possible with Windows. Asus Zenbook seems also to work almost out of the box.[&#94;6] I've just learned that you can use sudo dmidecode -s system-product-name to determine your exact laptop product name. In the following, I will give you an overview of the notebooks I took a look at. I think all of them are very good. In many cases I will need some more equipment: MicroHDMI 2 VGA adapter: Samsung AA-AH2NMHB/E for 29.90 Euro USB Ethernet adapter: \"Cable Matters - SuperSpeed USB 3.0\" for 16 Euro External DVD burner: Samsung SE-208DB for 30 Euro works with DVDÂ±R Dual layer disks and DVDÂ±RW disks. Is there anything more important to look at? Others: Lenovo Thinkpad T450s (20BWS1UT00 with i5-5200U, Nvidia GeForce 940M). See notebookcheck TUXEDO Book BU1505 Samsung ATIV Book 9 2014 Edition Lenovo ThinkPad X1 Notebook for developers Acer Acer Aspire Model V5-573G-54208G50aii Price 649 Euro Dimensions (B Ã— D Ã— H) 382 Ã— 256 Ã— 18 Weight 2.04 kg CPU Intel Core i5-4200U Display Size 15.6\" Display Resolution 1920 Ã— 1080 Matte display âœ” RAM 8 GB DDR3, 1600 MHz Disk 1000 GB HDD Network 10/100/1000MBit Wireless WLAN-Chip Atheros AR5BWB222 Bluetooth 4.0 Akku 3560 mAh USB 1Ã— USB 3.0, 2Ã— USB 2.0 SD Card Reader âœ” Linux-Support âœ” Keyboard Chiclet-Keyboard Noise 33.3 dB Apple Macbook Pro Model Retina 15\" Price 1999 Euro Dimensions (B Ã— D Ã— H) 358.9 Ã— 247.1 Ã— 18 mm Weight 2.02 kg CPU Intel Core i7 2760QM Display Size 15.4\" Display Resolution 2880Ã—1800 Display more Matte display âœ” RAM 8 GB 1600 MHz DDR3L Disk 256 SSD Network no RJ45 Wireless 802.11a/b/g/n WLAN-Chip ? Bluetooth 4.0 Akku up to 7h USB 2Ã— USB 3.0 SD Card Reader âœ” Linux-Support ? Keyboard Chiclet-Keyboard Noise 29.4 dB in normal mode, 47.4 dB max Although the hardware looks very nice, it is still comparable with both of my favorites. Asus Asus Zenbooks Asus Zenbook Asus Zenbook Asus Zenbook Model UX51VZ-CN035H UX51VZ-DB114H U500VZ Price 1390 Euro 1380 Euro 1350 Euro Dimensions (B Ã— D Ã— H) 380 Ã— 254 Ã— 20 380 Ã— 254 Ã— 20 380 Ã— 254 Ã— 20 mm Weight 2.2 kg 2.2 kg 2.2 kg CPU Intel Core i7-3612QM Intel Core i7 3632QM Intel Core i7-3612QM Display Size 15.6\" 15.6\" 15.6\" Display Resolution 1920Ã—1080 2880Ã—1620 1920Ã—1080 Matte display âœ” âœ˜ âœ” RAM 8 GB DDR3, 1600 MHz 8 GB DDR3, 1600 MHz 4 GB Disk 256 SSD 256 SSD 512 GB SSD Network 10/100/1000, RJ45 ? ? Wireless 802.11a/g/n, 2Ã—2 WiDi 802.11a/g/n, WiDi 802.11a/b/g/n, 2Ã—2 WLAN-Chip ? ? ? Bluetooth 4.0 4.0 4.0 Akku ? 4750 mAh 4750 mAh USB 3Ã— USB 3.0 3Ã— USB 3.0 2Ã— USB 3.0 SD Card Reader âœ” âœ” âœ” Linux-Support ? ? ? Keyboard ? ? Chiclet-Keyboard with Numblock Noise ? ? 34 dB in normal mode, 42 dB max Asus PU500CA-XO002X and Asus N550JV-CN201H Asus Asus Model PU500CA-XO002X N550JV-CN201H Price 998 Euro 1099 Dimensions (B Ã— D Ã— H) 383 Ã— 257 Ã— 22.5 mm 383 Ã— 255 Ã— 27 Weight 1.96 kg 2.7 kg CPU Intel Core i5-3317U Intel Core i7-4700HQ Display Size 15.6\" 15.6\" Display Resolution 1366 Ã— 768 1920 Ã— 1080 Matte display âœ” âœ” RAM 4 GB 8GB DDR3 Disk 524 GB 1000 GB HDD Network ? ? Wireless 802.11 a/b/g/n, WiDi 802.11 b/g/n WLAN-Chip Atheros (AR9485) Bluetooth 4.0 4.0 Akku 4000 mAh, up to 7h 4000 mAh USB 1Ã— USB 3.0 2Ã— USB 3.0 SD Card Reader âœ” âœ” Linux-Support ? ? Keyboard Chiclet-Keyboard with Numblock Chiclet-Keyboard with Numblock Noise 30.7 dB in normal mode, 38.4 dB max 32.9 dB in normal mode, 38 dB max Dell XPS 15 Model 9530-1906 Price 1711 Euro Dimensions (B Ã— D Ã— H) 372 Ã— 254 Ã— 18 Weight 2.02 kg CPU Intel Core i7-4702HQ Display Size 15.6\" Display Resolution 3200x1800 Matte display âœ˜ RAM 8 GB DDR3L, 1600 MHz Disk 512 GB SSD Network (no RJ45) Wireless 802.11 ac, 2x2 WLAN-Chip Intel AC 7260 Bluetooth 4.0 Akku ? USB 3Ã— USB 3.0 SD Card Reader âœ” Linux-Support ? Keyboard Chiclet-Keyboard Noise 29.8 dB, 42.1 dB max There seem to be other versions of the XPS 15: XPS 15 (L501X) XPS 15 (L502X) XPS 15z However, I was not able to find any specification of those. Fujitsu Fujitsu Lifebook Model E753 Price 1759 Euro Dimensions (B Ã— D Ã— H) 374 Ã— 374 Ã— 20 Weight 1.99 kg CPU Intel Core i7-3632QM Display Size 15.6\" Display Resolution 1920Ã—1080 Matte display âœ” RAM 8 GB DDR3 Disk 256 GB SSD Network 10/100/1000MBit Wireless 802.11 a/b/g/n WLAN-Chip Centrino Advanced-N 6235 Bluetooth 4.0 Akku 6700 mAh USB 3Ã— USB 3.0 SD Card Reader âœ” Linux-Support ? Keyboard Chiclet-Keyboard Noise 33.3 dB HP HP Envy 15 Model J011SG Price 811 Euro Dimensions (B Ã— D Ã— H) 380 Ã— 251 Ã— 28 Weight 2.19 kg CPU Intel Core i5-4200M Display Size 15.6\" Display Resolution 1920Ã—1080 Matte display âœ˜ RAM 12 GB DDR3L, 1600 MHz Disk 1000 GB Network 10/100/1000 RJ-45 Wireless 802.11b/g/n WLAN-Chip Intel AC 7260 Bluetooth 4.0 Akku 2200 mAh USB 4Ã— USB 3.0 SD Card Reader âœ” Linux-Support ? Keyboard with numblock Noise ? Samsung Serie 9 The next few lines show the difference of the 900X4C A0A to... NP900X4C-A01 : Intel Core i5-3317U, 128GB SSD, no Dualband 900X3C A03 : 3610 mAh, 1399 Euro 900X4B-A01 : Intel Core i7 2637M, 1999 Euro 900X4C-A04 : Intel Core i5 3317U, 1999 Euro 900X4C-A05 : Intel Core i5 3317U, 128GB SSD, no Dualband, ca 1200 Euro 900X4C A06 : 256 GB SSD, 15.6\" Display, 1629 Euro 900X4C A09 : Costs 1999 Euro (any other difference?) 900X4D A03 has also 15\" Display, but only 4GB RAM and a Intel Core i5-3317U and a 128 GB SSD. But it costs only 799 Euro. 900X4D K01 : Intel Core i5-3337U, 128 GB SSD, 8400 mAh, Dual Band, 997 Euro Samsung ATIV Book 9 2014 Edition Samsung ATIV Book 9 2014 Edition Model NP930X5J-K01DE Price 1599 Euro Dimensions (B Ã— D Ã— H) ? Ã— ? Ã— 14.9 mm Weight 1.78 kg CPU Intel Core i7-4500U Display Size 15.6\" Display Resolution 1920Ã—1080 Display more Touch-Display Matte display âœ˜ RAM 8 GB ? MHz Disk 256GB SSD Network RJ45 with adapter and 1.000 Mbit/s Wireless 802.11 ac (2x2) ( source ) WLAN-Chip Intel Wireless-AC 7260, 802.11 ac Bluetooth 4.0 Akku ?, 14h USB 2Ã— USB 3.0, 1 Ã— USB 2.0 SD Card Reader âœ” Linux-Support ? Keyboard Chiclet-keyboard Noise ? Good audio qualit: 24-bit, 192kHz audio, 2x 2W HDMI out, mini VGA, an SD card reader 720p webcam Release date should be 28.03.2014 ( source ). Sources techradar.com notebookcheck.de Tuxedo Tuxedo Book Model BC1503 Price 763 Euro Dimensions (B Ã— D Ã— H) 374 Ã— 252 Ã— 31 mm Weight 2.4 kg CPU Intel Core i5 4200M Display Size 15.6\" Display Resolution 1920Ã—1080 Display more IPS-Display Matte display âœ” RAM 1Ã—8 GB 1600 MHz Disk 120 SSD (Samsung EVO / SATA III) Network has RJ45 built-in, 10/100/1000 Wireless 802.11 ac/a/b/g/n WLAN-Chip Intel Dual AC7260 Bluetooth 4.0 Akku 62,16 Wh, 2.5h[&#94;4] USB 2Ã— USB 3.0 SD Card Reader âœ” Linux-Support shipped with Linux Mint â˜º Keyboard ? Noise Laut[&#94;4] See also: tuxedocomputers.com , linux-onlineshop.de TUXEDO Book BU1505 (with Skylake, up to 16GB RAM, ca. 1240 Euro) Librem 15 Librem 15 Model Price 2185 Euro Dimensions (B Ã— D Ã— H) 375 Ã— 244 Ã— 22 mm Weight 2.0 kg CPU Intel i7-5557U (Broadwell-U architecture) Display Size 15.6\" Display Resolution 3840Ã—2160 Display more IPS-Display Matte display âœ” RAM 1Ã—8 GB 1600 MHz Disk 250 GB SSD Network âœ˜, 10/100/1000 Wireless 802.11 n WLAN-Chip ? Bluetooth âœ”, ? Akku 65W, 48 Wh, Up to 6 hours usage USB 1Ã— USB 3.1, 2Ã— USB 3.0 SD Card Reader SDXC Linux-Support âœ” Keyboard ? Noise ? Other On a first glance, the Samsung ATIV Book 8 NP880Z5E-X01 looked quite promising. But it doesn't have an SSD, it weights 2.54 kg, but has no optical drive. Samsung ATIV 870Z5E-X03DE ATIV Book 8 870Z5E X04 ATIV Book 8 880Z5E X01 ATIV Book 9 900X4D K01 ( notebookinfo.de ) Notebooks that did not meet the criteria Display is too small: Chromebook Pixel has only 12.85\" XPS 13 has only 13.3\" Asus Zenbook has only 13.3\" Lenovo IdeaPad U300s have only 13.3\" All Samsung Series 9 X3A seem to have 13.3\" displays Samsung Series 9 900X3D-A02: 13.3\" Samsung Series 9 900X3C-A01: 13.3\" Samsung Series 9 900X3C A07: 13.3\" Too low resolution: Acer TravelMate 6594eG-464G50Mikk Asuspro PU500 All Acer Aspire TimelineU M5 To heavy: Lenovo IdeaPad Y510p: 2.89 kg HP EliteBook 8570p-B6Q03EA-ABD: 2.91 kg Sony Vaio VPC-F21Z1E/BI: 3.17 kg Availability: seems not to be available on Amazon Samsung Serie 9 NP900X4C-A02 Sony Vaio SV-E1511V1EW Sony Vaio VGN-TX2 HP Envy 6-1000sg Other: Acer Aspire M3-581TG: Too loud, only 667MHz RAM Dear Notebook-Producers After searching so much for notebooks, I have some hints for you what you could do better: Add a single specification page for each notebook. This page should include at least: Weight in kg and dimensions in mm Battery life in mAh Display (size, glare or matte display, supported resolutions) Exact CPU name (not only Intel i5 - if it varies, list all possible CPUs) Disk (size, SSD or not) Wireless support (IEEE 802.11 supported standards? Dual band? Bluetooth? Bluetooth version?) Keyboard: Does it have a numblock? Backlit? Does it have a DVD-Player / Burner? Blue-Ray? Webcam (resolution) Microphone Sensors (GPS) Image of the notebook A good specification page would include: Noise in dB Information about Linux support (especially Debian) Explain your version names! Provide a possibility to compare your products like Intel does with ark.intel.com for its processors Provide a possibility to filter your products by technical specification. Add an image of your product to Wikipedia Commons References [&#94;1] Linux and the Samsung Series 9 NP900X3C : A review for the NP900X3C and openSUSE on 24th or September, 2012. [&#94;2] Samsung Series 9 - Ubuntu Community Page [&#94;3] Linux auf Samsung Series 9 2012 [&#94;4] Tuxedo Book DC1502 im Test [&#94;5] No wireless with Intel Centrino Advanced-N 7260 [&#94;6] AsusZenbook - Ubuntu Community Page","tags":"Cyberculture","title":"Highend Notebooks"},{"url":"https://martin-thoma.com/install-and-configure-computer/","text":"When I reinstall my computer, I usually do these following steps: Copy all data to an external HDD Write down all WLAN configurations (eventually with screenshots; NOT ONLY PASSWORDS!) Write down all programs that I use. Export configuration of those programs. Wait a week or a month and see if someting is missing in the lists from above. Drop the old system and install a new one Software I usually install If possible, I will give the debian package names in the following list: LaTeX and scientific writing jabref : A reference manager gnuplot pdf2svg aspell and aspell-de Google Chrome Multimedia vlc : A very good DVD player OnlineTvRecorder and especially OTR-Verwaltung avidemux wine mplayer sudo add-apt-repository ppa:clipgrab-team && sudo apt-get update && sudo apt-get install clipgrab Graphics gimp inkscape dia imagemagick pdf2svg librsvg2-bin Programming vim python python3 python-numpy python-setuptools python-mysqldb python-scipy python-h5py python-matplotlib sudo -H pip install sklearn tflearn ruby ruby-sqlite3 ruby-mysql gcc g++ cmake build-essential gdb OpenGL: xorg-dev libglu1-mesa-dev freeglut3 freeglut3-dev libglew1.5 libglew1.5-dev libglu1-mesa libglu1-mesa-dev libgl1-mesa-glx libgl1-mesa-dev apache2 php5 php5-mysql zsh and Oh-my-zsh eclipse sqlitebrowser tcl phpmyadmin selfhtml meld diffpdf virtualbox Themes Balazan-Theme from bisigi-project (simply download it.) Other sublime_text libreoffice curl DRM-caused (I want to watch DVDs!) ubuntu-restricted-extras libdvd-pkg libdvdread4 libdvdnav4 , then run sudo dpkg-reconfigure libdvd-pkg totem banshee mplayer rythmbox Configure Set standards update-alternatives --config editor update-alternatives --config x-www-browser MATE See issues/262 : mv ~/.config/gtk-3.0/bookmarks ~/.config/gtk-3.0/bookmarks-backup ln -s ~/.gtk-bookmarks ~/.config/gtk-3.0/bookmarks GUI I like the old menu bar quite a lot. It opens instantly and is customizable: Old menu bar You can get it back in MATE by doing a right-click on the menu. Then click on \"add to panel\": Add to panel After that, the following dialog will pop up. Choose \"Menu Bar\" Add menu bar DRM-Stuff sudo /usr/share/doc/libdvdread4/install-css.sh sudo regionset #use that with caution dotfiles See github.com/MartinThoma/dotfiles . Data Download / copy all data back from GitHub / external HDDs to my internal HDD.","tags":"Cyberculture","title":"Install and configure computer"},{"url":"https://martin-thoma.com/slurm/","text":"SLURM is short for 'Simple Linux Utility for Resource Management'. It helps you to make use of a cluster by giving you a command line interface to add jobs to a queue. That means, you and other users can specify program calls that get executed as soon als all conditions are met. I currently need to work with this, because I have some pretty heavy tasks that occur periodically, but don't need to be executed immediately. More concrete, I am working in the field of ASR - Automatic Speech Recognition. In ASR you have models that include probabilities for ... well, let's don't get into detail for that. The important part is that those models need to be trained. And they can get adapted to speakers. As soon as you have more recordings, you can try to improve the model. And this training involves a lot of computation and data processing. As the training job is executed periodically, but not always when a new recording is present, you might also have recordings for many different speakers. So you can improve many models when this script is started. So this can be done on different computers in parallel. SLURM basic usage A simple call could look like this: srun python test.py -aflag -param value Other notable commands are: squeue : Gives a list of all running / pending jobs sbatch : Run a batch script in background scancel : Stop a job Important parameters for srun are: --mem=[X in MB] --job-name=[Name of your SLURM job] --dependency : Start this job when all dependencies are met. This could be time or other jobs Another important command is squeue . It allows you to list all jobs in command line (if you have a GUI: sview ). You can get your jobs only with squeue -u mthoma , where mthoma should be replaced by your user name. Help texts sbatch $ sbatch --help Usage: sbatch [OPTIONS...] executable [args...] Parallel run options: -A, --account=name charge job to specified account --begin=time defer job until HH:MM MM/DD/YY -c, --cpus-per-task=ncpus number of cpus required per task --comment=name arbitrary comment -d, --dependency=type:jobid defer job until condition on jobid is satisfied -D, --workdir=directory set working directory for batch script -e, --error=err file for batch script's standard error --export[=names] specify environment variables to export --get-user-env load environment from local cluster --gid=group_id group ID to run job as (user root only) --gres=list required generic resources -H, --hold submit job in held state -i, --input=in file for batch script's standard input -I, --immediate exit if resources are not immediately available --jobid=id run under already allocated job -J, --job-name=jobname name of job -k, --no-kill do not kill job on node failure -L, --licenses=names required license, comma separated -m, --distribution=type distribution method for processes to nodes (type = block|cyclic|arbitrary) -M, --clusters=names Comma separated list of clusters to issue commands to. Default is current cluster. Name of 'all' will submit to run on all clusters. --mail-type=type notify on state change: BEGIN, END, FAIL or ALL --mail-user=user who to send email notification for job state changes -n, --ntasks=ntasks number of tasks to run --nice[=value] decrease secheduling priority by value --no-requeue if set, do not permit the job to be requeued --ntasks-per-node=n number of tasks to invoke on each node -N, --nodes=N number of nodes on which to run (N = min[-max]) -o, --output=out file for batch script's standard output -O, --overcommit overcommit resources -p, --partition=partition partition requested --propagate[=rlimits] propagate all [or specific list of] rlimits --qos=qos quality of service -Q, --quiet quiet mode (suppress informational messages) --requeue if set, permit the job to be requeued -t, --time=minutes time limit --time-min=minutes minimum time limit (if distinct) -s, --share share nodes with other jobs --uid=user_id user ID to run job as (user root only) -v, --verbose verbose mode (multiple -v's increase verbosity) Constraint options: --contiguous demand a contiguous range of nodes -C, --constraint=list specify a list of constraints -F, --nodefile=filename request a specific list of hosts --mem=MB minimum amount of real memory --mincpus=n minimum number of logical processors (threads) per node --reservation=name allocate resources from named reservation --tmp=MB minimum amount of temporary disk -w, --nodelist=hosts... request a specific list of hosts -x, --exclude=hosts... exclude a specific list of hosts Consumable resources related options: --exclusive allocate nodes in exclusive mode when cpu consumable resource is enabled --mem-per-cpu=MB maximum amount of real memory per allocated cpu required by the job. --mem >= --mem-per-cpu if --mem is specified. Affinity/Multi-core options: (when the task/affinity plugin is enabled) -B --extra-node-info=S[:C[:T]] Expands to: --sockets-per-node=S number of sockets per node to allocate --cores-per-socket=C number of cores per socket to allocate --threads-per-core=T number of threads per core to allocate each field can be 'min' or wildcard '*' total cpus requested = (N x S x C x T) --ntasks-per-core=n number of tasks to invoke on each core --ntasks-per-socket=n number of tasks to invoke on each socket --cpu_bind= Bind tasks to CPUs (see \"--cpu_bind=help\" for options) --hint= Bind tasks according to application hints (see \"--hint=help\" for options) --mem_bind= Bind memory to locality domains (ldom) (see \"--mem_bind=help\" for options) Help options: -h, --help show this help message -u, --usage display brief usage message Other options: -V, --version output version information and exit squeue squeue --help Usage: squeue [OPTIONS] -A, --account=account(s) comma separated list of accounts to view, default is all accounts -a, --all display jobs in hidden partitions -h, --noheader no headers on output --hide do not display jobs in hidden partitions -i, --iterate=seconds specify an interation period -j, --job=job(s) comma separated list of jobs IDs to view, default is all -l, --long long report -M, --clusters=cluster_name cluster to issue commands to. Default is current cluster. cluster with no name will reset to default. -n, --nodes=hostlist list of nodes to view, default is all nodes -o, --format=format format specification -p, --partition=partition(s) comma separated list of partitions to view, default is all partitions -q, --qos=qos(s) comma separated list of qos's to view, default is all qos's -s, --step=step(s) comma separated list of job steps to view, default is all -S, --sort=fields comma separated list of fields to sort on --start print expected start times of pending jobs -t, --states=states comma separated list of states to view, default is pending and running, '--states=all' reports all states -u, --user=user_name(s) comma separated list of users to view -v, --verbose verbosity level -V, --version output version information and exit Help options: --help show this help message --usage display a brief summary of squeue options More information Manpages: srun scancel SLURM Quickstart Guide SLURM Overview from Harvard","tags":"Cyberculture","title":"SLURM"},{"url":"https://martin-thoma.com/ruby/","text":"I'm currently learning Ruby to improve my Jekyll blog. At the moment, I can't really say if I like Ruby. Just like PHP and Python, Ruby is implicitly typed. This means you can do the following: # A list a = [ 1 , 2 , 3 , 4 , 5 ] # An integer b = 42 # A floating point number c = 3 . 141 Ruby is also dynamically typed: a = 42 a = \"now a is a string!\" One thing that is pretty annoying is the usage of begin ... end . I thought LaTeX was the only \"language\" in use that had this syntax. Syntax examples If, else if, else a = 1 if a == 1 || a % 2 == 0 puts \"a equals 1 or is even\" elsif a == 3 puts \"a equals 3\" else puts \"a does not equal 1 or 3 and is not even\" end String manipulation String manipulation is weird in Ruby. Take a look at the last example. What would you expect? s = \"0123456789\" puts s [ 2 .. 4 ] puts s [ 2 .. s . length () ] puts s [ 2 ..- 2 ] Output is: 234 23456789 2345678 Now what would you expect to happen with \"0123456789\"[2..4] ? I would expect Ruby to give \"234\" . But this one actually fails. Dictionaries Dictionaries, which are sometimes also called 'maps' or 'associative arrays' are a neat data structure. Ruby uses this syntax: dictionary = { \"a\" => 7 , \"b\" => \"x\" } if dictionary . has_key? ( \"a\" ) puts \"key 'a' is in dictionary! It is \" + dictionary [ \"a\" ]. to_s dictionary [ \"a\" ] = 42 puts \"Now it is \" + dictionary [ \"a\" ]. to_s puts dictionary . size () puts dictionary . length () puts dictionary . count () end map myList = [ 1 , 2 , 3 , 4 , 5 ] x = myList . map { | element | [ element , element + 1 ] } x . each do | a , b | puts \"a: \" + a . to_s + \", b: \" + b . to_s end will print a: 1 , b: 2 a: 2 , b: 3 a: 3 , b: 4 a: 4 , b: 5 a: 5 , b: 6 .count(), .length(), .size() At a first glance, those three seem to be aliases. But .count() is not quite the same as .length() and .size() ( source ). Blocks A very interesting idea in Ruby is that of blocks. It seems to be similar to Pythons decorators: def time_method ( method = nil , * args ) beginning_time = Time . now if block_given? yield else self . send ( method , args ) end end_time = Time . now puts \"Time elapsed #{ ( end_time - beginning_time ) * 1000 } milliseconds\" end time_method do ( 1 .. 10000 ) . each { | i | i } end Logging Logging in Ruby is very convenient. See Logger Documentation Notable libraries and projects Nokogiri: Parsing HTML The following code will parse yourHTMLcode and select all a -tags (also known as links): require 'nokogiri' doc = Nokogiri :: HTML . parse ( yourHTMLcode ) links = doc . css ( 'a' ) . map { | link | [ link [ 'href' ] , link . text ] } links . each do | link , linktext | puts \"Link '\" + link + \"' was used with '\" + linktext + \"'\" end Sequel This way you can select elements from a SQLite-Database: require 'sequel' db = Sequel . sqlite ( \"search.db\" ) rows = db . fetch ( \"SELECT rowid FROM pages WHERE url='/imprint';\" ) . all #puts rows #puts rows.count() puts rows [ 0 ][ :rowid ] See also: ruby.bastardsbook.com/chapters/html-parsing nokogiri.org Style Guide","tags":"Code","title":"Ruby"},{"url":"https://martin-thoma.com/sum-of-cubed-digits-riddle/","text":"Let \\(N \\in \\mathbb{N}\\) be a number with digits \\(a_k\\) , where \\(a_0\\) is the least significant digit and \\(n\\) is the most significant digit. Find all numbers with the following property: $$N = \\sum_{k=0}&#94;n a_k \\cdot 10&#94;k = \\sum a_k&#94;3$$ Lower and upper bounds The lower bound is \\(0\\) The upper bound is \\(2916\\) since \\(4\\cdot 9&#94;3 = 2916\\) You can find better upper bounds, but as we've just reduced the possible number space to only 2917 numbers, it doesn't really matter. Find all solutions #!/usr/bin/env python3 def find_sum_of_cubes (): \"\"\"Returns all numbers N with the following property N = \\sum_{k=0}&#94;n a_k \\cdot 10&#94;k = \\sum a_k&#94;3 \"\"\" def has_sum_of_cubes_property ( n ): digits = map ( int , list ( str ( n ))) return sum ( map ( lambda n : n ** 3 , digits )) == n return list ( filter ( has_sum_of_cubes_property , range ( 2917 ))) if __name__ == \"__main__\" : print ( find_sum_of_cubes ()) which gives [ 0 , 1 , 153 , 370 , 371 , 407 ]","tags":"Code","title":"Sum of cubed digits riddle"},{"url":"https://martin-thoma.com/how-to-use-jekyll-with-github/","text":"You've probably noticed that I didn't write any posts the last few weeks. The reason is that I've migrated my WordPress Blog to Jekyll. This means it takes some source files and generates purely static pages from that. The generation process is independant of user requests. Jekyll is a static blog generator, just like Pelican , Hyde , nanoc and Octopress . I've spend about 40-80 hours to migrate from WordPress to Jekyll. And I'm not done jet. Jekyll compared with WordPress Jekyll is a static site generator. This means you have the source files on your computer. Then you generate the website with Jekyll and upload only the generated files. So you only push content to the server, but you don't have to download anything from the server. Reasons for Jekyll: Security : With Jekyll, you only upload static files (HTML, CSS, JavaScript, Images, ...). There is nothing where the user can pass some data. This also means there is one thing less to update. Assuming your provider updates your server software (e.g. Apache) you don't have to update anything. In contrast, when you don't regularly install updates on your WordPress blog (and hope that those updates don't break anything), your blog is quite likely to be hacked. Speed : The webserver needs only to serve the sites. Nothing else. Of course, when you use caching with PHP you might get into a similar situation with WordPress. But it will never be faster. Hosting : You only need webspace. This reduces hosting cost significantly. Additionally, you can use Amazon S3 for hosting! Backups : Creating security backups is VERY easy with Jekyll. Every tool that can make bakups of files can backup your Jekyll blog. No need to worry about databases. If a file is corrupt, only that file is affected. No worries about maximum execution time for importing / exporting backups. No need to get SSH access. Simple FTP access does the job. Reasons for WordPress: Comments : There is no way to get comments only with static pages. So you need something else, e.g. disqus . Search : Could probably be done with JavaScript, but I guess it is difficult. Editor : WordPress gives you a WYSIWYG editor. I don't know if there is something similar for Jekyll. Compile time : Compilation time is very long for Jekyll. For my blog, it needs over 6 minutes. As I test the result quite often before I publish posts, this is very annoying. Tagging, Category pages, Author pages : Currently, Jekyll lacks basic support for blogging. You don't have tag pages per default, the plugins that provide tags don't have paginated tag index pages. The same problem occurs when it comes to categories or authors. Timed posts : I did not use timed posts very often, but it is very easy to create them with WordPress. With Jekyll, on the other hand, you have to know how to create cronjobs. And your computer has to be running. Install Jekyll On an Ubunty system I need for this blog: $ sudo apt-get install ruby1.9.1-dev imagemagick ruby-rmagick libmagickwand-dev ruby-execjs ruby-nokogiri $ sudo gem install jekyll $ sudo gem install dimensions $ sudo gem install fileutils $ sudo mkdir -p /var/www/blog GitHub Create your repository Go to github.com , sign in and create a new repo: Call it [Username].github.io . Branches The way to use Jekyll with GitHub is by using branches. Go to your Git repository that cointains your blog: moose@pc08 ~/Downloads/MartinThoma.github.io $ ls _config.yml favicon.ico index.html Makefile Readme.md css images js _plugins _site _drafts _includes _layouts _posts thumbs Now you should create a new branch that will contain your source files. The following command creates a branch sources that starts where the branch master currently is: git checkout -b source master Now update this branch to the server: git push -u origin source When you enter git checkout . master you will switch to the master brach. The same way you can switch to the source branch. After you've entered the command, you can look at the folder in your file system. There will only be the data of the current branch. Custom Domain If you want to host your content at GitHub, but have a custom Domain like martin-thoma.com instead of martinthoma.github.io , you have to: Ask your provider (in my case \"Knallhart\") to add an A-record to Github. Add a file called CNAME with content martin-thoma.com (yes, without http:// ) to the root of your directory GitHub also offers some help on setting up a custom domain with Pages . FTP Server If you have your own FTP server, you probably want to use it. One tool that might now come to your mind is rsync . But rsync needs SSH ( source ). If you have SSH, then you can do something like this: rsync -avz --delete _site/ user@host:/path/to/web/root The --delete options \"delete[s] extraneous files from dest dirs\", -a means archive which preserves the owner, group, change date and some more of files, -v is verbose as always and -z is for compression while the file transfer happens. --progress might also be interesting, especially for the first upload. Otherwise, you might want to try curlftpfs . This program lets you mount a FTP folder: curlftpfs ftp.example.com/backups /mnt/ftpserver and you can also umount it: rsync --delete /var/backups /mnt/ftpserver Markdown I've switched between rdiscount and redcarpet . The former is faster, the latter supports fenced code blocks. I finally stuck with redcarped, because Liquid has problems when it comes to C++ for loops after curly braces. Other Markdown parsers are maruku (which has a Multiple lines for HTML <li>-tag issue) and kramdown (which is slow and does not handle fenced code blocks and LaTeX correctly). Similar to Matthias I would like to share a feature matrix of Markdown parsers included into Jekyll. I have used jekyll 1.4.3 to create the following table. I've used this page to see if fenced code blocks and pygments is working and that page for LaTeX. Everything was tested with this site . redcarpet rdiscount kramdown maruku LaTeX âœ“ âœ“ âœ“ ? Fenced code blocks âœ“ âœ“ ~ ? Pygments âœ“ âœ“ âœ“ ? Site generation 176.90s 165.41s 293.26s ? Kramdown destroyed some fenced code blocks (but not all) and maruku did not even compile my site at all. Linebreaks and newline Linebreaks are an issue. Sometimes I want to get a <br/> , sometimes I make linebreaks to make reading of the text files easier. It's basically this discussion . Currently, I'm not satisfied with the situation. I never had that problem with WordPress. WordPress simply created paragraphs just at the right location. Customization You can create custom Liquid filters , plugins and templates. Everything is quite easy. The Liquid templating language seems to be very similar to Django Templates (Python). Make the Website super-fast CSS Minification sudo gem install juicer juicer install jslint juicer install yui_compressor Images I've included small images as base64 (used this online tool ). According to caniuse it's quite save to use. Site Search Site search is a real problem. I've seen three solutions so far: Dynamic Search : You can add a dynamic part to your statically generated website. For example, I create a search/index.php and a SQLite database like it was described here . Static JavaScript : Create a JSON file or something similar and search dynamically with JavaScript in it. External Search Engines : You could use a search engine for searching your site, of course. Hosted by you: Commercial * Google Custom Search * Index Den : Has no direct support to parse your website PHP+SQLite JavaScript solutions One JavaScript solution I've found is lunr . This one is really bad as it copies the whole body to a json file. This json file has to be loaded before it works. But my posts total at the moment to 2MB. I'm pretty sure my readers don't want to wait until 2MB are downloaded. So this one does only work for smaller websites. Christan Fei's solution does only search in the title and category. Templates Jekyll uses Liquid as a templating language. It is similar to Django templates. Here is a short introduction to Liquid. A Sublime Text template is the following: <snippet> <content><![CDATA[ --- layout: post title: ${1:} author: Martin Thoma date: 2014-11-22 17:19 categories: - ${2:Cyberculture} tags: - ${3:Rating} featured_image: logos/${4:star.png} --- ${5:} ]]></content> <!-- Optional: Set a tabTrigger to define how to trigger the snippet --> <tabTrigger>---</tabTrigger> <!-- Optional: Set a scope to limit where the snippet will trigger --> <!-- <scope>source.python</scope> --> </snippet> Some tests Validation validator.w3.org : My site is HTML-valid. The error that this validator shows is caused by an bug inside of the validator itself. jigsaw.w3.org : My site is CSS-valid. Speed: Could be better... tools.pingdom.com PageSpeed 72 on mobile and 85 on desktop Accessiblity: wave.webaim.org Functional Accessibility Evaluator More: Mobile readyness Load test Alexa Google Structured Data Testing Tool : Test if google can extract the author from your blog posts Twitter card validator (more about Twitter cards ) Nibbler : This one tests quite a lot. I've also used LinkChecker to check if all new links are valid. I've found quite a lot of old links and replaced them with new links. Resources Setting up a custom domain with Pages Search a Jekyll-generated website Jekyll vs. Hyde - A Comparison Of Two Static Site Generators","tags":"The Web","title":"How to use Jekyll with GitHub"},{"url":"https://martin-thoma.com/how-to-check-if-a-point-is-inside-of-a-polygon/","text":"Suppose you have a with \\(n\\) sides. This is called a \\(n\\) -glon. Basics about polygones A \\(n\\) -glon can be defined by a list of \\(n\\) points. Note that the order is important: [A, B, C, D, E, F, G] != [A, B, C, D, F, E, G] I will not consider self-intersecting polygones for the following statements. I'm aware of them, but whenever you have a self-intersecting polygon you can create multiple polygones that cover the same area and don't intersect each other (some pairs might have a finite number of points in common, but not an infinite number). Is a point in a triangle / a rectangle It is quite easy to check weather a point is inside of a triangle or inside of a rectangle. I have already written an article about how to check if a point is inside of a rectangle . Is a point inside of a n-glon? Let \\(P\\) be a point and \\(N = [P_1, P_2, \\dots, P_n]\\) be a \\(n\\) -glon. It is now much more difficult to check if \\(P\\) is inside of \\(N\\) . The area-approach works for convex \\(n\\) -glons, but that's it. Count Crossing Line Segments However, you can try another approach which I have visualized in the following image: Check if P is inside of N When \\(P\\) is inside of \\(N\\) , every line \\(P_{1}P, P_{2}P, \\dots, P_{n}P\\) will cross the polygon lines \\(P_{1}P_2,P_{2}P_3, \\dots, P_{n}P_1\\) an even number of times. If P is outside, at least one of the lines \\(P_{i}P\\) will cross a polygon line \\(P_{j}P_{j+1}\\) once. This means, for every check you have to check \\(n&#94;2\\) pairs of line segments for crossings. How you can do that is explained in my article How to check if two line segments intersect . This algorithm is in \\(\\mathcal{O}(n&#94;2)\\) time complexity (it does need a constant amount of additional space). Triangularization When you have a lot of querys, you might want to divide your polygon into convex polygones. The easiest way to do this might be dividing \\(N\\) into triangles. That way, you can check for every triangle if \\(P\\) is inside of it. I assume that the number of triangles is not bigger than \\(n\\) . As the check is in constant time for one triangle, you would have an algorithm that needs \\(\\mathcal{O}(n)\\) time and space for its checks (+ some preprocessing which is done only once).","tags":"Code","title":"How to check if a point is inside of a polygon?"},{"url":"https://martin-thoma.com/word-error-rate-calculation/","text":"The Word Error Rate (short: WER) is a way to measure performance of an ASR . It compares a reference to an hypothesis and is defined like this: $$\\mathit{WER} = \\frac{S+D+I}{N}$$ where S is the number of substitutions, D is the number of deletions, I is the number of insertions and N is the number of words in the reference Examples REF: What a bright day HYP: What a day In this case, a deletion happened. \"Bright\" was deleted by the ASR. REF: What a day HYP: What a bright day In this case, an insertion happened. \"Bright\" was inserted by the ASR. REF: What a bright day HYP: What a light day In this case, an substitution happened. \"Bright\" was substituted by \"light\" by the ASR. Range of values As only addition and division with non-negative numbers happen, WER cannot get negativ. It is 0 exactly when the hypothesis is the same as the reference. WER can get arbitrary large, because the ASR can insert an arbitrary amount of words. Calculation Interestingly, the WER is just the Levenshtein distance for words. I've understood it after I saw this on the German Wikipedia: \\begin{align} m &= |r|\\\\ n &= |h|\\\\ \\end{align} \\begin{align} D_{0, 0} &= 0\\\\ D_{i, 0} &= i, 1 \\leq i \\leq m\\\\ D_{0, j} &= j, 1 \\leq j \\leq n \\end{align} $$ \\text{For } 1 \\leq i\\leq m, 1\\leq j \\leq n\\\\ D_{i, j} = \\min \\begin{cases} D_{i - 1, j - 1}&+ 0 \\ {\\rm if}\\ u_i = v_j\\\\ D_{i - 1, j - 1}&+ 1 \\ {\\rm(Replacement)} \\\\ D_{i, j - 1}&+ 1 \\ {\\rm(Insertion)} \\\\ D_{i - 1, j}&+ 1 \\ {\\rm(Deletion)} \\end{cases} $$ But I have written a piece of pseudocode to make it even easier to code this algorithm: WER calculation Python #!/usr/bin/env python def wer ( r , h ): \"\"\" Calculation of WER with Levenshtein distance. Works only for iterables up to 254 elements (uint8). O(nm) time ans space complexity. Parameters ---------- r : list h : list Returns ------- int Examples -------- >>> wer(\"who is there\".split(), \"is there\".split()) 1 >>> wer(\"who is there\".split(), \"\".split()) 3 >>> wer(\"\".split(), \"who is there\".split()) 3 \"\"\" # initialisation import numpy d = numpy . zeros (( len ( r ) + 1 ) * ( len ( h ) + 1 ), dtype = numpy . uint8 ) d = d . reshape (( len ( r ) + 1 , len ( h ) + 1 )) for i in range ( len ( r ) + 1 ): for j in range ( len ( h ) + 1 ): if i == 0 : d [ 0 ][ j ] = j elif j == 0 : d [ i ][ 0 ] = i # computation for i in range ( 1 , len ( r ) + 1 ): for j in range ( 1 , len ( h ) + 1 ): if r [ i - 1 ] == h [ j - 1 ]: d [ i ][ j ] = d [ i - 1 ][ j - 1 ] else : substitution = d [ i - 1 ][ j - 1 ] + 1 insertion = d [ i ][ j - 1 ] + 1 deletion = d [ i - 1 ][ j ] + 1 d [ i ][ j ] = min ( substitution , insertion , deletion ) return d [ len ( r )][ len ( h )] if __name__ == \"__main__\" : import doctest doctest . testmod () Explanation No matter at what stage of the code you are, the following is always true: If r[i] equals h[j] you don't have to change anything. The error will be the same as it was for r[:i-1] and h[:j-1] If its a substitution, you have the same number of errors as you had before when comparing the r[:i-1] and h[:j-1] If it was an insertion, then the hypothesis will be longer than the reference. So you can delete one from the hypothesis and compare the rest. As this is the other way around for deletion, you don't have to worry when you have to delete something.","tags":"Cyberculture","title":"Word Error Rate Calculation"},{"url":"https://martin-thoma.com/formatting-strings-python/","text":"In Python, you can use the following ways to format Strings: Print directly Printing them directly (just like printf in C ): birthday = 28 month = \"April\" year = 1990 print ( \"My birthday is the %i -th %s %i .\" % ( birthday , month , year )) The first string contains the rules how to format. %i means that the first argument in the following tuple should be interpreted as a integer. The second one %s should be interpreted as a string and the third one again as a integer. Save as string >>> a = \"Why is %i the answer?\" % 42 >>> a 'Why is 42 the answer?' Named formatting You might prefer named formatting: >>> \"{guy} loves {girl}.\" . format ( girl = \"Marie\" , guy = \"Martin\" ) 'Martin loves Marie.' You can also store this first in a dictionary an unpack it: >>> myDictionary = { \"girl\" : \"Marie\" , \"guy\" : \"Martin\" , \"other\" : \"Internet\" } >>> \"{guy} loves {girl}.\" . format ( girl = \"Marie\" , guy = \"Martin\" ) 'Martin loves Marie.' Date and Time You can format time any way you like, just look at this reference . Lists Question: I would like to print a list! How do I do that? Answer: Convert your list to a string >>> myList = [ 1 , 2 , 3 ] >>> print ( \"Your list: %s \" % ( str ( myList ))) Your list : [ 1 , 2 , 3 ] str and repr When you build your own objects, you should add an implementation for the method str and repr . The first one should return a string representation that is human readable of the object, the second one should return a string that identifies the object. Formatters %i Integer >>> print ( \" %i \" % ( 123 )) 123 %s String >>> print ( \" %s \" % ( \"Martin\" )) Martin %o Int as octal >>> print ( \" %o \" % ( 123.123 )) 173 %x Int as hexadecimal (lower case) >>> print ( \" %x \" % ( 123.123 )) 7 b %X Int as hexadecimal (upper case) >>> print ( \" %X \" % ( 123.123 )) 7 B %f Floating point >>> print ( \" %f \" % ( 123.123 )) 123.123000 %.2f Floating point with two decimal places >>> print ( \" %.2f \" % ( 123.123 )) 123.12 %e Floating point in scientific notation >>> print ( \" %e \" % ( 123.123 )) 1.231230e+02 %% Percent sign >>> print ( \" %i%% \" % ( 65 )) 65 % %6.2f Print a float with 2 decimal places. Add spaces if this has less than 6 characters. >>> print ( \" %6.2f \" % ( 65.123 )) 65.12 Columns my_list = [( 'Easybox 1234' , 54 , 'DC:9F:DB:B2:B1:1C' ), ( 'FRITZ!Box 6360 Cable' , 12 , '24:65:11:06:71:54' ), ( 'wkit-802.1x' , 15 , 'A0:D3:C1:9F:FF:11' )] header = u \"{0:<20}{1:>6}{2:>20}\" . format ( 'SSID' , 'Signal' , 'HwAddress' ) print ( header ) print ( \"-\" * len ( header )) for ssid , signal , hwaddress in my_list : print ( u \"{0:<20}{1:>6}{2:>20}\" . format ( ssid , str ( signal ) + '%' , hwaddress )) results in SSID Signal HwAddress ---------------------------------------------- Easybox 1234 54% DC:9F:DB:B2:B1:1C FRITZ!Box 6360 Cable 12% 24:65:11:06:71:54 wkit-802.1x 15% A0:D3:C1:9F:FF:11 Resources Format Specification Mini-Language Time formatting Pretty Print","tags":"Code","title":"Formatting Strings in Python"},{"url":"https://martin-thoma.com/fibonacci-recursion-decorators/","text":"I think everybody who learned something about recursion has seen the Fibonacci sequence: $$ f(n) := \\begin{cases} n &\\text{if } n \\leq 1\\\\ f(n-1) + f(n-2) &\\text{otherwise} \\end{cases} $$ The simplest solution to get this number is: def fib ( n ): if n < 2 : return n else : return fib ( n - 1 ) + fib ( n - 2 ) The problem is, of course, that the number of evaluations goes wild. Here is a table of the number of function calls n 0 1 2 3 4 5 6 7 8 9 10 20 calls 1 1 3 5 9 15 25 41 67 109 177 21891 To be exact, the number of calls of the fib-function is: $$ f(n) := \\begin{cases} 1 &\\text{if } n \\leq 1\\\\ f(n-1) + f(n-2) + 1 &\\text{otherwise} \\end{cases} $$ This means the dumb function is in \\(\\mathcal{O}(2&#94;n)\\) ! (I'm not quite sure, but this I think this is not only time complexity, but also space complexity. I think it is not tail recursive , so the complete stackframe has to be saved.) Memorization with decorators One way to solve the problem much faster (in fact in \\(\\mathcal{O}(n)\\) time and space complexity) by storing values we already calculated. A very neat way to achieve this are decorators. It might be a common problem that you have a recursive, mathematical function with no side effects. So you can write a wrapper that checks if the value has already been calculated. If not, the function proceeds as usual. It it has already been calculated, you can simply look it up: def memoize ( obj ): cache = {} def memoizer ( * args , ** kwargs ): if args not in cache : cache [ args ] = obj ( * args , ** kwargs ) return cache [ args ] return memoizer @memoize def fib ( n ): if n < 2 : return n else : return fib ( n - 1 ) + fib ( n - 2 ) Notice that I've only added @memoize over the function definiton of fib ! I love Python â˜º By the way, this formula has also some limitations. Python has a fixed maximum recursion depth. So fib(332) worked fine, but fib(333) gave: RuntimeError: maximum recursion depth exceeded in comparison You can get around this limitation by successive calls of fib: # Call to fill array fib ( 332 ) # The number of recursive steps is now much smaller: print ( fib ( 500 )) That gave 139423224561697880139724382870407283950070256587697307264108962948325571622863290691557658876222521294125. A pretty big number. Formula of Moivre-Binet The formula of Moivre-Binet gives a closed form for calculating fibonacci numbers: \\(\\varphi = \\frac{\\sqrt{5}+1}{2}\\) \\(\\psi = 1 - \\varphi\\) \\(f(n) = \\frac{\\varphi&#94;n - \\psi&#94;n}{\\phi - \\psi}\\) Although this is mathematically exact, it will not work on computers due to a fixed floating point precision. Lets check how long it works: #!/usr/bin/env python import functools def memoize ( obj ): cache = {} @functools.wraps ( obj ) def memoizer ( * args , ** kwargs ): if args not in cache : cache [ args ] = obj ( * args , ** kwargs ) return cache [ args ] return memoizer @memoize def fib ( n ): if n < 2 : return n else : return fib ( n - 1 ) + fib ( n - 2 ) def moivreBinet ( n ): phi = ( 5 ** 0.5 + 1 ) / 2 psi = 1 - phi return int (( phi ** n - psi ** n ) / ( phi - psi )) from itertools import count for i in count ( 0 ): exact = fib ( i ) constTime = moivreBinet ( i ) if exact != constTime : print (( \"The %i -th fibonacci number is %i . Moivre-Binet \" + \"gives due to precicion error %i (delta= %i ).\" ) % ( i , exact , constTime , abs ( exact - constTime ))) break So the answer is: The 72-th fibonacci number is 498454011879264. Moivre-Binet gives due to precicion error 498454011879265 (delta=1). This is a reason to prefer the \\(\\mathcal{O}(n)\\) solution over the \\(\\mathcal{O}(1)\\) solution. If you're only exact for 72 numbers, you could also simply store them. Looking number up form an array is always faster than any calculation. Very high numbers The following solution is fast and works 0.075 seconds for the 20000 Fibonacci number (which has 4180 digits). def fib ( n ): def accFib ( n , Nm2 = 0 , Nm1 = 1 ): for i in range ( n ): Nm2 , Nm1 = Nm1 , Nm1 + Nm2 return Nm2 return accFib ( n ) Additional ressources The article on literate programs is worth reading. They show some very different programs that calculate Fibonacci numbers.","tags":"Code","title":"Fibonacci, recursion and decorators"},{"url":"https://martin-thoma.com/programmierparadigmen-klausur/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žProgrammierparadigmen\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr. Snelting im Wintersemester 2013/2014 gehÃ¶rt. Behandelter Stoff Vorlesung Datum Kapitel Inhalt 23.10.2013 Funktionale Programmierung 10 Haskell: Quicksort, Listen, Filter , Cons-Operator 25.10.2013 Funktionale Programmierung 11 Haskell: filter, map, iter, foldr, foldl, Currying, ExtensionalitÃ¤tsprinzip, Kombinatoren (Summe, Produkt), flatten, cons, zip 30.10.2013 Funktionale Programmierung 12 Haskell: zipWith, short circuit evaluation, foldl, foldr, Unendliche Listen, Typen, Polymorphie 06.11.2013 Backtracking, Algebraische und rekursive Datentypen, map for trees, Typklassen 08.11.2013 Typklassen, Monaden 13.11.2013 Sichtbarkeitsbereich \\(\\subseteq\\) GÃ¼ltigkeitsbereich; \\(\\alpha\\) / \\(\\eta\\) -Ã„qivalenz, Redex; Funktion, die sich als eigenes Argument nimmt; \\(\\lambda\\) -KlakÃ¼l ist Turing-MÃ¤chtig 29.11.2013 Logische Programmierung Prolog 10.01.2014 Scala Kein ; , weniger verbose als Java, ... 15.01.2014 Scala Concurrency in Scala: Actors, react; MPI, OpenMP 22.01.2014 - X10: async, val, var 24.01.2014 - C ( volatile ) ÃœbungsblÃ¤tter Ãœbungsblatt Inhalt ÃœB 0 : Haskell Haskell installieren (siehe UbuntuUsers ), Maximum dreier Zahlen berechnen ÃœB 1 : Rekursive Funktionen in Haskell Potenzen, Primzahlen, Sortieren Tutorium 16.12.2013 let f = \\ x . plus x x in f ( f c_2 ) &#94;= ( \\ f . f ( f c_2 )) ( \\ x . plus x x ) let wird wegen dem Typsystem benÃ¶tigt ( let ist polymorph, \\(\\lambda\\) -Term nicht). let f = \\ x . 1 in ( f 7 ) + ( f [ \"a\" ]) &#94;= ( \\ f . ) ( \\ x . 1 ) f : \\ alpha_5 -> int f : \\ forall \\ alpha_5 . \\ alpha_5 \\ rightarrow int Material Inoffizielles Skript in A5 ( LaTeX-Quellen ): Wer das gerne fÃ¼r ca. 10 Euro in SW gedruckt mit Ringbindung hÃ¤tte, soll mir eine E-Mail schreiben Vorlesungswebsite und ÃœbungsblÃ¤tter Ein Anki-Deck (NICHT meines!) Stackexchange: What is the meaning of M âŠ¨ Ï†? How can I compile the x10 example? What is the difference of 'async' before or after 'for' in X10? How do I generate and print Fibonacci numbers in X10? What is the difference between ifne and ifnonnull? Haskell list comprehension - list of all list splits How can I ask questions on a family tree in Prolog? Klausurvorbereitung H-99: Ninety-Nine Haskell Problems P-99: Ninety-Nine Prolog Problems Scala S-99: Ninety-Nine Scala Problems Learning Scala by Joel Abrahamsson Ãœbungsbetrieb Wo sind die ÃœbungsblÃ¤tter: Link Abgabeform: auf Papier und via E-Mail Abgabe: Datum steht auf den ÃœbungsblÃ¤ttern; Ort: Kasten im Keller des Infobaus RÃ¼cknahme: im Tutorium Turnus: wÃ¶chentlich, erscheint am Donnerstag. Ãœbungsschein verpflichtend: Es gibt keinen Ãœbungsschein. Bonus durch Ãœbungsschein: Es gibt keinen Klausurbonus. Termine und Klausurablauf Siehe Klausurtermine-Seite fÃ¼r zukÃ¼nftige Termine (z.B. Programmierparadigmen am 23.09.2014 ) Datum : Donnerstag, den 10. April 2014 von 14:00 bis 16:00 Uhr ( Quelle ) Ort : Audimax ( Quelle ) Punkte : 120 Punkteverteilung : Vermutlich etwas in dieser Richtung: 25 Punkte: Haskell / Scala 20 Punkte: Logische Programmierung 25 Punkte: Typinferenz / Lambda-KalkÃ¼l 10 Punkte: C 10 Punkte: MPI 10 Punkte: X10 20 Punkte: Compilerbau Bestehensgrenze : ? Ãœbungsschein : Gibt es nicht. Bonuspunkte : Gibt es nicht. Ergebnisse : stehen seit dem 17.04.2014 fest Einsicht : am Mittwoch den 30.04.2014, 14:00 Uhr - 16:00 in Raum 010, Informatik GebÃ¤ude (Geb. 50.34) (bekanntgegeben Ã¼ber Vorlesungswebsite am 17.04.2014) Erlaubte Hilfsmittel : (siehe Website ) Erlaubte Hilfsmittel fÃ¼r die Klausur sind alle Quellen in Papierform, insbesondere Vorlesungsfolien der Veranstaltung Programmierparadigmen Ãœbungszettel und BeispiellÃ¶sungen der Veranstaltung Programmierparadigmen BÃ¼cher, Ausdrucke und beliebige eigenen Aufzeichnungen Ergebnisse Stehen seit dem 17.04.2014 fest. Kritik In der Vorlesung werden zu viele Inhalte behandelt. Eine Folge ist, dass nichts richtig behandelt werden. AuÃŸerdem erscheinen mir einige der Inhalte weder in der Wissenschaft noch in der Wirtschaft relevant zu sein (Prolog, X10). Ich wÃ¼rde vorschlagen diese Inhalte zu entfernen. Wenn man der Meinung ist, dass man ParallelitÃ¤t mehr behandeln sollte, dann wÃ¤re vermutlich CUDA deutlich wichtiger als X10.","tags":"German posts","title":"Programmierparadigmen Klausur"},{"url":"https://martin-thoma.com/working-terminal/","text":"I've just switched from Bash to ZSH because of oh-my-ZSH . I think this is just the right time to explain the words Shell, command line, Terminal, Bash and ZSH. Terminal is an terminal emulator, sometimes also called a \"terminal window\". I work in a window environment (MATE) and I want to use command line tools within that environment. So I need a \"terminal window\": Terminal Window with ZSH and Bash ZSH and Bash are both Unix shells. A shell is a command line interpreter that provides a text-based user interface. Command line describes the textual way you interact with the computer. When you're in a graphical user interface situation you interact by manipulating windows with your keyboard/mouse. When you're in a text-based user interface situation, you interact by entering commands in a line (hence command line). Solarized Dark Theme The Solarized Dark Theme is very good for command line. It can be installed like this as explained here : $ git clone https://github.com/oz123/solarized-mate-terminal.git $ cd solarized-mate-terminal $ ./solarized-mate.sh dark restart the terminal. Oh-my-ZSH Installation Oh-my-ZSH is a plugin for ZSH. I think this plugin is very good and makes a big difference to Bash. So when you look at the screenshots below, keep in mind that this is not a \"plain vanilla\" zsh. Install \" Oh-my-ZSH \" Install \" powerline fonts \" and change your Terminal font to one of them Change your Terminal theme to \"agnoster\" by setting ZSH_THEME=\"agnoster\" in ~/.zshrc Set your terminal theme to \"Solarized Dark\" ( description ) Make ZSH your default Shell in MATE Terminal ( description ) and eventually sudo chsh -s /usr/bin/zsh username ZSH and Bash Here are some differences. On the left side is zsh, on the right is bash: Bash vs zsh: cd command completion Bash vs zsh: Git prompt indicator Bash vs zsh: Spelling correction Bash vs zsh: time command I like the time command of bash more, but that's it. All other interactions are either almost the same or better in zsh. I especially like that zsh doesn't print everything again when you autocomplete with tab. And it also autocompletes when you make an capitalization error. I also begin to like the Git-specific prompt indicators: ZSH 'git add' indicator Some usefull tools ack You might already know grep . And if you've worked with it, you might already have typed something like the following: grep --exclude-dir = \".svn\" \"searchterm\" * grep -rI \"onlytextSearchterm\" . An alternative to grep is ack (for Ubuntu users: ack-grep ). See beyondgrep.com . Windows It seems to be possible to get something similar (the same?) for Windows. See OH MY CYGWIN .","tags":"Code","title":"Working with Terminal"},{"url":"https://martin-thoma.com/part-iii-matrix-multiplication-on-multiple-cores-in-python-java-and-c/","text":"This is Part III of my matrix multiplication series. Part I was about simple matrix multiplication algorithms and Part II was about the Strassen algorithm. Part III is about parallel matrix multiplication. We got some pretty interesting results for matrix multiplication so far. Now, I would like to get to know in how far performance increases (or decreases) if I make use of multiple cores. I only have two cores, so I hope somebody with a better computer will also run the ikj single core algorithm form part I and the parallel version from this article and post the results as a comment. The implementations As last time, I've added the scripts to a GIT repository . So you can test it on your machine. Before we start implementing code for multiple processors, we have to get an algorithm that is actually parallelisable. You could use Cannon's algorithm , a algorithm that makes use of systolic arrays or try to find a solution by your own. The Scalable Universal Matrix Multiplication Algorithm (short: SUMMA) could also work. The paper that I've linked is well-written and easy to understand. You should definitively read it, if you're interested in matrix multiplication. I will not use any advanced algorithm in this article. I will make the outer most for loop of the ikj-algorithm (see part I) execute in parallel. More about parallel matrix multiplication: Case Study: Matrix Multiplication berrendorf Algorithms for efficient matrix multiplication Coppersmith-Winograd algorith Python Because of global interpreter lock (GIL), you need to start new processes in Python ( source ). The ikj single core algorithm implemented in Python needs: time python ikjMultiplication.py -i 2000 .in > 2000 -nonparallel.out real 36m0.699s user 35m53.463s sys 0m2.356s The most simple way to parallelize the ikj algorith is to use the multiprocessing module and compute every line of the result matrix C with a new process. But for the 2000x2000-example, this would mean we started 2000 processes. The overhead is much worse than the benefit: time python ikjMultiplication.py -i 2000 .in > 2000 -parallel.out real 20m47.693s user 40m34.460s sys 0m2.092s When we share memory, the code looks like this: #!/usr/bin/python # -*- coding: utf-8 -*- import multiprocessing , numpy , ctypes def read ( filename ): lines = open ( filename , 'r' ) . read () . splitlines () A = [] B = [] matrix = A for line in lines : if line != \"\" : matrix . append ( map ( int , line . split ( \" \\t \" ))) else : matrix = B return A , B def printMatrix ( matrix , f ): for line in matrix : f . write ( \" \\t \" . join ( map ( str , line )) + \" \\n \" ) def lineMult ( start ): global A , B , mp_arr , part n = len ( A ) # create a new numpy array using the same memory as mp_arr arr = numpy . frombuffer ( mp_arr . get_obj (), dtype = ctypes . c_int ) C = arr . reshape (( n , n )) for i in xrange ( start , start + part ): for k in xrange ( n ): for j in xrange ( n ): C [ i ][ j ] += A [ i ][ k ] * B [ k ][ j ] def ikjMatrixProduct ( A , B , threadNumber ): n = len ( A ) pool = multiprocessing . Pool ( threadNumber ) pool . map ( lineMult , range ( 0 , n , part )) # mp_arr and arr share the same memory arr = numpy . frombuffer ( mp_arr . get_obj (), dtype = ctypes . c_int ) C = arr . reshape (( n , n )) return C def extant_file ( x ): \"\"\" 'Type' for argparse - checks that file exists but does not open. \"\"\" if not isfile ( x ): raise argparse . ArgumentError ( \"{0} does not exist\" . format ( x )) return x if __name__ == \"__main__\" : import argparse , sys from os.path import isfile from argparse import ArgumentParser parser = ArgumentParser ( description = \"ikjMatrix multiplication\" ) parser . add_argument ( \"-i\" , \"--input\" , dest = \"filename\" , required = True , type = extant_file , help = \"input file with two matrices\" , metavar = \"FILE\" ) parser . add_argument ( \"-o\" , \"--output\" , type = argparse . FileType ( mode = 'w' ), default = sys . stdout , dest = \"output\" , help = \"file to write output to (default=stdout)\" ) args = parser . parse_args () A , B = read ( args . filename ) n , m , p = len ( A ), len ( A [ 0 ]), len ( B [ 0 ]) threadNumber = 2 part = len ( A ) / threadNumber if part < 1 : part = 1 # shared, can be used from multiple processes mp_arr = multiprocessing . Array ( ctypes . c_int , n * p ) C = ikjMatrixProduct ( A , B , threadNumber ) printMatrix ( C , args . output ) and it needs MUCH more time: time python ikjMultiplication-shared.py -i 2000 .in > 2000 -parallel-2threads.out real 131m35.433s user 250m36.820s sys 0m9.533s When we don't use shared memory, things run faster: #!/usr/bin/python # -*- coding: utf-8 -*- import multiprocessing , numpy , ctypes def read ( filename ): lines = open ( filename , 'r' ) . read () . splitlines () A = [] B = [] matrix = A for line in lines : if line != \"\" : matrix . append ( map ( int , line . split ( \" \\t \" ))) else : matrix = B return A , B def printMatrix ( matrix , f ): for line in matrix : f . write ( \" \\t \" . join ( map ( str , line )) + \" \\n \" ) def lineMult ( start ): global A , B , C , part n = len ( A ) for i in xrange ( start , start + part ): for k in xrange ( n ): for j in xrange ( n ): C [ i ][ j ] += A [ i ][ k ] * B [ k ][ j ] def ikjMatrixProduct ( A , B , threadNumber ): n = len ( A ) pool = multiprocessing . Pool ( threadNumber ) pool . map ( lineMult , range ( 0 , n , part )) return C def extant_file ( x ): \"\"\" 'Type' for argparse - checks that file exists but does not open. \"\"\" if not isfile ( x ): raise argparse . ArgumentError ( \"{0} does not exist\" . format ( x )) return x if __name__ == \"__main__\" : import argparse , sys from os.path import isfile from argparse import ArgumentParser parser = ArgumentParser ( description = \"ikjMatrix multiplication\" ) parser . add_argument ( \"-i\" , \"--input\" , dest = \"filename\" , required = True , type = extant_file , help = \"input file with two matrices\" , metavar = \"FILE\" ) parser . add_argument ( \"-o\" , \"--output\" , type = argparse . FileType ( mode = 'w' ), default = sys . stdout , dest = \"output\" , help = \"file to write output to (default=stdout)\" ) args = parser . parse_args () A , B = read ( args . filename ) n , m , p = len ( A ), len ( A [ 0 ]), len ( B [ 0 ]) threadNumber = 2 part = len ( A ) / threadNumber if part < 1 : part = 1 C = [[ 0 for i in xrange ( n )] for j in xrange ( n )] C = ikjMatrixProduct ( A , B , threadNumber ) printMatrix ( C , args . output ) time python ikjMultiplication.py -i 2000 .in > 2000 -parallel-4threads.out real 22m46.066s user 41m42.396s sys 0m2.324s Java Shell.java: import java.io.BufferedReader ; import java.io.FileReader ; import java.io.IOException ; import java.util.LinkedList ; import java.util.List ; import java.util.ArrayList ; import java.util.concurrent.Callable ; import java.util.concurrent.ExecutionException ; import java.util.concurrent.ExecutorService ; import java.util.concurrent.Executors ; import java.util.concurrent.Future ; public class Shell { static List < ArrayList < ArrayList < Integer >>> read ( String filename ) { ArrayList < ArrayList < Integer >> A = new ArrayList < ArrayList < Integer >>(); ArrayList < ArrayList < Integer >> B = new ArrayList < ArrayList < Integer >>(); String thisLine ; try { BufferedReader br = new BufferedReader ( new FileReader ( filename )); // Begin reading A while (( thisLine = br . readLine ()) != null ) { if ( thisLine . trim (). equals ( \"\" )) { break ; } else { ArrayList < Integer > line = new ArrayList < Integer >(); String [] lineArray = thisLine . split ( \"\\t\" ); for ( String number : lineArray ) { line . add ( Integer . parseInt ( number )); } A . add ( line ); } } // Begin reading B while (( thisLine = br . readLine ()) != null ) { ArrayList < Integer > line = new ArrayList < Integer >(); String [] lineArray = thisLine . split ( \"\\t\" ); for ( String number : lineArray ) { line . add ( Integer . parseInt ( number )); } B . add ( line ); } br . close (); } catch ( IOException e ) { System . err . println ( \"Error: \" + e ); } List < ArrayList < ArrayList < Integer >>> res = new LinkedList < ArrayList < ArrayList < Integer >>>(); res . add ( A ); res . add ( B ); return res ; } static void printMatrix ( int [][] matrix ) { for ( int [] line : matrix ) { int i = 0 ; StringBuilder sb = new StringBuilder ( matrix . length ); for ( int number : line ) { if ( i != 0 ) { sb . append ( \"\\t\" ); } else { i ++; } sb . append ( number ); } System . out . println ( sb . toString ()); } } public static int [][] parallelMult ( ArrayList < ArrayList < Integer >> A , ArrayList < ArrayList < Integer >> B , int threadNumber ) { int [][] C = new int [ A . size ()][ B . get ( 0 ). size ()]; ExecutorService executor = Executors . newFixedThreadPool ( threadNumber ); List < Future < int [][]>> list = new ArrayList < Future < int [][]>>(); int part = A . size () / threadNumber ; if ( part < 1 ) { part = 1 ; } for ( int i = 0 ; i < A . size (); i += part ) { System . err . println ( i ); Callable < int [][]> worker = new LineMultiplier ( A , B , i , i + part ); Future < int [][]> submit = executor . submit ( worker ); list . add ( submit ); } // now retrieve the result int start = 0 ; int CF [][]; for ( Future < int [][]> future : list ) { try { CF = future . get (); for ( int i = start ; i < start + part ; i += 1 ) { C [ i ] = CF [ i ]; } } catch ( InterruptedException e ) { e . printStackTrace (); } catch ( ExecutionException e ) { e . printStackTrace (); } start += part ; } executor . shutdown (); return C ; } public static void main ( String [] args ) { String filename ; int cores = Runtime . getRuntime (). availableProcessors (); System . err . println ( \"Number of cores:\\t\" + cores ); int threads ; if ( args . length < 3 ) { filename = \"3.in\" ; threads = cores ; } else { filename = args [ 1 ]; threads = Integer . parseInt ( args [ 2 ]); } List < ArrayList < ArrayList < Integer >>> matrices = read ( filename ); ArrayList < ArrayList < Integer >> A = matrices . get ( 0 ); ArrayList < ArrayList < Integer >> B = matrices . get ( 1 ); int [][] C = parallelMult ( A , B , threads ); printMatrix ( C ); } } LineMultiplier.java: import java.util.ArrayList ; import java.util.concurrent.Callable ; public class LineMultiplier implements Callable < int [][]> { ArrayList < ArrayList < Integer >> A ; ArrayList < ArrayList < Integer >> B ; int start ; int end ; public int [][] C ; public LineMultiplier ( ArrayList < ArrayList < Integer >> a , ArrayList < ArrayList < Integer >> b , int s , int e ) { A = a ; B = b ; C = new int [ a . size ()][ b . get ( 0 ). size ()]; start = s ; end = e ; } @Override public int [][] call () { for ( int i = start ; i < end ; i ++) { for ( int k = 0 ; k < B . size (); k ++) { for ( int j = 0 ; j < B . get ( 0 ). size (); j ++) { C [ i ][ j ] += A . get ( i ). get ( k ) * B . get ( k ). get ( j ); } } } return C ; } } Execute it with only one thread: time java Shell -i 2000 .in 1 > 2000 -paralllel.out Number of cores: 2 0 real 0m40.571s user 0m42.259s sys 0m0.388s Execute it with two threads: time java Shell -i 2000 .in 2 > 2000 -paralllel.out Number of cores: 2 0 1000 real 0m30.188s user 0m54.999s sys 0m0.512s Note that real time is lower than user time. The reason is simply that the execution time on each processor is added. So user time might be double as high as real time! We got from 40.571s down to 0m30.188s! Information for parallelism Thread pools Java theory and practice: Thread pools and work queues StackOverflow C++ Making the ikj-algorithm parallel is trivial with C++. You only need to add #pragma omp parallel for before the outer most for loop and add -fopenmp as a compile flag! (If you really want to see the code, go to my Git repository .) $ time ./ikj-algorithm.out 2 2000 .in > 2000 -parallel.out real 0m12.563s user 0m20.569s sys 0m0.156s So we got from 20.407 seconds down to 12.563 seconds by adding only one line! More Information Guide into OpenMP: Easy multithreading programming for C++","tags":"Code","title":"Part III: Matrix multiplication on multiple cores in Python, Java and C++"},{"url":"https://martin-thoma.com/part-iv-how-to-multiply-matrix-with-its-transpose-in-python-and-c/","text":"This is Part IV of my matrix multiplication series. Part I was about simple implementations and libraries: Performance of Matrix multiplication in Python, Java and C++ , Part II was about multiplication with the Strassen algorithm and Part III will be about parallel matrix multiplication (I didn't write it yet). You can always multiply a matrix \\(J \\in \\mathbb{R}&#94;{n \\times m}\\) with its transpose \\(J&#94;T\\) , because \\(J&#94;T \\in \\mathbb{R}&#94;{m \\times n}\\) . You will get a matrix \\(C \\in \\mathbb{R}&#94;{n \\times n}\\) . Standard matrix multiplication of square matrices \\(\\in \\mathbb{R}&#94;{n \\times n}\\) is in \\(\\mathcal{O}(n&#94;3)\\) . With the Strassen algorithm you can multiply in \\(\\approx \\cal O(n&#94;{2.807})\\) . But this is for general matrix multiplication. When we do \\(J \\cdot J&#94;T\\) we have more structure, so it might be possible to do this multiplication faster. One important property of the result matrix \\(R = J \\cdot J&#94;T\\) is symmetry. So \\(R_{i,j} = R_{j,i}\\) . If we used the ikj-algorithm for this multiplication, we needed \\(n&#94;2 \\cdot m\\) operations. This way, we only need \\(\\frac{n&#94;2 +n}{2} \\cdot m\\) operations. Yes, I know, asymptotically it is irrelevant. But skipping almost half of the operations is still quite good. Python NumPy I guess doing this with NumPy is the best option: #!/usr/bin/python # -*- coding: utf-8 -*- import numpy from optparse import OptionParser parser = OptionParser () parser . add_option ( \"-i\" , dest = \"filename\" , default = \"2000.in\" , help = \"input file with two matrices\" , metavar = \"FILE\" ) ( options , args ) = parser . parse_args () def read ( filename ): lines = open ( filename , 'r' ) . read () . splitlines () J = [] for line in lines : J . append ( map ( int , line . split ( \" \\t \" ))) return numpy . matrix ( J ) def printMatrix ( matrix ): matrix = numpy . array ( matrix ) for line in matrix : print \" \\t \" . join ( map ( str , line )) J = read ( options . filename ) R = J * J . T printMatrix ( R ) Time: real 7m19.223s user 7m12.147s sys 0m2.388s When you want to do this in an application, you might want to use numpy.load . C++ First try #include <sstream> #include <string> #include <fstream> #include <iostream> #include <vector> #include <algorithm> using namespace std ; int getMatrixN ( string filename ) { std :: ifstream inFile ( filename . c_str ()); return std :: count ( std :: istreambuf_iterator < char > ( inFile ), std :: istreambuf_iterator < char > (), '\\n' ); } int getMatrixM ( string filename ) { string line ; ifstream infile ; infile . open ( filename . c_str ()); getline ( infile , line ); return count ( line . begin (), line . end (), '\\t' ) + 1 ; } void read ( string filename , vector < vector < double > > & A ) { string line ; FILE * matrixfile = freopen ( filename . c_str (), \"r\" , stdin ); int i = 0 , j ; double a ; while ( getline ( cin , line ) && ! line . empty ()) { istringstream iss ( line ); j = 0 ; while ( iss >> a ) { A [ i ][ j ] = a ; j ++ ; } i ++ ; } fclose ( matrixfile ); } vector < vector < double > > ikjalgorithmTranspose ( vector < vector < double > > & J , vector < vector < double > > & T , vector < vector < double > > & R , int n , int m ) { for ( register int i = 0 ; i < n ; i ++ ) { for ( register int k = 0 ; k < m ; k ++ ) { for ( register int j = i ; j < n ; j ++ ) { R [ i ][ j ] += J [ i ][ k ] * T [ k ][ j ]; } } } for ( register int i = 0 ; i < n ; i ++ ) { for ( register int j = 0 ; j < i ; j ++ ) { R [ i ][ j ] += R [ j ][ i ]; } } return R ; } void transpose ( vector < vector < double > > & A , vector < vector < double > > & B , int n , int m ) { for ( int i = 0 ; i < n ; i ++ ) { for ( int j = 0 ; j < m ; j ++ ) { B [ j ][ i ] = A [ i ][ j ]; } } } void printMatrix ( vector < vector < double > > & matrix , int n ) { for ( int i = 0 ; i < n ; i ++ ) { for ( int j = 0 ; j < n ; j ++ ) { if ( j != 0 ) { cout << \" \\t \" ; } cout << matrix [ i ][ j ]; } cout << endl ; } } int main ( int argc , char * argv []) { string filename ; if ( argc < 3 ) { filename = \"../Testing/5161x7058.in\" ; } else { filename = argv [ 2 ]; } int n = getMatrixN ( filename ); int m = getMatrixM ( filename ); vector < double > inner ( m ); vector < double > inner2 ( n ); vector < vector < double > > J ( n , inner ), T ( m , inner2 ), R ( n , inner ); read ( filename , J ); transpose ( J , T , n , m ); ikjalgorithmTranspose ( J , T , R , n , m ); printMatrix ( R , n ); return 0 ; } Time: real 5m31.488s user 5m27.560s sys 0m1.812s Direct multiplication One might think that transposing first is a bad idea, because you can do this: vector < vector < double > > ikjDirect ( vector < vector < double > > & J , vector < vector < double > > & R , int n , int m ) { for ( register int i = 0 ; i < n ; i ++ ) { for ( register int k = 0 ; k < m ; k ++ ) { for ( register int j = 0 ; j < n ; j ++ ) { R [ i ][ j ] += J [ i ][ k ] * J [ j ][ k ]; } } } return R ; } I stopped execution after 15 minutes.","tags":"Code","title":"Part IV: How to multiply matrix with its transpose in Python and C++"},{"url":"https://martin-thoma.com/how-to-install-arch-linux-20131001/","text":"I've watched the following video which explains pretty much everything there is to know: You might also want to read the Arch Linux Installation Guide . The German guide is also very good. I just like to add some notes. They are primarily for myself, so you really should read the installation guide or watch the video. The Arch Linux installation setup is command line based. Keyboard layout You can switch to a German keyboard layout with this command: loadkeys de Partitioning and mounting You need a bootable partition and a swap partition (that is at least as big as much RAM you have). Partitioning can be done with cfdisk (configure disk). Check the result with parted /dev/sda print fdisk -l Afterwards: mkfs.ext4 /dev/sda1 mkfs.ext4 /dev/sda3 mkswap /dev/sda2 swapon /dev/sda2 mount /dev/sda1 /mnt mkdir /mnt/home mount /dev/sda3 /mnt/home/ Getting internet I only have WLAN at the moment, which makes things more difficult: wpa_passphrase \"SSID\" PASSWORD > /etc/wpa_supplicant/wpa_supplicant.conf wpa_supplicant -i wlp4so -D wext -c /etc/wpa_supplicant/wpa_supplicant.conf -B dhcpcd wlp4s0 wlp4s0 is the wlan interface (which is wlan0 most of the time). You get it with ip link . I had a lot of fun at this point as you can see here . Install base system packstrap -i /mnt base base base-devel After accepting all defaults (by pressing enter) and letting it download: genfstab -U -p /mnt : sed 's/rw,realtime,data=ordered/defaults,realtime/' >> /mnt/etc/fstab arch-chroot /mnt nano /etc/locale.gen Uncomment your language (from now on, your promt should be \"sh-4.2#\"). locale = gen echo LANG = en_US.UTF-8 > /etc/locale.conf export LANG = en_US.UTF-8 ln -s /usr/share/zoneinfo/Europe/Berlin /etc/localtime hwclock --systohc --utc systemctl enable dhcpcd.service Now edit and uncomment multilib. Then: mkinitcpio -p linux Now set the password by entering passwd . Create your user: useradd -m -g users -G wheel -s /bin/bash moose passwd moose Synchronise caches: pacman -Syy Install grub: pacman -S grub-bios pacman -S os-prober grub-install /dev/sda grub-mkconfig -o /boot/grub/grub.cfg exit restart Give yourself sudo: pacman -S sudo nano /etc/sudoers Add your user to the bottom section \"User privilege specification\" Install GNOME pacman -S gnome xorg systemctl enable gdm.service MATE Add the following to your /etc/pacman.conf: [mate] SigLevel = Optional TrustAll Server = http://repo.mate-desktop.org/archlinux/$arch Run # pacman -Syy # pacman -S mate mate-extras Lets see if I get an answer to some essential basic questions .","tags":"Cyberculture","title":"How to install Arch Linux 2013.10.01"},{"url":"https://martin-thoma.com/projects-i-never-realized/","text":"The following is a collection of ideas for projects I had, but never realized. I would really love to do them, but they seem to be a little bit too time consuming to do them in my free time. Please send me an E-Mail if you would like to realize them! Book portal I really miss a book recommendation portal. It should allow you to mark books you've read or started to read, let you rate and tag books. The tags should be created by users, similar to the system StackExchange uses. Tags might be funny\", \"zombie\", \"magic\", \"romance\", \"love\", ... and users should rate for tags for books. In some general settings you define language(s) you know. Every book, which should be administrated by ISBN number if possible, should have information about the language. The portal should also see when books are only released with a new cover / collectors edition and notice that its the same story. With this information, it should recommend books and allow you to search books. Eventually you could connect to friends and let their ratings influence what you get. And, very important, it should let you follow series and/or authors. So you should be able to say \"When there is a new book of the 'Harry Potter' series, send me an e-mail!\" or \"When there is a new book of the 'Harry Potter' series translated to 'German', send me an e-mail!\". Science and Education Platform Sometimes, scientists get new insights that are able to influence millions. But until such a great invention or discovery is made, hundreds or thousands of people might have thought about the same problem. Today, with MOOCs education in some fields is quite open to a lot of people. Khan academy offers many very basic courses, Coursea and Udacity a few advanced ones. But the process of creating new content seems to be quite closed. Wikiversity is more open, but very limited. For example, I think it is not possible to include my graphic filter examples . And it is not possible to track progress of students. I think it is necessary to gamify this. Both, students and educators, should get rewards. They might be only digital, but a student who can see the progress he makes might be much more interested in continuing a course. A teacher who can see the influence he has, who can see how students learn and where problems are might be much better able to improve his content and be motivated to do so. Also, scientists should not have to worry about presenting their studies. A lot of people know how to create graphics, some people know better about (the English) language and others are experts in LaTeX. If people were able to create requests online, get rewards for helping others and provide rewards to show that they really need help, I guess much better research could be made. Of course, this should be open. For every unit / paper, there should be definitions what is necessary to know. The topics should automatically be linked to content that provides the knowledge. It is very complex to plan such a system, because education in different languages / nations might be very different and ideas how to educate vary a lot. Even subtasks (creating a LaTeX editor, a graph that shows influence of papers / books by citation, creating an image editor, creating a reward system) are very difficult. And everything has to scale for millions of users. This means you would have to plan quite a lot before you could even think about implementation. For this project, you would need: Somebody, who has experience with online courses. A teacher for children. A teacher for teenagers. A teacher for students. Somebody, who has experience with gamification. Somebody, who has contacts to politics and knows how to advertise. Advertisement Site I actually want advertisement. But I want also to easily keep track of it. I don't want to look at stuff just to see that the advertisment was old. And I don't want advertisment when I have lots to do and no time to buy things anyway. So giving people the possibility to go to a website and look at advertisment the way they want might be very interesting. Site for Documents Who wants to read all of the legal stuff we have to sign all the times? I would really like to have a website where standard contracts are. Some people read them and highlight the important stuff / the implications. A bit like tldrlegal.com , but not only for licenses. Wikipedia AI Try to categorize images in Category:Uncategorized images or find images that have the wrong category / missing categories. Translations I did some translation work some years ago for LordsAWar . From a software point of view, this was a pain in the ass. Rosetta (part of Launchpad, for Ubuntu) is much better. Another idea that is much better is Duolingo . getlocalization.com might also be worth a try. Wiki-like Dictionary Wikipedia is great, but the Wiktionaries suck. I would like to have a dictionary service. It should be working for all language combinations (English â†” German; English â†” French; German â†” French; ...). The data should initially be filled by computers, but then be improved / corrected by humans. Database It is basically a database with a nice interface. The database should have the following tables: Languages: LangID, Name in the language itself, icon Literature: LiteratureID, LangID, ISBN Words: WordID, Word, Normalized Occurences in Standard Literature WordPronounciation: WordPronounciationID, Pronounciation in phonetics, Pronounciation by a human Pronounciation by a human should be stored on Wikipedia Commons WordTags: WordTagID, Tag, Description in Markdown Examples: Adjective, Substantive, male, genitiv, past, medicine ... TagTag: TagTagID, TagID, TagTag, Description in Markdown Examples: Gender, Word-Class, Tense, Context, ... Tags2Words: T2WID, TagID, WordID Sentences: SentenceID, Sentence Words2Sentece: ID, SentenceID, WordID Definitions: ID, WordID, Definition, Image Images should be stored on Wikipedia Commons Translations: ID, WordID, TranslationID Note that translations don't have to be unique. There might be more than one correct translation for a word (e.g. \"Bank\") Note that some translations might be more appropriate, depending on the context. Users: UserID, DisplayName, E-mail, HashedPassword Initial Data Wiktionaries For nouns: Lemmas of articles Features Downloadable minimal dataset for language combinations (e.g. on your smartphone in case you don't have internet access). The most important words (2000 or so) should come with the audio data. Web search like dict.leo.org (e.g. example search ) Forum to ask for translations, given context. Discussion pages for entries Moderators to \"protect\" entries. Ranking to find most important words which need some human work Distributed, Universal Tagging System Tagging Most information can be displayed rather simple. A string that describes the kind of information and a bool / int / float / string / BLOB for the information itself and an identifier. For example, you can describe a product with the following labels: Identifier: \"898a4c822ffc456fa7a417e500b2c05a\" \"898a4c822ffc456fa7a417e500b2c05a\", \"ISBN-10\": \"0141439513\" (string) \"898a4c822ffc456fa7a417e500b2c05a\", \"ISBN-13\": \"978-0141439518\" (string) \"898a4c822ffc456fa7a417e500b2c05a\", \"Pages\": 480 (int) \"898a4c822ffc456fa7a417e500b2c05a\", \"Publisher\": \"Penguin Classics\" (string) \"898a4c822ffc456fa7a417e500b2c05a\", \"Category\": \"Book\" (string) \"898a4c822ffc456fa7a417e500b2c05a\", \"Category\": \"Literature\" (string) \"898a4c822ffc456fa7a417e500b2c05a\", \"Category\": ed054753e4b240a8aa1322ad348bf728 (identifier) \"898a4c822ffc456fa7a417e500b2c05a\", \"VIEW\": 0839c5beac414fb19c400b6ca0372388 (identifier) Identifier: \"ed054753e4b240a8aa1322ad348bf728\" \"ed054753e4b240a8aa1322ad348bf728\", \"Name\": \"Literature\" \"ed054753e4b240a8aa1322ad348bf728\", \"Category\": \"Books\" As you can see, it is possible to create nested categories with this structure. You an also create lists this way. Now clients should store information like this and share it. Views When information is presented like this, it is quite useless. But what about this kind of presentation: Pride and prejudice infobox (defined here ) Or, for example ark.intel.com : Intel Arc compare processors So another required feature of such a client are \"views\". A view is defined by an identifier (so that you can tag views just like any other object) and an HTML template. Objects could have labels called \"VIEW\" with type identifier that tell the client which view should be added. Distribution There are plenty of cool tools out there (Amazon recommendations, ark.intel.com to compare Intel processors, blackberry allows you to compare their phones, Wikipedia info boxes, ...). But most of them are very ristricted. For example, the way I compare smartphones is not fundamentally different from the way I compare processors. Yes, the attributes differ. But basically it is creating a table with all the information. Also, Intel does not provide information about AMD processors. So we need a way to get and share information. XML is the way-to-go for centralized computer systems. Maybe they can also be used to realize what I'm thinking about. But I think a problem that has to be solved is that we don't have a single source for all information that we trust in. We have networks of trust. When Intel says A and a friend says B about an Intel processor, I guess I will rather believe A. But when Intel does not provide some information about a processor and a friend says B, but a person I don't know says C, I'll believe B. But when thousands of people say C and my friend says B, I might rather believe C. It's getting complicated, right? Maybe the processor example is not good, as there is much information and information is either right or wrong. But lets say we talk about genre of movies. This might be much more difficult as there is no \"definitely right\" or \"definitely wrong\". Multiple answers might be right. So every information has also have to carry information about who thinks it is right. And you have to be able to define networks you trust in. Perhaps you could create \"people objects\" that can also be labeled. \"Your\" object had to be protected so that only you could add \"friend of\" labels or \"I trust\" labels or something like this. Python Code Search Do you know Debian Code Search ? Michael Stapelberg, the creator of it, described how he did it in his bachelor's thesis . I would like to have the same for Python code. This could be done by downloading all Python packages. I already did this part, see Analyzing PyPI Metadata and the follow-up post which is still on my TODO-list to be published (see draft ). It would also be possible to add GitHub repositories. Comment.it Sometimes, I just want to add my 2ct to something. I would like to have a central website / service - preferable as a browser plugin - with which I can add comments to other websites on an URL basis (including anchors for maximum exactness). Then I could read what other people think of something, even if there is no comments section. The comment should contain a very specific link. For some websites - like wikipedia - a permalink can be created. Others might change the content after a comment was made. For this reason a screenshot should be taken. Deep links help to make a comment to exactly what you mean. Help the user to use deep links. Identifiers besides URLs: Books have ISBN numbers. There are ISSN numbers. Other products have bar codes. People have lots of identifiers (names, ORCiD, e-mail). However, the possibility to add comments to a person should be examined carefully. They might not like it. They might not get useful comments / to much \"shitstorm\". They might also use legal means to prevent comments. To make comments more useful, gamification can be used: People have \"karma\". It represents the value they've added to the community. They start with 0 karma. At X karma, they get the \"trusted user\" rights. Everybody can add comments by default Moderators might restrict this to \"trusted users\" Only trusted users can add URLs within the comment. Upvotes for good comments Upvotes give karma to the creator of the comment You are only allowed to upvote when you are a trusted user Downvotes for bad comments Downvotes remove karma from the creator of the comment The downvoter gets also karma removed (to prevent bashing people) Users with more than 10 comments with less than -5 rating get soft deleted. Moderators can delete users if they are purely spam It is a \"soft delete\" Users can veto soft deletes. In this case they have to speak with a moderator, after they passed some Captchas. For reviews there are microformats which should be used. Charity Search & Find \"Vermittlung\" ( recruiting? ) of people who have the ability needed for charity organizations. People: profile / abilities Text, grade / level? tags? location Karma? Filtering Projects: Profile page for each project photos members / oranization / roles / karma / contributers domain Other elements: Forum: phpBB? Disqus? File uploads: Imgur? Calendar E-Mail list: GNU Mailman? Surveys: Limemonkey? Online CV A service to create an online CV. Manage your CV only in one place instead of many (LinkedIn, StackExchange, ORCiD, ResearchGate, ...). Sadly, many nice URLs are already gone: cv.me, its.me, about.me note.me, write.me, ping.me, help.me lookat.me Things to link: arXiv profile page http://dblp.uni-trier.de/ - http://dblp.uni-trier.de/pers/hd/t/Thoma_0001:Martin Job Portal for cheap jobs It seems to me that LinkedIn is mainly for high-paid jobs. However, \"cheap\" jobs like cleaning people or handymen are also looking for jobs Social Network like Facebook (Groups, pages, sharing, upvoting), but with Markdown. Bug Tracker for Users OpenID login Profiles for users Private: Contact data Public: name, biography Statistical: Links to bugs Software: id, name description url download_url source_url is_open_source license Bug title description software_id Monetarization: Offering Beta-Testers Official accounts to administrate bugs \"security status\" Educating users how to commit issues Screenshots: imgur.com Seach terms: QA (quality assurance), bugs Alternative Products: User Echo Database administration interface It would be nice to have a database administration interface similar to phpMyAdmin for other databases, too (postgres, sqlite). One could also make it a web service (dbadmin.io or something similar). Chrome I had some ideas how to improve Chrome . MATE After the changes in desktop environments, MATE got my favorite desktop environment. Although I was more happy with GNOME 2.6. Adding the drag-and-drop effect that creates a new window from an tab, known from Chrome, to Terminal and Pluma (gEdit). Creating a LaTeX plugin for Pluma that auto-completes the environments. LaTeX Tools I would like to create online tools (pure HTML/CSS/JavaScript) that make the following tasks simpler. A table editor. I know Trubens table tool , but this tool does not allow to combine cells. Also, the site is down quite often. A Ti k Z editor. An editor for bibliography. A LaTeX source code beautifier. A LaTeX-aware spell checker. This spell checker could probably use aspell, but it would have to filter LaTeX code. Also, I would like to create an app that helps users to create formulas. This app should run on smartphones and on tablets. I don't think that this can be done with pure JavaScript. Jabber Messaging App There are some commercial messangers which are wide-spread (WhatsApp, Facebook Messanger, Skype), some known secure messangers (Threema, Signal) and lots of other messangers (see Comparison of instant messaging clients , 2 ). However, there seems not to be a single client which has the following: Security Free Software Encryption of text messages Support of Android and iOS as well as a web interface Support of open protocolls (XMPP - see Comparison of instant messaging protocols ) Support of sharing pictures Support of sharing short audio messages Efficient voice calls Efficient video calls Text messaging features Emoticons UTF-8 Typing indicator Status: Message on server / Message on target client / Message read Open Hardware I'm fascinated by the idea of open hardware. That means that you publish plans of something and maybe also how to create it. Although I don't have any experience in this field, I can think of some interesting projects. One way to support open hardware would be to create an education and science platform, like the one I've described above. Open Internet I guess most smartphone users know this situation: You go to a friend / on vacation and you don't have WLAN. This means you have to use mobile internet, which is expensive. If you're in an area where not many people live, it is ok. If you're in a big city, it is not. There are so many people who have an internet connection and a router which already establishes a WLAN. You can see them, but not use the connection! What a shame! What we would need is a device with the following attributes: Simplicity It has to be a DSL modem and a router combined, eventually also a DSL filter . Everything has to be configurable via web interface. This interface has to be VERY GOOD. You should be able to get a backup file via web interface that contains every single configuration. This file should be an good documented XML file. The documentation should contain example data. Every setting should have its own url, just like in Google Chrome. As many self-tests that give meaningful messages as possible: A LED that indicates if the device has power. Ethernet jack should glow if a device is connected and blink if data is send. A software test via web interface that checks if internet connection is available. Direct feedback when you enter wrong / malformed credentials. A reset button that restores the software completely from non-erasable memory. Small memory and rechargeable battery that allows you to download router software updates when the battery is full. A user manual with pictures that explains what to do to get internet. Functionality and requirements It has to be able to create a WLAN. It has to be fast. I think currently 802.11n is with 450 Mbit/s the best you can get for WLAN and 1000 Mbit/s for Ethernet At least one Ethernet jack. It should be secure (WPA2, eventually don't support WEP and WPA). Reasonable energy consumption and no active fans. A standardized power supply unit that can be bought without buying a new device. Box - how it looks The case should be robust. You should be able to mount it to a wall or to lay it on the floor. I don't think it is necessary to support VoIP, ISDN and Surf Sticks. Now the special part: It should allow you to create a WLAN that others can use by registering in a service. The device should guarantee that you get the bandwidth, in case you need it. But if you have free bandwidth, others should be able to use it. Of course, this function should also protect you from legal trouble. An essential problem is keeping you from legal trouble while making sure that nobody uses the system to betray external users. But when you solve this problem, I guess it would be quite easy to establish free WLAN in all bigger cities. A great chance for tourism and a backup-option for you when your internet connection breaks. The service should also allow the user to register the free WLAN online. An app should download these locations and be able to navigate a user to the next free WLAN. Ah and of course everything in there should be free. This piece of hardware is critical for your internet access. If you want to be sure that you don't get under surveillance by an attack on this piece of hardware, it would be good to know that some smart people had the possibility to check if everything is fine with this hardware. Work computers Today, we have a lot of computers that are used for very, very simple work. The most computing intensive part might be large Excel sheets. So basically, they don't need any improvements in hardware for years. But the few things they do, need to be done well. Security is important. It is also important that things are stable and don't change a lot. And what they do should be fast. Loading times are almost not acceptable. I guess many tasks could be done within a browser. So work that needs heavy computation can be done on a stronger machine (the cloud - not necessarily outside of the company). Why hasn't any big company like General Motors , General Electric , Wallmart or even countries that have thousands of schools and government employees tried to create such a computer that is really reliable, robust and cheap (energy and because it can be produced it can be produced in very big numbers)? Here is what I think should be ok: processor with low power consumption (700 MHz or more) 2 GB of RAM (I guess you might now think of this missatributed Bill Gates quote ... but with cat /proc/meminfo you can see how much you currently use). 30 GB SSD: Important information should be stored on a computer that is protected very well against data loss. A SSD is silent and can read content very fast. Ideally, only the OS is stored on the employees computer. VERY silent fan, if possible non at all. Big monitor with high resolution, because those people have to work all day with the computer and low quality speakers. Good and silent keyboards (like the CODE keyboard ). Network card. Graphic card that allows the high resolution display. This is just a quick thought. I think such a system should contain some reference software that has to run fluidly. The software should also be open, of course. I think the following should be enough: Linux based OS (e.g. Debian ) Basic command line tools (bash, grep, find, cat, vim) Desktop manager with classic desktop metaphor (e.g. MATE ) File manager with access to a network drive (e.g. Caja or Nautilus) Modern Browser (Firefox or Chrome) Tasks that can (and should) be done via browser are: E-mails: e.g. Roundcube Excel: Hmmm ... I know that Google Docs offers some similar stuff. Bug I guess it can't replace Microsoft Excel by now. I don't know if there are any self-hosted services Word: e.g. Etherpad Outlook: e.g. OwnCloud LaTeX: e.g. FlyLaTeX Geographic information systems: I don't know if there is software online. But I guess with OpenStreetMaps it should not be too difficult to create it. ArcGis seems to be one solution. Basically, you can do almost everything with a web application. So the client can get quite slim. But although you could probably do everything with a self hosted client/server solution, those solutions don't always exist yet. Tasks that should not be done via browser might be: Professional video/audio editing: I guess you need more than one monitor to display all relevant information. Programming: Although I have seen Cloud9 , I doubt that programming in the cloud can be convenient in the next years. How does bug fixing work? How about manual testing? Whats with parallel execution? Messaging: If you want to use encrypted communication (e.g. E-mail with PGP) you should probably do the encryption on your machine. Hmmm ... astonishingly, I can currently not think of more tasks. Not so smart phone Do you remember the good old days when your cell phone wasn't essentially a small PC? I've bought a smartphone a while ago ( article ), but I still see reasons to have a cell phone: Battery life: My Motorola W156 had a battery with only 940 mAh, but 465 hours stand-by time. If it had 3100 mAh as the Samsung Galaxy Note II , it would have a standby time of 1534 hours! That are about 64 days! Security: Have you ever heard of somebody hacking a device that can only phone and send SMS? Cost: The Motorola W156 costs 25 Euro on Amazon. Robustness: A friend of mine put her Nokia 3310 accidentally in the washing machine. After that, she removed the battery, let it dry for a week, put the battery back. It worked. What the hell!?! (See also: Nokia is forever and Indestructible Nokia 3310 meme ) Size: Modern smartphones are a little bit uncomfortable to phone with. They are too big, although they are very thin. A size of 114 x 43 x 14 mm is fine, maybe a little bigger is also ok. The needed functionality is: Phone with good quality Send SMS (and repetedly try to do so if no net is available) Store about 100 contacts Save about 100 SMS Load battery via micro USB ( Common External Power Supply ) If not too complicated: Let me back up all data on the phone via this micro-USB slot and let me also restore such a backup 3.5mm phone jack for using a headset What is not needed: Camera, Flashlight Internet access, Bluethooth, NFC, ... Multi-colored display: B/W screen is just ok Fingerprint scanner Light Alarm Clock An alarm clock which wakes you up with light. Features: Set multiple alarms (Non-lit) display which shows the time time to the next alarm in X d - Y h - Z m format Batteries Be able to set multiple alarms: Choose days for which the alarm rings Choose dimming profile for the alarm (smooth - aprubt) Be able to change the (dimming) light which is inside Machine Learning Face recognition package I am not aware of any Python face recognition package, although I think face recognition is a very well-studied problem. There are a couple of web services (e.g. 1 , 2 , 3 ), but sometimes you don't want to send a company your photos. Or your application just needs to process too many pictures. There is also this repository , but even if you only put a hand in front of your eyes or tilt your head, it stops recognizing your head. So the aim of this project would be to build a Python package which allows recognition of faces in images, gives a good representation of those faces and allows to tell if two faces are the same or different (face verification). The api could be something like: import faces face_list = faces . get_face_locations ( 'some_photo.jpg' ) if len ( face_list ) >= 2 : if faces . is_same_person ( face_list [ 0 ][ 'representation' ], face_list [ 1 ][ 'representation' ]): print (( \"The person found at %s and the person found \" \"at %s are the same\" ) % ( face_list [ 0 ][ 'location' ], face_list [ 1 ][ 'location' ])) faces . save_overlay ( input = 'some_photo.jpg' , output = 'some_photo-overlay.jpg' , face_list ) Jarvis Basically a smart room Hardware: In the corners of the room: Microphones Cameras Speakers Lights Connected by WLAN Display (Beamer?) Software Activity recognition Objection recognition Applications Where did I put XY Record what I did at which time / how long in the month Write short emails / SMS Read out emails / SMS Make entries in calendar","tags":"Cyberculture","title":"Projects I never realized"},{"url":"https://martin-thoma.com/bitcoin/","text":"Bitcoin [...] is a cryptographic currency where the creation and transfer of bitcoins is based on an open-source cryptographic protocol that is independent of any central authority . Bitcoins can be transferred through a computer or smartphone without an intermediate financial institution. The concept was introduced in a 2008 paper by a pseudonymous developer known only as \"Satoshi Nakamoto\", who called it a peer-to-peer, electronic cash system . The processing of Bitcoin transactions is secured by servers called bitcoin miners. These servers communicate over an internet-based network and confirm transactions by adding them to a ledger which is updated and archived periodically using peer-to-peer filesharing technology. In addition to archiving transactions, each new ledger update creates some newly minted bitcoins. The number of new bitcoins created in each update is halved every 4 years until the year 2140 when this number will round down to zero. At that time no more bitcoins will be added into circulation and the total number of bitcoins will have reached a maximum of 21 million bitcoins . To accommodate this limit, each bitcoin is subdivided down to eight decimal places; forming 100 million smaller units called satoshis. In August 2013 Germany's Finance Ministry subsumed Bitcoins under the term \"unit of account\"â€”a financial instrumentâ€”though not as e-money or a functional currency. Although bitcoin is promoted as a digital currency, many commentators have criticized bitcoin's volatile exchange rate, relatively inflexible supply, high risk of loss, and minimal use in trade. Source: Wikipedia Sounds interesting, doesn't it? I'd like to share my thoughts about some aspects of Bitcoin. Please note that I'm neither an economics student, nor did I read the specifications of Bitcoin. Security of Bitcoin Data loss Once in a while, hard discs crash. If you're unlucky, you will lose all your data. This could mean you lose your Bitcoin wallet, so you lose your money. There is absolutely no way to get the money back. It's lost. Just like if you've lost bank notes in a big city. You will never get it back ( source ). BUT, unlike with bank notes, nobody else will get it. These Bitcoins are lost and nobody can do anything against that. I think that means after 2140 the number of active Bitcons will drop ! This is called a deflation with normal money. But as you can subdivide every bitcoin in as small pieces as you like, I'm not sure what this means for economy. Attacks When money is involved, there will always be people who try to profit from that. So you have to think about security of Bitcoins. System attacks For me, a system attack is an attack where somebody tries to break the system. He does NOT want to profit from the system, but he wants to harm all people who use it. The only attack I've found is a 51%-attack ( source ). This means, in long term you have to have more than 50% of the computing power of the total bitcoin network. So if there is a dramatic change in computing power, this might make Bitcoin as a system insecure. Also, in short term with much luck you might also take down the network with less computing power ( source ). But the more people participate, the more unlikely it gets. And this problem might our current system also have. If somebody manages to get MUCH more computing power, he could break encryption. This means, all bank transactions could at least be read by this attacker, if not manipulated. Theft Theft is possible by stealing your credentials. This can be done by infecting your computer with a virus, just like it can be done today with your bank account if you use online banking (or with the computers of banks, though that should be much more difficult). Also, the software you use for Bitcoin transactions might have errors. Money laundering It seems to be a big problem of Bitcoin that money laundering might be easy. You can't close a criminals account, you cannot stop criminals using Bitcoin for illegal operations. But what can you do with the current currency against that? Not much, when the money gets abroad. Credits You can't give credits as banks do it today with Bitcoin. If I understand it correctly, the \"Common Equity Capital Ratio\" has to be at least 3.5% in 2013 ( source ). In other words: banks are allowed to give more than 27x the amount of money they actually have! Now I'm very uncertain if I'm here correct, but I think this was an important reason why the financial crisis happened. This would not have been possible with Bitcoin! With Bitcoin, you can only give credit for money you currently have. No cent ... uhmm ... Sotisho more than that. BUT: I really don't know if this would be better. I guess it would be extremely difficult for states to get money. There would be the need of heavy restructuring in how we finance our countries. Interest A problem with credits in the Bitcoin-system would be that it is very difficult to estimate what the result of the interest would be. As there are \"only\" 21 million Bitcoins, it would bet possible that the sum of all dept is more than available Bitcoins. Can it be legal to force people to pay when you know that at least one technically can't pay at the end? This problem seems not to exist in the current system, as they always print new money. Wages At the moment, employed people have to fight in unions for more money. They really need it, because inflation happens all the time. So just to keep the current situation, employees have to do something. With Bitcoin, the situation might change. As we produce more and more every year, a deflation would be likely. This means, bosses would have to cut loans to keep the situation the same. But it is much more difficult to change the bills you pay. People will not blindly accept less money on their accounts per month. Unlike today, when people are basically ok when they get a compensation for inflation. See also Bitcoin.de : You can see how much 1 Bitcoin is worth in Dollar / Euro. bitcoin.stackexchange.com: What can we do if Bitcoin is used as money laundering? Will we ever need smaller amounts of Bitcoin than a Satoshi? On the Matter of Why Bitcoin Matters","tags":"Cyberculture","title":"Bitcoin"},{"url":"https://martin-thoma.com/apply-viterbi-algorithm/","text":"The goal of the Viterbi algorithm is find the most likely sequence of hidden states given some observed events. Lets say this is your HMM : A hidden Markov model (HMM) example We always start in \\(x\\) and always end in \\(z\\) . Now you observed the sequence \\(O_1 = BAB\\) . What is the most likely sequence that would generate this path? Candidates are: xxyz xyyz xyzz If you're learing this because you will write the exam at KIT, you might have such an diagram: Scheme of the Viterbi algorithm In this case, the bold path is the Viterbi path. You can see this when you get backwards from the last state: \\(\\frac{1}{125} \\cdot 1 \\cdot 0.2 > \\frac{9}{2500} \\cdot 0.8 \\cdot 0.2\\) . After this step, you only have one choice. So the Viterbi path is xyzz. Please note that there might be multiple paths with the highest possibility. As every state depends only on the state before, you can get the most likely path step by step. In every step, you calculate how likely it is that you end up in state x, state y, state z. After that, it doesn't matter how you got there. So you always have to expand those three nodes. You will get 9 following states, but only three of them matter (for each resulting state, the paths that had the highest probability leading there). See also Wikipedia","tags":"My bits and bytes","title":"How to apply the Viterbi algorithm"},{"url":"https://martin-thoma.com/calculate-histogram-equalization/","text":"Let's say you have the following greyscale image: \\(A = \\begin{pmatrix} 255 & 50 & 255\\\\ 0 & 50 & 50 \\end{pmatrix} \\) Histogram Now the histogram is a function \\(H: [0,255] \\rightarrow \\mathbb{N}_0\\) . The histogram of \\(A\\) is \\(H(x) := \\begin{cases} 1 &\\text{, if } x = 0\\\\ 3 &\\text{, if } x = 50\\\\ 2 &\\text{, if } x = 255 \\end{cases} \\) Accumulated histogram The accumulated histogram \\(H_\\alpha: [0,255] \\rightarrow \\mathbb{N}_0\\) is defined as \\(H_\\alpha(x) := \\sum_{i=0}&#94;x H(i)\\) This means, in the given example you get \\(H_\\alpha(x) := \\begin{cases} 1 &\\text{, if } x < 50\\\\ 4 &\\text{, if } 50 \\leq x < 255\\\\ 6 &\\text{, if } x = 255 \\end{cases} \\) Normalized histogram The normalized histogram is defined as \\(H_n(x) := \\mathrm{round}(\\frac{255}{w \\cdot h} \\cdot H_\\alpha(x))\\) where \\(w\\) is the width of the image and \\(h\\) is the height of the image. In our example it's: \\(H_n(x) := \\begin{cases} 43 &\\text{, if } x < 50\\\\ 170 &\\text{, if } 50 \\leq x < 255\\\\ 255 &\\text{, if } x = 255 \\end{cases} \\) So the resulting image is \\(A = \\begin{pmatrix} 255 & 170 & 255\\\\ 43 & 170 & 170 \\end{pmatrix} \\) See also Some code Code and examples","tags":"My bits and bytes","title":"How do I calculate a Histogram equalization?"},{"url":"https://martin-thoma.com/calculations-with-quaternions/","text":"Quaternions are an expansion of the concept of complex numbers on structures with four (instead of two) components. A quaterion \\(h\\) can be written as a vector or in the form of \\(h = h_0 + ih_1 + j h_2 + kh_3\\) , where \\(i, j\\) and \\(k\\) are related to the \\(i\\) in complex numbers. Accordingly \\(h_0\\) is often called real part and h_1, h_2, h_3 are called imaginary part of a quaternion. For \\(i, j\\) and \\(k\\) the following rules are applied: \\(i&#94;2 = j&#94;2 = k&#94;2 = -1\\) and \\(ijk=-1\\) Basic rules From these rules follows: \\begin{align} ij &= k\\\\ ji &= -k\\\\ jk &= i\\\\ kj &= -i\\\\ ki &= j\\\\ ik &= -j \\end{align} ( proof ) Multiplication Now, obviously quaternions multiplication is not commutative: \\(ij = k \\neq -k = ji\\) But for numbers in \\(\\mathbb{R}\\) , it is commutative ( proof ). The multiplication is: \\begin{align} x y &=( x_0 y_0 - x_1 y_1 - x_2 y_2 - x_3 y_3)\\\\ &+( x_0 y_1 + x_1 y_0 + x_2 y_3 - x_3 y_2) \\mathrm i\\\\ &+( x_0 y_2 - x_1 y_3 + x_2 y_0 + x_3 y_1) \\mathrm j\\\\ &+( x_0 y_3 + x_1 y_2 - x_2 y_1 + x_3 y_0) \\mathrm k \\end{align} Calculating multiplicative inverse This means, when you're given an element \\(x = x_0 + x_1 \\mathrm i + x_2 \\mathrm j + x_3 \\mathrm k\\) its inverse \\(y\\) can be calculated by solving the following linear system of equations: \\begin{align} x_0 y_0 - x_1 y_1 - x_2 y_2 - x_3 y_3 &= 1\\\\ x_0 y_1 + x_1 y_0 + x_2 y_3 - x_3 y_2 &= 0\\\\ x_0 y_2 - x_1 y_3 + x_2 y_0 + x_3 y_1 &= 0\\\\ x_0 y_3 + x_1 y_2 - x_2 y_1 + x_3 y_0 &= 0\\\\ \\end{align} which can be written as: $$\\left(\\begin{array}{cccc|c} x_0 & -x_1 & -x_2 & -x_3 & 1\\\\ x_1 & x_0 & -x_3 & x_2 & 0\\\\ x_2 & x_3 & x_0 & -x_1 & 0\\\\ x_3 & -x_2 & x_1 & x_0 & 0 \\end{array}\\right).$$ According to mathworks it is \\(y = \\frac{x_0 - \\mathrm i x_1 - \\mathrm j x_2 - \\mathrm k x_3}{x_0&#94;2 + x_1&#94;2 + x_2&#94;2 + x_3&#94;2}\\) More Conjugate Just like the complex conjugate is defined as \\(\\overline{z} = a - ib\\) with \\(z=a+ib\\) the conjugate of quaternions is defined as \\(\\bar x := x_0-x_1\\mathrm i-x_2\\mathrm j-x_3\\mathrm k\\) with \\(x=x_0+x_1\\mathrm i+x_2\\mathrm j+x_3\\mathrm k\\) Rotating points Quaternions can be used to rotate points. It works like this: \\(x' = q x \\overline{q}\\) Pretty simple, isn't it? For example, if you had the point (2,0,0) and you wanted to rotated it by \\(q = (\\frac{\\sqrt{2}}{2}, 0, \\frac{\\sqrt{2}}{2}, 0)\\) you would transform (2,0,0) to (2i+0k+0j) and calculate \\begin{align} x' &= q x \\overline{q}\\\\ &= (\\frac{\\sqrt{2}}{2}+\\frac{\\sqrt{2}}{2} \\mathrm j) \\cdot 2 \\mathrm i \\cdot (\\frac{\\sqrt{2}}{2} - \\frac{\\sqrt{2}}{2} \\mathrm j)\\\\ &= (\\sqrt{2} \\mathrm i + \\sqrt{2} \\mathrm{ji}) \\cdot (\\frac{\\sqrt{2}}{2} - \\frac{\\sqrt{2}}{2} \\mathrm j)\\\\ &= (\\sqrt{2} \\mathrm i - \\sqrt{2} \\mathrm k) \\cdot (\\frac{\\sqrt{2}}{2} - \\frac{\\sqrt{2}}{2} \\mathrm j)\\\\ &= \\mathrm i - \\mathrm{ij} - \\mathrm k + \\mathrm{kj}\\\\ &= \\mathrm{i - k -k - i}\\\\ &= -2 \\mathrm k\\\\ &\\Rightarrow x' = (0,0,-2) \\end{align} Rotation matrix to quaternion Let \\(M\\) be a rotation matrix and \\(m_{ij}\\) be an entry of this matrix. General rule \\begin{align} s &= \\frac{1}{2} \\sqrt{1 + \\sum_{i=1}&#94;3 m_{ii}}\\\\ x &= \\frac{m_{32} - m_{23}}{4s}\\\\ y &= \\frac{m_{13} - m_{31}}{4s}\\\\ z &= \\frac{m_{21} - m_{12}}{4s} \\end{align} resulting in the quaternion \\((s, x, y, z)\\) . Special rule A rotation matrix $$R_y = \\begin{pmatrix} \\cos(\\theta) & 0 & \\sin(\\theta)\\\\ 0 & 1 & 0\\\\ -\\sin(\\theta) & 0 & \\cos(\\theta) \\end{pmatrix}$$ can be transformed to a quaternion \\(q = (\\cos(\\frac{\\theta}{2}), \\vec u \\sin (\\frac{\\theta}{2}))\\) where \\(\\vec u\\) describes the axis you rotate by. In this case \\(R_y\\) is the y-axis, so $$\\vec u = \\begin{pmatrix}0\\\\1\\\\0\\end{pmatrix}$$ .","tags":"Mathematics","title":"Calculations with quaternions"},{"url":"https://martin-thoma.com/informatik-am-kit/","text":"Ich werde immer wieder gefragt, wie Informatik am KIT ist. Was kann ich Ã¼ber Karlsruhe erzÃ¤hlen? Wieviel Praxis bekommt man in einem Informatik-Studium am KIT? Leider denke ich nicht, das ich wirklich gut darÃ¼ber schreiben dann, da ich nur â€žInformatik I\" an der Uni Augsburg gehÃ¶rt habe. Sonst war ich nur am KIT. Auch Ã¼ber Karlsruhe kann ich nicht so viel erzÃ¤hlen, wie man sich vielleicht denkt. Ich bin meistens am studieren. Daher habe ich von Karlsruhe auÃŸerhalb der Innenstadt bisher wenig gesehen. Ein paar Anhaltspunkte kÃ¶nnte die Wikipediaseite des KIT sowie die einstieg-informatik.de-Seite geben. Genug allgemeines bla-bla. Nun lasse ich die Disclaimer-SÃ¤tze (meinem Eindruck nach, ich kenne eigentlich nur das KIT und habe keine aussagekrÃ¤ftigen Vergleiche, ...) weg und erzÃ¤hle etwas Ã¼ber Karlsruhe und das KIT. Das Studium Allgemeines Die Regelstudienzeit des Bachelor-Informatik-Studium betrÃ¤gt 6 Semester und 180 ECTS . Davon sind 15 ECTS fÃ¼r die Bachelor-Arbeit, 6 ECTS fÃ¼r Softskills (z.B. Sprachkurse und verpflichtent 2 ECTS fÃ¼r Teamarbeit in der Softwareentwicklung) und folgende Plicht-Kurse vorgesehen: Lehrveranstaltung ECTS Weitere Links 1. Semester Grundbegriffe der Informatik 4 Programmieren 5 Mein Tutorium HÃ¶here Mathematik I 9 Lineare Algebra I 9 2. Semester Algorithmen I 6 Softwaretechnik I 6 Rechnerorganisation 6 HÃ¶here Mathematik II 6 Lineare Algebra II 5 3. Semester Theoretische Grundlagen der Informatik 6 Praxis der Software-Entwicklung (PSE) 6 Betriebssysteme 6 Digitaltechnik und Entwurfsverfahren 6 Wahrscheinlichkeitstheorie und Statistik 4.5 4. Semester Datenbanksysteme 4 Rechnernetze 4 Numerik 4.5 5. Semester Algorithmen II 6 Programmierparadigmen 6 6. Semester Bachelorarbeit 15 $\\sum$ 124 Ich habe â€ž Analysis I+II \" anstelle von â€žHÃ¶here Mathematik I+II\" und â€ž Lineare Algebra und analytische Geometrie I+II \" anstelle von â€žLineare Algebra I+II\" gehÃ¶rt. Das sind die Mathematiker-Kurse. Wie ihr nun erkannt haben werdet, bleiben \\(180 - 124 - 6 = 50\\) Ã¼brig. Da ich die Mathematiker-Kurse gemacht habe (die jeweils 9 ECTS anstelle von 5 und 4 geben), bei mir sogar nur 41 ECTS. Davon muss man zwei Stammmodule fÃ¼r jeweils 6 ECTS machen. Dann sind es nur noch \\(50-2 \\cdot 6 = 38\\) ECTS. Die Praxis der Softwareentwicklung (PSE) ist Ã¼brigens eine tolle Sache am KIT-Informatik-Studium. Dort sucht man sich aus einer vorgegebenen Auswahl an Projekten eines aus. Dieses bearbeitet man in einer Gruppe von 5 Studenten fÃ¼r ein halbes Jahr. Ich habe an einem Projekt des Frauenhofer Instituts gearbeitet, das sich UpToDatE (Upload automation and data entry) nannte. Mal schauen, vielleicht schreibe ich mal etwas darÃ¼ber. Stammmodule Computergraphik Echtzeitsysteme Formale Systeme Kognitive Systeme Rechnerstrukturen Sicherheit Softwaretechnik II Telematik Proseminare Die Informatik-Proseminare sind leider sehr schlecht organisiert. Ich habe auf GitHub ein Ã¶ffentliches Repository, wo ihr hoffentlich aktuelle Informationen Ã¼ber Info-Proseminare finden (bzw. auch eintragen) kÃ¶nnt. Softstkills Von den 6 ECTS fÃ¼r Softskills sind ja schon 2 verpflichtend in Teamarbeit fÃ¼r die Softwareentwicklung (TSE - gehÃ¶rt zu PSE). Das ist nur ein Kniff mit dem Modulhandbuch, weil man wohl kein Stammmodul mit 8 ECTS machen konnte / wollte, also hat man PSE mit 6 ECTS und 2 ECTS fÃ¼r TSE. Praktisch bedeutet PSE auch so viel Arbeit, dass 8 ECTS angebracht sind (eher sogar mehr) und man muss im Team arbeiten. Man bekommt die Punkte also nicht geschenkt, aber man muss auch nichts auÃŸerhalb von PSE dafÃ¼r machen. Von den 4 Ã¼brigen Punkten kann man sich aus vielen interessanten Kursen des HOC etwas aussuchen, z.B. Kurse des Sprachenzentrums . Diese sind deutlich besser als die Sprachkurse in der Schule. Ich habe mich fÃ¼r English C1: Advanced entschieden. Da ich aber auch ein Tutorium gehalten habe (was 4 ECTS und 8,67 Euro/Stunde gibt), hÃ¤tte ich das nicht machen mÃ¼ssen. Der Kurs war aber so toll, dass ich es nicht bereue. Weitere Kurse Ich habe folgendes belegt: Web-Engineering 4 Algorithmen fÃ¼r planare Graphen 5 SEHR viele weitere Kurse sind im Modulhandbuch zu finden. Hier ist Ã¼brigens mal ein AbhÃ¤ngigkeitsgraph zum KIT-Bachelor-Informatik: AbhÃ¤ngigkeiten im Bachelor-Informatik Studium am KIT Es ist am KIT als Informatiker Ã¼brigens sehr leicht eine HiWi-Stelle zu finden. ErgÃ¤nzungsfÃ¤cher Man kann am KIT aus einer FÃ¼lle von NebenfÃ¤chern ErgÃ¤nzungsfÃ¤chern wÃ¤hlen: Elektro- und Informtionstechnik Maschinenbau Mathematik Physik Grundlagen des Rechts Volkswirtschaftslehre Betriebswirtschaftslehre Operation Research Auf Anfrage kann man aber wohl noch weitere machen. So studiert ein Bekannter in Richtung Medizinische Bildgebungsverfahren einiges. Mathematik Proseminar 3 Mein Vortrag zum Proseminar Diskrete Mathematik EinfÃ¼hrung in die Algebra und Zahlentheorie 9 Topologie und Geometrie 9 Man kann noch Analysis III und Funktionalanalysis / HilbertrÃ¤ume machen und vermutlich geht noch viel mehr, wenn man nachfragt. Sonstiges Das KIT hat eine 24h-Bibliothek (ja, die ist wirklich 24h offen, auch Sonntags. Meines Wissens macht die nur an Weihnachten zu), die ATIS (tolle LernrÃ¤ume, viele Computer, Drucker, ein Scanner), ein Rechenzentrum . Der Campus ist zusammenhÃ¤ngend. Das, was als â€žCampus Nord\" bezeichnet wird ist ein Forschungsbereich. Dort werden keine Vorlesungen gehalten. FÃ¼r Bachelor-Studenten ist der Campus Nord also irrelevant, auÃŸer ihr wollt da einen Job. Tipps zum Studium Ganz unbescheiden: Mein Blog ist toll â˜º Nein, im ernst, wenn du etwas vom Mathe-Stoff nicht verstehst, kann ich dir nur empfehlen mal rein zu schauen und vielleicht die Tags â€ž linear algebra \" oder â€ž analysis \" zu durchstÃ¶bern. Ich blogge zu relativ vielen Themen, mal auf Deutsch und manchmal auf Englisch, die meistens fÃ¼r einen KIT-Informatik-Studenten von Interesse sind. Eventuell ist auch meine kleine Linkliste interessant. Mathe ist interessant , aber wohl nicht jedermanns Sache. Ich denke ein guter Informatiker sollte auch gute Mathe-Kenntnisse haben. Noch kann ich nicht beurteilen, ob sich fÃ¼r mich das Besuchen der Mathe-Kurse (+Klausuren) gelohnt hat. Es war auf jeden Fall deutlich schwerer. Aber ich bin davon Ã¼berzeugt, dass es sich lohnen wird. Bleib am Ball : Gerade in Mathe - egal ob Analysis oder HM - muss man immer versuchen am Ball zu bleiben. Vorbereitung (das Kapitel im Skript lesen) und Nachbereitung (am Abend kurz aufschreiben: Was wurde gemacht? Und dann kontrollieren: Kann ich das auch?) lohnen sich. Bzw., ich habe das im 2. Semester nicht gemacht und es hat sich bei der Klausurvorbereitung gerÃ¤cht. Die ersten Vorlesungen sind besonders wichtig. In fast allen gibt es ein gutes Skript, das auch online ist. Fast Ã¼berall wird genau das Skript gemacht, nicht mehr und nicht weniger. Aber manchmal werden Dinge im Skript eher betont oder vielleicht etwas genauer erklÃ¤rt/ein Beispiel mehr gemacht. Also: Skript direkt am Anfang ausdrucken und immer mitnehmen. Drucken : Bis auf die Skripte wÃ¼rde ich alles in der ATIS (und nicht im SCC) drucken. Du solltest nach der O-Phase beide Accounts haben. ÃœbungsblÃ¤tter : Es lohnt sich, die ÃœbungsblÃ¤tter ordentlich zu machen. Sie sind, neben Altklausuren, die beste Klausurvorbereitung. Also: Mache deine LÃ¶sungen kleinschrittig, eventuell mit ErklÃ¤rungen die du in einem Semester nutzen kannst, schreibe sie sauber auf und mach alle. Egal wie schwer sie sind oder wie wenig Zeit du hast. Das wird - im 2. Semester - anstrengend, aber es lohnt sich. Also nicht nur auf die Punkte schauen, die du fÃ¼r den Ãœbungsschein brauchst, sondern auch an die bevorstehende Klausur denken. FAQ Frage : Ich kann nich programmieren. Ist das schlimm? Antwort : Nein! Am KIT lernt man alles von Grund auf. In â€žProgrammieren\" lernt man Java, in â€žBetriebssysteme\" grundlegendes C, in â€žPSE\" - je nach dem was man macht - C++, Java, C#, in â€žSWT I\" grundlagen Ã¼ber paralleles Programmieren mit Java. Frage : Wie Praxisnah ist das Studium? Antwort : Kommt darauf an, was man spÃ¤ter machen will und was man als Vergleich nimmt. Vermutlich sind die Fachhochschulen nÃ¤her an der Praxis, wenn man auf reines Programmieren hinaus will. Aber wenn ihr einfach nur im Beruf programmieren wollt, mÃ¼sst ihr nicht studieren. Vielleicht macht dann eine Ausbildung mehr Sinn. Frage : Was lernt man in der Informatik, wenn nicht Programmieren? Antwort : Vieles. Algorithmen und Datenstrukturen, wie genau ein Rechner von einzelnen Transistoren, Ã¼ber Schaltungen, Schaltwerke, Maschinencode und Assembler funktioniert, was theoretische Berechnungsmodelle sind, was Ã¼berhaupt berechenbar ist, wie Computer lernen kÃ¶nnen, wie man mit Ungenauigkeit in Berechnungen umgeht, wie man Programme/Probleme sinnvoll strukturiert, was Sicherheit in der Informatik ist und wie man verschiedene Sicherheitsbegriffe zeigen kann... Frage : Was ist charakteristisch fÃ¼r die Informatik am KIT? Antwort : Das KIT hat eine groÃŸe Informatik-FakultÃ¤t. Wenn man hier Informatik zu studieren beginnt, kann man sich in alle (oder zumindest viele) Richtungen weiterentwickeln. AuÃŸerdem ist das Informatik-Studium am KIT sehr Mathematik-lastig. Frage : Ich wÃ¼rde gerne XYZ lernen, aber das steht nicht im Modulhandbuch. Kann ich das trotzdem am KIT lernen? Antwort : Es gibt einen E-Mail-Verteiler fÃ¼r Studenten. Dort kann man einfach mal fragen, ob andere auch interesse daran haben. AuÃŸerdem gibt es Hochschulgruppen . Bei Ã¼ber 3000 Studenten wird sich schon jemand finden, der auch XYZ machen will / es kann. Karlsruhe Am KIT werden immer wieder interessante VortrÃ¤ge gehalten, z.B. Google Tech Talk: JavaScript and V8 - A functional-ish language and implementation in the mainstream TalKIT Weitere Es gibt den Science Slam Karlsruhe , Physik am Samstag und sehr viele weitere Veranstaltungen . Falls man mehr Ã¼ber Karlsruhe wissen will: Auch dazu gibt es einen Wikipedia-Artikel . Wohnungen Tja, eine Wohnung zu finden ist in Karlsruhe schwer. Mit der Wohnungssuche sollte man sehr frÃ¼h beginnen. Es gibt zwar einige Wohnheime , aber auch die sind voll. Und die QualitÃ¤t der Wohnheime ist sehr unterschiedlich. Ich habe gehÃ¶rt, dass das HaDiKo und die Insterburg nicht so toll sind, aber das an der WaldhornstraÃŸe soll sehr gut sein. Es gibt neben den Wohnheimen in dieser Liste noch mindestens eine weiteres (das evangelische Studentinnen-Wohnheim in RÃ¼purr). Die zentralen Wohnungen sind meistens Altbauwohnungen. Ich habe meine Ã¼ber studenten-wg.de gefunden. Allgemein gilt jedoch: Umso frÃ¼her man sucht, umso besser. FÃ¼r einen Eindruck von Karlsruhe kann man sich meine Photo-Spheres anschauen.","tags":"German posts","title":"Informatik am KIT"},{"url":"https://martin-thoma.com/gedanken-zur-bundestagswahl-2013/","text":"Am 22. September 2013 findet die Bundestagswahl 2013 statt. Worum geht es? Parteien Ich werde jeweils zwei Videos verlinken. Eines von â€žMrWissen2go\" und einen Wahlwerbespot der Parteien selbst. Die Parteien sind aufsteigend nach vermutlichem Ergebnis geordnet. Piraten Mitgliederzahl 31.669 DurchÂ­schnittsÂ­alter 38,9 Jahre FrauenÂ­anteil ca. 5â€“15 Prozent Themen Transparenz Bedingungsloses Grundeinkommen Datenschutz und Internet Wahlprogramm VollstÃ¤ndig als PDF (recht groÃŸ) als HÃ¶rbuch DIE LINKE. Mitgliederzahl 63.761 DurchÂ­schnittsÂ­alter 60 Jahre FrauenÂ­anteil 37,7 Prozent Themen 10 Euro Mindeslohn HÃ¶here Steuern auf hohe Einkommen HÃ¶here Sozialleistungen Wahlprogramm VollstÃ¤ndig als PDF (912 kB) als HÃ¶rbuch (6.1 MB) Ich konnte leider keinen \"offiziellen\" Wahlwerbespot finden. Aber der folgende Clip kommt dem am nÃ¤chsten: FDP Mitgliederzahl 58.675 DurchÂ­schnittsÂ­alter 53 Jahre FrauenÂ­anteil 23,0 Prozent Themen Staatsschulden abbauen ohne SteuererhÃ¶hung BÃ¼rgergeld Soli abschaffen Wahlprogramm VollstÃ¤ndig als PDF GrÃ¼ne Mitgliederzahl 60.808 DurchÂ­schnittsÂ­alter 48 Jahre FrauenÂ­anteil 37,8 Prozent Themen HÃ¶here Steuern auf hohe Einkommen Kostenlose Kita-PlÃ¤tze 8,50 Euro Mindestlohn BÃ¼rgerversicherung fÃ¼r alle Massentierhaltung abschaffen Gentechnik verhindern Ã–PNV billiger machen Wahlprogramm VollstÃ¤ndig als PDF HÃ¶rbuch SPD Mitgliederzahl 472.469 DurchÂ­schnittsÂ­alter 59 Jahre FrauenÂ­anteil 31,5 Prozent Themen HÃ¶here Steuern fÃ¼r hÃ¶here Einkommen Wahlalter auf 16 Jahre senken Kostenlose Kita-PlÃ¤tze Volle Rente ab 63 Jahren fÃ¼r alle, die min. 45 Jahre gearbeitet haben Wahlprogramm VollstÃ¤ndig als PDF CDU / CSU Mitgliederzahl 469.575 DurchÂ­schnittsÂ­alter 59 Jahre FrauenÂ­anteil 25,6 Prozent Themen konservativ (im GroÃŸen und Ganzen soll sich nichts Ã¤ndern) mehr KameraÃ¼berwachung Mieten sollen im Ã¶ffentlichen Raum nicht weiter ansteigen Wahlprogramm VollstÃ¤ndig als PDF (683.47 kB) als HÃ¶rbuch (1.44 MB) KoalitionsmÃ¶glichkeiten Koalitionsrechner - Ergebnis Die Parteien haben viele aussagen Ã¼ber Koalitionen nach der Bundestagswahl gemacht: FÃ¼r CDU/CSU kommt die FDP und die SPD in Frage. ( Quelle ) Die FDP will nur mit der Union eine Koalition. ( Quelle ) Rot-Rot-GrÃ¼n wird es nicht geben. ( Quelle , siehe auch im Wahlprogramm der GrÃ¼nen: â€žDie Linke steht abseits des grÃ¼nen Wandels.\") Die SPD will eigentlich nur mit den GrÃ¼nen. ( Quelle ) Nun kann man Umfrageergebnisse betrachten: Umfrageergebnisse zur Bundestagswahl 2013 Quelle: wahlrecht.de Damit steht fest: CDU / CSU bleibt in der Regierung. Wenn die FDP die 5%-HÃ¼rde schafft, gibt es wieder Schwarz-Gelb. Sonst wirds vielleicht interessant, aber vermutlich Schwarz-Rot Themen Ich finde es interessant, welche Themen fÃ¼r die Parteien wichtig sind und welche in der Ã–ffentlichkeit hÃ¤ufig diskutiert werden. Im folgenden mal einige Themen, die meiner Meinung nach wichtig sind. Sozialer Ausgleich Ich denke, dass in Deutschland die viel zitierte â€žSchere zwischen Arm und Reich\" zu groÃŸ wird. Zu dem Thema gibt es in den Wiki-Artikeln Einkommensverteilung in Deutschland und VermÃ¶gensverteilung in Deutschland viele Informationen, z.B.: 2008 betrug nach Zahlen des DIW das mittlere verfÃ¼gbare Einkommen 1.252 Euro die Ã¤rmsten 50% haben 1,4% des VermÃ¶gens in Deutschland die Top 0,1 % haben 22,5% des VermÃ¶gens in Deutschland die Top 10% haben 66,6% des VermÃ¶gens in Deutschland 5 Mio. verdienen weniger als 8,50 Euro pro Stunde ( Quelle ) Im Jahr 2011 sind an mehr als 1,21 Millionen Bedarfsgemeinschaften mit Aufstockern durchschnittlich 737 Euro je Monat gezahlt worden. ( Quelle ) Es ist sehr einfach, was dagegen hilft: HÃ¶here Steuern auf hÃ¶here Einkommen Mindestlohn HÃ¶here Sozialleistungen fÃ¼r Arme HÃ¶he ErbschaftsvermÃ¶gen (um eine konkrete Zahl zu nennen: > 10,000,000 Euro) mÃ¼ssen stark mit Erbschaftssteuer eingeschrÃ¤nkt werden. Davor darf es keine â€žSteuerflucht\" geben. (Existiert dieses Problem?) Ich bin auÃŸerdem davon Ã¼berzeugt, dass viele Menschen, die eigentlich Anspruch auf Sozialleistungen hÃ¤tten, diesen nicht in Anspruch nehmen. Zum einen, weil sie es nicht wollen ( Quelle ), zum anderen aber vermutlich auch, weil sie nicht wissen, dass sie Anspruch haben. Hier mal ein paar Leistungen, die es gibt: Arbeitslosengeld Arbeitslosengeld II BAfÃ¶G Hartz IV Kinderzulage Kindergeld Kinderkrankengeld Elterngeld Ãœbergangsgeld Wohngeld Wohnungshilfe In der Kategorie:Sozialleistung (Deutschland) findet man noch viel mehr. Eurokrise Die Eurokrise muss beendet werden. Wichtige Zahlen dazu sind: Die Jugendarbeitslosigkeit in Spanien betrug 2012 ca. 24,9%. Griechenland: Arbeitslosigkeit bei Menschen mit Hochschulbildung unter 24 Jahren: 28,8% - in Deutschland 12,8% In Griechenland betrug die Arbeitslosigkeit 2011 ca. 17,6% Die Staatverschuldung ist katastrophal - egal ob man Deutschland, Frankreich, Spanien, Griechenland oder Italien anschaut. Hier kann man nicht davon ausgehen, dass irgendeine Partei eine belegbar gute LÃ¶sung vorbringt. Wie auch? Das Problem gab es noch nie. Aber die Frage nach dem, was man zu tun gedenkt ist doch interessant: CDU / CSU: FÃ¼r: SparmaÃŸnahmen, Schuldenbremse, StabilitÃ¤tspakt , EuropÃ¤ische Bankenunion Gegen: Eurobonds SPD: FÃ¼r: Finanztransaktionssteuer DIE LINKE.: FÃ¼r: Einmalige Abgabe von 10% auf VermÃ¶gen zur Schuldentilgung bei einem Freibetrag von 1.000.000 Euro auf PrivatvermÃ¶gen und 2.000.000 Euro auf BetriebsvermÃ¶gen; Finanztransaktionssteuer Piraten: FÃ¼r: Finanztransaktionssteuer; Schuldenschnitte GrÃ¼ne: FÃ¼r: VermÃ¶gensabgabe (vergleichbar mit LINKE) Das ist selbstverstÃ¤ndlich keine vollstÃ¤ndige Liste. Wenn es einen wirklich interessiert, sollte man das Wahlprogramm der Parteien danach durchsuchen. Korruption und Transparenz Korruption kann dazu fÃ¼hren, dass Entscheidungen getroffen werden, die fÃ¼r den Staat nicht optimal sind. Dazu sollte Abgeordnetenbestechung zuerst einmal illegal sein, also ein â€žAnti-Korruptionsgesetz\" eingefÃ¼hrt werden. Dagegen wehren sich aber CDU/CSU und FDP sehr. Es gab auch schon eine Abstimmung SchÃ¤rfere Regeln gegen Abgeordnetenbestechung - kontrolliert doch selbst, wie eure Abgeordneten abgestimmt haben. AuÃŸerdem fÃ¼hrt der Verdacht auf bestechliche Politiker zu weiterer Politikverdrossenheit. Siehe zu Abgeordnetenbestechung: Blockade bei Abgeordnetenbestechung Abgeordnetenbestechung: Mit wem will Seehofer eigentlich eine GesetzesverschÃ¤rfung durchsetzen? Ãœberraschung: Bundestag soll doch noch Ã¼ber Abgeordnetenbestechung abstimmen Energiewende Die Versorgung mit Energie ist ein essentieller bestandteil der Ã¶ffentlichen Infrastruktur. Sei es in Form von elektrischer Energie fÃ¼r Haushalte und Firmen, in Form von WÃ¤rme oder in Form von MobilitÃ¤t. Dabei wÃ¤re es schÃ¶n, das Problem nachhaltig zu lÃ¶sen. Momentan geschieht dies in Form von On - und Offshore Windkraftparks sowie im Netzausbau . Das Erneuerbare-Energien-Gesetz (EEG) soll dabei helfen und regelt die sog. EinspeisevergÃ¼tung . Steuern Im Bezug auf Steuern sehe ich zwei groÃŸe Probleme: Konzerne spielen LÃ¤nder gegeneinander aus Steuern sind in Deutschland kompliziert Das Konzerne LÃ¤nder gegeneinander ausspielen, sieht man an Google ( Quelle ). Versteht mich jetzt nicht falsch, ich finde Google super. Aber jedes Unternehmen wird, wenn es ihm auf legale Art mÃ¶glich ist, versuchen Kosten (also auch Steuern) so niedrig wie mÃ¶glich zu halten. Also sollte man sich doch innerhalb der Euro-Zone auf ein gemeinsames Steuersystem einigen kÃ¶nnen, oder? AuÃŸerdem scheint es mir in Deutschland zu viele Steuern/Abgaben zu geben und diese auch zu kompliziert zu sein Sinnvoll finde ich Erbschaftssteuer: Sie sorgt dafÃ¼r, dass sich Reichtum weniger stark anhÃ¤uft. Umsatzsteuer : Sie stellt einen einfachen Weg dar, wie der Staat an Geld kommt. Sie betrifft alle gleichmÃ¤ÃŸig. Ich finde es nicht sinnvoll, hier zwischen verschiedenen Klassen (Lebensmittel, LuxusgÃ¼ter) zu unterscheiden. Wenn Lebensmittel mehr kosten wÃ¼rden, wÃ¼rde man ihren Wert vielleicht mehr schÃ¤tzen. Einkommensteuer: Auch mit der Lohnsteuer bekommt der Staat viel Geld. Aber im Gegensatz zur Umsatzsteuer kann man hier Leute, die viel Verdienen stÃ¤rker belasten. Energiesteuern: Durch Energiesteuern kann man Anreize schaffen, sparsame GerÃ¤te / Infrastruktur zu entwickeln. Dies sollte fÃ¼r die BÃ¼rger auf lange Sicht von Vorteil sein. Rauschmittelsteuern : Eigentlich sollten Menschen nicht rauchen und saufen. Also sollten diese Produkte - obwohl sie eventuell billig in der Herstellung sind - teuer verkauft werden. Die Steuer sollte sÃ¼chtigen dazu dienen, von ihrer Sucht frei zu kommen bzw. in die SuchtprÃ¤vention gesteckt werden. Grundsteuer: Durch eine hohe Grundsteuer nutzt vermutlich derjenige, der am meisten damit verdienen kann, das GrundstÃ¼ck. Sie kann also eine gute Verteilung dieser knappen Ressource ermÃ¶glichen. Steuern/Abgaben die ich nicht verstehe, sind: SolidaritÃ¤tszuschlag Kirchensteuer : Das sollte die Kirche selbst machen! Arbeitslosenversicherung: Sollte durch Umsatz- und Einkommenssteuer gedeckt werden. GrundstÃ¤tzlich denke ich sollte hier jeder gleich versichert sein. Wenn jemand mehr als grundlegende Leistungen will, soll er das Privat machen. Aber eine gewisse Grundsicherung soll jeder bekommen. Krankenversicherung: Siehe Arbeitslosenversicherung Pflegeversicherung: Siehe Arbeitslosenversicherung Tabak, Alkopop, Schaumwein: Sollte eine â€žRauschmittelsteuer\" sein Grunderwerbssteuer : Warum wird Grunderwerb extra gezÃ¤hlt? Warum nicht einfach nur Umsatzsteuer? Kapitalertragsteuer : Warum ist das nicht einfach Einkommenssteuer? Versicherungsteuer, Kraftfahrzeugsteuer : Siehe Grunderwerbsteuer Stromsteuer: Inwiefern unterscheided sie sich von der Energiesteuer? Ganz allgemein sollte es wenig S1teuern geben. Die Steuer die es gibt, sollten einfach zu verstehen und zu berechnen sein. AuÃŸerdem sollte es eine vollstÃ¤ndige, aktuelle, frei verfÃ¼gbare Liste der Steuern sowie der Berechnung selbiger geben. Ich weiÃŸ nicht, wie die Lohnsteuer berechnet wird. Sinnvoll wÃ¼rde ich folgende Berechnung finden: Am Ende eines Jahres wird das Einkommen (Lohn, KapitalertrÃ¤ge) berechnet. Sei dieses Gesamteinkommen \\(x\\) (in Euro): \\(x \\leq 12.000\\) : Keine Steuer \\(x \\leq 24.000\\) : 15% Steuer. Die zu bezahlende Steuer ist also \\((x - 12.000) \\cdot \\frac{15}{100}\\) \\(x \\leq 36.000\\) : 20% Steuer. Die zu bezahlende Steuer ist also \\((36.000 - 12.000) \\cdot \\frac{15}{100} + (x-24.000) \\cdot \\frac{20}{100}\\) ... \\(x > 120.000\\) : 50% Steuer. Die zu bezahlende Steuer ist also \\((36.000 - 12.000) \\cdot \\frac{15}{100} + (36.000-24.000) \\cdot \\frac{20}{100} + \\dots + (x-120.000) \\cdot \\frac{50}{100}\\) Bitte hÃ¤ngt euch nicht an den Zahlen auf. Das sollte nur das System veranschaulichen. Mit diesem System wÃ¤re es ganz einfach zu berechnen, wer wieviel zahlen muss. Damit kann es auch nicht passieren, dass jemand trotz hÃ¶herem Einkommen weniger Geld hat. Hier mal eine Grafik Ã¼ber das Steueraufkommen in Deutschland: Steueraufkommen in Deutschland (Stand: 2008) Es gibt noch den Ansatz der â€ž Flat Tax \", die Steuern einfacher machen soll. Ob das sinnvoll ist, kann ich nicht sagen. Aber eine Vereinfachung verbunden mit einer EuropÃ¤ischen Vereinheitlichung kÃ¶nnte Firmen entlasten und SteuerschlupflÃ¶cher schlieÃŸen. BÃ¼rgerrechte Im SpÃ¤hskandal (NSA, Prism, Tempora, Xkeyscore, ...) hat die CDU/CSU bisher nichts gemacht, um fÃ¼r AufklÃ¤rung und Beendigung der illegalen Praktiken zu sorgen. In einigen anderen Berechen wurden jedoch kritische Gesetze/Projekte/Aussagen umgesetzt/gestartet/gemacht: Verkauf von Meldedaten, manchmal auch â€žBestandsdatenauskunft\" genannt ( Quelle ) Mehr VideoÃ¼berwachung Friedrich nimmt NSA in Schutz Vorratsdatenspeicherung (siehe Abstimmung , EU-Richtlinie ) Aber auch die SPD scheint in dem NSA-Skandal nicht ganz unbeteiligt zu sein ( Quelle ). Auch die Vorratsdatenspeicherung haben sie mit beschlossen. Die GrÃ¼nen und Piraten sind gegen VideoÃ¼berwachung, wollen das Fernmeldegeheimnis zu einem Kommunikations- und Mediennutzungsgeheimnis ausweiten, gegen die Bestandsdatenauskunft vorgehen und Vorratsdatenspeicherung verhindern. Kleine Themen Mit folgenden Themen scheinen die Parteien ihren Wahlkampf zu betreiben. Obwohl sie fÃ¼r einzelne Leute sehr wichtig sein mÃ¶gen, glaube ich das sie im groÃŸen und ganzen zu vernachlÃ¤ssigen sind. Verglichen mit den obigen Themen betreffen die folgenden Themen nur wenige Leute. Einiges davon habe ich aus dem Wahl-o-mat : Adoptionsrecht / Gleichstellung fÃ¼r Homosexuelle Betreuungsgeld Syrien-Krise Generelles Tempolimit auf Autobahnen NATO-Austritt Deutschlands; RÃ¼stungsexporte; MilitÃ¤rische Beteiligungen Deutschlands Aufnahme von mehr FlÃ¼chtigen Einwanderung Lohnersatzleistungen bei Pflege von AngehÃ¶rigen Frauenquote in AufsichtsrÃ¤ten Renteneintrittsalter Ehegattensplitting Autobahn-Maut fÃ¼r AuslÃ¤nder AbschlieÃŸende Worte Dieser Artikel stellt nur eine kurze Zusammenfassung von Gedanken dar, die mir wichtig oder interessant zu sein scheinen. Bitte denkt Ã¼ber die Themen nach und Ã¼berlegt euch: Bin ich mit der Politik der letzten 4 Jahre zufrieden? Was ist mir wichtig? Wenn man nur auf die grobe Ausrichtung der Parteien betrachtet, kann man eventuell sagen: Wenn man GrundsÃ¤tzlich mit der Politik der letzten Jahre zufrieden ist, sollte man CDU/CSU wÃ¤hlen. Wenn man Wert auf Transparenz legt, und will das Internetkompetenz in das Parlament kommt, sollte man die Piraten wÃ¤hlen. Wenn man auf Umweltschutz, neue (aber nicht radikale) Ideen, wert legt, sollte man die GrÃ¼nen wÃ¤hlen Wenn man extreme Ã„nderungen im sozialen Bereich will, sollte man DIE LINKE wÃ¤hlen. Wenn man CDU/CSU und FDP wieder sehen will, und will das auf Datenschutz-Aspekte mehr wert gelegt wird, sollte man FDP wÃ¤hlen. SPD: Hmm ... wenn man das gleiche in Rot will, was man schon kennt? Ich kann keinen wirklichen Themenschwerpunkt finden, in dem sich die SPD stark von der CDU/CSU abhebt. Wenn es euch irgendwie kÃ¼mmert, was in Deutschland passiert, solltet ihr wÃ¤hlen gehen. Links Aussagelose Wahlslogans","tags":"German posts","title":"Gedanken zur Bundestagswahl 2013"},{"url":"https://martin-thoma.com/gausssche-zahlen-und-verwandte-ringe/","text":"Sei \\(\\mathbb{Z}[\\sqrt{z}]\\) mit \\(z \\in \\mathbb{Z}\\) der kleinste Ring, der \\(\\mathbb{Z}\\) und \\(\\sqrt{z}\\) enthÃ¤lt. Sei \\(A := \\{a + b \\sqrt{z} | a, b \\in \\mathbb{Z}\\}\\) . Behauptung : \\(\\mathbb{Z}[\\sqrt{z}] = A\\) Beweis : z.Z.: \\(\\mathbb{Z}[\\sqrt{z}] \\subseteq A\\) und \\(\\mathbb{Z}[\\sqrt{z}] \\supseteq A\\) Zuerst zeige ich \\(\\mathbb{Z}[\\sqrt{z}] \\supseteq A\\) : $\\mathbb{Z}[\\sqrt{z}]$ enthÃ¤lt $\\mathbb{Z} \\Rightarrow \\{a \\in \\mathbb{Z}\\} \\subseteq \\mathbb{Z}[\\sqrt{z}]$ $\\mathbb{Z}[\\sqrt{z}]$ enthÃ¤lt $\\sqrt{z} \\Rightarrow \\{\\sqrt{z}\\} \\subseteq \\mathbb{Z}[\\sqrt{z}]$ $\\mathbb{Z}[\\sqrt{z}]$ ist ein Ring, also ist $(\\mathbb{Z}[\\sqrt{z}], +)$ eine abelsche Gruppe. $\\Rightarrow A \\subseteq \\mathbb{Z}[\\sqrt{z}]$ Nun \\(\\mathbb{Z}[\\sqrt{z}] \\subseteq A\\) : \\((A, +) \\leq (\\mathbb{R}, +)\\) , denn (UG-Kriterium) \\(0 = 0 + 0 \\sqrt{z} \\in A \\Rightarrow A \\neq \\emptyset\\) \\(\\forall (a+b \\sqrt{z}), (c + d \\sqrt{z}) \\in A:\\) \\((a+b\\sqrt{z}) - (c+d\\sqrt{z}) = \\underbrace{(a-c)}_{\\in \\mathbb{Z}} + \\underbrace{(b-d)}_{\\in \\mathbb{Z}} \\sqrt{z} \\in A\\) \\((A, +)\\) ist abelsch, da \\((\\mathbb{R}, +)\\) abelsch ist \\((A, \\cdot)\\) ist Untermonoid von \\((\\mathbb{R}, \\cdot)\\) , denn \\(1 = 1 + 0 \\sqrt{z} \\in A\\) \\(\\forall (a+b \\sqrt{z}), (c + d \\sqrt{z}) \\in A:\\) \\((a+b\\sqrt{z}) \\cdot (c+ d\\sqrt{z}) = \\underbrace{(ac + z bd)}_{\\in \\mathbb{Z}} + \\underbrace{(ad + bc)}_{\\in \\mathbb{Z}} \\sqrt{z} \\in A\\) Distributivgesetze: Vererben sich aus \\((\\mathbb{R}, \\cdot)\\) \\(\\Rightarrow \\mathbb{Z}[\\sqrt{z}] \\subseteq A\\) \\(\\Rightarrow \\mathbb{Z}[\\sqrt{z}] = A \\blacksquare\\)","tags":"Mathematics","title":"GauÃŸ'sche Zahlen und verwandte Ringe"},{"url":"https://martin-thoma.com/solve-linear-congruence-equations/","text":"When you have a system of linear congruences like: $$ \\begin{align} x &\\equiv 4 \\mod 19\\\\ x &\\equiv 12 \\mod 37\\\\ x &\\equiv 14 \\mod 43 \\end{align} $$ you can solve it quite easily. Johannes Schickling has written a very nice JavaScript Application that applies the following algorithm online. I've used his source code to write the following Python code. Pseudocode Solve a system of linear congruences Python #!/usr/bin/env python # -*- coding: utf-8 -*- def ExtendedEuclideanAlgorithm ( a , b ): \"\"\" Calculates gcd(a,b) and a linear combination such that gcd(a,b) = a*x + b*y As a side effect: If gcd(a,b) = 1 = a*x + b*y Then x is multiplicative inverse of a modulo b. \"\"\" aO , bO = a , b x = lasty = 0 y = lastx = 1 while ( b != 0 ): q = a / b a , b = b , a % b x , lastx = lastx - q * x , x y , lasty = lasty - q * y , y return { \"x\" : lastx , \"y\" : lasty , \"gcd\" : aO * lastx + bO * lasty } def solveLinearCongruenceEquations ( rests , modulos ): \"\"\" Solve a system of linear congruences. >>> solveLinearCongruenceEquations([4, 12, 14], [19, 37, 43]) {'congruence class': 22804, 'modulo': 30229} \"\"\" assert len ( rests ) == len ( modulos ) x = 0 M = reduce ( lambda x , y : x * y , modulos ) for mi , resti in zip ( modulos , rests ): Mi = M / mi s = ExtendedEuclideanAlgorithm ( Mi , mi )[ \"x\" ] e = s * Mi x += resti * e return { \"congruence class\" : (( x % M ) + M ) % M , \"modulo\" : M } if __name__ == \"__main__\" : import doctest doctest . testmod () Links Try it online Sources","tags":"Mathematics","title":"How to solve linear congruence equations"},{"url":"https://martin-thoma.com/how-to-calculate-the-legendre-symbol/","text":"Pseudocode Pseudocode: Calculate Legendre symbol Python #!/usr/bin/env python # -*- coding: utf-8 -*- def isPrime ( a ): return all ( a % i for i in xrange ( 2 , a )) # http://stackoverflow.com/a/14793082/562769 def factorize ( n ): factors = [] p = 2 while True : while ( n % p == 0 and n > 0 ): #while we can divide by smaller number, do so factors . append ( p ) n = n / p p += 1 #p is not necessary prime, but n%p == 0 only for prime numbers if p > n / p : break if n > 1 : factors . append ( n ) return factors def calculateLegendre ( a , p ): \"\"\" Calculate the legendre symbol (a, p) with p is prime. The result is either -1, 0 or 1 >>> calculateLegendre(3, 29) -1 >>> calculateLegendre(111, 41) # Beispiel aus dem Skript, S. 114 -1 >>> calculateLegendre(113, 41) # Beispiel aus dem Skript, S. 114 1 >>> calculateLegendre(2, 31) 1 >>> calculateLegendre(5, 31) 1 >>> calculateLegendre(150, 1009) # http://math.stackexchange.com/q/221223/6876 1 >>> calculateLegendre(25, 1009) # http://math.stackexchange.com/q/221223/6876 1 >>> calculateLegendre(2, 1009) # http://math.stackexchange.com/q/221223/6876 1 >>> calculateLegendre(3, 1009) # http://math.stackexchange.com/q/221223/6876 1 \"\"\" if a >= p or a < 0 : return calculateLegendre ( a % p , p ) elif a == 0 or a == 1 : return a elif a == 2 : if p % 8 == 1 or p % 8 == 7 : return 1 else : return - 1 elif a == p - 1 : if p % 4 == 1 : return 1 else : return - 1 elif not isPrime ( a ): factors = factorize ( a ) product = 1 for pi in factors : product *= calculateLegendre ( pi , p ) return product else : if (( p - 1 ) / 2 ) % 2 == 0 or (( a - 1 ) / 2 ) % 2 == 0 : return calculateLegendre ( p , a ) else : return ( - 1 ) * calculateLegendre ( p , a ) if __name__ == \"__main__\" : import doctest doctest . testmod () More Rules how to calculate with Legendre symbols Python and Pseudocode source files","tags":"Mathematics","title":"How to calculate the Legendre symbol"},{"url":"https://martin-thoma.com/how-many-homomorphisms-exist-between-znz-and-zmz/","text":"Today I've wondered how many homomorphisms are between the groups \\((\\mathbb{Z}/n\\mathbb{Z},+)\\) and \\((\\mathbb{Z}/m\\mathbb{Z},+)\\) with \\(m, n \\geq 2\\) . Does it make a difference if I use + or \\(\\cdot\\) as operators? Let \\(M := (\\mathbb{Z}/m\\mathbb{Z},+)\\) and \\(N := (\\mathbb{Z}/n\\mathbb{Z},+)\\) be groups and \\(\\varphi: M \\rightarrow N\\) be a group homomorphism. Let \\(H := \\{\\varphi: M \\rightarrow N\\}\\) Some fundamental theorems (which I'm not going to prove) are: \\(\\varphi(M)\\) is a group. \\(K_\\varphi := \\{m \\in M | \\varphi(m) = e_N\\}\\) is a group. Lagrange's theorem : \\(H \\leq G \\Rightarrow \\#H | \\# G\\) \\(\\varphi(1)\\) defines the complete homomorphism as \\(\\varphi(n) = \\varphi(1 + (n-1)) = \\varphi(1) + \\varphi(n-1)\\) \\(\\varphi(1) = 0\\) is always a homomorphism (that maps everything to 0). $m = n$ Theorem : \\(n=m \\Rightarrow |H|=n\\) Proof : You can map \\(1\\) to \\(n\\) values \\(\\stackrel{(IV)}{\\Rightarrow}\\) there can't be more than \\(n\\) homomorphisms. For every \\(i \\in \\{0, \\dots, n-1\\}\\) exists an homomorphism \\(\\varphi_i(1) = i\\) : \\begin{align} \\varphi(a) + \\varphi(b) &= (ai \\mod n) + (bi \\mod n)\\\\ &= ai + bi \\mod n\\\\ &= (a+b)i \\mod n\\\\ &= \\varphi(a+b) \\end{align} This means, that all of them are actually homomorphisms. For different \\(i,j \\in \\{0, \\dots, n-1\\}\\) the homomorphisms \\(\\varphi_i\\) and \\(\\varphi_j\\) are different. So we really have \\(n\\) homomorphisms \\(\\blacksquare\\) My first thought was that it's only a permutation, but \\(m \\in M\\) 0 1 2 3 4 5 \\(\\varphi(m) \\in N\\) 0 3 0 3 0 3 is not a permutation, but a homomorphism. Distinct primes Theorem : \\(n, m \\in \\mathbb{P}, n \\neq m \\Rightarrow |H| = 1\\) Proof : Let \\(n, m \\in \\mathbb{P}, n \\neq m\\) . Part 1 : \\(1 \\leq |H|\\) This follows directly from (V). Part 2 : \\(|H| \\leq 1\\) We know that \\begin{align} \\stackrel{(I)+(III)}{\\Rightarrow} &\\# \\varphi(M) | \\# N\\\\ \\stackrel{n \\in \\mathbb{P}}{\\Rightarrow} &\\# \\varphi(M) \\in \\{1, n\\} \\end{align} and \\begin{align} \\stackrel{(II)+(III)}{\\Rightarrow} &\\# K_\\varphi | \\# M\\\\ \\stackrel{m \\in \\mathbb{P}}{\\Rightarrow} &\\# K_\\varphi \\in \\{1, m\\} \\end{align} Case 1: \\(m > n\\) Now the kernel can't be trivial anymore, so \\(\\# K_\\varphi = m\\) . This means that everything is mapped to 0. There is only one homomorphism that does so. Case 2: \\(m < n\\) Now the image \\(\\varphi(M)\\) can't be all of \\(N\\) . This means \\(\\varphi(M) = 1\\) which is again the 0-mapping \\(\\blacksquare\\) Any $n$ and $m$ Theorem : \\(|H| = gcd(n, m)\\) Proof : First a sanity check: The theorems above are special cases of this theorem. Let's try to prove it. Let \\(n\\) be composed of primes \\(p_1, \\dots, p_x\\) (where \\(p_i = p_j\\) is allowed). Then \\(N = \\mathbb{Z}/n\\mathbb{Z} \\cong \\mathbb{Z}/p_1\\mathbb{Z} \\times \\mathbb{Z}/p_2\\mathbb{Z} \\times \\cdots \\times \\mathbb{Z}/p_x\\mathbb{Z}\\) according to the Chinese remainder theorem . The same is true for \\(M\\) . As there are \\(p_i\\) homomorphisms between \\(\\mathbb{Z}/p_i\\mathbb{Z}\\) and \\(\\mathbb{Z}/p_j\\mathbb{Z}\\) with \\(p_i = p_j\\) and as you can take a \\(p_i\\) from the left and a \\(p_j\\) from the right you can combine the different homomorphisms. So it is basically a combinatoric problem. As everything (except for same primes) will only have 1 homomorphism, you have to multiply the number of homomophisms for each pair \\((p_i, p_j)\\) . But this is simply the gcd \\(\\blacksquare\\) $(\\mathbb{Z}/n\\mathbb{Z}, \\cdot)$ What changes when we use \\((\\mathbb{Z}/n\\mathbb{Z}, \\cdot)\\) and \\((\\mathbb{Z}/m\\mathbb{Z}, \\cdot)\\) ? Well, first of all \\(m\\) and \\(n\\) have to be primes. Otherwise, not every element would have an inverse. Second, you have to exclude 0. Which means we only use units: \\((\\mathbb{Z}/n\\mathbb{Z}, \\cdot)&#94;\\times\\) and \\((\\mathbb{Z}/m\\mathbb{Z}, \\cdot)&#94;\\times\\) According to the German Wikipedia ( source ): $(\\mathbb{Z}/n\\mathbb{Z})&#94;\\times$ is cyclic $:\\Leftrightarrow n \\in \\{p&#94;r, 2p&#94;r | p \\in \\mathbb{P}, r \\in \\mathbb{N}_{\\geq 1}\\}$ So there is no simple way to reduce it to the same proofs. But I've created a little script that automatically finds homomorphisms . Related Quick way to find the number of the group homomorphisms Ï•:Z3â†’Z6?","tags":"Mathematics","title":"How many Homomorphisms exist between Z/nZ and Z/mZ?"},{"url":"https://martin-thoma.com/stabilizer-subgroup-subgroup/","text":"Let $(G, \\cdot)$ be a group and $M$ a set. A group action is a function: $G \\circ M \\rightarrow M$ that satisfies the following two conditions Identity: $\\forall m \\in M: e_G \\circ m = m$ Associativity: $\\forall g, h \\in G, m \\in M: (g \\cdot h) \\circ m= g \\circ (h \\circ m)$ Let $m \\in M$. Then $G_m := \\{g \\in G | g \\circ m = m\\}$ is called the stabilizer of $m$. Theorem : \\(G_m\\) is a group Proof : Let \\(m \\in M\\) . \\(\\stackrel{identity}{\\Rightarrow}e_G \\in G_m\\) Let \\(a \\in G_m\\) . This means, that \\(a \\circ m = m\\) . And \\(\\exists a&#94;{-1} \\in G\\) , as \\(G\\) is a group. \\(a&#94;{-1} \\cdot a = e_G\\) , this means \\((a&#94;{-1} \\cdot a) \\circ m = m\\) . \\(\\stackrel{associativity}{\\Rightarrow}a&#94;{-1} \\circ (a \\circ m) = m \\Leftrightarrow a&#94;{-1} \\circ m = m \\Leftrightarrow a&#94;{-1} \\in G_m\\) Let \\(a, b \\in G_m\\) . Then: \\(a \\circ m = m\\) and \\(b \\circ m = m\\) \\(\\Rightarrow a \\circ (b \\circ m) = m\\) \\(\\stackrel{associativity}{\\Rightarrow} (a \\cdot b) \\circ m = m \\Leftrightarrow (a \\cdot b) \\in G_m \\blacksquare\\)","tags":"Mathematics","title":"Why is the stabilizer subgroup a subgroup?"},{"url":"https://martin-thoma.com/intersection-two-normal-subgroups-normal-subgroup//","text":"Let \\((G, \\cdot)\\) be a group and \\(X \\lhd G\\) and \\(Y \\lhd G\\) be two normal subgroups. I will show this in two steps: Show that \\(X \\cap Y\\) is a group Show that \\(X \\cap Y\\) is a normal group of \\((G, \\cdot)\\) Intersection of two subgroups is a subgroup Theorem : \\((X \\cap Y) \\leq G\\) Proof : \\(X \\cap Y\\) is not empty: \\(e_G \\in X \\land e_G \\in Y \\Rightarrow e_G \\in (X \\cap Y)\\) \\(X \\cap Y\\) has inverse elements. Let \\(a \\in (X \\cap Y)\\) . As a is in \\(X\\) and \\(X\\) is a group, \\(a&#94;{-1} \\in X\\) . The same is true for \\(Y\\) . So: \\(\\forall a \\in (X \\cap Y) \\exists a&#94;{-1} \\in (X \\cap Y): a \\cdot a&#94;{-1} = a&#94;{-1} \\cdot a = e_G\\) \\(\\forall a,b \\in (X \\cap Y): a \\cdot b&#94;{-1} \\in (X \\cap Y)\\) , because both, \\(a\\) and \\(b&#94;{-1}\\) are in \\(X\\) . As \\(X\\) is a group, the result has to be in \\(X\\) . Same argumentation for \\(Y\\) . Then the result is in \\(X\\) and \\(Y \\blacksquare\\) Intersection of two normal subgroups is normal First the definition of a normal subgroup: Let \\(N \\leq G\\) be a subgroup of \\(G\\) . \\(N \\lhd G :\\Leftrightarrow \\forall n \\in N \\forall g \\in G: g \\cdot n \\cdot g&#94;{-1} \\in N\\) Theorem : \\((X \\cap Y) \\lhd G\\) Proof : \\(X \\cap Y\\) is a subgroup of \\(G\\) as I have proved above. \\(\\forall n \\in (X \\cap Y) \\forall g \\in G: g \\cdot n \\cdot g&#94;{-1} \\in X\\) and \\(\\forall n \\in (X \\cap Y) \\forall g \\in G: g \\cdot n \\cdot g&#94;{-1} \\in Y\\) \\(\\Rightarrow \\forall n \\in (X \\cap Y) \\forall g \\in G: g \\cdot n \\cdot g&#94;{-1} \\in (X \\cap Y)\\) \\(\\Rightarrow (X \\cap Y) \\lhd G \\blacksquare\\)","tags":"Mathematics","title":"Why is the intersection of two normal subgroups a normal subgroup?"},{"url":"https://martin-thoma.com/how-to-analyze-mailman-archives/","text":"All mailing lists I use are GNU Mailman lists. This software provides archives of all Emails that were send over the list. They look like this: GNU Mailman list archive Once in a while, I would like to search if a topic was already discussed. Here is how you can do it: Download archives wget --save-cookies cookie.txt --post-data 'username=user&password=pass' -A gz -m -p -E -k -K -np https://lists.abc.org/mailman/blub/ Rename archives for file in *.txt.gz ; do mv \" $file \" \" ${ file %.txt.gz } .txt\" ; done To make them sortable: for file in *January.txt ; do mv \" $file \" \" ${ file %January.txt } 01.txt\" ; done for file in *February.txt ; do mv \" $file \" \" ${ file %February.txt } 02.txt\" ; done for file in *March.txt ; do mv \" $file \" \" ${ file %March.txt } 03.txt\" ; done for file in *April.txt ; do mv \" $file \" \" ${ file %January.txt } 04.txt\" ; done for file in *May.txt ; do mv \" $file \" \" ${ file %May.txt } 05.txt\" ; done for file in *June.txt ; do mv \" $file \" \" ${ file %June.txt } 06.txt\" ; done for file in *July.txt ; do mv \" $file \" \" ${ file %July.txt } 07.txt\" ; done for file in *August.txt ; do mv \" $file \" \" ${ file %August.txt } 08.txt\" ; done for file in *September.txt ; do mv \" $file \" \" ${ file %September.txt } 09.txt\" ; done for file in *October.txt ; do mv \" $file \" \" ${ file %October.txt } 10.txt\" ; done for file in *November.txt ; do mv \" $file \" \" ${ file %November.txt } 11.txt\" ; done for file in *December.txt ; do mv \" $file \" \" ${ file %December.txt } 12.txt\" ; done Analyze them To analyze the archives properly, you should perhaps first import all emails in a relational database. But with grep you could also do simple keyword searches.","tags":"Cyberculture","title":"How to analyze Mailman archives"},{"url":"https://martin-thoma.com/audible/","text":"I have just decided to try Audible.de, the German part of Audible.com which is \"An Amazon Company\". They offer audiobooks. You have to know that I really like to listen to audiobooks when I can't read and need some distraction. Everybody who lives in Germany and buys something at Amazon knows the coupons that you get with a purchase: Audible coupon - front Audible coupon - back Buying audiobooks Buying the audiobook I liked (\"Darknet\" from Daniel Suarez) was just as I knew it from Amazon. Another design , but even my bank account data is there. After purchasing it, I wanted to listen to it: After having bought an audiobook After clicking on \"my library\" I get to this page: My library A click on \"Start Audible-Assistant\" redirects to: Software download assistant So I thought I could download it to my smartphone. Android App If the Audible Android App was software for your computer, you would call it spyware: It requires the permission to add or change calendar dates, send E-mails to \"guests\" (whatever this means), pairing with Bluetooth devices, and some other stuff (which seems to be okay) Why the hell do they want to change my calendar dates? I only want to listen to audiobooks I've bought... This is not okay for me, so lets see if I can listen to it on my computer. Linux As so often, there is no support for Linux. But Wine does a great job in bringing Windows applications to Linux. So I've installed the software: Audible Manager I thought, maybe I need to activate it via the web interface. Back to image \"Software download assistant\", click on \"Add device\" (the big orange button): Audible Web assistant My E-mail There seems to be no way for me to download an audiobook with Audible. As it's now very late, I've contacted customer service and described the issue (12.08.2013, 23:00): Sehr geehrte Damen und Herren, wenn ich mein HÃ¶rbuch herunterladen will, werde ich darauf hingewiesen, dass ich noch kein GerÃ¤t hinzugefÃ¼gt habe. Wenn ich dann Ã¼ber den Link (http://www.audible.de/assistant) ein GerÃ¤t (meinen Linux-Computer auf dem der AudibleManager mit wine lÃ¤uft) hinzufÃ¼gen will, bekomme ich einen Fehler 404 (Seite nicht gefunden). Mit freundlichen GrÃ¼ÃŸen, Martin Thoma Answer: Lieber Herr Thoma, vielen Dank fÃ¼r Ihr freundliches Schreiben. Es tut uns leid, tatsÃ¤chlich kÃ¶nnen wir unseren Service derzeit nicht auf Linux-Systemen anbieten. Ob es in Zukunft eine UnterstÃ¼tzung fÃ¼r Linux geben wird, kÃ¶nnen wir gegenwÃ¤rtig leider nicht versprechen. Wir bitten um Ihr VerstÃ¤ndnis. Wenn Sie den Manager bereits installiert haben und als Browser Firefox benutzen, dann sollten Sie das admhelper.adh Script mit dem AudibleDownloadHelper via wine Ã¶ffnen kÃ¶nnen. Wir hoffen, dass dies eine gute Alternative fÃ¼r Sie ist und stehen bei allen weiteren Fragen gerne zur VerfÃ¼gung. Ich wÃ¼nsche Ihnen einen wunderbaren Tag. Herzliche GrÃ¼ÃŸe [A name which I don't want to show here.] Audible-Kundenservice Virtual Box I've finally got it to work. I've installed XP with Virtual Box. Cancellation Step 0 Step 1 Step 2 Step 3 Step 4 Step 5 Step 6 Step 7 Conclusion DRM seems to be necessary for such a service. Okay, I want to get my free audiobook, so I have to accept this. But this one reason why the service SUCKS. It would be much easier to let the user download the audiobook as a simple MP3 / WAV / OGG file. Everybody can play these files. Do you want to install software for every service you want to purchase audiobooks / songs from? Please also consider that Amazon might close your account ( source ), so you can not simply stick with one provider. Currently, I can only say: Don't use audible. It's a terrible service.","tags":"My bits and bytes","title":"Audible"},{"url":"https://martin-thoma.com/improving-lecture-notes-job-almost-done/","text":"Some of you might know that I've bin improving the lecture notes for the computer engineering lecture (digital electronics) since April 2013. How I've got the job This was kind of funny. I send Prof. Dr. Asfour some notes of passages that could be improved (mainly typos). About two days later he proposed me to correct it by myself. Another day later I signed the contract. I've never signed a contract that fast. What I did My job was to correct errors (German language, statements about computer science and LaTeX), find parts that were outdated and update them, find sections that were difficult to understand and simplify them and to make it easier to make changes in the future (Well, I don't think Prof. Dr. Asfour thought this was my job ... but I think it's important.) So Prof. Dr. Asfour created a SVN repository with all LaTeX sources of the latest lecture notes (which were already great!). He also sent me Emails he received from students who mentioned errors just like I did and some notes from a tutor who tried to improve the script some time ago. Revisions With svn checkout svn://somepath@1 working-directory you can checkout the first revision of a SVN repository. Total number of files and folders: find . | wc -l Revision 1: 1885 Revision 30: 1488 How often did I change files ( source ): svn log -qvr 1 :HEAD | perl -nle 'print if /&#94;Changed paths:/ ... /&#94;-+$/ and /&#94;\\s/' \\ | sort | uniq -c | sort -n 1 M /ti1.bib 2 M / 2 M /anhang-1.tex 2 M /anhang-3.tex 2 M /anhang-5.tex 2 M /diss-report.cls 2 M /figures/Makefile 2 M /titel.tex 2 M /zahlen_codes 3 M /vorwort.tex 7 M /einleitung.tex 8 M /Makefile 10 M /my_def.tex 11 M /sw.tex 14 M /arith.tex 14 M /skript.tex 16 M /daten.tex 19 M /sn.tex 22 M /README.txt 28 M /skript.pdf With CodeAnalyzer over all .tex files: Revision 1 Revision 30 Total files 31 14 Total Lines 24,679 11,077 Avg Line Length 39 45 Code Lines 18,500 8,967 Comment Lines 1,124 871 Whitespace Lines 5,177 1,391 Resulting PDF pages 229 233 Examples 93 < 93 Images 211 211 StackExchange I've learned quite a lot about LaTeX while correcting the document. My questions on StackExchange might reflect that: xfig: What are epic macro, eepic macro and eepicemu macro in xfig? SetFigFontNFSS vs. SetFigFont Quotation marks: Is there any difference between \\grqq/\\glqq and \"` / \"'? How to use nag? - This gave me a lot of input what I could improve How should I prevent images from floating between list and paragraph before Can I tell LaTeX to break a list? How can I prevent breaks in a custom environment? Is it possible to define an environment that might not be displayed? Why doesn't grep give the matching line? And some language questions: Nummerierung im Text Gibt es ein Verb fÃ¼r \"Ein Zeichen wird durch seine Escape-Sequenz ersetzt\"? \"Theoretische Informatik\" oder \"theoretische Informatik\" What I've learned You can open file skript.tex on line 1234 with vim +1234 skript.tex grep -rniI , find , xargs , make and Meld are VERY useful I like Git more than SVN (because I don't need internet to commit) nag package is interesting There seems to be no good way to create images for digital electronics which might contain LaTeX. xfig is the best I found, but it is very hard to use. Conclusion Working as a \"Skript-HiWi\" is easy work, but more time consuming than you might think. Even if you know how to work with LaTeX. Rebuilding a big document takes some time. I was astonished that there were some topics which I didn't understand yet. After I've prepared for the exam, I thought I knew everything in the lecture notes. Obviously, this was not the case (or I forgot how to do division with twos complement meanwhile).","tags":"My bits and bytes","title":"Improving lecture notes: Job (almost) done!"},{"url":"https://martin-thoma.com/why-everybody-should-know-about-conditional-probability/","text":"Probability theory is difficult, but I think everybody should be taught basics in this subject. Why? Because it is relevant for everybody. Suppose you go to the doctor to make a cancer test. The test is positive. That means you have cancer, right? Wrong! Basics A probability is a numerical value in [0, 1] that is assigned to events (or lets rather say outcomes of an experiment). A probability can never be less than zero and never be more than one. The sum of all probabilities of all outcomes of one experiment is always 1. Example: Your experiment \\(x\\) could be throwing a coin. The outcome of your experiment is either head or tails. So if \\(Pr[x = \\text{head}] = 0.6\\) , then \\(Pr[x = \\text{tail}] = 0.4\\) . Now you might argue that the coin can also stand on its border. This would result in a different model of the situation with different probabilities, e.g.: \\(Pr[x = \\text{head}] = 0.559\\) , \\(Pr[x = \\text{border}] = 0.001\\) and \\(Pr[x = \\text{tail}] = 0.4\\) . Another very important rule is Bayes rule: \\(Pr[A|B] = \\frac{Pr[B|A] \\cdot Pr[A]}{Pr[B]}\\) This works also with more variables: \\(Pr[A|BC] = \\frac{Pr[B|AC] \\cdot Pr[A|C]}{Pr[B|C]}\\) Cancer Lets say the probability of having cancer is \\(Pr[C] = 0.01\\) . This means the probability of not having cancer is \\(Pr[\\neg C] = 0.99\\) . Now you have cancer tests. They can either be positive (+) which means they say you have cancer. Or they are negative (-), which means according to the test, you don't have cancer. They are not always working as expected. So you get so called \"false positives\" and \"false negatives\". A false positive is a positive result, while it should be negative. So the test says you have cancer, while you don't have cancer. It is denoted by \\(Pr[+ | \\neg C] = 0.2\\) . A false negative is a negative result, while it should be positive. So the test says you don't have cancer, but you actually have cancer. It is denoted by \\(Pr[- | C] = 0.1\\) . You should note that \\(Pr[+ | \\neg C] + Pr[- | C] = 0.2 + 0.1 = 0.3 \\neq 1\\) . Why is this the case? Because the test might also not be related at all to you having cancer. But \\(Pr[+ | \\neg C] + Pr[- | \\neg C]\\) has to be 1 and \\(Pr[+ | C] + Pr[- | C]\\) also has to be one. So you can draw this table: $Pr[\\text{Testresult}|\\text{Cancer}]$ $C$ $\\neg C$ $+$ $0.9$ $0.2$ $-$ $0.1$ $0.8$ You can see that the correct results are much more likely than the wrong ones. Some intermediate results How likely is a positive / negative test result? \\begin{align} Pr[+] &= Pr[+|C] \\cdot Pr[C] + Pr[+| \\neg C] \\cdot Pr[\\neg C] = 0.207\\\\ Pr[-] &= Pr[-|C] \\cdot Pr[C] + Pr[-| \\neg C] \\cdot Pr[\\neg C] = 0.793 \\end{align} How likely are the combinations? (This time you don't know if you have cancer): $Pr[\\text{Testresult}, \\text{Cancer}]$ $C$ $\\neg C$ $+$ $0.009$ $0.198$ $-$ $0.001$ $0.792$ Reversing it It is quite likely that you would like to know how likely it is that you have cancer. Without a test, you know: \\begin{align} Pr[C] &= 0.01\\\\ Pr[\\neg C] &= 0.99 \\end{align} Now you get a positive test result. How likely is it that you have cancer? In other words: Calculate \\(Pr[C|+]\\) \\begin{align} Pr[C|+] &= \\frac{Pr[C, +]}{Pr[+]} = \\frac{0.009}{0.207} = \\frac{1}{23} \\approx 0.043\\\\ Pr[\\neg C|+] &= 1 - \\frac{1}{23} = \\frac{22}{23} \\approx 0.957\\\\ Pr[C|-] &= \\frac{0.001}{0.793} = \\frac{1}{793} \\approx 0.001\\\\ Pr[\\neg C|-] &= 1 - \\frac{1}{793} = \\frac{792}{793} \\approx 0.999 \\end{align} How would you interpret these results? I'd say: When you get a positive result you shouldn't really worry. But perhaps you should make other tests. When you get a negative results you can be very sure that you don't have cancer. Testing again A very natural approach to a positive test result might be taking the same test again. How does this influence the probability? There are four possibilities what could have happened: You have cancer: Second test was negative Second test was positive You don't have cancer: Second test was negative Second test was positive First of all, I compare some intermediate results \\begin{align} Pr[++] &= Pr[C] \\cdot Pr[+|C] \\cdot Pr[+|C] + Pr[\\neg C] \\cdot Pr[+|\\neg C] \\cdot Pr[+|\\neg C]\\\\ &= 0.477 \\neq 0.042849 = 0.207&#94;2 = (Pr[+])&#94;2\\\\ Pr[+-] &= Pr[C] \\cdot Pr[+|C] \\cdot Pr[-|C] + Pr[\\neg C] \\cdot Pr[+|\\neg C] \\cdot Pr[-|\\neg C] \\\\ &= 0.01 \\cdot 0.9 \\cdot 0.1 + 0.99 \\cdot 0.2 \\cdot 0.8\\\\ &= 0.1593\\\\ Pr[C,+,+] &= Pr[C] \\cdot Pr[+ | C]&#94;2 = 0.01 \\cdot 0.9&#94;2 = 0.0081\\\\ Pr[C,+,-] &= Pr[C] \\cdot Pr[+ | C] \\cdot Pr[-|C] = 0.01 \\cdot 0.9 \\cdot 0.1 = 0.0009\\\\ Pr[C|++] &= \\frac{Pr[C,+,+]}{Pr[++]} = \\frac{0.0081}{0.207&#94;2} = \\frac{9}{530} \\approx 0.170\\\\ Pr[C|+-] &= \\frac{Pr[C,+,-]}{Pr[+-]} = \\frac{0.0009}{0.1593} = \\frac{1}{177} \\approx 0.006 \\end{align} Woooha! So if one test says you have cancer, don't worry. When two tests say you have cancer, you have a 17% chance of having cancer. On the other hand: One negative and one positive test is better than no test at all, because without a test you have a probability of 0.01 to have cancer. With both tests, you only have a probability of 0.006. Why probability is important for you As you might have seen, your intuition about probability is wrong. But we hear numbers all the time. It is important for us to understand them, so we should drop our intuition and learn how to use those numbers.","tags":"Mathematics","title":"Why everybody should know about conditional probability"},{"url":"https://martin-thoma.com/kollisionsresistente-hashfunktionen-und-einwegfunktionen/","text":"Definitionen Sei $f:X \\rightarrow Y$ eine Funktion. $f$ heiÃŸt eine Einwegfunktion, genau dann wenn fÃ¼r alle $x \\in X$ gilt: $y := f(x)$ kann in Polynomialzeit berechnet werden FÃ¼r die Berechnung eines Urbildes $x$ aus $y$ existiert kein randomisierter Algorithmus, der in Polynomialzeit lÃ¤uft. Eine Funktion $H:\\{0,1\\}&#94;* \\rightarrow \\{0,1\\}&#94;k$ heiÃŸt kollisionsresistente Hashfunktion , wenn gilt: Jeder effiziente Algorithmus findet nur mit kleiner Wahrscheinlichkeit eine Kollision. Was heiÃŸt â€žkleine Wahrscheinlichkeit\"? Nach dem Auswerten der Funktion \\(H\\) fÃ¼r \\(x_1, x_2, \\dots x_n\\) sollte die Wahrscheinlichkeit nicht signifikant hÃ¶her sein als \\(\\displaystyle 1-\\frac{n!\\cdot{{2&#94;k} \\choose n}}{{2&#94;k}&#94;n}\\) Diese Wahrscheinlichkeit kommt von dem Geburtstagsparadoxon bzw. dem Schubfachprinzip . Wir haben \\(2&#94;k\\) SchubfÃ¤cher (Funktionswerte) in die wir die \\(x_i\\) (Urbilder) einordnen kÃ¶nnen. Satz Behauptung : Jede kollisionsresistente Hashfunktion ist eine Einwegfunktion. Beweis : durch Widerspruch Sei \\(f\\) eine kollisionsresistente Hashfunktion Annahme : \\(f\\) ist keine Einwegfunktion Dann existiert ein Angreifer \\(\\mathcal{A}\\) , der fÃ¼r eine Bild \\(f(x)\\) ein \\(x'\\) findet, sodass \\(f(x) = f(x')\\) gilt. Der Angreifer \\(\\mathcal{B}\\) macht nichts anderes, als zufÃ¤llig Werte \\(x \\in \\{0,1\\}&#94;{2k}\\) zu wÃ¤hlen, \\(f(x)\\) zu berechnen, den Angreifer \\(\\mathcal{A}\\) auf \\(f(x)\\) anzuwenden und zu Ã¼berprÃ¼fen, ob das von \\(\\mathcal{A}\\) gelieferte \\(x' \\neq x\\) ist. Sobald das ein mal der Fall ist, hat der Angreifer gewonnen. Nun wenden wir \\(f\\) auf \\(x \\in \\{0,1\\}&#94;{2k}\\) an. Es gilt: \\(Pr_x[\\underbrace{|f&#94;{-1}(f(x))|}_{\\substack{\\text{Anzahl der Urbilder}\\\\\\text{zum Hashwert} f(x)} } = 1] \\leq \\frac{2&#94;k}{2&#94;{2k}} = \\frac{1}{2&#94;k}\\) . Die \\(2&#94;k\\) im ZÃ¤hler stehen fÃ¼r die Funktionswerte und die \\(2&#94;{2k}\\) fÃ¼r die Urbilder. Nun ist \\(\\frac{1}{2&#94;k}\\) eine vernachlÃ¤ssigbare Funktion. \\(\\Rightarrow\\) Die Wahrscheinlichkeit, dass wir keine Kollsion finden ist vernachlÃ¤ssigbar. \\(\\Rightarrow\\) Mit signifikanter Wahrscheinlichkeit hat \\(f(x)\\) \\(k \\geq 2\\) Urbilder. \\(\\Rightarrow\\) Die Wahrscheinlichkeit, dass \\(\\mathcal{B}\\) Kollisionen findet ist etwa \\((1-\\frac{1}{k}) \\cdot m\\) , wobei \\(m\\) die Anzahl der Widerholungen ist.","tags":"German posts","title":"Kollisionsresistente Hashfunktionen und Einwegfunktionen"},{"url":"https://martin-thoma.com/signs-that-it-is-too-hot-outside/","text":"Weather map Wetterkarte vom 26.07.2013 Wetterkarte vom 04.07.2015 See also 20 Signs It's Too Freaking Hot Outside - As a single image on imgur.com Another image","tags":"My bits and bytes","title":"Signs that it is too hot outside"},{"url":"https://martin-thoma.com/simquadrat/","text":"Simquadrat ist ein Dienst von sipgate . Das besondere daran ist, dass Simkarten verkauft werden, die eine Festnetznummer haben. Ich habe das ganze ausprobiert und will meine Erfahrungen nun teilen. Das Angebot Man geht auf simquadrat.de , bezahlt 4,95 Euro und bekommt eine Festnetznummer des Ortes, fÃ¼r den man die Postadresse angibt. Die meisten Leute, die ich kennen haben eine Festnetz-Flat. Das bedeutet, sie kÃ¶nnen mich kostenlos auf dem Handy anrufen. Toll, oder? Es ist ein Prepaid -Service. Das heiÃŸt, ich habe ein Guthaben, das ich vertelefonieren kann. Wenn das Guthaben weg ist, kann ich nicht mehr telefonieren. Das hat fÃ¼r mich vor allem den Vorteil, dass es keine versteckten Kosten gibt (bzw. diese micht nicht so hart treffen). FÃ¼r 10 Euro bekommt man eine 1-Monat-Festnetzflat . Die Bestellung Die Bestellung auf simquadrat.de ist extrem einfach. Bestellung bei Simquadrat Nach drei Schritten ist man wirklich fertig. Die beiden E-Mails, die man dann bekommt, sind auch schÃ¶n kurz: Simquadrat: BestÃ¤tigung Simquadrat: Rechnung Nach wenigen Tagen ist dann die Simkarte angekommen: Brief, Seite 1 Brief, Seite 2 Simkarte von Sipgate Wie man sieht, bekommt man eine Simkarte, wo man sich die richtige GrÃ¶ÃŸe herausbrechen kann. Micro- und Mini-Simkarten gehen also (bei Nano-Sim fÃ¼rs iPhone bin ich mir nicht sicher, aber ich glaube auch das konnte man angeben). Der Dienst Simquadrat hat sofort funktioniert. Ich konnte telefonieren und SMS schreiben (die aber nicht bei meiner Freundin angekommen sind ... aber das kÃ¶nnte auch gut an ihrem Handy/Anbieter liegen). Auch die Online-BenutzeroberflÃ¤che ist gut: Simquadrat - So siehts aus, wenn man eingeloggt ist ABER: Die TelefonqualitÃ¤t ist unterirdisch . Ich erwarte, dass der Zugangsanbieter mein GesprÃ¤ch in so guter QualitÃ¤t Ã¼bertrÃ¤gt, wie es mein Handy unterstÃ¼tzt. Mit Simyo ist die QualitÃ¤t genauso gut wie Ã¼ber das Festnetz-Telefon. Laut prepaid-wiki nutzt Simquadrat wie Simyo das E-Plus-Netz. Ich habe mit meiner Freundin mit meinem Nexus 4 am selben Tag (mit einem Abstand von 10 Minuten fÃ¼r dem Simkartenwechsel) einmal mit Simyo und einmal mit Simquadrat telefoniert. Das ist, im Bezug auf die QualitÃ¤t der SprachÃ¼bertragung, ein himmelweiter Unterschied. Fazit Wenn man sehr gÃ¼nstig in Deutschland erreichbar sein will, ist Simquadrat super. Sonst ist Simyo besser.","tags":"German posts","title":"Simquadrat"},{"url":"https://martin-thoma.com/dns-services/","text":"I've just read (ok, now it's over 3 months ago) that Google Public DNS now supports DNSSEC ( source ). I was curious what I currently use on my Linux Mint 14 machine. The relevant file is /etc/resolv.conf : nameserver 127.0.1.1 # OpenDNS Fallback (configured by Linux Mint in /etc/resolvconf/resolv.conf.d/tail). nameserver 208.67.222.222 nameserver 208.67.220.220 namebench A programm called namebench checks how fast several DNS configurations would be for you. namebench Further reading Dnsmasq (German) Debian manual - The hostname resolution : explains where 127.0.1.1 comes from","tags":"The Web","title":"DNS-Services"},{"url":"https://martin-thoma.com/sql-injections/","text":"SQL is a language that allows prorammers to access data in databases. Most of the time (always?) you pass your queries in form of strings to the database. In online services it is quite common that the programmer formulates a template and the user fills in variables. Example: IMDb Take a look at IMDb . Users can search for movies by title: IMDb: User Interface to search for a movie by title When you search for \"Harry Potter\" for example, the following happens: Search query within URL and results You obviously interacted with imdb.com in a very dynamic way. The output of the website depends on what you typed in and IMDb has to search in its database for your search terms. The programmers might have created a query that looks like this SELECT * FROM ` movie ` WHERE title = $ _GET [ 'q' ] Where $_GET['q'] is your query. Proof of concept You need: Apache Web Server PHP MySQL PhpMyAdmin (for convenience) When you search for \"LAMP\" (for Linux users) or for \"WAMP\" (for Windows users) you find a lot of information how to install this. Place the following as hack.php in your web servers directory (might be /var/www ): <? $mysqlhost = \"localhost\" ; $mysqluser = \"root\" ; $mysqlpwd = \"asdfasdf\" ; $connection = mysql_connect ( $mysqlhost , $mysqluser , $mysqlpwd ) or die ( \"Your connection string was wrong\" ); $db_selected = mysql_select_db ( 'imdb' , $connection ); $q = $_GET [ 'q' ]; if ( $q != \"\" ) { $result = mysql_query ( \"SELECT * FROM `movies` WHERE title=' $q '\" ); if ( ! $result ) { die ( 'MySQL query error: ' . mysql_error ()); } echo \"Found \" . mysql_num_rows ( $result ) . \" movies:<br/>\" ; while ( $row = mysql_fetch_assoc ( $result )) { echo $row [ \"id\" ] . \": \" . $row [ \"title\" ] . \"<br/>\" ; } } ?> <form method=\"get\" action=\"hack.php\"> <input type=\"text\" name=\"q\"/> <input type=\"submit\" /> </form> Now create a database called imdb with PHPMyAdmin and execute the following SQL: CREATE TABLE IF NOT EXISTS ` movies ` ( ` id ` int ( 11 ) NOT NULL AUTO_INCREMENT , ` title ` varchar ( 255 ) NOT NULL , PRIMARY KEY ( ` id ` ) ) AUTO_INCREMENT = 4 ; INSERT INTO ` movies ` ( ` id ` , ` title ` ) VALUES ( 1 , 'Harry Potter' ), ( 2 , 'Lord of the Rings' ), ( 3 , 'Rise of the Silver Surfer' ); CREATE TABLE IF NOT EXISTS ` users ` ( ` id ` int ( 11 ) NOT NULL AUTO_INCREMENT , ` username ` varchar ( 255 ) NOT NULL , ` password ` varchar ( 32 ) NOT NULL , ` email ` varchar ( 255 ) NOT NULL , PRIMARY KEY ( ` id ` ) ) AUTO_INCREMENT = 3 ; INSERT INTO ` users ` ( ` id ` , ` username ` , ` password ` , ` email ` ) VALUES ( 1 , 'admin' , 'qewrtqwert' , 'admin@imdb.com' ), ( 2 , 'user' , 'secret' , 'mylittlepony@stupid.com' ); Now go to http://localhost/hack.php . It should look like this: Screenshot of my minimal example When you search for \"Harry Potter\" it should show you \"1: Harry Potter\". Note that there could be a lot of information, but I wanted to keep this example as small as possible. Normal use of the web service This resulted in the following query: SELECT * FROM ` movies ` WHERE title = 'Harry Potter' But a Hacker could also enter a string like this: ' OR '1'='1 : What a hacker could do Even worse, the attacker could know that you use MySQL. Then he might know that MySQL uses INFORMATION_SCHEMA tables . He might enter this into the title input element: ' UNION SELECT table_name, table_type FROM information_schema.tables WHERE ' 1 '=' 1 which results in this query: SELECT * FROM ` movies ` WHERE title = '' UNION SELECT table_name , table_type FROM information_schema . tables WHERE '1' = '1' which gives: Attacker got all table names This way, the attacker gets all table names from all databases on this machine. So he essentially can get everything stored in your database. And, of course, after getting everything he could drop it: xkcd 327: Exploits of a mom History Just a few famous examples to show you that this happens all the time: 2005: USC admissions page ( source ) 2006: 800,000 datasets of personal information of students of UCLA ( source ) 2008, 2009: Heartland Payment Systems; 130 million credit and debit cards ( source 1 , source 2 , see Albert Gonzalez ) 2010: Royal Navy Website; Passwords and Usernames stolen ( source ) 2011: Sony: LulzSec says it accessed the passwords, email addresses, home addresses and dates of birth of one million users. The group says it also stole all admin details of Sony Pictures, including passwords. 75,000 music codes and 3.5 million music coupons were also accessed, according to the press release. ( source ) 2011: Expedia ( source ) 2011: MySql - Usernames and passwords stolen ( source 1 , source 2 ) 2011: Comodo ( source 1 , source 2 ) Solutions Sanitize user input, e.g. with mysql_real_escape_string Use prepared statements Switch of error reporting (this makes attacks more difficult, but doesn't prevent them) See also Challenge Websites : Try if you can write SQL injections yourself â˜º","tags":"Code","title":"SQL Injections"},{"url":"https://martin-thoma.com/medion-life-md-83962-e69229/","text":"Momentan kann man diese Blootooth Lautsprecher fÃ¼r 30 Euro bei Aldi kaufen: Medion MD 83962 Medion MD 83962: AnschlÃ¼sse Medion MD 83962: Micro-USB Netzteil Medion MD 83962: Micro-USB auf USB Anschluss Ich habe sie mir angeschaut, bin aber enttÃ¤uscht. Wenn ich sie per Bluetooth an mein Nexus 4 anschlieÃŸe gibt es hÃ¤ssliche GerÃ¤usche von sich. AuÃŸerdem ist die Audio-QualitÃ¤t nicht so toll und die Freisprechfunktion ist ... naja. Deutlich schechter als das interne Micro, wenn ich direkt zur Box rede. Um euch mal einen Vergleich zu geben, habe ich die ersten zwei Minuten des Open Movie \"Bick Buck Bunny\" mit meinem Nexus 4 aufgenommen. Bei der ersten Aufnahme hÃ¶rt man die erste 2 Minuten durch meine internen Notebook-Lautsprecher, bei der zweiten durch den Medion Life MD 83962 Lautsprecher (per Kabel mit dem Notebook verunden): Medion MD 83962: Bluetooth speakers Acer Travelmate 5744Z: Internal Speakers Hier hÃ¶rt man keinen groÃŸen Unterschied. Aber die internen Lautsprecher meines Acer Travelmate 5744Z hÃ¶ren sich besser an als der Bluetooth-Lautsprecher. Und das Micro ist wie gesagt ziemlich schlecht. Ich kann also definitiv keine Kaufempfehlung geben. Die MaÃŸe sind Ã¼brigens: 16,5 cm x 7,0 cm x 7,3 cm (Breite x Tiefe x HÃ¶he).","tags":"German posts","title":"Medion Life MD 83962 E69229"},{"url":"https://martin-thoma.com/data-backup-strategies/","text":"Yesterday, I thought what would happen if my internal or external hard drive crashed. The hard disk of this computer contains 53 GB of data (on Linux: df -H ). As my home folder only contains 35.3 GB of data, 17.7 GB seem to be programs. 21.1 GB the remaining data is for movies and 6.1 GB are for programming (and backed up via GitHub). Hence the by far biggest part of the lost data would be movies, the rest would be scattered across my home folder. The situation is similar for my external hard drive: A lot of video files, some audio files, A LOT of pictures and many, many miscellaneous files. I don't want to lose data, but I don't use my external HDD often. Most of the time I only have to do a RegEx search for file names (sometimes also a full text search for some files I found via RegEx) just to find out that the file I'm looking for is not there. Online Services I want to back up one computer with at least 200 GB which I don't need to access often and 10 GB that need to access often. A backup service should include software, that ... ... allows me to configurate upload / dowload bandwidth limts ... should integrate into my os in such a way that it feels like using a hard disk ... lets me upload files of sizes up to 5 GB ... uploads in background automatically as soon as my notebook gets an internet connection ... uploads only parts of files, if only parts changed ... starts uploading as soon as a file changed ... creates checksums and compares them to check if files were correctly uploaded A version control would be great, but that's a feature I don't expect. Also a possibility to share content (single files with a code) would be great, but I don't know if any of those services offers that. Name Euro / Year Free trial Clients Information Backblaze 37.06 Wiki Carbonite 46.78 Wiki CrashPlan 46.78 Wiki IDrive 116.58 - Jungle Disk 238.62 ? Wiki MiMedia 77.20 ? Wiki Mozy 131.00 Wiki Nomadesk 93.57 - SugarSync 194.94 Wiki Ubuntu One 187.09 Wiki I was a little bit surprised that there seems no way to use Google Drive as backup option (at least on Linux as there is this petition which was signed by 16,774 people). What could go wrong? A DOS attack against one of those companies might lead to temporarily unavailable services. Financial problems, bad backup techniques or personal mistakes might lead to permanent loss of data. Information might get leaked to the public. Information might get leaked to government ( PRISM , Tempora ) You might get analyzed by the company that stores your data. They could create a personal profile and sell that (maybe not even on the content you use, but perhaps only with filenames and edit times) The software you've installed for your backup might be a malware. The software you've installed might have security issues that allow attackers to execute malware. Offline RAID All RAID levels (except for RAID 0) offer redundancy. This means, they store data on more than one hard disk. This way, you can restore data after on (or if maybe more) hard disk crashes. But this is by no mean a guarantee that your data is secure. It's recommended to use RAID with a RAID controller (a dedicated piece of hardware). Otherwise, you need some software that does it and your CPU time gets wasted with these operations. What could go wrong: One disk fails. You buy a new one to get security back, the RAID controller copies information to the new disk that replaced the crashed one. While it copies, the other disk gets heavy load. This heavy load might lead to another crash. Boom. Your data is lost. Your computer might get damaged (e.g. by a fire, by an earthquake, by overvoltage, by a cup of tea you accidentally threw over it, by an act of agression ) A burglar would probably steal all hardware you have at home. But RAID is no option for me as I use a notebook as my main computer. External HDD A very easy way to secure your files is an external hard disk drive. You can choose by yourself what and when to save your files for redundancy. But as I know myself, I will make those backups less often after a while. So I guess this will not work for me. You could probably also make an external HDD raid. More possibilities Amazon S3 Glacier for 15.44 Euro/year or Amazon S3 Standard for 133.34 Euro/year e.g. with DragonDisk and others - transactions are not included! Give external hard disks to friends / to bank. Software: rsync for Linux Time machine for Mac See also Instapaper's backup method","tags":"Cyberculture","title":"Data Backup Strategies"},{"url":"https://martin-thoma.com/improve-german-public-transportation/","text":"Public transportation in Germany is much worse than it could be. I've got quite angry today because of that and thought about ways to improve the situation. A story from today: I've bought two tickets to get from Karlsruhe to Augsburg (230 km) in about a month. I wanted to visit my dad in summer break just after an exam. I've bought a fixed connection to get there for \"only\" 35 Euro instead of 59 Euro. But I've made a mistake, my conenction started to early. Two hours after having bought the tickets, I wanted to exchange them for a connection that starts later. But I had to pay 15 Euro for exchanging them, 15 Euro for canceling the connection. And it got worse: I had to give them my home address to get at least some of the money back. For what the hell do they need my home address? What could get improved? Most people basically choose one company: Deutsche Bahn It's too expensive. Customer service of \"Deutsche Bahn\" is very bad. Delays of at least 10 minutes always happen VERY often, delays of more than 30 minutes happen from time to time; I already had delay of more than 2 hours. Alternative companies Most people choose \"Deutsche Bahn\" (short: DB) because it is the biggest company that provides public transportation when you want to travel between cities. DB is well known and connects all big cities. However, there are alternatives. After a law (Â§ 13 Abs. 2 of the PersonenbefÃ¶rderungsgesetz ) was annulled, bus companies provided alternatives to traveling by train. Some companies are: MeinFernbus.de univers-reisen.de City2City.de But they are difficult to find and people maybe don't trust in them. Informing people Google Transit , FahrtenFuchs.de and Busliniensuche.de provide one possibility to inform people. But they all seem to have only a few bus companies. Google Transit is interesting as they provide format specification for exchanging transit information. What could be done Contact bus companies and ask them if they want to provide transit information to the public in Google Transit Feed Format. You might want to hint them to Google Transit Partner Program . I've contacted \"meinfernbus.de\" (Saturday, 06.07.2013). Lets see if they answer. Contacted \"KVV.de\" (Saturday, 06.07.2013) Contacted \"avv-augsburg.de\" (Saturday, 06.07.2013) Write software that allows bus companies to get their data into Google Transit Format Write standard relational SQL database to store the required information Create UI scribbles (e.g. with Balsamiq ) Write software Some reactions AVV (Augsburg) My email from 06.07.2013 to kundencenter@avv-augsburg.de: Sehr geehrte Damen und Herren, ich habe gerade gesehen, dass Google die MÃ¶glichkeit anbietet, die Fahrplaninformationen in Google Maps einzubinden: http://maps.google.com/help/maps/mapcontent/transit/index.html KÃ¶nnten Sie das anbieten? Es ist vermutlich deutlich einfacher, die Fahrplanauskunft von Google zu nutzen als auf die AVV-Seite zu gehen. Mit freundlichen GrÃ¼ÃŸen, Martin Thoma No reaction by now (21.07.2013) KVV (Karlsruhe) They have called me on 07.07.2013 and told me that they plan to bring the information to Google Maps, although they don't know how long it will take. MeinFernbus.de My email from 06.07.2013: Sehr geehrte Damen und Herren, ich habe mich heute sehr Ã¼ber die Deutsche Bahn geÃ¤rgert und auf der Suche nach Alternativen meinfernbus.de gefunden. Allerdings habe ich zuerst Ã¼ber Google Maps nach Busverbindungen zwischen Karlsruhe und Augsburg gesucht, wo mir leider nur die Bahn angeboten wurde. Haben Sie schon von Google Transit gehÃ¶rt? Was halten Sie davon, an diesem Programm teilzunehmen? Mit freundlichen GrÃ¼ÃŸen, Martin Thoma Answer from 08.07.2013: Sehr geehrter Herr Thoma, bitte entschuldigen Sie die spÃ¤te Antwort. Vielen Dank fÃ¼r Ihre Email, Ihre Kooperationsanfrage ist bei uns eingegangen. Wir freuen uns sehr, dass Sie mit MeinFernbus.de, dem MarktfÃ¼hrer im deutschen Fernbusverkehr, zusammenarbeiten mÃ¶chten. Wir prÃ¼fen gerne eine entsprechende Zusammenarbeit. Zu gegebener Zeit setzt sich unser Kooperationsmanager mit Ihnen in Verbindung. Aufgrund der Vielzahl eingehender Anfragen bitten wir Sie zunÃ¤chst noch um etwas Geduld. Vielen Dank fÃ¼r Ihr VerstÃ¤ndnis, herzliche GrÃ¼ÃŸe aus der Hauptstadt Friederike Freytag See also Reisetagebuch (A German comedian)","tags":"Cyberculture","title":"Improve German Public Transportation"},{"url":"https://martin-thoma.com/graphic-filters/","text":"I begin to fall in love with JavaScript and HTML5. You can access your Webcam with JS! As an example, I've implemented some graphic filters. Basics HTML5 You need: <canvas> <video> This is the bare minimum HTML code you need for valid HTML: <!DOCTYPE html> < html > < head > < title > Some title </ title > </ head > < body > < video autoplay id = \"vid\" style = \"display:none;\" ></ video > < canvas id = \"canvas\" width = \"640\" height = \"480\" ></ canvas > < script type = \"text/javascript\" src = \"graphic-filter.js\" > </ script > </ body > </ html > JavaScript Important functions / datastructures are: getUserMedia : see support by browsers ImageData : WTF? The image is a ONE dimensional array of integers in 0, ..., 255. So the first 4 array elements describe the pixel (0|0) with its RGBA value A starting point for your code might be: 'use strict' ; var video = document . querySelector ( \"#vid\" ); var canvas = document . querySelector ( '#canvas' ); var context = canvas . getContext ( '2d' ); var localMediaStream = null ; var onCameraFail = function ( e ) { console . log ( 'Camera did not work.' , e ); }; setInterval ( function snapshot () { if ( localMediaStream ) { context . drawImage ( video , 0 , 0 ); var width = 640 ; var height = 480 ; var imgDataNormal = context . getImageData ( 0 , 0 , width , height ); var imgData = context . createImageData ( width , height ); // convert image to grayscale for ( var i = 0 ; i < imgData . width * imgData . height * 4 ; i += 4 ) { var r = imgDataNormal . data [ i + 0 ]; var g = imgDataNormal . data [ i + 1 ]; var b = imgDataNormal . data [ i + 2 ]; var brightness = ( 3 * r + 4 * g + b ) >>> 3 ; imgData . data [ i ] = brightness ; imgData . data [ i + 1 ] = brightness ; imgData . data [ i + 2 ] = brightness ; } context . putImageData ( imgData , 0 , 0 ); } }, 500 ); navigator . getUserMedia = navigator . getUserMedia || navigator . webkitGetUserMedia || navigator . mozGetUserMedia || navigator . msGetUserMedia ; window . URL = window . URL || window . webkitURL ; navigator . getUserMedia ({ video : true }, function ( stream ) { video . src = window . URL . createObjectURL ( stream ); localMediaStream = stream ; }, onCameraFail ); console . log ( localMediaStream ); Interactive example You need a webcam for this: Open demonstration in new window This is what it should look like: Webcam example And it gives these results: Prewitt x-filter example Prewitt y-filter example Laplace filter example By the way, you can check if a website is currently accessing your webcam (with Google Chrome): Webcam indicator on tab in Google Chrome If you want to use these examples from your Android phone, you might have to enable getUserMedia. To do this, enable \"Web RTC\" in \"chrome://flags\": Enamble Web-RTC in Chrome for Android","tags":"Code","title":"Graphic filters"},{"url":"https://martin-thoma.com/threejs-is-awesome/","text":"I recently discovered three.js , a JavaScript library/API used to create and display animated 3D computer graphics. Here are some examples what you can do with three.js. It's pure JavaScript, no Flash required! They all worked smooth on my Notebook ( Intel Pentium P6200 processor) with Google Chrome 28 on Linux. You have to click on the links to see the examples! Stemkoski Textures Three.js textures example Demonstration Three.js Threejs Skybox example Demonstration Reflection Reflection example Demonstration Webcam Webcam example Demonstration Motion detection Motion detection with three.js! Demonstration 3D function plotter 3D function plotter Demonstration HexGL Demonstration Solar System Solar system simulation Demonstration Planet Maker PlanetMaker Demonstration - takes ages to load, but when its loaded it is fast See also stemkoski : Many examples Chrome Experiments","tags":"Code","title":"three.js is AWESOME!"},{"url":"https://martin-thoma.com/music-videos/","text":"Paint: Lord of the Rings Chatroulette Concert Chatroulette Love Song 28 Cartoon Theme Songs in 7 Minutes Bodo Wartke - Da muss er durch Liebeslied (In German, English, French, Spanish, Italian, Chinese, Russian, Turkish, Arabic, Bavarian, Swiss, Finnish) Believe in Steve Atomic Theory Song The 50 States Of The USA and The Capitals (From television series \"Animaniacs\") Nations of the world Yakko's Universe Song The Planet Song Panama Canal","tags":"Cyberculture","title":"Music videos"},{"url":"https://martin-thoma.com/spline-interpolation/","text":"Just like before with polynomial interpolation, we have a list of \\(n+1\\) given point \\((x_i, y_i)\\) with \\(x_0 < x_1 < \\dots < x_n\\) . We want to find a function that goes through those points and approximates the underlying function that produced that points as good as possible. Polynomial interpolation The problem of polynomial interpolation were oscillations at the end of the interval you wanted to interpolate (see interactive example ): Oscillations you get with polynomial interpolation As you can see, polynomial interpolation with equally spaced points is very, very bad at the ends of the interval. Tschebyscheff spaced points are much better, but you can still see that the interpolated function is different from the original. Splines A way to solve this problem are splines. A spline is a piecewise-defined function that goes through some points (aka knots) and is smooth. More formally: Let \\(s: [x_0,x_n] \\rightarrow \\mathbb{R}\\) be a spline. Then: (S1) cubic : \\(\\forall i \\in \\{1, \\dots, n\\}: s|_{x_{i-1}, x_i}\\) is a cubic function (S2) interpolation : \\(\\forall i \\in \\{0, \\dots, n\\}: s(x_i) = y_i\\) (S3) smooth : \\(s \\in C&#94;2([x_0, x_n])\\) and \\(\\int_{x_0}&#94;{x_n} s''(x)&#94;2 \\mathrm{d}x\\) is minimal When you use a cubic function \\(a x&#94;3 + b x&#94;2 + cx + d\\) for each of the \\(n\\) intervals that we got by our \\(n+1\\) points, you have \\(4n\\) variables that you need to calculate. Condition (S2) gives two equations per interval which makes \\(2n\\) equations of the form: $$ \\begin{align} y_i &= a_i x_i&#94;3 &&+ b_i x_i&#94;2 &&+ c_i x_i &&+ d_i\\\\ y_{i+1} &= a_i x_{i+1}&#94;3 &&+ b_i x_{i+1}&#94;2 &&+ c_i x_{i+1} &&+ d_i \\end{align} $$ At first glance condition (S3) - \\(s \\in C&#94;2([x_0, x_n])\\) - seems to be redundant with (S1) - \\(s\\) is piecewise cubic. Every polynomial is in \\(C&#94;\\infty(\\mathbb{R})\\) , so it certainly is in \\(C&#94;2([x_0, x_n])\\) . That's correct. But \\(s\\) is not a polynomial. It's only piecewise-defined as a polynomial. That makes a difference at the ends of the intervals. And it gives us \\(2n-2\\) more equations: $$\\displaystyle \\begin{align} s_i' (x_{i}) &= s_{i+1}'(x_{i}) \\;\\;\\; &&\\forall i=1, \\dots, n-1\\\\ s_i''(x_{i}) &= s_{i+1}''(x_{i}) \\;\\;\\; &&\\forall i=1, \\dots, n-1 \\end{align} $$ which is equivalent to $$\\displaystyle \\begin{align} 3a_i x_i&#94;2 + 2b_i x_i + c_i &= 3a_{i+1} x_i&#94;2 + 2b_{i+1} x_i + c_{i+1} \\;\\;\\; &&\\forall i=1, \\dots, n-1\\\\ 6a_i x_i + 2b_i &= 6a_{i+1} x_i + 2b_{i+1} \\;\\;\\; &&\\forall i=1, \\dots, n-1 \\end{align} $$ All equations we have are linear. Please note that the variables we want to determine are \\(a_i, b_i, c_i, d_i\\) . So \\(x_i&#94;3\\) is simply a multiplicative constant that we have to evaluate before we solve our system of equations. But at the moment, we only have \\(2n+2\\cdot(n-1) = 4n -2\\) equations, but we have \\(4n\\) variables. So we need ancillary conditions to solve this linear system of equations. Possible ancillary conditions natural splines : $s''(x_0) =0, \\;\\;\\; s''(x_n) = 0$ clamped splines : $s'(x_0) = f'(x_0),\\;\\;\\; s'(x_n)= f'(x_n)$ where $y_0'$ and $y_n'$ can be any value periodic : $s'(x_0) = s'(x_n), \\;\\;\\; s''(x_0) = s''(x_n)$ not-a-knot : $s_1''' = s_2''', \\;\\;\\; s_{n-1}''' = s_{n}'''$ George MacKerron shows how the results can differ in his article Cubic splines in JavaScript (via CoffeeScript) : Different results for different ancillary conditions Code for natural splines I will store splines as a list of maps. Each map is one piece of the spline and has: \\(u\\) : Start of the interval \\(v\\) : End of the interval \\(a,b,c,d\\) : cubic function \\(ax&#94;3 + bx&#94;2 + cx +d\\) Please note that I didn't test the code below. It's likely that there are errors with indices. #!/usr/bin/env python # -*- coding: utf-8 -*- def niceCubicPolynomial ( p ): tmp = \"\" if p [ \"a\" ] == 1 : tmp += \" x&#94;3\" elif p [ \"a\" ] != 0 : tmp += \" %.2f x&#94;3\" % p [ \"a\" ] if p [ \"b\" ] == 1 : tmp += \" \\t + x&#94;2\" elif p [ \"b\" ] != 0 : tmp += \" \\t + %.2f x&#94;2\" % p [ \"b\" ] else : tmp += \" \\t\\t \" if p [ \"c\" ] == 1 : tmp += \" \\t + x\" elif p [ \"c\" ] != 0 : tmp += \" \\t + %.2f x\" % p [ \"c\" ] else : tmp += \" \\t\\t \" if p [ \"d\" ] != 0 : tmp += \" \\t + %.2f \" % p [ \"d\" ] return tmp def getSpline ( points ): \"\"\" points should be a list of maps, where each map represents a point and has \"x\" and \"y\" \"\"\" import numpy , scipy.linalg # sort points by x value points = sorted ( points , key = lambda point : point [ \"x\" ]) n = len ( points ) - 1 # Set up a system of equations of form Ax=b A = numpy . zeros ( shape = ( 4 * n , 4 * n )) b = numpy . zeros ( shape = ( 4 * n , 1 )) for i in range ( 0 , n ): # 2n equations from condtions (S2) A [ i ][ 4 * i + 0 ] = points [ i ][ \"x\" ] ** 3 A [ i ][ 4 * i + 1 ] = points [ i ][ \"x\" ] ** 2 A [ i ][ 4 * i + 2 ] = points [ i ][ \"x\" ] A [ i ][ 4 * i + 3 ] = 1 b [ i ] = points [ i ][ \"y\" ] A [ n + i ][ 4 * i + 0 ] = points [ i + 1 ][ \"x\" ] ** 3 A [ n + i ][ 4 * i + 1 ] = points [ i + 1 ][ \"x\" ] ** 2 A [ n + i ][ 4 * i + 2 ] = points [ i + 1 ][ \"x\" ] A [ n + i ][ 4 * i + 3 ] = 1 b [ n + i ] = points [ i + 1 ][ \"y\" ] # 2n-2 equations for (S3): if i == 0 : continue # point i is an inner point A [ 2 * n + ( i - 1 )][ 4 * ( i - 1 ) + 0 ] = 3 * points [ i ][ \"x\" ] ** 2 A [ 2 * n + ( i - 1 )][ 4 * ( i - 1 ) + 1 ] = 2 * points [ i ][ \"x\" ] A [ 2 * n + ( i - 1 )][ 4 * ( i - 1 ) + 2 ] = 1 A [ 2 * n + ( i - 1 )][ 4 * ( i - 1 ) + 0 + 4 ] = - 3 * points [ i ][ \"x\" ] ** 2 A [ 2 * n + ( i - 1 )][ 4 * ( i - 1 ) + 1 + 4 ] = - 2 * points [ i ][ \"x\" ] A [ 2 * n + ( i - 1 )][ 4 * ( i - 1 ) + 2 + 4 ] = - 1 b [ 2 * n + ( i - 1 )] = 0 A [ 3 * n + ( i - 1 )][ 4 * ( i - 1 ) + 0 ] = 6 * points [ i ][ \"x\" ] A [ 3 * n + ( i - 1 )][ 4 * ( i - 1 ) + 1 ] = 2 A [ 3 * n + ( i - 1 )][ 4 * ( i - 1 ) + 0 + 4 ] = - 6 * points [ i ][ \"x\" ] A [ 3 * n + ( i - 1 )][ 4 * ( i - 1 ) + 1 + 4 ] = - 2 b [ 3 * n + ( i - 1 )] = 0 # Natural spline: A [ 3 * n - 1 + 0 ][ 0 + 0 ] += 6 * points [ 0 ][ \"x\" ] A [ 3 * n - 1 + 0 ][ 0 + 1 ] += 2 b [ 3 * n - 1 + 0 ] += 0 A [ 3 * n + n - 1 ][ 4 * ( n - 1 ) + 0 ] += 6 * points [ n ][ \"x\" ] A [ 3 * n + n - 1 ][ 4 * ( n - 1 ) + 1 ] += 2 b [ 3 * n + n - 1 ] += 0 x = scipy . linalg . solve ( A , b ) spline = [] for i in range ( 0 , n ): spline . append ({ \"u\" : points [ i ][ \"x\" ], \"v\" : points [ i + 1 ][ \"x\" ], \"a\" : float ( x [ 4 * i + 0 ]), \"b\" : float ( x [ 4 * i + 1 ]), \"c\" : float ( x [ 4 * i + 2 ]), \"d\" : float ( x [ 4 * i + 3 ])}) return spline if __name__ == \"__main__\" : points = [] points . append ({ \"x\" : 0.0 , \"y\" : - 4 }) points . append ({ \"x\" : 1.0 , \"y\" : 9 }) points . append ({ \"x\" : 2.0 , \"y\" : 35 }) points . append ({ \"x\" : 3.0 , \"y\" : 70 }) spline = getSpline ( points ) for p in spline : tmp = \"[ %.2f , %.2f ]:\" % ( p [ \"u\" ], p [ \"v\" ]) tmp += niceCubicPolynomial ( p ) print ( tmp ) See also How do the different ancillary conditions for splines differ?","tags":"Code","title":"Spline interpolation"},{"url":"https://martin-thoma.com/zero-mean-normalized-cross-correlation/","text":"An image from Tsukuba University. This is one of hundreds of images that you can use to test your algorithms. Link is below. Zero Mean Normalized Cross-Correlation or shorter ZNCC is an integer you can get when you compare two grayscale images. Lets say you have a webcam at a fixed position for security. It takes images all the time, but most of the time the room is empty. So quite a lot of images will not be interesting. They only waste space. So you want to get rid of those redundant images. BUT those images are not identical! Even if the scenery didn't change, your sensor will produce slightly different results. A human will not notice them, but you can't simply compare images bit by bit. Even if you could, the images will be different because the sun moved (and so do shadows) and perhaps you have a clock in the image. Now you can solve this problem with various techniques. I want to describe those techniques in a very general way. As the images in other scenarios might have different sizes and you probably don't want to compare whole images, I'll assume you have a part of both image of size \\((2n+1) \\times (2n+1)\\) . The pixel in the center has coordinates \\((u_1, v_1)\\) for the part of the first image and \\((u_2, v_2)\\) for the second image. Sum of squared differences Go through all pixels, get the difference of both and add up the squares: \\(\\displaystyle SSD(Img_1, Img_2, u_1, v_1, u_2, v_2, n) := \\sum_{i=-n}&#94;n \\sum_{j=-n}&#94;n \\left ( Img_1(u_1+i, v_1+j) - Img_2(u_2 + i, v_2 + j) \\right )&#94;2\\) When SSD is small, both images are very similar. Wehn SSD is 0, the images are identical. Zero Mean Normalized Cross-Correlation The average gray value is: \\(\\displaystyle \\overline{Img}(u, v, n) := \\frac{1}{(2n+1)&#94;2} \\sum_{i=-n}&#94;n \\sum_{j=-n}&#94;n Img(u+i, v+j)\\) The standard deviation is: \\(\\displaystyle \\sigma(u, v, n) := \\sqrt{\\frac{1}{(2n+1)&#94;2} \\left (\\sum_{i=-n} \\sum_{j=-n}&#94;n (Img(u +i, v+j)-\\overline{Img}(u, v, n))&#94;2 \\right )}\\) The ZNCC is defined as: \\(\\displaystyle ZNCC(Img_1, Img_2, u_1, v_1, u_2, v_2, n) := \\frac{\\frac{1}{(2n+1)&#94;2}\\sum_{i=-n}&#94;n \\sum_{j=-n}&#94;n \\prod_{t=1}&#94;2 \\left (Img_t (u_t+i,v_t+j) - \\overline{Img}(u_t, v_t, n) \\right )}{\\sigma_1(u_1, v_1, n) \\cdot \\sigma_2(u_2, v_2, n)}\\) The higher the ZNCC gets, the more are those two images correlated. (I think the value is always in [0, 1]) Here is some Python code: #!/usr/bin/env python # -*- coding: utf-8 -*- def getAverage ( img , u , v , n ): \"\"\"img as a square matrix of numbers\"\"\" s = 0 for i in range ( - n , n + 1 ): for j in range ( - n , n + 1 ): s += img [ u + i ][ v + j ] return float ( s ) / ( 2 * n + 1 ) ** 2 def getStandardDeviation ( img , u , v , n ): s = 0 avg = getAverage ( img , u , v , n ) for i in range ( - n , n + 1 ): for j in range ( - n , n + 1 ): s += ( img [ u + i ][ v + j ] - avg ) ** 2 return ( s ** 0.5 ) / ( 2 * n + 1 ) def zncc ( img1 , img2 , u1 , v1 , u2 , v2 , n ): stdDeviation1 = getStandardDeviation ( img1 , u1 , v1 , n ) stdDeviation2 = getStandardDeviation ( img2 , u2 , v2 , n ) avg1 = getAverage ( img1 , u1 , v1 , n ) avg2 = getAverage ( img2 , u2 , v2 , n ) s = 0 for i in range ( - n , n + 1 ): for j in range ( - n , n + 1 ): s += ( img1 [ u1 + i ][ v1 + j ] - avg1 ) * ( img2 [ u2 + i ][ v2 + j ] - avg2 ) return float ( s ) / (( 2 * n + 1 ) ** 2 * stdDeviation1 * stdDeviation2 ) if __name__ == \"__main__\" : A = [[ 1 , 2 , 3 ],[ 4 , 5 , 6 ],[ 7 , 8 , 9 ]] B1 = [[ 1 , 2 , 3 ],[ 4 , 5 , 6 ],[ 7 , 8 , 9 ]] B2 = [[ 1 , 2 , 3 ],[ 4 , 5 , 6 ],[ 7 , 8 , 7 ]] print ( zncc ( A , B1 , 1 , 1 , 1 , 1 , 1 )) print ( zncc ( A , B2 , 1 , 1 , 1 , 1 , 1 )) See also Feature point image matching Tsukuba University stereo images : Just in case you want to try those algorithms Correlation based similarity measures-Summary Bachelorarbeit : Bildvorverarbeitung und BildÃ¤hnlichkeitsfunktionen fÃ¼r beleuchtungstolerante visuelle Navigation (German)","tags":"Code","title":"Zero Mean Normalized Cross-Correlation"},{"url":"https://martin-thoma.com/javascript-wtf/","text":"JavaScript is THE web programming language. It gets interpreted by your browser and web applications like Google Mail, Google Maps and Facebook make heavy use of them. Almost always, when you see something working smoothly / interactive, you see JavaScript in action. But JavaScript has a lot of \"features\" which are ... well, I don't have words for those. Just continue reading. Most of the following content is from a StackOverflow question Strangest language feature Weak typing Example console . log ( 3. . toString ()); Output '3' Explanation 3. is a floating point and can get converted to a string. But 3.toString() gives SyntaxError: Unexpected token ILLEGAL Weak typing and string concatenation Example console . log ( '5' + 3 ); console . log ( '5' - 3 ); Output '53' 2 Explanation JavaScript automatically converts datatypes and + is used for string concatenation and for addition. In the first case, as the first datatype is a string and + is defined for strings as concatenation, JS converts 3 to '3' which results in the string '53' . In the second case, - is only defined for subtraction so '5' gets converted to a number (int? float? I don't know. I guess int.) Automatic semicolons Example 1 function test () { return { id : 1338 , title : 'This is a test' }; } console . log ( test ()); Example 2 function test () { return 2 + 2 ; } console . log ( test ()); Output 1 Uncaught SyntaxError: Unexpected token : Output 2 undefined Explanation JS adds a ; at every line end. Automatically. You can't prevent it. Please note that the second output is no error! It has a (valid) return value of undefined . Truth table Example console . log ( \"------- 0 == XYZ ---------\" ); console . log ( 0 == 0 ); console . log ( 0 == false ); console . log ( 0 == '' ); console . log ( 0 == null ); console . log ( 0 == undefined ); console . log ( 0 == \" \\t\\r\\n\" ); console . log ( 0 == '0' ); console . log ( 0 == 'false' ); console . log ( \"------- false == XYZ ---------\" ); console . log ( false == false ); console . log ( false == '' ); console . log ( false == null ); console . log ( false == undefined ); console . log ( false == \" \\t\\r\\n\" ); console . log ( false == '0' ); console . log ( false == 'false' ); console . log ( \"------- '' == XYZ ---------\" ); console . log ( '' == '' ); console . log ( '' == null ); console . log ( '' == undefined ); console . log ( '' == \" \\t\\r\\n\" ); console . log ( '' == '0' ); console . log ( '' == 'false' ); console . log ( \"------- null == XYZ ---------\" ); console . log ( null == null ); console . log ( null == undefined ); console . log ( null == \" \\t\\r\\n\" ); console . log ( null == '0' ); console . log ( null == 'false' ); console . log ( \"------- undefined == XYZ ---------\" ); console . log ( undefined == undefined ); console . log ( undefined == \" \\t\\r\\n\" ); console . log ( undefined == '0' ); console . log ( undefined == 'false' ); console . log ( \"------- \\t\\r\\n == XYZ ---------\" ); console . log ( \" \\t\\r\\n\" == \" \\t\\r\\n\" ); console . log ( \" \\t\\r\\n\" == '0' ); console . log ( \" \\t\\r\\n\" == 'false' ); console . log ( \"------- '0' == XYZ ---------\" ); console . log ( '0' == '0' ); console . log ( '0' == 'false' ); console . log ( \"------- 'false' == XYZ ---------\" ); console . log ( 'false' == 'false' ); console . log ( \"--------------------\" ); console . log ( \"------- XYZ == 0 ---------\" ); console . log ( 0 == 0 ); console . log ( false == 0 ); console . log ( '' == 0 ); console . log ( null == 0 ); console . log ( undefined == 0 ); console . log ( \" \\t\\r\\n\" == 0 ); console . log ( '0' == 0 ); console . log ( 'false' == 0 ); console . log ( \"------- XYZ == false ---------\" ); console . log ( false == false ); console . log ( '' == false ); console . log ( null == false ); console . log ( undefined == false ); console . log ( \" \\t\\r\\n\" == false ); console . log ( '0' == false ); console . log ( 'false' == false ); console . log ( \"------- XYZ == '' ---------\" ); console . log ( '' == '' ); console . log ( null == '' ); console . log ( undefined == '' ); console . log ( \" \\t\\r\\n\" == '' ); console . log ( '0' == '' ); console . log ( 'false' == '' ); console . log ( \"------- XYZ == null ---------\" ); console . log ( null == null ); console . log ( undefined == null ); console . log ( \" \\t\\r\\n\" == null ); console . log ( '0' == null ); console . log ( 'false' == null ); console . log ( \"------- XYZ == undefined ---------\" ); console . log ( undefined == undefined ); console . log ( \" \\t\\r\\n\" == undefined ); console . log ( '0' == undefined ); console . log ( 'false' == undefined ); console . log ( \"------- XYZ == \\t\\r\\n ---------\" ); console . log ( \" \\t\\r\\n\" == \" \\t\\r\\n\" ); console . log ( '0' == \" \\t\\r\\n\" ); console . log ( 'false' == \" \\t\\r\\n\" ); console . log ( \"------- XYZ == '0' ---------\" ); console . log ( '0' == '0' ); console . log ( 'false' == '0' ); console . log ( \"------- XYZ == 'false' ---------\" ); console . log ( 'false' == 'false' ); Output == 0 false '' null undefined \" \\t\\r\\n\" '0' 'false' 0 true true true false false true true false false true true true false false true true false '' true true true false false false false false null false false false true true false false false undefined false false false true true false false false \" \\t\\r\\n\" true true false false false true false false '0' true true false false false false true false 'false' false false false false false false false true Explanation Wow. This is fucked up. I've expected that strings compared to anything that is not the string itself evaluates to false. At least the table is symmetric and the diagonal is true. Please also note that JavaScript has a === operator. The truth Example console . log ( 2 == [ 2 ]); console . log ( 2 == [[ 2 ]]); Output true true Explanation At StackOverflow Date Example var futureDate = new Date ( 2010 , 77 , 154 ); console . log ( futureDate ); console . log ( futureDate . getYear ()); Output Tue Nov 01 2016 00 :00:00 GMT+0100 ( CET ) 116 Explanation 77 months and 154 days from the 0th day of 0th month of 2010 You should use getFullYear() instead of getYear() , as the later one returns year - 1900 (Why? When is this useful?) Integer overflow Example console . log ( 111111111111111111111 ); Output 111111111111111110000 Explanation It's ok that JavaScript fails at handling this integer. I think it converts this to a float, but I'm not sure about that. But no matter what it does here, it doesn't throw an error. That's bad. How is a developer supposed to know in a big application know when something went wrong? Function parameters In Javascript, declaring the parameters a function accepts is only a convenience to the programmer. All variables passed through the function call are accessible by the keyword arguments . So the following would alert \"world\": \u0002wzxhzdk:16\u0003 Source on StackOverflow Global variables Example var a = 12 ; function test () { a = 1337 ; } test (); console . log ( a ); Output 1337 Explanation When you forget to use var inside of test() you might accidentally use a global variable. See also Do you know some more JavaScript WTFs? You might also be interested in PHP: A strange language","tags":"Code","title":"JavaScript: WTF?!?"},{"url":"https://martin-thoma.com/polynomial-interpolation/","text":"Suppose you have a list of \\(n+1\\) given point \\((x_i, y_i)\\) with \\(i \\in \\{0, \\dots, n\\}\\) and \\(\\forall i,j \\in \\{0, \\dots, n\\}: i \\neq j \\Rightarrow x_i \\neq x_j\\) . Now you want to find a polynomial \\(\\displaystyle p(x) = \\sum_{i=0}&#94;n a_i \\cdot x&#94;i\\) that goes through all of the given points. This means: \\(\\forall i \\in \\{0, \\dots, n\\}: p(x_i) = y_i\\) Existence and uniqueness Theorem : When you have a list of \\(n+1\\) points with mutually different \\(x_i\\) there is exactly one polynom of degree \\(\\leq n\\) that fits those points. Proof : You can formulate a linear system of equations: $$\\underbrace{\\begin{pmatrix} x_0&#94;0 & \\cdots & x_0&#94;n \\\\ \\vdots & \\ddots & \\vdots \\\\ x_n&#94;0 & \\cdots & x_n&#94;n \\end{pmatrix} }_{:= A \\in \\mathbb{R}&#94;{(n+1) \\times (n+1)}} \\begin{pmatrix} a_0 \\\\ \\vdots \\\\ a_n \\end{pmatrix} = \\begin{pmatrix} y_0 \\\\ \\vdots \\\\ y_n \\end{pmatrix}$$ A matrix of the form of \\(A\\) is called Vandermonde matrix . When the data points \\(x_i\\) are mutually different, it is known that the Vandermonde matrix is invertible ( source ). This means, the solution \\((a_0 \\dots a_n)&#94;T\\) of this linear equation gives the polynom \\(p(x) = \\sum_{i=0}&#94;n a_i x&#94;i\\) So the solution exists and is unique \\(\\blacksquare\\) Straight forward interpolating polynomials For this algorithm, I'll find the polynomial in its monomial from \\(p(x) = \\sum_{i=0}&#94;n a_i x&#94;i\\) . I'll use the matrix \\(A\\) from section \" Uniqueness \". You might want to take a look at my article about Gaussian elimination . #!/usr/bin/env python # -*- coding: utf-8 -*- def pprintGaus ( A ): \"\"\" Pretty print a n&times;n matrix with a result vector n&times;1. \"\"\" n = len ( A ) for i in range ( 0 , n ): line = \"\" for j in range ( 0 , n + 1 ): line += str ( A [ i ][ j ]) + \" \\t \" if j == n - 1 : line += \"| \" print ( line ) print ( \"\" ) def pprintPolynomial ( A ): \"\"\" Pretty print a polynomial. \"\"\" line = \"\" for i in range ( len ( x ) - 1 , - 1 , - 1 ): if x [ i ] != 0 : if i == 0 : line += \"+\" + str ( x [ i ]) else : if x [ i ] == 1 : line += \"+ x&#94;\" + str ( i ) + \" \\t \" elif x [ i ] == - 1 : line += \"- x&#94;\" + str ( i ) + \" \\t \" else : line += \"+\" + str ( x [ i ]) + \"&middot;x&#94;\" + str ( i ) + \" \\t \" print ( line ) def gauss ( A ): \"\"\" Solve a linear sysem of equations given by a n&times;n matrix with a result vector n&times;1. \"\"\" n = len ( A ) for i in range ( 0 , n ): # Search for maximum in this column maxEl = abs ( A [ i ][ i ]) maxRow = i for k in range ( i + 1 , n ): if abs ( A [ k ][ i ]) > maxEl : maxEl = A [ k ][ i ] maxRow = k # Swap maximum row with current row (column by column) for k in range ( i , n + 1 ): tmp = A [ maxRow ][ k ] A [ maxRow ][ k ] = A [ i ][ k ] A [ i ][ k ] = tmp # Make all rows below this one 0 in current column for k in range ( i + 1 , n ): c = - A [ k ][ i ] / A [ i ][ i ] for j in range ( i , n + 1 ): if i == j : A [ k ][ j ] = 0 else : A [ k ][ j ] += c * A [ i ][ j ] # Solve equation Ax=b for an upper triangular matrix A x = [ 0 for i in range ( n )] for i in range ( n - 1 , - 1 , - 1 ): x [ i ] = A [ i ][ n ] / A [ i ][ i ] for k in range ( i - 1 , - 1 , - 1 ): A [ k ][ n ] -= A [ k ][ i ] * x [ i ] return x def setGauss ( points ): \"\"\" Create a system of equations for gaussian elimination from a set of points. \"\"\" n = len ( points ) - 1 A = [[ 0 for i in range ( n + 2 )] for j in range ( n + 1 )] for i in range ( n + 1 ): x = points [ i ][ \"x\" ] for j in range ( n + 1 ): A [ i ][ j ] = x ** j A [ i ][ n + 1 ] = points [ i ][ \"y\" ] return A if __name__ == \"__main__\" : from fractions import Fraction # Read input data points = [] points . append ({ \"x\" : Fraction ( - 1 ), \"y\" : Fraction ( 1 )}) points . append ({ \"x\" : Fraction ( 1 ), \"y\" : Fraction ( 1 )}) points . append ({ \"x\" : Fraction ( 2 ), \"y\" : Fraction ( 2 )}) A = setGauss ( points ) # Print input pprintGaus ( A ) # Calculate solution x = gauss ( A ) # Print result pprintPolynomial ( x ) It is also interesting to get the value of \\(p(x)\\) at any given point \\(x \\in \\mathbb{R}\\) : def evaluatePolynomial ( p , x ): y = 0 xi = 1 for i , a in enumerate ( p ): y += a * xi xi *= x return y Time complexity to get the polynomial: \\(\\frac{1}{3} n&#94;3 + \\mathcal{O}(n&#94;2)\\) (where \\(n\\) is the number of points) Space complexity for the polynomial: \\(\\mathcal{O}(n&#94;2)\\) (where \\(n\\) is the number of points) Time complexity to evaluate the value of \\(p(x)\\) for any \\(x \\in \\mathbb{R}\\) : \\(\\mathcal{O}(n)\\) . Polynomials \\(\\displaystyle \\mathbb{R}_n[X] := \\left \\{p:\\mathbb{R} \\rightarrow \\mathbb{R} | p(x) = \\sum_{i=0}&#94;n a_i \\cdot x&#94;i \\text{ with } a_0, \\dots, a_n \\in \\mathbb{R} \\right \\}\\) So \\(\\mathbb{R}_n[X]\\) are all polynomials with real coefficients and degree not higher than latex]n \\(. $\\mathbb{R}_n[X]\\) forms a vector space for \\(n \\in \\mathbb{N}_0\\) . The degree of that vector space is \\(n+1\\) . What does that mean? This means you can use different bases for polynomials. The base we usually use for \\(\\mathbb{R}_n[X]\\) is \\(\\{x&#94;0, x&#94;1, x&#94;2, x&#94;3, \\dots\\}\\) , but you can switch the base. Lagrange interpolation Define \\(n+1\\) polynomials like this: \\(\\displaystyle L_{i}(x) := \\prod_{j=0 \\atop j \\neq i}&#94;n \\frac{x-x_j}{x_i - x_j}\\) This means: \\(\\displaystyle L_{i}(x_i) := \\prod_{j=0 \\atop j \\neq i}&#94;n \\frac{x_i-x_j}{x_i - x_j} = 1\\) and \\(\\displaystyle L_{i}(x_p) := \\prod_{j=0 \\atop j \\neq i}&#94;n \\frac{x_p-x_j}{x_i - x_j} = 0 \\;\\; p \\in \\{0, \\dots, n\\} \\setminus \\{i\\}\\) So the polynomial \\(y_i \\cdot L_{i}(x)\\) fits the point \\((x_i, y_i)\\) and is zero for all other points. This implies that \\(\\displaystyle p(x) = \\sum_{i=0}&#94;n y_i \\cdot L_i(x)\\) is an interpolation of our data points. The degree of \\(p(x)\\) is not higher than \\(n\\) . You can see that easily when you take a look at the definition of \\(p(x)\\) and \\(L_i(x)\\) . The polynomials \\(L_i(x)\\) form another base for \\(\\mathbb{R}_n[X]\\) . Lagranges way to interpolate polynomials can be implemented like this: def lagrangeInterpolation ( points ): p = [] for i in range ( len ( points )): Li = { \"y\" : points [ i ][ \"y\" ], \"polynomial\" :[]} for j in range ( len ( points )): if j == i : continue Li [ \"polynomial\" ] . append ({ \"sub\" : points [ j ][ \"x\" ], \"divisor\" : points [ i ][ \"x\" ] - points [ j ][ \"x\" ] }) p . append ( Li ) return p def evaluateLagrangePolynomial ( p , x ): y = 0 for Li in p : prod = 1 for term in Li [ \"polynomial\" ]: prod *= ( x - term [ \"sub\" ]) / term [ \"divisor\" ] y += Li [ \"y\" ] * prod return y Time complexity to get the polynomial: \\(n&#94;2 + \\mathcal{O}(n)\\) (where \\(n\\) is the number of points) Space complexity for the polynomial: \\(\\mathcal{O}(n&#94;2)\\) (where \\(n\\) is the number of points) Time complexity to evaluate the value of \\(p(x)\\) for any \\(x \\in \\mathbb{R}\\) : \\(\\mathcal{O}(n&#94;2)\\) . Newton interpolation Define \\(\\displaystyle N_i(x) := \\prod_{j=0}&#94;{i-1} (x-x_j)\\) So you know that \\(N_i(x) = 0 \\Leftrightarrow \\exists p \\in \\{1, \\dots, i\\}: x = x_{i-p}\\) So your polynomial is \\(\\displaystyle p(x) = \\sum_{i=0}&#94;n c_i \\cdot N_i(x)\\) for the correct \\(c_i\\) . You can do this by solving the following system of equations. Please note that you don't have to store that matrix to get those \\(c_i\\) , divided differences are better. $$\\begin{pmatrix} 1 & & & & 0 \\\\ 1 & (x_1 - x_0) & & & \\\\ 1 & (x_2 - x_0) & (x_2 - x_0)(x_2 - x_1) & & \\\\ \\vdots & \\vdots & & \\ddots & \\\\ 1 & (x_n - x_0) & \\cdots & & \\prod_{i=0}&#94;{n-1}(x_n - x_i) \\\\ \\end{pmatrix} \\cdot \\begin{pmatrix} c_0 \\\\ \\vdots \\\\ c_n \\end{pmatrix} = \\begin{pmatrix} f_0 \\\\ \\vdots \\\\ f_n \\end{pmatrix}$$ You can get this lower triangular matrix like this: def getGaussSystemForNewton ( points ): n = len ( points ) - 1 A = [[ 0 for i in range ( n + 2 )] for j in range ( n + 1 )] for j in range ( 0 , n + 2 ): for i in range ( j , n + 1 ): if j == 0 : A [ i ][ j ] = 1 else : A [ i ][ j ] = A [ i ][ j - 1 ] * ( points [ i ][ \"x\" ] - points [ j - 1 ][ \"x\" ]) if j == n + 1 : for i in range ( 0 , n ): A [ i ][ j ] = points [ i ][ \"y\" ] return A From my previous posts about solving equations of upper triangular matrices and lower unitriangular matrices you know that the space complexity of this is in \\(\\Theta(n&#94;2)\\) . According to Wikipedia, you can use Horner's method to evaluate this Polynom in \\(\\mathcal{O}(n)\\) . But I really don't want to implement this today. Interactive example Click to add points. Ctrl+Click to remove point. You can enter a function that is valid JavaScript in the text field.","tags":"Code","title":"Polynomial interpolation"},{"url":"https://martin-thoma.com/mathematische-strukturen/","text":"Es gibt einen ganzen Haufen an mathematischen Strukturen. Dieser Artikel soll jeweils die Definition und bekannte Beispiele sammeln. Weitere Strukturen bzw. Beispiele kÃ¶nnen gerne in den Kommentaren genannt werden. Magma Sei $M$ eine Menge und $*:M \\times M \\rightarrow M$ eine auf $M$ abgeschlossene Abbildung. Dann heiÃŸt $(M,*)$ ein Magma . Sei $(M,*)$ ein Magma. $(M,*)$ heiÃŸt kommutativ $:\\Leftrightarrow \\forall a, b \\in M: a*b = b*a$. Ein Synonym zu â€žkommutativ\" ist â€žabelsch\". Beispiele: Jede Halbgruppe ist auch ein Magma. \\((\\mathbb{Z}, -)\\) ist ein Magma, aber keine Halbgruppe: \\(1-(1-1) = 1-0 = 1 \\neq -1 = 0-1 = (1-1)-1\\) \\((\\mathbb{R} \\setminus \\{0\\}, : )\\) ist ein Magma, aber keine Halbgruppe: \\(1 : (7:7)=1:1=1 \\neq \\frac{1}{49} = \\frac{1}{7} : 7 = (1:7):7\\) Gegenbeispiele: \\((\\mathbb{N}, : )\\) ist nicht abgeschlossen, also kein Magma. \\((\\mathbb{N}, - )\\) ist nicht abgeschlossen, also kein Magma. Halbgruppe Sei $(M, *)$ ein Magma. $(M, *)$ heiÃŸt Halbgruppe $:\\Leftrightarrow (M, *)$ ist assoziativ. Eine VerknÃ¼pfung \\(*\\) ist genau dann assoziativ auf einer Menge \\(M\\) , wenn gilt: \\(\\forall a,b,c \\in M: (a*b)*c = a*(b*c)\\) Beispiele: Jedes Monoid ist auch eine Halbgruppe. \\((\\mathbb{N}_{\\geq 1}, +)\\) ist eine Halbgruppe, aber kein Monoid. Monoid Sei $(M, *)$ eine Halbgruppe. $(M, *)$ heiÃŸt Monoid $:\\Leftrightarrow (M, *)$ hat ein neutrales Element $e_M$ Ein Element \\(e_M \\in M\\) heiÃŸt genau dann neutral, wenn gilt: \\(\\forall a \\in M: e_M * a = a * e_M = a\\) Beispiele: Jede Gruppe ist auch ein Monoid. \\((\\mathbb{N}_{0}, +)\\) ist mit 0 als Neutralelement ein Monoid, aber keine Gruppe. \\((\\mathbb{N}_{0}, \\cdot)\\) ist mit 1 als Neutralelement ein Monoid, aber keine Gruppe. \\((\\mathbb{Z}, \\cdot)\\) ist mit 1 als Neutralelement ein Monoid, aber keine Gruppe. Gruppe Sei $(M, *)$ ein Monoid. $(M, *)$ heiÃŸt Gruppe $:\\Leftrightarrow \\forall a \\in M: \\exists a&#94;{-1} \\in M: a * a&#94;{-1} = a&#94;{-1} * a = e_M$ Beispiele: Jeder Ring \\((R, +, \\cdot)\\) beinhaltet eine Gruppe \\((R, +)\\) . \\((\\mathbb{Q}, +)\\) \\((\\mathbb{R}, +)\\) \\((\\mathbb{Q} \\setminus \\{0\\}, \\cdot)\\) \\((\\mathbb{R} \\setminus \\{0\\}, \\cdot)\\) Ring Sei $R$ eine Menge und $+:R \\times R \\rightarrow R$, $\\cdot:R \\times R \\rightarrow R$ VerknÃ¼pfungen darauf. $(R, +, \\cdot)$ heiÃŸt Ring $:\\Leftrightarrow$ $(R,+)$ ist eine kommutative Gruppe (das Neutralelement heiÃŸe 0), $(R,\\cdot)$ ist eine Halbgruppe und die Distributivgesetze sind erfÃ¼llt. Die Distributivgesetze lauten: \\(\\forall a,b,c,d \\in R: (a+b) \\cdot c = ac + bc\\) und \\(\\forall a,b,c,d \\in R: a \\cdot (c+d) = ac + ad\\) AuÃŸerdem: Sei $(R,+,\\cdot)$ ein Ring. $(R,+,\\cdot)$ heiÃŸt Ring mit Eins $:\\Leftrightarrow (R, \\cdot)$ ist Monoid. Sei $(R,+,\\cdot)$ ein Ring. $(R,+,\\cdot)$ heiÃŸt kommutativer Ring $:\\Leftrightarrow (R, \\cdot)$ ist kommutativ. Beispiele: Jeder KÃ¶rper ist auch ein Ring. \\((\\mathbb{Z}, +, \\cdot)\\) ist ein kommutativer Ring mit Eins, aber kein KÃ¶rper. Es fehlen die Inversen bei der Multiplikation. KÃ¶rper Sei $(K, +, \\cdot)$ ein kommutativer Ring mit Eins. $(K, +, \\cdot)$ heiÃŸt KÃ¶rper $:\\Leftrightarrow$ $(K,+)$ ist kommutativ. $(K \\setminus \\{0\\}, \\cdot)$ ist kommutative Gruppe. Beispiele: \\((\\mathbb{Q}, +, \\cdot)\\) \\((\\mathbb{R}, +, \\cdot)\\) \\((\\mathbb{C}, +, \\cdot)\\) \\((\\mathbb{Z} / p \\mathbb{Z}, +, \\cdot)\\) , wobei \\(p\\) eine Primzahl ist Modul Sei $(R, +_R, \\cdot_R)$ ein Ring und $(M, +_M)$ eine kommutative Gruppe. AuÃŸerdem sei $\\cdot_V: R \\times M \\rightarrow M$ eine Abbildung. $(M, R, \\cdot_V)$ heiÃŸt R-Modul $:\\Leftrightarrow \\forall \\lambda, \\mu \\in R \\; x,y \\in M:$ $1_R \\cdot x = x$ $\\lambda \\cdot (\\mu \\cdot x) = (\\lambda \\cdot \\mu) \\cdot x$ $(\\lambda + \\mu) \\cdot x = \\lambda \\cdot x + \\mu \\cdot x$ $\\lambda \\cdot (x+y) = \\lambda \\cdot x + \\lambda \\cdot y$ Beispiele: Jeder K-Vektorraum ist auch ein K-Modul. Das \\(\\mathbb{Z}\\) -Modul \\(\\mathbb{Z}/2 \\mathbb{Z}\\) ist ein Modul ohne Basis, also kein Vektorraum. Vektorraum Sei $(K, +_K, \\cdot_K)$ ein KÃ¶rper und $(V,+_V)$ eine kommutative Gruppe. AuÃŸerdem sei $\\cdot_V: K \\times V \\rightarrow V$ eine skalalre Multiplikation . $(V, K, \\cdot_V)$ heiÃŸt $K$-Vektorraum $:\\Leftrightarrow \\forall \\lambda, \\mu \\in K \\; x,y \\in V:$ $1_K \\cdot x = x$ $\\lambda \\cdot (\\mu \\cdot x) = (\\lambda \\cdot \\mu) \\cdot x$ $(\\lambda + \\mu) \\cdot x = \\lambda \\cdot x + \\mu \\cdot x$ $\\lambda \\cdot (x+y) = \\lambda \\cdot x + \\lambda \\cdot y$ Beispiele: \\((\\mathbb{R}[X], \\mathbb{R}, \\cdot_V)\\) : Der Vektorraum der polynome mit Koeffizienten aus \\(\\mathbb{R}\\) . Weitere Ideal Ein Ideal in einem Ring $(R, +, \\cdot)$ ist eine Teilmenge $I \\subseteq R$, die bezÃ¼glich der Addition eine Untergruppe ist und die folgende Eigenschaft hat: $\\forall x \\in I, r \\in R: xr \\in I \\text{ und } rx \\in I$ Beispiele: Kerne von Ringhomomorphismen sind immer Ideale. (Und Ideale sind Kerne von Ringhomomorphismen.) Algebra Es sei $R$ ein Ring. Eine $R$-Algebra ist ein Ring $A$ zusammen mit einem Ringhomomorphismus $\\sigma: R \\rightarrow A$, sodass gilt: $\\forall r \\in R, a \\in A: \\sigma(r) \\cdot a = a \\cdot \\sigma(r)$ Beispiele: Jeder Ring ist eine \\(\\mathbb{Z}\\) -Algebra. IntegritÃ¤tsring Es sei $R$ ein vom Null-Ring verschiedener Ring. $R$ heiÃŸt integritÃ¤tsring $:\\Leftrightarrow R$ ist kommuativ und Nullteilerfrei. Beispiele: Zu dem Ring \\((\\mathbb{Z}, +, \\cdot)\\) ist \\((\\mathbb{Q}, +, \\cdot)\\) ein QuotientenkÃ¶rper. Hauptidealring Es sei $R$ ein IntegritÃ¤tsring. $R$ heiÃŸt Hauptidealring $:\\Leftrightarrow$ Jedes Ideal $I \\subseteq R$ ist ein Hauptideal. QuotientenkÃ¶rper Es sei $R$ ein IntegritÃ¤tsring. Der kleinste KÃ¶rper, in den $R$ eingebettet werden kann, wird der QuotientenkÃ¶rper des IntegritÃ¤tsrings genannt. Beispiele: Jeder KÃ¶rper ist ein IntegritÃ¤tsring. \\((\\mathbb{Z}, +, \\cdot)\\) Hilfsbegriffe Ideal Sei $(R, +, \\cdot)$ ein Ring und $I \\subseteq R$. $I$ heiÃŸt Ideal $:\\Leftrightarrow$ $(I, +)$ ist eine Gruppe, $\\forall r \\in R \\forall a \\in I: r \\cdot a \\in I$ und $\\forall r \\in R \\forall a \\in I: a \\cdot r \\in I$. Beispiele: Die Menge \\(2\\mathbb{Z}\\) der geraden ganzen Zahlen ist ein Ideal im Ring \\((\\mathbb{Z}, +, \\cdot)\\) . Hauptideal Sei $(R, +, \\cdot)$ ein Ring und $I \\subseteq R$ ein Ideal. $I$ heiÃŸt Hauptideal $:\\Leftrightarrow I$ wird von einem Element erzeugt. Beispiele: \\(n\\mathbb{Z}\\) Primideal Sei $(R, +, \\cdot)$ ein Ring und $I \\subsetneq R$ ein Ideal. $I$ heiÃŸt Primideal in $R :\\Leftrightarrow \\forall x, y \\in R: xy \\in I \\Rightarrow x \\in I \\lor y \\in I$ Beispiele: \\(2\\mathbb{Z}\\) ist Primideal in \\((\\mathbb{Z}, +, \\cdot)\\) Maximales Ideal Sei $(R, +, \\cdot)$ ein Ring und $I \\subsetneq R$ ein Ideal. $I$ heiÃŸt maximales Ideal in $R :\\Leftrightarrow$ Es gibt kein Ideal $J$, fÃ¼r das gilt: $I \\subsetneq J \\subsetneq R$ Beispiele: In \\((\\mathbb{Z},+,\\cdot)\\) ist jedes Primideal maximal.","tags":"German posts","title":"Mathematische Strukturen"},{"url":"https://martin-thoma.com/structs-in-c/","text":"I guess this article isn't very interesting, except if you have VERY little experience with C / C++. I only give some complete code examples. If you want some text, you could read C++ Programming/Structures (a wikibook). Point Basic example #include <iostream> using namespace std ; struct Point { double x ; double y ; }; int main () { Point a = { 12 , 34 }; printf ( \"(%.2f|%.2f) \\n \" , a . x , a . y ); return 0 ; } Functions #include <iostream> #define ABS(a) (a < 0 ? -(a) : a) using namespace std ; struct Point { double x ; double y ; }; double getManhattanDistance ( Point a , Point b ) { return ABS ( a . x - b . x ) + ABS ( a . y - b . y ); } int main () { Point a = { 1 , 1 }; Point b = { 3 , - 4 }; printf ( \"(%.2f|%.2f) \\n \" , a . x , a . y ); printf ( \"(%.2f|%.2f) \\n \" , b . x , b . y ); printf ( \"Distance: %.2f \\n \" , getManhattanDistance ( a , b )); return 0 ; } More stuff Initialization Point a = {} initializes all values of point to 0. Constructors You can write constructors for structs: #include <iostream> #define ABS(a) (a < 0 ? -(a) : a) using namespace std ; struct Point { double x ; double y ; Point () : x ( 2.0 ), y ( 5.0 ) {} Point ( double a , double b ) : x ( 9.0 ), y ( 9.0 ) { x = a ; y = b ;} }; double getManhattanDistance ( Point a , Point b ) { return ABS ( a . x - b . x ) + ABS ( a . y - b . y ); } int main () { Point a = {}; Point b = { 3 , - 4 }; Point c ; printf ( \"(%.2f|%.2f) \\n \" , a . x , a . y ); printf ( \"(%.2f|%.2f) \\n \" , b . x , b . y ); printf ( \"(%.2f|%.2f) \\n \" , c . x , c . y ); printf ( \"Distance: %.2f \\n \" , getManhattanDistance ( a , b )); return 0 ; } Which gives: ./struct-example.out ( 2 .00 | 5 .00 ) ( 3 .00 | -4.00 ) ( 2 .00 | 5 .00 ) Distance: 10 .00 Functions in structs You can also add functions to structs: #include <iostream> #define ABS(a) (a < 0 ? -(a) : a) using namespace std ; struct Point { double x ; double y ; Point () : x ( 2.0 ), y ( 5.0 ) {} Point ( double a , double b ) : x ( 9.0 ), y ( 9.0 ) { x = a ; y = b ;} double getZeroDist () { return ABS ( x ) + ABS ( y ); } }; double getManhattanDistance ( Point a , Point b ) { return ABS ( a . x - b . x ) + ABS ( a . y - b . y ); } int main () { Point a = { 3 , - 10 }; printf ( \"(%.2f|%.2f) \\n \" , a . x , a . y ); printf ( \"Distance: %.2f \\n \" , a . getZeroDist ()); return 0 ; } Result: ./struct-example.out ( 3 .00 | -10.00 ) Distance: 13 .00 Read also Wikipedia: struct (C programming language) Operator overloading A practical approach to floats : An example for union Connect four : One usage example for structs Is there anything interesting to say about structs?","tags":"Code","title":"Structs in C++"},{"url":"https://martin-thoma.com/calculate-square-roots/","text":"Suppose you have an equation like this: \\(x&#94;2 = a, \\;\\;\\;\\; a \\in \\mathbb{R}_{\\geq 0}\\) Your task is to compute the solution \\(x \\in \\mathbb{R}_{\\geq 0}\\) . How do you solve this algorithmically? Input and output Write a program that takes two parameters \\(a, n \\in \\mathbb{N}_{\\geq 1}\\) : \\(a\\) : The number you should take the square root of. \\(a\\) is not bigger than 65535. To make this a little bit simpler, you can also assume that \\(a\\) is an integer. \\(n\\) : Number of iterations you may use Your program should output exactly one positive floating point number. The decimal separator is a point. At the end of the number should be a newline character \\n . Reference code // Thanks to http://stackoverflow.com/a/15363123/562769 #include <stdio.h> #include <gmp.h> int main ( int argc , char * argv []) { mpf_t res , a ; mpf_set_default_prec ( 1000000 ); // Increase this number. mpf_init ( res ); mpf_init ( a ); mpf_set_str ( a , \"2\" , 10 ); mpf_sqrt ( res , a ); gmp_printf ( \"%.1000Ff \\n\\n \" , res ); // Increase this number. return 0 ; } You need GMP ( libgmp-dev ) to compile this. Compile it like this: gcc sqrt-reference.c -lgmp -lm -O0 -g3 -o reference.out This is the script I use to get the number of correct digits: #!/usr/bin/env python # -*- coding: utf-8 -*- def getScore ( program , a , n ): import os os . system ( \"./reference.out \" + str ( a ) + \" > reference.txt\" ) os . system ( \"./\" + program + \" \" + str ( a ) + \" \" + str ( n ) + \" > result.txt\" ) f = open ( 'reference.txt' , 'r' ) reference = f . read () f . close () f = open ( 'result.txt' , 'r' ) result = f . read () f . close () points = 0 areEqual = True while reference [ points ] != \" \\n \" and result [ points ] != \" \\n \" : if reference [ points ] == result [ points ]: points += 1 else : break if points >= 2 : points -= 1 # decimal point return points if __name__ == \"__main__\" : from argparse import ArgumentParser parser = ArgumentParser () # Add more options if you like parser . add_argument ( \"-p\" , \"--program\" , dest = \"program\" , help = \"your program\" , metavar = \"FILE\" , required = True ) parser . add_argument ( \"-a\" , metavar = 'A' , type = int , required = True , help = \"calculate squre root of a\" ) parser . add_argument ( \"-n\" , metavar = 'N' , type = int , required = True , help = \"maximum n iterations\" ) args = parser . parse_args () print ( \"Points for a= %i and n= %i : %i \" % ( args . a , args . n , getScore ( args . program , args . a , args . n ))) Newton's method How should be choose the initial value? I thought \\(\\frac{a}{2}\\) could be ok. In a good implementation you'll probably do this with a lookup table. With long double: #include <iostream> #include <cmath> using namespace std ; long double newton ( int a , int n ) { long double x = (( long double ) a ) / 2 ; for ( int i = 0 ; i < n ; i ++ ) { x = x - ( x * x - a ) / ( 2 * x ); } return x ; } int main ( int argc , char * argv []) { if ( argc != 3 ) { cout << \"Please enter exactly two arguments.\" << endl ; return 1 ; } int a = atoi ( argv [ 1 ]); int n = atoi ( argv [ 2 ]); printf ( \"%.80Lf \\n \" , newton ( a , n )); return 0 ; } I failed to convert this to a version that uses GMP :-/ But it converges quite fast: Newtons method for calculating square roots Exponential identity According to Wikipedia (Source: Methods of computing square roots ) many calculators use the following identity: \\(\\displaystyle \\sqrt{a} = e&#94;{\\frac{1}{2}\\ln a}\\) But to calculate this, you need to be able to calculate \\(e&#94;x\\) for \\(x \\in \\mathbb{R}_{\\geq 0}\\) and \\(\\ln(a)\\) for \\(a \\in \\mathbb{R}_{\\geq 0}\\) . I've used the definition of \\(e&#94;x\\) to calculate \\(e&#94;x\\) : \\(\\displaystyle e&#94;x := \\sum_{i = 0}&#94;\\infty \\frac{x&#94;i}{i!}\\) and: \\(\\displaystyle \\ln(1+x) =- \\sum_{k=0}&#94;\\infty \\frac{(-x)&#94;{k+1}}{k+1}\\) So I gave it a try: #include <iostream> #include <cmath> using namespace std ; long double ln ( int S , int n ) { long double tmp = S - 1 ; long double result = tmp ; long double sign = 1.0 ; for ( int i = 2 ; i < n / 2 ; i ++ ) { tmp *= ( S - 1 ); sign *= - 1 ; result += sign * tmp / i ; } return result ; } long double e ( long double x , int n ) { long double numerator = 1 ; long double denominator = 1 ; long double result = 1 ; for ( int i = 1 ; i < n / 2 ; i ++ ) { numerator *= x ; denominator *= i ; result += numerator / denominator ; } return result ; } long double sqrt ( int a , int n ) { return e ( ln ( a , n ) * 0.5 , n ); } int main ( int argc , char * argv []) { if ( argc != 3 ) { cout << \"Please enter exactly two arguments.\" << endl ; return 1 ; } int a = atoi ( argv [ 1 ]); int n = atoi ( argv [ 2 ]); printf ( \"%.80Lf \\n \" , sqrt ( a , n )); return 0 ; } This converges VERY slow: For \\(a = 2\\) $n=1$: 1 digit correct $n=10$: 1 digit correct $n=100$: 2 digits correct $n=1000$: 4 digit correct $n=10,000$: 5 digit correct $n=100,000$: 5 digit correct $n=1,000,000$: 6 digit correct Ok, lets take a better Taylor series for calculating \\(e&#94;x\\) : \\(\\displaystyle e&#94;x = \\sum_{k=0}&#94;\\infty \\frac{x&#94;{-1+2 k} (2 \\cdot k+x)}{(2\\cdot k)!}\\) This didn't change anything! I'm very surprised ... as I've calculated \\(\\pi\\) for another article, changing the series to something similar improved the speed of convergence drastically. See also StackOverflow: How does the computer calculate Square roots? IntelÂ® 64 and IA-32 Architectures Software Developer's Manual : FSQRT, SQRTPS, SQRTSS Source code of this article Feel free to add a program that calculates square roots. When they are interesting, I'll probably add them to this article.","tags":"Cyberculture","title":"Calculate square roots"},{"url":"https://martin-thoma.com/inverting-matrices/","text":"Suppose you have a matrix \\(A \\in \\mathbb{R}&#94;{n \\times n}\\) and you want to invert it. I've already explained how to invert a matrix ( English explanation ), but I didn't provide any code and / or runtime analysis. C++ Code #include <iostream> #include <cmath> #include <vector> using namespace std ; void print ( vector < vector < double > > A ) { int n = A . size (); for ( int i = 0 ; i < n ; i ++ ) { for ( int j = 0 ; j < 2 * n ; j ++ ) { cout << A [ i ][ j ] << \" \\t \" ; if ( j == n - 1 ) { cout << \"| \" ; } } cout << \" \\n \" ; } cout << endl ; } void calculateInverse ( vector < vector < double > >& A ) { int n = A . size (); for ( int i = 0 ; i < n ; i ++ ) { // Search for maximum in this column double maxEl = abs ( A [ i ][ i ]); int maxRow = i ; for ( int k = i + 1 ; k < n ; k ++ ) { if ( abs ( A [ k ][ i ]) > maxEl ) { maxEl = A [ k ][ i ]; maxRow = k ; } } // Swap maximum row with current row (column by column) for ( int k = i ; k < 2 * n ; k ++ ) { double tmp = A [ maxRow ][ k ]; A [ maxRow ][ k ] = A [ i ][ k ]; A [ i ][ k ] = tmp ; } // Make all rows below this one 0 in current column for ( int k = i + 1 ; k < n ; k ++ ) { double c = - A [ k ][ i ] / A [ i ][ i ]; for ( int j = i ; j < 2 * n ; j ++ ) { if ( i == j ) { A [ k ][ j ] = 0 ; } else { A [ k ][ j ] += c * A [ i ][ j ]; } } } } // Solve equation Ax=b for an upper triangular matrix A for ( int i = n - 1 ; i >= 0 ; i -- ) { for ( int k = n ; k < 2 * n ; k ++ ) { A [ i ][ k ] /= A [ i ][ i ]; } // this is not necessary, but the output looks nicer: A [ i ][ i ] = 1 ; for ( int rowModify = i - 1 ; rowModify >= 0 ; rowModify -- ) { for ( int columModify = n ; columModify < 2 * n ; columModify ++ ) { A [ rowModify ][ columModify ] -= A [ i ][ columModify ] * A [ rowModify ][ i ]; } // this is not necessary, but the output looks nicer: A [ rowModify ][ i ] = 0 ; } } } int main () { int n ; cin >> n ; vector < double > line ( 2 * n , 0 ); vector < vector < double > > A ( n , line ); // Read input data for ( int i = 0 ; i < n ; i ++ ) { for ( int j = 0 ; j < n ; j ++ ) { cin >> A [ i ][ j ]; } } for ( int i = 0 ; i < n ; i ++ ) { A [ i ][ n + i ] = 1 ; } // Print input print ( A ); // Calculate solution calculateInverse ( A ); // Print result cout << \"Result:\" << endl ; print ( A ); } This code is VERY similar to the code of Gaussian elimination . In fact, I've only changed all occurrences of n+1 to 2*n . I also had to change lines 57-70, as we need to do all operations now on a matrix instead of a vector. Time complexity Lines 43-52: \\(\\displaystyle Operations = \\sum_{i=0}&#94;{n-1} \\left (\\sum_{k=i+1}&#94;{n-1} (\\sum_{j=i}&#94;{2n} 1) \\right ) = \\frac{5}{6} n&#94;3 - \\frac{5}{6} n\\) (see Wolfram|Alpha ) Lines 63-70: \\(\\displaystyle Operations = \\sum_{i=0}&#94;{n-1} \\left (\\sum_{k=0}&#94;{i-1} (\\sum_{j=n}&#94;{2n} 1) \\right ) = \\frac{1}{2} n&#94;3 - \\frac{1}{2} n\\) (see Wolfram|Alpha ) So we need about \\(\\frac{4}{3} n&#94;3 + \\mathcal{O}(n&#94;2)\\) operations to invert a matrix with GauÃŸ-Elimination. Space complexity My algorithm needs space for the inverse matrix, so it is in \\(\\mathcal{O}(n&#94;2)\\) . Inverting an upper triangular matrix Suppose you have an upper triangular matrix \\(A \\in \\mathbb{R&#94;{n \\times n}}\\) that you would like to invert. It could look like this: \\( \\begin{pmatrix} 2 & 7 & 1 & 8 & 2\\\\ 0 & 8 & 1 & 8 & 2\\\\ 0 & 0 & 8 & 4 & 5\\\\ 0 & 0 & 0 & 9 & 0\\\\ 0 & 0 & 0 & 0 & 4 \\end{pmatrix} \\) How could we improve the algorithm from above to get speed it up? Well, we don't need lines 24-53 any more, as those lines bring \\(A\\) to an upper triangular form. But we still need lines 63-70. So we can improve the algorithm to a complexity of \\(\\frac{1}{2} n&#94;3 + \\mathcal{O}(n&#94;2)\\) . See also Computational complexity of mathematical operations","tags":"Code","title":"Inverting matrices"},{"url":"https://martin-thoma.com/fractions-in-cpp/","text":"Today, I thought I should try to implement a class in C++ that deals with fractions. This is actually quite easy as I'll show you. First some math Names When you have a fraction \\(\\frac{a}{b}\\) then \\(a\\) is called numerator and \\(b\\) is called denominator . Operations The rules for basic operations are simple: Addition: \\(\\frac{a}{b} + \\frac{c}{d} = \\frac{a \\cdot d + c \\cdot b}{b \\cdot d}\\) Subtraction: \\(\\frac{a}{b} - \\frac{c}{d} = \\frac{a \\cdot d - c \\cdot b}{b \\cdot d}\\) Multiplication: \\(\\frac{a}{b} \\cdot \\frac{c}{d} = \\frac{a \\cdot c}{b \\cdot d}\\) Division: \\(\\frac{a}{b} : \\frac{c}{d} = \\frac{a \\cdot d}{b \\cdot c}\\) Euklids algorithm You can calculate the greatest common divisor with Euklids algorithm . If you don't know it, please read the Wikipedia article. Knowing the greatest common divisor is important, because we want that our Faction class automatically cancels those factors so that the numerator and denominator are as small as possible. C++ Code #include <iostream> using namespace std ; class Fraction { private : // Calculates the greates common divisor with // Euclid's algorithm // both arguments have to be positive long long gcd ( long long a , long long b ) { while ( a != b ) { if ( a > b ) { a -= b ; } else { b -= a ; } } return a ; } public : long long numerator , denominator ; Fraction () { numerator = 0 ; denominator = 1 ; } Fraction ( long long n , long long d ) { if ( d == 0 ) { cerr << \"Denominator may not be 0.\" << endl ; exit ( 0 ); } else if ( n == 0 ) { numerator = 0 ; denominator = 1 ; } else { int sign = 1 ; if ( n < 0 ) { sign *= - 1 ; n *= - 1 ; } if ( d < 0 ) { sign *= - 1 ; d *= - 1 ; } long long tmp = gcd ( n , d ); numerator = n / tmp * sign ; denominator = d / tmp ; } } operator int () { return ( numerator ) / denominator ;} operator float () { return (( float ) numerator ) / denominator ;} operator double () { return (( double ) numerator ) / denominator ;} }; Fraction operator + ( const Fraction & lhs , const Fraction & rhs ) { Fraction tmp ( lhs . numerator * rhs . denominator + rhs . numerator * lhs . denominator , lhs . denominator * rhs . denominator ); return tmp ; } Fraction operator += ( Fraction & lhs , const Fraction & rhs ) { Fraction tmp ( lhs . numerator * rhs . denominator + rhs . numerator * lhs . denominator , lhs . denominator * rhs . denominator ); lhs = tmp ; return lhs ; } Fraction operator - ( const Fraction & lhs , const Fraction & rhs ) { Fraction tmp ( lhs . numerator * rhs . denominator - rhs . numerator * lhs . denominator , lhs . denominator * rhs . denominator ); return tmp ; } Fraction operator -= ( Fraction & lhs , const Fraction & rhs ) { Fraction tmp ( lhs . numerator * rhs . denominator - rhs . numerator * lhs . denominator , lhs . denominator * rhs . denominator ); lhs = tmp ; return lhs ; } Fraction operator * ( const Fraction & lhs , const Fraction & rhs ) { Fraction tmp ( lhs . numerator * rhs . numerator , lhs . denominator * rhs . denominator ); return tmp ; } Fraction operator *= ( Fraction & lhs , const Fraction & rhs ) { Fraction tmp ( lhs . numerator * rhs . numerator , lhs . denominator * rhs . denominator ); lhs = tmp ; return lhs ; } Fraction operator * ( int lhs , const Fraction & rhs ) { Fraction tmp ( lhs * rhs . numerator , rhs . denominator ); return tmp ; } Fraction operator * ( const Fraction & rhs , int lhs ) { Fraction tmp ( lhs * rhs . numerator , rhs . denominator ); return tmp ; } Fraction operator / ( const Fraction & lhs , const Fraction & rhs ) { Fraction tmp ( lhs . numerator * rhs . denominator , lhs . denominator * rhs . numerator ); return tmp ; } std :: ostream & operator << ( std :: ostream & strm , const Fraction & a ) { if ( a . denominator == 1 ) { strm << a . numerator ; } else { strm << a . numerator << \"/\" << a . denominator ; } return strm ; } int main () { Fraction a ( 1 , 3 ); Fraction b ( 3 , 28 ); Fraction c ; c = a + b ; cout << c << \" \\t (should be 37/84)\" << endl ; c = a - b ; cout << c << \" \\t (should be 19/84)\" << endl ; c = a * b ; cout << c << \" \\t (should be 1/28)\" << endl ; c = a / b ; cout << c << \" \\t (should be 28/9)\" << endl ; c = - 1 * b ; cout << c << \" \\t (should be -3/28)\" << endl ; c = b * ( - 1 ); cout << c << \" \\t (should be -3/28)\" << endl ; c = Fraction ( - 100 , 3 ); cout << ( int ) c << \" \\t (should be -33)\" << endl ; cout << ( float ) c << \" \\t (should be -33.3...)\" << endl ; cout << ( double ) c << \" \\t (should be -33.3...)\" << endl ; a -= b ; cout << a << \" \\t (should be 19/84)\" << endl ; return 0 ; } See also You might also be interested in my article about operator overloading . Does anybody know if there is an \"official\" Fraction class?","tags":"Code","title":"Fractions in C++"},{"url":"https://martin-thoma.com/solving-linear-equations-with-gaussian-elimination/","text":"Please note that you should use LU-decomposition to solve linear equations. The following code produces valid solutions, but when your vector $b$ changes you have to do all the work again. LU-decomposition is faster in those cases and not slower in case you don't have to solve equations with the same matrix twice. Suppose you have a system of \\(n \\in \\mathbb{N_{\\geq 1}}\\) linear equations and variables \\(x_1, x_2, \\dots, x_n \\in \\mathbb{R}\\) : \\begin{align} a_{1,1} \\cdot x_1 + a_{1,2} x_2 + \\dots + a_{1,n} \\cdot x_{n} &= b_1\\\\ a_{2,1} \\cdot x_1 + a_{2,2} x_2 + \\dots + a_{2,n} \\cdot x_{n} &= b_2\\\\ \\vdots &= \\vdots\\\\ a_{n,1} \\cdot x_1 + a_{n,2} x_2 + \\dots + a_{n,n} \\cdot x_{n} &= b_n \\end{align} All factors \\(a_{i,j} \\in \\mathbb{R}\\) for \\(i,j \\in 1, \\dots, n\\) can be written in one matrix \\(A \\in \\mathbb{R}&#94;{n \\times n}\\) and all \\(b_i\\) can be written as a vector \\(b\\) . You combine all \\(x_i\\) in the same way to a vector \\(x\\) . So you can write the system of equations as: \\(A \\cdot x = b\\) How Gaussian elimination works First, you write \\(A\\) and \\(b\\) in an augmented matrix \\((A|b)\\) : $$ \\left(\\begin{array}{cccc|c} a_{1,1} & a_{1,2} & \\dots & a_{1,n} & b_1\\\\ a_{2,1} & a_{2,2} & \\dots & a_{2,n} & b_2\\\\ \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\ a_{n,1} & a_{n,2} & \\dots & a_{n,n} & b_n \\end{array}\\right)$$ On this matrix you may make exactly three operations: Swap rows Add one row onto another Multiply every factor of one row with a constant You want to get a triangular matrix. So you subsequently eliminate one variable from the system of equations until you have a matrix like this: $$ \\left(\\begin{array}{ccccc|c} a_{1,1} & a_{1,2} & a_{1,3} & \\dots & a_{1,n} & b_1\\\\ 0 & a_{2,2} & a_{2,3} & \\dots & a_{2,n} & b_2\\\\ 0 & 0 & a_{3,3} & \\dots & a_{3,n} & b_3\\\\ \\vdots & \\vdots & \\ddots & \\ddots& \\vdots & \\vdots\\\\ 0 & 0 & \\dots & 0 & a_{3,n} & b_n\\\\ \\end{array}\\right)$$ It's actually quite simple to get this form: Pseudocode for Gaussian elimination C++ Code #include <iostream> #include <cmath> #include <vector> using namespace std ; void print ( vector < vector < double > > A ) { int n = A . size (); for ( int i = 0 ; i < n ; i ++ ) { for ( int j = 0 ; j < n + 1 ; j ++ ) { cout << A [ i ][ j ] << \" \\t \" ; if ( j == n - 1 ) { cout << \"| \" ; } } cout << \" \\n \" ; } cout << endl ; } vector < double > gauss ( vector < vector < double > > A ) { int n = A . size (); for ( int i = 0 ; i < n ; i ++ ) { // Search for maximum in this column double maxEl = abs ( A [ i ][ i ]); int maxRow = i ; for ( int k = i + 1 ; k < n ; k ++ ) { if ( abs ( A [ k ][ i ]) > maxEl ) { maxEl = abs ( A [ k ][ i ]); maxRow = k ; } } // Swap maximum row with current row (column by column) for ( int k = i ; k < n + 1 ; k ++ ) { double tmp = A [ maxRow ][ k ]; A [ maxRow ][ k ] = A [ i ][ k ]; A [ i ][ k ] = tmp ; } // Make all rows below this one 0 in current column for ( int k = i + 1 ; k < n ; k ++ ) { double c = - A [ k ][ i ] / A [ i ][ i ]; for ( int j = i ; j < n + 1 ; j ++ ) { if ( i == j ) { A [ k ][ j ] = 0 ; } else { A [ k ][ j ] += c * A [ i ][ j ]; } } } } // Solve equation Ax=b for an upper triangular matrix A vector < double > x ( n ); for ( int i = n - 1 ; i >= 0 ; i -- ) { x [ i ] = A [ i ][ n ] / A [ i ][ i ]; for ( int k = i - 1 ; k >= 0 ; k -- ) { A [ k ][ n ] -= A [ k ][ i ] * x [ i ]; } } return x ; } int main () { int n ; cin >> n ; vector < double > line ( n + 1 , 0 ); vector < vector < double > > A ( n , line ); // Read input data for ( int i = 0 ; i < n ; i ++ ) { for ( int j = 0 ; j < n ; j ++ ) { cin >> A [ i ][ j ]; } } for ( int i = 0 ; i < n ; i ++ ) { cin >> A [ i ][ n ]; } // Print input print ( A ); // Calculate solution vector < double > x ( n ); x = gauss ( A ); // Print result cout << \"Result: \\t \" ; for ( int i = 0 ; i < n ; i ++ ) { cout << x [ i ] << \" \" ; } cout << endl ; } You can call it like this: ./gauss.out < 3x3.in 1 2 3 | 1 4 5 6 | 1 1 0 1 | 1 Result: 0 -1 1 Python code #!/usr/bin/env python # -*- coding: utf-8 -*- def pprint ( A ): n = len ( A ) for i in range ( 0 , n ): line = \"\" for j in range ( 0 , n + 1 ): line += str ( A [ i ][ j ]) + \" \\t \" if j == n - 1 : line += \"| \" print ( line ) print ( \"\" ) def gauss ( A ): n = len ( A ) for i in range ( 0 , n ): # Search for maximum in this column maxEl = abs ( A [ i ][ i ]) maxRow = i for k in range ( i + 1 , n ): if abs ( A [ k ][ i ]) > maxEl : maxEl = abs ( A [ k ][ i ]) maxRow = k # Swap maximum row with current row (column by column) for k in range ( i , n + 1 ): tmp = A [ maxRow ][ k ] A [ maxRow ][ k ] = A [ i ][ k ] A [ i ][ k ] = tmp # Make all rows below this one 0 in current column for k in range ( i + 1 , n ): c = - A [ k ][ i ] / A [ i ][ i ] for j in range ( i , n + 1 ): if i == j : A [ k ][ j ] = 0 else : A [ k ][ j ] += c * A [ i ][ j ] # Solve equation Ax=b for an upper triangular matrix A x = [ 0 for i in range ( n )] for i in range ( n - 1 , - 1 , - 1 ): x [ i ] = A [ i ][ n ] / A [ i ][ i ] for k in range ( i - 1 , - 1 , - 1 ): A [ k ][ n ] -= A [ k ][ i ] * x [ i ] return x if __name__ == \"__main__\" : from fractions import Fraction n = input () A = [[ 0 for j in range ( n + 1 )] for i in range ( n )] # Read input data for i in range ( 0 , n ): line = map ( Fraction , raw_input () . split ( \" \" )) for j , el in enumerate ( line ): A [ i ][ j ] = el raw_input () line = raw_input () . split ( \" \" ) lastLine = map ( Fraction , line ) for i in range ( 0 , n ): A [ i ][ n ] = lastLine [ i ] # Print input pprint ( A ) # Calculate solution x = gauss ( A ) # Print result line = \"Result: \\t \" for i in range ( 0 , n ): line += str ( x [ i ]) + \" \\t \" print ( line ) JavaScript code /** Solve a linear system of equations given by a n&times;n matrix with a result vector n&times;1. */ function gauss ( A ) { var n = A . length ; for ( var i = 0 ; i < n ; i ++ ) { // Search for maximum in this column var maxEl = Math . abs ( A [ i ][ i ]); var maxRow = i ; for ( var k = i + 1 ; k < n ; k ++ ) { if ( Math . abs ( A [ k ][ i ]) > maxEl ) { maxEl = Math . abs ( A [ k ][ i ]); maxRow = k ; } } // Swap maximum row with current row (column by column) for ( var k = i ; k < n + 1 ; k ++ ) { var tmp = A [ maxRow ][ k ]; A [ maxRow ][ k ] = A [ i ][ k ]; A [ i ][ k ] = tmp ; } // Make all rows below this one 0 in current column for ( k = i + 1 ; k < n ; k ++ ) { var c = - A [ k ][ i ] / A [ i ][ i ]; for ( var j = i ; j < n + 1 ; j ++ ) { if ( i == j ) { A [ k ][ j ] = 0 ; } else { A [ k ][ j ] += c * A [ i ][ j ]; } } } } // Solve equation Ax=b for an upper triangular matrix A var x = new Array ( n ); for ( var i = n - 1 ; i >- 1 ; i -- ) { x [ i ] = A [ i ][ n ] / A [ i ][ i ]; for ( var k = i - 1 ; k >- 1 ; k -- ) { A [ k ][ n ] -= A [ k ][ i ] * x [ i ]; } } return x ; } PHP <?php /** * Gaussian elimination * @param array $A matrix * @param array $x vector * @return array solution vector */ function gauss ( $A , $x ) { # Just make a single matrix for ( $i = 0 ; $i < count ( $A ); $i ++ ) { $A [ $i ][] = $x [ $i ]; } $n = count ( $A ); for ( $i = 0 ; $i < $n ; $i ++ ) { # Search for maximum in this column $maxEl = abs ( $A [ $i ][ $i ]); $maxRow = $i ; for ( $k = $i + 1 ; $k < $n ; $k ++ ) { if ( abs ( $A [ $k ][ $i ]) > $maxEl ) { $maxEl = abs ( $A [ $k ][ $i ]); $maxRow = $k ; } } # Swap maximum row with current row (column by column) for ( $k = $i ; $k < $n + 1 ; $k ++ ) { $tmp = $A [ $maxRow ][ $k ]; $A [ $maxRow ][ $k ] = $A [ $i ][ $k ]; $A [ $i ][ $k ] = $tmp ; } # Make all rows below this one 0 in current column for ( $k = $i + 1 ; $k < $n ; $k ++ ) { $c = - $A [ $k ][ $i ] / $A [ $i ][ $i ]; for ( $j = $i ; $j < $n + 1 ; $j ++ ) { if ( $i == $j ) { $A [ $k ][ $j ] = 0 ; } else { $A [ $k ][ $j ] += $c * $A [ $i ][ $j ]; } } } } # Solve equation Ax=b for an upper triangular matrix $A $x = array_fill ( 0 , $n , 0 ); for ( $i = $n - 1 ; $i > - 1 ; $i -- ) { $x [ $i ] = $A [ $i ][ $n ] / $A [ $i ][ $i ]; for ( $k = $i - 1 ; $k > - 1 ; $k -- ) { $A [ $k ][ $n ] -= $A [ $k ][ $i ] * $x [ $i ]; } } return $x ; } ?> And some tiny tests: <?php $A = array ( array ( 7 )); $x = array ( 3 ); $result = gauss ( $A , $x ); var_dump ( $result ); ### array (size=1) ### 0 => float 0.42857142857143 = 3 / 7 $A = array ( array ( 7 )); $x = array ( 0 ); $result = gauss ( $A , $x ); var_dump ( $result ); ### array (size=1) ### 0 => int 0 ?> Test equations with two variables (see Wolfram|Alpha ): <?php $A = array ( array ( 7 , 1 ), array ( 5 , 3 )); $x = array ( 1 , 3 ); $result = gauss ( $A , $x ); var_dump ( $result ); ### array (size=2) ### 0 => float 0 ### 1 => float 1 ?> Test equations with two variables (see Wolfram|Alpha ): <?php $A = array ( array ( 7 , 1 ), array ( 5 , 3 )); $x = array ( 1 , 1 ); $result = gauss ( $A , $x ); var_dump ( $result ); ### array (size=2) ### 0 => float 0.125 ### 1 => float 0.125 ?> Complexity Time complexity Time complexity is in \\(\\mathcal{O}(n&#94;3)\\) (lines 44 - 53): \\begin{align} Operations &= \\sum_{i=0}&#94;{n-1} \\sum_{k=i+1}&#94;{n-1} \\sum_{j=i}&#94;{n} 1\\\\ &= \\sum_{i=0}&#94;{n-1} \\sum_{k=i+1}&#94;{n-1} (n-i+1) \\\\ &= \\left (\\sum_{i=0}&#94;{n-1} \\sum_{k=i+1}&#94;{n-1} (n+1) \\right ) - \\left (\\sum_{i=0}&#94;{n-1} \\sum_{k=i+1}&#94;{n-1} i \\right )\\\\ &= \\dots \\\\ &= \\frac{1}{6} \\cdot n \\cdot (2 n&#94;2+3 n-5)\\\\ &= \\frac{1}{3} \\cdot n&#94;3 + \\mathcal{O}(n&#94;2) \\end{align} Space complexity Space complexity of this implementation is in \\(\\mathcal{O}(n)\\) , but you can easily come down to \\(\\mathcal{O}(1)\\) when you use A[n] for storing x .","tags":"Code","title":"Solving linear equations with Gaussian elimination"},{"url":"https://martin-thoma.com/generating-many-prime-numbers/","text":"Today, a fellow student claimed that it would take much time to check the first 1,000,000 numbers for primes. I claimed that it would be a matter of seconds to do so for the first 1,000,000,000 numbers. So, lets prove my claim. Trivial approach #include <iostream> // cin, cout #include <cmath> // sqrt #include <vector> using namespace std ; vector < unsigned long > primeList ; bool isPrime ( unsigned long n ) { vector < unsigned long >:: iterator myIt ; unsigned long root = ( unsigned long ) sqrt ( n ); for ( myIt = primeList . begin (); myIt != primeList . end (); myIt ++ ){ if ( n % ( * myIt ) == 0 ) { return false ; } else if (( * myIt ) > root ) { return true ; } } return true ; } int main ( int argc , char * argv []) { primeList . push_back ( 2 ); cout << 2 << endl ; unsigned long long max = ( unsigned long long ) atoi ( argv [ 1 ]); for ( unsigned long i = 3 ; i < max ; i += 2 ) { if ( isPrime ( i )) { primeList . push_back ( i ); cout << i << endl ; } } return 0 ; } Execute it for 100,000,000: time ./generate-prime-list.out 100000000 > primes.txt real 0m57.274s user 0m41.855s sys 0m15.229s So 41 seconds for all primes not bigger than 100,000,000. Now, lets test it for 1,000,000,000: time ./generate-prime-list.out 1000000000 > primes.txt real 18m18.205s user 15m56.904s sys 2m12.500s 16 minutes ... not exactly \"seconds\". But please keep in mind that I also wrote the result to a txt-file. This txt file is 502.0 MB big. It takes quite a lot of time to write such an amount of data from memory to disk. Sieve of Eratosthenes A first try #include <iostream> // cin, cout #include <vector> using namespace std ; void sieveOfEratosthenes ( unsigned long n ) { vector < bool > primesEratosthenes ( n + 1 , true ); cout << 2 << endl ; for ( unsigned long i = 3 ; i < n ; i += 2 ) { if ( primesEratosthenes [ i ] == true ) { cout << i << endl ; for ( unsigned long j = 2 ; j * i <= n ; j ++ ) { primesEratosthenes [ j * i ] = false ; } } } } int main ( int argc , char * argv []) { unsigned long long n = ( unsigned long long ) atoi ( argv [ 1 ]); sieveOfEratosthenes ( n ); return 0 ; } This one takes 1 minute 5 seconds: make ; time ./generate-prime-list.out 1000000000 > testPrimes.txt g++ -std = c++0x -Wall -pedantic -O3 -D NDEBUG generate-prime-list.cpp -o generate-prime-list.out real 3m20.436s user 1m4.908s sys 2m11.748s I'm getting closer to \"seconds\". â˜º ofstream, endl, \\n and buffers Writing 502.0 MB takes some time. It's not getting better when I pipe this through bash. So lets write it directly: #include <fstream> // ofstream #include <vector> using namespace std ; void sieveOfEratosthenes ( unsigned long n ) { ofstream myfile ; myfile . open ( \"huge-prime-list.txt\" ); vector < bool > primesEratosthenes ( n + 1 , true ); myfile << 2 << endl ; for ( unsigned long i = 3 ; i < n ; i += 2 ) { if ( primesEratosthenes [ i ] == true ) { myfile << i << endl ; for ( unsigned long j = 2 ; j * i <= n ; j ++ ) { primesEratosthenes [ j * i ] = false ; } } } myfile . close (); } int main ( int argc , char * argv []) { unsigned long long n = ( unsigned long long ) atoi ( argv [ 1 ]); sieveOfEratosthenes ( n ); return 0 ; } time ./generate-prime-list.out 1000000000 real 3m21.249s user 1m4.016s sys 2m12.332s Ok, no real change :-/ Another idea is to replace endl by \\n (see explanation ) That was a good try. Now it needs only 46 seconds: time ./generate-prime-list.out 1000000000 real 0m49.539s user 0m46.619s sys 0m0.920s Another reason why this might be slow could be too many system calls. So I could buffer some and write them in blocks. I could also just write blocks of unsigned long numbers instead of a string representation. This might lead to a much smaller file size which in consequence is faster to write: #include <stdio.h> // fopen #include <iostream> // atoi #include <vector> using namespace std ; void sieveOfEratosthenes ( unsigned long n ) { FILE * pFile ; pFile = fopen ( \"huge-prime-list.txt\" , \"wb\" ); vector < bool > primesEratosthenes ( n + 1 , true ); unsigned long tmp = 2 ; fwrite ( & tmp , sizeof ( unsigned long ), 1 , pFile ); for ( unsigned long i = 3 ; i < n ; i += 2 ) { if ( primesEratosthenes [ i ] == true ) { fwrite ( & i , sizeof ( unsigned long ), 1 , pFile ); for ( unsigned long j = 2 ; j * i <= n ; j ++ ) { primesEratosthenes [ j * i ] = false ; } } } fclose ( pFile ); } int main ( int argc , char * argv []) { unsigned long long n = ( unsigned long long ) atoi ( argv [ 1 ]); sieveOfEratosthenes ( n ); return 0 ; } And execute it: time ./generate-prime-list.out 1000000000 real 0m39.700s user 0m38.546s sys 0m0.640s 38 seconds for all primes from 2 to 1,000,000,000. The file size is now only 203.4 MB. By the way, simply setting this with setbuf(pFile, NULL); to unbuffered resulted in 50 seconds execution time. You can get the list with this snippet: #include <iostream> #include <fstream> using namespace std ; int main ( int argc , char * argv []) { if ( argc != 2 ) { cout << \"You have to specify a file name\" << endl ; } else { FILE * pFile ; pFile = fopen ( argv [ 1 ], \"rb\" ); long long x ; size_t read ; while ( ! feof ( pFile )) { read = fread ( & x , sizeof ( long long ), 1 , pFile ); ( void ) read ; if ( feof ( pFile )){ break ; // otherwise it duplicates the last entry } cout << x << endl ; } fclose ( pFile ); } } Improve sieving The following change was suggested by Niklas B. . Thanks! Take a look at the inner for loop. This one does the sieving, so it gets executed very often. In this loop, you have to calculate j i for checking the condition of the loop and again for setting it to false. You can get rid of one of those operations. Additionally, you don't have to start sieving at 2 p, but you can start at p*p as you already sieved out all multiples of the first, second, ..., current-1-th prime. #include <stdio.h> // fopen #include <iostream> // atoi #include <vector> using namespace std ; void sieveOfEratosthenes ( long long n ) { FILE * pFile ; pFile = fopen ( \"huge-prime-list.bin\" , \"wb\" ); vector < bool > primesEratosthenes ( n + 1 , true ); long long tmp = 2 ; fwrite ( & tmp , sizeof ( long long ), 1 , pFile ); for ( long long i = 3 ; i < n ; i += 2 ) { if ( primesEratosthenes [ i ]) { fwrite ( & i , sizeof ( long long ), 1 , pFile ); for ( long long j = i * i ; j <= n ; j += i ) { primesEratosthenes [ j ] = false ; } } } fclose ( pFile ); } int main ( int argc , char * argv []) { if ( argc != 2 ) { cout << \"You have to specify n\" << endl ; } else { long long n = ( long long ) atoi ( argv [ 1 ]); sieveOfEratosthenes ( n ); } return 0 ; } Execute: time ./generate-prime-list.out 1000000000 real 0m24.222s user 0m23.485s sys 0m0.436s primesieve Primesieve is a free software program and C++ library that generates prime numbers and prime k-tuplets (twin primes, prime triplets, ...) \\(< 2&#94;{64}\\) using a highly optimized implementation of the sieve of Eratosthenes. According to the GUI, it finds all 50,847,534 primes below 1,000,000,000 in 0.16 seconds. But write them to a file... Sieve of Atkin Arthur Oliver Lonsdale Atkin (July 31, 1925 â€“ December 28, 2008) was a British mathematician who invented this sieve. I've implemented it according to the pseudocode provided in Wikipedia . A very long explanation of Atkins sieve is on StackOverflow My first implementation #include <stdio.h> // fopen #include <iostream> // atoi #include <vector> #include <cmath> // sqrt, ceil, using namespace std ; void sieveOfAtkin ( long long limit ) { FILE * pFile ; pFile = fopen ( \"huge-prime-list.bin\" , \"wb\" ); long long root = ceil ( sqrt ( limit )); // initialize the sieve vector < bool > is_prime ( limit , false ); // put in candidate primes: // integers which have an odd number of // representations by certain quadratic forms for ( long long x = 1 ; x <= root ; x ++ ) { long long xSquare = x * x ; for ( long long y = 1 ; y <= root ; y ++ ) { long long n = ( 4 * xSquare ) + ( y * y ); if ( n <= limit && ( n % 12 == 1 || n % 12 == 5 )) { is_prime [ n ] = ! is_prime [ n ]; } n = ( 3 * xSquare ) + ( y * y ); if ( n <= limit && n % 12 == 7 ) { is_prime [ n ] = ! is_prime [ n ]; } n = ( 3 * xSquare ) - ( y * y ); if ( x > y && n <= limit && n % 12 == 11 ) { is_prime [ n ] = ! is_prime [ n ]; } } } // eliminate composites by sieving for ( long long n = 5 ; n <= root ; n ++ ) { if ( is_prime [ n ]) { long long add = n * n ; for ( long long k = add ; k < limit ; k += add ) { // n is prime, omit multiples of its square; this is // sufficient because composites which managed to get // on the list cannot be square-free is_prime [ k ] = false ; } } } // Output primes long long primTmp = 2 ; fwrite ( & primTmp , sizeof ( long long ), 1 , pFile ); primTmp = 3 ; fwrite ( & primTmp , sizeof ( long long ), 1 , pFile ); for ( long long n = 5 ; n < limit ; n ++ ) { if ( is_prime [ n ]) { fwrite ( & n , sizeof ( long long ), 1 , pFile ); } } fclose ( pFile ); } int main ( int argc , char * argv []) { if ( argc != 2 ) { cout << \"You have to specify n\" << endl ; } else { long long n = ( long long ) atoi ( argv [ 1 ]); sieveOfAtkin ( n ); } return 0 ; } Atkins sieve has a much worse performance than Sieve of Eratosthenes: time ./generate-prime-list.out 1000000000 real 1m6.001s user 1m4.724s sys 0m0.604s Primegen Primegen is an implementation by Daniel J. Bernstein . It's a little bit cluttered with 80 files and 3854 LOC in total. When I have some time, I'll update this article and create a new version of my sieve with ideas from Primegen. Primegen is fast: time ./primes > primes.txt real 0m11.677s user 0m10.649s sys 0m0.708s About 11 seconds for writing all primes between 2 and 1,000,000,000 to a txt file. See also You might want to try the following Project Euler problem sets: Project Euler Problem 3 : What is the largest prime factor of the number 600851475143 ? Problem 7 : What is the 10 001st prime number? Problem 60 SPOJ PRIME1 PRIME2 KPRIMES2 Segmented sieve of Eratosthenes Fun with prime numbers : This looks almost like my article. It might be interesting, because the author thought about finding primes above \\(10&#94;9\\) which I didn't. Finally The last script that took 23 seconds for calculating and writing all primes in 2 to 1,000,000,000 seems to be the best one. Do you know anything else that could get improved? Please provide a working example (e.g. as a gist )","tags":"Cyberculture","title":"Generating many prime numbers"},{"url":"https://martin-thoma.com/solving-equations-of-upper-triangular-matrices/","text":"Suppose you have an equation like \\(R \\cdot x = b\\) with \\(R \\in \\mathbb{R}&#94;{n \\times n}\\) and \\(x,b \\in \\mathbb{R}&#94;n\\) . \\(b\\) and \\(R\\) are given and you want to solve for \\(x\\) . Example With \\(n=5\\) , the problem could look like this: $$\\begin{pmatrix} 2 & 7 & 1 & 8 & 2\\\\ 0 & 8 & 1 & 8 & 2\\\\ 0 & 0 & 8 & 4 & 5\\\\ 0 & 0 & 0 & 9 & 0\\\\ 0 & 0 & 0 & 0 & 4 \\end{pmatrix} \\cdot \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\\\ x_5 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 1 \\\\ 4 \\\\ 1 \\\\ 5 \\end{pmatrix}$$ This is only a shorthand for: \\begin{align} 2 \\cdot x_1 + 7 \\cdot x_2 + 1 \\cdot x_3 + 8 \\cdot x_4 + 2 \\cdot x_5 &= 3\\\\ 8 \\cdot x_2 + 1 \\cdot x_3 + 8 \\cdot x_4 + 2 \\cdot x_5 &= 1\\\\ 8 \\cdot x_3 + 4 \\cdot x_4 + 5 \\cdot x_5 &= 4\\\\ 9 \\cdot x_4 + 0 \\cdot x_5 &= 1\\\\ 4 \\cdot x_5 &= 5 \\end{align} First step: Solve for $x_5$ First you see that \\(x_5 = \\frac{5}{4}\\) . So you divide \\(b\\) by the current row. Don't divide through 0. When you would have to divide by 0 and b is 0, this system has an infinite amount of solutions. When you would have to divide by 0 and b is not 0, then this system has no solution. Now you replace every occurrence of \\(x_5\\) in the system of equations above: \\begin{align} 2 \\cdot x_1 + 7 \\cdot x_2 + 1 \\cdot x_3 + 8 \\cdot x_4 + 2 \\cdot \\frac{5}{4} &= 3\\\\ 8 \\cdot x_2 + 1 \\cdot x_3 + 8 \\cdot x_4 + 2 \\cdot \\frac{5}{4} &= 1\\\\ 8 \\cdot x_3 + 4 \\cdot x_4 + 5 \\cdot \\frac{5}{4} &= 4\\\\ 9 \\cdot x_4 + 0 \\cdot \\frac{5}{4} &= 1\\\\ 4 \\cdot \\frac{5}{4} &= 5 \\end{align} Now you make the multiplications and remove the first trivial line. \\begin{align} 2 \\cdot x_1 + 7 \\cdot x_2 + 1 \\cdot x_3 + 8 \\cdot x_4 + \\frac{5}{2} &= 3\\\\ 8 \\cdot x_2 + 1 \\cdot x_3 + 8 \\cdot x_4 + \\frac{5}{2} &= 1\\\\ 8 \\cdot x_3 + 4 \\cdot x_4 + \\frac{25}{4} &= 4\\\\ 9 \\cdot x_4 + 0 &= 1\\\\ \\end{align} Second step: update Get the constant factors to the right side of the equations: \\begin{align} 2 \\cdot x_1 + 7 \\cdot x_2 + 1 \\cdot x_3 + 8 \\cdot x_4 &= \\frac{1}{2} \\\\ 8 \\cdot x_2 + 1 \\cdot x_3 + 8 \\cdot x_4 &= -\\frac{3}{2} \\\\ 8 \\cdot x_3 + 4 \\cdot x_4 &= -\\frac{9}{4}\\\\ 9 \\cdot x_4 &= 1\\\\ \\end{align} You're now in the same situation as in the first step. Next you will solve for \\(x_4\\) , then for \\(x_3, x_2\\) and finally for \\(x_1\\) . This is called \"back substitution\". According to Wolfram|Alpha , the solution is: $$x = \\frac{1}{4608} \\cdot \\begin{pmatrix}4017\\\\-1182\\\\-1552\\\\512\\\\5760\\end{pmatrix} = \\begin{pmatrix}\\frac{1339}{1536} \\\\ -\\frac{197}{768} \\\\ -\\frac{97}{288} \\\\ \\frac{1}{9} \\\\ \\frac{5}{4}\\end{pmatrix}$$ Python straightforward algorithm I will use fractions for operations as I don't want to lose precision while dividing. #!/usr/bin/env python # -*- coding: utf-8 -*- def solveUpperTriangularMatrix ( R , b ): # Convert R and b to Fraction from fractions import Fraction fR , fb = [], [] for x , line in enumerate ( R ): fLine = [] for y , el in enumerate ( line ): fLine . append ( Fraction ( el )) fR . append ( fLine ) for el in b : fb . append ( Fraction ( el )) # The solution will be here x = [ Fraction ( 0 )] * len ( b ) for step in range ( len ( b ) - 1 , 0 - 1 , - 1 ): if fR [ step ][ step ] == 0 : if fb [ step ] != 0 : return \"No solution\" else : return \"Infinity solutions\" else : x [ step ] = fb [ step ] / fR [ step ][ step ] for row in range ( step - 1 , 0 - 1 , - 1 ): fb [ row ] -= fR [ row ][ step ] * x [ step ] return x if __name__ == \"__main__\" : R = [[ 2 , 7 , 1 , 8 , 2 ], [ 0 , 8 , 1 , 8 , 2 ], [ 0 , 0 , 8 , 4 , 5 ], [ 0 , 0 , 0 , 9 , 0 ], [ 0 , 0 , 0 , 0 , 4 ]] b = [ 3 , 1 , 4 , 1 , 5 ] x = solveUpperTriangularMatrix ( R , b ) print ( x ) # Convert x to float x = map ( float , x ) print ( x ) A better algorithm Just like for unipotent lower triangular matrices , we can operate directly on the given input: #!/usr/bin/env python # -*- coding: utf-8 -*- def solveUpperTriangularMatrix ( R , b ): # Convert R and b to Fraction from fractions import Fraction for x , line in enumerate ( R ): for y , el in enumerate ( line ): R [ x ][ y ] = Fraction ( el ) for x , el in enumerate ( b ): b [ x ] = Fraction ( el ) # The solution will be here for step in range ( len ( b ) - 1 , 0 - 1 , - 1 ): if R [ step ][ step ] == 0 : if b [ step ] != 0 : return \"No solution\" else : return \"Infinity solutions\" else : b [ step ] = b [ step ] / R [ step ][ step ] for row in range ( step - 1 , 0 - 1 , - 1 ): b [ row ] -= R [ row ][ step ] * b [ step ] if __name__ == \"__main__\" : R = [[ 2 , 7 , 1 , 8 , 2 ], [ 0 , 8 , 1 , 8 , 2 ], [ 0 , 0 , 8 , 4 , 5 ], [ 0 , 0 , 0 , 9 , 0 ], [ 0 , 0 , 0 , 0 , 4 ]] b = [ 3 , 1 , 4 , 1 , 5 ] solveUpperTriangularMatrix ( R , b ) print ( b ) Conversion to Fraction You could think that the conversion to fraction is not necessary. But if you simply remove line 5 to 16, you will get: [ 1 , 0 , -1, 0 , 1 ] because of integer arithmetic. When you convert the input to float before passing it to solveUpperTriangularMatrix , you will get [ 0 .8717447916666666, -0.25651041666666663, -0.3368055555555556, 0 .1111111111111111, 1 .25 ] which is almost the same as when we calculated with Fraction and converted to float afterwards: [ 0 .8717447916666666, -0.2565104166666667, -0.3368055555555556, 0 .1111111111111111, 1 .25 ] So: Using Fractions needs some computing time, but you will get better results. Time complexity I'll analyze the second algorithm. The conversion of our input data is obviously in \\(\\mathcal{O}(n&#94;2)\\) . Let's only analyse the part after the conversion. Assume that there is exactly one solution and that line 15-21 take \\(c_1\\) operations and line 24 takes \\(c_2\\) operations. Then we would have a total of \\begin{align} \\text{Operations} &= \\sum_{i=1}&#94;n \\left ( c_1 + \\sum_{j=1}&#94;{i-1} c_2 \\right )\\\\ &= \\sum_{i=1}&#94;n c_1 + \\sum_{i=1}&#94;n \\sum_{j=1}&#94;{i-1} c_2\\\\ &= n \\cdot c_1 + c_2 \\cdot \\left (\\sum_{i=1}&#94;n \\sum_{j=1}&#94;{i-1} 1 \\right )\\\\ &= n \\cdot c_1 + c_2 \\cdot \\left (\\sum_{i=1}&#94;n (i-1) \\right )\\\\ &= n \\cdot c_1 + c_2 \\cdot \\left ((\\sum_{i=1}&#94;n i) - (\\sum_{i=1}&#94;n 1) \\right )\\\\ &= n \\cdot c_1 + c_2 \\cdot \\left (\\frac{n&#94;2+n}{2} - n \\right )\\\\ &= n \\cdot c_1 + (n&#94;2-n) \\cdot \\frac{c_2}{2}\\\\ \\end{align} So the algorithms time complexity is in \\(\\Theta(n&#94;2) \\subsetneq \\mathcal{O}(n&#94;2)\\) . Space complexity Please note that I take advantage of Pythons dynamic typing system. I think it's difficult to see space complexity in python programs. But when you make the same in C++, you will see that you will need space in \\(\\mathcal{O}(n)\\) when you do the conversion. Without the conversion, you're in \\(\\mathcal{O}(1)\\) . I guess you might want to leave this choice to the user of your functions. When he wants better results, he should give the input as Fraction. When he wants to get results rather faster, he should give the input as float. Notes In this algorithm, we don't need anything below the diagonal.","tags":"Code","title":"Solving equations of upper triangular matrices"},{"url":"https://martin-thoma.com/solving-equations-of-unipotent-lower-triangular-matrices/","text":"Suppose you have an equation like \\(L \\cdot x = b\\) with \\(L \\in \\mathbb{R}&#94;{n \\times n}\\) and \\(x,b \\in \\mathbb{R}&#94;n\\) . \\(b\\) and \\(L\\) are given and you want to solve for \\(x\\) . Example With \\(n=5\\) , the problem could look like this: \\( \\begin{pmatrix} 1 & 0 & 0 & 0 & 0\\\\ 2 & 1 & 0 & 0 & 0\\\\ 7 & 1 & 1 & 0 & 0\\\\ 8 & 2 & 8 & 1 & 0\\\\ 1 & 8 & 2 & 8 & 1 \\end{pmatrix} \\cdot \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\\\ x_5 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 1 \\\\ 4 \\\\ 1 \\\\ 5 \\end{pmatrix} \\) This is only a shorthand for: \\begin{align} &1 \\cdot x_1 &= 3 \\\\ &2 \\cdot x_1 + 1 \\cdot x_2 &= 1\\\\ &7 \\cdot x_1 + 1 \\cdot x_2 + 1 \\cdot x_3 &= 4\\\\ &8 \\cdot x_1 + 2 \\cdot x_2 + 8 \\cdot x_3 + 1 \\cdot x_4 &= 1\\\\ &1 \\cdot x_1 + 8 \\cdot x_2 + 2 \\cdot x_3 + 8 \\cdot x_4 + 1 \\cdot x_5 &= 5 \\end{align} This is easy to solve, isn't it? First step: Solve for \\(x_1\\) First you see that \\(x_1 = 3\\) . Now you replace every occurence of \\(x_1\\) in the system of equations above: \\begin{align} &1 \\cdot 3 &= 3 \\\\ &2 \\cdot 3 + 1 \\cdot x_2 &= 1\\\\ &7 \\cdot 3 + 1 \\cdot x_2 + 1 \\cdot x_3 &= 4\\\\ &8 \\cdot 3 + 2 \\cdot x_2 + 8 \\cdot x_3 + 1 \\cdot x_4 &= 1\\\\ &1 \\cdot 3 + 8 \\cdot x_2 + 2 \\cdot x_3 + 8 \\cdot x_4 + 1 \\cdot x_5 &= 5 \\end{align} Now you make the multiplications and remove the first trivial line. \\begin{align} &6 + 1 \\cdot x_2 &= 1\\\\ &21 + 1 \\cdot x_2 + 1 \\cdot x_3 &= 4\\\\ &24 + 2 \\cdot x_2 + 8 \\cdot x_3 + 1 \\cdot x_4 &= 1\\\\ &3 + 8 \\cdot x_2 + 2 \\cdot x_3 + 8 \\cdot x_4 + 1 \\cdot x_5 &= 5 \\end{align} Second step: update Get the constant factors to the right side of the equations: \\begin{align} &1 \\cdot x_2 &= 1-6=-5\\\\ &1 \\cdot x_2 + 1 \\cdot x_3 &= 4-21=-17\\\\ &2 \\cdot x_2 + 8 \\cdot x_3 + 1 \\cdot x_4 &= 1-24=-23\\\\ &8 \\cdot x_2 + 2 \\cdot x_3 + 8 \\cdot x_4 + 1 \\cdot x_5 &= 5-3=2 \\end{align} You can now easily see that you're in the same situation as in the first step! Next you will solve for \\(x_2\\) , then for \\(x_3, x_4\\) and finally for \\(x_5\\) . This is the reason why solving such a system of equations is sometimes called \"forward substitution\". Python straightforward algorithm #!/usr/bin/env python # -*- coding: utf-8 -*- def solveLowerUnitriangularMatrix ( L , b ): x = [ 0 ] * len ( b ) for step in range ( 0 , len ( b )): x [ step ] = b [ step ] for row in range ( 0 , len ( b )): b [ row ] = b [ row ] - L [ row ][ step ] * x [ step ] return x if __name__ == \"__main__\" : L = [[ 1 , 0 , 0 , 0 , 0 ], [ 2 , 1 , 0 , 0 , 0 ], [ 7 , 1 , 1 , 0 , 0 ], [ 8 , 2 , 8 , 1 , 0 ], [ 1 , 8 , 2 , 8 , 1 ]] b = [ 3 , 1 , 4 , 1 , 5 ] print ( solveLowerUnitriangularMatrix ( L , b )) Pretty easy, isn't it? But can we even do better? Even better algorithm Yes, we can! Take a look at what's happening when row = 0 in line 9. We make a step that is not necessary. Also, we can take the space of b to store x! #!/usr/bin/env python # -*- coding: utf-8 -*- def solveLowerUnitriangularMatrix ( L , b ): for step in range ( 0 , len ( b )): for row in range ( step + 1 , len ( b )): b [ row ] -= L [ row ][ step ] * b [ step ] if __name__ == \"__main__\" : L = [[ 1 , 0 , 0 , 0 , 0 ], [ 2 , 1 , 0 , 0 , 0 ], [ 7 , 1 , 1 , 0 , 0 ], [ 8 , 2 , 8 , 1 , 0 ], [ 1 , 8 , 2 , 8 , 1 ]] b = [ 3 , 1 , 4 , 1 , 5 ] solveLowerUnitriangularMatrix ( L , b ) print ( b ) Now it looks super clean, doesn't it â˜º Keep in mind that you have to store b if you need the values after you've applied this algorithm. This is the reason why there here. This algorithm \"returns\" its value by manipulating b. Time complexity I'll analyze the second algorithm. Let's assume that line 7 takes \\(c\\) operations and \\(n\\) is the size of \\(L \\in \\mathbb{R}&#94;{n \\times n}\\) . Then we would have a total of \\begin{align} \\text{Operations} &= \\sum_{i=1}&#94;n \\left ( \\sum_{j=i+1}&#94;n c \\right )\\\\ &= c \\cdot \\sum_{i=1}&#94;n \\left ( \\sum_{j=i+1}&#94;n 1 \\right )\\\\ &= c \\cdot \\sum_{i=1}&#94;n (n - i)\\\\ &= c \\cdot \\left ( \\sum_{i=1}&#94;n n - \\sum_{i=1}&#94;n i \\right )\\\\ &= c \\cdot \\left ( n&#94;2 - \\frac{n&#94;2+n}{2} \\right )\\\\ &= \\frac{c}{2} (n&#94;2 - n) \\end{align} So the algorithms time complexity is in \\(\\Theta(n&#94;2) \\subsetneq \\mathcal{O}(n&#94;2)\\) . Space complexity Well, thats simple: \\(\\mathcal{O}(1)\\) ! I do ignore the size of the input. So \\(\\mathcal{O}(1)\\) means: For variable sized input data I do need a constant amount of additional space. More improvements In the last algorithm I've presented you can see that we actually don't check the values on or above of the diagonal. This means, the following two function calls do give the same b: #!/usr/bin/env python # -*- coding: utf-8 -*- def solveLowerUnitriangularMatrix ( L , b ): for step in range ( 0 , len ( b )): for row in range ( step + 1 , len ( b )): b [ row ] -= L [ row ][ step ] * b [ step ] return L if __name__ == \"__main__\" : L = [[ 1 , 0 , 0 , 0 , 0 ], [ 2 , 1 , 0 , 0 , 0 ], [ 7 , 1 , 1 , 0 , 0 ], [ 8 , 2 , 8 , 1 , 0 ], [ 1 , 8 , 2 , 8 , 1 ]] b = [ 3 , 1 , 4 , 1 , 5 ] solveLowerUnitriangularMatrix ( L , b ) print ( b ) L = [[ 10 , 9 , 8 , 7 , 6 ], [ 2 , 5 , 4 , 3 , 2 ], [ 7 , 1 , 1 , 0 , 1 ], [ 8 , 2 , 8 , 2 , 3 ], [ 1 , 8 , 2 , 8 , 4 ]] b = [ 3 , 1 , 4 , 1 , 5 ] solveLowerUnitriangularMatrix ( L , b ) print ( b ) So, theoretically, we could store some other information on and above of the diagonal. We also don't change L. Keep this in mind, this might be important in later articles.","tags":"Code","title":"Solving equations of lower unitriangular matrices"},{"url":"https://martin-thoma.com/k-nearest-neighbor-classification-interactive-example/","text":"When the circle has exactly the same number of blue / green dots in it, it will be green. When you move the mouse over the box, everything will be calculated and drawn again. This leads to flickering with k-means, as k-means includes a random choice of cluster centers. Changelog Version Change 2.2 Cluster centers have the same color as the clustered points; when one cluster has no points (and there are at least as many points as clusters) everything gets recalculated 2.1 users can now specify an arbitrary number of classes; ctrl-key change of class was removed; added hints to configuration options 2.0 k-means implemented 1.0 k-nearest neighbor implemented Code is on GitHub . You may use it for free, but you should add a link to this article. See also One interesting setting for k=2 k-means: Good vs. Bad Voronoi diagram K-nearset neighbor k-means clustering Udacity: Introduction to A.I: k-means","tags":"Code","title":"k-nearest-neighbor classification and k-means - an interactive example"},{"url":"https://martin-thoma.com/the-collatz-sequence/","text":"The goal of this post is to show you some tools that allow you to visualize data. And I also want to analyze some basic characteristics of the Collatz sequence. The Collatz sequences \\((c&#94;n_i)\\) of a number \\(n \\in \\mathbb{N}_{> 0}\\) is defined like this: \\(f:\\mathbb{N}_{>0} \\rightarrow \\mathbb{N}_{> 0}\\;\\;\\;\\;f(n) := \\begin{cases} \\frac{n}{2} & \\text{if } n \\text{ is even}\\\\ 3 \\cdot n + 1 & \\text{if } n \\text{ is odd} \\end{cases} \\) So the sequence \\((c&#94;n_{i})\\) is defined as: \\(c&#94;n_{i} := \\begin{cases} n & \\text{if } i = 0\\\\ f(c&#94;n_i) & \\text{otherwise} \\end{cases} \\) You can define a directed graph \\(G=(V, E)\\) like this: \\(V = \\mathbb{N}_{>0}, \\;\\;\\; E = \\{(n, f(n)) | n \\in V\\}\\) I will call this the Collatz graph . Collatz conjecture $\\forall_{n \\in \\mathbb{N}_{>0}} \\exists_{i \\in \\mathbb{N}_{>0}}: c&#94;n_i = 1$ The Collatz conjecture was not (dis)proved by now. This is astonishing, as it was proposed in 1937 and I think it is very easy to understand. We also don't know if the Collatz graph is connected. When it is not connected, it could be that one sequence \\((c&#94;n_i)\\) goes to infinity or that there is another circle ( \\(4,2,1,4\\) is a circle in the Collatz graph). Small $n$ When you go through all possible Collatz sequences with \\(n \\in 1, \\dots, 15\\) , this is what you get: A graph for all Collatz sequences $(c&#94;n_i)$ with $n\\leq15$ This image was created with the following Python script: #!/usr/bin/env python # -*- coding: utf-8 -*- # Based on: http://en.wikipedia.org/wiki/File:Collatz-graph-all-30-no27.svg def f ( n ): if n % 2 == 0 : return n / 2 else : return 3 * n + 1 def writeDotfile ( filename , limit , explored ): dotfile = file ( filename , 'w' ) dotfile . write ( 'digraph { \\n ' ) dotfile . write ( 'node[style=filled,color=\".7 .3 1.0\"]; \\n ' ) dotfile . write ( '1 \\n ' ) dotfile . write ( 'node[style=filled,color=\".95 .1 1\"]; \\n ' ) #dotfile.write('size=\"15,8\";\\n') for n in range ( 2 , limit ): while n not in explored : dotfile . write ( str ( n ) + ' -> ' ) explored . add ( n ) n = f ( n ) dotfile . write ( str ( n ) + '; \\n ' ) dotfile . write ( '} \\n ' ) def createPng ( dotfile , base , program ): import os command = program + \" -Tsvg \" + dotfile + \" -o \" + base + \".svg\" print ( \"Execute command: %s \" % command ) os . system ( command ) command = \"inkscape \" + base + \".svg\" + \" -w 512 --export-png=\" + base + \".png\" print ( \"Execute command: %s \" % command ) os . system ( command ) if __name__ == \"__main__\" : import argparse parser = argparse . ArgumentParser ( description = \"Graph for small Collatz sequences\" ) parser . add_argument ( \"-f\" , \"--file\" , dest = \"filename\" , default = \"collatz-graph.gv\" , help = \"write dot-FILE\" , metavar = \"FILE\" ) parser . add_argument ( \"-p\" , \"--program\" , dest = \"program\" , help = \"dot, neato, twopi, circo, fdp, sfdp, osage\" , metavar = \"PROGRAM\" , default = \"dot\" ) parser . add_argument ( \"-n\" , dest = \"limit\" , default = 20 , type = int , help = \"limit\" ) args = parser . parse_args () writeDotfile ( args . filename , args . limit , set ([ 1 ])) import os createPng ( args . filename , os . path . splitext ( args . filename )[ 0 ], args . program ) called like this: python small-numbers.py -n 15 -p fdp $n=27$ \\(n=27\\) is an enourmously long sequence: Collatz sequence $c&#94;{27}_i$ It was created with pgfplots: \\documentclass[varwidth=true, border=2pt]{standalone} \\usepackage[margin=2.5cm]{geometry} %layout \\usepackage{pgfplots} \\begin{document} \\begin{tikzpicture} \\begin{axis}[ axis x line=middle, axis y line=middle, enlarge y limits=true, scaled y ticks = false, width=15cm, height=8cm, % size of the image grid = major, grid style={dashed, gray!30}, ylabel=$c&#94;{27}_i$, xlabel=$i$, legend style={at={(0.1,-0.1)}, anchor=north} ] \\addplot[sharp plot, mark=x, blue] table [x=steps, y=n, col sep=comma] {../collatz27.csv}; \\end{axis} \\end{tikzpicture} \\end{document} How long are Collatz sequences? I've been interested in the question how long Collatz sequences are. Of course, they will be longer when \\(n\\) is bigger. But how does the choice of \\(n\\) influence the number of steps it takes until you reach \\(c&#94;n_i = 1\\) ? I've tested all Collatz sequences with \\(n \\leq 10,000,000\\) . This is the result: Collatz sequence steps For every hexagon, you check how many datapoints \\((n,steps)\\) you have there. This leads to the count. As you can see, step numbers from 50-120 are very common, the rest is very uncommon. The number of steps increases very slow. The data was created as a 116.9 MB csv file with this C++ code: #include <iostream> #include <string> #include <map> #include <vector> #include <climits> // get maximum value of unsigned long long #include <cstdlib> // exit #define SURPRESS_OUTPUT true #define SHOW_DICT_CREATION false using namespace std ; struct element { /** What is the next collatz number? */ unsigned long long next ; /** How many steps does it take until you reach 1? */ unsigned long long steps ; }; map < unsigned long long , struct element > collatz ; unsigned long long CRITICAL_VALUE = ( ULLONG_MAX - 1 ) / 3 ; unsigned long long maxAddFromOneEntry = 0 ; unsigned long long maxEntry = 0 ; unsigned long long maxStepsToOne = 0 ; unsigned long long saveULong = 0 ; /** n >= 1 */ unsigned long long nextCollatz ( unsigned long long n ) { if ( n % 2 == 0 ) { return n / 2 ; } else { if ( n >= CRITICAL_VALUE ) { cerr << \"Critical value is: \" << CRITICAL_VALUE << endl ; cerr << \"n is: \" << n << endl ; cerr << \"saveULong is: \" << saveULong << endl ; exit ( 1 ); } return 3 * n + 1 ; } } void insertCollatz ( unsigned long long i ){ if ( collatz . find ( i ) == collatz . end ()) { if ( SHOW_DICT_CREATION && ! SURPRESS_OUTPUT ) { cout << i << \" is not in collatz:\" << endl ; } // i is not in collatz vector < unsigned long long > steps ; unsigned long long current = i ; unsigned long long next = nextCollatz ( current ); while ( collatz . find ( current ) == collatz . end ()) { steps . push_back ( current ); current = next ; next = nextCollatz ( current ); } if ( steps . size () > maxAddFromOneEntry ) { maxAddFromOneEntry = steps . size (); } vector < unsigned long long >:: reverse_iterator it ; for ( it = steps . rbegin (); it != steps . rend (); it ++ ){ struct element el ; el . next = current ; el . steps = collatz [ current ]. steps + 1 ; collatz [ * it ] = el ; if ( el . steps > maxStepsToOne ) { maxStepsToOne = el . steps ; } if ( * it > maxEntry ) { maxEntry = * it ; } current = * it ; if ( SHOW_DICT_CREATION && ! SURPRESS_OUTPUT ) { cout << \" \\t inserted \" << * it << \"->\" << el . next << endl ; } } return ; } else if ( SHOW_DICT_CREATION && ! SURPRESS_OUTPUT ) { cout << i << \" was already in collatz.\" << endl ; } } void printCollatz () { for ( map < unsigned long long , struct element >:: iterator it = collatz . begin (); it != collatz . end (); ++ it ) { unsigned long long next = ( * it ). first ; while ( next != 1 ) { cout << next << \"->\" ; next = collatz [ next ]. next ; } cout << 1 << endl ; } } void printSteps ( unsigned long long max ) { cout << \"n,steps\" << endl ; for ( unsigned long long i = 1 ; i <= max ; i ++ ) { cout << i << \",\" << collatz [ i ]. steps << endl ; } } int main ( int argc , char * argv []) { struct element e ; e . next = 4 ; e . steps = 0 ; collatz [ 1 ] = e ; unsigned long long maxCollatz = ( unsigned long long ) atoi ( argv [ 1 ]); for ( unsigned long long i = 2 ; i <= maxCollatz ; i ++ ) { insertCollatz ( i ); saveULong = i ; if ( i % 1000000 == 0 ) { cerr << i << endl ; } } cerr << \"maxAddFromOneEntry: \" << maxAddFromOneEntry << endl ; cerr << \"maxStepsToOne: \" << maxStepsToOne << endl ; cerr << \"maxEntry: \" << maxEntry << endl ; cerr << \"entries: \" << collatz . size () << endl ; //printCollatz(); printSteps ( maxCollatz ); return 0 ; } Then I've processed it with R: R -f analyze.R analyze.R: library(ggplot2) memory.limit(4000) mydata = read.csv(\"/home/moose/Downloads/algorithms/collatz/steps.csv\") # Prepare data p<-ggplot(mydata, aes ( x=n,y=steps )) p<-p + geom_hex(bins=30) p<-p + opts(panel.background = theme_rect(fill='white', colour='white')) # This will save the result in a pdf file called Rplots.pdf p And finally, I've converted it to png: inkscape Rplots.pdf -w 512 --export-png = collatz-sequence-steps.png I've explained this a bit more detailed on StackExchange . Maximum in sequence In the following plot you can see \\(n \\in 1, \\dots, 10,000,000\\) on the \\(x\\) -axis and the maximum \\(y = \\max(\\{a&#94;n_i | i \\in \\mathbb{N}_{> 0}\\})\\) : Hexagonal binpacking plot for maximum in sequence library(ggplot2) mydata = read.csv(\"../collatz-maxNumber.csv\") # Prepare data p<-ggplot(mydata, aes(x=n, y=maximum)) + scale_y_log10() p<-p + geom_hex(bins=50) p<-p + opts(panel.background = theme_rect(fill='white', colour='white')) # This will save the result in a pdf file called Rplots.pdf p Execution times Generating all Collatz sequences up to 10,000,000 items took about 50 seconds. But R needed about 10 minutes to generate images from that. Inkscape didn't like the heavy plot: moose@pc07$ inkscape Rplots.pdf -w 512 --export-png = maxInSequence.png ( inkscape:26733 ) : GLib-ERROR **: /build/buildd/glib2.0-2.34.1/./glib/gmem.c:165: failed to allocate 3440640 bytes &#94;CTrace/breakpoint trap ( core dumped ) Maximum in sequence and steps Maximum value and number of steps for n up to 10,000 Read more All sources of this article are on GitHub Dot guide , Node shapes R on UbuntuUsers (German) Project Euler 14","tags":"Code","title":"The Collatz sequence"},{"url":"https://martin-thoma.com/maps-in-c/","text":"Maps are one of the most useful datastructures in C++ and there is no excuse for not knowing it. Here is a basic example that shows how you can use it: #include <iostream> // cout #include <string> #include <map> using namespace std ; int main () { map < string , string > phonebook ; // Put some stuff in it phonebook [ \"Martin\" ] = \"(0123) 45 678\" ; phonebook [ \"Alice\" ] = \"+(13) 37 0000\" ; phonebook [ \"Bob\" ] = \"+(13) 37 0000\" ; phonebook [ \"Charlie\" ] = \"Alice\" ; // Look stuff up cout << \"The phone number of Alice is \" << phonebook [ \"Alice\" ] << endl ; cout << \"Number of phone book entries: \" << phonebook . size () << endl ; // Print everything cout << \"Iterate over all phonebook entries: \" << endl ; for ( map < string , string >:: iterator it = phonebook . begin (); it != phonebook . end (); ++ it ) { cout << \" \\t \" << ( * it ). first << \": \" << ( * it ). second << endl ; } // Check if entry exists: string person = \"Bob\" ; cout << \"Does \" << person << \" have a phone number ?\" << endl ; map < string , string >:: iterator it = phonebook . find ( person ); if ( it != phonebook . end ()) { //element found: cout << \" \\t \" << \"Yes! His number is: \" << it -> second << endl ; } else { cout << \" \\t \" << \"No.\" << endl ; } } See also Wikipedia: Map (Computer Science) C++ Reference: general information and example Map is ordered collection ( source )","tags":"Code","title":"Maps in C++"},{"url":"https://martin-thoma.com/google-code-jam-round-1c-2013/","text":"Problem A ( Consonants ): Small Set: 4305/4834 users (89%) Large Set: 1551/3778 users (41%) Problem B ( Pogo ): Small Set: 2537/3129 users (81%) Large Set: 121/638 users (19%) Problem C ( The Great Wall ): Small Set: 934/1260 users (74%) Large Set: 74/330 users (22%) More information is on go-hero.net . Consonants A solution from nip : #!/usr/bin/env python # -*- coding: utf-8 -*- def solve ( s , n ): vowels = { 'a' , 'e' , 'i' , 'o' , 'u' } nvalue = 0 count = 0 # how many consecutive consonants pos = - 1 # position of the last substring of n consonants for i , c in enumerate ( s ): if c in vowels : count = 0 else : count += 1 if count >= n : pos = i + 2 - n if pos >= 0 : nvalue += pos return nvalue if __name__ == \"__main__\" : testcases = input () for caseNr in xrange ( 1 , testcases + 1 ): name , n = raw_input () . split ( \" \" ) print ( \"Case # %i : %s \" % ( caseNr , solve ( name , int ( n )))) Pogo This is a very clever solution from xiaowuc1 (translated from Java to Python). The idea is to calculate at first the maximum number of steps you need and then go from your target destination to the origin. How many steps do you need? In the \\(i\\) round, you will make \\(i\\) steps. You need at least \\(x+y\\) steps to get from \\((0|0)\\) to \\((x|y)\\) . This means, you need to solve \\(\\sum_{i=1}&#94;n i = x + y\\) for \\(n\\) . This is \\(\\frac{n&#94;2 + n}{2} = x+y\\) . You might also need to make one extra step if the parity of \\(\\frac{n&#94;2 + n}{2}\\) is not the same as \\(x+y\\) . You can calculate this with a simple loop (see code below). After you know the maximum number of steps, you can apply a greedy solution: Start from \\((x|y)\\) and always go into the direction that is farer away from the origin. #!/usr/bin/env python # -*- coding: utf-8 -*- def calculateSteps ( x , y ): s = 0 dist = abs ( x ) + abs ( y ) while ( s ** 2 + s ) / 2 < dist or (( s ** 2 + s ) / 2 ) % 2 != dist % 2 : s += 1 return s def solve ( x , y ): \"\"\" starting at (0|0) and going i steps, how can you reach (x|y)? \"\"\" s = calculateSteps ( x , y ) solution = \"\" for i in range ( s , 1 - 1 , - 1 ): if abs ( x ) > abs ( y ): if x > 0 : solution += \"E\" x -= i else : solution += \"W\" x += i else : if y > 0 : solution += \"N\" y -= i else : solution += \"S\" y += i return solution [:: - 1 ] if __name__ == \"__main__\" : testcases = input () for caseNr in xrange ( 1 , testcases + 1 ): x , y = raw_input () . split ( \" \" ) x , y = int ( x ), int ( y ) print ( \"Case # %i : %s \" % ( caseNr , solve ( x , y ))) The Great Wall The following solution is not applicable for the large input set, but it works fine for the small one: #!/usr/bin/env python # -*- coding: utf-8 -*- from collections import defaultdict def prepareTribes ( tribes ): tribeStack = [] for tribe in tribes : for attackNumber in range ( 0 , tribe [ \"ni\" ]): tribeStack . append ({ \"day\" : tribe [ \"di\" ] + attackNumber * tribe [ \"delta_di\" ], \"west\" : 2 * ( tribe [ \"wi\" ] + attackNumber * tribe [ \"delta_pi\" ]), \"east\" : 2 * ( tribe [ \"ei\" ] + attackNumber * tribe [ \"delta_pi\" ]), \"height\" : tribe [ \"si\" ] + attackNumber * tribe [ \"delta_si\" ] }) return sorted ( tribeStack , key = lambda tribe : tribe [ \"day\" ]) def runAttack ( wall , tribe ): increase = [] for i in xrange ( tribe [ \"west\" ], tribe [ \"east\" ] + 1 ): if wall [ i ] < tribe [ \"height\" ]: # wall-ee increase . append ({ \"wallPos\" : i , \"height\" : tribe [ \"height\" ]}) return increase def solve ( tribes ): wall = defaultdict ( int ) tribeStack = prepareTribes ( tribes ) #for tribe in tribeStack: # print tribe[\"day\"], \"[\" + str(tribe[\"west\"]) + \",\" + str(tribe[\"east\"])+\"]\", tribe[\"height\"] successes = 0 increase = [] for i , tribe in enumerate ( tribeStack ): increaseTmp = runAttack ( wall , tribe ) #print wall #print tribe if len ( increaseTmp ) > 0 : successes += 1 increase += increaseTmp if i + 1 == len ( tribeStack ) or tribeStack [ i + 1 ][ \"day\" ] > tribe [ \"day\" ]: for el in increase : if wall [ el [ \"wallPos\" ]] < el [ \"height\" ]: wall [ el [ \"wallPos\" ]] = el [ \"height\" ] return successes if __name__ == \"__main__\" : testcases = input () for caseNr in xrange ( 1 , testcases + 1 ): N = input () # Number of tribes attacking the wall tribes = [] for tribe in range ( N ): di , ni , wi , ei , si , delta_di , delta_pi , delta_si = raw_input () . split ( \" \" ) tribes . append ({ \"di\" : int ( di ), # the day of the tribe's first attack \"ni\" : int ( ni ), # the number of attacks from this tribe \"wi\" : int ( wi ), # the westmost \"ei\" : int ( ei ), # and eastmost points respectively of the Wall attacked on the first attack \"si\" : int ( si ), # the strength of the first attack \"delta_di\" : int ( delta_di ), # the number of days between subsequent attacks by this tribe \"delta_pi\" : int ( delta_pi ), # the distance this tribe travels to the east between subsequent attacks (if this is negative, the tribe travels to the west) \"delta_si\" : int ( delta_si ) # the change in strength between subsequent attacks }) print ( \"Case # %i : %s \" % ( caseNr , solve ( tribes ))) By the way, nobody has solved the large input set of this one with Python! But here is a Java solution .","tags":"Code","title":"Google Code Jam â€“ Round 1C 2013"},{"url":"https://martin-thoma.com/how-do-hash-functions-work/","text":"Everybody who has written a noticeable amount of Java code should know the method hashCode () . But most beginners have difficulties to understand the significance of this little method. The following article gives you one small example with some impressions how much hash functions influence execution time. Connect four Connect Four [...] is a two-player game in which the players first choose a color and then take turns dropping colored discs from the top into a seven-column, six-row vertically-suspended grid. The pieces fall straight down, occupying the next available space within the column. The object of the game is to connect four of one's own discs of the same color next to each other vertically, horizontally, or diagonally before your opponent. Source: Wikipedia It looks like this: Connect Four Source: commons.wikimedia.org The task Imagine you would like to find a good strategy where to drop your disk. A simple brute-force method is to create a so called game tree . This means you go through each possibility at each situation that could occur in the game for both players. This approach has generally two problems: You have to know how to go through each situation. For connect four it is easy. Both players place their disks in turns and in every turn the current player has at most 7 possibilities. But it is impossible for games like Calvinball or Mao . The game tree might be HUGE. In this case, you can have \\(4,531,985,219,092 \\approx 4.5 \\cdot 10&#94;{12}\\) game situations ( source ). Even if you would need only one bit for each situation, it would require 566.5 GB! Anyway, lets say we want to store many unique game situations. Unique means, even if you have hundreds of possible paths to get to a given game situations, you will store this game situation only once. Implementation First of all, I would like to mention that you can skip the source code . I've only included it to make it easier to understand what I'm talking about. Lets say our game situation looks like this: struct gamesituation { /** How does the board currently look like? */ char board [ BOARD_WIDTH ][ BOARD_HEIGHT ]; /** * What are the next game situations that I can reach from this * board? * The next[i] means that the player dropped the disc at column i */ int next [ 7 ]; /* I could use a bitfield for this ... but it would make access * much more inconvenient. */ unsigned char isEmpty ; // Is this gamesitatution already filled? unsigned char isFinished ; // Is this game finished? unsigned char stalemate ; // Was this game a stalemate? unsigned char winRed ; // Did red win? unsigned char winBlack ; // Did black win? }; You need a check if one player won: /* * Check if player has won by placing a disc on (x,y). * with direction (xDir, yDir) * @return 1 iff RED won, -1 iff BLACK won and 0 if nobody won */ signed char hasPlayerWon ( char board [ BOARD_WIDTH ][ BOARD_HEIGHT ], int x , int y , char xDir , char yDir ) { char color = board [ x ][ y ]; int tokensInRow = getTokensInRow ( board , color , x , y , xDir , yDir ) + getTokensInRow ( board , color , x , y , - xDir , - yDir ) - 1 ; if ( tokensInRow >= WINNING_NR ) { if ( color == RED ) { return 1 ; } else if ( color == BLACK ) { return - 1 ; } else { perror ( \"this color doesn't / shouldn't exist \\n \" ); exit ( 1 ); } } return 0 ; } /* * A new disc has been dropped. Check if this disc means that * somebody won. * @return 1 iff RED won, -1 iff BLACK won, otherwise NOT_FINISHED */ int isBoardFinished ( char board [ BOARD_WIDTH ][ BOARD_HEIGHT ], int x , int y ) { signed char status ; // check left-right status = hasPlayerWon ( board , x , y , 1 , 0 ); if ( status != 0 ) { return status ; } // top-down status = hasPlayerWon ( board , x , y , 0 , 1 ); if ( status != 0 ) { return status ; } // down-left to top-right status = hasPlayerWon ( board , x , y , 1 , 1 ); if ( status != 0 ) { return status ; } // top-left to down-right status = hasPlayerWon ( board , x , y , - 1 , 1 ); if ( status != 0 ) { return status ; } return NOT_FINISHED ; } If you need an explanation for this, you should read this article . And you need a function that can mirror boards (to get rid of identical, but mirrored situations) and one that can compare boards: char isSameBoard ( char a [ BOARD_WIDTH ][ BOARD_HEIGHT ], char b [ BOARD_WIDTH ][ BOARD_HEIGHT ]) { for ( int x = 0 ; x < BOARD_WIDTH ; x ++ ) { for ( int y = 0 ; y < BOARD_HEIGHT ; y ++ ) { if ( a [ x ][ y ] != b [ x ][ y ]) { return FALSE ; } } } return TRUE ; } void mirrorBoard ( char board [ BOARD_WIDTH ][ BOARD_HEIGHT ], char newBoard [ BOARD_WIDTH ][ BOARD_HEIGHT ]) { for ( int x = 0 ; x < BOARD_WIDTH ; x ++ ) { for ( int y = 0 ; y < BOARD_HEIGHT ; y ++ ) { newBoard [ BOARD_WIDTH - x - 1 ][ y ] = board [ x ][ y ]; } } } You need a function that makes all possible moves for the players: /* * Make all possible turns that the player can make in this * game situation. */ void makeTurns ( char board [ BOARD_WIDTH ][ BOARD_HEIGHT ], char currentPlayer , unsigned int lastId , int recursion ) { unsigned int insertID ; int outcome ; for ( int column = 0 ; column < BOARD_WIDTH ; column ++ ) { // add to column int height = BOARD_HEIGHT - 1 ; // the disc falls down while ( height >= 0 && board [ column ][ height ] == EMPTY ) { height -- ; } height ++ ; // this colum is full if ( height == 6 ) { continue ; } // place disc board [ column ][ height ] = currentPlayer ; if ( didBoardAlreadyOccur ( board )) { // I've already got to this situation insertID = getBoardIndex ( board ); savePreviousID ( insertID , lastId , column ); } else { char mirrored [ BOARD_WIDTH ][ BOARD_HEIGHT ]; mirrorBoard ( board , mirrored ); if ( didBoardAlreadyOccur ( mirrored )) { // I've already got this situation, but mirrored // so take care of symmetry at this point mirroredCounter ++ ; insertID = getBoardIndex ( mirrored ); savePreviousID ( insertID , lastId , column ); } else { registeredSituations ++ ; if ( registeredSituations == MAXIMUM_SITUATIONS ) { giveCurrentInformation (); exit ( MAXIMUM_SITUATIONS_REACHED_EXIT_STATUS ); } if ( REGISTERED_MOD > 0 && registeredSituations % REGISTERED_MOD == 0 ) { giveCurrentInformation (); } outcome = isBoardFinished ( board , column , height ); if ( ABS ( outcome ) <= 1 ) { // the game is finished insertID = getNewIndex ( board ); storeToDatabase ( insertID , board , TRUE , outcome ); savePreviousID ( insertID , lastId , column ); } else { // Switch players if ( currentPlayer == RED ) { currentPlayer = BLACK ; } else { currentPlayer = RED ; } insertID = getNewIndex ( board ); setBoard ( insertID , board ); savePreviousID ( insertID , lastId , column ); char copy [ BOARD_WIDTH ][ BOARD_HEIGHT ]; for ( int x = 0 ; x < BOARD_WIDTH ; x ++ ) { for ( int y = 0 ; y < BOARD_HEIGHT ; y ++ ) { copy [ x ][ y ] = board [ x ][ y ]; } } makeTurns ( copy , currentPlayer , insertID , recursion + 1 ); } } } } } How is this realated to hash functions? You might have noticed a few functions that I didn't explain by now: didBoardAlreadyOccur(board) : Checks if a given board is stored in database. getBoardIndex(board) : This is a function that takes a board and gives a non-negative integer which is characteristic for the given board. savePreviousID(insertID, lastId, column) : store insertID as a possible next situation for lastId in database setBoard(insertID, board) : Insert board into database at position insertID How would you implement didBoardAlreadyOccur(board) ? This function (or insertID) will be the slowest part of the code and will be called VERY often. So it needs to be as fast as possible. A hash function Most of the time you can create hash functions by mapping values to integers. In my case, I mapped the board - which is a two-dimensional char array - to one integer by thinking of it as a very long number. I think of a red disc as the digit 1, a black disc as the digit 2 and an empty field as 0: unsigned int charToInt ( char x ) { if ( x == RED ) { return 1 ; } else if ( x == BLACK ) { return 2 ; } else { return 0 ; } } When you want to get the board number, you can get it like this: Empty=0, red=1, yellow=2 The board number is 00000000000000000210000211210112212 For most game situations, this number will be much too big to store it in an integer. Also, we would like to get an index for our array so that we know where to store this board. The simplest solution to this problem is to calculate NUMBER % ARRAY_SIZE : unsigned int getFirstIndex ( char board [ BOARD_WIDTH ][ BOARD_HEIGHT ]) { unsigned int index = 0 ; for ( int x = 0 ; x < BOARD_WIDTH ; x ++ ) { for ( int y = 0 ; y < BOARD_HEIGHT ; y ++ ) { index += charToInt ( board [ x ][ y ]) * myPow ( 3 , (( x + y * BOARD_WIDTH ) % HASH_MODULO )); } } index = index % MAXIMUM_SITUATIONS ; return index ; } The function getFirstIndex maps an char Array with BOARD_WIDTH * BOARD_HEIGHT = 7 * 6 = 42 elements to an integer interval [0, MAXIMUM_SITUATIONS] = [0, 20000000]. Although I only use three values for the char array, that is \\(3&#94;{42} = 109418989131512359209 \\approx 1.09 \\cdot 10&#94;{20}\\) . There are many game situation numbers that can never occur (e.g. two more red than black dists), but we still map a significantly larger space to [0,20000000]. You can't change that. You can probably find (much) better mappings, but as we know that there are \\(4.5 \\cdot 10&#94;{12}\\) game situations, you will always have the problem that your codomain is much smaller than the domain of your hash function. That's a fundamental problem of hash functions. This means, you will have two board situations that map to the same hash number. This is called a \"hash collision\". When you use the hash number directly as an index for your board, you will have to deal with hash collisions. Some solutions are: Ignoring the problem: That's boring and not always possible (but simple). Linear probing Quadratic probing Linear probing The idea of linear probing is very simple: Inserting a new item: You look at the index \\(i\\) that your hash function gave you. If this index is already full, you look at \\(i+1\\) When you took a look at all slots of your array, you can't insert the new item. Searching for an already inserted item: You look at the index \\(i\\) that your hash function gave you. If \\(i\\) is empty, you're ready. The item was not inserted. If \\(i\\) is not the item you've searched for, you have to look at \\(i+1\\) . Keep looking at the next item until you find your searched item, you've looked at all items or you find an empty slot. Deleting is complicated. You have to look at all items after the deleted one, remove them from your array and insert them again. That's not good. The problem of linear probing is clustering . When you have some hash values that are close together, you might get hash collisions faster. When you've got your first collisions, you resolve them by inserting the value close to the value where you originally wanted to save it. So you get one big cluster quite fast. When you want to insert an element in the cluster, you first have to search the end of the cluster. That's bad for performance. An advantage of linear probing compared to quadratic probing is that you might get a better performance due to cache effects. Quadratic probing The idea of quadratic probing is the same as for linear probing, but you try to fix the clustering-problem by using a clever way to search for a free spot: \\(h_i(x) = \\left(h(x) + (-1)&#94;{i+1} \\cdot \\left\\lceil\\frac{i}{2}\\right\\rceil&#94;2\\right) \\bmod~m\\) where \\(h\\) is your hash function and \\(i\\) is your i-th try to find a free spot while you have \\(m\\) spots in total. This one also suffers from clustering, but it's not as bad as with linear clustering. Double hashing This solution could be the best one, but also the hardest one to implement correctly. You could find a free spot by using a second hash function \\(h'\\) like this: \\(h_i(x) = (h(x)+h'(x)\\cdot i) ~ \\bmod ~ m\\) BUT you have to make sure that \\(Pr[h(x)=h(y) \\land h'(x)=h'(y)] = \\frac{1}{m&#94;2}\\) Performance You can use linear probing, quadratic probing and double hashing in my example and measure how many game situations get stored. The more game situations you can store in the same amount of time, the better: Linear probing, quadratic probing and double hashing for connect four You can see that linear probing performs much worse than quadratic probing and double hashing. When you compare quadratic probing with double hashing, there seems not to be a big difference. But note that my second hash function is almost the same as the first one. You could probably choose a better second hash function and get better results (suggestions are welcome). Why are hash functions important? Hash functions help you to map a big amount of data to a small space. They are important, because they are a relevant part of many datastructures. The better they are, the faster will operations on those datastructures work. Better means: Faster to compute or less collisions. Some datastructures like this are: HashMap and HashTable (â†’ difference ) HashSet Final notes Another resolution for hash collisions is creating a linked list. This means you will not suffer from clustering and you can insert in \\(\\mathcal{O}(1)\\) . But searching for an element is still in \\(\\mathcal{O}(n)\\) , where \\(n\\) is the number of elements that were already inserted. Resources You can find the code at GitHub .","tags":"Code","title":"How do hash functions work?"},{"url":"https://martin-thoma.com/google-code-jam-round-1b-2013/","text":"Problem A ( Osmos ): Small Set: 4668/7250 users (64%) Large Set: 3537/4578 users (77%) Problem B ( Falling Diamonds ): Small Set: 952/1882 users (51%) Large Set: 525/724 users (73%) Problem C ( Garbled Email ): Small Set: 444/896 users (50%) Large Set: 255/345 users (74%) More information are on go-hero.net . Osmos #!/usr/bin/env python # -*- coding: utf-8 -*- def howBigDoIget ( A , motes ): while len ( motes ) > 0 and A > min ( motes ): A += min ( motes ) motes . remove ( min ( motes )) return A def stepsNeededForNext ( A , motes ): m = min ( motes ) steps = 0 if m >= 1 and A == 1 : return 10 ** 12 while A <= m : A += ( A - 1 ) steps += 1 return steps def solve ( A , motes ): steps = 0 A = howBigDoIget ( A , motes ) while len ( motes ) > 0 and A <= max ( motes ): if ( stepsNeededForNext ( A , motes ) >= len ( motes )): steps += len ( motes ) return steps else : A += ( A - 1 ) A = howBigDoIget ( A , motes ) steps += 1 return steps if __name__ == \"__main__\" : testcases = input () for caseNr in xrange ( 1 , testcases + 1 ): A , N = map ( int , raw_input () . split ( \" \" )) motes = sorted ( map ( int , raw_input () . split ( \" \" ))) copyed = motes [:] solution = solve ( A , motes ) if solution > N : solution = N print ( \"Case # %i : %s \" % ( caseNr , solution )) Falling Diamonds Once you've read the task, you should understand some very basic ideas: First of all, diamonds only fall at $x=0$ ! If your target coordinates are $(x,y)$ , you have the same output as for $(-x,y)$ , as everything is symmetric. You have to get a basis for your diamonds pyramid. I've colored the basis in yellow in the images below. When your target is above the ground, you can let the diamond slide down to calculate the size of the basis. You have to get those yellow diamonds first, before you can get the orange one. Let Diamonds slide down Note that you don't have to calculate a probabilty for the yellow pyramids. You get those with probability of 1. What I've forgot: You should also catch the case that you can fill up the next bigger pyramid. If this is possible, you can guarantee that you will reach your target \\((x,y)\\) . The rest is simple math. You have \\(rest\\) diamonds left after you've build the base (yellow). Then you need \\(y+1\\) diamonds slide to the right side. The probability that you have exactly \\(k\\) hits while making \\(N\\) tries with a probability of 50% is \\(\\binom{N}{k} \\cdot (\\frac{1}{2})&#94;N\\) . You want at least \\(k\\) hits, so you want \\(\\sum_{i=k}&#94;N \\binom{N}{i} \\cdot (\\frac{1}{2})&#94;N\\) . #!/usr/bin/env python # -*- coding: utf-8 -*- import gmpy \"\"\" Calculate the binomial coefficient \"\"\" def binomial ( n , k ): return gmpy . comb ( n , k ) def solve ( N , x , y ): \"\"\" @param N: Number of diamonds @param x,y: Target coordinate @return: possiblity, that a diamond will be at coordinate (x,y) \"\"\" if x == 0 : n = y + 1 if N >= ( n * n + n ) / 2 : return 1.0 else : return 0.0 # From this point, x != 0 is True xTmp = x + y # let target slide down n = xTmp - 1 baseDiamands = ( n ** 2 + n ) / 2 # are there enough diamonds left after you've build the basis? rest = N - baseDiamands if rest <= 0 : return 0.0 # are there enough diamonds left so that you can guarantee that # you will fill up the next bigger pyramid at least to the # target position? biggerBaseDiamonds = baseDiamands + n + 2 + y if N >= biggerBaseDiamonds : return 1.0 # some math: # bernoulli prob = 0.0 hitsNeeded = y + 1 for k in range ( hitsNeeded , rest + 1 ): prob += binomial ( rest , k ) return prob / 2 ** rest if __name__ == \"__main__\" : testcases = input () for caseNr in xrange ( 1 , testcases + 1 ): N , x , y = map ( int , raw_input () . split ( \" \" )) print ( \"Case # %i : %.9Lf \" % ( caseNr , solve ( N , abs ( x ), y )))","tags":"Code","title":"Google Code Jam â€“ Round 1B 2013"},{"url":"https://martin-thoma.com/sicherheit-klausur/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žSicherheit\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Jun.-Prof. Hofheinz im Sommersemester 2013 gehÃ¶rt. An diesem Artikel wird natÃ¼rlich noch gearbeitet. Behandelter Stoff 25.04.2013 Caesar, Vigenere, One-Time-Pad VL 01 22.04.2013 Symmetrische VerschlÃ¼sselungen; Stromchiffren; Blockchiffren (DES, AES); Betriebsmodi : Modus VerschlÃ¼sselung EntschlÃ¼sselung Parallelisierbarkeit verschl. entschl. ECB $c_i = ENC(K, m_i)$ $m_i = DEC(K, m_i)$ Ja Ja CBC $c_i = ENC(K, m_i \\oplus c_{i-1})$ $m_i = DEC(K, c_i) \\oplus c_{i-1}$ Nein Ja CFB $c_i = m_i \\oplus ENC(K, c_{i-1})$ $m_i = c_i \\oplus ENC(K, c_{i-1})$ Nein Ja OFB $c_i = m_i \\oplus ENC(K, IV)&#94;i$ $m_i = c_i \\oplus ENC(K, IV)&#94;i$ Nein Nein DES-Feistelstruktur VL 02 25.04.2013 Lineare Kryptoanalyse, Differentielle Kryptoanalyse, Semantische Sicherheit , IND-CPA , Feistel-Schema VL 03 29.04.2013 Hashfunktionen , Kollisionsresistenz $\\Rightarrow$ Einwegeigenschaft , Merkle-Damgard-Konstruktion und Length-Extension-Problematik, Birthday Attack, Meet-in-the-Middle-Angriff VL 04 06.05.2013 Public-Key-VerschlÃ¼sselung (Idee, RSA); Meet-in-the-Middle-Angriff fÃ¼r Hashfunktionen VL 05 13.05.2013 Rest Public-Key-VerschlÃ¼sselung (ElGamal, Vergleich RSA/ElGamal), Symmetrische Authentifikation von Nachrichten (Sicherheitsmodell, Hash-then-Sign, PRFs , HMAC ), MAC VL 06 27.05.2013 Asymmetrische Authentifikation von Nachrichten (RSA-PSS, ElGamal, DSA) VL 07 03.06.2013 SchlÃ¼sselaustausch ( Kerberos , TLS, Angriffe) VL 08 10.06.2013 SchlÃ¼sselaustausch (TLS-Angriffe, weitere Verfahren), Identifikationsprotokolle VL 09 13.06.2013 Identifikationsprotokolle (Sicherheitsanalyse), Zero-Knowledge-Protokolle, Commitment â†’ Hiding VL 10 17.06.2013 Zero-Knowledge-Protokolle, Nutzerauthentifikation VL 11 24.06.2013 Nutzerauthentifikation (WÃ¶rterbuchangriffe, interaktive Authentifikation, positionsbasierte Kryptographie); Rainbowtables; LM-Hashes VL 12 27.06.2013 Nutzerauthentifikation (positionsbasierte Kryptographie), Zugriffskontrolle (Bell-LaPadula) VL 13 01.07.2013 Zugriffskontrolle (Bell-LaPadula, Chinese Wall), Analyse grÃ¶ÃŸerer Systeme VL 14 08.07.2013 Analyse grÃ¶ÃŸerer Systeme, hÃ¤ufige Sicherheitsprobleme VL 15 11.07.2013 HÃ¤ufige Sicherheitsprobleme VL 16 Falls hier was fehlt, kÃ¶nnt ihr mich gerne in den Kommentaren oder per Mail (info@martin-thoma.de) darauf aufmerksam machen. Ich bin ja mal gespannt, ob ich das bis zum Ende aktuell halte. Definitionen und SÃ¤tze Eine Ã¼ber $k$ parametrisierte Funktion $H$ ist kollisionsresistent , wenn jeder PPT-Algorithmus nur mit hÃ¶chstens vernachlÃ¤ssigbarer Wahrscheinlichkeit eine Kollision findet. FÃ¼r jeden PPT-Algorithmus $\\mathcal{A}$ ist $Adv&#94;{cr}_{H,\\mathcal{A}}(k) := Pr[(X,X') \\leftarrow \\mathcal{A}(1&#94;k): X \\neq X' \\land H_k(X) = H_k(X')]$ vernachlÃ¤ssigbar. Eine Ã¼ber $k$ parametrisierte Funktion $H$ ist eine Einwegfunktion bzgl. der Urbildverteilung $\\mathcal{X}_k$, wenn jeder PPT-Algorithmus nur mit hÃ¶chstens vernachlÃ¤ssigbarer Wahrscheinlichkeit ein Urbild eines gegebenen, aus $\\mathcal{X}_k$ gezogenen Bildes findet. FÃ¼r jeden PPT-Algorithmus $\\mathcal{A}$ ist $Adv&#94;{cr}_{H,\\mathcal{A}}(k) := Pr[X' \\leftarrow \\mathcal{A}(1&#94;k, H(X)): H(X) = H(X')]$ vernachlÃ¤ssigbar, wobei $X \\leftarrow \\mathcal{X}_k$ gewÃ¤hlt wurde. Jede kollisionsresistente Hashfunktion $H:\\{0,1\\}&#94;* \\rightarrow \\{0,1\\}&#94;k$ ist eine Einwegfunktion bzgl. der Gleichverteilung auf $\\{0,1\\}&#94;{2k}$. Ist $f$ eine kollisionsresistente Hashfunktion, so ist die Merkleâ€“DamgÃ¥rd-Konstruktion mit $f$ kollisionsresistent. Hash-Then-Sign-Paradigma: Sei (Sig, Ver) EUF-CMA-sicher und H eine kollisionsresistente Hashfunktion. Dann ist der durch Sig'(K, M) = Sig(K, H(M)), Ver'(K, M, $\\sigma$) = Ver(K, H(M), $\\sigma$) erklÃ¤rte MAC EUF-CMA-sicher. Fragen Wann ist ein VerschlÃ¼sselungsschema IND-CPA-sicher? IND-CPA bedeutet â€žindistinguishability under chosen-plaintext attacks\". Ein VerschlÃ¼sselungsschema ist genau dann IND-CPA-Sicher, wenn kein effizienter Angreifer $\\mathcal{A}$ Chiffrate von selbstgewÃ¤hlten Klartexten unterscheiden kann. Wann ist eine Signatur EUF-CMA-sicher? EUF-CMA bedeutet â€žexistentially unforgeable under chosen-message attacks\". Eine Signatur ist genau dann EUF-CMA-Sicher, wenn alle PPT-Angreifer $\\mathcal{A}$ folgendes Spiel nur vernachlÃ¤ssigbar oft gewinnen: $\\mathcal{A}$ hat Zugriff auf ein $Sig(K, \\cdot)$-Orakel $\\mathcal{A}$ gibt als Ausgabe $(M&#94;*, \\sigma&#94;*)$ $\\mathcal{A}$ gewinnt, wenn $Ver(K, M&#94;*, \\sigma&#94;*) = 1$ und $M&#94;*$ â€žfrisch\" ist Was sind Replay-Angriffe? Bei Replay-Angriffen fÃ¤ngt der Angreifer einen Teil der Kommunikation von Alice und Bob ab. SpÃ¤ter schickt er diesen Teil ohne weitere Bearbeitung an einen der Beiden. Was versteht man unter der Merkleâ€“DamgÃ¥rd-Konstruktion? Die Merkleâ€“DamgÃ¥rd-Konstruktion ist eine Methode zur Konstruktion von kryptographischen Hash-Funktionen. Sie funktioniert so: Merkle-Damgard-Konstruktion Quelle: Wikipedia Wie funktioniert RSA? Generiere zwei Primzahlen $p, q \\in \\mathbb{P}$ Berechne $n := p \\cdot q$ und $\\varphi(n) = (p-1) \\cdot (q-1)$ WÃ¤hle $e$, sodass gilt: $ggT(e, \\varphi(n)) = 1$ und $1 < e < \\varphi(n)$ Berechne $d$, sodass gilt: $e \\cdot d \\equiv 1 \\mod \\varphi(n)$ VerschlÃ¼sselung einer Nachricht $m$: $c = m&#94;{e} \\mod n$ VerschlÃ¼sselung eines Ciphertextes $c$: $m = c&#94;{d} \\mod n$ Welches Problem birgt ein kleines $e$ beim RSA-Verfahren? Folgender Angriff ist fÃ¼r $e=3$ mÃ¶glich: Nachricht $m$ wird an 3 Benutzer geschickt Angreifer kennt Chiffrate fÃ¼r $N_1, N_2, N_3$. Chinesischer Restsatz fÃ¼r $m&#94;3 \\mod N_1 N_2 N_3$. Wurzelziehen Ã¼ber $\\mathbb{Z}$ liefert $m$ Was ist damit gemeint, wenn man sagt â€žRSA ist Homomorph\"? Homomorphie ist folgende (unerwÃ¼nschte) Eigenschaft: \\begin{align} Enc(pk, m_1) \\cdot Enc(pk, m_2) &= m_1&#94;e \\cdot m_2&#94;e\\\\ &= (m_1 \\cdot m_2)&#94;e \\\\ &= Enc(pk, m_1 \\cdot m_2) \\end{align} Diese Eigenschaft ist z.B. in folgendem Szenario problematisch: Angenommen bei einer Auktion werden die gebotenen GeldbetrÃ¤ge verschlÃ¼sselt. Dann kann ein Angreifer das Chiffrat (gÃ¼ltig) verÃ¤ndern. So kann er den Geldbetrag ohne Probleme verdoppeln. Was sind HMACs ? Spezielle symmetrische Signaturen, die wie folgt aufgebaut sind: $Sig(K, M) = H(K \\oplus opad, H(K \\oplus ipad, M))$ Wie funktioniert ElGamal ? WÃ¤hle eine zyklische Gruppe $\\mathbb{G} = \\langle g \\rangle$. $pk = (\\mathbb{G}, g, g&#94;x)$, $sk=(\\mathbb{G}, g, x)$, wobei $x$ zufÃ¤llig gewÃ¤hlt wird. VerschlÃ¼sselung einer Nachricht $m$: $Enc(pk, m) = (g&#94;y, g&#94;{xy} \\cdot m)$ mit zufÃ¤lligem $y$ â†’ VerschlÃ¼sselung ist zufÃ¤llig! VerschlÃ¼sselung eines Ciphertextes $c$: $Dec(sk, (Y, Z)) = \\frac{Z}{Y&#94;x} = \\frac{g&#94;{xy} \\cdot m}{(g&#94;{y})&#94;x} = m$ Wie funktioniert das Kerberos-SchlÃ¼sselaustauschprotokoll? Alice schreibt dem KC , dass Alice und Bob gerne einen SchlÃ¼sselaustausch vornehmen wollen. Das KC schickt Alice ihren SchlÃ¼ssel $K_A$, den sie fÃ¼r die Kommunikation mit Bob verwenden kann. ZusÃ¤tzlich wird ein Zeitstempel $T_{KC}$, eine GÃ¼ltigkeitsdauer $L$ sowie ein frischer SchlÃ¼ssel $K$ Ã¼bertragen. TODO!!!! Ein gutes YouTube-Video gibts auch. Warum kann es schlecht fÃ¼r die Sicherheit sein, wenn man komprimiert? Annahme: Ein Angreifer kann zu dem Geheimtext, der komprimiert wird, etwas vor der Kompression hinzufÃ¼gen. Wenn der Ciphertext deutlich weniger wÃ¤chst als er an Text hinzugefÃ¼gt hat, kann er vermuten, dass er den Text erraten hat. (â†’ CRIME-Angriff) Was ist damit gemeint, dass das One-Time-Pad-Chiffre verwundbar ist? Ein Angreifer kann die Klartextnachricht Ã¤ndern. Wenn er weiÃŸ (oder zumindest ahnt) was der Klartext ist, kann er dafÃ¼r sorgen, dass ein Klartext gleicher LÃ¤nge seiner Wahl bei der EntschlÃ¼sselung herauskommt. Nennen Sie Verfahren, die IND-CPA-sicher sind. Eine Blockciffre im CBC-Modus Nennen Sie Verfahren, die EUF-CMA-sicher sind. Sei PRF: $\\{0,1\\}&#94;k \\times \\{0,1\\}&#94;k \\rightarrow \\{0,1\\}&#94;k$ eine PRF und $H:\\{0,1\\}&#94;* \\rightarrow \\{0,1\\}&#94;k$ eine kollisionsresistente Hashfunktion. Dann ist der durch $Sig(K, M) = PRF(K, H(M))$ gegebene MAC EUF-CMA-sicher. Diverses TLS Handshake TLS Handshake Change Cipher Spec Drop Ein Angriff auf verschlÃ¼sselte Verbindungen: Change cipher spec drop Material Vorlesungswebsite Mein Anki-Deck Skript StackExchange: What are the differences between a digital signature, a MAC and a hash? In der Fachschaft gibt es folgende Altklausuren: Hauptklausur SS 2012 Nachklausur SS 2011 Hauptklausur SS 2011 Nachklausur SS 2010 Hauptklausur SS 2010 Aufbau der Klausur Bisher gab es meist 6 Aufgaben mit jeweils 10 Punkten: Blockchiffren und Betriebsmodi ElGamal / Diffie-Hellman-SchlÃ¼sselaustausch RSA; RSA-OAEP Kerberos / Feistel / (H)MAC Bell-LaPadula / Chinese Wall Multiple Choice Ãœbungsbetrieb Es gibt ÃœbungsblÃ¤tter auf der Vorlesungswebsite, aber keinen Ãœbungsschein, keine Abgaben und keine Bonuspunkte. Termine und Klausurablauf Datum : Freitag, den 26. Juli 2013 von 14:00 bis 15:00 Uhr (Klausur dauerte eine Stunde) Ort : seit 24.07.2013 auf der Vorlesungswebsite (ich bin im H.S.a.F) Punkte : 60 Bestehensgrenze : 20 Ãœbungsschein : Nein Bonuspunkte : Nein Nicht vergessen Studentenausweis Kugelschreiber Ergebnisse Sind noch nicht drauÃŸen (Stand: 30.07.2013) Sind nun drauÃŸen (Stand: 09.08.2013): VorlÃ¤ufige Ergebnisse als PDF Ergebnis der Sicherheitsklausur","tags":"German posts","title":"Sicherheit-Klausur"},{"url":"https://martin-thoma.com/semantische-sicherheit/","text":"In der Vorlesung vom 25.04.2013 hat Prof. Hofheinz gesagt, dass man semantische Sicherheit praktisch nicht beweisen kann, da man zuerst \\(\\mathcal{P} \\neq \\mathcal{NP}\\) beweisen mÃ¼sste. Warum das so ist, versuche ich nun zu erlÃ¤utern. Einwegfunktionen und $\\mathcal{P} \\neq \\mathcal{NP}$ Sei $f:X \\rightarrow Y$ eine Funktion. $f$ heiÃŸt eine Einwegfunktion, genau dann wenn fÃ¼r alle $x \\in X$ gilt: $y := f(x)$ kann in Polynomialzeit berechnet werden FÃ¼r die Berechnung eines Urbildes $x$ aus $y$ existiert kein randomisierter Algorithmus, der in Polynomialzeit lÃ¤uft. Es gilt: Wenn eine Einwegfunktion \\(f\\) existiert, dann gilt \\(\\mathcal{P} \\neq \\mathcal{NP}\\) . Warum? Nun, angenommen es gibt eine Einwegfunktion \\(f\\) . Dann sei die formale Sprache \\(L_f\\) definiert durch: \\(L_f := \\{(\\bar x, y) | \\exists x: \\bar x \\text{ ist PrÃ¤fix von } x \\text{ und } y = f(x)\\}\\) Es gilt: \\(L_f \\notin \\mathcal{P}\\) , da fÃ¼r ein gegebenes \\(y\\) das zugehÃ¶rige \\(x\\) in polynomialzeit bestimmt werden kÃ¶nnte (wie will man sonst prÃ¼fen, ob \\(\\bar x\\) ein PrÃ¤fix von \\(x\\) ist?) Falls jemanden diese BegrÃ¼ndung nicht ausreicht ist hier noch ein Beweis von Prof. Hofheinz (Danke!) Beh.: \\(L_f \\notin \\mathcal{P}\\) Bew.: durch Widerspruch Annahme.: \\(L_f \\in P\\) \\(\\Rightarrow\\) Es existiert ein Polyzeit-Algorithmus \\(\\mathcal{A}\\) fÃ¼r \\(L_f\\) , der bei Eingabe \\((\\bar x, y)\\) entscheidet, ob ein \\(x\\) mit \\(f(x)=y\\) und PrÃ¤fix \\(\\bar x\\) existiert oder nicht. Dann kÃ¶nnen wir einen Algorithmus \\(\\mathcal{B}\\) aus \\(\\mathcal{A}\\) bauen, der \\(f\\) invertiert. Gegeben \\(y\\) verfÃ¤hrt \\(\\mathcal{B}\\) wie folgt: \\(\\mathcal{B}\\) ruft \\(\\mathcal{A}(0,y)\\) auf und erfÃ¤hrt so, ob ein Urbild \\(x\\) von \\(y\\) mit Anfangsbit \\(0\\) existiert. Wenn ja, ruft \\(\\mathcal{B}\\) den Algorithmus \\(\\mathcal{A}(00,y)\\) auf, wenn nein ruft \\(\\mathcal{B}\\) den Algorithmus \\(\\mathcal{A}(10,y)\\) auf usw. So wird ein Urbild \\(x\\) bitweise bestimmt. Ein solches \\(\\mathcal{B}\\) findet also effizient Urbilder, im Widerspruch zur Einwegannahme Ã¼ber \\(f \\blacksquare\\) Aber: Wenn das \\(x\\) gegeben ist, dann ist es einfach zu zeigen, dass \\(y= f(x)\\) gilt und damit auch, ob \\(\\bar x\\) ein PrÃ¤fix von \\(x\\) ist. Damit ist \\(L_f \\in \\mathcal{NP}\\) . Damit gilt: \\(L_f \\in \\mathcal{NP} \\setminus \\mathcal{P}\\) . Wenn aber \\(\\mathcal{NP} \\setminus \\mathcal{P} \\neq \\emptyset\\) , dann gilt insbesondere \\(\\mathcal{P} \\neq \\mathcal{NP}\\) . An dieser Stelle sollte man also einsehen, dass eine Einwegfunktion nach obiger Definition nur existieren kann, wenn \\(\\mathcal{P} \\neq \\mathcal{NP}\\) gilt. Semantische Sicherheit Wikipedia gibt folgende Beschreibung von semantischer Sicherheit: Ein VerschlÃ¼sselungsverfahren ist semantisch sicher, wenn jeder Angreifer jede Information, die er aus einem Chiffrat Ã¼ber die Nachricht ableiten kann, bereits dann ableiten kann, wenn er nur die LÃ¤nge des Chiffrats kennt. Ein Chiffrat verrÃ¤t also nichts Ã¼ber eine Nachricht als ihre LÃ¤nge. Herr Prof. Hofheinz hat folgende informelle Definition von Semantischer Sicherheit in der Vorlesung gegeben: Ein symmetrisches VerschlÃ¼sselungsverfahren ist semantisch sicher, wenn es fÃ¼r jede $M$ -Verteilung, jede Funktion $f$ und jeden PPT-Algorithmus $\\mathcal{A}$ einen PPT-Algorithmus $\\mathcal{B}$ gibt, so dass $Pr \\left [\\mathcal{A}&#94;{\\text{Enc}(K, \\cdot)}(\\text{Enc}(K, M)) = f(M) \\right ] - Pr [\\mathcal{B}(\\varepsilon) = f(M)]$ vernachlÃ¤ssigbar (als Funktion im Sicherheitsparameter $K$ ) ist. Hier ist \\(M\\) eine Nachricht (Message), \\(\\text{Enc(K, M)}\\) die VerschlÃ¼sselung einer konkreten Nachricht \\(M\\) mit dem SchlÃ¼ssel \\(K\\) , \\(\\varepsilon\\) eine triviale Information (ich glaube das ist z.B. die LÃ¤nge des Ciphertextes) und \\(f\\) extrahiert beliebige Informationen aus dem Plaintext Die erste Wahrscheinlichkeit bezeichnet die MÃ¶glichkeit, aus dem Ciphertext Informationen der Art \\(f\\) Ã¼ber den Plaintext \\(M\\) zu erhalten. Die zweite Wahrscheinlichkeit bezeichnet die MÃ¶glichkeit â€žaus dem Nichts\" Informationen Ã¼ber eine Nachricht zu erhalten. Damit will man triviale Informationen eliminieren. Insgesamt gibt es also die Wahrscheinlichkeit an, nicht-triviale Informationen aus einer VerschlÃ¼sselten Nachricht zu erhalten. Mit effizient ist vermutlich in Polynomialzeit gemeint. Wenn es nun mehrfach benutzbare semantisch sichere Verfahren gibt, dann kann man dieses Verfahren als Einwegfunktion nutzen. Wenn eine Einwegfunktion existiert, gilt \\(\\mathcal{P} \\neq \\mathcal{NP}\\) . Also folgt: Wenn es nun mehrfach benutzbare semantisch sichere Verfahren existieren, gilt \\(\\mathcal{P} \\neq \\mathcal{NP}\\) . Dies ist aber eines der Millennium-Probleme und noch nicht geklÃ¤rt.","tags":"German posts","title":"Semantische Sicherheit"},{"url":"https://martin-thoma.com/google-code-jam-round-1a-2013/","text":"Problem A ( Bullseye ): Small Set: 5856/6195 users (95%) Large Set: 1806/4795 users (38%) Problem B ( Manage your Energy ): Small Set: 2323/3789 users (61%) Large Set: 456/1133 users (40%) Problem C ( Good Luck ): Small Set: 1366/1774 users (77%) Large Set: 31/605 users (5%) More information might soon be on go-hero.net . I'm too slow for Google Code Jam sigh . Nevertheless, here are my solutions: Bullseye Small <? function solve ( $r , $t ) { $circles = 0 ; while ( $t >= 0 ) { $circles ++ ; $t -= ( $r + 1 ) * ( $r + 1 ) - $r * $r ; $r += 2 ; } return floor ( $circles ) - 1 ; } $fp = fopen ( $argv [ 1 ], 'r' ); $testcases = fgets ( $fp ); $caseNr = 0 ; while ( $line = fgets ( $fp )) { $caseNr ++ ; $a = explode ( ' ' , $line ); $r = $a [ 0 ]; $t = $a [ 1 ]; echo \"Case # $caseNr : \" . solve ( $r , $t ) . \" \\n \" ; } ?> Large Argh I've copied the wrong equation from my pad to my computer You basically have to solve this: \\begin{align} t - \\sum_{i=0}&#94;x ((r+1+2i)&#94;2 - (r+2i)&#94;2) &\\geq 0\\\\ \\Leftrightarrow t - (x+1)(2x+2r+1) &\\geq 0 \\\\ \\Leftrightarrow (-2)x&#94;2 + (2r+3)x + (t-2r-1) &\\geq 0 \\\\ \\Rightarrow x_{1,2} = 0 \\Leftrightarrow x_{1,2} &= \\frac{1}{-4} \\cdot (-(2r+3) \\pm \\sqrt{(2r+3)&#94;2-4(-2)(t-2r-1)}) \\\\ &= -\\frac{1}{4} \\cdot (-2r-3 \\pm \\sqrt{4r&#94;2+12r+9+8(t-2r-1)})\\\\ &= -\\frac{1}{4} \\cdot (-2r-3 \\pm \\sqrt{4r&#94;2+12r+9+8t-16r-8})\\\\ &= -\\frac{1}{4} \\cdot (-2r-3 \\pm \\sqrt{4r&#94;2-4r+1+8t})\\\\ &= \\frac{1}{4} \\cdot (2r+3 \\pm \\sqrt{(2r-1)&#94;2+8t})\\\\ &= \\frac{1}{4} \\cdot (2r+3 \\pm \\sqrt{(2r-1)&#94;2+8t})\\\\ \\end{align} I have to know that \\(1 \\leq r\\) and \\(1 \\geq x \\in \\mathbb{N}\\) . So you have to round \\(x_1, x_2\\) to the nearest solution. Did you know that Python has (in numpy) a method to calculate roots of a quadratic equation? See numpy.roots for reference. #!/usr/bin/env python # -*- coding: utf-8 -*- from numpy import ceil , roots def check ( r , t , x ): return t - ( x + 1 ) * ( 2 * r + 2 * x + 1 ) >= 0 def solveFast ( r , t ): myRoots = roots (( 2 , 2 * r + 3 , 2 * r + 1 - t )) for i in xrange ( 2 ): if myRoots [ i ] >= 0 : answer = int ( ceil ( myRoots [ i ])) + 1 while not check ( r , t , answer ): answer -= 1 return answer + 1 if __name__ == \"__main__\" : testcases = input () for caseNr in xrange ( 1 , testcases + 1 ): line = raw_input () r , t = map ( int , line . split ( ' ' )) print ( \"Case # %i : %s \" % ( caseNr , solveFast ( r , t ))) Good Luck This one solves at least the first test case, but not the second one. I love itertools â˜º #!/usr/bin/env python # -*- coding: utf-8 -*- from math import factorial from itertools import combinations_with_replacement import pprint from copy import deepcopy def mul ( integers ): s = 1 for p in integers : s *= p return s def merge ( candidates , block ): newCandidates = deepcopy ( candidates ) for el in set ( block ): diff = block . count ( el ) - newCandidates . count ( el ) for i in xrange ( diff ): newCandidates . append ( el ) return newCandidates def canBeIn ( b , candidates , N ): merged = merge ( candidates , b ) return not ( len ( merged ) > N ) \"\"\" N: number of numbers in total that got randomly picked M: A_i in [2, M] \"\"\" def solve ( N , M , products , productToBuildungs ): candidates = [] # Is there a simple answer? for p in products : if productToBuildungs [ p ][ 0 ] == 1 : candidates = merge ( candidates , productToBuildungs [ p ][ 1 ][ 0 ]) if len ( candidates ) == N : return candidates for p in products : pos = filter ( lambda b : canBeIn ( b , candidates , N ), productToBuildungs [ p ][ 1 ]) if len ( pos ) == 1 : candidates = merge ( candidates , pos [ 0 ]) while len ( candidates ) < N : candidates . append ( 2 ) return candidates if __name__ == \"__main__\" : testcases = input () for caseNr in xrange ( 1 , testcases + 1 ): print ( \"Case # %i :\" % caseNr ) line = raw_input () arr = line . split ( ' ' ) R = int ( arr [ 0 ]) N = int ( arr [ 1 ]) M = int ( arr [ 2 ]) K = int ( arr [ 3 ]) # which products can I get productToBuildungs = {} for r in xrange ( 0 , N + 1 ): for product in combinations_with_replacement ( range ( 2 , M + 1 ), r ): s = mul ( product ) if s not in productToBuildungs : productToBuildungs [ s ] = [ 1 , [ list ( product )]] else : productToBuildungs [ s ][ 0 ] += 1 productToBuildungs [ s ][ 1 ] . append ( list ( product )) for r in xrange ( R ): products = [ int ( el ) for el in raw_input () . split ( ' ' ) if int ( el ) != 1 ] print ( '' . join ( map ( str , sorted ( solve ( N , M , products , productToBuildungs )))))","tags":"Code","title":"Google Code Jam â€“ Round 1A 2013"},{"url":"https://martin-thoma.com/google-code-jam-templates/","text":"Here are some templates that are a good start for Google Code Jam. C++ #include <stdio.h> #include <string> #include <iostream> using namespace std ; int main ( void ) { /* number of test cases */ unsigned short int testcases ; cin >> t ; for ( int i = 1 ; i <= t ; i ++ ) { //loops for each case for ( int zeile = 0 ; zeile < 4 ; zeile ++ ) { for ( int spalte = 0 ; spalte < 4 ; spalte ++ ) { cin >> game [ zeile ][ spalte ]; } } cout << \"Case #\" << i << \": \" << solve () << endl ; } return 0 ; } Compile g++ A.cpp Execute ./a.out < A-small-practice.in > result.txt Python Input: input , raw_input() String parsing: strip() , split() #!/usr/bin/env python # -*- coding: utf-8 -*- if __name__ == \"__main__\" : testcases = input () for caseNr in xrange ( 1 , testcases + 1 ): cipher = raw_input () print ( \"Case # %i : %s \" % ( caseNr , solve ( cipher ))) Execute python A.py < A-small-practice.in > result.txt Java This is an ajusted version of mystics solution for \"Dancing with Googlers\". You might want to take a look at Scanner and PrintWriter . import java.util.* ; import java.io.* ; public class DancingWithGoogle { final static String PROBLEM_NAME = \"dance\" ; final static String WORK_DIR = \"/home/moose/Desktop/\" + PROBLEM_NAME + \"/\" ; final static String INPUT_FILE_NAME = \"input.txt\" ; final static String OUTPUT_FILE_NAME = \"output.txt\" ; static int [][] maxBest = new int [ 31 ][ 2 ]; static void preprocess () { for ( int i = 0 ; i <= 30 ; i ++) Arrays . fill ( maxBest [ i ], - 1 ); for ( int A = 0 ; A <= 10 ; A ++) for ( int B = A ; B <= 10 && B <= A + 2 ; B ++) for ( int C = B ; C <= 10 && C <= A + 2 ; C ++) { int tot = A + B + C , sur = ( C - A == 2 ? 1 : 0 ); maxBest [ tot ][ sur ] = Math . max ( maxBest [ tot ][ sur ], C ); } } void solve ( Scanner sc , PrintWriter pw ) { int N = sc . nextInt (); int S = sc . nextInt (); int p = sc . nextInt (); int [] tot = new int [ N ]; for ( int i = 0 ; i < N ; i ++) tot [ i ] = sc . nextInt (); int [][] dp = new int [ N + 1 ][ N + 1 ]; for ( int i = 0 ; i <= N ; i ++) Arrays . fill ( dp [ i ], - 100000 ); dp [ 0 ][ 0 ] = 0 ; for ( int pos = 0 ; pos < N ; pos ++) for ( int sur = 0 ; sur <= pos ; sur ++) for ( int nSur = 0 ; nSur < 2 ; nSur ++) if ( maxBest [ tot [ pos ]][ nSur ] >= 0 ) dp [ pos + 1 ][ sur + nSur ] = Math . max ( dp [ pos + 1 ][ sur + nSur ], dp [ pos ][ sur ] + ( maxBest [ tot [ pos ]][ nSur ] >= p ? 1 : 0 )); pw . println ( dp [ N ][ S ]); } public static void main ( String [] args ) throws Exception { preprocess (); Scanner sc = new Scanner ( new FileReader ( WORK_DIR + INPUT_FILE_NAME )); PrintWriter pw = new PrintWriter ( new FileWriter ( WORK_DIR + OUTPUT_FILE_NAME )); int caseCnt = sc . nextInt (); for ( int caseNum = 0 ; caseNum < caseCnt ; caseNum ++) { System . out . println ( \"Processing test case \" + ( caseNum + 1 )); pw . print ( \"Case #\" + ( caseNum + 1 ) + \": \" ); new DancingWithGoogle (). solve ( sc , pw ); } pw . flush (); pw . close (); sc . close (); } } Adjust the path and execute it within Eclipse. PHP Input / output: \\ \\(fp = <a href=\"http://php.net/manual/en/function.fopen.php\">fopen</a> (<a href=\"http://php.net/manual/en/reserved.variables.argv.php\">\\) argv[1] , 'r'): Open file pointer to file in first command line argument string fgets (\\$fp): Read one line Execute: php A.php input.txt > output.txt JavaScript Did you know that you can also solve those tasks with JavaScript? I've explained how to install v8 . Here is a solution from aditsu : // run with v8: d8 file.js < file.in var m , res , dot function check ( x0 , y0 , dx , dy ) { var x = 0 var o = 0 var t = 0 for ( var i = 0 ; i < 4 ; ++ i ) { switch ( m [ x0 + i * dx ][ y0 + i * dy ]) { case 'X' : x ++ ; break case 'O' : o ++ ; break case 'T' : t ++ ; break case '.' : dot = 1 ; break } } if ( x + t == 4 ) res = 'X' if ( o + t == 4 ) res = 'O' } var t = readline () for ( var i = 1 ; i <= t ; ++ i ) { m = [] for ( var j = 0 ; j < 4 ; ++ j ) { m [ j ] = readline () } readline () res = null dot = 0 for ( var j = 0 ; j < 4 ; ++ j ) { check ( j , 0 , 0 , 1 ) check ( 0 , j , 1 , 0 ) } check ( 0 , 0 , 1 , 1 ) check ( 3 , 0 , - 1 , 1 ) res = res ? res + ' won' : dot ? 'Game has not completed' : 'Draw' print ( 'Case #' + i + ': ' + res ) }","tags":"Code","title":"Google Code Jam Templates"},{"url":"https://martin-thoma.com/triangle-area/","text":"I've just seen the following image on spikedmath.com: Some geometry questions. Source: spikedmath.com The second answers seem to be obviously the correct ones, right? Wrong. According to Heron's formula you can calculate a triangles area like this: Let \\(a, b, c\\) be the side lengths of the triangle. \\(s := \\frac{a+b+c}{2}\\) \\(T = \\sqrt{s \\cdot (s-a) \\cdot (s-b) \\cdot (s-c)}\\) So the area of the first triangle is \\(s_1 := \\frac{16}{2} = 8\\) \\(T_1 := \\sqrt{8 \\cdot (8-5) \\cdot (8-5) \\cdot (8-6)} = \\sqrt{8 \\cdot 3 \\cdot 3 \\cdot 2} = 3 \\cdot 4 = 12\\) The area of the second one is \\(s_1 := \\frac{18}{2} = 9\\) \\(T_1 := \\sqrt{9 \\cdot (9-5) \\cdot (9-5) \\cdot (9-8)} = \\sqrt{9 \\cdot 4 \\cdot 4 \\cdot 1} = 3 \\cdot 4 = 12\\) Both triangles have the same area! When you draw it, it looks like this: Both triangles in one picture","tags":"My bits and bytes","title":"Triangle area"},{"url":"https://martin-thoma.com/rechnernetze-klausur/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žEinfÃ¼hrung in Rechnernetze\" des Moduls â€žKommunikation und Datenhaltung\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr. Beigl im Sommersemester 2013 gehÃ¶rt. Behandelter Stoff 16.04.2013 Einleitung Kapitel 1 24.04.2013 E-Mail, DNS , dig, nslookup, Peer-to-Peer-Netzwerke, Bootstrapping-Problem, ISO-/OSI-Schichtenmodell, SAPs ; Dienstgeber/-bringer, -funktionalitÃ¤t, -nehmer, -primitiv, -leistung; Request, Indication, Response, Confirm; QoS Kapitel 2 , Folie 18 30.04.2013 SDU , PDU , ISO / OSI-Architektur Kapitel 2 bis wohin? 21.05.2013 CRC , Generatorpolynome, VorwÃ¤rtsfehlerkorrektur, Sequenznummern, Quittung, Stop-and-wait ? 28.05.2013 Protokollmechanismen und Verbindungen: Stop-and-wait; Go-Back-N ARQ , Flusskontrolle (Open Loop, Closed Loop); Kreditbasierte Flusskontrolle Kapitel 4.5 - 4.8 04.06.2013 ? Kapitel 5 12.06.2013 Ãœbungsblatt 2: ARQ : BestÃ¤tigter Dienst (JA), ZuverlÃ¤ssiger Dienst (JA, wenn...); Stop-and-Wait; ? 18.06.2013 Paketvermittlung 7.2.2 25.06.2013 Broadcast-Routing: Dateneinheit wird fÃ¼r jedes System erstellt; Hot-Potato; Potential des Missbrauchs (â†’ The Internet could crash. We need a Plan B. ); Outlaw-detection; Distanz-Vector-Routing; Link-State-Routing 7-44 02.07.2013 IPv4 (Class A/B/C/D/E-Netze); CIDR ; Zuteilung von Adressen ( DHCP ); Subnetze und Subnetz-Maskierung 7-44 Falls hier was fehlt, kÃ¶nnt ihr mich gerne in den Kommentaren oder per Mail (info@martin-thoma.de) darauf aufmerksam machen. Ich bin ja mal gespannt, ob ich das bis zum Ende aktuell halte. Ãœbersicht Ã¼ber Dienstprimitive Name Dienstleistung Grundtypen Parameter Physical (Ph) Connect (Con) Request (Req) AbhÃ¤ngig vom Dienst Data Link (DL) Data (Dat) Indication (Ind) Network (N) Release (Rel) Response (Rsp) Transport (T) Abort (Abo) Confirmation (Cnf) HTTP Provider Abort (PAbo) FTP Disconnect (Dis) ... ... Fragen Welche QualitÃ¤tsparameter sind fÃ¼r Rechnernetze denkbar? Angemessenheit Technische Leistung (Antwortzeit, Datenrate) ZuverlÃ¤ssigkeit Sicherheit Kosten Material Vorlesungswebsite Forum Mein Anki-Deck Ein Video Ã¼ber CRC Der Wikipedia-Artikel Routing beinhaltet viele wichtige Informationen. TCP flags: Hackers Playground RenÃ© Pickhardt und weitere: Web Science MOOC auf der Wikiversity. Aufbau der Klausur HÃ¤ufige Aufgabenstellungen sind: Berechnen einer Subnetzmaske bzw. ob eine IP-Adresse in einem gegebenem Subnetz enthalten ist CRC berechnen / Ã¼berprÃ¼fen ob CRC korrekt ist Distanz-Vektor Algorithmus (Bellman-Ford) durchgehen Protokollablauf durchspielen Ãœbungsbetrieb ÃœbungsblÃ¤tter sind hier . Termine und Klausurablauf Datum : Donnerstag, den 1. August 2013 von 14:00 bis 15:00 Uhr Ort : Seit 28.07.2013 online : Ort von bis Audimax A (30.95, EG) Abdullah Galler Audimax B (30.95, EG) Gassenschmidt LÃ¶ffler HSaF (50.35, EG) Loose Tobias Neue Chemie (30.46, EG) Traub Zumkeller Einsicht : 17.09.2013 Punkte : 30 Bestehensgrenze : 13 Punkte Notenskala : Note von bis BereichsgrÃ¶ÃŸe 1,0 30,00 26,50 3,5 1,3 26,25 25,00 1,25 1,7 24,75 23,50 1,25 2,0 23,25 22,00 1,25 2,3 21,75 20,50 1,25 2,7 20,25 19,00 1,25 3,0 18,75 17,50 1,25 3,3 17,25 16,00 1,25 3,7 15,75 14,50 1,25 4,0 14,25 13,00 1,25 5,0 12,75 00,00 12,75 Ãœbungsschein : Nein Bonuspunkte : Nein Nicht vergessen Studentenausweis Kugelschreiber Ergebnisse Sind nun online . Hier ist die Statistik: Klausurergebnisse Rechnernetze 2013","tags":"German posts","title":"Rechnernetze-Klausur"},{"url":"https://martin-thoma.com/eaz-klausur/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žEinfÃ¼hrung in die Algebra und Zahlentheorie\" (EAZ) am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr. KÃ¼hnlein im Sommersemester 2013 gehÃ¶rt. Behandelter Stoff 16.04.2013 Teilbarkeit; ggT, kgV; Euklidischer Algorithmus Kapitel 1.1 17.04.2013 Primzahlen; Fundamentalsatz der Arithmetik; p-Adische Bewertung Kapitel 1.2 23.04.2013 Verteilung der Primzahlen; Sieb des Erasthostenes; Euler-Produkt; Dichtheitssatz Kapitel 1.3 24.04.2013 Magma, Monoid, Halbgruppe, Gruppe, Erzeugnis $\\langle X \\rangle$ Kapitel 2.2.1 08.05.2013 Gruppenhomomorphismen Kapitel 2.3.1 - 2.3.5 15.05.2013 Faktorgruppen, Homomorphiesatz, Einfachheit, Freie Gruppen Kapitel 2.4 28.05.2013 SylowsÃ¤tze; alternierende Gruppe $A_n$ Kapitel 2.6 29.05.2013 Exkurs: Aufbau des Zahlensystems, Grothendieck-Konstruktion Kapitel 2.7 04.06.2013 Ringe, Ringhomomorphismen, Einheitengruppe, Nullteiler Kapitel 3 05.06.2013 Ideal; Chinesischer Restsatz Kapitel 3 Material Vorlesungswebsite Mein Anki-Deck (digitale Karteikarten) Ãœberblick Ã¼ber mathematische Strukturen StackExchange Das Urbild einer Gruppe unter einem Gruppenhomomorphismus ist eine Gruppe ( Beweis ) Der Stabilisator einer Gruppenoperation ist eine Gruppe ( Beweis ) Der Schnitt von Normalteilern ist wieder ein Normalteiler ( Beweis ) What does \"characteristic\" mean in mathematics? Wie man das Legendre-Symbol einfach berechnet: Pseudocode How many 3-Sylow groups are in a group of order 126? - Durch die Frage (und die Kommentare) habe ich sehr viel gelernt! How can I find decompositions in $\\mathbb{Z}[\\sqrt{d}]$? Why is $A_5$ a simple group? Is the pre-image of a subgroup under a homomorphism a group? Gedanken zu den Klausurhinweisen Eine schÃ¶ne Skriptsammlung Aufbau der Klausur Eine Aufgabe, wo man das Legendre-Symbol ausrechnen muss Eine Aufgabe, wo man mit dem Satz von Lagrange wichtig ist Eine Aufgabe zu Normalteilern / Sylowgruppen Der Kleine Satz von Fermat / Homomorphiesatz Ãœbungsbetrieb Wo sind die ÃœbungsblÃ¤tter: online Abgabeform: handschriftlich Abgabe: Donnerstags, KÃ¤sten in GebÃ¤ude 1C RÃ¼cknahme: in den Tutorien Turnus: wÃ¶chentlich Ãœbungsschein verpflichtend: Nein Bonus durch Ãœbungsschein: Nein Termine und Klausurablauf Datum : 05.09.2013, 11:00 Uhr - 13:00 Uhr Zeit : 2 Stunden Ort : HÃ¶rsaal am Fasanengarten Punkte : 60 Punkte Bestehensgrenze : 22 Punkte Ãœbungsschein : Gibt es (sogar benotet) Bonuspunkte : Nein Nicht vergessen Studentenausweis Kugelschreiber Ergebnisse Seit dem 12.09.2013 drauÃŸen: an den Informationstafeln bei den RÃ¤umen 4A-21.1 und 4B-01","tags":"German posts","title":"E.i.d. Algebra und Zahlentheorie-Klausur"},{"url":"https://martin-thoma.com/datenbanksysteme-klausur/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žDatenbanksysteme\" des Moduls â€žKommunikation und Datenhaltung\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr. BÃ¶hm im Sommersemester 2013 gehÃ¶rt. An diesem Artikel wird natÃ¼rlich noch gearbeitet. Behandelter Stoff 15.04.2013 Warum Datenbanken toll sind ; Transaktionseigenschaften ; Datenschutz; Datensicherheit; Relationsmodell; IntegritÃ¤tsbedingungen; SchlÃ¼ssel; FremdschlÃ¼ssel; SQL; View; Selektion ; Projektion ; Query-Algebra ; Anfrage-Optimierer ; Anfragen sind deklarativ ; 3-Ebenen-Architektur; Trennung zwischen Schema und Instanz, 9 Codd'sche Regeln Kapitel 1 18.04.2013 Datentyp, Instanz, Polymorphes Typsystem, Typkonstruktoren, ... (TODO) Kapitel 2 - Kapitel 3 , Folie 32 22.04.2013 SQL (alter, drop, index, unique); Index; ER-Diagramm; UML; TrÃ¤germenge $\\mu$, Aktueller Zustand einer Variablen $\\sigma$ Kapitel 3 , Folie 32 - Kapitel 4 , Folie 33 29.04.2013 SystemunabhÃ¤ngige Modellierung - Strukturelle Seite; abstrakte Klassen , Metaklassen , Parametrisierte Klassen; Aggregation und Assoziation Kapitel 5 , Folie 1 - Kapitel 6 , Folie 24 06.06.2013 FD , ReflexivitÃ¤t, ProjektivitÃ¤t, Akkumulation, RAP-Regeln, EinfÃ¼geanomalie, LÃ¶schanomalie; AbhÃ¤ngigkeitstreue / Verbundtreue; 1. - 4. Normalform Kapitel 7 13.06.2013 NebenlÃ¤ufigkeitsprobleme: Lost update, dirty read, non-repeatable read; Serielle AusfÃ¼hrung beseitigt Probleme, aber IO/Kommunikation machts ineffizient; History, Prefix Commit-Closed, commited projection; Transaktionen Kapitel 11 24.06.2013 Serialisierbarkeitsgraph; Synthese-Verfahren; BCNF; Histories: RC , ACA , ST ; prefix commit-closed Kapitel 11 27.06.2013 Kapitel 8: Relationale Algebra, BereichskalkÃ¼l; Syntaktisch sicher $\\Rightarrow$ Semantisch sicher; Kapitel 12: Anwendungsprogrammierung Kapitel 8 , 12 Falls hier was fehlt, kÃ¶nnt ihr mich gerne in den Kommentaren oder per Mail (info@martin-thoma.de) darauf aufmerksam machen. Ich bin ja mal gespannt, ob ich das bis zum Ende aktuell halte. SQL create view MG as select Mitarbeiter , Gehalt from MGA where Gehalt > 70 insert into MG values ( 'Alice' , 90 ) Fragen Was ist der Unterschied zwischen einem DBS und einem DBMS? Ein DBMS ist eine Software zur Datenverwaltung. Die eigentlichen Daten sind in der Datenbank. Ein DBS ist eine DBMS und eine Datenbank. Ein DBMS kann mehrere Datenbanken verwalten. Sei $H = r_1[y] w_1[x] r_3[x] w_1[z] r_2[z] w_3[y] r_2[x] w_2[y] c1 r_3[y] c_3 w_2[z] c_2$. Welche Transaktionen sind in dieser History? Ein Eintrag $r_i[x]$ bedeutet, dass die Transaktion $i$ die Ressource $x$ liest. Ein Eintrag $w_i[x]$ bedeutet, dass die Transaktion $i$ die Ressource $x$ schreibt. $c_i$ bedeutet, dass die $i$-te Transaktion commitet wird Es gibt also die Transaktion $T_1, T_2 \\text{ und } T_3$ mit $T_1 = r_1[y] w_1[x] c_1$ Material Folien Vorlesungswebsite Mein Anki-Deck (digitale Karteikarten) Mitschrieb-Wiki In der Fachschaft gibt es folgende Altklausuren: 25. Februar 2011 30. Juli 2010 (DB + Rechnernetze, mit LÃ¶sung) Aufbau der Klausur HÃ¤ufige Aufgabenstellungen sind: Histories und Transaktionen: Ist eine gegebene History RC, ACA, Strict? Modellierung SQL-Abfragen formulieren In der Klausur vom SS 2013 wurde das in 4 Aufgaben Ã  15 Punkte aufgeteilt. Unter anderem war diesmal der RAP-Algorithmus und der Dekompositionsalgorithmus relevant. Ãœbungsbetrieb Es gibt nur ein \"Ãœbungsblatt\" mit Bonuspunkten fÃ¼r die Klausur. Auf dieses beziehe ich mich. Wo sind die ÃœbungsblÃ¤tter: Portal - Aufgaben Abgabeform: Online Abgabe: 07.07.2013 RÃ¼cknahme: ? Turnus: Einmalig Ãœbungsschein verpflichtend: Nein Bonus durch Ãœbungsschein: Ja Ein paar interessante Informationen zum Blatt: Was ist mit \"Brute-Force-AnsÃ¤tze\" in der Aufgabenstellung gemeint? Antwort von Herrn Keller: Bei Anfragen, die nur eine Anzahl in der Projektionsliste erwarten, kÃ¶nnen sie mit einer Query SELECT FROM das korrekte Ergebnistupel durch ausprobieren herausbekommen. Im Portal wird das zunÃ¤chst als \"korrekt\" bewertet, allerdings werden wir das im Nachhinein filtern. Wie kann man bei der ORACLE-Datenbank die Anzahl der ausgegebenen Zeilen beschrÃ¤nken (LIMIT)? \u0002wzxhzdk:2\u0003 Ein bisschen was zu JOIN sollte man sich durchlesen. Ich habe Ã¼brigens das folgende Captcha bekomme: Datenbanksysteme - Captcha Wie zur HÃ¶lle soll man das lÃ¶sen? Ich hatte auf â€ž448444\" getippt, aber das war falsch. Termine und Klausurablauf Datum : Mittwoch, den 31. Juli 2013 von 11:00 bis 13:00 Uhr Ort : seit 29.07.2013 online: Wer Wo Nachnamen A-G Gerthsen HÃ¶rsaal Nachnamen H-J Nusselt HÃ¶rsaal Nachnamen K-L HÃ¶rsaal Neue Chemie Nachnamen M-R Daimler HÃ¶rsaal Nachnamen S Gaede HÃ¶rsaal Nachnamen T-Z Benz HÃ¶rsaal Punkte : 60 Bestehensgrenze : ? Ãœbungsschein : ? Bonuspunkte : ? Nicht vergessen Studentenausweis Kugelschreiber Ergebnisse Sind noch nicht drauÃŸen (Stand: 20.04.2013)","tags":"German posts","title":"Datenbanksysteme-Klausur"},{"url":"https://martin-thoma.com/kogsys-klausur/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žKognitive Systeme\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Dr. Waibel im Sommersemester 2013 gehÃ¶rt. Behandelter Stoff Vorlesung 15.04.2013 Kapitel 1 EinfÃ¼hrung 17.04.2013 Faltung, Fouriertransformation, Dirac-Funktion 29.04.2013 Klassifikation I Schablonenanpassung: Probleme , Statistische Auswertung immer wichtig da Signale ambig sind, Assoziative Netze, Bayes Decision Theorie, Gaussian Classificator - \"Covarianzmatrix tut das Richtige [und eliminiert von einander AbhÃ¤ngige Dimensionen]\", Mahalanobis-Distanz; Gauss-Klassifikator ist quadratischer Form (Kreis, Ellipse, Linie), Overfitting = \"Vorurteil\" passiert, wenn man zu wenig Daten bzw. zu viele Dimensionen dafÃ¼r hat - \"Fluch der DimensionalitÃ¤t\"; Hauptachsentransformation reduziert DimensionalitÃ¤t 06.05.2013 Machine Lerning Klassifikation: Risikobetrachtung bei Klassifikatoren, Gaussian Mixtures, Parzan Windows (nicht-parametrisiert, Ã¼berwacht), Fisher Linear Discriminant (scatter matrix), Linear seperable, K-nearest neighbors (nicht-parametrisch, nicht-linear, Ã¼berwacht) 13.05.2013 Neural Nets Perceptron Criterion Function; MLP 27.05.2013 Bildverarbeitung I Lochkartenmodell, HSI-Farbmodell, RGB2HSI, RGB2Graustufen, Histogrammspreizung 29.05.2013 Bildverarbeitung II Pixel-Transformation, Bildverarbeitung, Merkmalsextraktion, Form, Struktur, Klassifikation 03.06.2013 (Nicht verfÃ¼gbar) 2D-Bildverarbeitung: Schwellwert, Graustufen, Segmentierung, Kanten-/Knotenerkennung; Hough-Tranformation; Harris-Corner-Detector; Kalman-Filter ; Erosion / Dilatation; Ã–ffnen / SchlieÃŸen 10.06.2013 (Nicht verfÃ¼gbar) Spracherkennung: Lautbildung, Vokale werden durch 1., 2. Formante bestimmt 24.06.2013 (Nicht verfÃ¼gbar) 3D-Bildverarbeitung: Kalman-Filter ; Partikelfilter; homogene Koordinaten Falls hier was fehlt, kÃ¶nnt ihr mich gerne in den Kommentaren oder per Mail (info@martin-thoma.de) darauf aufmerksam machen. Folien 01: EinfÃ¼hrung Nichts interessantes. 02, 03: Digital Signal Processing Alias-Effekt , Abtasttheorem Digitalisierung: Zeit- und Wertdiskretisierung Dirac-Funktion Faltung Fouriertransformation Korrelation: Autokorrelation, Kreuzkorrelation 04: Intelligente und Kognitive Systeme Interessant, aber vermutlich nicht Klausurrelevant. 05, 06: Klassifikation Schablonenanpassung: Wie Ã¤hnlich ist das Muster einer Schablone? Normalisierung der Helligkeit Gauss-Klassifikation: Parametrisch Parzen Window: Nicht parametrisch k-nearest-neighbor: nicht parametrisch Perceptron: nicht parametrisch Bayes-Regel Principal Component Analysis (PCA) Linear Discriminant Function, Fisher-Linear Discriminant 07, 08: Machine Learning Pattern recognition classification Image Source: Folien von Prof. Waibel Perceptron<: Sigmoidfunktion /li> Classifier Discriminant Functions Linear Discriminant Functions 09: Bildverarbeitung I BildreprÃ¤sentation als Monochrombild RGB / HSI-Modell Bayer-Pattern Lochkamera-Modell Affine Punktoperatoren: $g := round(a \\cdot I(u,v) + b) I'(u,v) := \\begin{cases} 0 &\\text{, falls } g < 0\\\\ q &\\text{, falls } g > q\\\\ g &\\text{sonst} \\end{cases}$ KontrasterhÃ¶hung: $b=0; a > 1$ Kontrastverminderung: $b=0; a < 1$ HelligkeitserhÃ¶hung: $b>0; a = 1$ Helligkeitsverminderung: $b<0; a = 1$ Invertierung: $b=q; a =-1$ Nicht-Affine Punktoperatoren Automatische Kontrastanpassung (Spreizung, Histogrammdehnung, Histogrammausgleich) 10: Bildverarbeitung II Fourier-Transformation 2D Fourier-Transformation Fourier-RÃ¼cktransformation Ortsbereich / Frequenzbereich Tiefpassfilter Mittelwertfilter: RauschunterdrÃ¼ckung GauÃŸ-Filter : RauschunterdrÃ¼ckung, GlÃ¤ttung Hochpassfilter Prewitt Sobel Laplace Roberts KOmbinierte Operatoren Laplacian of Gaussian Canny-Kantendetektor 11: Bildverarbeitung III Segmentierung (Schwelltwert, Farbe) Morphologische Operatoren: Dilatation, Erosion Ã–ffnen, SchlieÃŸen Hough-Transformation Sum of Squared Differences; Zero Mean Normalized Cross-Correlation Partikelfilter 12: Spracherkennung Faltung Formanten Spektogramm Akustisches Modell, Sprachmodell (Hidden-)Markov-Modell Forward-, Forward-Backward- und Viterbi-Algorithmus 13: ? 14: ? 15: Bildverarbeitung IV Geometrische 3D-Transformationen: Rotation um Achsen Quaternionen Erweitertes Lochkameramodell Kamerakalibrierung Diskrete Lineare Transformation Stereorekonstruktion Epipolargeometrie Fundamentalmatrix 16: Visuelle Wahrnehmung Vermutlich nichts Klausurrelevantes (offiziell ab Folie 25) 17: Wissen und Planung I Satz, Wissensdatenbank, Deduktion Symbolmenge, Modellmenge, Syntax, Semantik Korrektheit und vollstÃ¤ndigkeit eines Deduktions-Algorithmus Algorithmen: Resolution, Horn-Klauseln, DPLL Planungssprachen: STRIPS , ADL A*-Suche, Partial-Order-Planning, Planungsgraphen 18: Wissen und Planung II Partial-Order-Planning Planungsgraphen Kantenmodell, OberflÃ¤chenmodell, Volumenmodell Freiraum, Hindernisraum, Konfigurationsraum Polygonzerlegung Sichtgraphen Quadtrees Voronoi-Diagramme Potentialfeldmethode 19: Robotik Offiziell nicht Klausurrelevant. Material Vorlesungswebsite Mein Anki-Deck Klausuren Folien Skript Zusammenfassung Videos Neural network tutorial: The back-propagation algorithm The backpropagation algorithm Pseudocode fÃ¼r DPLL-Verfahren Resolutions-Algorithmus Colorizer : Hier kann man ein bisschen mit FarbrÃ¤umen rumspielen und die Unterschiede interaktiv feststellen. StackOverflow: Why is $(-1) \\cdot j = j \\cdot (-1)$ for quaternions? Artikel: Graphic filters : Mit einem interaktiven Beispiel aller Filter! Clustering-Algorithmen : Mit interaktivem Beispiel Calculations with quaternions How do I calculate a histogram equalization? How to apply the Viterbi algorithm Interactive example for route planning Word Error Rate (WER) calculation Grafische Faltung: John Hopkins University , Java Applet onmyphd.com , JavaScript Das Passwort fÃ¼r kogsys darf ich auch im Jahr 2013 nicht verraten. Aufbau der Klausur 6 Aufgaben: Bildverarbeitung Bildverarbeitung, Filter und Transformation Logik, WissensreprÃ¤sentation und Planung Eine Aufgabe, in der man den Resolutionsalgorithmus / das DPLL-Verfahren anwenden muss A*-Algorithmus Allgemeine Fragen Signal- und Sprachverarbeitung Klassifikation und Maschinelles Lernen Ãœbungsbetrieb Wo sind die ÃœbungsblÃ¤tter: Link Abgabeform: nur Handschriftlich Abgabe: teilweise online, teilweise offline, wenn offline mÃ¼ssen die ÃœbungsblÃ¤tter direkt vor der Ãœbung abgegeben werden, oder irgendwann davor im BÃ¼ro des Ãœbungsleiters in der Kinderklinik. Direkt im BÃ¼ro scheint ihm aber nicht so lieb zu sein. RÃ¼cknahme: gar nicht, empfohlen wird eine Kopie des Originals zu behalten Turnus: ? (6 BlÃ¤tter insgesammt) Ãœbungsschein verpflichtend: es gibt keinen Ãœbungsschein soweit ich weiÃŸ Bonus durch Ãœbungsschein: pro Ãœbungsblatt max. 1 Bonuspunkt â†’ max. 6 Bonuspunkte (es gibt tatsÃ¤chlich 0,25-Punkte!) Termine und Klausurablauf Datum : Mittwoch, den 18. September 2013 von 11:00 bis 12:00 Uhr Ort : steht noch nicht fest (Stand: 12.09.2013) Punkte : 60 Bestehensgrenze : 20 Ãœbungsschein : Gibt es nicht Bonuspunkte : Ja, max 6 Ergebnisse : ab 14.10.2013 im Websubmit und in 50.20. (Kinderklinik) am Eingang Einsicht : 24.10.2013 von 13:30 bis 14:30 Uhr (Kinderklinik, Raum 148) Nicht vergessen Studentenausweis Kugelschreiber Ergebnisse Sind noch nicht drauÃŸen (Stand: 18.09.2013)","tags":"German posts","title":"KogSys-Klausur"},{"url":"https://martin-thoma.com/numerik-klausur/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žNumerische Mathematik fÃ¼r die Fachrichtungen Informatik und Ingenieurwesen\" des Moduls â€žPraktische Mathematik\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Dr. WeiÃŸ im Sommersemester 2013 gehÃ¶rt. Behandelter Stoff Vorlesung : 17.04.2013 Kapitel 1.1 Wiederholung LGS, GauÃŸ'sches Eliminationsverfahren , LR-Zerlegung , Frobeniusmatrix 24.04.2013 01.05.2013 08.05.2013 15.05.2013 Kapitel 1.4 VorwÃ¤rts- und RÃ¼ckwÃ¤rtsanalyse 22.05.2013 Kapitel 1.7 Lineare Ausgleichsprobleme; QR-Zerlegung 29.05.2013 Kapitel 1.7 -2.1 Fixpunktiteration 05.06.2013 Kapitel 2 Banachscher Fixpunktsatz; Newton-Verfahren; Vereinfachtes Newton-Verfahren 12.06.2013 Kapitel 3 - 3.1.2 Interpolation von Funktionen mittels Polynomen (â†’ Artikel ); Monomdarstellung; Lagrange-Polynome; Newton-Polynome; Dividierende Differenzen 26.06.2013 Kapitel 3.2 - S. 54, unten Kubische Spline-Interpolation â†’ Visualisierung Skript Kapitel 1: Wann ist ein LGS eindeutig lÃ¶sbar? Wann gibt es unendlich viele LÃ¶sungen? GauÃŸsches Eliminationsverfahren Was versteht man unter VorwÃ¤rts / RÃ¼ckwÃ¤rtssubstitution? Beim GauÃŸ'schen Eliminationsverfahren mit Spaltenpivotwahl tauscht man eine Zeile nach oben. Ist es das betragsmÃ¤ÃŸig grÃ¶ÃŸte oder kleinste? Warum? Was ist eine Permutationsmatrix? Was eine Frobeniusmatrix? LR-Zerlegung Was ist eine unipotente Dreiecksmatrix? Was ist eine obere Dreiecksmatrix, was eine untere? Was ist StellenauslÃ¶schung? Nenne ein Beispiel! ÃœbungsblÃ¤tter Die AufgabenblÃ¤tter stehen hier . # Stoff 1 LR-Zerlegung, Normen 2 Konditionszahl einer Matrix, StellenauslÃ¶schung, relativer Fehler 3 - 4 LR-Zerlegung, GauÃŸ-Elimination mit Spaltenpivotwahl 5 Cholesky-Zerlegung 6 Nichtlineare Gleichungssysteme, Newton-Verfahren 7 Fixpunktiteration, Polynomauswertung, Interpolation 8 Tschebyscheff-Polynom, Interpolation 9 Splines 10 Bernstein-Polynom, Bezier-Kurven 11 Quadraturformeln Material Vorlesungswebsite Mein Anki-Deck (nur 12 Karten) Polynom- und Spline-Interpolation : Ein interaktives Beispiel schickling.github.io : Viele Implementierungen Pseudocode Cholesky-Zerlegung , siehe Artikel StackExchange: How do the different ancillary conditions for splines differ? Aufbau der Klausur Aufgabe 1: LR-Zerlegung oder Cholesky-Zerlegung; GauÃŸ-Elimination mit Spaltenpivotwahl; LÃ¶sen eines LGS Aufgabe 2: Nicht-lineare Gleichungssysteme, Fixpunktiteration, Newton-Verfahren Aufgabe 3: a) Polynominterpolation mit Lagrange-Polynomen b) Newton-Darstellung des Polynoms bestimmen Aufgabe 4: Quadraturformel herleiten und Integral nÃ¤herungsweise berechnen Aufgabe 5: Ordnungsbedingungen, SÃ¤tze 27 - 31 Ãœbungsbetrieb Wo sind die ÃœbungsblÃ¤tter: Link Abgabeform: nur Handschriftlich Abgabe: Mittwochs, in der Vorlesung RÃ¼cknahme: Freitags, in der Ãœbung Turnus: wÃ¶chentlich Ãœbungsschein verpflichtend: Ja Bonus durch Ãœbungsschein: Nein Termine und Klausurablauf Datum : Dienstag, den 24. September 2013 von 11:00 bis 13:00 Uhr Ort : steht seit dem 11.09.2013 fest: Klausureinteilung entsprechend des Anfangsbuchstabens des Nachnamens: Benz-HÃ¶rsaal (10.21) A-C Daimler-HÃ¶rsaal (10.21) D-G und I Neue Chem. (30.46) J-L Gerthsen-HÃ¶rsaal (30.21) H und M-R HS. a. F. (50.35) S-Z Punkte : ? Bestehensgrenze : ? Ãœbungsschein : Verpflichtend (ist inzwischen auch eingetragen) Bonuspunkte : Gibt es nicht Einsicht : Termin noch nicht bekannt (Stand: 22.09.2013) Nicht vergessen Studentenausweis Kugelschreiber Ergebnisse Sind noch nicht drauÃŸen (Stand: 22.09.2013)","tags":"German posts","title":"Numerik-Klausur"},{"url":"https://martin-thoma.com/what-does-usrbinpython-mean/","text":"You've probably already seen one of the following lines: #!/bin/sh #!/usr/bin/python #!/usr/bin/python3 #!/usr/bin/env python #!/usr/bin/perl #!/usr/bin/php #!/usr/bin/ruby This is a shebang . It's a directive for your command line interpreter how it should execute a script. For example, you have a file with this content: #!/usr/bin/python3 # -*- coding: utf-8 -*- import sys print ( sys . version_info ) Now you can execute it via python3 yourFile.py . But alternatively, you can make it executable and simply type ./yourFile.py By the way, you should use #!/usr/bin/env python for some reasons .","tags":"Code","title":"What does #!/usr/bin/python mean?"},{"url":"https://martin-thoma.com/colors-in-vim/","text":"ANSI Color codes 0 1 2 3 4 5 6 7 256 colors You might need to set t_Co=256 . x016_Grey0 x017_NavyBlue x018_DarkBlue x019_Blue3 x020_Blue3 x021_Blue1 x022_DarkGreen x023_DeepSkyBlue4 x024_DeepSkyBlue4 x025_DeepSkyBlue4 x026_DodgerBlue3 x027_DodgerBlue2 x028_Green4 x029_SpringGreen4 x030_Turquoise4 x031_DeepSkyBlue3 x032_DeepSkyBlue3 x033_DodgerBlue1 x034_Green3 x035_SpringGreen3 x036_DarkCyan x037_LightSeaGreen x038_DeepSkyBlue2 x039_DeepSkyBlue1 x040_Green3 x041_SpringGreen3 x042_SpringGreen2 x043_Cyan3 x044_DarkTurquoise x045_Turquoise2 x046_Green1 x047_SpringGreen2 x048_SpringGreen1 x049_MediumSpringGreen x050_Cyan2 x051_Cyan1 x052_DarkRed x053_DeepPink4 x054_Purple4 x055_Purple4 x056_Purple3 x057_BlueViolet x058_Orange4 x059_Grey37 x060_MediumPurple4 x061_SlateBlue3 x062_SlateBlue3 x063_RoyalBlue1 x064_Chartreuse4 x065_DarkSeaGreen4 x066_PaleTurquoise4 x067_SteelBlue x068_SteelBlue3 x069_CornflowerBlue x070_Chartreuse3 x071_DarkSeaGreen4 x072_CadetBlue x073_CadetBlue x074_SkyBlue3 x075_SteelBlue1 x076_Chartreuse3 x077_PaleGreen3 x078_SeaGreen3 x079_Aquamarine3 x080_MediumTurquoise x081_SteelBlue1 x082_Chartreuse2 x083_SeaGreen2 x084_SeaGreen1 x085_SeaGreen1 x086_Aquamarine1 x087_DarkSlateGray2 x088_DarkRed x089_DeepPink4 x090_DarkMagenta x091_DarkMagenta x092_DarkViolet x093_Purple x094_Orange4 x095_LightPink4 x096_Plum4 x097_MediumPurple3 x098_MediumPurple3 x099_SlateBlue1 x100_Yellow4 x101_Wheat4 x102_Grey53 x103_LightSlateGrey x104_MediumPurple x105_LightSlateBlue x106_Yellow4 x107_DarkOliveGreen3 x108_DarkSeaGreen x109_LightSkyBlue3 x110_LightSkyBlue3 x111_SkyBlue2 x112_Chartreuse2 x113_DarkOliveGreen3 x114_PaleGreen3 x115_DarkSeaGreen3 x116_DarkSlateGray3 x117_SkyBlue1 x118_Chartreuse1 x119_LightGreen x120_LightGreen x121_PaleGreen1 x122_Aquamarine1 x123_DarkSlateGray1 x124_Red3 x125_DeepPink4 x126_MediumVioletRed x127_Magenta3 x128_DarkViolet x129_Purple x130_DarkOrange3 x131_IndianRed x132_HotPink3 x133_MediumOrchid3 x134_MediumOrchid x135_MediumPurple2 x136_DarkGoldenrod x137_LightSalmon3 x138_RosyBrown x139_Grey63 x140_MediumPurple2 x141_MediumPurple1 x142_Gold3 x143_DarkKhaki x144_NavajoWhite3 x145_Grey69 x146_LightSteelBlue3 x147_LightSteelBlue x148_Yellow3 x149_DarkOliveGreen3 x150_DarkSeaGreen3 x151_DarkSeaGreen2 x152_LightCyan3 x153_LightSkyBlue1 x154_GreenYellow x155_DarkOliveGreen2 x156_PaleGreen1 x157_DarkSeaGreen2 x158_DarkSeaGreen1 x159_PaleTurquoise1 x160_Red3 x161_DeepPink3 x162_DeepPink3 x163_Magenta3 x164_Magenta3 x165_Magenta2 x166_DarkOrange3 x167_IndianRed x168_HotPink3 x169_HotPink2 x170_Orchid x171_MediumOrchid1 x172_Orange3 x173_LightSalmon3 x174_LightPink3 x175_Pink3 x176_Plum3 x177_Violet x178_Gold3 x179_LightGoldenrod3 x180_Tan x181_MistyRose3 x182_Thistle3 x183_Plum2 x184_Yellow3 x185_Khaki3 x186_LightGoldenrod2 x187_LightYellow3 x188_Grey84 x189_LightSteelBlue1 x190_Yellow2 x191_DarkOliveGreen1 x192_DarkOliveGreen1 x193_DarkSeaGreen1 x194_Honeydew2 x195_LightCyan1 x196_Red1 x197_DeepPink2 x198_DeepPink1 x199_DeepPink1 x200_Magenta2 x201_Magenta1 x202_OrangeRed1 x203_IndianRed1 x204_IndianRed1 x205_HotPink x206_HotPink x207_MediumOrchid1 x208_DarkOrange x209_Salmon1 x210_LightCoral x211_PaleVioletRed1 x212_Orchid2 x213_Orchid1 x214_Orange1 x215_SandyBrown x216_LightSalmon1 x217_LightPink1 x218_Pink1 x219_Plum1 x220_Gold1 x221_LightGoldenrod2 x222_LightGoldenrod2 x223_NavajoWhite1 x224_MistyRose1 x225_Thistle1 x226_Yellow1 x227_LightGoldenrod1 x228_Khaki1 x229_Wheat1 x230_Cornsilk1 x231_Grey100 x232_Grey3 x233_Grey7 x234_Grey11 x235_Grey15 x236_Grey19 x237_Grey23 x238_Grey27 x239_Grey30 x240_Grey35 x241_Grey39 x242_Grey42 x243_Grey46 x244_Grey50 x245_Grey54 x246_Grey58 x247_Grey62 x248_Grey66 x249_Grey70 x250_Grey74 x251_Grey78 x252_Grey82 x253_Grey85 x254_Grey89 x255_Grey93 Colorize Vim You can highlight your current line by adding the following line to your .vimrc : hi CursorLine cterm=NONE ctermbg=187 The following line will use color 0 (black) for the text color of the line numbers and color 187 (see above) for the background. highlight LineNr ctermfg=0 ctermbg=187","tags":"Code","title":"Colors in Vim"},{"url":"https://martin-thoma.com/kv-diagramme/","text":"Ich setze im Folgenden vorraus, dass man schon mal was von KV-Diagrammen gehÃ¶rt hat und vielleicht schon ein paar gezeichnet hat. Insbesondere erklÃ¤re ich nicht wie man aus dem KV-Diagramm der GrÃ¶ÃŸe 16 eines der GrÃ¶ÃŸe 32 bekomt und was die Beschriftung bedeutet. KV-Diagramme sind fÃ¼r die TI-Klausur am KIT bei Herrn Prof. Dr. Asfour sehr wichtig. Im folgenden sind die wichtigsten Eigenschaften, die so explizit leider nicht in der Vorlesung genannt wurden. Konstruktion aus Schaltfunktion Gegeben sei folgende vollstÃ¤ndig definierte Schaltfunktion: \\(f(w,x,y,z) := (w \\lor \\bar y) (\\bar w \\lor x \\lor y) (\\bar w \\lor \\bar x \\lor z)\\) Nun kann man eine Funktionstabelle aufstellen: Dabei schreibt man sich erst das GerÃ¼st hin, also eine Titelzeile mit den vier Variablen \\(w,x,y,z\\) und \\(2&#94;4 = 16\\) Zeilen fÃ¼r die verschiedenen Funktionswerte. Wir brauchen jeweils eine Spalte fÃ¼r die vier Variablen, eine fÃ¼r den Funktionswert \\(f(w,x,y,z)\\) und am besten noch eine mit der Nummer. Nun zÃ¤hlen wir fÃ¼r die vier Variablen binÃ¤r hoch. Dabei einsprechen die konkatenierten Ziffern der Variablen der Spalte â€žNummer\". Ich fine es am einfachsten, dies Spaltenweise zu schreiben. Also 8 Nullen, 8 Einsen fÃ¼r \\(w\\) . Dann 4 Nullen, 4 Einsen, 4 Nullen, 4 Einsen fÃ¼r \\(x\\) usw. Als letztes schauen wir uns die drei geklammerten Terme von oben an und schauen, wann diese jeweils Null sind. In die entsprechenden Zeilen der Tabelle tragen wir eine Null ein. In alle Ãœbrigen kommt eine Eins. Nr $w$ $x$ $y$ $z$ $f(w,x,y,z)$ 0 0 0 0 0 1 1 0 0 0 1 1 2 0 0 1 0 0 3 0 0 1 1 0 4 0 1 0 0 1 5 0 1 0 1 1 6 0 1 1 0 0 7 0 1 1 1 0 8 1 0 0 0 0 9 1 0 0 1 0 10 1 0 1 0 1 11 1 0 1 1 1 12 1 1 0 0 0 13 1 1 0 1 1 14 1 1 1 0 0 15 1 1 1 1 1 Will man diese Tabelle in ein KV-Diagramm Ã¼bernehmen, muss man nur die Spalte \\(f(w,x,y,z)\\) in der richtigen Reihenfolge in die Tabelle fÃ¼llen. Das macht man, indem man immer bei einem Eckpunkt beginnt und dann eine Z-Form durchgeht: KV-Speed-Zeichnen Am Ende sieht es so aus: Prim- und Kernprimimplikaten Sei \\(g(w,x,y,z)\\) eine Schaltfunktion. \\(g\\) ist ein Implikant von \\(f:\\Leftrightarrow \\forall_{(w,x,y,z) \\in \\{0,1\\}&#94;4}: g(w,x,y,z) \\Rightarrow f(w,x,y,z)\\) . Ist \\(g\\) ist ein Implikant von \\(f\\) , so ist \\(f\\) ein Implikat von \\(g\\) . Das kann man nun sehr schÃ¶n mit dem KV-Diagramm verknÃ¼pfen. Wenn man die beiden Funktionen \\(f\\) und \\(g\\) in das KV-Diagramm einzeichnet, muss \\(f\\) Ã¼berall dort eine 1 haben, wo \\(g\\) eine 1 hat. Was hat es nun mit Primimplikanten auf sich? Wenn man diese KÃ¤stchen um 1-BlÃ¶cke macht, dann mÃ¼ssen sie jeweils insgesamt genau \\(2&#94;k, k \\in \\mathbb{N}_0\\) Einsen umfassen und dÃ¼rfen an den RÃ¤ndern fortgesetz werden (siehe der grÃ¼ne um 5 und 13). Wenn so ein Block ein Primimplikant ist, darf es keinen grÃ¶ÃŸeren Eins-Block geben. Beispiel: KV-Diagramm - Beispiel mit Primimplikanten Das Rosa-KÃ¤stchen ist ein Implikant. Es ist jedoch kein Primimplikant, da das blaue KÃ¤stchen grÃ¶ÃŸer ist. Bis auf das rosa KÃ¤stchen und das braune KÃ¤stchen sind alle eingezeichenten KÃ¤stchen Primimplikanten sein. Es gibt keine weiteren Primimplikanten in dieser Funktion. Nun ist ein Primimplikant ein Kernprimimplikant, wenn er eine 1 Ã¼berdeckt, die von keinem anderen Primimplikanten Ã¼berdeckt wird. Das gilt fÃ¼r alle Primimplikanten auÃŸer den hellgrÃ¼nen und den braunen KÃ¤stchen. Nochmals fÃ¼r das Beispiel: Primimplikanten sind: (0,1,5,4) // ganz oben, ist auch Kernprimimplikant (10,11) // 3. Zeile, ist auch Kernprimimplikant (11,15) // 3. Zeile, ist kein Kernprimimplikant (15,13) // 3. Spalte, ist kein Kernprimimplikant (13,5) // 3. Spalte, ist kein Kernprimimplikant Primimplikate sind: (2,3,7,6) // 2. Zeile, ist auch Kernprimimplikat (6,14) // 4. Spalte, ist kein Kernprimimplikat (14,12) //4. Spalte, ist kein Kernprimimplikat (8,9) // 4. Zeile, ist auch Kernprimimplikat (8, 12) // 4. Zeile, ist kein Kernprimimplikat Hasards Wie sieht man einen Hasard im KV-Diagramm? Man sucht sich eine Anfangsbelegung und eine Endbelegung. Wenn sich dazwischen \\(n\\) Variablen Ã¤ndern, gibt es \\(n!\\) Pfade im KV-Diagram. Ist einer dieser Pfade nicht monoton, so ist dieser Ãœbergang Hasardbehaftet. Nun kann man sich entweder die Funktion selbst im KV-Diagramm anschauen, oder die einzelnen Variablen mit dem Todzeitmodell aufsplitten. Untersucht man ersteres, kann man Funktionshasards finden, bei letzterem Strukturhasards. Nun kann man jeden Hasard noch aufteilen, je nach dem was der Wert der Funktion mit der Anfangsbelegung A bzw. der Wert der Funktion bei der Endbelegung B ist: \\(f(A) = 0 \\land f(B) = 0 \\Rightarrow\\) Statischer 0-Hasard \\(f(A) = 0 \\land f(B) = 1 \\Rightarrow\\) Dynamischer 01-Hasard \\(f(A) = 1 \\land f(B) = 0 \\Rightarrow\\) Dynamischer 10-Hasard \\(f(A) = 1 \\land f(B) = 1 \\Rightarrow\\) Statischer 1-Hasard Beispiel Hier ist ein Beispiel fÃ¼r einen dynamischen 1-0-Hasard: Beispiel eines dynamischen 1-0-Hasards Fallstricke Bei dem Suchen nach Eins- oder NullblÃ¶cken darf man an den Spiegelachsen springen: KV Diagramm: Fallstrick 1 Quelle: Klausur vom SS 2010 (KIT) KV Diagramm: Fallstrick 2 Quelle: Klausur vom SS 2010 (KIT)","tags":"German posts","title":"KV-Diagramme"},{"url":"https://martin-thoma.com/what-does-volatile-mean/","text":"You might have read the variable modifier volatile in C, C++ or in Java. But do you know what it means? C Programming Language The C Programming language by Kerninghan and Ritchie (second edition) contains this keyword only 13 times. Here are the most important ones: [...] declaring it volatile announces that it has special properties relevant to optimization. Neither qualifier affects the range of values or arithmetic properties of the object. Qualifiers are discussed in Par.A.8.2. Page 158 The purpose of volatile is to force an implementation to suppress optimization that could otherwise occur. For example, for a machine with memory-mapped input/output, a pointer to a device register might be declared as a pointer to volatile, in order to prevent the compiler from removing apparently redundant references through the pointer. Except that it should diagnose explicit attempts to change const objects, a compiler may ignore these qualifiers. Page 172 Java Java Language Specification actually covers this quite good: The Java programming language allows threads to access shared variables (Â§17.1). As a rule, to ensure that shared variables are consistently and reliably updated, a thread should ensure that it has exclusive use of such variables by obtaining a lock that, conventionally, enforces mutual exclusion for those shared variables. The Java programming language provides a second mechanism, volatile fields, that is more convenient than locking for some purposes. A field may be declared volatile, in which case the Java Memory Model ensures that all threads see a consistent value for the variable (Â§17.4). Ok, so in Java it is important for multithreading. The example 8.3.1.4-1 of the JLS 7.0 is also very interesting. A write to a volatile field (Â§8.3.1.4) happens-before every subsequent read of that field. For the purposes of the Java programming language memory model, a single write to a non-volatile long or double value is treated as two separate writes: one to each 32-bit half. This can result in a situation where a thread sees the first 32 bits of a 64-bit value from one write, and the second 32 bits from another write. Writes and reads of volatile long and double values are always atomic. When do you need it volatile? I'm not sure if it is correct what I write here. It makes sense, but please leave a note in comments when I'm wrong. Thermometer Imagine you want to build your own thermometer. So you have to access hardware. Now you only want to print the temperature periodically. Something like this: #include <stdio.h> #include <unistd.h> int getTemperature () { // accessing the hardware device register happens here return 42 ; } int main () { for ( int i = 0 ; i < 60 ; i ++ ) { int temperature = getTemperature (); printf ( \"Temperature: %i &deg;C \\n \" , temperature ); sleep ( 2 ); } return 0 ; } Now, as you always access the same register and you don't change it, the CPU could cache the result. That would be bad, because another source (the hardware) changes the value. So you don't want to cache it. This is - if I understand it correctly - what volatile is good for. It makes sure that you really access memory and not some registers, because it got optimized or cached. I / O Imagine you write an application that want to transfer data from a disk to another disk. You might have one producer and one consumer. The producer tries to get data from the disk. Lets say the disk has a buffer and a register that indicates how many blocks are in the buffer. So your producer might poll at some point: int register = 0; while(register == 0); Now the register can get changed by the device, but it seems to be an obvious that you can optimize this to while(TRUE); Now, with this \"optimization\" that the compiler might make, you will never notice when you can read from the disk. So you would mark register as volatile to tell the compiler that he should not optimize it. Do you know some better examples? Perhaps short C examples with real code where you can actually see the difference? Further reading When exactly do you use the volatile keyword in Java? Different meaning in Java and C#","tags":"Code","title":"What does volatile mean?"},{"url":"https://martin-thoma.com/c-puzzle-3/","text":"What is the output of the following programm? #include <stdio.h> int main () { printf ( \"%i \\n \" , - 13 >> 1 ); } . . . . . . . . . . . . . . . . . . . Short answer -7 Long answer Signed integers are two's complement binary values that can be used to represent both positive and negative integer values. Source: Intels IA-32 Architectures Software Developer's Manuals , page 83 When you want to get the two's complement representation of -13, you have to get the binary representation of 13, invert the digits and add one. As 13 is 1101 in binary, -13 looks like this on a 32 bit machine: 1111.1111.1111.1111.1111.1111.1111.0011 So two results might be logical: 0111.1111.1111.1111.1111.1111.1111.1001 or 1111.1111.1111.1111.1111.1111.1111.1001 Lets get the assembly code: gcc -S -O0 test.c .file \"test.c\" .section .rodata .LC0: .string \"%i\\n\" .text .globl main .type main, @function main: .LFB0: .cfi_startproc pushl %ebp .cfi_def_cfa_offset 8 .cfi_offset 5, -8 movl %esp, %ebp .cfi_def_cfa_register 5 andl $-16, %esp subl $16, %esp movl $-7, 4(%esp) movl $.LC0, (%esp) call printf leave .cfi_restore 5 .cfi_def_cfa 4, 4 ret .cfi_endproc .LFE0: .size main, .-main .ident \"GCC: (Ubuntu/Linaro 4.7.2-2ubuntu1) 4.7.2\" .section .note.GNU-stack,\"\",@progbits In line 18 you can see that the bitshift already happened. When you introduce a variable for a , you can see that the compiler makes use of the assembly command sarl %eax or sarl $2, %eax when you shift by two. When you take a look at Oracles IA-32 Assembly Language Reference Manual , page 56, you find: sar right shifts (signed divides) a byte, word, or long value for a count speciï¬ed by an immediate value and stores the quotient in that byte, word, or long respectively. The second variation right shifts by a count value speciï¬ed in the CL register. sar rounds toward negative inï¬nity; the high-order bit remains unchanged . This means, 1111.1111.1111.1111.1111.1111.1111.1001 is correct. And that's -7.","tags":"Code","title":"C Puzzle #3"},{"url":"https://martin-thoma.com/google-reader-alternatives/","text":"On July 1, 2013, Google will retire Google Reader ( source ). A first step should be to save your data (especially your subscriptions). You can do that with Google Takeout . You could also sign a petition against closing Google Reader , but I doubt that this will have any effect. Currently, 106,712 people support this petition, though. How I used Google Reader Most important for me was the Chrome plugin: Google Reader in Chrome - Icon indicates number of new items Google Reader in Chrome - Show all new items The website offered a nice, clean way to administrate my 109 Feeds. Last (and least) the Android App. I don't have my smartphone long enough to really use this app, but it is one of 10 Apps I've currently installed. Google Reader Website Google Reader Android App Now, I am interested in alternatives. They should allow me to import my subscriptions, have a Google Chrome Extension (in Chrome Web Store ) have an Android App (in Android Market ) have export options sync my feeds, as I would like to read my feeds on several computers and my smartphone allow me to login via Google OpenID Web Services The Old Reader The Old Reader is a web service that wants to provide the same service as Google did before. The Old Reader Looks pretty good, doesn't it? But it currently displays the message \"There are 27283 users in the import queue ahead of you.\" BazQux Reader BazQux Reader seemed to be a real alternative. It allowed me to sign in with Google, import my subscriptions and it looked familiar: BazQux Reader Another point for BazQux: It supports OPML-Export (Click on the icon at the top right corner â†’ Subscriptions â†’ Export OPML) But now the drawbacks: 9 $/year no Chrome plugin no Android App Bloglovin' Bloglovin sends you emails with your feeds. Those emails don't have an unsubscribe link. Bloglovin' is another WebService that looks very nice and is free, seems to be a real alternative. While importing my subscriptions, I got a 504 Gateway Time-out, but it imported my feeds anyway. bloglovin The service seems to be free, they have an Android App and an iPhone App , but no Google Chrome App and I can't sign in with Google. Bloglovin' does not provide an export function. Good Noows It seems to get better. Good Noows lets me sign in with Google, offers an import function and has a Chrome App . I seems to be free. Good Noows However, it has no Android App and seems not to support export. Bloglines Bloglines offers an export function! I can't login with Google, but I can import my 109 Feeds. It looks like this: It has no Chrome App and the Android App is possibly not official. Host yourself Selfoss Selfoss gives you the possibility to host your RSS-Aggregator by yourself. It looks quite good, requires only PHP 5.3 and MySQL and mobiles are supported. Screenshot of selfoss Selfoss: GitHub , Download Tiny Tiny RSS TT-RSS allows you to host a service similar to Google Reader. This could be an interesting alternative, but currently the demo page is disabled. I'm waiting for reviews of this one. Tiny Tiny RSS: GitHub , Issue Tracker , Download , Demo Android Client: Market Tried, but no alternative Pulse : Where can I add RSS-Feeds in this service? FeedAFever : Why should I pay for this, when there are free services? Feedly : What is this? Is it a Web service? Is it a standalone software? Do I have to host it myself? Hivemined : Not ready yet NewsBlur : I could not sign in. Rolio.com : No import More alternatives Here is an article that lists lots of alternatives. A short survey I'm interested in your experiences. Would you please participate in this five minute survey? Wird geladen...","tags":"The Web","title":"Google Reader Alternatives"},{"url":"https://martin-thoma.com/myth-the-internet-doesnt-forget/","text":"I've created a playlist with 51 songs on YouTube about two years ago. Let's see the stats: 6 of 51 are still available 5 had copyright problems 17 songs are not available because of GEMA 22 are gone for other reasons YouTube Video is not available in Germany because of GEMA Song Available 4 songs This video is no longer available due to a copyright claim by WMG. 1 songs This video is no longer available due to a copyright claim by Warner Music Group. Metallica - T... Not available in Germany (WMG, GEMA) 2 songs Unfortunately, this SME-music-content is not available in Germany because GEMA has not granted the respective music publishing rights. 1 songs Unfortunately, this SME-music-content is not available in Germany because GEMA has not granted the respective music publishing rights. 9 songs [...] UMG-music-content is not available in Germany because GEMA [...] 2 song Unfortunately, this video is not available in Germany because it may contain music for which GEMA has not granted the respective music rights. 2 songs This video is not available in your country. 11 song This video is no longer available because the YouTube account associated with this video has been terminated. 3 songs This video is unavailable. 2 songs content violated YouTube's Terms of Service 2 songs This video has been removed by the user. 4 songs This video is private. Cheney's Got A Gun Available ! My Favorite Things Available ! Osama Bin Laden Song Available ! Harry Potter Parody Song: Stay - Katy Cartee Haile Available ! Wii 'Fat' Song Available ! Billy Talent - Fallen Leaves Available !","tags":"The Web","title":"Myth: The Internet doesn''t forget"},{"url":"https://martin-thoma.com/nexus-4/","text":"Buying it You can buy a Nexus 4 in Saturn , but the 16GB-version costs 395 Euro there ( source ). In Google Play Store, it costs \"only\" 349 Euro ( source ). Comdirect So, I've decided to buy it from Google Play Store. But you have to have a Google Wallet account to use it. For a Google Wallet account, you need a credit card. Unlike in the USA, most people in Germany don't have a credit card. I had to get one and decided to use the free one from Comdirect . Here is a list of letters I got... I've expected one or two. 08.02.2013 I sent my information for registration to comdirect 15.02.2013 Notice that I need to send a MeldebestÃ¤tigung as I did identity verification with my passport and not with my identity card . The MeldebestÃ¤tigung costs 8.00 Euro. 21.02.2013 General information like account number 22.02.2013 PIN for online login 28.02.2013 Visa-Card 27.02.2013 iTAN list 04.03.2013 .comdirect girocard 05.03.2013 re-activation of bank account 05.03.2013 bank account blocked: three failed online logins 05.03.2013 PIN for Girocard Three cards I got from one bank At 28.02.2013, I first transferred 5 Euro to check if everything works as expected. I have to transfer it to my girocard. It arrived at 01.03.2013. Then I have to transfer it to my Visa card. It arrived at 04.03.2013. Quite a long time for an internal transaction. As I made three attempts to login into my online account from comdirect bank, my account was locked. I had to send a fax and ask them to unlock my account! Another Euro for the fax. (By the way, I think this is a security leak. If I wanted to do harm to the bank, I could make lots of accesses to their customers accounts and lock them. I guess it wouldn't take me more than 30 minutes to write the code and about one day to let it run. Very bad.) Google Play Ok, I've got a credit card. Now I will have bought a Nexus 4 in a couple of minutes, right? Wrong. Google Mail from Google Play from 2013-03-06, 10:47 Invalid address: Google help Google Play Store: Invalid address bug What the hell? They think I live in Helgoland or have military address? Ok, let's try it again: Google Wallet 2013-03-06 Google Wallet 2013-03-06, 10:55 WTF? Although the transaction was canceled, my bank thinks it happened. I can't see the transaction in my bank account, though. According to my online bank account, I haven't reached my limit. But I cannot pay for the \"second\" phone. That sucks. The next day it worked: Google Play Store Google Play Store 2013-03-06, 10:46 Google Play Store, 2013-03-07 2013-03-07: Now I have to wait for the phone. 2013-03-08: Hurray, it's here! My old not-so-smart phone and my new Nexus 4: Nexus 4 and Motorola W156 Micro-SIM vs. Mini-SIM Did you know that different SIM cards exist? I didn't. I've learned that I have a Mini-SIM, but you need a Micro-SIM for the Nexus 4. GSM SIM card evolution ( source ) I use a pre-paid card from simyo . Currently, they offer a free exchange of Mini-SIM-cards to Micro-SIM or Nano-SIM: Simyo: Free Micro-SIM Phew! I was lucky. Simyo Kombi SIM (Mini and Micro SIM) The Micro-SIM-card arrived at 2013-03-14 and will be unlocked the next day. Beginners questions What do those small icons on the top mean? Those icons are the notifications. Hold your finger on the top bar and pull down. Now you can view / clear them. How can I close apps? See this answer . How do I remove widgets? Go to your home screen Leave your finger on the widget for three seconds Move your finger to the appearing \"remove\" How do I open a shell? Install Android Terminal Emulator . (It says quite often \"Permission denied\") How can I execute Python? Install QPython+ (Android Python) . (WARNING: This seems to be a beta.) How can I take screenshots on my Nexus 4? Press \"Volume down\" and \"Power\" at the same time: How to take a screenshot with Nexus 4 How can I enable Geolocations for my photos? Camera settings Android: Store location setting Experiments with Nexus 4 Photo-Sphere You can create awesome photos with photo sphere. But objects have to be not very close. Here is my first try with my room: A sphere photo of my room Karlsruhe Panorama, 2013-03-09 09:30 Karlsruhe (Panorama) 2013-03-09 09:51 [sphere 60431] At the moment, it is not simply possible to include a sphere into a WordPress blog. Code was published to create this effect and it works , but the WordPress plugin has some issues . By the way, you can directly create a tiny world image from a photo sphere: Karlsruhe - Tiny World Adding a nicer alarm One reason why I bought this phone was that my alarm clock (which is my old phone) is awful. zedge.net seems to be one place where you can get ring tones. I like Sintels song , which was in Google Music. I've installed Rings Extended , as I wasn't able to find the ringtone without it. That could be better. Sky Map As my phone as quite a lot of sensors (GPS, compass, altimeter) I guessed it might be possible to store the well-known stars and show them on the device when you look in their direction. The app is calles \" Sky Map \". I have to try that when the sky is clear. Android Sky Map Movies I was very surprised that they don't have Blender Open Movies in the movie section of play store â˜¹ MyTracks MyTracks lets you record the track you take and see some stats about that. Quite nice, but the export doesn't work. I filed my first bug / feature request for an app: Issue 1260 What it replaces Nexus 4 could replace quite a lot of stuff: What Nexus 4 could replace But it can't replace credit cards in Germany as NFC isn't supported by the shops by now. It can't really replace a camera as the quality is ugly. Just take a close look at the photo above. This was taken with Nexus 4. Sadly, if you don't install apps like AirDroid , it can't replace a USB stick or a MP3 player. Yes, you can use Google Music and that works, but I would like to be able to copy MP3s from my laptop computer to my smartphone. Directly. With a USB-cable and without having to use the internet. It does replace a notepad, if you only use it for writing texts and not for drawing or math. And, finally, at the moment it doesn't even replace my old phone because of the SIM-problem I've explained above. But as soon as this is fixed, the Nexus 4 will replace my Motorola W156. Here is a comparision of those phones: Nexus 4 Motorola W156 Display 4.7 in (120 mm) diagonal IPS 1280Ã—768 px (316 ppi) 1.6 in (40 mm) diagonal 128Ã—128 pixel Colors 16 777 216 2 Memory 16 GB 20 kb ( source ) Body 133.9 x 68.7 x 9.1 mm 114 x 43 x 14 mm Weight 139 g 85 g Stand-by time 390 hours 465 hours Battery 2100 mAh (Li - Polymer) 940 mAh (Li - Ion) Here is the source for that comparison. What it hopefully really replaces are maps. I've just downloaded maps for the center of Paris. That were only about 2 MB. Here is a screenshot of maps guidance in action: Google Maps on Nexus 4 in action Mounting as USB-Stick This is a mayor drawback of the Nexus 4. You can't simply plug it in and work with it like you do with a USB-Stick. You have to enter mkdir Android go-mtpfs Android [ do what you want ] sudo umount Android Conclusion I finally paid 358,99 Euro for the phone and shipping, 8 Euro for the \"MeldebestÃ¤tigung\" and 1 Euro for the fax to re-activate my bank account which is 367,99 Euro in total. But if you want to experiment with a high quality smart phone, I guess it's a good choice. What's next? I have some ideas for apps. So my next steps are: Kick Windows 7 and install Arch Linux as the implementation / QA for PSE is over Start developing apps Get Started with Publishing I guess I'll also write an article what could get improved in Android.","tags":"Cyberculture","title":"Nexus 4"},{"url":"https://martin-thoma.com/add-a-new-font-to-imagemagick/","text":"You can list all fonts that are known to ImageMagick by identify -list font . When your font isn't there, but it is installed, you might want to try these steps: sudo updatedb Download imagick_type_gen Execute it: perl imagick_type_gen > types.xml Copy the result to the folder where it should be locate type.xml . That was /usr/lib/ImageMagick-6.5.7/config/type.xml for me sudo cp type.xml /usr/lib/ImageMagick-6.5.7/config/type.xml You can find some nice fonts here .","tags":"Cyberculture","title":"Add a new font to ImageMagick"},{"url":"https://martin-thoma.com/latex-beamer/","text":"I really enjoy creating presentations with LaTeX. The reasons are: You can use versioning (GIT, SVN, ...) You can use your favorite editor! When you've created an animation with Ti k Z, you can easily go one step back an go through it as fast as it is apropriate! Good separation of presentation and content It compiles to PDF Everybody can open it It always looks the same (no moved elements or hidden bullet points) You can use math mode â˜º No need to buy anything. It's free and OpenSource. A big community ( StackExchange and LateX-Community ) helps you, when you got questions. I'll now introduce you to the basics of LaTeX beamer presentations. If you only look for example, please go to my GitHub LaTeX Repository . Basics This is a basic presentation: \\documentclass { beamer } \\usetheme { Frankfurt } \\usepackage { hyperref } \\usepackage [utf8] { inputenc } % this is needed for german umlauts \\usepackage [english] { babel } % this is needed for german umlauts \\usepackage [T1] { fontenc } % this is needed for correct output % of umlauts in pdf \\begin { document } \\title { The title of your presentation } \\subtitle { A subtitle } \\author { Martin Thoma } \\date { 25. March 2013 } \\subject { Computer Science } \\frame { \\titlepage } \\section { Introduction } \\subsection { A subsection! } \\begin { frame }{ Slide title } Slide content \\end { frame } \\end { document } Style If you want to create nice-looking presentations like this one or that one , you should probably adjust the style. Here is an overview of the default ones that LaTeX has: Beamer theme gallery or here . The important commands for changing the appearance, that should get included just after documentclass, are: \\usetheme { Frankfurt } \\usecolortheme { default } When you're from KIT, you should use the KIT theme . Here are some screenshots: LaTeX Beamer: Example of a titlepage LaTeX Beamer: Example of a titlepage LaTeX Beamer: Example of source code LaTeX Beamer: Example of a slide Sections and subsections Take a look at the slides I've included above. Do you notice the little bubbles at the bottom that indicate how many slides are left? You get the text over the bubbles with \\section{Your text} and the bubbles with frame , but you need at least one \\subsection{bla} ! When you make more than one subsection, the frame-bubbles that belong to the same one get highlighted. Reveal information You might want to try those commands to hide and reveal information: \\pause \\uncover \\visible \\onslide and \\only You can use it like this: \\begin { frame }{ Another title } Some text \\\\ \\uncover <2-> { Uncover me on slide 2 (-) \\\\ } \\visible <3-> { visible from slide 3 on (-) \\\\ } \\only <4-> { only from slide 4 (-) \\\\ } \\onslide <5-> { on slide 5 and further (-) \\\\ } \\uncover <6> { Uncover me on slide 6 \\\\ } \\visible <7> { visible on 7 \\\\ } \\only <8> { only on slide 8 \\\\ } \\alt <8> { I am on slide 8 \\\\ }{ I am not on slide 8 \\\\ } \\onslide <9> { on slide 9 \\\\ } \\end { frame } Note that the numbers work like \\uncover<n-m>{ELEMENT} . If no m is specified, ELEMENT is visible until end of this frame. When you have a list and you want to uncover it element by element, you can use this: \\begin { itemize } [<+->] \\item one \\item two \\item three \\end { itemize } Blocks You can use block , exampleblock or alertblock inside your frame: \\begin { exampleblock }{ Test } This is my text. \\end { exampleblock } It looks like this: LaTeX Beamer blocks: block, exampleblock, alertblock Images Quite often, you want to have one big image. You need \\usepackage{graphicx} in your preamble. This is how you get the image it: \\begin { frame }{ My frame title } \\includegraphics [width=\\textwidth, height=0.8\\textheight, keepaspectratio] { ../relative/path/image.jpg } \\end { frame } Further reading Sizes in LaTeX How to visualize Graph algorithms with LaTeX UMBC Beamer guide texdoc beameruserguide or online","tags":"Cyberculture","title":"LaTeX Beamer"},{"url":"https://martin-thoma.com/linux-access-rights-and-attributes/","text":"RWX Files Linux files have three important access rights for files: R ead W rite E x ecute If you want to mark a file as executable, you can add the x-right: chmod +x When you want to mark a file as readable, you can dd the r-right: chmod +r You can remove rights in a similar way: chmod -x testfile Now, often this is expressed numerically. Three bits determine if the file is readable (4), writable (2) or executable (1). Did you notice that all of them are powers of two? Folders rwx has a meaning for folders, too: R ead: if that is missing, you can't use ls in the directory. W rite: you need this to create new files / folders in the direcotry x ... like \"enter\"?: if that is missing, you can't enter the directory. User, Group, Others The rights above can be set for the user who created the file (sometimes also called the owner). Then the group that owns the file and all others. This is the reason why you have three times the rights from above: moose@pc07:~/Downloads$ ls -l total 29624 drwxr-xr-x 8 moose moose 4096 2013 -02-22 14 :18 algorithms -rw-r--r-- 1 moose moose 60058 2013 -02-11 08 :00 args4j-2.0.21.jar drwxr-xr-x 6 moose moose 4096 2013 -02-25 20 :07 bwinf -rw-r--r-- 1 moose moose 22160041 2013 -02-05 16 :45 DT2012.zip drwxr-xr-x 8 moose moose 4096 2013 -02-28 19 :23 graphentheorie -rw-r--r-- 1 moose moose 2164878 2013 -02-22 12 :38 guava-14.0-rc1.jar -rw-r--r-- 1 moose moose 2705344 2013 -03-01 21 :07 HardVacuum.zip drwxr-xr-x 8 moose moose 4096 2013 -02-05 16 :38 informatik-2011 -rw-r--r-- 1 moose moose 111926 2013 -02-24 19 :09 Jim_Keener_resume.pdf drwxr-xr-x 2 moose moose 4096 2011 -11-08 11 :50 juniper_linux -rw-r--r-- 1 moose moose 288666 2012 -12-04 11 :38 junit-4.11.jar drwxr-xr-x 13 moose moose 4096 2013 -02-01 23 :33 LaTeX-examples drwxr-xr-x 2 moose moose 4096 2009 -08-11 17 :04 otrdecoder -rw-r--r-- 1 moose moose 728292 2013 -03-01 19 :33 PlanetCute PNG.zip drwxr-xr-x 2 moose moose 4096 2012 -11-13 10 :49 ProjectEuler drwxr-xr-x 2 moose moose 4096 2013 -03-04 20 :28 Screenshots Matlab -rw-r--r-- 1 moose moose 764196 2013 -03-04 20 :28 Screenshots Matlab.zip -rw-r--r-- 1 moose moose 534614 2013 -03-01 19 :48 spritelib_gpl.zip drwxr-xr-x 8 moose moose 4096 2013 -02-27 18 :36 Team drwxr-xr-x 5 moose moose 4096 2013 -02-27 19 :17 ViMuDat You might wonder what happens when you execute chmod +x filename . Does it set the execute-flag only for the user? Or for all three - user, group, others? Try and find out. You might want to remove all rights with chmod 000 filename before you start. Did you know that you can search for file permissions with find /home/ -perm 777 ? SUID, SGID, Sticky Bit Files Sometimes, you want to execute programs as root, although the user who started the execution isn't root. Take passwd, the program that allows users to change passwords, for example: moose@pc07:/usr/bin$ ls -l | grep passwd$ -rwsr-xr-x 1 root root 53812 2011 -02-14 23 :11 gpasswd -rwxr-xr-x 1 root root 13612 2012 -11-06 21 :41 htpasswd -rwsr-xr-x 1 root lpadmin 13540 2012 -12-04 16 :24 lppasswd -rwsr-xr-x 1 root root 37140 2011 -02-14 23 :11 passwd -rwxr-xr-x 1 root root 5070304 2012 -04-24 23 :38 smbpasswd -rwxr-xr-x 1 root root 9688 2013 -01-18 17 :59 vino-passwd Instead of \"x\" in the user-execution-row, it states \"s\". That means, you can execute it and it has the SUID-bit set. If \"x\" wasn't set, the \"S\" would be in a capital letter. When you change your password, you need to edit /etc/shadow . This file has very limited access rights: -rw-r----- and is owned by \"root\" and group \"shadow\": moose@pc07:/etc$ ls -l | grep shadow$ -rw-r----- 1 root shadow 813 2013 -01-24 06 :21 gshadow -rw-r----- 1 root shadow 1274 2013 -01-24 06 :21 shadow Here is more about shadow file . The SGID (set group id) bit works similar to the SUID (set user id) bit. When you want to execute something with as the group of the file, you set the SGID bit. The sticky bit seems to be used for programs to stick in memory after it was finished. You can set the sticky bit like this: chmod +t testfile or like that: chmod 1777 testfile Folders suid: is ignored on UNIX and Linux systems sgid: new files and subdirectories created within this folder inherit the folders group ID t: when the sticky bit is set, only owners may change the filename or delete files Type The first column of ls -l tells you the type of the item: -: a file b: a block device c: a character device d: a directory l: a symbolic link p: pipe s: a socket moose@pc07:/dev$ ls -l total 0 crw------- 1 root video 10 , 175 2013 -03-04 10 :01 agpgart crw-rw----+ 1 root audio 14 , 4 2013 -03-04 10 :01 audio drwxr-xr-x 2 root root 640 2013 -03-04 12 :59 block drwxr-xr-x 2 root root 100 2013 -03-04 12 :59 bsg drwxr-xr-x 3 root root 60 2013 -03-04 10 :01 bus lrwxrwxrwx 1 root root 3 2013 -03-04 10 :01 cdrom -> sr0 lrwxrwxrwx 1 root root 3 2013 -03-04 10 :01 cdrw -> sr0 crw-rw----+ 1 root audio 14 , 3 2013 -03-04 10 :01 dsp lrwxrwxrwx 1 root root 3 2013 -03-04 10 :01 dvd -> sr0 lrwxrwxrwx 1 root root 3 2013 -03-04 10 :01 dvdrw -> sr0 crw-rw---- 1 root root 10 , 61 2013 -03-04 10 :01 ecryptfs crw-rw---- 1 root video 29 , 0 2013 -03-04 10 :01 fb0 lrwxrwxrwx 1 root root 13 2013 -03-04 10 :01 fd -> /proc/... crw-rw-rw- 1 root root 1 , 7 2013 -03-04 10 :01 full crw-rw-rw- 1 root fuse 10 , 229 2013 -03-04 10 :01 fuse crw-rw---- 1 root root 251 , 0 2013 -03-04 18 :14 hidraw0 crw-rw---- 1 root root 10 , 228 2013 -03-04 10 :01 hpet drwxr-xr-x 4 root root 380 2013 -03-04 18 :14 input crw-rw---- 1 root root 1 , 11 2013 -03-04 10 :01 kmsg srw-rw-rw- 1 root root 0 2013 -03-04 10 :01 log brw-rw---- 1 root disk 7 , 0 2013 -03-04 10 :01 loop0 [ ... ] stat You can display quite a lot of information of a file with stat: moose@pc07:~/Desktop/Test$ stat testfile File: ` testfile ' Size: 13 Blocks: 8 IO Block: 4096 regular file Device: 801h/2049d Inode: 923339 Links: 1 Access: ( 0777 /-rwxrwxrwx ) Uid: ( 1000 / moose ) Gid: ( 1000 /moose ) Access: 2013 -03-04 21 :31:52.154187243 +0100 Modify: 2013 -03-04 21 :31:51.154184098 +0100 Change: 2013 -03-04 21 :31:51.154184098 +0100 The content of the file is \"Hello World.\" (12 characters) Attributes According to the manpage of chattr: The `c', 's', and `u' attributes are not honored by the ext2 and ext3 filesystems as implemented in the current mainline Linux kernels. These attributes may be implemented in future versions of the ext2 and ext3 filesystems. Version I've just learned that you can give files version-attributes: moose@pc07:~/Desktop/Test$ lsattr -v 1338 -----------------e- ./testfile You can set the version like this: chattr -v 1339 testfile Append only This one is weird. Theoretically, it should allow me to append to a file, but not to change / delete anything in the file. First of all, I had to use sudo to add this attribute: sudo chattr +a testfile Then, I had all permissions: moose@pc07:~/Desktop/Test$ stat testfile File: ` testfile ' Size: 13 Blocks: 8 IO Block: 4096 regular file Device: 801h/2049d Inode: 923339 Links: 1 Access: ( 0777 /-rwxrwxrwx ) Uid: ( 1000 / moose ) Gid: ( 1000 /moose ) Access: 2013 -03-04 21 :31:52.154187243 +0100 Modify: 2013 -03-04 21 :31:51.154184098 +0100 Change: 2013 -03-04 21 :33:55.154184312 +0100 moose@pc07:~/Desktop/Test$ lsattr -----a-----------e- ./testfile But I couldn't append to the file with gedit. With bash, it worked fine: moose@pc07:~/Desktop/Test$ echo \"One more line \" >> testfile moose@pc07:~/Desktop/Test$ cat testfile Hello World. One more line So I guess I found another bug in gEdit. Immutable You can mark a file as immutable with sudo chattr +i testfile . It's funny, you can't see that with ls -l , you have to use lsattr . I guess if you manage to get root privileges and want to troll somebody, you could set this bit. I think this might take quite a while until you recognize it. Secure deletion and undeletable When secure deletion is set with chattr +s testfile the operating system overwrites the file with random data when it is deleted. chattr +u testfile makes your file undeletable. This is strange. You can still delete the file with rm , but the system will not overwrite it. I've just asked a question on SE . Synchronous update when you set chattr +S testfile the file gets directly written to the HDD and not buffered by the kernel cache.","tags":"Cyberculture","title":"Linux access rights and attributes"},{"url":"https://martin-thoma.com/check-file-systems-maximum-path-depth/","text":"Today, I've wondered how deep a path could be at maximum. I've guessed the file system may be limiting that, but perhaps also some tools that I use for basic operations like listing a folders contents would fail before. So I've created the following C-Snippet to test it: #include <sys/stat.h> #include <sys/types.h> #include <stdio.h> #include <string.h> #include <stdlib.h> int i = 0 ; int returnCode ; char * pathname ; void giveInformation () { printf ( \"return code \\t\\t : %i \\n \" , returnCode ); printf ( \"Created sub-directories \\t : %i \\n \" , i ); printf ( \"length of pathname \\t : %i \\n \" , strlen ( pathname )); if ( strlen ( pathname ) <= 80 ) { printf ( \"Path \\t\\t\\t : %s \\n \" , pathname ); } } int main () { pathname = \"/home/moose/Desktop/Test\" ; char * ext = \"/one\" ; returnCode = 0 ; int maxDir = 1000000 ; while ( i < maxDir && returnCode == 0 ) { char * newName = malloc ( strlen ( pathname ) + strlen ( ext ) + 1 ); strcpy ( newName , pathname ); strcat ( newName , ext ); returnCode = mkdir ( newName , 0777 ); if ( i != 0 ) { // if you remove this line, your system gets very slow: free ( pathname ); } pathname = newName ; i ++ ; } giveInformation (); return 0 ; } Now run it: $ time ./createDirectories return code : -1 Created sub-directories : 1018 length of pathname : 4096 real 0m0.281s user 0m0.004s sys 0m0.180s Ok, something went wrong at the end. Lets see what crashes when I enter this path in Gnome terminal $ cd one/one/one .... one/ $ mkdir two $ cd two cd: error retrieving current directory: getcwd: cannot access parent directories: File name too long Strangely, it showed me a path /home/moose/.../one/one/one/one/tw$ . No, this is not a typo. It showed tw, not two. So, maybe the path can get only that long? Now I created a folder called \"three\" and one called \"this\". I entered both of them with cd, both showed /home/moose/.../one/one/th . So I guess this is a problem of Gnome Terminal and not a limitation of the file system. Let's see what Nautilus does. I once got Nautilus to crash , I think I get it another time: Contents, according to nautilus: 1,016 items, totalling 4.0 MB Then I've opened the folder \"one\" and double clicked as fast as I could. CPU utilization: 100%, but no crash. And 995 items are left â˜º Now a single double click causes 100% CPU utilization for about 25 seconds. When I use a single character for sub-directories, I get: moose@pc07:~/Desktop/Test$ ./createDirectories return code : -1 Created sub-directories : 2036 length of pathname : 4096 Number of directories in one directory Do you know how many folders can fit into one folder? Well, lets find out: #include <sys/stat.h> #include <sys/types.h> #include <stdio.h> #include <string.h> #include <stdlib.h> int i = 0 ; int returnCode ; char * pathname ; /** http://stackoverflow.com/a/440240/562769 */ void gen_random ( char * s , const int len ) { static const char alphanum [] = \"0123456789\" \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\" \"abcdefghijklmnopqrstuvwxyz\" ; for ( int i = 0 ; i < len ; ++ i ) { s [ i ] = alphanum [ rand () % ( sizeof ( alphanum ) - 1 )]; } s [ len ] = 0 ; } void giveInformation () { printf ( \"return code \\t\\t : %i \\n \" , returnCode ); printf ( \"Created sub-directories \\t : %i \\n \" , i ); printf ( \"length of pathname \\t : %i \\n \" , strlen ( pathname )); if ( strlen ( pathname ) <= 80 ) { printf ( \"Path \\t\\t\\t : %s \\n \" , pathname ); } } int main () { pathname = \"/home/moose/Desktop/Test/test/\" ; returnCode = 0 ; int maxDir = 1000000 ; while ( i < maxDir && returnCode == 0 ) { // get unique name char * foldername = malloc ( 50 + 1 ); gen_random ( foldername , 50 ); char * completePath = malloc ( strlen ( pathname ) + strlen ( foldername ) + 1 ); strcpy ( completePath , pathname ); strcat ( completePath , foldername ); returnCode = mkdir ( completePath , 0777 ); free ( foldername ); free ( completePath ); i ++ ; } giveInformation (); return 0 ; } I've executed it and after eight minutes I canceled the execution. $ ls | wc -l 378463 Ok, not a million folders, but 378.463 is also quite a lot. When I try to open this folder with Nautilus, I get 140% CPU utilization by Nautilus. Quite impressive, for only showing some folders. You should probably not execute the script above, as deleting the folder isn't that easy . By the way, I got a new error message that I didn't know before: Cannot move file to trash - Filename too long!","tags":"Code","title":"Check File Systems maximum path depth"},{"url":"https://martin-thoma.com/os-klausur/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesungen des Moduls â€žBetriebssysteme\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Prof. Dr. Bellosa und spÃ¤ter bei Prof. Dr. Beigl gehÃ¶rt. Wenn ich im Folgenden eine Seitenzahl angebe, dann ist damit \"Operating System Concepts\" von Silberschatz gemeint (ISBN 0-471-69466-5): Themen Process Coordination: Shared Memory Critical-Section Problem: Peterson's Solution , Synchronisation Deadlock , Starvation Process Management Process Sheduling Process States: new, ready, running, waiting, terminated Process Control Block: Folie 6/65 slide_proc_management Memory Management Globale / lokale Seitenersetzungsstrategie Equal allocation Slab allocator Begriffe Folgende Begriffe muss man kennen und erklÃ¤ren kÃ¶nnen: Critical Section und Race Condition Semaphor : counting Semaphores, binary Semaphores und Mutex Locks â†’ Antwort auf S. 200f Dining-Philosophers Problem â†’ Antwort auf S. 207f Deadlock, Starvation Safe State FAQ Wie funktionieren Bitmasken und insbesondere ~, &, |? Nenne ein reales Beispiel, bei dem eine Race-Condition auftreten kÃ¶nnte. Welche Probleme hat Contiguous Allocation? â†’ Antwort Welche Scheduling-Verfahren gibt es? Priority Scheduling Round Robin Multilevel Feedback Queue Lottery Scheduling PSJF FCFS What is the difference between Page and Frame? In a paging system, programs and data stored on disk are divided into equal, fixed sized blocks called pages, and main memory is divided into blocks of the same size called frames. Exactly one page can fit in one frame. Physical memory is divided into parts called â€žframe\" and logical memory is divided into parts called â€žpage\". Quelle: wiki.answers.com Nennen und erlÃ¤utern Sie die drei notwendigen Bedingungen fÃ¼r eine gÃ¼ltige LÃ¶sung des Problems kritischer Abschnitte. Mutual exclusion: Only one thread can be in the CS at a time. Progress: If no thread is in the CS one of the threads trying to enter will eventually get in Threads that are not trying to enter do not hinder processes that try to enter from getting in Bounded waiting: Once a thread starts trying to enter the critical section, there is a bound on the number of times other threads get in. Wie kann man das Problem kritischer Abschnitte lÃ¶sen? Interrupts deaktivieren (nur im Kernel-Space, nur Single-Core) Spezielle atomare Instruktionen: Test-and-set Compare-and-swap Fetch-and-add swap Semaphor (wait und signal) Monitor Algorithmus von Peterson Nennen und erklÃ¤ren Sie die ver notwendigen Bedingungen fÃ¼r Deadlocks. Mutual exclusion: Eine Ressource kann nicht gleichzeitig von mehreren Prozessen benutzt werden Hold and wait: Ein Prozess, der bereits mindestens eine Ressource hÃ¤lt, wartet auf mindestens eine andere Ressource No preemption: Zugeteilte Ressourcen kÃ¶nnen einem Prozess nicht wieder entzogen werden. Er muss diese selbst freigeben. Circular wait: Es gibt eine Menge von Prozessen $\\{P_0, P_1, \\dots, P_n\\}$, wobei $P_0$ auf eine Ressource wartet, die $P_1$ hÃ¤lt, $P_1$ auf eine Ressource wartet, die $P_2$ hÃ¤lt, ..., $P_n$ auf eine Ressource wartet, die $P_0$ hÃ¤lt. Was kann man in Bezug auf das Deadlock-Problem machen? Prevention Avoidance Detection: Prozess abschieÃŸen Rollback Vogel-StrauÃŸ-Algorithmus : Der User wird sich schon drum kÃ¼mmern, z.B. indem er einen Prozess abschieÃŸt ( kill -9 ) oder indem er den PC vom Strom nimmt. ErklÃ¤ren Sie Raid 0 - 5. Raid 0: Striping. Platten werden \"aneinandergehÃ¤ngt\". Raid 1: Mirroring. Daten werden auf mehrere Platten gespiegelt. Raid 2: Fehlerkorrigierender Hamming-code. Raid 3: Byteweise ParitÃ¤t. Raid 4: Blockweise ParitÃ¤t. Raid 5: Blockweise, verteilte ParitÃ¤t. Warum verwenden wir Seitentabellen? KÃ¶nnte man nicht einfach im Hauptspeicher je zwei DatenwÃ¶rter kombinieren, wobei das erste die Metainformationen (z.B. Zugriffsrechte, Prozess-ID) und das zweite die Daten enthÃ¤lt? Prinzipiell wollen wir in einer x86-Architektur, dass sich die Hardware um das Paging kÃ¼mmert. Bei MIPS sieht das wohl anders aus ( Quelle ). Wenn man sich fÃ¼r jedes Datenwort ein Datenwort mit Metainformationen merken wÃ¼rde, hÃ¤tte man sehr viel Overhead. Diese Informationen hat man bei Paging auf IA-32 nur jede 4096 Byte! (Allgemein ist Overhead Ã¼brigens eine BegrÃ¼ndung, die hÃ¤ufig stimmt.) Falls man es wirklich genau wissen will, sollte man wohl die IA-32 Architectures Software Developer's Manuals lesen. Das sind ja nur 3044 Seiten. Einstufige Seitentabellen sind deutlich einfacher zu verstehen und zu implementieren. Warum verwendet man sie nicht auf 64 Bit Systemen? Sie wÃ¼rden zu viel Speicher benÃ¶tigen. Es wird eine Seitentabelle pro Prozess benÃ¶tigt. Die GrÃ¶ÃŸe einer einstufigen Seitentabelle berechnet sich wie folgt: Sei $m$ die GrÃ¶ÃŸe des Hauptspeichers in Byte, $p$ die GrÃ¶ÃŸe einer Seite in Byte und $a$ die Anzahl der zusÃ¤tzlichen Bit pro Seite (Access Control bits, validity. Siehe StackExchange ). Dann gilt: GrÃ¶ÃŸe der Seitentabelle = GrÃ¶ÃŸe eines Seiteneintrages Â· Anzahl der Seiten $= \\lceil \\frac{\\log_2(\\frac{m}{p}) + a}{8}\\rceil \\text{Byte} \\cdot \\frac{2&#94;{64} \\text{ Byte}}{p \\text{ Byte}}$ Typischerweise gilt: $m = 4 GB = 4 \\cdot 2&#94;{30} \\text{ Byte} = 2&#94;{32} \\text{ Byte}$, $p = 4096 \\text{ Byte}$ und $a = 8$. Daraus folgt eine SeitengrÃ¶ÃŸe von 4 Byte und 4.503.599.627.370.496 Seiten. Das ergibt eine SeitentabellengrÃ¶ÃŸe von 16 Petabyte. Wenn man nur Segmentierung nutzt, wie kommt man dann von der logischen Adresse auf die physische? Segmentation: Logical to linear address ( source ) Wie ist ein Inode aufgebaut? Struktur eines Inodes Wie groÃŸ kann eine Datei maximal werden, wenn man Inodes mit jeweils einem indirekten, doppelt indirektem und dreifach indirektem Block hat? Sei $b$ die GrÃ¶ÃŸe eines Blocks in Byte und ein Zeiger belege 4 Byte. Dann berechnet sich die maximale DateigrÃ¶ÃŸe in Byte wie folgt: $12 \\cdot b + \\frac{b}{4} \\cdot b+ \\frac{\\frac{b}{4} \\cdot b}{4} \\cdot b + \\frac{\\frac{\\frac{b}{4} \\cdot b}{4} \\cdot b}{4} \\cdot b = 12 \\cdot b + \\frac{b&#94;2}{4} + \\frac{b&#94;3}{16} + \\frac{b&#94;4}{64}$ Bei einer BlockgrÃ¶ÃŸe von 1024 Byte sind das 17,25 GB ( Rechnung ), bei einer BlockgrÃ¶ÃŸe von 4096 Byte sogar 4,40 TB ( Rechnung )! Wenn ihr Linux habt, kÃ¶nnt ihr diese Werte so herausfinden: \u0002wzxhzdk:0\u0003 Depict the common memory layout of a process. Give an example of the data that is stored in each section. Common process memory layout Ich sehe gerade, dass bei rodata wohl das SchlÃ¼sselwort const mit dabei stehen sollte. Statische Variablen kÃ¶nnen natÃ¼rlich geÃ¤ndert werden. What is anonymous memory? Anonymous memory is memory, that is not backed by a file. Examples are stack and heap. Material Material zum Ãœben (also alte Klausuren ) gibts wie immer entweder online oder bei der Fachschaft. Die LÃ¶sungen zu den Klausuren sind PasswortgeschÃ¼tzt, aber wenn ihr euch einmal Ã¼ber VPN einloggt, stehen ganz unten auf der Seite die Zugangsdaten. Das Skript / die Folien sind im VAB . Folgende Wiki-Artikel und manpages sollte man sich durchlesen: Unix-Dateirechte und chmod sowie mein Artikel . Als Buch kann ich neben dem Silberschatz folgendes Empfehlen: LPIC-1 - Vorbereitung auf die PrÃ¼fung des Linux Professinal Institute. ISBN 978-3-937514-81-9 Some Random Facts subl $16, %esp allokiert 16 Byte auf dem Stack. Termine und Klausurablauf Datum : 18.03.2012 um 14:00 Uhr. Ort : ich bin im 30.21 Gerthsen ( HÃ¶rsaalverteilung ) Dauer : 60 Minuten Punkte : 60 Benuspunkte : AbhÃ¤ngig von den Punkten im Ãœbungsschein: 110 - 129 Punkte: 1 Bonuspunkt 130 - 149 Punkte: 2 Bonuspunkte 150 - 169 Punkte: 3 Bonuspunkte 170 - x Punkte: 4 Bonuspunkte Quelle Nicht vergessen : Studentenausweis Einsicht : 09.04.2013 (war seit spÃ¤testens 13.02.2013 bekannt) Ort der Einsicht : 07.07 ( Vincenz-Priessnitz-Str. 1 , 2.OG, links), Raum 215 Zeit der Einsicht : Je nach Matrikelnummer unterschiedlich. Ergebnisse HÃ¤ngen noch nicht aus (Stand: 15.03.2013) HÃ¤ngen nun aus (Stand: 08.04.2013) und sind im VAB Ergebnisse der OS-Klausur vom WS 2012 / 2013","tags":"German posts","title":"Betriebssysteme Klausur"},{"url":"https://martin-thoma.com/how-chrome-could-be-improved-2nd-post/","text":"Chrome 25 was just released and I would like to mention some features I am still missing. As I already wrote an article How Chrome could be improved for Chrome 18 I will also mention what was realised meanwhile. If you're curious if you have the current version, just visit chrome://chrome/ . Caps lock indicator for password fields It's annoying to have caps lock on while typing passwords. So an indicator is needed. I would prefer a caps icon indicator solution: Password field caps icon indicator Another way to indicate it would be by text: Password field caps lock warning Improve MathML support Chrome uses WebKit and WebKit didn't support MathML for quite a long time. A quite good work-around is MathJax , but it is a work-around. Native support would be nice. With Chrome 24, they have added MathML support, but its still not optimal: The font doesn't look very nice (see MathML Torture Test and image below) Multiscripts seems not to work big brackets get a whitespace in the middle (see image below) Scriptlevel seems not to work (see MathML Browser test ) Here is an image where you can see some of the problems: MathML rendered with Chrome 24 In Chrome 25, MathML was deactivated. Which Browsers support MathML? Test page HTML5test.com - Chrome seems to cheat, MathML is not supported as you can see on the test page. Chrome 25 scores 448/500 Points and 13 bonus points. Webkit MathML project , Webkit MathML master bug Stop Animations Sometimes I would like to be able to stop animations. It can be very useful to be able to stop animations if you want to explain something in the animation. For example, this page on Wikipedia has some animations. If you give private lessons in math to another person, you might want to tell something to the single images of the animation. But I am quite sure, that you can't speak that fast. It would also be nice if you were able to stop all animations on the page. Regrettably, some webmasters carry the usage of animations to excess. What do I still miss? Disable sound for tabs Sometimes I watch a movie while I play a flash game. Some flash games don't offer an option to mute them. So I would like to get the possibility to disable sound for one tab. It could look like this. Disable the sound of a tab UPDATE: This is issue 3541 . Spell checker I write Blogs in German and in English. So I would like a spell-checker option at the bottom-left corner to switch languages: Spell checker PDF page numbers It would be great, if I could see the number of the page your currently on. Sometimes PDF-Documents don't even have numbers (e.g. LaTeX beamer slides). What do you do if you have a question to one slide if there are dozens of slides? Manually count them, to get the page number you're looking for? UPDATE : You actually can jump to any page and share it as links! You only have to add #page=123 . For example, you can take a look at this huge TikZ PDF manual . UPDATE2 : You could automatically adjust this #page=123 string according to the page that gets currently viewed. This would make sharing much easier and it would fix the issue that you don't know where you. Another advantage of this solution is that it doesn't bloat up the user interface. UPDATE3 : I finally found it! It's issue 66900 Security Disabling Extensions Auto-Disable extensions for https. Only PayPal, Amazon, Ebay, GMail and my bank accounts work with https. I don't need my Addons for these sites and I would appreciate if I could auto-disable them for https. Password Reuse Visualizer Firefox offers a tool which helps to identify passwords, that get reused often. It is called ' Password Reuse Visualizer ' and looks like this: Password Reuse Visualizer What was realized? Rotate PDF You can view this PDF online as an example. If you make a right-click on it, you can rotate it now. Rightclick menu of Google Chrome HTML5 input elements - partly Chrome 25 does still not support the datetime input element , tel input element, . They have added a very nice color input element: Some Screenshots for non-Chrome users: The button gets displayed like that: Google Chrome input type color element If you click on it, this dialog box gets displayed: Google Chrome Color Dialog Box They have added support to many of the time-elements like week: HTML5 input type 'week' If you want to check how your browser displays the different input types, here is a test page for input elements . According to What was realized that I don't need? The German wiki offers a really nice overview of version changes : Checking spelling mistakes with Google Chrome to mobile Metro-App for Windows 8 Support for Retina-Displays Google Cloud Print Improved support for Gamepads Web Speech API Although I think that this feature is very cool, it doesn't quite work. Here is a demo for Web Speech . I said: \"Hallo Marie. Die Web Speech API funktioniert nocht nicht so richtig.\" (German) which means \"Hello Marie. The Web Speech API doesn't quite work by now.\" Web Speech recognized: \"Hallo Mausi Mausi. Zieh dich aus.\" (German) which means \"Hello darling. Undress!\". I guess this would be interesting if I sent it per email without checking the recognized text.","tags":"Cyberculture","title":"How Chrome could be improved - 2nd Post"},{"url":"https://martin-thoma.com/how-to-check-if-two-line-segments-intersect/","text":"You have to line segments and you want to know if they intersect. I'll give you an algorithm how to do it. Test cases First of all, we should think about how lines can be arranged: Testcase T1 Testcase T2 Testcase T3 Testcase T4 Testcase T5 Testcase T6 Testcase F1 Testcase F2 Testcase F3 Testcase F4 Testcase F5 Testcase F6 Testcase F7 Testcase F8 Bounding boxes You can draw boxes around line segments such that the edges of the boxes are in parallel to the coordinate axes: Two line segments with their bounding boxes With this image in mind, it is obvious that the bounding boxes need to intersect if the lines should intersect. At this point you have to make a decision: If the endpoint of one line is on the other line, is this an intersection? I think so. If two lines have at least one point in common, they intersect. If two bounding boxes have at least one point in common, they intersect. It is much easier to check if two bounding boxes intersect. It's simply: /** * Check if bounding boxes do intersect. If one bounding box * touches the other, they do intersect. * @param a first bounding box * @param b second bounding box * @return <code>true</code> if they intersect, * <code>false</code> otherwise. */ public boolean doBoundingBoxesIntersect ( Point [] a , Point [] b ) { return a [ 0 ]. x <= b [ 1 ]. x && a [ 1 ]. x >= b [ 0 ]. x && a [ 0 ]. y <= b [ 1 ]. y && a [ 1 ]. y >= b [ 0 ]. y ; } If you have difficulties to understand why this works, take a look at this great animation for this formula . The algorithm Flowchart how to check if two lines intersect Looks quite simple, doesn't it? Cross product Well, you might notice that you need to check if one line intersects with a given line segment. To check this, you have to understand one cool idea: You can definie a cross product for points: \\begin{align} \\times_P&: Point \\times Point \\rightarrow \\mathbb{R}\\\\ \\times_P(a, b) &:= a.x \\cdot b.y - b.x \\cdot a.y; \\end{align} This cross product has one nice characteristics: \\(a \\times_P b = 0 \\Leftrightarrow a\\) and \\(b\\) are on one line through origin You can verify this. If you take two points on a line through origin, they have the same slope \\(\\frac{\\Delta y}{\\Delta x}\\) : $$ \\begin{align} 0 &= a \\times_P b\\\\ \\Leftrightarrow 0 &= a.x \\cdot b.y - b.x \\cdot a.y\\\\ \\Leftrightarrow b.x \\cdot a.y &= a.x \\cdot b.y\\\\ \\Leftrightarrow \\frac{a.y}{a.x} &= \\frac{b.y}{b.x} \\end{align} $$ Ok, now you can check if a point is on a line: /** * Checks if a Point is on a line * @param a line (interpreted as line, although given as line * segment) * @param b point * @return <code>true</code> if point is on line, otherwise * <code>false</code> */ public boolean isPointOnLine ( LineSegment a , Point b ) { // Move the image, so that a.first is on (0|0) LineSegment aTmp = new LineSegment ( new Point ( 0 , 0 ), new Point ( a . second . x - a . first . x , a . second . y - a . first . y )); Point bTmp = new Point ( b . x - a . first . x , b . y - a . first . y ); double r = crossProduct ( aTmp . second , bTmp ); return Math . abs ( r ) < EPSILON ; } The second cool characteristic of the cross product is that it can be used to determine if a point b is left or right of the line through the origin and a point a: /** * Checks if a point is right of a line. If the point is on the * line, it is not right of the line. * @param a line segment interpreted as a line * @param b the point * @return <code>true</code> if the point is right of the line, * <code>false</code> otherwise */ public boolean isPointRightOfLine ( LineSegment a , Point b ) { // Move the image, so that a.first is on (0|0) LineSegment aTmp = new LineSegment ( new Point ( 0 , 0 ), new Point ( a . second . x - a . first . x , a . second . y - a . first . y )); Point bTmp = new Point ( b . x - a . first . x , b . y - a . first . y ); return crossProduct ( aTmp . second , bTmp ) < 0 ; } When we have one line \\(a\\) through the origin and one line segment \\(b\\) , you can check if \\(b\\) crosses \\(a\\) by checking if the end points of \\(b\\) are on different sides of \\(a\\) : /** * Check if line segment first touches or crosses the line that is * defined by line segment second. * * @param first line segment interpreted as line * @param second line segment * @return <code>true</code> if line segment first touches or * crosses line second, * <code>false</code> otherwise. */ public boolean lineSegmentTouchesOrCrossesLine ( LineSegment a , LineSegment b ) { return isPointOnLine ( a , b . first ) || isPointOnLine ( a , b . second ) || ( isPointRightOfLine ( a , b . first ) &#94; isPointRightOfLine ( a , b . second )); } Now you have everything you need: /** * Check if line segments intersect * @param a first line segment * @param b second line segment * @return <code>true</code> if lines do intersect, * <code>false</code> otherwise */ public boolean doLinesIntersect ( LineSegment a , LineSegment b ) { Point [] box1 = a . getBoundingBox (); Point [] box2 = b . getBoundingBox (); return doBoundingBoxesIntersect ( box1 , box2 ) && lineSegmentTouchesOrCrossesLine ( a , b ) && lineSegmentTouchesOrCrossesLine ( b , a ); } By the way, testcase F5 is the only reason why you need doBoundingBoxesIntersect(box1, box2) . All other tests still pass if you remove this function. Where do two line segments intersect? When you know that two line segments intersect, you can also calculate the intersection. The intersection could be a line or only a point. I did this with JavaScript: Ihr Browser kann leider keine eingebetteten Frames anzeigen. Die Seite ist hier . This is the code that checks for line segments: /** You know that lines a and b have an intersection and now you want to get it! */ function getIntersection ( a , b ) { /* the intersection [(x1,y1), (x2, y2)] it might be a line or a single point. If it is a line, then x1 = x2 and y1 = y2. */ var x1 , y1 , x2 , y2 ; if ( a [ \"first\" ][ \"x\" ] == a [ \"second\" ][ \"x\" ]) { // Case (A) // As a is a perfect vertical line, it cannot be represented // nicely in a mathematical way. But we directly know that // x1 = a [ \"first\" ][ \"x\" ]; x2 = x1 ; if ( b [ \"first\" ][ \"x\" ] == b [ \"second\" ][ \"x\" ]) { // Case (AA): all x are the same! // Normalize if ( a [ \"first\" ][ \"y\" ] > a [ \"second\" ][ \"y\" ]) { a = { \"first\" : a [ \"second\" ], \"second\" : a [ \"first\" ]}; } if ( b [ \"first\" ][ \"y\" ] > b [ \"second\" ][ \"y\" ]) { b = { \"first\" : b [ \"second\" ], \"second\" : b [ \"first\" ]}; } if ( a [ \"first\" ][ \"y\" ] > b [ \"first\" ][ \"y\" ]) { var tmp = a ; a = b ; b = tmp ; } // Now we know that the y-value of a[\"first\"] is the // lowest of all 4 y values // this means, we are either in case (AAA): // a: x--------------x // b: x---------------x // or in case (AAB) // a: x--------------x // b: x-------x // in both cases: // get the relavant y intervall y1 = b [ \"first\" ][ \"y\" ]; y2 = Math . min ( a [ \"second\" ][ \"y\" ], b [ \"second\" ][ \"y\" ]); } else { // Case (AB) // we can mathematically represent line b as // y = m*x + t <=> t = y - m*x // m = (y1-y2)/(x1-x2) var m , t ; m = ( b [ \"first\" ][ \"y\" ] - b [ \"second\" ][ \"y\" ]) / ( b [ \"first\" ][ \"x\" ] - b [ \"second\" ][ \"x\" ]); t = b [ \"first\" ][ \"y\" ] - m * b [ \"first\" ][ \"x\" ]; y1 = m * x1 + t ; y2 = y1 } } else if ( b [ \"first\" ][ \"x\" ] == b [ \"second\" ][ \"x\" ]) { // Case (B) // essentially the same as Case (AB), but with // a and b switched x1 = b [ \"first\" ][ \"x\" ]; x2 = x1 ; var tmp = a ; a = b ; b = tmp ; var m , t ; m = ( b [ \"first\" ][ \"y\" ] - b [ \"second\" ][ \"y\" ]) / ( b [ \"first\" ][ \"x\" ] - b [ \"second\" ][ \"x\" ]); t = b [ \"first\" ][ \"y\" ] - m * b [ \"first\" ][ \"x\" ]; y1 = m * x1 + t ; y2 = y1 } else { // Case (C) // Both lines can be represented mathematically var ma , mb , ta , tb ; ma = ( a [ \"first\" ][ \"y\" ] - a [ \"second\" ][ \"y\" ]) / ( a [ \"first\" ][ \"x\" ] - a [ \"second\" ][ \"x\" ]); mb = ( b [ \"first\" ][ \"y\" ] - b [ \"second\" ][ \"y\" ]) / ( b [ \"first\" ][ \"x\" ] - b [ \"second\" ][ \"x\" ]); ta = a [ \"first\" ][ \"y\" ] - ma * a [ \"first\" ][ \"x\" ]; tb = b [ \"first\" ][ \"y\" ] - mb * b [ \"first\" ][ \"x\" ]; if ( ma == mb ) { // Case (CA) // both lines are in parallel. As we know that they // intersect, the intersection could be a line // when we rotated this, it would be the same situation // as in case (AA) // Normalize if ( a [ \"first\" ][ \"x\" ] > a [ \"second\" ][ \"x\" ]) { a = { \"first\" : a [ \"second\" ], \"second\" : a [ \"first\" ]}; } if ( b [ \"first\" ][ \"x\" ] > b [ \"second\" ][ \"x\" ]) { b = { \"first\" : b [ \"second\" ], \"second\" : b [ \"first\" ]}; } if ( a [ \"first\" ][ \"x\" ] > b [ \"first\" ][ \"x\" ]) { var tmp = a ; a = b ; b = tmp ; } // get the relavant x intervall x1 = b [ \"first\" ][ \"x\" ]; x2 = Math . min ( a [ \"second\" ][ \"x\" ], b [ \"second\" ][ \"x\" ]); y1 = ma * x1 + ta ; y2 = ma * x2 + ta ; } else { // Case (CB): only a point as intersection: // y = ma*x+ta // y = mb*x+tb // ma*x + ta = mb*x + tb // (ma-mb)*x = tb - ta // x = (tb - ta)/(ma-mb) x1 = ( tb - ta ) / ( ma - mb ); y1 = ma * x1 + ta ; x2 = x1 ; y2 = y1 ; } } return { \"first\" : { \"x\" : x1 , \"y\" : y1 }, \"second\" : { \"x\" : x2 , \"y\" : y2 }}; } TL;DR The complete, tested code is on GitHub . Here is the most important part: public class Geometry { public static final double EPSILON = 0.000001 ; /** * Calculate the cross product of two points. * @param a first point * @param b second point * @return the value of the cross product */ public static double crossProduct ( Point a , Point b ) { return a . x * b . y - b . x * a . y ; } /** * Check if bounding boxes do intersect. If one bounding box * touches the other, they do intersect. * @param a first bounding box * @param b second bounding box * @return <code>true</code> if they intersect, * <code>false</code> otherwise. */ public static boolean doBoundingBoxesIntersect ( Point [] a , Point [] b ) { return a [ 0 ]. x <= b [ 1 ]. x && a [ 1 ]. x >= b [ 0 ]. x && a [ 0 ]. y <= b [ 1 ]. y && a [ 1 ]. y >= b [ 0 ]. y ; } /** * Checks if a Point is on a line * @param a line (interpreted as line, although given as line * segment) * @param b point * @return <code>true</code> if point is on line, otherwise * <code>false</code> */ public static boolean isPointOnLine ( LineSegment a , Point b ) { // Move the image, so that a.first is on (0|0) LineSegment aTmp = new LineSegment ( new Point ( 0 , 0 ), new Point ( a . second . x - a . first . x , a . second . y - a . first . y )); Point bTmp = new Point ( b . x - a . first . x , b . y - a . first . y ); double r = crossProduct ( aTmp . second , bTmp ); return Math . abs ( r ) < EPSILON ; } /** * Checks if a point is right of a line. If the point is on the * line, it is not right of the line. * @param a line segment interpreted as a line * @param b the point * @return <code>true</code> if the point is right of the line, * <code>false</code> otherwise */ public static boolean isPointRightOfLine ( LineSegment a , Point b ) { // Move the image, so that a.first is on (0|0) LineSegment aTmp = new LineSegment ( new Point ( 0 , 0 ), new Point ( a . second . x - a . first . x , a . second . y - a . first . y )); Point bTmp = new Point ( b . x - a . first . x , b . y - a . first . y ); return crossProduct ( aTmp . second , bTmp ) < 0 ; } /** * Check if line segment first touches or crosses the line that is * defined by line segment second. * * @param first line segment interpreted as line * @param second line segment * @return <code>true</code> if line segment first touches or * crosses line second, * <code>false</code> otherwise. */ public static boolean lineSegmentTouchesOrCrossesLine ( LineSegment a , LineSegment b ) { return isPointOnLine ( a , b . first ) || isPointOnLine ( a , b . second ) || ( isPointRightOfLine ( a , b . first ) &#94; isPointRightOfLine ( a , b . second )); } /** * Check if line segments intersect * @param a first line segment * @param b second line segment * @return <code>true</code> if lines do intersect, * <code>false</code> otherwise */ public static boolean doLinesIntersect ( LineSegment a , LineSegment b ) { Point [] box1 = a . getBoundingBox (); Point [] box2 = b . getBoundingBox (); return doBoundingBoxesIntersect ( box1 , box2 ) && lineSegmentTouchesOrCrossesLine ( a , b ) && lineSegmentTouchesOrCrossesLine ( b , a ); } } Addendum Some notes for me: Writing Tests first is worth the effort. I guess it finally saved me some time and it gives me some confidence that my code works. I should update my system. I'm still using Ubuntu 10.04.4 LTS. Especially, I have Eclipse 3.5.2. This means I could not try EclEmma to test my code coverage â˜¹ LaTeX is great. I've created all images with LaTeX and it was quite fast after I got the first one. Here is the LaTeX source . edit: I now have a more modern system. So I was able to use EclEmma, which works fine. And I have 100% branch code coverage for this part of code â˜º","tags":"Code","title":"How to check if two line segments intersect"},{"url":"https://martin-thoma.com/how-to-create-a-digital-signature/","text":"At first, you have to write your signature on a white sheet of paper. You might have to make several tries: Some tries for a nice signature Then you should scan it in a high quality. Now crop the image to the size you like. I have used GIMP for this task: Crop the image to the correct section with GIMP Now you should have an image like this one: Cropped signature Inkscape Open it with Inkscape , click on the image go to the menu \"Path > Trace Bitmap\": Trace Bitmap in Inkscape Now choose \"Colors\", check \"Remove background\" and click on \"Update\": Trace Bitmap: Settings Close the window and look closely at the image. It should now look like this: Traced bitmap in Inkscape You have to click at a part of the image that is currently not selected and then hit the remove key. Now select the \"Edit path by nodes\" tool: Edit path by nodes Click on the gray area. The image will look like this: Remove nodes Remove nodes of areas that have to many or where you don't want to have this gray area. This will take some time. Some nodes you should remove As soon as you're finished, you should save your signature as SVG (if you want to edit it later) and as PDF (for LaTeX). LaTeX \\documentclass [a4paper,12pt] { article } \\usepackage { pdfpages } % needed for includepdf \\begin { document } \\section* { Some Text } Lorem ipsum dolor sit amet, pro discere accusam detraxit ei. Ei maluisset definitiones ius. Ut quo persius reprimique, sed ea postulant consulatu, essent tibique et cum. Usu ne etiam facilis, eam everti eruditi ea, his ad eros sententiae. Cu amet admodum recteque mei. Postea aeterno officiis pri in, per te quis numquam, ius ei veri consul. Ei sententiae constituam vix, ad quidam noster bonorum mel. Eu ius rebum disputationi, invenire signiferumque mei ea. Euripidis expetendis argumentum sit eu, viris latine persecuti mel at. Mel ut clita fabellas laboramus, an discere inermis est. Nulla liberavisse usu in. Augue comprehensam ut pro, ne vel dicit oblique. Vel dico omnium et, vis an tota solum argumentum. Eam omnes quidam in. Eu eam illum malorum diceret, nonumes mentitum repudiare eam et. \\\\ \\noindent Yours faithfully \\\\ \\\\ \\includegraphics [height=10mm] { max-mustermann-cropped-signature.pdf } \\\\ Max Mustermann \\end { document } Result The result looks like this: A signed document, created with LaTeX It looks even better if you make the image a little bit darker in the first step with GIMP.","tags":"Cyberculture","title":"How to create a digital signature"},{"url":"https://martin-thoma.com/cmos-circuits/","text":"CMOS is a technology used to create digital circuits. The basic idea is to combine a pMOS circuit and a nMOS circuit. MOSFET Four MOSFET are important for CMOS: nMOS pMOS depletion enhancement Inverter Inverter in CMOS technology NAND NAND gate in CMOS technology Images I tried to find good software to create those images. I didn't find any that allowed me to create those images. I've tried this: Cirkuit : Looks good, but crashes. EAGLE: too complex KLogic: seems only to be able to create logic plans PCB Designer: too complex, weird interface Anything else? Which other circuits do we have to know? (Perhaps Transmission Gate?)","tags":"Cyberculture","title":"CMOS circuits"},{"url":"https://martin-thoma.com/algorithmen-ii-klausur/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesungen des Moduls â€žAlgorithmen II\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Prof. Dr. Wagner gehÃ¶rt. Vorbereitung Themen : Netzwerke und FlÃ¼sse Wert eines Flusses, s-t-Schnitt (Minimale) Schnitte, erhÃ¶hende Wege Max-Flow Min-Cut Theorem Ford-Fulkerson-Algorithmus: ErhÃ¶hende Wege, VorwÃ¤rts- und RÃ¼ckwÃ¤rtskanten Spezialfall: Algorithmus von Edmonds und Karp KÃ¼rzeste erhÃ¶hende Wege Laufzeit: \\(\\mathcal{O}(|V| \\cdot |E&#94;2|)\\) Flussproblem als Lineares Programm DualitÃ¤t Algorithmus von Goldberg und Tarjan (Residualgraph, Push/Relabel) MINCOSTFLOW, erhÃ¶hende Kreise Cycle Canceling Algorithmus Algorithmus von Stoer & Wagner Kreise Definition: Kreis, einfacher Kreis Kreisbasen, Kreisraum Matroide Zertiï¬kat fur MCB Randomisierte Algorithmen Las Vegas Algorithmus / Monte Carlo Algorithmus Monte Carlo Algorithmus fÃ¼r MinCut Fast Random MinCut Maximum Satisï¬ability Problem Random MaxCut Maximum Satisï¬ability Problem IQP Algorithmische Geometrie Was ist ein einfaches Polygon, was ein konvexes Polygon? Sweep Line Algorithmus Konvexe HÃ¼lle: Graham Scan Gift Wrapping Algorithmus (Jarvis March) â†’ Code Golf String-Matching Rabin & Karp Endlichen Automaten Vorberechnungen fÃ¼r viele Suchanfragen: SuffixbÃ¤ume Suffixarray LCP -Array Approximierende Algorithmen Multiprozessor-Scheduling List Scheduling Algorithm Bin Packing Next Fit Algorithm First Fit Algorithm APAS Restricted Bin Packing APAS und FAPAS PAS FPAS Parametrisierte Algorithmen â†’ Wiki Fixed Parameter Tractable Kernbildung (Vertex Cover) Tiefenbeschrankte SuchbÃ¤ume Online Algorithmen Job Scheudling c-kompetitivitÃ¤t Ski-Verleih Beispiel Paging ( LFD , Kompetitive Paging-Algorithmen, Konservative Paging-Algorithmen , BÃ©lÃ¡dys Anomalie ) Parallele Algorithmen PRAM Modell Berechnung von Summen PrÃ¤fxsumme List Ranking Binaroperationen einer partitionierten Menge Zusammenhangskomponenten Minimaler Spannbaum Algorithmen fur externen Speicher Einfaches Rechnermodell Interner Stack / Externer Stack / Externe Warteschlange Multiway Merge Sort Tournament-BÃ¤ume Algorithmen und Laufzeiten Algorithmus Laufzeit Algorithmus von Ford und Fulkerson - Algorithmus von Edmonds und Karp $\\mathcal{O}(|V| \\cdot |E|&#94;2)$ Algorithmus von Stoer und Wagner $\\mathcal{O}(|V|&#94;3)$ oder besser, je nach Wahl des aktiven Knotens Algorithmus von Stoer und Wagner $\\mathcal{O}(|V|&#94;2 \\log |V| + |V| |E|)$ Algorithmus von Horton $\\mathcal{O}(|E|&#94;3 |V|)$ Algorithmus von de Pina $\\mathcal{O}(|E|&#94;3 + |E| |V|&#94;2 \\log |V|)$ Sweep-Line-Algorithmus $\\mathcal{O}(n \\cdot \\log n)$ Graham-Scan $\\mathcal{O}(n \\cdot \\log n)$ Gift-Wrapping (Jarvis' March) $\\mathcal{O}(h \\cdot n)$ Algorithmus von Rabin und Karp $\\mathcal{O}((n-m) \\cdot m)$ String-Matching-Automat Vorbereitung: $\\mathcal{O}(|\\Sigma| \\cdot m&#94;3)$ Matching: $\\mathcal{O}(n)$ Suffix-BÃ¤ume Vorbereitung: $\\mathcal{O}(n&#94;2)$ Matching: $\\mathcal{O}(m \\cdot \\log |\\Sigma|)$ Suffix-Arrays Vorbereitung: $\\mathcal{O}(n)$ Matching: $\\mathcal{O}(m \\cdot \\log |n|)$ KomplexitÃ¤tsklassen Die Klasse $\\mathcal{PP}$ (probabilistic polynomial) enthÃ¤lt alle Entscheidungsprobleme $\\Pi$, fÃ¼r die es einen polynomialen, randomisierten Algorithmus $A$ gibt, so dass fÃ¼r alle Instanzen $I$ von $\\Pi$ gilt: $ \\begin{cases} I \\in Y_\\Pi & Pr[A(I) \\text{ ist \"Ja\"}] \\ge \\frac{1}{2} \\\\ I \\notin Y_\\Pi & Pr[A(I) \\text{ ist \"Ja\"}] \\le \\frac{1}{2} \\end{cases}$ Die Klasse $\\mathcal{BPP}$ (bounded error PP) enthÃ¤lt alle Entscheidungsprobleme $\\Pi$, fÃ¼r die es einen polynomialen, randomisierten Algorithmus $A$ gibt, so dass fÃ¼r alle Instanzen $I$ von $\\Pi$ gilt: $ \\begin{cases} I \\in Y_\\Pi & Pr[A(I) \\text{ ist \"Ja\"}] \\geq \\frac{3}{4} \\\\ I \\notin Y_\\Pi & Pr[A(I) \\text{ ist \"Ja\"}] \\leq \\frac{1}{4} \\end{cases}$ Die Klasse $\\mathcal{RP}$ (randomisiert polynomial) enthÃ¤lt alle Entscheidungsprobleme $\\Pi$, fÃ¼r die es einen polynomialen, randomisierten Algorithmus $A$ gibt, so dass fÃ¼r alle Instanzen $I$ von $\\Pi$ gilt: $ \\begin{cases} I \\in Y_\\Pi & Pr[A(I) \\text{ ist \"Ja\"}] \\geq \\frac{1}{2} \\\\ I \\notin Y_\\Pi & Pr[A(I) \\text{ ist \"Ja\"}] = 0 \\end{cases}$ Es gilt: \\(\\mathcal{RP} \\subseteq \\mathcal{BPP} \\subseteq \\mathcal{PP}\\) Die Klasse $\\mathcal{NC}$ (Nick's Class) ist die Klasse der Probleme, die durch einen parallelen Algorithmus $A$ mit polylogarithmischer Laufzeit und polynomieller Prozessorenzahl gelÃ¶st werden kÃ¶nnen, d.h. $T_A(n) \\in \\mathcal{O}((\\log n)&#94;k_1)$ mit Konstante $k_1$ und $P_A(n) \\in \\mathcal{O}(n&#94;{k_2})$ mit Konstante $k_2$. Die Klasse $\\mathcal{SC}$ (Steve's Class) ist die Klasse der Probleme, die durch einen sequentiellen Algorithmus mit polylogarithmischem Speicherplatzbedarf und polynomieller Laufzeit gelÃ¶st werden kÃ¶nnen. ÃœbungsblÃ¤tter Ãœbungsblatt 1 , 06.02.2013: LÃ¶sung Amortisierte Laufzeitanalyse: Buchungsmethode Was ist ein Netzwerk? Was ist ein Fluss? Was sind die KapazitÃ¤tsbedingung und die Flusserhaltung? Ãœbungsblatt 2 , 13.02.2013: LÃ¶sung Wie bekommt man aus dem maximalen Fluss den minimalen Schnitt mit Push-Relabel? Berechnung eines Matchings mit hilfe eines MAX-FLOW-Algorithmus. Wie benutze ich den Algorithmus von Stoer und Wagner? Funktioniert fÃ¼r negative Kantengewichte nicht, z.B. Graph mit 3 Knoten und 2 negativen Kanten. Ãœbungsblatt 3 , 20.02.2013: LÃ¶sung Algorithmus von de Pina ausfÃ¼hren ( Vorlesung Nr 7 ) Einiges zu Kreisbasen Wie bekomme ich mit einem nicht-perfektem MÃ¼nzwurf eine 50%-Wahrscheinlichkeit? â†’ Antwort Ãœbungsblatt 4 , 20.02.2013: LÃ¶sung Wie finde ich heraus, ob sich zwei gegebene Strecken schneiden? â†’ Antwort Ãœbungsblatt 5 , 22.02.2013: LÃ¶sung Wie berechnet man den Suffix-Baum und das Suffix-Array von mississippi? â†’ Vorlesung Nr 13 Wie funktioniert der Rabin-Karp-Algorithmus zum String-Matching? Wie erstellt man einen String-Matching-Automaten? Ãœbungsblatt 6 , 24.02.2013: LÃ¶sung Welcher Algorithmus fÃ¼r Vertex Cover hat eine ApproximationsgÃ¼te von 2? Fakten und interessante Fragen Algorithmus ist konservativ $\\Rightarrow$ Algorithmus ist k-kompetitiv. (Quelle: Begleitmaterial zur Vorlesung Online-Algorihmen , Uni Dortmund) $c(S, V \\setminus S) := \\sum_{(i,j) \\in E,\\\\i \\in S, j \\in V \\setminus S} c(i,j)$ Was ist der Worst-Case fÃ¼r List Scheduling mit $m$ Maschinen? Gegeben seien $n \\cdot (m-1)$ Jobs Ã  1 Sekunde und ein Job mit $n$ Sekunden. Die Gesamtlaufzeit betrÃ¤gt dann $2 \\cdot n - 1$ Sekunden, die beste Laufzeit ist jedoch $n$ Sekunden. Was ist der Worst-Case fÃ¼r Next Fit ? $n$ Elemente mit dem Gewicht $\\frac{1}{2}$ und $2n$ Elemente mit dem Gewicht $\\frac{1}{2}$ und $2n$ Elemente mit dem Gewicht $\\frac{1}{2 \\cdot n}$. Termine und Klausurablauf Datum : Freitag, den 1. MÃ¤rz 2013 von 11:00 bis 13:00 ( Quelle ) Ort : Tulla-HÃ¶rsaal (Siehe Liste ) Dauer : 2 Stunden Punkte : 60 Bestehensgrenze : 20 Ãœbungsschein : Gibt es nicht. Bonuspunkte : Gibt es nicht. Nicht vergessen : Studentenausweis Kugelschreiber Ergebnisse Der Termin fÃ¼r die Klausureinsicht ist noch nicht bekannt (Stand: 01.03.2013) Seit heute (07.03.2013) sind die Ergebnisse da: Ergebnisse MusterlÃ¶sung Termin der Einsicht ist noch nicht bekannt (Stand: 07.03.2013) Update vom 09.03.2013: Einsicht ist am Dienstag, den 19. MÃ¤rz von 15:00 bis 17:00 Uhr und am Donnerstag, den 4. April von 15:00 bis 17:00 jeweils in Raum 301 im Infobau 50.34 Algorithmen II - Ergebnis-Statistik","tags":"German posts","title":"Algorithmen II - Klausur"},{"url":"https://martin-thoma.com/what-can-arraylist-linkedlist-do-what-list-cant/","text":"I've told my students to write List < MyClass > myList = new ArrayList < MyClass >(); instead of ArrayList < MyClass > myList = new ArrayList < MyClass >(); as this allows them to switch to any Class that implements List without having to change more code. This does always make sense, except if you need methods from ArrayList or LinkedList. But which methods does ArrayList / LinkedList offer that List doesn't have? ArrayList has: Object clone() void ensureCapacity(int minCapacity) void removeRange(int fromIndex, int toIndex) void trimToSize() LinkedList has: void addFirst(E e) void addLast(E e) Object clone() Iterator descendingIterator() E getFirst() E getLast() boolean offer(E e) boolean offerFirst(E e) boolean offerLast(E e) E peek() E peekFirst() E peekLast() E poll() E pollFirst() E pollLast() E pop() void push(E e) E removeFirst() boolean removeFirstOccurrence(Object o) E removeLast() boolean removeLastOccurrence(Object o)","tags":"Code","title":"What can ArrayList / LinkedList do what List can't?"},{"url":"https://martin-thoma.com/basic-multithreading-in-java/","text":"A lot of computing power is wasted in many programs as most programs use only one core. If your program is computation intensive, you might want to put some extra effort in your program and make use of this wasted computing power. There are two ways to execute your code on multiple cores: Multiprocessing and multithreading. Both, processes and threads, provide the possibility to execute code sequences independently and concurrently. But where is the difference? When you execute code in multiple processes , the operating system handles the scheduling. It decides when which process gets executed and tries to find an optimal order. Every process has its own memory segment. A process is sometimes also called \"kernel level thread\". When you execute code in multiple threads , all threads have one process they belong to (see Multi-Threading models , also from Java ). Every set of threads that have the same process share their memory. In Java, you will use multithreading most of the time. I will only write about multithreading, but you can create multiple processes wiht ProcessBuilder . Java Basics for Multithreading All important lessons you need to learn are covered in Java Concurrency Tutorial . If you're really interested in multithreading, you should read this. You can put the part that can get executed concurrently in a separate class that implements the interface Runnable . This class has a method called run(). You can create a new Thread(Runnable) by calling start() . Here is an example: Sum public class Sum implements Runnable { private final int UpperEnd ; public Sum ( int upperEnd ) { UpperEnd = upperEnd ; } @Override public void run () { for ( int i = 0 ; i < UpperEnd ; i ++) { RaceCondition . bigSum ++; } } } Main import java.util.ArrayList ; import java.util.List ; public class Main { public static int BIG_NR ; public static int NR_THREADS ; public static long bigSum ; public static void main ( String [] args ) { if ( args . length < 2 ) { System . err . println ( \"You should specify the number \" + \"of threads and BIG_NR. Call me like this:\\n\" + \"java -jar RaceCondition.jar 5 20000\\n\" + \"This will create 5 Threads which try to count\" + \"up to 2000000.\\n\" + \"-v will show status \" + \"information \" ); return ; } boolean verbose = false ; if ( args . length > 2 ) { verbose = true ; } NR_THREADS = Integer . parseInt ( args [ 0 ]); BIG_NR = Integer . parseInt ( args [ 1 ]); List < Thread > threads = new ArrayList < Thread >(); for ( int i = 0 ; i < NR_THREADS ; i ++) { Runnable task = new Sum ( BIG_NR ); Thread worker = new Thread ( task ); worker . start (); threads . add ( worker ); } int running = 0 ; do { running = 0 ; for ( Thread thread : threads ) { if ( thread . isAlive ()) { running ++; } } if ( verbose ) { System . out . println ( \"Remaining threads: \" + running ); } } while ( running > 0 ); System . out . println ( RaceCondition . bigSum ); } } Call it like this: java Main 5 2000 Race Conditions When you execute the code above, the output will vary. Why is this the case? In short: The execution order is not defined and RaceCondition.bigSum++ is not atomic. Let's imagine that you call this with two threads only: java Main 2 2000 Now you could get this execution order: Thread 1: Loads RaceCondition.bigSum . It is 0. Thread 2: Executes completely. Now RaceCondition.bigSum is 2000 Thread 1: Increases the loaded value of RaceCondition.bigSum by 1. Now it is 1. Thread 1: Finishes it's execution. The Value of RaceCondition.bigSum is 2000 = BIG_NR. Ok, we can obviously get values in \\([\\text{BIG}\\_\\text{NR}, \\text{NR}\\_\\text{THREADS} \\cdot \\text{BIG}\\_\\text{NR}]\\) . Can we get smaller values? Yes, we can! Execute: java Main 50 20000 Thread 1 loads bigSum . It's 0. Thread 2 loads bigSum . It's 0. Thread 3 - 50 execute completely. Thread 2 executes until it is at the latest bigSum++ . The latest doesn't execute. Thread 1 increases the loaded value from 0 to 1 and writes 1 back Thread 2 loads bigSum = 1 Thread 1 executes and finishes. Thread 2 increases the loaded value from 1 to 2 and writes 2 back. You can get all values in \\([2, \\text{NR}\\_\\text{THREADS} \\cdot \\text{BIG}\\_\\text{NR}]\\) ! Usually, you don't want to get different results when you give the same input to your program. How can you fix this? Take a look at AtomicLong and replace the long bigNr by the AtomicLong bigNr . Playing with BASH If you want to execute this more often, you could save it as a executable JAR and execute the following bash script. It takes three arguments: \\(1: The number of times you execute a the program with a fixed number of THREADS</li> <li>\\) 2: The maximum number of THREADS you would like to use $3: BIG_NR The script executes the program \\($1 \\cdot $2\\) times. The output gets divided by the number of threads and the result is saved in raceCondition.tmp. Every line is one execution of the program. When the second number is BIG_NR, then no race conditions occured. rm raceCondition.tmp touch raceCondition.tmp # Up to $2 threads for (( threads = 1 ; threads< = $2 ; threads++ )) do for (( c = 1 ; c< = $1 ; c++ )) do # $threads threads, count up to $3 in each thread thisExecutionSum = ` java -jar RaceCondition.jar $threads $3 ` # Normalize: thisExecutionSum / number of threads normalizedSum = ` awk -vsome = $thisExecutionSum -vtotal = $threads 'BEGIN { printf(\"%d\\n\", some/total); exit } ' ` echo -e $threads \"\\t\" $normalizedSum >> raceCondition.tmp done done","tags":"Code","title":"Basic Multithreading in Java"},{"url":"https://martin-thoma.com/flipflops-und-latches/","text":"Flipflops und Latches sind 1-bit Datenspeicher. Es gibt sie als synchrone und als asynchrone Varianten, wobei â€žsynchron\" nur bedeutet, dass das Bauteil zusÃ¤tzlich einen Takteingang hat. Der wichtigste (und einzige?) Unterschied zwischen Flipflops und Latches ist, dass Flipflops Taktflankengesteuert sind und Latches Pegelgesteuert sind. Das heiÃŸt, Flipflops kÃ¶nnen nur dann ihren Wert Ã¤ndern, wenn der anliegende Takt von 0 auf 1 wechselt. Latches hingegen kÃ¶nnen ihren Wert immer Ã¤ndern, wenn der anliegende Takt auf 1 ist. Beide haben die gleichen Ansteuertabellen, kÃ¶nnen aber unterschiedliche Zeitdiagramme haben. Interesannt sind vor allem die Ansteuertabellen. Dabei darf man sich nicht von der Art, wie diese aufgeschrieben werden, verwirren lassen: \\(q&#94;t\\) ist der Zustand des Flipflops zum Zeitpunkt \\(t\\) . Analog dazu ist \\(q&#94;{t+1}\\) der Zustand des Flipflops zum Zeitpunkt \\(t+1\\) . Nun steht rechts in der Tabelle, welche Signale man braucht um den Zustand \\(q&#94;{t+1}\\) zu erreichen, wenn man im Zustand \\(q&#94;t\\) ist. D-Latch D-Flipflop D-Flipflops D-Flipflops ignorieren im Prinzip den aktuellen Zustand und setzt den neuen Zustand einfach auf das d-Signal. D-Flipflops kÃ¶nnen aus D-Latches erstellt werden: D-Flipflop Ansteuertabelle $q&#94;t$ $q&#94;{t+1}$ $d&#94;t$ 0 0 0 0 1 1 1 0 0 1 1 1 D-Flipflop mit Eingang D, unbennanten Takt und Ausgang Q sowie Q negiert. RS-Flipflops Das RS-Flipflop bietet zwei MÃ¶glichkeiten: Entweder man resettet es, dann wird der neue Zustand 0, oder man setzt es. Dann ist der neue Zustand 1. Ein RS-Flipflop hat zwei EingÃ¤nge und einen oder zwei AusgÃ¤nge. Ansteuertabelle $q&#94;t$ $q&#94;{t+1}$ $r&#94;t$ $s&#94;t$ 0 0 - 0 0 1 0 1 1 0 1 0 1 1 0 - RS-Flipflop T-Flipflop T-Flipflops wechseln den Zustand, wenn T gesetzt ist. Ansteuertabelle $q&#94;t$ $q&#94;{t+1}$ $T&#94;t$ 0 0 0 0 1 1 1 0 1 1 1 0 T-Flipflop mit Eingang T, unbenanntem Taktsignal, Ausgang Q und dem negiertem Ausgang Q. JK-Flipflop JK-Flipflops haben zwei EingÃ¤nge, â€žJ\" und â€žK\". Warum die allerdings Jump und Kill genannt werden, ist mir nicht klar. Habt ihr eine Merkregel fÃ¼r die Ansteuertabelle dieses Flipflops? Ansteuertabelle $q&#94;t$ $q&#94;{t+1}$ $j&#94;t$ $k&#94;t$ 0 0 0 - 0 1 1 - 1 0 - 1 1 1 - 0 JK-Flipflop","tags":"German posts","title":"Flipflops und Latches"},{"url":"https://martin-thoma.com/das-consensus-verfahren/","text":"Mithilfe des Consensus-Verfahrens kÃ¶nnen Primimplikanten gefunden werden. Dazu braucht man eine Schaltfunktion \\(f:\\{0,1\\}&#94;n \\rightarrow \\{0,1\\}\\) in disjunktiver Normalform (DNF). Zu betonen ist, dass man keine Minimalform bekommt, da das Ãœberdeckungsproblem noch gelÃ¶st werden muss. Dies kann man z.B. mit der zweiten Quineschen Tabelle machen. Dazu baut man eine Tabelle auf. Ich nenne sie mal Consensus-Tabelle. Diese hat 4 Spalten: Nr. Gebildet aus WÃ¼rfel - eine Spalte fÃ¼r jeden der \\(n\\) Parameter der Schaltfunktion \\(f\\) Gestrichen wegen Nun ergibt jeder Minterm der DNF eine Zeile in der Consensus-Tabelle. Die Reihenfolge ist dabei egal. Die Nr. wird fortlaufend von 1 an gesetzt, die Spalte â€žGebildet aus\" bleibt erst mal leer. Nun zieht man eine Linie, um die folgenden Zeilen abzutrennen. Diesen abgetrennten Teil nennen ich nun â€žBlock\". Man vergleicht nun jede Zeile mit den darÃ¼ber liegenden Zeilen. : Falls an einer bestimmten Stelle nur eine der Zeilen ein don't care hat, wird an dieser Stelle der Wert der anderen Zeile genommen. Diese Spalte zÃ¤hlt also nicht als unterschiedlich. Unterscheiden sich zwei Zeilen nur an einer Stelle, schreibt man eine neue Zeile in den neuen Block. Diese Zeile hat ein don't care an der Stelle, an der sich die beiden Zeilen unterschieden, eine eigene Nummer. Eventuell Ã¼berdeckt die neue Zeile beide vorhergehenden. Wegen der don't care-Regelung ( ) muss das jedoch nicht der Fall sein. Sobald man alle Zeilen des vorhergehenden Block Ã¼berprÃ¼ft hat, kann man wieder eine Linie machen. Das sieht dann etwa so aus (aus Folien von Prof. Dr. Asfour): Consensus-Verfahren Wie man sieht, kann es auch sein, dass eine neue Zeile bereits von einer alten Ã¼berdeckt wird. Diese Zeilen kann man also direkt streichen. Sobald man keine neuen Zeilen / BlÃ¶cke mehr bilden kann, ist man fertig. Die Zeilen, die nicht gestrichen wurden, sind Primimplikanten. Code Ich finde Algorithmen werden am eindeutigsten durch Implementierungen beschrieben. Hier ist meine fÃ¼r das Consensus-Verfahren: #!/usr/bin/python # -*- coding: utf-8 -*- def initDatastructure ( terme ): dictList = [] for nr , term in enumerate ( terme ): dictList . append ({ 'number' : nr + 1 , 'gebildet' : '' , 'term' : term , 'gestrichen' : False }) return dictList ''' check if item1 and item2 differ in at least one digit ''' def hasComplementaryDigit ( item1 , item2 ): term1 = item1 [ 'term' ] term2 = item2 [ 'term' ] for i in range ( len ( term1 )): if ( term1 [ i ] == '1' and term2 [ i ] == '0' ) or \\ ( term1 [ i ] == '0' and term2 [ i ] == '1' ): return True return False ''' check if item1 and item2 have a consensus term ''' def hasConsensus ( item1 , item2 ): term1 = item1 [ 'term' ] term2 = item2 [ 'term' ] differences = 0 for i in range ( len ( term1 )): if ( term1 [ i ] != term2 [ i ]) and ( term1 [ i ] != '-' ) and ( term2 [ i ] != '-' ): differences += 1 return differences <= 1 ''' create the consensus term of two items ''' def getConsensus ( item1 , item2 ): term1 = item1 [ 'term' ] term2 = item2 [ 'term' ] consensus = '' for i in range ( len ( term1 )): if term1 [ i ] == term2 [ i ]: consensus += term1 [ i ] elif ( term1 [ i ] != term2 [ i ]) and ( term1 [ i ] != '-' ) and ( term2 [ i ] != '-' ): consensus += '-' elif ( term1 [ i ] != term2 [ i ]) and ( term1 [ i ] != '-' ): consensus += term1 [ i ] else : consensus += term2 [ i ] return consensus def isIncludedIn ( bigger , smaller ): for i in range ( len ( bigger )): if bigger [ i ] != '-' and bigger [ i ] != smaller [ i ]: return False return True def consensusIsIncludedIn ( dictList , consensus ): for element in dictList : if element [ 'gestrichen' ] == False and \\ isIncludedIn ( element [ 'term' ], consensus ): return element [ 'number' ] return False def printList ( dictList , horizontalLinesAfter ): print ( 'Nr \\t Gebildet aus \\t W&uuml;rfel \\t Gestrichen wegen' ) for line , element in enumerate ( dictList ): if element [ 'gestrichen' ] == False : element [ 'gestrichen' ] = '' if element [ 'number' ] == False : element [ 'number' ] = '' print ( ' %s \\t\\t %s \\t %s \\t %s ' % ( element [ 'number' ], element [ 'gebildet' ], element [ 'term' ], element [ 'gestrichen' ])) if line in horizontalLinesAfter : print ( '-' * 50 ) def consensus ( terme ): dictList = initDatastructure ( terme ) horizontalLinesAfter = [ len ( dictList ) - 1 ] pointer2 = 1 nextNumber = len ( dictList ) + 1 while pointer2 != ( len ( dictList ) - 1 ): if pointer2 > horizontalLinesAfter [ - 1 ]: horizontalLinesAfter . append ( len ( dictList ) - 1 ) if dictList [ pointer2 ][ 'gestrichen' ] != False : pointer2 += 1 continue for pointer1 in range ( pointer2 - 1 , - 1 , - 1 ): if dictList [ pointer1 ][ 'gestrichen' ] != False : continue elif not hasComplementaryDigit ( dictList [ pointer1 ], dictList [ pointer2 ]): continue elif not hasConsensus ( dictList [ pointer1 ], dictList [ pointer2 ]): continue consensus = getConsensus ( dictList [ pointer1 ], dictList [ pointer2 ]) # Wird der neue Konsensus-Term eventuell bereits &uuml;berdeckt? gestrichen = consensusIsIncludedIn ( dictList , consensus ) if gestrichen == False : nr = nextNumber nextNumber += 1 else : nr = False # Kann dank dem neuen Consensus-Term etwas gestrichen werden? if gestrichen == False : for element in dictList : if element [ 'gestrichen' ] == False and \\ isIncludedIn ( consensus , element [ 'term' ]): element [ 'gestrichen' ] = nr dictList . append ({ 'number' : nr , 'gebildet' : str ( dictList [ pointer2 ][ 'number' ]) + ', ' + str ( dictList [ pointer1 ][ 'number' ]), 'term' : consensus , 'gestrichen' : gestrichen }) pointer2 += 1 printList ( dictList , horizontalLinesAfter ) consensus ([ '-0-00' , '--00-' , '-1-00' , '010-1' , '1-11-' , '110-1' ]) #consensus(['-00-', '-011', '0100']) Ausgabe: Nr Gebildet aus W&uuml;rfel Gestrichen wegen 1 -0-00 7 2 --00- 3 -1-00 7 4 010-1 9 5 1-11- 6 110-1 9 -------------------------------------------------- 7 3, 1 ---00 8 6, 5 11-11 9 6, 4 -10-1 -------------------------------------------------- 10 7, 5 1-1-0 8, 2 110-1 9 9, 7 -100- 2 9, 5 11-11 8 -------------------------------------------------- 10, 8 1111- 5 10, 2 1--00 7 -------------------------------------------------- Quellen Die Folien von Dr. Asfour (DT-VL12) sowie die Vorlesung (auf YouTube verfÃ¼gbar. Der interessante Teil beginnt erst sehr spÃ¤t.). Es wurde sogar spÃ¤ter nochmals von Herrn Prof. Dr. Asfour erklÃ¤rt .","tags":"German posts","title":"Das Consensus-Verfahren"},{"url":"https://martin-thoma.com/das-quine-mccluskey-verfahren/","text":"Das Quine-McCluskey-Verfahren wird angewendet, wenn man eine Schaltfunktion minimieren will. Es muss also eine Schaltfunktion gegeben sein. Es sollte eigentlich zusÃ¤tzlich Kostenfunktion gegeben sein, aber meist ist das nicht der Fall. Verfahren Gegeben : Eine Schaltfunktion \\(f:\\{0,1\\}&#94;n \\rightarrow \\{0,1\\}, \\; n \\in \\mathbb{N}\\) Schritt 1: Aufstellen der Funktionstabelle. Sie hat die Spalten â€žNr.\", die bei 0 beginnt und bis \\(2&#94;n - 1\\) geht. Eine Spalte pro Funktionsparameter (z.B. \\(a, b, c, ...\\) ) Eine Spalte fÃ¼r den Funktionswert \\(f(a,b,c,...)\\) Schritt 2 : Aufstellen der ersten Quinesche Tabelle 0ter Ordnung. Sie hat die Spalten â€žNr.\" Eine Spalte pro Parameter â€žâœ“\" (HÃ¤kchen) In der ersten Quineschen Tabelle stehen nur noch die Zeilen, deren Funktionswert 1 ist. Das sind die sogenannten Minterme. ZusÃ¤tzlich sind sie nach Anzahl der 1er geordnet. Schritt 3 : \\(i\\) -tes Zusammenfassen Nun erstellt man die erste Quinesche Tabelle \\(i\\) -ter Ordnung. Also beim ersten mal erster Ordnung, beim zweiten Mal zweiter Ordnung, ... Diese Tabellen haben alle die gleichen Spalten und die Zeilen-Anzahl kann sowohl wachsen als auch schrumpfen. Das \\(i\\) gibt dabei die Anzahl der â€ždon't care\" Stellen an, also der Stellen die sowohl 0 als auch 1 sein kÃ¶nnen. Um aus der ersten Quinesche Tabelle \\((i-1)\\) -ter Ordnung die rsten Quinesche Tabelle \\(i\\) -ter Ordnung zu erstellen, geht man wie folgt vor: Vergleiche alle Zeilen, in denen sich die Anzahl der 1er um genau 1 unterscheidet: Unterscheiden sich Zeile Nr. x und Zeile Nr. y an nur einer Stelle, so schreibe in die Tabelle \\(i\\) ter Ordnung eine neue Zeile. Die Nummer dieser Zeile ist â€žx, y\" und sie hat an der Stelle, an der sich die Zeilen x und y unterschieden, ein don't care. Hake die Zeilen x und y in der Tabelle \\((i-1)\\) -ter Ordnung ab Es ist mÃ¶glich, das Zeilen nicht abgehakt werden, weil sie sich mit keiner Zeile zusammenfassen lassen. Das ist ok. Sobald in einem Schritt keine Zusammenfassung mehr mÃ¶glich ist, ist man hier fertig. Falls noch eine MÃ¶glich ist, geht man wieder in Schritt 3. Nun schreibt man alle Zeilen auf, die nicht abgehakt sind. Das sind die Primimplikanten. Schritt 4 : Aufstellen der zweiten Quineschen Tabelle Die zweite Quinesche Tabelle (auch Ãœberdeckungstabelle genannt) hat folgende Spalten: Primimplikanten Eine Spalte pro Minterm. Die Beschriftung ist dabei eine Nr. Eine Spalte â€žKosten\" Nun macht man in den Zellen ein Kreuz, in denen der Primimplikant den Minterm abdeckt (also wenn die Nr. im Namen des Minterms vorkommt). Die Kosten muss man pro Primimplikant berechnen. Schritt 5 : Vereinfachen der zweiten Quineschen Tabelle Dieser Schritt erinnert mich irgendwie an Sudoku. Zeilendominanz : Hat eine Zeile a nur x-e an Stellen, wo auch eine andere Zeile b x-e hat und ist Zeile b nicht teurer als a, so kann Zeile a gestrichen werden. Also: Es wird die Zeile mit weniger x gestrichen Spaltendominanz : Ãœberdeckt eine Spalte eine andere Spalte mit ihren x-en, so kann die Spalte mit mehr x-en gestrichen werden. Schritt 6 : Identifizieren von Kernprimimplikanten. Wenn eine Zeile als einzige an einer bestimmten Spalte ein x hat, ist der zugehÃ¶rige Primimplikant ein Kernprimimplikant. Er muss auf jeden Fall in der Minimalform vorkommen. Diesen schreibt man sich also auf, Streicht die Zeile und alle Spalten, an denen der Kernprimimplikant ein x hatte. Dann geht man zurÃ¼ck zu Schritt 5. Gab es keinen Kernprimimplikanten, geht man zu Schritt 7. Schritt 7 : Handarbeit Ich muss mal nach einem Beispiel suchen, aber ich glaube es ist mÃ¶glich, dass man die zweite Quinesche Tabelle ab einem gewissen Punkt nicht mehr vereinfachen kann, aber dennoch Zeilen und Spalten Ã¼brig sind. Dann muss man â€ždurch scharfes Hinsehen\" (also Brute-Force) die Minimalform finden, oder? Hier bin ich mir nicht ganz sicher. Beispiele Die folgende Aufgabe ist vom Ãœbungsblatt 7 (WS 2012/2013). Herr Terlemez hat mir freundlicherweise erlaubt, sie hier verwenden zu dÃ¼rfen. (Die offiziellen Aufgaben und LÃ¶sungen sind passwortgeschÃ¼tzt.) Aufgabe : Gegeben sei die Schaltfunktion \\(g(d,c,b,a) := dc \\bar b a \\lor d \\bar c ba \\lor d \\bar c \\bar b a \\lor \\bar d ca \\lor dcb\\) Bestimmen Sie alle Primimplikanten von $g$ mit Hilfe der 1. Quineschen Tabelle des Quine-McCluskey-Verfahrens. Geben Sie die Ãœberdeckungstabelle (2. Quinesche Tabelle) fÃ¼r die gefundenen Primimpikanten an (ohne Vereinfachung). Lesen Sie eine disjunktive Minimalform von $g$ ab. LÃ¶sung : (Habe gerade leider keine Zeit, diese abzutippen. Kommt vielleicht noch.) Handschriftliche LÃ¶sung der Aufgabe 7.2.1 aus DT Handschriftliche LÃ¶sung der Aufgabe 7.2.2 aus DT Quellen Ich habe diesen Artikel mit meinem Wissen aus den Folien (DT-VL12), der Vorlesung und dem Tutorium erstellt.","tags":"German posts","title":"Das Quine-McCluskey-Verfahren"},{"url":"https://martin-thoma.com/ti-klausur-dt-ro/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesungen â€žDigitaltechnik und Entwurfsverfahren\" sowie â€žRechnerorganisation\" des Moduls â€žTechnische Informatik\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr. Asfour gehÃ¶rt. Vorbereitung DT Themen : Zahlensysteme: Horner-Schema, Euklidischer Algorithmus Zahlendarstellungen: Wie wandle ich eine Zahl von 10-er-System ins Zahlensystem xy um und umgekehrt? Vorzeichen Betrag-Vorzeichen â†’ Antwort Einer-Komplement â†’ Antwort Zweier-Komplement â†’ Antwort Exzess-q â†’ Antwort Komma Festkomma â†’ Beispiele Gleitkomma â†’ Beispiele ( \\(\\pm \\text{Mantisse} \\cdot b&#94;\\text{Exponent}\\) ) IEEE 754 Format A practical approach to floats Wie wird NaN dargestellt? Wie wird \\(-\\infty\\) und \\(+\\infty\\) dargestellt? Was ist eine normalisierte Zahl, was eine denormalisierte? Was ist BCD , AIKEN und STIBITZ ? Wie werden die Ziffern von 0 - 9 dort dargestellt? Was sind Hamming-Codes? â†’ Antwort Wie lauten die Huntingtonschen Axiome? â†’ Antwort Nenne 3 verschiedene vollstÃ¤ndige Operatorensysteme. â†’ Antwort Was sind Primterme, Primimplikanten, Primimplikate, Minterme und Maxterme? Was sind DMF, DNF, KMF, KNF? Wie wende ich die Shannon-Zerlegung an? â†’ Antwort Wie minimiere ich Funktionen mit KV-Diagrammen? Wie funktioniert das Quine-McCluskey Verfahren? â†’ Antwort Was macht das Consensus-Verfahren? â†’ Antwort Wie funktioniert das Nelson-Verfahren? Was bedeutet selbstleitend und selbstsperrend? Was ist MOSFET ? â†’ Aufbau CMOS , N-MOS, P-MOS Was ist der Unterschied zwischen einem Hasard und einem Hasard-Fehler? Woran erkennt man Funktionshasards, woran Strukturhasards? Wie lauten die Ansteuertabellen von D-, T-, JK- und RS-Flipflops? â†’ Antwort Was macht ein Carry-ripple-Addierer? â†’ Antwort Inwiefern stellt der Carry-lookahead-Addierer eine Verbesserung des Carry-ripple-Addierers dar? â†’ Antwort Was macht man, wenn bei der Addition zweier BCD-Zahlen eine Pseudotetrade auftritt? â†’ Antwort Was macht man, wenn bei der Addition zweier BCD-Zahlen ein Ãœbertrag in die nÃ¤chste BCD-Ziffer auftritt? â†’ Antwort Was macht man, wenn bei der Addition zweier BCD-Zahlen bei der Korrekturaddition ein Ãœbertrag auftrat? â†’ Antwort Was ist die PPS-Methode? â†’ Antwort Vorbereitung RO Themen : Y-Diagramm Aufbau eines Mikroprozessors Umrechnen von Zahlensystemen RAM-Typen (DRAM, FPM-DRAM, EDO-RAM, SDRAM, DDRAM, DDR-SDRAM, RDRAM) Cache-Speicher Begriffe Was sind Tristate-Treiber? â†’ Antwort Was ist der Unterschied zwischen Assembler , Maschinensprache und Mikrobefehlen? WofÃ¼r stehen RISC und CISC und was sind Beispiele? â†’ Antwort Was ist ein User/System Bit, was ein Trace Bit und was ein Decimal bit? â†’ Antwort Welche Informationen kÃ¶nnen im Statusregister des Rechnewerkes stehen? â†’ Antwort Welche Informationen kÃ¶nnen im Akkumulator stehen? â†’ Antwort Warum benÃ¶tigt die ALU Hilfsregister? â†’ Antwort Entspricht das logische Rechtsschieben der Division durch zwei? â†’ Antwort Was ist ein superskalarer Prozessor? â†’ Antwort Was ist ein little Endian und was ist big Endian? â†’ Antwort Was versteht man unter dem Nulladressformat? â†’ Antwort Was ist eine â€žeffektive Adresse\"? â†’ Antwort Was bedeutet ZF , CF , SF , OF und wozu sind sie jeweils gut? Was ist eine Load/Store-Architektur? â†’ Antwort Was sind die fÃ¼nf Schritte in der DLX-Pipeline-Verarbeitung? â†’ Antwort In welcher Pipeline-Phase werden die Operanden aus dem memory geholt? â†’ Antwort Durch welche AbhÃ¤ngigkeiten entstehen VerzÃ¶gerungen in der DLX-Pipeline und wann treten diese auf? â†’ Antwort Was ist eine echte DatenabhÃ¤ngigkeit, was eine GegenabhÃ¤ngigkeit und was eine AusgabeabhÃ¤ngigkeit? â†’ Antwort Was ist eine falsche AbhÃ¤ngigkeit? â†’ Antwort Treten bei echten AbhÃ¤ngigkeiten immer Konflikte auf? â†’ Antwort Welche Konflikte gibt es und wann kÃ¶nnen sie auftreten? â†’ Antwort Welche AbhÃ¤ngigkeiten kÃ¶nnen bei der DLX-Pipeline zu Konflikten fÃ¼hren? â†’ Antwort Wie kann man Datenkonflikte durch Software lÃ¶sen? â†’ Antwort Wie kann man Datenkonflikte durch Hardware lÃ¶sen? â†’ Antwort Nennen Sie ein Beispiel fÃ¼r einen Konflikt, der nicht durch Forwarding lÃ¶stbar ist? â†’ Antwort Wie kann man Ressourcenkonflikte lÃ¶sen? â†’ Antwort Was bedeutet t RAC , t RC , t CAC und t PC ? Wie versteht man unter Bus-SchnÃ¼ffeln? â†’ Antwort MIPS Befehlsformate MIPS Befehlsformate Quelle: Folien von Prof. Dr. Asfour Typ-R Befehle sind arithmetisch-logische Befehle wie add, sub, and, or sowie Vergleichsbefehle wie slt . Typ-I Befehle sind Lade- und Speicherbefehle sowie Verzweigungsbefehle: lw \\(rt, imm(\\) rs) sw \\(rt, imm(\\) rs) beq $rs, $rt, immediate : Hier wird immediate als 16-Bit vorzeichenbehaftete Zahl interpretiert und als Offset benutzt. Die Basisadresse ist dabei im PC. Also lautet die Zieladresse: (PC zum Zeitpunkt des Befehls + 4) + immediate Grundlegende Befehle Syntax ErklÃ¤rung li $t0, 9 load immediate: LÃ¤dt eine Konstante in ein Register sll $rd, $rd, shamt shift left logical: $rd = $rs << shamt ble Rsrc1, Src2, label Branch on Less Than Equal: Rsrc1 â‰¤ Src2 bne $rs, $rt, imm Branch on not equal: if($rs!=$rt) PC = PC + imm (imm could also be a label) slti $rt, $rs, imm Store less than immediate: if($rs < imm) {$rt = 1;} else {$rt = 0} la Rdest, address Load computed address, not the contents of the location, into register Rdest MiMa Mikrobefehlsformat der MiMa Quelle: Folien von Prof. Dr. Asfour Fetch-Phase In der Fetch-Phase muss das die neue Instruktion ins IR geladen werden und der PC um eins erhÃ¶ht werden: Takt: IAR â†’ SAR; IAR â†’ X; R = 1 Takt: Eins â†’ Y; ALU auf addieren; R = 1 Takt: ALU auf addieren; R = 1 Takt: Z â†’ IAR Takt: SDR â†’ IR Das zugehÃ¶rige Mikroprogramm ist: 0010 0001 0000 1000 1000 0000 0001 0001 0100 0000 0000 1000 0000 0010 0000 0000 0000 0001 1000 0000 0011 0000 1010 0000 0000 0000 0000 0100 0000 0000 1001 0000 0000 0000 0101 Fragen Zeichnen Sie ein Y-Diagramm. Y-Diagramm Quelle: Folien von Prof. Dr. Asfour Wie ist ein Von-Neumann-Rechner aufgebaut? Von-Neumann-Architektur Das Steuerwerk wird auch â€žLeitwerk\" genannt, das Rechenwerk auch â€ž A rithmetic L ogic U nit\". Der BUS beinhaltet Adress-, Daten- und Steuerleitungen. Im Gegensatz zur Harvard-Architektur wird beim Speicher in der Von-Neumann-Architektur nicht zwischen Daten und Programmen unterschieden. Wie ist ein Mikroprozessor aufgebaut? Aufbau eines Mikroprozessors Quelle: Folien von Prof. Dr. Asfour Aus welchen Phasen besteht die BefehlsausfÃ¼hrung? Holphase Dekodierphase AusfÃ¼hrungsphase Warum gibt es mehr als ein Befehlsregister? Die Befehlsformate sind unterschiedlich lang Opcode-Prefetching Was ist der Unterschied zwischen BCD in gepackter Darstellung und BCD in ungepackter Darstellung? Bei BCD in gepackter Darstellung werden in einem Byte (8 Bit) zwei BCD-Zahlen dargestellt. In der ungepackten Darstellung wird in einem Byte nur eine BCD-Zahl dargestellt. Pipeline-Konflikte: Welche Forwarding-Techniken gibt es und wie werden sie umgesetzt? Forwarding-Techniken Quelle: Quelle: Folien von Prof. Dr. Asfour Welche Halbleiterspeichertypen gibt es? Klassifizierung von Halbleiterspeicher Skizzieren Sie eine SRAM-Zelle. CMOS SRAM Zelle Wie unterscheiden sich RISC- und CISC-Architekturen? CISC RISC Komplexe Befehle, die in mehreren Taktzyklen ausgefÃ¼hrt werden Einfache Befehle, die in einem Taktzyklus ausgefÃ¼hrt werden Jeder Befehl kann auf den Speicher zugreifen Nur Lade- und Speicherbefehle greifen auf den Speicher zu Wenig Pipelining Intensives Pipelining Befehle werden von einem Mikroprogramm interpretiert Befehle werden durch festverdrahtete Hardware ausgefÃ¼hrt Befehlsformat variabler LÃ¤nge Befehlsformat fester LÃ¤nge Die KomplexitÃ¤t liegt im Mikroprogramm Die KomplexitÃ¤t liegt im Compiler Einfacher Registersatz Mehrere RegistersÃ¤tze Wie sieht das Schaltsymbol eines Halbaddierers aus? Schaltsymbol eines Halbaddierers Wie kann man die DatenabhÃ¤ngigkeiten einer Pipeline spezifizieren und erkennen? Datenabhaengigkeiten in einer Pipeline Erkennen kann man sie sehr schnell, indem man eine Tabelle mit den Spalten Befehl, Ziel-Register und Operanden-Register macht. Dabei muss man insbesondere bei der Multiplikation, sw und lw aufpassen. Folgendes (sehr gekrizeltes) Beispiel fÃ¼r die Klausur vom 26. Juli 2012 : DatenabhÃ¤ngigkeiten schnell erkennen Material TI-Website alte Klausuren Flash-Animation zur Adressierung Meine Karteikarten (Siehe Anki auf Wikipedia und UbuntuUsers fÃ¼r mehr Informationen) titut.de , tutorium.chrismandery.de StackOverflow: Strange jump in MIPS assembly Aufbau der Klausur Die Klausuren sind alle sehr Ã¤hnlich aufgebaut. Eine typische Klausur hat 10 Aufgaben zu diesen Themen: Schaltfunktionen Spezielle Bausteine Laufzeiteffekte Schaltwerke Rechnerarithmetik und Codes Allgemeines : Ankreuzaufgaben MIPS-Assembler : C-Code in MIPS umwandeln und umgekehrt Pipelining : Datenkonflikte erkennen und mit NOPs beheben, eventuell gibts noch Forwarding Cache-Speicher Speicher Termine und Klausurablauf Datum : Mittwoch, den 3. April 2013 von 14:00 bis 16:00 Uhr Ort : Gaede (bei mir; siehe HÃ¶rsaaleinteilung , die seit dem 2. April 2013 drauÃŸen ist) Dauer : 1 h DT, 1 h RO Punkte : (vermutlich) 90 Bestehensgrenze : (vermutlich) 40 Ãœbungsschein : Wird nicht ins Studienportal eingetragen Bonuspunkte : Ãœbungsschein RO: 1 Bonuspunkt Ãœbungsschein DT: 1 Bonuspunkt FÃ¼r die Probeklausuren jeweils: Note â€žSehr gut\": 2 Bonuspunkte Note â€žGut\": 1,5 Bonuspunkte Note â€žBefriedigend\": 1 Bonuspunkt Note â€žAusreichend\": 0,5 Bonuspunkte Nicht vergessen Studentenausweis Kugelschreiber Ergebnisse Die Klausureinsicht ist am Montag, den 29. April 2013. FÃ¼r die Einsicht muss man sich hier anmelden.","tags":"German posts","title":"TI-Klausur (DT & RO)"},{"url":"https://martin-thoma.com/software-licenses/","text":"Do you know the difference between MIT-license and BSD license? I don't. And I don't want to read the MIT license , although it is very short. And I definitely don't want to read the Apache 2.0 license . Instead of reading all licenses, you could first read A Short Guide To Open-Source And Similar Licenses . Even shorter: TL;DR - Open Source Licenses Explained in Plain English . TL;DR Legal Licenses are important for OpenSource, because if you don't provide a license, nobody may use your source ( source ). So even if everybody can see your code, it is not OpenSource if you don't choose an OpenSource license. I think Jeff Atwood has written an article about the fact, that many GitHub projects are not OpenSource due to a missing license. Sadly, I don't find the article. But here is another one by him: Pick a License, Any License","tags":"Code","title":"Software Licenses"},{"url":"https://martin-thoma.com/strassen-algorithm-in-python-java-cpp/","text":"This is Part II of my matrix multiplication series. Part I was about simple matrix multiplication algorithms and Part II was about the Strassen algorithm. Part III is about parallel matrix multiplication. The usual matrix multiplication of two \\(n \\times n\\) matrices has a time-complexity of \\(\\mathcal{O}(n&#94;3)\\) . This means, if \\(n\\) doubles, the time for the computation increases by a factor of 8. But you don't have to use that much resources. The Strassen algorithm has a time complexity of \\(\\mathcal O(n&#94;{log_2(7)+o(1)}) \\approx \\cal O(n&#94;{2.807})\\) . The idea is similar to the Karatsuba algorithm for simple multiplication. Basically, you make a tradeof: Instead of one multiplication, you use many additions. As additions are - at least for humans - easier, you might rather like to use many additions. Lets see how the Strassen algortihms execution time compares to the other execution times in Part I. As last time, I'll multiply two \\(2000 \\times 2000\\) matrices that have to be read from a file. Everything - reading, calculation and writing the result - counts to the execution time. The implementations As last time, I've added the scripts to a GIT repository , so feel free to test it on your machine. I will use the I am also happy if you post some of your solutions with running times â˜º If you know other languages, you could create a script for these. I focus on Python, Java and C++. I have implemented only the Strassen algorithm for this post. Please take a look at Wikipedia for a detailed explanation how this algorithm works. The important idea of the algorithm is that you break both matrices into four \\(\\frac{n}{2} \\times \\frac{n}{2}\\) matrices and multiply them in a clever way. Note that you can also use the Strassen algorithm recursively for those \\(\\frac{n}{2} \\times \\frac{n}{2}\\) matrices. You can do this until you have \\(1 \\times 1\\) matrices which are simple numbers. But it does make sense to stop this recursion and use the ikj-algorithm as soon as the matrices are small enough. But what exactly is \"small enough\"? I'll test that. The size when you use the ikj-algorithm is called LEAF_SIZE in my scripts. Note that only leaf sizes of multiples of two matter as the size of the (sub-)matrices that get passed to strassenR are multiples of two. If you post a solution, please consider these restrictions: Input : The input file should get passed with the parameter -i , e.g.: python -i bigMatrix.in or java Shell -i bigMatrix.in The leaf-size should get passed with -l , e.g.: python -i bigMatrix.in -l 32 The standard value for the command line parameter -i should be \"bigMatrix.in\" The user should not have to give the size of the matrix! The two square-matrices that should get multiplied are ... ... read from a text-file. ... represented like this: Every line of one matrix is one line in the text-file. Newlines are only \"\\n\". Every number is separated by \"\\t\". The both matrices are separated by one newline. Output : The result has to get printed to standard output. The result has to be formatted like the input (tabs for separation of number, \\n for marks a new line) Tests and Setting Tests and setting are the same as in the first part. Python I've used Python 2.6.5. #!/usr/bin/python # -*- coding: utf-8 -*- from optparse import OptionParser from math import ceil , log def read ( filename ): lines = open ( filename , 'r' ) . read () . splitlines () A = [] B = [] matrix = A for line in lines : if line != \"\" : matrix . append ( map ( int , line . split ( \" \\t \" ))) else : matrix = B return A , B def printMatrix ( matrix ): for line in matrix : print \" \\t \" . join ( map ( str , line )) def ikjMatrixProduct ( A , B ): n = len ( A ) C = [[ 0 for i in xrange ( n )] for j in xrange ( n )] for i in xrange ( n ): for k in xrange ( n ): for j in xrange ( n ): C [ i ][ j ] += A [ i ][ k ] * B [ k ][ j ] return C def add ( A , B ): n = len ( A ) C = [[ 0 for j in xrange ( 0 , n )] for i in xrange ( 0 , n )] for i in xrange ( 0 , n ): for j in xrange ( 0 , n ): C [ i ][ j ] = A [ i ][ j ] + B [ i ][ j ] return C def subtract ( A , B ): n = len ( A ) C = [[ 0 for j in xrange ( 0 , n )] for i in xrange ( 0 , n )] for i in xrange ( 0 , n ): for j in xrange ( 0 , n ): C [ i ][ j ] = A [ i ][ j ] - B [ i ][ j ] return C def strassenR ( A , B ): \"\"\" Implementation of the strassen algorithm. \"\"\" n = len ( A ) if n <= LEAF_SIZE : return ikjMatrixProduct ( A , B ) else : # initializing the new sub-matrices newSize = n / 2 a11 = [[ 0 for j in xrange ( 0 , newSize )] for i in xrange ( 0 , newSize )] a12 = [[ 0 for j in xrange ( 0 , newSize )] for i in xrange ( 0 , newSize )] a21 = [[ 0 for j in xrange ( 0 , newSize )] for i in xrange ( 0 , newSize )] a22 = [[ 0 for j in xrange ( 0 , newSize )] for i in xrange ( 0 , newSize )] b11 = [[ 0 for j in xrange ( 0 , newSize )] for i in xrange ( 0 , newSize )] b12 = [[ 0 for j in xrange ( 0 , newSize )] for i in xrange ( 0 , newSize )] b21 = [[ 0 for j in xrange ( 0 , newSize )] for i in xrange ( 0 , newSize )] b22 = [[ 0 for j in xrange ( 0 , newSize )] for i in xrange ( 0 , newSize )] aResult = [[ 0 for j in xrange ( 0 , newSize )] for i in xrange ( 0 , newSize )] bResult = [[ 0 for j in xrange ( 0 , newSize )] for i in xrange ( 0 , newSize )] # dividing the matrices in 4 sub-matrices: for i in xrange ( 0 , newSize ): for j in xrange ( 0 , newSize ): a11 [ i ][ j ] = A [ i ][ j ] # top left a12 [ i ][ j ] = A [ i ][ j + newSize ] # top right a21 [ i ][ j ] = A [ i + newSize ][ j ] # bottom left a22 [ i ][ j ] = A [ i + newSize ][ j + newSize ] # bottom right b11 [ i ][ j ] = B [ i ][ j ] # top left b12 [ i ][ j ] = B [ i ][ j + newSize ] # top right b21 [ i ][ j ] = B [ i + newSize ][ j ] # bottom left b22 [ i ][ j ] = B [ i + newSize ][ j + newSize ] # bottom right # Calculating p1 to p7: aResult = add ( a11 , a22 ) bResult = add ( b11 , b22 ) p1 = strassenR ( aResult , bResult ) # p1 = (a11+a22) * (b11+b22) aResult = add ( a21 , a22 ) # a21 + a22 p2 = strassenR ( aResult , b11 ) # p2 = (a21+a22) * (b11) bResult = subtract ( b12 , b22 ) # b12 - b22 p3 = strassenR ( a11 , bResult ) # p3 = (a11) * (b12 - b22) bResult = subtract ( b21 , b11 ) # b21 - b11 p4 = strassenR ( a22 , bResult ) # p4 = (a22) * (b21 - b11) aResult = add ( a11 , a12 ) # a11 + a12 p5 = strassenR ( aResult , b22 ) # p5 = (a11+a12) * (b22) aResult = subtract ( a21 , a11 ) # a21 - a11 bResult = add ( b11 , b12 ) # b11 + b12 p6 = strassenR ( aResult , bResult ) # p6 = (a21-a11) * (b11+b12) aResult = subtract ( a12 , a22 ) # a12 - a22 bResult = add ( b21 , b22 ) # b21 + b22 p7 = strassenR ( aResult , bResult ) # p7 = (a12-a22) * (b21+b22) # calculating c21, c21, c11 e c22: c12 = add ( p3 , p5 ) # c12 = p3 + p5 c21 = add ( p2 , p4 ) # c21 = p2 + p4 aResult = add ( p1 , p4 ) # p1 + p4 bResult = add ( aResult , p7 ) # p1 + p4 + p7 c11 = subtract ( bResult , p5 ) # c11 = p1 + p4 - p5 + p7 aResult = add ( p1 , p3 ) # p1 + p3 bResult = add ( aResult , p6 ) # p1 + p3 + p6 c22 = subtract ( bResult , p2 ) # c22 = p1 + p3 - p2 + p6 # Grouping the results obtained in a single matrix: C = [[ 0 for j in xrange ( 0 , n )] for i in xrange ( 0 , n )] for i in xrange ( 0 , newSize ): for j in xrange ( 0 , newSize ): C [ i ][ j ] = c11 [ i ][ j ] C [ i ][ j + newSize ] = c12 [ i ][ j ] C [ i + newSize ][ j ] = c21 [ i ][ j ] C [ i + newSize ][ j + newSize ] = c22 [ i ][ j ] return C def strassen ( A , B ): assert type ( A ) == list and type ( B ) == list assert len ( A ) == len ( A [ 0 ]) == len ( B ) == len ( B [ 0 ]) # Make the matrices bigger so that you can apply the strassen # algorithm recursively without having to deal with odd # matrix sizes nextPowerOfTwo = lambda n : 2 ** int ( ceil ( log ( n , 2 ))) n = len ( A ) m = nextPowerOfTwo ( n ) APrep = [[ 0 for i in xrange ( m )] for j in xrange ( m )] BPrep = [[ 0 for i in xrange ( m )] for j in xrange ( m )] for i in xrange ( n ): for j in xrange ( n ): APrep [ i ][ j ] = A [ i ][ j ] BPrep [ i ][ j ] = B [ i ][ j ] CPrep = strassenR ( APrep , BPrep ) C = [[ 0 for i in xrange ( n )] for j in xrange ( n )] for i in xrange ( n ): for j in xrange ( n ): C [ i ][ j ] = CPrep [ i ][ j ] return C if __name__ == \"__main__\" : parser = OptionParser () parser . add_option ( \"-i\" , dest = \"filename\" , default = \"2000.in\" , help = \"input file with two matrices\" , metavar = \"FILE\" ) parser . add_option ( \"-l\" , dest = \"LEAF_SIZE\" , default = \"8\" , help = \"when do you start using ikj\" , metavar = \"LEAF_SIZE\" ) ( options , args ) = parser . parse_args () LEAF_SIZE = options . LEAF_SIZE A , B = read ( options . filename ) C = strassen ( A , B ) printMatrix ( C ) The execution-times were the same as with the ikj-algorithm, no matter what the leaf size was: ikj-algorithm 44m13.458s LEAF_SIZE Time 2 47m45.983s 8 47m41.311s 16 48m5.472s 32 48m5.624s 64 47m55.076s Java The Java-code is a little bit long and has three classes. I'll only past the important methods. If you're interested in a full, working example, please look at GitHub . public static int [][] ikjAlgorithm ( int [][] A , int [][] B ) { int n = A . length ; // initialise C int [][] C = new int [ n ][ n ]; for ( int i = 0 ; i < n ; i ++) { for ( int k = 0 ; k < n ; k ++) { for ( int j = 0 ; j < n ; j ++) { C [ i ][ j ] += A [ i ][ k ] * B [ k ][ j ]; } } } return C ; } private static int [][] add ( int [][] A , int [][] B ) { int n = A . length ; int [][] C = new int [ n ][ n ]; for ( int i = 0 ; i < n ; i ++) { for ( int j = 0 ; j < n ; j ++) { C [ i ][ j ] = A [ i ][ j ] + B [ i ][ j ]; } } return C ; } private static int [][] subtract ( int [][] A , int [][] B ) { int n = A . length ; int [][] C = new int [ n ][ n ]; for ( int i = 0 ; i < n ; i ++) { for ( int j = 0 ; j < n ; j ++) { C [ i ][ j ] = A [ i ][ j ] - B [ i ][ j ]; } } return C ; } private static int nextPowerOfTwo ( int n ) { int log2 = ( int ) Math . ceil ( Math . log ( n ) / Math . log ( 2 )); return ( int ) Math . pow ( 2 , log2 ); } public static int [][] strassen ( ArrayList < ArrayList < Integer >> A , ArrayList < ArrayList < Integer >> B ) { // Make the matrices bigger so that you can apply the strassen // algorithm recursively without having to deal with odd // matrix sizes int n = A . size (); int m = nextPowerOfTwo ( n ); int [][] APrep = new int [ m ][ m ]; int [][] BPrep = new int [ m ][ m ]; for ( int i = 0 ; i < n ; i ++) { for ( int j = 0 ; j < n ; j ++) { APrep [ i ][ j ] = A . get ( i ). get ( j ); BPrep [ i ][ j ] = B . get ( i ). get ( j ); } } int [][] CPrep = strassenR ( APrep , BPrep ); int [][] C = new int [ n ][ n ]; for ( int i = 0 ; i < n ; i ++) { for ( int j = 0 ; j < n ; j ++) { C [ i ][ j ] = CPrep [ i ][ j ]; } } return C ; } private static int [][] strassenR ( int [][] A , int [][] B ) { int n = A . length ; if ( n <= LEAF_SIZE ) { return ikjAlgorithm ( A , B ); } else { // initializing the new sub-matrices int newSize = n / 2 ; int [][] a11 = new int [ newSize ][ newSize ]; int [][] a12 = new int [ newSize ][ newSize ]; int [][] a21 = new int [ newSize ][ newSize ]; int [][] a22 = new int [ newSize ][ newSize ]; int [][] b11 = new int [ newSize ][ newSize ]; int [][] b12 = new int [ newSize ][ newSize ]; int [][] b21 = new int [ newSize ][ newSize ]; int [][] b22 = new int [ newSize ][ newSize ]; int [][] aResult = new int [ newSize ][ newSize ]; int [][] bResult = new int [ newSize ][ newSize ]; // dividing the matrices in 4 sub-matrices: for ( int i = 0 ; i < newSize ; i ++) { for ( int j = 0 ; j < newSize ; j ++) { a11 [ i ][ j ] = A [ i ][ j ]; // top left a12 [ i ][ j ] = A [ i ][ j + newSize ]; // top right a21 [ i ][ j ] = A [ i + newSize ][ j ]; // bottom left a22 [ i ][ j ] = A [ i + newSize ][ j + newSize ]; // bottom right b11 [ i ][ j ] = B [ i ][ j ]; // top left b12 [ i ][ j ] = B [ i ][ j + newSize ]; // top right b21 [ i ][ j ] = B [ i + newSize ][ j ]; // bottom left b22 [ i ][ j ] = B [ i + newSize ][ j + newSize ]; // bottom right } } // Calculating p1 to p7: aResult = add ( a11 , a22 ); bResult = add ( b11 , b22 ); int [][] p1 = strassenR ( aResult , bResult ); // p1 = (a11+a22) * (b11+b22) aResult = add ( a21 , a22 ); // a21 + a22 int [][] p2 = strassenR ( aResult , b11 ); // p2 = (a21+a22) * (b11) bResult = subtract ( b12 , b22 ); // b12 - b22 int [][] p3 = strassenR ( a11 , bResult ); // p3 = (a11) * (b12 - b22) bResult = subtract ( b21 , b11 ); // b21 - b11 int [][] p4 = strassenR ( a22 , bResult ); // p4 = (a22) * (b21 - b11) aResult = add ( a11 , a12 ); // a11 + a12 int [][] p5 = strassenR ( aResult , b22 ); // p5 = (a11+a12) * (b22) aResult = subtract ( a21 , a11 ); // a21 - a11 bResult = add ( b11 , b12 ); // b11 + b12 int [][] p6 = strassenR ( aResult , bResult ); // p6 = (a21-a11) * (b11+b12) aResult = subtract ( a12 , a22 ); // a12 - a22 bResult = add ( b21 , b22 ); // b21 + b22 int [][] p7 = strassenR ( aResult , bResult ); // p7 = (a12-a22) * (b21+b22) // calculating c21, c21, c11 e c22: int [][] c12 = add ( p3 , p5 ); // c12 = p3 + p5 int [][] c21 = add ( p2 , p4 ); // c21 = p2 + p4 aResult = add ( p1 , p4 ); // p1 + p4 bResult = add ( aResult , p7 ); // p1 + p4 + p7 int [][] c11 = subtract ( bResult , p5 ); // c11 = p1 + p4 - p5 + p7 aResult = add ( p1 , p3 ); // p1 + p3 bResult = add ( aResult , p6 ); // p1 + p3 + p6 int [][] c22 = subtract ( bResult , p2 ); // c22 = p1 + p3 - p2 + p6 // Grouping the results obtained in a single matrix: int [][] C = new int [ n ][ n ]; for ( int i = 0 ; i < newSize ; i ++) { for ( int j = 0 ; j < newSize ; j ++) { C [ i ][ j ] = c11 [ i ][ j ]; C [ i ][ j + newSize ] = c12 [ i ][ j ]; C [ i + newSize ][ j ] = c21 [ i ][ j ]; C [ i + newSize ][ j + newSize ] = c22 [ i ][ j ]; } } return C ; } } Here are the results for different leaf-sizes: Matrix multiplication with Java: Execution time in seconds for different leafsizes C++ #include <sstream> #include <string> #include <fstream> #include <iostream> #include <vector> #include <algorithm> #include <cmath> // Set LEAF_SIZE to 1 if you want to the pure strassen algorithm // otherwise, the ikj-algorithm will be applied when the split // matrices are as small as LEAF_SIZE x LEAF_SIZE int leafsize ; using namespace std ; /* * Implementation of the strassen algorithm, similar to * http://en.wikipedia.org/w/index.php?title=Strassen_algorithm&oldid=498910018#Source_code_of_the_Strassen_algorithm_in_C_language */ void strassen ( vector < vector < int > > & A , vector < vector < int > > & B , vector < vector < int > > & C , unsigned int tam ); unsigned int nextPowerOfTwo ( int n ); void strassenR ( vector < vector < int > > & A , vector < vector < int > > & B , vector < vector < int > > & C , int tam ); void sum ( vector < vector < int > > & A , vector < vector < int > > & B , vector < vector < int > > & C , int tam ); void subtract ( vector < vector < int > > & A , vector < vector < int > > & B , vector < vector < int > > & C , int tam ); void printMatrix ( vector < vector < int > > matrix , int n ); void read ( string filename , vector < vector < int > > & A , vector < vector < int > > & B ); void ikjalgorithm ( vector < vector < int > > A , vector < vector < int > > B , vector < vector < int > > & C , int n ) { for ( int i = 0 ; i < n ; i ++ ) { for ( int k = 0 ; k < n ; k ++ ) { for ( int j = 0 ; j < n ; j ++ ) { C [ i ][ j ] += A [ i ][ k ] * B [ k ][ j ]; } } } } void strassenR ( vector < vector < int > > & A , vector < vector < int > > & B , vector < vector < int > > & C , int tam ) { if ( tam <= leafsize ) { ikjalgorithm ( A , B , C , tam ); return ; } // other cases are treated here: else { int newTam = tam / 2 ; vector < int > inner ( newTam ); vector < vector < int > > a11 ( newTam , inner ), a12 ( newTam , inner ), a21 ( newTam , inner ), a22 ( newTam , inner ), b11 ( newTam , inner ), b12 ( newTam , inner ), b21 ( newTam , inner ), b22 ( newTam , inner ), c11 ( newTam , inner ), c12 ( newTam , inner ), c21 ( newTam , inner ), c22 ( newTam , inner ), p1 ( newTam , inner ), p2 ( newTam , inner ), p3 ( newTam , inner ), p4 ( newTam , inner ), p5 ( newTam , inner ), p6 ( newTam , inner ), p7 ( newTam , inner ), aResult ( newTam , inner ), bResult ( newTam , inner ); int i , j ; //dividing the matrices in 4 sub-matrices: for ( i = 0 ; i < newTam ; i ++ ) { for ( j = 0 ; j < newTam ; j ++ ) { a11 [ i ][ j ] = A [ i ][ j ]; a12 [ i ][ j ] = A [ i ][ j + newTam ]; a21 [ i ][ j ] = A [ i + newTam ][ j ]; a22 [ i ][ j ] = A [ i + newTam ][ j + newTam ]; b11 [ i ][ j ] = B [ i ][ j ]; b12 [ i ][ j ] = B [ i ][ j + newTam ]; b21 [ i ][ j ] = B [ i + newTam ][ j ]; b22 [ i ][ j ] = B [ i + newTam ][ j + newTam ]; } } // Calculating p1 to p7: sum ( a11 , a22 , aResult , newTam ); // a11 + a22 sum ( b11 , b22 , bResult , newTam ); // b11 + b22 strassenR ( aResult , bResult , p1 , newTam ); // p1 = (a11+a22) * (b11+b22) sum ( a21 , a22 , aResult , newTam ); // a21 + a22 strassenR ( aResult , b11 , p2 , newTam ); // p2 = (a21+a22) * (b11) subtract ( b12 , b22 , bResult , newTam ); // b12 - b22 strassenR ( a11 , bResult , p3 , newTam ); // p3 = (a11) * (b12 - b22) subtract ( b21 , b11 , bResult , newTam ); // b21 - b11 strassenR ( a22 , bResult , p4 , newTam ); // p4 = (a22) * (b21 - b11) sum ( a11 , a12 , aResult , newTam ); // a11 + a12 strassenR ( aResult , b22 , p5 , newTam ); // p5 = (a11+a12) * (b22) subtract ( a21 , a11 , aResult , newTam ); // a21 - a11 sum ( b11 , b12 , bResult , newTam ); // b11 + b12 strassenR ( aResult , bResult , p6 , newTam ); // p6 = (a21-a11) * (b11+b12) subtract ( a12 , a22 , aResult , newTam ); // a12 - a22 sum ( b21 , b22 , bResult , newTam ); // b21 + b22 strassenR ( aResult , bResult , p7 , newTam ); // p7 = (a12-a22) * (b21+b22) // calculating c21, c21, c11 e c22: sum ( p3 , p5 , c12 , newTam ); // c12 = p3 + p5 sum ( p2 , p4 , c21 , newTam ); // c21 = p2 + p4 sum ( p1 , p4 , aResult , newTam ); // p1 + p4 sum ( aResult , p7 , bResult , newTam ); // p1 + p4 + p7 subtract ( bResult , p5 , c11 , newTam ); // c11 = p1 + p4 - p5 + p7 sum ( p1 , p3 , aResult , newTam ); // p1 + p3 sum ( aResult , p6 , bResult , newTam ); // p1 + p3 + p6 subtract ( bResult , p2 , c22 , newTam ); // c22 = p1 + p3 - p2 + p6 // Grouping the results obtained in a single matrix: for ( i = 0 ; i < newTam ; i ++ ) { for ( j = 0 ; j < newTam ; j ++ ) { C [ i ][ j ] = c11 [ i ][ j ]; C [ i ][ j + newTam ] = c12 [ i ][ j ]; C [ i + newTam ][ j ] = c21 [ i ][ j ]; C [ i + newTam ][ j + newTam ] = c22 [ i ][ j ]; } } } } unsigned int nextPowerOfTwo ( int n ) { return pow ( 2 , int ( ceil ( log2 ( n )))); } void strassen ( vector < vector < int > > & A , vector < vector < int > > & B , vector < vector < int > > & C , unsigned int n ) { //unsigned int n = tam; unsigned int m = nextPowerOfTwo ( n ); vector < int > inner ( m ); vector < vector < int > > APrep ( m , inner ), BPrep ( m , inner ), CPrep ( m , inner ); for ( unsigned int i = 0 ; i < n ; i ++ ) { for ( unsigned int j = 0 ; j < n ; j ++ ) { APrep [ i ][ j ] = A [ i ][ j ]; BPrep [ i ][ j ] = B [ i ][ j ]; } } strassenR ( APrep , BPrep , CPrep , m ); for ( unsigned int i = 0 ; i < n ; i ++ ) { for ( unsigned int j = 0 ; j < n ; j ++ ) { C [ i ][ j ] = CPrep [ i ][ j ]; } } } void sum ( vector < vector < int > > & A , vector < vector < int > > & B , vector < vector < int > > & C , int tam ) { int i , j ; for ( i = 0 ; i < tam ; i ++ ) { for ( j = 0 ; j < tam ; j ++ ) { C [ i ][ j ] = A [ i ][ j ] + B [ i ][ j ]; } } } void subtract ( vector < vector < int > > & A , vector < vector < int > > & B , vector < vector < int > > & C , int tam ) { int i , j ; for ( i = 0 ; i < tam ; i ++ ) { for ( j = 0 ; j < tam ; j ++ ) { C [ i ][ j ] = A [ i ][ j ] - B [ i ][ j ]; } } } int getMatrixSize ( string filename ) { string line ; ifstream infile ; infile . open ( filename . c_str ()); getline ( infile , line ); return count ( line . begin (), line . end (), '\\t' ) + 1 ; } void read ( string filename , vector < vector < int > > & A , vector < vector < int > > & B ) { string line ; FILE * matrixfile = freopen ( filename . c_str (), \"r\" , stdin ); if ( matrixfile == 0 ) { cerr << \"Could not read file \" << filename << endl ; return ; } int i = 0 , j , a ; while ( getline ( cin , line ) && ! line . empty ()) { istringstream iss ( line ); j = 0 ; while ( iss >> a ) { A [ i ][ j ] = a ; j ++ ; } i ++ ; } i = 0 ; while ( getline ( cin , line )) { istringstream iss ( line ); j = 0 ; while ( iss >> a ) { B [ i ][ j ] = a ; j ++ ; } i ++ ; } fclose ( matrixfile ); } void printMatrix ( vector < vector < int > > matrix , int n ) { for ( int i = 0 ; i < n ; i ++ ) { for ( int j = 0 ; j < n ; j ++ ) { if ( j != 0 ) { cout << \" \\t \" ; } cout << matrix [ i ][ j ]; } cout << endl ; } } int main ( int argc , char * argv []) { string filename ; if ( argc < 3 ) { filename = \"2000.in\" ; } else { filename = argv [ 2 ]; } if ( argc < 5 ) { leafsize = 16 ; } else { leafsize = atoi ( argv [ 4 ]); } int n = getMatrixSize ( filename ); vector < int > inner ( n ); vector < vector < int > > A ( n , inner ), B ( n , inner ), C ( n , inner ); read ( filename , A , B ); strassen ( A , B , C , n ); printMatrix ( C , n ); return 0 ; } For C++, you get those user-times for the different leaf-sizes: Execution times in seconds with differen leafsizes with C++ Conclusion As always, C++ is the fastest solution. I am a little bit surprised, that the LEAF_SIZE doesn't matter for Python. I think I have used some very slow operations that are much more important than any speed gains or losses due to LEAF_SIZE. I guess the list creation might be slow. Does anybody know a tool for performance analysis of Python programs? This tool should be able to track which pieces of code got executed most often any preferably visualize it. For Java and C++, the Strassen algorithm had better execution times than the ikj-algorithm and it was also better than any library that I could find. The reasons why librarys perform worse than my implementation might be that pure integer matrices are rather rare. Usually you have double-matrices. Maybe you use different algorithms to keep rounding errors as small as possible (Can anybody provide more information to my speculations?) Leafsizes from 64 to 256 seem to be the best solution.","tags":"Code","title":"Part II: The Strassen algorithm in Python, Java and C++"},{"url":"https://martin-thoma.com/check-x-in-a-row-for-board-games/","text":"In board games, you have quite often the situation that you want to check something in different directions. Most of the time, the implementation I see for situations like this is very redundant and prone to off-by-one errors. Some simple ideas can improve the quality of codes (code that is easier to understand and less loc ) and reduce the probability of tiny mistakes. Tic Tac Toe Battleships Moves of the queen in chess isOnBoard(int x, int y) You should create a method that checks if a coordinate is on your board. This can be as simple as this: public boolean isOnBoard ( int x , int y ) { return 0 <= x && x < width && 0 <= y && y < height ; } Diagonal, horizontal and vertical You can create a method like this: /** * This method checks XYZ and does XYZ. * * @param player the current player * @param xDir -1 if you want to go to the left, 0 if you don't want * to move in x-direction and 1 if you want to go to * the right * @param yDir -1 if you want to go to the bottom, 0 if you don't * want to move in y-direction and 1 if you want to go * to the top */ private void myBoardAction ( Player player , int xDir , int yDir ) { for ( int x = 0 ; x < board . width ; x ++) { for ( int y = 0 ; y < board . height ; y ++) { for ( int c = 0 ; c < SOME_CONSTANT ; c ++) { if ( board . isOnBoard ( x + c * xDir , y + c * yDir ) && board . checkXYZ ( x + c * xDir , y + c * yDir )) { doXYZ (); } } } } } What's so special about it? Well, note how the xDir and yDir parameters change the behavior of the method. If you want to move only to the right, you will call myBoardAction(player, 1, 0) . If you want to go to the top left, you will call myBoardAction(player, -1, 1) . Of course, you can't simply take this piece of code and only change doXYZ() and checkXYZ . You will have to change the starting and and position and maybe add a break. But this thought can be applied to board games quite nice. Please also note that I go from (0|0) to (board.width|board.height) and even add in the inner loop something. So some calls will be out of bound. But because of short-circuit evaluation this works. I don't bother about ends, I simply include the critical parts. Most of the time, it is not much work to check if the call is within the boundary, but finding (and fixing) a bug is much work. Yes, I know, this is more efficient if you use the correct boundaries. But it's only a constant in time difference. And I guess this constant is very small for most games. Ah, and if you want to check a condition for all diagonals, horizontals and verticals the hole board, you can call it like this: myBoardAction ( player , 1 , 1 ); // top right myBoardAction ( player ,- 1 , 1 ); // top left myBoardAction ( player , 1 , 0 ); // vertical myBoardAction ( player , 0 , 1 ); // horizontal This is enough. You don't need more, as you go through the whole board. No need to write redundant code â˜º","tags":"Code","title":"Check x-in-a-row for board games"},{"url":"https://martin-thoma.com/cyclic-references-kill-nautilus/","text":"I just wanted to answer an assignment and noticed that cyclic references kill Nautilus. What I did mkdir testFolder cd testFolder touch testFile.txt ln -s testFile.txt mySoftlink rm testFile.txt ln -s mySoftlink testFile.txt ls -l total 0 lrwxrwxrwx 1 moose moose 10 2013 -01-20 21 :20 myfile.txt -> mySoftLink lrwxrwxrwx 1 moose moose 10 2013 -01-20 21 :18 mySoftLink -> myfile.txt Those two softlinks refer to each other. Now try to open this folder with Nautilus: nautilus /home/moose/Desktop/testFolder/ Nautilus opens and instantly closes again. My Nautilus I use Ubuntu 10.04.4 LTS with Nautilus 2.30.1. Bug report? I know, the current version of Nautilus is 3.6.1, but how often do you find a bug which is so easy to reproduce? The Nautilus Bugtracker is here , but where would you look for the bug?","tags":"Code","title":"Cyclic references kill Nautilus"},{"url":"https://martin-thoma.com/wie-wende-ich-die-shannon-zerlegung-an/","text":"Die Shannon-Zerlegung ist hilfreich, um die disjunktive bzw. konjunktive Form einer Funktion zu erhalten. Im Folgenden gibt es ein paar Beispiele, wie man das macht: Vorgehen Man hat eine boolsche Funktion $f(x_1, x_2, \\dots, x_n)$ gegeben. Entwickeln nach einer Variablen $x_i$: $g(x_1, \\dots, x_n) := f(x_1, \\dots, x_i=1, \\dots, x_n)$ $h(x_1, \\dots, x_n) := f(x_1, \\dots, x_i=0, \\dots, x_n)$ $f(x_1, x_2, \\dots, x_n) = x_i [ g(x_1, \\dots, x_n)] \\lor \\bar x_i [h(x_1, \\dots, x_n)]$ Vereinfachen der Funktion Beispiel 1 \\begin{align} f(c, b, a) :&= (c \\land b) \\barwedge a) \\Leftrightarrow (b \\lor a)\\\\ \\text{Entwickeln nach c:} &= c[((1 \\land b) \\barwedge a) \\Leftrightarrow (b \\lor a)] \\lor \\bar c [((0 \\land b) \\barwedge a) \\Leftrightarrow (b \\lor a)]\\\\ &= c[(b \\barwedge a) \\Leftrightarrow (b \\lor a)] \\lor \\bar c [(0 \\barwedge a) \\Leftrightarrow (b \\lor a)]\\\\ &= c[(b \\barwedge a) \\Leftrightarrow (b \\lor a)] \\lor \\bar c [1 \\Leftrightarrow (b \\lor a)]\\\\ &= c((b \\barwedge a) \\Leftrightarrow (b \\lor a)) \\lor \\bar c (b \\lor a)\\\\ \\text{Entwickeln nach b:}&= b \\lor \\bar b\\\\ &= b \\lor \\bar b \\\\ &= b(c \\bar a \\lor \\bar c) \\lor \\bar b (ca \\lor \\bar c a)\\\\ \\text{Entwickeln nach a:} &= a[b(c \\bar 1 \\lor \\bar c) \\lor \\bar b (c \\lor \\bar c)] \\lor \\bar a [b(c \\bar 0 \\lor \\bar c) \\lor \\bar b (\\bar c a)]\\\\ &=a(b \\bar c \\lor \\bar b) \\lor \\bar ab\\\\ &= ab \\bar c \\lor a \\bar b \\lor \\bar a b\\\\ &= ab \\bar c \\lor a \\bar b c \\lor a \\bar b \\bar c \\lor \\bar a b c \\lor \\bar a b \\bar c \\end{align} Die letzte Darstellung der Funktion \\(f\\) wird Disjunktive Normalform (DNF) genannt. Die vorletzte ist einfach nur eine disjunktion von Konjunktionen. Beispiel 2 \\begin{align} f(c,b,a) &:= ab \\lor \\bar c\\\\ \\text{Entwickeln nach b:} &= b[a \\lor \\bar c] \\lor \\bar b[\\bar c]\\\\ &= b(a \\lor \\bar c) \\lor \\bar b \\bar c\\\\ \\text{Entwickeln nach a:} &= a[b \\lor \\bar b \\bar c] \\lor \\bar a [b(\\bar c) \\lor \\bar b \\bar c]\\\\ &= a(b \\lor \\bar b \\bar c) \\lor \\bar a \\bar c\\\\ &= ab \\lor a \\bar b \\bar c \\lor \\bar a \\bar c\\\\ &= (abc \\lor ab \\bar c) \\lor a \\bar b \\bar c \\lor (\\bar a b \\bar c \\lor \\bar a \\bar b \\bar c) \\end{align} Man muss auch nicht immer Entwicklen, um das Ergebnis zu erhalten. Die Klammern im Ergebnis verdeutlichen, wie man den letzten Schritt durchfÃ¼hrt. Also wie man von einer Disjunktiven Form auf die Disjunktive Normalform kommt.","tags":"German posts","title":"Wie wende ich die Shannon-Zerlegung an?"},{"url":"https://martin-thoma.com/adressierung/","text":"Dies ist eine Zusammenfassung von mir zu dem Themen Caches, Addressierung und TLB. Ich habe insbesondere bei dem letzem Teil (Cache-Typen und TLBs) das GefÃ¼hl, dass ich das noch nicht richtig verstanden habe, deshalb ist der Inhalt hier mit Vorsicht zu genieÃŸen. Bitte meldet mir Fehler oder Unstimmigkeiten (per E-Mail an info@martin-thoma.de oder direkt als Kommentar). Allgemeines CPU-Caches sind aus Cache-Zeilen aufgebaut. Diese sind die kleinsten adressierbaren Einheiten im Cache. Die LÃ¤nge der Cache-Zeilen variiert, aber 32-64 Byte sind Ã¼blich. [1] Nun ist der Cache deutlich kleiner als der Hauptspeicher und man muss eine schnelle MÃ¶glichkeit haben, Hauptspeicher-Adressen auf den Cache abzubilden. Eine MÃ¶glichkeit das zu machen, ist ein sog. â€ždirect mapped cache\". Das ist im Prinzip eine Hash-Funktion, die zusÃ¤tlich noch schnell von der Hardware umgesetzt werden kÃ¶nnen muss. Also unterteilt man gedanklich die Hauptspeicheradressen in 3 Teile: Tag Index Block-Offset Der Index gibt direkt die Cache-Zeile an, in der die Daten einer Hauptspeicheradresse landen werden. Es wÃ¤re also z.B. mÃ¶glich, die Pins des Adressbus, auf denen die Index-Bits liegen, auf einen Multiplexer zu legen, der die entsprechende Cache-Zeile durchschaltet. Es gilt also: Index-LÃ¤nge in Bit = \\(\\log_2(\\text{Cache-Zeilen})\\) Nun kann es passieren, dass viele Hauptspeicher-Adressen in der selben Zeile landen. Um diese unterscheiden zu kÃ¶nnen, speichert man folgendes in einer Cache-Zeile: Tag Datenblock Flags Der Datenblock beinhaltet die eigentlichen Daten aus dem Hauptspeicher. BenÃ¶tigt nun ein Programm die Daten aus einer Hauptspeicheradresse, wird der Index dieser Adresse extrahiert und an dieser Cache-Zeile nachgeschaut. Wenn dann die Tags Ã¼bereinstimmen, ist es die richtige Adresse und man kann die Daten aus dem Cache entnehmen. Da man durch den Block-Offset ja eine ganze Reihe von Hauptspeicher-Adressen zusammenfasst, muss gelten: GrÃ¶ÃŸe der Cache-Zeile \\(= 2&#94;{\\text{LÃ¤nge des Block-offsets}} \\cdot\\) GrÃ¶ÃŸe des Inhalts einer Hauptspeicheradresse Der Block-Offset wird nicht weiter verwendet. Es wird schlicht ignoriert. Der Tag muss aktiv im Cache gespeichert werden und die LÃ¤nge des Tags im Cache muss mindestens so lang sein wie die Tag-LÃ¤nge der Hauptspeicher- Adresse. NatÃ¼rlich wird der Tag im Cache genau so lang sein wie der in der Hauptspeicher-Adresse. Man hat ja keinen Speicher zu verschenken. Bei einem Voll-Assoziativem Cache wÃ¼rde es also keinen Index geben. Eine Hauptspeicher-Adresse wÃ¼rde dann nur in Tag und Block-Offset geteilt werden. Bei einem \\(n\\) -fach Satzassoziativem Cache gibt es \\(\\frac{\\text{Cachzeilen}}{n}\\) SÃ¤tze mit jeweils \\(n\\) Cachezeilen. Das Datenwort kann nur in einem Satz stehen, dort aber an einer beliebigen Stelle. Nun geht die CPU wie folgt vor: Datenwort mit Hauptspeicheradresse x = $x_\\text{tag}$ | $x_\\text{index}$ | $x_\\text{blockoffset}$ wird benÃ¶tigt $x_\\text{index}$ = der zu durchsuchende Satz im Cache Dieser Satz wird zu den $n$ Vergleichern durchgeschaltet Jeder Vergleicher vergleich den $x_\\text{tag}$ und den in der Cache-Zeile gespeicherten tag Wird die Adresse gefunden â†’ Cache Hit Datenwort in keiner Cache-Zeile: Cache-Miss, Hauptspeicherzugriff Physical address and virtual address Die physische Adresse entspricht dem, womit man den Speicherbaustein anspricht. Nun kann es mÃ¶glich sein, dass man mehrere RAM-Bausteine hat oder dass das Programm theoretische mehr Speicher braucht als an Hauptspeicher zur verfÃ¼gung steht. Dennoch will man als Programmierer einheitlich adressieren. Also nutzt man im Userspace virtuelle Adressen (Im Kernel-Space kÃ¶nnen sowohl physische als auch virtuelle Adressen genutzt werden, siehe StackOverflow ). AuÃŸerdem will man Speicherschutz herstellen. Die virtuellen Adressen sind scheinbar zusammenhÃ¤ngend und der Adressraum ist sehr groÃŸ. Der virtuelle Adressraum ist in BlÃ¶cke (Pages) unterteilt und die Pages werden von langsamen, aber groÃŸen auf schnelle, aber kleine Speichermedien je nach Bedarf aus- oder eingelagert. Das passiert allerdings selten. Um zu sehen, wie hÃ¤ufig das der Fall ist, sollte man sich folgendes anschauen: /proc/swaps /proc/meminfo - ein paar ErklÃ¤rungen zu meminfo vmstat -s Cache-Modelle Fordert nun ein Prozess die Daten einer virtuellen Adresse an, kommt es nun auf die verschiedenen Cache-Modelle (PIPT, VIPT, VIVIT) an. Es gilt jedoch immer: Die CPU schaut im TLB nach, ob sie direkt erfahren kann, wo die Daten sind. Falls das nicht funktiniert, geht es wie folgt weiter: Physically Indexed, Physically Tagged Hier wird der index und der tag aus der physischen Adresse gezogen. Damit muss zuerst die MMU die virtuelle Adresse in eine physische Adresse umwandeln, bevor man im Cache nachschauen kann. Virtually indexed, physically tagged Man bekommt den Index aus der virtuellen Adresse, kann im Cache nachschauen ob dort Ã¼berhaupt etwas steht, falls ja muss aber noch die MMU die physische Adresse nachschlagen damit man den tag Ã¼berprÃ¼fen kann. Frage: Wieso steht in den Folien \"No ambiguities\"? Annahme: Wir haben eine virtuelle Adresse 123456789. Der Index sind die Ziffern [4,6] also 456. Nun wird das auf die physische Adresse 123456789 gemappt. Der Tag sind die Ziffern [1,3] also 123. Nun haben wir eine zweite virtuelle Adresse 000456000. Der index sind die Ziffern [4,6] also 456. Die zugehÃ¶rige phyische Adresse sein 123000000. Der Tag sind die Ziffern [1,3] also 123. Nun mÃ¼sste doch fehlerhaft ein Cache-Hit herauskommen, oder? Physically Indexed / Virtually Tagged Macht keinen Sinn, weil man Probleme wegen Doppeldeutigkeiten bekommen kann und man auf jeden Fall immer zuerst die MMU nutzen kann. Virtually Indexed / Virtually Tagged Kein MMU-Zugriff benÃ¶tigt, also schneller als die anderen Varianten. Birgt aber ein paar Probleme (Ambiguity, Alias) Quellen [&#94;1] Functional Principles of Cache Memory Page-Table Lookups Virtuelle Adresse CPU cache Four-level page tables Linux Specifics: Address Space Layout Some example assignments (Memory access times, With and without TLBs)","tags":"German posts","title":"Adressierung"},{"url":"https://martin-thoma.com/how-to-sort-with-java/","text":"Sorting is a very basic task that every programmer should be able to solve. In Python, you have sort and sorted. In C++, you can use operator overloading . I'll now tell you how to do basic sorting with Java. I will not write about natural language sorting or language-aware sorting. This is only about simple sorting with Java. Sorting without programming First of all, you have to make sure that you understand how sorting works - without Java, just in the real world. What you need: A container \\(C\\) of objects A way to compare two objects of the list at a time. The comparison, lets call it \\(\\leq\\) needs to satisfy the following conditions: totality : \\(\\forall x, y \\in C: x \\leq y \\lor y \\leq x\\) antisymmetry : \\(\\forall x,y \\in C: x \\leq y \\land y \\leq x \\Rightarrow x = y\\) transitivity : \\(\\forall x,y,z \\in C: x \\leq y \\land y \\leq z \\Rightarrow x \\leq z\\) Just think about what you sort in your everyday life: Numbers Words Contries by population Playing cards You can apply different algorithms like selection sort which you would use for numbers or insertion sort which you would use for card games. No matter what algorithm you use, you need to be able to compare the elements. Note that you can compare some objects, like countries, by many measures. You could look at the population, the birth rate or the area. No matter what you use to compare, the this will not influence the way you sort. Collections One way to sort is to implement the interface List . For all datastructures, that implement the interface List or one of its sub-interfaces you can use Collections an go on like this: import java.util.Collections ; import java.util.LinkedList ; import java.util.List ; public class Main { public static void main ( String [] args ) { List < String > myList = new LinkedList < String >(); myList . add ( \"I\" ); myList . add ( \"think\" ); myList . add ( \"therefore\" ); myList . add ( \"I\" ); myList . add ( \"am\" ); System . out . println ( myList ); Collections . sort ( myList ); System . out . println ( myList ); } } Output: [ I, think, therefore, I, am ] [ I, I, am, therefore, think ] Note that I didn't write a Comparator or implement Comparable as String has one by default. Don't mix Collections and Collection ! A Set is a Collection, but it is not sortable. Collections is a class that you can use for sorting. Like Math , that has utilities like sqrt Arrays import java.util.Arrays ; public class Main { public static void main ( String [] args ) { String [] myStrings = new String [ 5 ]; myStrings [ 0 ] = \"I\" ; myStrings [ 1 ] = \"think\" ; myStrings [ 2 ] = \"therefore\" ; myStrings [ 3 ] = \"I\" ; myStrings [ 4 ] = \"am\" ; System . out . println ( Arrays . asList ( myStrings )); Arrays . sort ( myStrings ); System . out . println ( Arrays . asList ( myStrings )); } } Interface Comparable This is an example how you could implement Comparable . Country.java public class Country implements Comparable < Country > { int population ; double area ; String name ; public Country ( int population , double area , String name ) { this . population = population ; this . area = area ; this . name = name ; } @Override public int compareTo ( Country o ) { // a negative integer, zero, or a positive integer as this // object is less than, equal to, or greater than the // specified object. return this . name . compareTo ( o . name ); } @Override public String toString () { return name + \": \" + population ; } } Main.java import java.util.ArrayList ; import java.util.Collections ; import java.util.List ; public class Main { public static void main ( String [] args ) { List < Country > europe = new ArrayList < Country >(); europe . add ( new Country ( 82000000 , 350000 , \"Germany\" )); europe . add ( new Country ( 60000000 , 360000 , \"France\" )); europe . add ( new Country ( 20000000 , 100000 , \"Norway\" )); europe . add ( new Country ( 30000000 , 500000 , \"Sweden\" )); europe . add ( new Country ( 50000000 , 123000 , \"Spain\" )); System . out . println ( europe ); Collections . sort ( europe ); System . out . println ( europe ); } } Output: [ Germany: 81903000 , France: 64667000 , Norway: 4985900 , Sweden: 9514406 , Spain: 47212990 , Switzerland: 8014000 , Monaco: 36371 ] [ France: 64667000 , Germany: 81903000 , Monaco: 36371 , Norway: 4985900 , Spain: 47212990 , Sweden: 9514406 , Switzerland: 8014000 ] You should definitely add JavaDoc and comment what you've compared. Note that it would sort the list in reverse order if you switched this.population - o.population; to o.population - this.population; . This would be bad style, as the JavaDoc of Comparable define the order. If you would like to sort in reverse, you should use Collections.reverse(europe); . You can also use compareTo() within compareTo(): @Override public int compareTo ( Country o ) { return this . name . compareTo ( o . name ); } Comparator If you need to compare objects in multiple ways, you might need to implement Comperator . If you only have to compare objects in one way, I would always use the Interface Comparable. It's easier to use. External Comparator An external Comparator PopulationDensityComperator.java could look like this: import java.util.Comparator ; public class PopulationDensityComperator implements Comparator < Country > { @Override public int compare ( Country o1 , Country o2 ) { double o1Density = o1 . population / o1 . area ; double o2Density = o2 . population / o2 . area ; if ( Math . abs ( o1Density - o2Density ) < 0.00001 ) { return 0 ; } else { return o1Density - o2Density ; } } } and you would use it like this in the Main.java: import java.util.ArrayList ; import java.util.Collections ; import java.util.List ; public class Main { public static void main ( String [] args ) { List < Country > europe = new ArrayList < Country >(); europe . add ( new Country ( 81903000 , 357121.41 , \"Germany\" )); europe . add ( new Country ( 64667000 , 668763 , \"France\" )); europe . add ( new Country ( 4985900 , 385199 , \"Norway\" )); europe . add ( new Country ( 9514406 , 450295 , \"Sweden\" )); europe . add ( new Country ( 47212990 , 504645 , \"Spain\" )); europe . add ( new Country ( 8014000 , 41285 , \"Switzerland\" )); europe . add ( new Country ( 36371 , 2.02 , \"Monaco\" )); System . out . println ( europe ); Collections . sort ( europe ); System . out . println ( europe ); Collections . sort ( europe , new PopulationDensityComperator ()); System . out . println ( europe ); } } Your output would be: [ Germany: 81903000 , France: 64667000 , Norway: 4985900 , Sweden: 9514406 , Spain: 47212990 , Switzerland: 8014000 , Monaco: 36371 ] [ France: 64667000 , Germany: 81903000 , Monaco: 36371 , Norway: 4985900 , Spain: 47212990 , Sweden: 9514406 , Switzerland: 8014000 ] [ Norway: 4985900 , Sweden: 9514406 , Spain: 47212990 , France: 64667000 , Switzerland: 8014000 , Germany: 81903000 , Monaco: 36371 ] Internal (anonymous) Comparator You can also directly implement the comperator where you need it: import java.util.ArrayList ; import java.util.Collections ; import java.util.Comparator ; import java.util.List ; public class Main { public static void main ( String [] args ) { List < Country > europe = new ArrayList < Country >(); europe . add ( new Country ( 81903000 , 357121.41 , \"Germany\" )); europe . add ( new Country ( 64667000 , 668763 , \"France\" )); europe . add ( new Country ( 4985900 , 385199 , \"Norway\" )); europe . add ( new Country ( 9514406 , 450295 , \"Sweden\" )); europe . add ( new Country ( 47212990 , 504645 , \"Spain\" )); europe . add ( new Country ( 8014000 , 41285 , \"Switzerland\" )); europe . add ( new Country ( 36371 , 2.02 , \"Monaco\" )); System . out . println ( europe ); Collections . sort ( europe ); System . out . println ( europe ); Collections . sort ( europe , new Comparator < Country >(){ @Override public int compare ( Country o1 , Country o2 ) { double o1Density = o1 . population / o1 . area ; double o2Density = o2 . population / o2 . area ; if ( Math . abs ( o1Density - o2Density ) < 0.00001 ) { return 0 ; } else if ( o1Density > o2Density ) { return 1 ; } else { return - 1 ; } } }); System . out . println ( europe ); } } Your output would be: [ Germany: 81903000 , France: 64667000 , Norway: 4985900 , Sweden: 9514406 , Spain: 47212990 , Switzerland: 8014000 , Monaco: 36371 ] [ France: 64667000 , Germany: 81903000 , Monaco: 36371 , Norway: 4985900 , Spain: 47212990 , Sweden: 9514406 , Switzerland: 8014000 ] [ Norway: 4985900 , Sweden: 9514406 , Spain: 47212990 , France: 64667000 , Switzerland: 8014000 , Germany: 81903000 , Monaco: 36371 ] I don't recommend this way for some reasons: It is more likely that your code gets more difficult to read It's more difficult to reuse your code (you can't use the same Comparator in another location) It's more difficult to extend your code An argument for such an Comparator might be, that it is easier to read. But this is only an argument if the Comparator is very short. More examples StackOverflow: java class implements comparable","tags":"Code","title":"How to sort with Java"},{"url":"https://martin-thoma.com/web-engineering/","text":"Dieser Artikel beschÃ¤ftigt sich mit der Vorlesung â€žWeb Engineering\" am KIT. Er dient als PrÃ¼fungsvorbereitung. Ich habe Web Engineering bei Dr. Nussbaumer gehÃ¶rt. Ãœber die Vorlesung In der Vorlesung â€žWeb Engineering\" lernt man, welche besonderen Herausforderungen Web-Projekte beinhalten und wie man damit umgehen kann. Es wird zwar auch Ã¼ber technische Aspekte geredet (siehe Part 1), aber es geht vor allem um Projektplanung und -management. Insbesondere wird hier nichts konkret entwickelt. DafÃ¼r gibt es vermutlich das Praktikum, das aber unabhÃ¤ngig von der Vorlesung ist. Herr Dr. Nussbaumer hÃ¤lt die Vorlesung sehr interaktiv. Er stellt viele Fragen, Ã¼ber die man in der Vorlesung diskutieren kann und ist auch immer nach der Vorlesung bereit etwas genauer zu erklÃ¤ren. Die Struktur unter â€žVorbereitung\" richtet sich nach dem Aufbau der Folien. Vorbereitung PrÃ¼fungsprotokolle sind bei der Fachschaft Informatik zu erhalten. Mein PrÃ¼fungsprotokoll ist hier und die TeX-Quelldateien bekommt ihr natÃ¼rlich auch. Im Folgenden sind einige Stichpunkte aufgelistet, die jedem etwas sagen sollten. Geschichte 1945: Vannevar Bush , Memex 1965: Ted Nelson , Hypertext und Xanadu 1969: ARPANET 1985: Bill Atkinson (Apple), HyperCard 1989: Tim Berners-Lee, World Wide Web 1993: Mosaic PART 1: Technologies Markup, HTML, Ressources, Cookies, MIME Host, Server, Client, User Agent Hypertext Paradigm HTTP, HTTPS, FTP, SMTP, UDDI CGI SOAP , WebDAV Moore's Law, Nielson's Law Was ist der Unterschied zwischen Software Engineering und Web Engineering? â†’ Antwort auf Folie 47ff, part0-1 Paretoprinzip Was ist das W3C? Was sind die Ziele des W3C? Wer ist Teil des W3C? Zone File Uniform addressing â†’ Was ist das? URI, URL, URN, URC, RFC1630 PART 2: Project Management Chaos-Report der Standish Group (25%, 45%, 30%) Bad: Very high budget Good: Executive Management, User Involvement, Experienced Project Manager, Clear Business Objectives, Minimizing Scope, Requirements Process, Standard Software Infrastructure, Formal Methology, Reliable Estimates, Skilled Staff â€žWhen projects fail, it's rarely technical.\" Outsource, Find&Buy;, Develop new solution Teams: < 6 Entwickler < 6 Monate RERO Verantwortungsbereiche: Product Management: Wie verkaufe ich die Software? Program Management: Wie bringe ich das Projekt zu einem erfolgreichem Abschluss? Architekture: Wie halte ich die Software erweiterbar, anpassbar und wartbar? Development: Wie schreibe ich den Code von Methode abc in Klasse xyz? Test: Sind alle funktionalen und qualitativen Anforderungen erfÃ¼llt? Ist das System robust? User Experience: Passiert das, was der Nutzer erwartet? Kann man dem User die Bedienung der Software erleichtern? Release / Operations: Wie halte ich die Software Ã¼ber Jahre am laufen? Aufsplitten der Teams nach Funktionen oder Features Wo ist der Unterschied? Tasks & Tools Work Breakdown Structure GANTT chart PERT SWOT Analysis Risiken Cost-reduction expectations Data security / protection (IPR) Process discipline (Was ist das?) Loss of business knowledge Vendor failure to deliver Scope creep Government oversight / regulation Culture (language and callcenters) Turnover of key personnel Knowledge transfer Process Models Code and fix Waterfall model Prototyping model Evolutionary Development model: Only for small, scientific projects where project goal is unclear Spiral model: Risk-driven RUP von SAP MSF â†’ msdn Artikel Rollen: Product Management: Anwalt des Kunden, teamÃ¼bergreifende Projekt-Vision, betriebswirtschaftliche Sicht auf das Projekt Program Management: â€žProjektleiter\", Teamkommunikation, technische Sicht auf das Projekt Architecture, Development, Testing, Release / Operations User Experience: Anwalt des Benutzers Skalierung: Feature-Teams vs. Functional Teams Meilensteine: Extern sichtbare und Interim-Meilensteine Reuse-Oriented Approaches Agile Methoden: Scrum: Rollen: Scrum Master, Product Owner, Development Team Iterations, Sprints, User Stories Scrum Plakat Video: What is Scrum? , Scrum in 8 minutes , Scrum Refcard , Scrum Master Checklist XP : Paarprogrammierung, Lecture 24: Richard Buckland (45 minutes) Agile manifesto PART 3: Requirements Engineering Ablauf: Initiate: Project Charter, Identify business opportunity, gather business requirements, FOR WHO THE IS THAT UNLIKE OUR PRODUCT Elicitation: Refine requirements (Busines requirements, functional requirements, non-functional requirements), Coopers Persona-Ansatz ( Beispiele ) Asses: Understand and organize requirements, features and feature sets Specification: Software requirements specification Validation Gather requirements (Interviewing, Shadowing , surveys, brainstorming, user instructions - z.B. bei Atomkraftwerken gibt es wohl schon ProzessablÃ¤ufe) A11Y, L10N, I18N, G11N : BITV RNA: Relationship-Navigation Analysis WAI PART 4: Entwurf Logischer Entwurf (Abstrakt: Wireframes, Navigation patterns) â†” Physikalischer Entwurf (Konkret: UI Frameworks, Services) Content Management Aspects Content-Typen mÃ¼ssen definiert werden, um Inhalte von der Darstellung trennen zu kÃ¶nnen Content-Typen sind auch fÃ¼r die Suche relevant Templates mÃ¼ssen erstellt werden Welche Metadaten liegen vor? Wie kÃ¶nnen Metadaten weitergegeben werden? â†’ Rich Snippets Welche ArbeitsablÃ¤ufe habe ich? Inhalt kann in flachen/strukturierten Dateien oder in Datenbanken liegen. Strukturierte Dateien: XML, RDF (â†’ Video ), Microformats Software Interface Aspects Usability is the extent to which a product can be used by specified users to achieve specified goals with effectiveness, efficiency and satisfaction in a specified context of use. - ISO 9241-11 User Experience is a person's perception and responses that result from the use or anticipated use of a product, system or service. - ISO 9241-210 User-centered design â†’ Wiki Mentale Modelle: Taschenrechner, Explorer, Start-Vorgang, Einkaufssysteme, Hyperlinks, Tastatur Metaphern User-Modelle: Rollen, Markt-Anteile, Personas Hypertext Systm Aspects Known-item search / exploratory search Business Process Aspects Kommt noch Weiteres WSDL MSF vs. Scrum - Roles in Scrum HTTP Weitere Informationen Folgende Artikel sollte man lesen: Internet Geschichte des Internets Chronologie des Internets Diese Tutorials sollte man machen: XML Tutorial - XML Quiz SOAP Tutorial Typische Fragen Was ist Web Engineering? It's not science, and it isn't exactly engineering, either. Disziplin aus Disziplinen (Software Engineering, Hypermedia, Information Systems, Network Engineering) Teilweise ist es wie Software Engineering (Requirements engineering, reproduzierbare Erfolge durch strukturierte Herangehensweise), teilweise hat es typische Problemquellen, die im Software Engineering weniger verbreitet sind (Skalierbarkeit, Load balancing, Hypermedia). Was ist eine Ressource? Eine Ressource ist ein Objekt, dass von einem Webserver oder Websystem mittels eines standardisierten Protokolls ausgeliefert wird und durch einen MIME-Typen spezifiziert wird. Wie werden Ressourcen adressiert? Durch URIs, meist URLs aber auch URNs. Was ist ein Webservice? Ein Webservice ist eine Software-Anwendung, die mit einem URI eindeutig identifizierbar ist und deren Schnittstelle als XML-Artefakt definiert, beschrieben und gefunden werden kann. Diese Schnittstelle kann mit WSDL beschrieben werden. Was ist das Endpoint-ABC? Wurde durch die WCF geprÃ¤gt und ist z.B. so in der Web.config . Das ABC steht fÃ¼r ... Address (Wo ist der Endpoint?) Binding (Wie verbinde ich? Protokoll? Encoding?) Contract (Welche Informationen will ich Ã¼bertragen?) Siehe auch: Filip's Technical Blog Welche Ziele verfolgt das W3C? Web for Everyone Web on Everything Knowledge Base Trust and Confidence Wie ist der Arbeitsprozess beim W3C? Workshops â†’ Notes from members â†’ Briefing package with membership vote â†’ Requirements Document â†’ Working Draft â†’ Candidate Recommendation â†’ Proposed Recommendation â†’ W3C Recommendation ( source ) Interessante Fragen Vergleichen Sie RPCs und Web Services Web Services sind leichter skalierbar. (Siehe auch: StackOverflow ) Wie lÃ¤uft ein HTTP-Request ab? Siehe TechChannel.de Hintergrundwissen What really happens when you navigate to a URL OS-DNS-Cache on Linux What exactly happens when you browse a website in your browser? (fun to read) What happens when you type in a URL in browser? (well structured) Termine Web Engineering wird mÃ¼ndlich geprÃ¼ft. Dazu muss man sich bei Herrn Matthias Keller (matthias.keller@kit.edu) melden und einen Termin ausmachen. ZusÃ¤tzlich muss man sich Ã¼ber QISPOS anmelden. Datum : Dienstag, der 19. Februar 2013 um 14:30 Uhr (individuell, siehe Organisation) Ort : Geb. 20.21 (SCC), Raum 303 (individuell, siehe Organisation) Dauer : 15 Minuten Punkte : 4 ECTS","tags":"German posts","title":"Web Engineering"},{"url":"https://martin-thoma.com/disable-wikipedia-fundraising-banner/","text":"I didn't spend this year for Wikipedia because of the advertising. It really got on my nerves: Wikipedia advertising - Fundraising campaign But you can simply disable it: How to disable Wikipedia fundraiser You only have to go to: Preferences â†’ Gadgets tab â†’ Browsing â†’ check \"Suppress display of the fundraiser banner\" Now I'm happy â˜º","tags":"The Web","title":"Disable Wikipedia fundraising banner"},{"url":"https://martin-thoma.com/pdf-printing-on-windows-7/","text":"\"Printing\" files on PDF-printers is useful as you can save everything as a digital PDF file instead of printing it. I've just installed Typing Test TQ for testing my typing speed and I wanted to save my results. This wasn't possible, but I could print them. So I thought I could print it to a PDF file and store it this way on my computer. Once again, I didn't think of Microsoft. The Linux-Way How would you solve this problem on a Debian machine? Well, most Debian machines would have a PDF printer pre-installed. So you would simply click on print, choose the PDF printer and be happy. If it is not pre-installed, type: sudo apt-get install cups-pdf Now you can use a PDF printer. Done. It works. The Windows-Way Windows 7 does not have a PDF printer, but it has a \"Microsoft XPS Document Writer\". Lets see what this is: XPS General Information Open XML Paper Specification is an open specification for a page description language and a fixed-document format originally developed by Microsoft as XML Paper Specification (XPS) that was later standardized by Ecma International as international standard ECMA-388. It is an XML-based specification, based on a new print path and a color-managed vector-based document format that supports device independence and resolution independence. OpenXPS was standardized as an open standard document format on June 16, 2009. XPS vs. PDF Comparison of OpenXPS and PDF XPS vs PDF. What's the status? on superusers TL;DR XPS is an alternative for PDF. It lacks program support compared to PDF. Getting a PDF-Printer After a quick search, I found CutePDF . Seems to work, but I don't give any malware-freeness-guarantees. Although I don't know if there is malware, there is definitely some spam content: Windows 7: Install another browser toolbar Why can't it simply only install a PDF-printer without getting annoyed with toolbars? I never had this problem on Linux...","tags":"Cyberculture","title":"PDF-Printing on Windows 7"},{"url":"https://martin-thoma.com/unreal-tournament-2004/","text":"I am currently at home and I found Unreal Tournament 2004 in my old stuff. Of course, I had to play it again â˜º Before you start, you might want to get the latest version. You have to find the patches by yourself. According to this page , you get all updates / bonus content with \" Mega Pack \" (201 MB). It's asthonishing that there is neither a possibility to upgrade the game within the game, nor an official source for patches. I guess providing a patches is an easy way to spread viruses. Do I have any chance to check if it's a valid patch or a patch with a virus? Error I played \"COPT - Camper and Sniper\" for about half an hour and got this error: UT2004 Build UT2004_Build_[2005-11-23_16.22] OS: Windows NT 6.1 (Build: 7601) CPU: GenuineIntel PentiumPro-class processor @ 2133 MHz with 3764MB RAM Video: Intel(R) HD Graphics (2372) General protection fault! History: UObject::ConditionalDestroy <- UObject::GetFullName <- DispatchDestroy <- DispatchDestroys <- UObject::PurgeGarbage <- UObject::CollectGarbage <- UObject::StaticExec <- UEngine::Exec <- UGameEngine::Exec <- UPlayer::Exec <- UViewport::Exec <- UWindowsViewport::Exec <- APlayerController::execConsoleCommand <- (ExtendedConsole Package.ExtendedConsole @ Function Engine.Console.Tick : 002C) <- UObject::ProcessEvent <- (InteractionMaster Package.InteractionMaster, Function Engine.InteractionMaster.Process_Tick) <- UInteractionMaster::MasterProcessTick <- ULevel::Tick <- (NetMode=0) <- TickLevel <- UGameEngine::Tick <- Level Unbenannt <- UpdateWorld <- MainLoop <- FMallocWindows::Free <- FMallocWindows::Realloc <- 10910191 0 FArray <- FArray::Realloc <- 0*2 <- FMallocWindows::Free Some Links Team stats by Hammerlock770 (another version is here , if the linked site gets offline) UT2004 Stats Official forum","tags":"Cyberculture","title":"Unreal Tournament 2004"},{"url":"https://martin-thoma.com/my-blog-in-2012/","text":"I get a lot of data about my visitors which I would like to share. The following data is from 2012 of my domain martin-thoma.com. It was collected by Piwik. Note that I excluded my visits. Articles These articles had the most visitors: How to draw a finite-state machine Performance of Matrix multiplication in Python, Java and C++ LaTeX-Vorlage fÃ¼r ein Lastenheft (german) Computer Science Jokes Wie fÃ¼hre ich einen Induktionsbeweis? (german) Recently, my article Frauenquote am KIT got also very popular. Visitors According to awstats: Different users: 81,028 Visits: 119,855 Page accesses: 2,379,654 Bytes sent: 27.95 GB According to Piwik: Number of visitors of my blog Where do they come from? Continent - Piwik Statistics 2012 Country - Piwik Statistics 2012 Region - Piwik Statistics 2012 Hardware Screen size Desktop vs. Mobile Software Operating Systems Browser families Browsers Browser Plugins Provider Providers Referrers Referrers Obviously, search engines are much more important for my website than other websites. Visitors who find me with Google, use these terms: \"lastenheft vorlage\" or \"lastenheft beispiel\" â†’ LaTeX-Vorlage fÃ¼r ein Lastenheft \"induktionsbeweis\" â†’ Wie fÃ¼hre ich einen Induktionsbeweis? \"computer science jokes\" â†’ Computer Science Jokes \"basiswechselmatrix\" â†’ Wie bestimme ich die Basiswechselmatrix? \"chomsky normalform\" â†’ Konstruktion der Chomsky-Normalform Spam Akistmet got a lot of comment spam on my blog: Akismet total stats for 2012 Akismet spam stats for 2012","tags":"My bits and bytes","title":"My blog in 2012"},{"url":"https://martin-thoma.com/how-fast-are-electrons-moving/","text":"I've recently learned something about electric circuits. The ideal model of circuits does ignore that electrons actually need time to pass the components of the circuit. So we introduced the \"dead time model\". So we added a model component for each real component that does only delay the incoming signal. But I've wondered if dead time of a cable wasn't important, too. So I thought the question would be How fast are electrons moving in a cable? , but I just realized that the question is How fast does a signal move in a wire? . How fast are electrons moving through a wire? If you have electric current \\(I\\) (measured in Ampere), the wire is a cylindric conductore with a cross-sectional area of \\(A\\) , \\(e = -1.6021766 \\cdot 10&#94;{-19} C\\) (coulombs) is the charge of an electron an \\(Q\\) is \\(\\frac{\\text{mobile electrons}}{\\text{volume}}\\) . \\(v = \\frac {I}{QeA}\\) According to this source, \\(Q = 8.5 \\cdot 10&#94;{22} \\frac{1}{cm&#94;3}\\) for copper. If \\(I=1 A\\) and if your wire has a radius of 0.5mm, you get: $v= \\frac{1 A}{ 8.5 \\cdot 10&#94;{22} \\frac{1}{cm&#94;3} \\cdot e \\cdot ((0.5mm)&#94;2 \\cdot pi)} = 9.349 \\cdot 10&#94;{-5} \\frac{m}{s} = $ (see Wolfram|Alpha ). Hmm ... seems to be very slow. Is my calculation correct? How fast are electrical signals moving through a wire? See physics.stackexchange.com \\(v = \\frac{c}{\\sqrt{\\mu_r \\varepsilon_r}}\\) where \\(\\varepsilon_r\\) is relative permittivity and \\(\\mu_r\\) is relative magnetic susceptibility . For copper: \\(\\mu_r = 0.999994\\) \\(\\varepsilon_r = 3\\) , as you can't measure permeability of metallic conductors (see \"Elektromagnetische Felder und Wellen\". Paul Lorrain, Dale R. Corson, FranÃ§ois Lorrain, page 75) \\(v = \\frac{c}{\\sqrt{0.999994 \\cdot 3}} = 0.577352 \\cdot c\\) How fast are electrons moving around an atom? Well, first of all I have to mention, that electrons seem not to move around a nucleus as this image suggests: Atom according to Bohrs model A model with atomic orbitals seems to be more accurate. However, you can calulate the speed \\(v\\) an electron would have in Bohrs model. The centripedal force is \\(F_Z = \\frac{m \\cdot v&#94;2}{r}\\) This force pushes the electron away from the nucleus. The coulomb-force is \\(F_C = \\frac{e&#94;2}{4 \\pi \\varepsilon_0 r&#94;2}\\) where \\(\\varepsilon_0 \\approx 8.8541 \\cdot 10&#94;{-12} \\frac{F}{m}\\) is permittivity . Now you calculate: \\begin{align}F_\\mathrm{C} = F_\\mathrm{Z} \\quad &\\Leftrightarrow \\quad \\frac{e&#94;2}{4 \\pi \\varepsilon_0 r&#94;2} = \\frac{m_{e}v&#94;2}{r}\\\\ &\\Leftrightarrow \\quad v&#94;2 = \\frac{e&#94;2}{4 \\pi \\varepsilon_0 r m_e} = \\frac{e&#94;2}{4 \\pi \\varepsilon_0 m_e} \\cdot \\frac{1}{r} \\end{align} Ok, we're almost there. But how do we get \\(r\\) ? Well, you have to know this equation: \\( m_{e} v r = n \\hbar\\) where \\(n\\) is the principal quantum number and \\(\\hbar\\) is the reduced Planck constant . So you get: \\(\\Leftrightarrow r = \\frac{n \\hbar}{v m_e}\\) Now insert this in the equation above: \\begin{align} v&#94;2 &= \\frac{e&#94;2}{4 \\pi \\varepsilon_0 m_e} \\cdot \\frac{1}{\\frac{n \\hbar}{v m_e}}\\\\ \\Rightarrow v &= \\frac{e&#94;2}{4 \\pi \\varepsilon_0 n \\hbar} \\end{align} Lets take a hydrogen nucleus ( \\(n=1\\) ): We get \\(2.19 \\cdot 10&#94;6 \\frac{m}{s} \\approx 7.88 \\cdot 10&#94;6 \\frac{km}{h}\\) (see Wolfram|Alpha ). This is much less than 1% of the speed of light (which is \\(1.079 \\cdot 10&#94;9 \\frac{km}{h}\\) ) Sources Very good: How fast do electrons travel in an atomic orbital? How fast do electrons move through a conductor? â†’ SPEED OF \"ELECTRICITY\" Explanation for speed of an electrical impulse Not so good: Drift velocity Speed of electricity Wave propagation speed","tags":"Cyberculture","title":"How fast are electrons moving?"},{"url":"https://martin-thoma.com/c-preprocessor-snippets/","text":"The C++ Preprocessor - which is in fact the same as the C Preprocessor - provides some very basic, but powerful abilities. I haven't used them quite often, but I have seen some nice examples. So here are some C++ Preprocessor Snippets: Maximum / Minimum If you want to find the maximum / minimum of two elements, no matter of which type, you can do something like this: #include <iostream> #define MAX(a, b) ((a < b) ? b : a) using namespace std ; int main () { cout << MAX ( 42 , 1337 ) << endl ; cout << MAX ( 1337 , 42 ) << endl ; cout << MAX ( - 1337 , 42 ) << endl ; cout << MAX ( 1337.0 , 42 ) << endl ; return 0 ; } Absolute Value You can get the absolute value like this: #include <iostream> #define ABS(a) (a < 0 ? -(a) : a) using namespace std ; int main () { int a = 42 , b = - 43 , c = 0 , d = - 1337 ; cout << ABS ( a ) << endl ; cout << ABS ( b ) << endl ; cout << ABS ( c ) << endl ; cout << ABS ( d ) << endl ; return 0 ; } By the way, brackets around a are important, because without them you could get: a=1,b=3 ABS(a-b) = ABS(1-3) = (1-3 < 0 ? -1-3 : 1-3) = -2 < 0 ? -4 : -2 = -4 Swap variable content This is an example for a multiline replacement. #include <iostream> #define SWAP(a, b) { int tmp; \\ tmp = b; \\ b = a; \\ a = tmp; \\ } using namespace std ; int main () { int a = 42 , b = 1337 ; swap ( a , b ); cout << a << endl ; cout << b << endl ; return 0 ; } See also Wikipedia: C preprocessor Tips and tricks using the preprocessor: Part one - part two A very good article about the meaning of #import, #error, #pragma. It is written very well and has some examples. Obfuscated C: Calculate PI Do you know more preprocessor snippets that are used very often or which are interesting?","tags":"Code","title":"C++ Preprocessor Snippets"},{"url":"https://martin-thoma.com/wie-wendet-man-den-transformationssatz-an/","text":"Folgender Artikel basiert auf meinem Mitschrieb der Analysis III Ãœbung bei Herrn Bolleyer. Sei \\(A \\in \\mathfrak{B}_d\\) mit \\(A&#94;0 \\neq \\emptyset\\) und \\(\\lambda_d (A \\setminus A&#94;0) = 0\\) sowie \\(\\phi \\in C&#94;1(U, \\mathbb{R}&#94;d)\\) mit \\(U \\subseteq \\mathbb{R}&#94;d\\) offen und \\(A \\subseteq U\\) . Weiter sei \\(\\phi\\) auf \\(A&#94;0\\) injektiv und \\(\\det(\\phi'(x)) \\neq 0\\) fÃ¼r \\(x \\in A&#94;0\\) . Sei \\(f \\in \\mathfrak{L}&#94;1(\\phi(A))\\) oder \\(f \\geq 0\\) auf \\(A\\) so gilt \\(\\int_{\\phi(A)} f(x) dy = \\int_A f(\\phi(x)) | \\det(\\phi'(x)) | dx\\) In Anwendungen: \\(Y \\in \\mathfrak{B}_d\\) und \\(f: Y \\rightarrow \\overline{\\mathbb{R}}\\) messbar. Aufgabe : Berechne \\(\\int_Y f(x) dy\\) falls es existiert. Vorgehensweise: Zeige \\(f\\) integrierbar oder \\(f \\geq 0\\) auf \\(Y\\) Finde \\(A \\in \\mathfrak{B}_d\\) und \\(\\phi: A \\rightarrow \\mathbb{R}&#94;d\\) mit \\(\\phi(A) = Y\\) und den obigen Eigenschaften \\(\\phi\\) sollte so gewÃ¤hlt sein, dass die spÃ¤teren Rechenwege relativ einfach werden. Berechne \\(\\int_{Y} f(y) dy = \\int_{\\phi(A)} f(y) dy = \\int_{A} f(\\phi(x)) |\\det (\\phi'(x)) | dx\\) Beispiele Sei \\(Y := \\{(x,y) \\in \\mathbb{R}&#94;2 | 1 \\leq \\| (2,2) - (x,y)\\| \\leq 2\\}\\) . Setze \\(\\phi : \\mathbb{R}&#94;2 \\rightarrow \\mathbb{R}&#94;2\\) mit \\(\\phi(r, \\varphi) := \\begin{pmatrix}2\\\\2\\end{pmatrix} + r \\cdot \\begin{pmatrix}\\cos(\\varphi)\\\\ \\sin(\\varphi) \\end{pmatrix} \\) \\(\\phi \\in C&#94;1(\\mathbb{R}&#94;2, \\mathbb{R}&#94;2)\\) und fÃ¼r \\(r \\in \\mathbb{R}\\) gilt \\(\\det \\phi'(r, \\varphi) = \\det \\left ( \\begin{array}{cc} \\cos(\\varphi) & - r \\sin(\\varphi)\\\\ \\sin(\\varphi) & r \\cos (\\varphi) \\end{array} \\right ) = r\\) FÃ¼r \\(r \\neq 0\\) gilt also \\(\\det \\phi'(r, \\varphi) \\neq 0\\) fÃ¼r jedes \\(\\varphi \\in \\mathbb{R}\\) . \\(\\phi\\) ist nicht injektiv auf \\(\\mathbb{R}&#94;2\\) . Setze \\(A := [1,2] \\times [0, 2\\pi]\\) . Dann ist \\(A&#94;0 = (1,2) \\times (0,2 \\pi)\\) und \\( \\phi\\) auf \\(A&#94;0\\) injektiv. AuÃŸerdem ist \\(\\det \\phi'(x) \\neq 0\\) fÃ¼r \\(x \\in A&#94;0\\) . FÃ¼r \\(f:Y \\rightarrow \\mathbb{R}\\) mit \\(f(Y_1, Y_2) := Y_1 - Y_2\\) gilt \\(f \\in \\mathfrak{L}&#94;1(Y)\\) ( \\(Y\\) kompakt, \\(f\\) stetig) AuÃŸerdem: \\begin{align} \\int_Y f(y) dy &= \\int_\\phi(A) f(y) dy \\\\ &\\stackrel{Tr}{=} \\int_A f(\\phi(r, \\varphi)) |\\det \\phi'(r, \\varphi)| d(r, \\varphi) \\\\ &= \\int_A r(2 + r \\cos(y) - 2 - r \\sin(\\varphi)) d(r, \\varphi) \\\\ &= \\int_1&#94;2 (\\int_0&#94;{2\\pi} r&#94;2 (\\cos \\varphi - \\sin \\varphi d \\varphi) dr \\\\ &= \\underbrace{(\\int_1&#94;2 r&#94;2 dr)}_{< \\infty} \\underbrace{(\\int_0&#94;{2\\pi} \\cos \\varphi - \\sin \\varphi d \\varphi)}_{= 0}\\\\ &= 0 \\end{align}","tags":"Cyberculture","title":"Wie wendet man den Transformationssatz an?"},{"url":"https://martin-thoma.com/blender-open-movies/","text":"Big Buck Bunny Elephants Dream Sintel More information www.sintel.org Soundtrack: I Move On","tags":"Cyberculture","title":"Blender Open Movies"},{"url":"https://martin-thoma.com/why-are-microsoft-products-so-user-unfriendly/","text":"Another rage-post ... Loading times Did you ever work with eclipse? Then you might know the feeling, that it takes an eternity until Eclipse has started. I've just stopped it. Eclipse takes 30 seconds to start: Eclipse Juno loading screen Visual Studio 2012 takes 1 minute and 15 seconds to start: Visual Studio Ultimate - Loading screen But that's not the worst. It's okay if it takes long to start, if it's later a swift. But it's not. I get those loading screens from time to time without having done anything: Visual Studio 2012 - loading something without any action from my side Why is it loading something from time to time without interaction? What does Visual Studio load? Control The next big problem I have with Microsoft products is the lack of control. I would like to know what are the effects of a command I use before I use it - no matter if it is a command line command or a GUI or key-press-combination command. As it is very difficult to make GUI commands unambiguous, I really like the command line for some tasks. Why doesn't Windows offer a default command line that is usable? I mean, yes, you have the PowerShell ... but why isn't it the default shell? Why does the user have to know that there are other (better?) shells? Is there any reason not to use the PowerShell in Windows 7? And even the PowerShell misses some really basic tools. I mean, did you try the path autocompletion (with tab) on bash (the Linux shell)? It completes the path / command, if there is only one possibility. If there are more possibilities, the user gets displayed all options (if there are too many, he will get asked before all are displayed). The Windows-shells go through each possibility. Here are some screenshots of the shells displaying the content of the current folder: Windows32 cmd Windows PowerShell v1.0 Now compare this to Linux: Gnome shell (bash) Where do you find easier what you need? And why do they have a black background with white font color? Try to work with this for some hours and than compare it to a shell with black font size and white background... Missing (command line) tools I like using git / svn from command line. But the default way to use SVN (and eventually GIT) seems to be by GUI. Why results in a crappy, overblown right click menu: Windows right click menu Now compare this to Linux 10.04 with GNOME: Right click menu on GNOME 2 And I should also mention that I didn't clean up my Linux system for over one year. I use it every day, install new software, remove software, forget to remove software. I have git and svn on my Linux machine as well as Apache, Python, some games, ... The Windows 7 machine is a fresh install. It has better hardware and I only use it for work (so it basically only has TurtoiseSVN, Visual Studio and IIS). I guess this would be even worse if I used it every day. Updates Windows makes its updates at very bad times. Sometimes it just makes an update and you have to wait for quarter of an hour to finish it, before you can shut down. Why? Can't you just ask the user before you make an update? A friend of mine had a tutorial after which she wanted to go to a Christmas party. Guess what happened: Before she could shut down the computer, Windows decided to make automatically an update. Took about 15 - 20 minutes. No Christmas parties for Windows users. Automatic shutdown of Windows Windows 7: Automatic update installation Windows really shut down my computer automatically and blocked it for about 15 minutes. What if I had to hold a presentation? What if I downloaded something? Nice features, crappy realization Windows has a very nice feature: You an search at the \"start\". But why doesn't it work for every program? I've searched for \"winver.exe\", a program shipped per default from Microsoft. Why can't you find this in start? Windows Start search If I have to type the whole name, this feature is essentially useless... Microsoft OWA is an online email service. A friend showed me this usability desaster: Microsoft OWA No structure for programs Where do programs get installed? C:\\ C:\\Program Files C:\\Program Files (x86) If you have a German system, the explorer will show a German path although the underlying path is English. What the hell? And switching languages isn't easy on Microsofts Systems . Drivers Installation CD Although many drivers exist for Windows, you have to install them almost always by CD. Mouse drivers You have to INSTALL mouse drivers! WTF! I expect an USB mouse to work immediately and not to get something like that: Installing USB mouse in Windows 7 Windows Explorer No tabs Clover tries to fix that, but I don't want to install a third party tool for such a basic tool. Structure Windows 7 Explorer Shell There is so much wrong with the Windows Shells: You can't maximize it (see explantation ) Crappy autocomplete: In Linux, if you have multiple ways to autocomplete, you get a list of the options. Windows 7 only pics the first. PowerShell: Its soooo slow! I don't want to wait for my shell to start! Windows Terminal in 'Full Screen' A wrap-up for Windows 8 Microsoft Bob Have you ever heard of Microsoft Bob ? I guess we should not complain about Windows 8 desktop, if you have seen this desktop environment interface...","tags":"Code","title":"Why are Microsoft products so User unfriendly?"},{"url":"https://martin-thoma.com/how-can-i-sketch-an-application/","text":"I've recently participated in a medium size software project. This project is rather fixed for a web project, so we don't suffer from rapid changes (\"rapid\" in terms of other web applications), but nether the less they change. The task seemed to be clear at the beginning, but bit for bit my team of developers discovered details that were not so clear. In this project I have learned that a GUI / prototype driven development can be of great benefit. I assumed this beforehand, but I didn't expect how much it helped. So, I had the idea to create a good GUI to have something to talk about. How do you create a GUI for a web project? HTML is quite simple I know it very well everything I write is obviously possible to realize but the result looks too much like the resulting product. The customer might think that we already have some functional prototype it is also unsatisfying to print HTML pages or screenshots of rendered browser views although HTML is easy, arranging items on a screen might take a while GIMP GIMP was the next option I tried, but its disadvantage is too severe to think seriously about using it for rapid GUI prototyping: It takes ages! A friend of mine helped me out of my misery. He told me of a product called \" Balsamiq \". Balsamiq Balsamiq is easy to use, has a lot of very intuitive features and is able to generate a linked PDF. This means, you can add links to some parts of the interface and simulate interactivity. The user should have opened the slides in full screen, so that on slide fills the screen. Then you might even think it was an web application. Here is an example PDF created with Balsamiq What's great about Balsamiq Balsamiq was carefully designed, is available (and working!) on Windows 7 and Ubuntu 10.04 and via browser. The learning curve is very well. I keep finding new features as I need them. So I first intuitively found the most important ones and recognized advanced ones later. Here are two screenshots of the GUI of the Balsamiq web service: Balsamiq GUI overview Do you see the arrow-symbol? This looks very cool in drafts. Why doesn't GIMP provide anything similar? Edit an element with Balsamiq What I've missed No application is perfect, so I also found some specials that Balsamiq didn't offer: Form elements in tables Adjusting table column width I've found workarounds for both problems, but I guess there could be a better way to solve it. Nevertheless, Balsamiq is a great application that might help a lot to develop great software!","tags":"Code","title":"How can I sketch an application?"},{"url":"https://martin-thoma.com/when-advertising-becomes-spam/","text":"The Web is great. You can easily find and publish information. It is great for trading as you can search through millions of articles and hundreds of vendors to find the product that fits best to your needs and is as cheap as possible. But recently I get a lot of spam from companies I like ( Amazon , PayPal and Thalia ). I like to get some e-mails from those companies. But how can they provide relevent content instead of spam? When is it good advertising and when does advertising become spam? Intervall of E-mails As a rule of thumb, I would say more e-mails without user-interaction than once a month is spam. So it is perfectly fine if I buy ten products in one week to get ten sales confirmation e-mails. But is not okay to get more than once a month information about the cheapest products, the latest cupons or the latest electronics that I could buy as a present for christmas. Of course, if the user has actively changed the interval of e-mails to once a week or even every day, it is okay to sent him e-mails every day. But this should be opt-in. So the user has to get active to get those e-mails. Easy unsubscribe In every e-mail should be a link to unsubscribe from this type of mail. The user should not have to login first, before he can unsubscribe. So the link has to be randomly generated for every user. Unambiguous sender address Thalia uses the address info@produktnews.thalia.de for sending product news. This is great, because I can create a filter that automatically deletes these e-mails. So although the unsubscribe-link doesn't work, I can get rid of this kind of spam without missing my order confirmations that get sent from info@thalia.de (that should be something like confirmation@thalia.de ) Although Thalia has one address that is clearly only for product information, they didn't solve this problem. They also use thalia@produktnews.thalia.de , what makes it much more difficult for me to filter spam. But it's better than PayPal. They seem to use paypal@e.paypal.de which could have any content. More ideas? Does anybody have more ideas how companies could make online advertising, but avoid to spam people?","tags":"The Web","title":"When advertising becomes spam"},{"url":"https://martin-thoma.com/microsoft-product-flavor-hell/","text":"As a KIT student I may download pretty much of Microsofts software from a MSDNAA-shop for free. So I've downloaded Windows 7 and Visual Studio. I need them for work, so I thought it would be as simple as choosing to download it. But I didn't think of Microsofts will to make business at the expense of user experience. Changing the language The Linux way If you want to change the language on a Linux (GNOME) system, you have to go to System â†’ Administration â†’ Language support You can choose from 140 languages for free, without any problems. However, most of them are only partially translated, but 28 are fully translated ( source ). 10 minutes to search through the menus, 1 minute to change the language. Now the Windows way: I don't know where I can change the language in Windows 7, so lets search in the settings. [10 minutes pass] Well, lets google for the right way to achieve a simple language change: Google search for language change in Windows. About 5 minutes. So, it seems as if I needed Windows 7 Ultimate or Windows 7 Enterprise edition. Which version do I have? Let's search ... hm, seeems as there are some versions: Windows 7 editions And also and Windows 7 Starter, Windows 7 Home Basic. Did I already mention the family pack? It's so complicated ... there is even a Wikipedia page about Windows 7 editions ! Find out which version I have (another 15 minutes of searching how to do so): winver search And finally: winver Aaaaargh! I don't have the right edition to be able to change my language to English. I have to reinstall the whole system to get it in English! Well, but as there are so many different editions, there have to be some differences. Lets see if I can find them. [5 minutes later] Oh, Microsoft offers some nice-looking information at windows.microsoft.com : Windows 7 editions differences What the #$@&%*!? Why do they write down similarities? I don't want to know what's the same, I want to know the difference! And even the similarities are meaningless. For example Start programs faster and more easily, and quickly find the documents you use most often. If you use comparisons as \"faster\" or \"more easily\" you have to say what you compare. Faster than Vista? Faster than DOS? Faster than Linux? All of those lines are meaningless marketing slang that does not offer any useful peace of information and only wastes time. Result: I have wasted about one hour later, I know that I can't get my system in English without reinstalling it. I have to waste another hour to download it and even one more hour to reinstall it. Linux vs. Windows: 11 minutes of work, nothing to pay vs. 3 hours of work (I got it for free, as I am a student. Otherwise, I might have had to pay about $150). Visual Studio The team I am working with created a diagram on one developers machine. After he had to go, we wanted to continue on another developers machine. So we saved the version and opened it on the other machine. So far so good. After a while we noticed, that we were not able to edit the content of the diagram! The first developer had Visual Studio 2012 Ultimate, the second one \"only\" Visual Studio 2012 Professional. The difference is obvious, isn't it? NO, IT IS NOT! Finally, a little story. Some weeks ago, a prof had some problems showing his slides that were made with Microsoft PowerPoint. The bulled points were showing, but not the text. A friend of mine said: \"The source of this problem is obvious. He certainly does not have PowerPoint Ultimate\" â˜º TL;DR Microsoft creates a lot of different editions for their software. \"Ultimate\" seems to be always the best. Microsoft makes things too complicated, without any reason to do so. This video shows what I mean: I don't understand why a company with that much money, great developers and a lot of user feedback is not able to produce satisfactory, working software.","tags":"Cyberculture","title":"Microsoft product flavor hell"},{"url":"https://martin-thoma.com/creating-gantt-charts/","text":"I am currently involved in a software project and I should create a Gantt chart. So I've searched for tools that allow me to do so, but it was astonishingly difficult to find good tools. I'm not completely content with any of them, but I would like to share my experiences. Gantter Overview Gantter is a free online tool that allows you to create Gantt charts. It looks like this: Overview of Gantter It is easy to use and has a good interface. I can simply define depencies: Gantter Predecessor depency Export Gantter offers some export options: HTML, PDF , PNG , MS-Project (.xml). All export options I've tried are unconvincing. I couldn't save the HTML export, the PDF export was splitted over several pages and the PNG ... well, it's a PNG. As I am currently on a Linux machine, I can't try the MS-Project export. Google Drive Gantter also has a Google Drive integration, but it requests these permissions: Google Drive permissions requested by Gantter I have contacted them today (11.12.2012) and asked why they want these permissions. I'll update this post as soon as I get an answer. My recommendation: Don't give them those rights! You can create an account without a Google Drive permission. GanttProject GanttProject is a Java Gantt chart program (as you might have noticed because of the SWING design): GanttProject - Overview It's quite good, but sometimes I got the feeling that it doesn't instantly response. It's perhaps imagination as I always think that of Java projects. The HTML-export is not so good. It basically converts the chart to an image and embeds this into a HTML page. This is not what I thought of! This way, you can't search or copy the tasks. You also can't see more information about the task. GanttProject export function GNOME Planner Planner is part of GNOME. Planner - Overview This is how you create a new task: Planner: Create a new task It is very annoying that you always have to click on \"Change\", then on \"As soon as possible\" change it to \"fixed date\" and then you can click on a date. Why don't you allow the user to click on a date and when he does, change it automatically to \"fixed date\"? The HTML-export is good, but I would also like to click on a tasks' bar and get the associated task highlighted (and perhaps some additional information). Trac jsGantt plugin You can let Trac automatically create a Gantt chart with Trac jsGantt plugin . According to this link, it should look like this: jsGanttSample I knew that I had to install the MasterTicketsPlugin to make it possible to add ticket dependencies. With that, it looked like this: jsGantt only with MasterTicketsPlugin Not quite what I've expected. So I guess I will also need SubticketsPlugin and TimingAndEstimationPlugin . Update: These Trac-Plugins are crap. The Gantt-Chart that was created looks ugly and doesn't look like I've expected. LaTeX pgfgantt This piece of LaTeX: \\documentclass { article } \\usepackage [pdftex,active,tightpage] { preview } \\setlength\\PreviewBorder { 2mm } \\usepackage { pgfgantt } \\begin { document } \\begin { preview } \\begin { ganttchart }{ 12 } \\gantttitle { 2012 }{ 12 } \\\\ \\gantttitlelist { 1,...,12 }{ 1 } \\\\ \\ganttgroup { Group 1 }{ 1 }{ 7 } \\\\ \\ganttbar { Task 1 }{ 1 }{ 2 } \\\\ \\ganttlinkedbar { Task 2 }{ 3 }{ 7 } \\ganttnewline \\ganttmilestone { Milestone }{ 7 } \\ganttnewline \\ganttbar { Final Task }{ 8 }{ 12 } \\ganttlink { elem2 }{ elem3 } \\ganttlink { elem3 }{ elem4 } \\end { ganttchart } \\end { preview } \\end { document } generates this Gantt chart: LaTeX: pgfgantt for creating Gantt charts Source is here . Another LaTeX Gantt chart solution This source: \\documentclass { article } \\usepackage [pdftex,active,tightpage] { preview } \\setlength\\PreviewBorder { 2mm } \\usepackage { gantt } \\begin { document } \\begin { preview } \\begin { gantt }{ 10 }{ 12 } \\begin { ganttitle } \\numtitle { 1 }{ 1 }{ 12 }{ 1 } \\end { ganttitle } \\ganttbar { a task }{ 0 }{ 2 } \\ganttbarcon { a consecutive task }{ 2 }{ 4 } \\ganttbarcon { another consecutive task }{ 8 }{ 2 } \\ganttmilestone [color=cyan] { Milestone with color! }{ 4 } \\ganttbar { another task }{ 2 }{ 2 } \\ganttbar [color=cyan] { another coloured task }{ 4 }{ 4 } \\ganttbar { another task }{ 4 }{ 2 } \\ganttcon { 4 }{ 5 }{ 4 }{ 7 } \\ganttmilestonecon { A connected Milestone }{ 7 } \\ganttbarcon { another consecutive task }{ 8 }{ 2 } \\end { gantt } \\end { preview } \\end { document } creates Another Gantt solution Full source is here . Although the result looks very nice, I don't think LaTeX is an optimal solution for Gantt charts of software projects. Yes, you get a great result. But it takes a lot of time and after a week or so this particular chart is definitely outdated. You can't add more information directly as you could do it with HTML tooltips. I don't know if you can produce a linked PDF, but I guess this would be quite a lot of manual work. More tools ProjectLibre was recommended to me, but it is not in the Ubuntu repository â˜¹ Conclusion LaTeX rulez. If you want nice looking results, you should definitely use LaTeX. Although I think combining an automatically generated Gantt-chart with tickes would be nice, this seems not to be possible by now.","tags":"The Web","title":"Creating Gantt Charts"},{"url":"https://martin-thoma.com/31-bwinf-runde-1-aufgabe-2/","text":"Die Aufgabenstellung Zum Transport von Geld werden schwer bewachte Geldtransporter eingesetzt. In einem solchen Geldtransporter kÃ¶nnen Koffer mit MÃ¼nzen transportiert werden. Die Koffer enthalten MÃ¼nzen in unterschiedlicher Menge und mit unterschiedlichem Gesamtwert. Entsprechend unterscheiden sich die Koffer in Gewicht und Wert. Da kommt so einiges an Gewicht zusammen. Es ist daher notwendig, den Transporter gleichmÃ¤ÃŸig zu beladen, so dass er nicht zu einer Seite umkippen kann. Unser Transporter hat links und rechts je einen Kofferraum. FÃ¼r jeden Kofferraum lassen sich Gesamtwert und Gesamtgewicht der darin enthaltenen Koffer bestimmen. Damit der Transporter keine Schlagseite bekommt, mÃ¼ssen die Koffer so eingerÃ¤umt werden, dass die Differenz zwischen den beiden Gesamtgewichten minimal ist. Aus versicherungstechnischen GrÃ¼nden dÃ¼rfen die beiden Gesamtwerte sich auÃŸerdem um hÃ¶chstens 10.000 Euro unterscheiden. Schreibe ein Programm zur Verteilung der Geldkoffer auf die beiden KofferrÃ¤ume. ÃœberprÃ¼fe dein Programm mit den auf www.bundeswettbewerb-informatik.de abgelegten Beispielen mit Angaben zu Werten und Gewichten der einzelnen Koffer. Quelle: www.bundeswettbewerb-informatik.de VollstÃ¤ndiger Pseudocode Pseudocode zum 31. BwInf, Runde 1, Aufgabe 2 LÃ¶sung mit GLPK Der folgende Code muss als partition.mod gespeichert werden: /* PARTITION */ /* Written in GNU MathProg by Martin Thoma <info@martin-thoma.de> */ /* Given a set of items I = {1,...,m} with weight w[i] > 0, the PARTITION problem is to split the set of items into two sets such that the absolute value of the difference of the sum of weights of the two sets is minimal */ param m, integer, > 0; /* number of items */ set I := 1..m; /* set of items */ param w{i in 1..m}, > 0; /* w[i] is weight of item i */ param v{i in 1..m}, > 0; /* v[i] is value of item i */ param c, > 0; /* maximum value difference */ param z{i in I, j in 1..m} := /* z[i,j] = 1 if item i is in bin j, otherwise z[i,j] = 0 */ if i = 1 and j = 1 then 1 /* put item 1 into bin 1 */ else if exists{jj in 1..j-1} z[i,jj] then 0 /* if item i is already in some bin, do not put it into bin j */ else if sum{ii in 1..i-1} w[ii] * z[ii,j] + w[i] > c then 0 /* if item i does not fit into bin j, do not put it into bin j */ else 1; /* otherwise put item i into bin j */ check{i in I}: sum{j in 1..2} z[i,j] = 1; /* each item must be exactly in one bin */ param n := 2; display n; set J := 1..n; /* set of bins */ var x{i in I, j in J}, binary; /* x[i,j] = 1 means item i is in bin j */ s.t. one{i in I}: sum{j in J} x[i,j] = 1; /* each item must be exactly in one bin */ /* analog zu http://lists.gnu.org/archive/html/help-glpk/2007-08/msg00036.html */ s.t. lim1{j in J}: (sum{i in I} v[i] * x[i,1]) - (sum{i in I} v[i] * x[i,2]) <= c; s.t. lim2{j in J}: (sum{i in I} v[i] * x[i,2]) - (sum{i in I} v[i] * x[i,1]) <= c; /* the difference of the values may not be more than 10000 */ s.t. lim3{j in J}: (sum{i in I} w[i] * x[i,1]) - (sum{i in I} w[i] * x[i,2]) >= 0; minimize obj: (sum{i in I} w[i] * x[i,1]) - (sum{i in I} w[i] * x[i,2]); /* No abs because of linearity: http://old.nabble.com/How-to-get-a-variable's-absolute-value-with-GNU-mathprog-tt22241565.html*/ /* objective is to minimize the difference of weights */ data; /* The optimal solution is 3 bins */ /*param m := 15; param v := 1 96000, 2 126000, 3 115000, 4 125000, 5 123000, 6 123000, 7 112000, 8 111000, 9 110000, 10 110000, 11 120000, 12 98000, 13 130000, 14 87000, 15 97000; param w := 1 27, 2 21, 3 27, 4 15, 5 19, 6 46, 7 47, 8 32, 9 14, 10 20, 11 50, 12 19, 13 22, 14 50, 15 46; param m := 20; param w := 1 27, 2 50, 3 19, 4 19, 5 22, 6 79, 7 32, 8 19, 9 75, 10 32, 11 43, 12 82, 13 18, 14 24, 15 20, 16 30, 17 24, 18 80, 19 49, 20 15; param v := 1 276000, 2 745000, 3 585000, 4 585000, 5 723000, 6 808000, 7 552000, 8 584000, 9 626000, 10 551000, 11 423000, 12 944000, 13 496000, 14 133000, 15 633000, 16 461000, 17 813000, 18 855000, 19 695000, 20 406000; param m := 30; param w := 1 103, 2 100, 3 95, 4 119, 5 148, 6 165, 7 721, 8 89, 9 89, 10 156, 11 181, 12 93, 13 239, 14 173, 15 87, 16 113, 17 1816, 18 107, 19 128, 20 102, 21 102, 22 115, 23 118, 24 124, 25 244, 26 394, 27 100, 28 92, 29 103, 30 126; param v := 1 42000, 2 31000, 3 20000, 4 20000, 5 20000, 6 20000, 7 180000, 8 9000, 9 9000, 10 18000, 11 18000, 12 28000, 13 28000, 14 17000, 15 121000, 16 14000, 17 579000, 18 13000, 19 13000, 20 12000, 21 12000, 22 12000, 23 12000, 24 12000, 25 33000, 26 65000, 27 22000, 28 11000, 29 11000, 30 11000; */ param m := 40; param w := 1 3512, 2 87, 3 87, 4 90, 5 91, 6 91, 7 99, 8 218, 9 89, 10 91, 11 91, 12 92, 13 92, 14 93, 15 95, 16 99, 17 100, 18 263, 19 88, 20 89, 21 91, 22 92, 23 93, 24 97, 25 99, 26 99, 27 90, 28 97, 29 399, 30 298, 31 160, 32 854, 33 132, 34 986, 35 255, 36 88, 37 89, 38 92, 39 97, 40 98; param v := 1 672000, 2 10000, 3 10000, 4 10000, 5 10000, 6 10000, 7 10000, 8 244000, 9 73000, 10 9000, 11 9000, 12 9000, 13 9000, 14 9000, 15 9000, 16 9000, 17 9000, 18 83000, 19 8000, 20 8000, 21 8000, 22 8000, 23 8000, 24 8000, 25 8000, 26 8000, 27 7000, 28 7000, 29 103000, 30 144000, 31 58000, 32 399000, 33 15000, 34 472000, 35 120000, 36 12000, 37 12000, 38 11000, 39 11000, 40 11000; param c := 10000; end; Jetzt muss man folgendes ausfÃ¼hren: glpsol --output example.out --log example.log --math partition.mod Das benÃ¶tigt fÃ¼r die grÃ¶ÃŸte Eingabe etwa 18 Sekunden. Wenn man nun in die example.out schaut, sieht man unter anderem folgendes: Problem: partition Rows: 47 Columns: 80 (80 integer, 80 binary) Non-zeros: 640 Status: INTEGER OPTIMAL Objective: obj = 5 (MINimum) Die interessante Zahl ist die 5. Das ist das Minimum, das in dieser Aufgabe gesucht war. Wie es zu erreichen ist, sieht man in der Ausgabe darunter. Weiteres Man kann das Problem auch als MULTIPROCESSOR SCHEDULING mit zwei Maschinen betrachten (und nicht als PARTITION). Vor ein paar Tagen habe ich gelernt, dass es fÃ¼r MULTIPROCESSOR SCHEDULING auch ein PAS gibt. Dabei bestimmt man fÃ¼r eine konstante Anzahl an Koffern die optimale aufteilung und verteilt den rest mittels LIST SCHEDULING.","tags":"German posts","title":"31. BwInf - Runde 1, Aufgabe 2"},{"url":"https://martin-thoma.com/how-can-i-clear-gedit-text-search-replace-history/","text":"Start gconf-editor : gconf-editor Go to /apps/gnome-settings/gedit/history-gedit2_search_for_entry and /apps/gnome-settings/gedit/history-gedit2_replace_entry_with and remove the content there: gedit: Clear text search / replace history","tags":"My bits and bytes","title":"How can I clear gedit text search / replace history?"},{"url":"https://martin-thoma.com/top-5-worst-website-designs/","text":"Here are some screenshots of the worst websites I have ever seen. Most of them use too many colors, something moves or the background is black. One uses frames. dokimos fabricland.co.uk Coolmath-Games ronoslund 5safepoints Do you know similar examples for bad website designs (Spambots might have a higher success rate for useful comments now. I'll have to check that ;-) )","tags":"The Web","title":"TOP 5: Worst Website Designs"},{"url":"https://martin-thoma.com/wie-zeige-ich-differenzierbarkeit/","text":"Weil das Thema so wichtig ist und man es doch recht leicht vergisst: Sei $I \\subseteq \\mathbb{R}$ ein Intervall und $f:I \\rightarrow \\mathbb{R}$ eine Funktion. $f$ heiÃŸt in $x_0 \\in I$ differenzierbar $\\displaystyle :\\Leftrightarrow \\lim_{x \\rightarrow x_0} \\frac{f(x) - f(x_0)}{x-x_0}$ existiert und ist in $\\mathbb{R}$. In diesem Fall heiÃŸt $\\displaystyle f'(x_0) = \\lim_{x \\rightarrow x_0} \\frac{f(x) - f(x_0)}{x-x_0}$ die Ableitung von $f$ in $x_0$ . $f$ heiÃŸt auf $I$ differenzierbar $:\\Leftrightarrow \\forall x \\in I: f \\text{ ist in } x$ differenzierbar. In diesem Fall wird durch $x \\mapsto f'(x)$ eine Funktion $f':I \\rightarrow \\mathbb{R}$ definiert, die Ableitung von $f$ auf $I$. Und wie zeigt man die Existenz dieses Grenzwertes? Das ist eine andere Frage :-P Man sollte sich vielleicht nochmal den Artikel Konvergenz von Folgen bzw. Konvergenz von Reihen anschauen. Ach ja, man kann auch zeigen, dass \\(\\displaystyle \\lim_{h \\rightarrow 0} \\frac{f(x_0+h)-f(x_0)}{h}\\) existiert und in \\(\\mathbb{R}\\) ist. Das ist Ã¤quivalent.","tags":"German posts","title":"Wie zeige ich Differenzierbarkeit?"},{"url":"https://martin-thoma.com/reflecting-a-point-over-a-line/","text":"It's astonishing how difficult it is to find a good explanation how to reflect a point over a line that does not use higher math methods. So here is my explanation: You have a point \\(P = (x,y)\\) and a line \\(g(x) = m \\cdot x + t\\) and you want to get the point \\(P' = (x', y')\\) that got mirrored over \\(g\\) . Reflection point over a line As you can see, you can construct this quite easily on paper: Construct the perpendicular through \\(P\\) to \\(g\\) . It starts in \\(L\\) and ends in \\(P\\) . Double the length of the perpendicular in the direction of \\(L\\) . The endpoint is \\(P'\\) . How can you do that without drawing it? First you have to get the perpendicular \\(s(x) = m_s \\cdot x + t\\) (the dashed red line). You have to know this: \\(m_s = - \\frac{1}{m}\\) And then you know that \\(P\\) is on \\(s\\) . So you simply put in the values \\(x,y\\) of P and solve to \\(t\\) : \\(t = y - m_s \\cdot x\\) Now you have \\(s\\) . As \\(s\\) and \\(g\\) have exactly point in common, the following equation gives exactly one result: \\(s(x) = g(x)\\) You have to solve for \\(x\\) . Then you only need to put \\(x\\) into \\(s(x)\\) or \\(g(x)\\) and you're done. You've calculated \\(L = (x,y)\\) . Now you know \\(\\Delta x = |x_L - x_P|\\) and \\(\\Delta y = |y_L - y_P|\\) and you can calculate \\(P'\\)","tags":"My bits and bytes","title":"Reflecting a point over a line"},{"url":"https://martin-thoma.com/profiling-c-programs/","text":"If you have a working program and you want to improve its execution speed, you might want to profile it. An easy way to do so, is adding global variables, increasing them at interesting points and counting how often these points are executed. A more sophisticated way is using a profiler. valgrind and kcachegrind Install valgrind and kcachegrind. For Ubuntu users: sudo apt-get install valgrind kcachegrind Create a profile: valgrind --tool = callgrind ./connectfour (I've profiled a connect four application. Replace that with your application) This command will create a file called similar to \"callgrind.out.4846\". Take a look at the profile: kcachegrind callgrind.out.4846 You can also create a call-graph: Call graph of connect four game graph creation program Just take a look at it by yourself. You will see much more than I could tell you now.","tags":"Code","title":"Profiling C programs"},{"url":"https://martin-thoma.com/debugging-a-c-program/","text":"As I began with programming C, I had enormous difficulties to produce working code. Most of the time it didn't even compile, but when it compiled and I got a runtime error, I basically read my whole code again. I didn't don't know any good online resource for C, so I've always searched with Google for answers to questions that I couldn't properly formulate. One question that is important for beginners is How do I find missing C header files (without Internet)? and another one might be: How can I debug my programs? Compile time vs. runtime A typical C workflow looks like this: You have an idea, you write your code, you compile it and you run it. C workflow You might make multiple errors. Simple typos or syntax errors are almost always detected at compile time. They are called \"compile time errors\". Others, like the access of an array-index that isn't in the array might only occur sometimes at runtime, depending on the input. Those are runtime errors and they are much more difficult to detect. Additionally, they can not be reproduced that easily as compile time errors can. gdb If you want to find runtime errors, you should deactivate all optimization flags and add debugging symbols. A gcc call might look like this: gcc mySourceFile.c -g This produces a binary file called \"a.out\". Now should run gdb - GNU debug: gdb ./a.out Within the command line program GNU debug you have to enter: run ./a.out You should now be able to see the line in which the runtime-error occurs. valgrind You might want to give valgrind a try. Uninitialised value was created by a stack allocation at 0x80488BC : This could mean that you used an uninitialized variable. Check your variable initializations from the given point. Add --track-origins=yes</code and run valgrind again.","tags":"Code","title":"Debugging a C program"},{"url":"https://martin-thoma.com/make-your-bash-more-useful/","text":"I just had the problem, that the bash prompt of my universities computer I've connected to via SSH looked like this: bash-4.0$ Change the prompt I think it's much more useful to see the path you're currently using. To get the current path in your bash promt, you have to add the following snippet to your .bashrc : # This will limit the path to 30 characters. PROMPT_COMMAND = 'if [ ${#PWD} -gt 30 ]; then myPWD=${PWD:0:12}... ${PWD:${#PWD}-15}; else myPWD=$PWD; fi' PS1 = \"\\u@\\h \\$myPWD $ \" (Source: cyberciti.biz ) Reload your bash config with source .bashrc and you should instantly see the changes. Aliases # Add color to ls alias ls = \"ls --color\" # simply update an svn-repository alias swt = 'svn up /home/moose/Studium/SWT'","tags":"Code","title":"Make your Bash more useful"},{"url":"https://martin-thoma.com/karlsruhe-oberburgermeisterwahl-2012/","text":"Da ich mein Erstwohnsitz inzwischen Karlsruhe ist, darf ich hier wÃ¤hlen. Am Sonntag, den 2. Dezember 2012 ist die Wahl des OberbÃ¼rgermeisters in Karlsruhe. Seit 1970 wird dieses Amt von einem CDU'ler besetzt. [1] Heinz Fenrich (CDU) ist seit 1998 im Amt, hat aber die Altersgrenze erreicht und kann somit nicht wieder gewÃ¤hlt werden. Die Kandidaten Die UStA hat den 7 Kandidaten einige Fragen gestellt und kurze Informationen bereitgestellt ( Link - Vielen Dank dafÃ¼r!). Hier mal das Interessanteste: Dr. Frank Mentrup, SPD-GrÃ¼ne-KAL Alter 48 Jahre In Karlsruhe seit 2007 Beruf Arzt fÃ¼r Kinder- und Jugendpsychiatrie Politik viel, vgl. Wikipedia 2011: StaatssekretÃ¤r im Ministerium fÃ¼r Kultus, Jugend und Sport Wikipedia Link Ziele und Aussagen: Wohnraummangel : â€ž[...] werde ich ein kommunales WohnraumfÃ¶rderungsprogramm fÃ¼r Karlsruhe erarbeiten\" Studiticket : viel bla bla, durchaus gute und vernÃ¼nftige BegrÃ¼ndungen, aber in kurz: An den Preisen fÃ¼r das Studiticket kann der OB nichts machen Rad vs. Baustellen : â€žDer weitere Ausbau von Radwegen, insbesondere auch auf studentischen Routen wie z.B. zwischen Wohnheimen und den Hochschulen muss zÃ¼gig erfolgen.\" Slacklinen : â€ž[ich werde] mich fÃ¼r die Einrichtung von Slacklineanlagen einsetzen.\" Sonstiges : Als OberbÃ¼rgermeister werde ich eine ausgewogene Stadtentwicklungspolitik verfolgen, die Karlsruhe zu einer grÃ¼nen Stadt machen wird mit einem durchgehenden GrÃ¼nstreifen vom Rhein bis in die BergdÃ¶rfer. Insgesamt erwecken Mentrup einen soliden Eindruck. Die Antworten scheinen durchdacht zu sein und er spricht einige Projekte / Initiativen an, die es bereits gibt. Er scheint also mit der Politik der Stadt vertraut zu sein. Ingo Wellenreuther, CDU Alter 52 Jahre In Karlsruhe geboren Beruf 11 Jahre Richter am Landgericht und Oberlandgericht Politik viel, vgl. Wikipedia seit Ã¼ber 10 Jahren Bundestagsabgeordneter seit dreizehn Jahren im Stadtrat Wikipedia Link Ziele und Aussagen: Wohnraummangel : â€ž[ich will] gezielt auf die Umlandgemeinden zugehen, [...] damit auch diese Wohnraum fÃ¼r Studenten schaffen\" Studiticket : â€žAls OberbÃ¼rgermeister wÃ¼rde ich mich fÃ¼r ein studierendenfreundliches Ergebnis stark machen.\" Rad vs. Baustellen : Sehr viel blah blah Slacklinen : â€ž[ich werde] mich beim Land fÃ¼r deren offizielle Genehmigung stark machen\" Sonstiges : â€žEine VergrÃ¶ÃŸerung des KIT-Campus SÃ¼d auf dem GelÃ¤nde des Wildparkstadions halte ich fÃ¼r dringend notwendig. Dies wÃ¼rde durch einen Stadionneubau in AutobahnnÃ¤he mÃ¶glich, fÃ¼r den ich mich seit vielen Jahren einsetze und der auch viele andere Probleme lÃ¶sen wÃ¼rde.\" Fostiropoulos, Linke Alter 54 Jahre In Karlsruhe Architektur studiert Beruf Unternehmen im Bereich der beruflichen Weiterbildung Politik seit 12 Jahren Stadtrat Ziele und Aussagen: Wohnraummangel : setzt sich fÃ¼r ein kommunale Wohnungsprogramm ein Studiticket : â€žÃ–PNV kostenlos und Ã¼ber Steuermittel finanziert\" Rad vs. Baustellen : nichts konkretes Slacklinen : â€žDafÃ¼r ist das Land zustÃ¤ndig.\" Sonstiges : Kostenfreie KindertagesstÃ¤tten fÃ¼r alle Kinder von 1 bis 6, kommunales Wohnungsprogramm Friedemann Kalmbach, WÃ¤hlerliste Alter 58 Jahre In Karlsruhe ? Beruf Technischer Zeichner in einer Maschinenbaufabrik Gymnasiallehrer (Physik, Geographie) Politik seit 2009 trÃ¤gt er politische Verantwortung im Gemeinderat Ziele und Aussagen: Wohnraummangel : kommunales Wohnungsbauprogramm, Investoren, BÃ¼roflÃ¤chen in Wohnraum umwandeln Studiticket : â€ž[Ich werde] den Druck auf den KVV deutlich erhÃ¶hen, um eine moderatere Preisgestaltung zu erzielen.\" Rad vs. Baustellen : Nichts konkretes Slacklinen : ist nicht Sache des OB Sonstiges : - JÃ¼rgen Wenzel, freie WÃ¤hler Karlsruhe Alter 50 Jahre In Karlsruhe geboren Beruf studierte klassische Malerei und Zeichnen arbeitete als Comiczeichner, Gestalter von Plattencovern und Werbeanzeigen Politik seit 2009 im Gemeinderat Sascha Oehme, UnabhÃ¤ngiger Kandidat Alter 42 Jahre In Karlsruhe ? Beruf Logistikmeister Politik Ã¶ffentlichen Wohnbau, Abschaffung der Hundesteuer, freies W-LAN Wikipedia Link Michael BÃ¶hm, UnabhÃ¤ngiger Kandidat alias â€žHerr Kruscht\" Alter 49 Jahre In Karlsruhe geboren (Eggstein) Beruf EntrÃ¼mpler Besitzer eines Blechdosenmuseums Politik Ã¶ffentlichen Wohnbau, Abschaffung der Hundesteuer, freies W-LAN Wikipedia Link Ist gegen die U-Bahn, mÃ¶chte das Karlsruher Rathaus auf den Werderplatz bauen. â€žDas jetzige Rathaus soll eine KindertagesstÃ¤tte werden und die SÃ¼dstadt eine eigenstÃ¤ndige Stadt.\" Herabsenkung des Wahlalters auf 16 Jahre. Prognosen 48,22%: Mentrup, SPD-GRÃœ-KAL 38,16%: Wellenreuther, CDU 04,18%: Fostiropoulos, Linke 04,05%: Kalmbach, GfK 03,00%: Wenzel, FW 02,39%: Oehme 00,68%: Kruscht Quelle: kanews.wahlfieber.de Links â†‘ : Wikipedia, Geschichte Karlsruhes","tags":"German posts","title":"Karlsruhe: OberbÃ¼rgermeisterwahl 2012"},{"url":"https://martin-thoma.com/linux-scheduler/","text":"Der folgende Text wurde von Moritz Klammler , einem Informatik-Studenten am KIT, als E-Mail an die interne Mailingliste der Vorlesung geschrieben. Ich habe nur ein paar Kleinigkeiten umformuliert und die Formattierung geÃ¤ndert. Mailinglisten-Beitrag Der in der Vorlesung vorgestellte \\(\\mathcal{O}(1)\\) Scheduler [1] wurde vom 2.6er Linux Kernel bis Version 2.6.23 verwendet und dann durch den sogenannten Completely Fair Scheduler (CFS) [2] abgelÃ¶st, der Rot-Schwarz-BÃ¤ume verwendet, und daher in \\(\\mathcal{O}(\\log(n))\\) lÃ¤uft -- dafÃ¼r aber komplett fair ist ;-) Beide Scheduler wurden von Ingo MolnÃ¡r entworfen und grÃ¶ÃŸtenteils implementiert. Abgesehen von den Wikipedia Artikeln fand ich auch Ingos eigene Beschreibung [3] sehr interessant. In der prÃ¤-2.6-Ã„ra des Linux Kernels wurde ein Scheduler verwendet, zu dessen Effizienz ich keine Angaben gefunden habe. Anhand der (ziemlich detaillierten) Beschreibung in Kapitel 10 von â€žUnderstanding the Linux Kernel\" [1] gehe ich jedoch davon aus, dass es \\(\\mathcal{O}(n)\\) gewesen sein muss. Auch wenn die dort beschriebenen Algorithmen inzwischen mehrfach Ã¼berholt sind, fand ich das Kapitel sehr lesenswert. Wie in der Vorlesung vermutet wurde, kann man den Scheduler natÃ¼rlich konfigurieren. Dazu ist es aber nicht notwendig, neu zu kompilieren -- noch nicht einmal neu zu booten. Stattdessen kann man (beim CFS) einfach Ã¼ber das /proc Dateisystem in die verschiedenen Dateien in /proc/sys/kernel/... schreiben. Die Ã„nderungen werden instantan wirksam. (Und spÃ¤testens zum nÃ¤chsten Reboot wieder zurÃ¼ckgesetzt, man kann also nicht viel kaputt machen.) Permanente Ã„nderungen kann man in /etc/sysctl.conf schreiben. (Habe ich noch nicht probiert.) Ich habe ein kleines Programm geschrieben, das sehr viele Subprozesse erzeugt, die alle sinnlose Rechnungen auf der CPU ausfÃ¼hren und zwischendurch in regelmÃ¤ÃŸigen Intervallen eine (eigentlich zwei) Zellen auf dem Terminal umfÃ¤rben. Man kann anhand dessen, wie sich das Muster Ã¤ndert, schÃ¶n sehen, wie oft ein einzelner Prozess an die Reihe kommt, und wie lange er es bleibt, wenn er es einmal ist. Das Programm kann von meiner Website heruntergeladen werden. In dem Archiv ist auch ein kleines Shell-Skript, sched-tune.sh , mit dem man die wichtigsten Parameter Ã¤ndern kann. Die README Datei in dem Archiv erklÃ¤rt genauer, wie man das Programm benutzen kann. Da der Bildschirm beim AusfÃ¼hren des Programms (gewollt) stark flackert, muss ich Epileptikern und anderen empfindlichen Personen unter UmstÃ¤nden leider davon abraten. Leider lÃ¤sst der Kernel keine vÃ¶llig unsinnigen Werte zu. Man kann also nur bedingt ausprobieren, welchen Einfluss extreme Einstellungen haben / hÃ¤tten. Wie in Referenz 4 beschrieben, â€žfriert\" die grafische OberflÃ¤che Ã¼brigens auch nicht ein, wenn man grÃ¶ÃŸere Scheduling Intervalle wÃ¤hlt, da jeder Tastendruck einen Interrupt auslÃ¶st, der -- egal wie geschedulet wird -- immer die Kontrolle an jenen Prozess Ã¼bergibt, der gerade das Keyboard â€žgegrabbt\" hat. GrÃ¼ÃŸe Moritz Video Ich habe mal ein Video von Moritz' Programm gemacht: Referenzen [1] â†‘ : â€ž O(1) Scheduler \" in: Wikipedia, the free encyclopedia. Abgerufen am 13. November 2012. [2] â†‘ : â€ž Completely Fair Scheduler \" in: Wikipedia, the free encyclopedia. Abgerufen am 13. November 2012. [3] â†‘ : Ingo MolnÃ¡r, â€ž This is the CFS scheduler \". Abgerufen am 13. November 2012. [4] â†‘ : Daniel P. Bovet und Marco Cesati, â€ž Understanding the Linux Kernel \". O'Reilly, 2000, abgerufen am 13. November 2012.","tags":"German posts","title":"Linux Scheduler"},{"url":"https://martin-thoma.com/tribonacci-folge/","text":"Folgende Aufgabe gab es (sinngemÃ¤ÃŸ) fÃ¼r das Modul â€žProgrammieren\" im zweiten Ãœbungsblatt 2012: Sei \\((a_n)_{n \\in \\mathbb{N}}\\) eine Folge und definiert durch: \\(a_n := \\begin{cases} 1 &\\text{, falls } n \\in \\{0,1,2\\}\\\\ a_{n-1} + a_{n-2} + a_{n-3} & \\text{, falls } n \\geq 3 \\end{cases} \\) . Ich werde im folgenden mal kurz mÃ¶gliche LÃ¶sungen in Python (und eine in Java) vorstellen. Python hat bei solchen Aufgaben den Vorteil, dass es viel kompakter ist und Ganzzahlen beliebig groÃŸ werden kÃ¶nnen. HÃ¤ndische LÃ¶sung Bevor man irgendwas programmiert, sollte man sicherstellen, dass man es testen kann. Was wÃ¤ren also die ersten paar Folgenglieder? \\(a_0 = a_1 = a_2 = 1, a_3 = 3, a_4 = 5, a_5 = 9, a_6 = 17, a_7 = 31, a_8 = 57\\) Rekursive LÃ¶sung Solche Aufgaben lassen sich hÃ¤ufig sehr einfach rekursiv lÃ¶sen: def tribonacci ( n ): if n < 3 : return n else : return tribonacci ( n - 1 ) + tribonacci ( n - 2 ) + tribonacci ( n - 3 ) Allerdings hat diese rekursive LÃ¶sung den riesigen nachteil, dass viele Berechnungen redundant sind. Angenommen, wir wollen tribonacci(5) berechnen. Dann lÃ¤uft folgendes ab: Aufruf tribonacci(5) Aufruf tribonacci(4) Aufruf tribonacci(3) Aufruf tribonacci(2) Aufruf tribonacci(1) Aufruf tribonacci(0) Aufruf tribonacci(2) Aufruf tribonacci(1) Aufruf tribonacci(3) Aufruf tribonacci(2) Aufruf tribonacci(1) Aufruf tribonacci(0) Aufruf tribonacci(2) Man sieht deutlich, dass z.B. tribonacci(3) mehrfach berechnet werden muss. Wie kann man so was verbessern? Bottom-Up Ansatz Wir benÃ¶tigen fÃ¼r ein neues Folgenglied immer nur das vorhergehende. Das kann dann so aussehen: def tribonacciBottomUp ( n ): last = 1 secondLast = 1 thirdLast = 1 for i in range ( 2 , n ): new = last + secondLast + thirdLast thirdLast = secondLast secondLast = last last = new return last Fill it Eine weitere MÃ¶glichkeit wÃ¤re die schwÃ¤che des rekursiven Ansatzes zu eliminieren, indem man alle bisher berechneten Werte in einem Array speichert. Wertetabelle i a_i 0 1 1 1 2 1 3 3 4 5 5 9 6 17 7 31 8 57 9 105 10 193 11 355 12 653 13 1201 14 2209 15 4063 16 7473 17 13745 18 25281 19 46499 20 85525 21 157305 22 289329 23 532159 24 978793 25 1800281 26 3311233 27 6090307 28 11201821 29 20603361 30 37895489 31 69700671 32 128199521 33 235795681 34 433695873 35 797691075 36 1467182629 37 2698569577 38 4963443281 39 9129195487 40 16791208345 Java Java-Nutzer mÃ¼ssen sich darÃ¼ber im klaren sein, dass alle Elemente, die grÃ¶ÃŸer als 36 sind, die int -Grenzen sprengen. Eine LÃ¶sung fÃ¼r das Ãœbungsblatt kÃ¶nnte ungefÃ¤hr so aussehen: /** This class calculates numbers of the Tribonacci sequence. */ public final class Tribonacci { /** * Utility classes should not have a public or default * constructor. */ private Tribonacci () { } /** * Calculate the n'th Element of the Tribonacci sequence (a_n). * The sequence is defined as: * a_0 = a_1 = a_2 = a * a_n = a_(n-1) + a_(n-2) + a_(n-3) * * @param n the element of the Tribonacci sequence you want to * calculate * @return the value of the n'th element in the Tribonacci * sequence */ public static long calculateTribonacci ( final long n ) { long last = 1 ; long secondLast = 1 ; long thirdLast = 1 ; for ( int i = 2 ; i < n ; i ++) { long newTri = last + secondLast + thirdLast ; thirdLast = secondLast ; secondLast = last ; last = newTri ; } return last ; } /** * Prints out the Tribonacci number a_36 * the (37th Tribonacci number) * @param args the command line arguments */ public static void main ( final String [] args ) { System . out . println ( calculateTribonacci ( 36 )); } }","tags":"Code","title":"Tribonacci-Folge"},{"url":"https://martin-thoma.com/project-euler-problem-35/","text":"The task in Problem 35 of Project Euler is: The number, 197, is called a circular prime because all rotations of the digits: 197, 971, and 719, are themselves prime. There are thirteen such primes below 100: 2, 3, 5, 7, 11, 13, 17, 31, 37, 71, 73, 79, and 97. How many circular primes are there below one million? How to solve If you have heard of the sieve of Eratosthenes, this one sounds quite easy: Find all primes below one million For each prime, do: Generate all rotations Check for every rotation if it is a prime Count the number of circular primes The implementation Sieve of Eratosthenes The finds all primes below \\(n \\in \\mathbb{N}\\) . But you can make a lot of mistakes in the implementation. First, this is the way the sieve of Eratosthenes works: Sieve of Eratosthenes: algorithm steps for primes below 121 (including optimization of starting from prime's square). Source: Wikimedia For example, this implementation is not good: def getPrimesBelowN ( n = 1000000 ): \"\"\" Sieve of Eratosthenes \"\"\" from math import ceil roundUp = lambda n , prime : int ( ceil ( float ( n ) / prime )) primes = range ( 2 , n ) for currentPrime in primes : for multiplicant in xrange ( 2 , roundUp ( n , currentPrime )): noPrime = multiplicant * currentPrime if noPrime in primes : primes . remove ( noPrime ) return primes Whats bad with this code? Well, just think about what it does: For every noPrime Python has to go through the whole list. I couldn't find how in is implemented, but I guess it is linear. So Python has to go through the whole list for in . Additionally, remove could also be expensive. How could this get improved? Here is a better solution: def getPrimesBelowN ( n = 1000000 ): \"\"\" Sieve of Eratosthenes \"\"\" from math import ceil roundUp = lambda n , prime : int ( ceil ( float ( n ) / prime )) primes = [ True ] * n primes [ 0 ] = False primes [ 1 ] = False primeList = [] for currentPrime in xrange ( 2 , n ): if not primes [ currentPrime ]: continue primeList . append ( currentPrime ) for multiplicant in xrange ( 2 , roundUp ( n , currentPrime )): primes [ multiplicant * currentPrime ] = False return primeList This solution does not need to search for noPrime , it simply jumps there in the list. A generator version of the sieve of Erasthostenes can be found on code.activestate.com . isCircularPrime Rotation the digits of a number is the same as cutting the number into two pieces and switching the position of the pieces: def isCircularPrime ( primes , number ): number = str ( number ) for i in xrange ( 0 , len ( number )): rotatedNumber = number [ i : len ( number )] + number [ 0 : i ] if int ( rotatedNumber ) not in primes : return False return True Here is the same problem as above, in the sieving algorithm: Searching through the list takes much more time than jumping to a position in the list. So this one is better: def isCircularPrime ( primes , number ): number = str ( number ) for i in xrange ( 0 , len ( number )): rotatedNumber = number [ i : len ( number )] + number [ 0 : i ] if not primes [ int ( rotatedNumber )]: return False return True Some more speedups Every prime that contains one of the digits 0, 2, 4, 6 or 8 can't be a circular prime, because one rotation exist where that digit is at the end. This rotation would be divisible by 2 and thus not be a prime (except for 2, of course). You can use the same thought for the digit 5. So you can skip those digits The final snippet #!/usr/bin/python # -*- coding: utf-8 -*- def getPrimesBelowN ( n = 1000000 ): \"\"\"Get all primes below n with the sieve of Eratosthenes. @return: a list 0..n with boolean values that indicate if i in 0..n is a prime. \"\"\" from math import ceil primes = [ True ] * n primes [ 0 ] = False primes [ 1 ] = False primeList = [] roundUp = lambda n , prime : int ( ceil ( float ( n ) / prime )) for currentPrime in xrange ( 2 , n ): if not primes [ currentPrime ]: continue primeList . append ( currentPrime ) for multiplicant in xrange ( 2 , roundUp ( n , currentPrime )): primes [ multiplicant * currentPrime ] = False return primes def isCircularPrime ( primes , number ): \"\"\"Check if number is a circular prime. Keyword arguments: primes -- a list from 0..n with boolean values that indicate if i in 0..n is a prime number -- the integer you want to check \"\"\" number = str ( number ) for i in xrange ( 0 , len ( number )): rotatedNumber = number [ i : len ( number )] + number [ 0 : i ] if not primes [ int ( rotatedNumber )]: return False return True if __name__ == \"__main__\" : print ( \"Start sieving.\" ) primes = getPrimesBelowN ( 1000000 ) print ( \"End sieving.\" ) numberOfPrimes = 2 print ( 2 ) # I print them now, because I want to skip all primes print ( 5 ) # that contain one of those digits: 0,2,4,5,6,8 for prime , isPrime in enumerate ( primes ): if ( not isPrime ) or ( \"2\" in str ( prime )) or \\ ( \"4\" in str ( prime )) or ( \"6\" in str ( prime )) or \\ ( \"8\" in str ( prime )) or ( \"0\" in str ( prime )) or \\ ( \"5\" in str ( prime )): continue if isCircularPrime ( primes , prime ): print ( prime ) numberOfPrimes += 1 print ( \"Number of circular primes: %i \" % numberOfPrimes ) It takes about 1.096 seconds (in comparison: having the version of isCircularPrime that searches through the list of primes took over 5 minutes!)","tags":"Code","title":"Project Euler: Problem 35"},{"url":"https://martin-thoma.com/project-euler-problem-33/","text":"The task in Problem 33 of Project Euler is: The fraction $\\frac{49}{98}$ is a curious fraction, as an inexperienced mathematician in attempting to simplify it may incorrectly believe that $\\frac{49}{98} = \\frac{4}{8}$, which is correct, is obtained by cancelling the 9s. We shall consider fractions like, $\\frac{30}{50} = \\frac{3}{5}$, to be trivial examples. There are exactly four non-trivial examples of this type of fraction, less than one in value, and containing two digits in the numerator and denominator. If the product of these four fractions is given in its lowest common terms, find the value of the denominator. How to solve The solution to this task is pretty straight forward. As the nominator has to have two digits and the denominator also has to be in [10, 99], we only have about \\(100 \\cdot 100 = 10000\\) that we have to check. How do we check a given nominator / denominator pair? Well, we can go through each digit of the nominator and check if it is also in the denominator. If it is there, we have to check if the resulting fraction has the same value as before. If it has, we can print it. My solution #!/usr/bin/python # -*- coding: utf-8 -*- def isCuriousFraction ( numerator , denomiator ): for digit in str ( numerator ): if digit in str ( denomiator ): for i , j in [( i , j ) for i in range ( 0 , 2 ) for j in range ( 0 , 2 )]: if str ( numerator )[ i ] == digit == str ( denomiator )[ j ]: if int ( str ( denomiator )[( j + 1 ) % 2 ]) == 0 : continue # devision through 0 is bad canceled = float ( str ( numerator )[( i + 1 ) % 2 ]) / \\ int ( str ( denomiator )[( j + 1 ) % 2 ]) divided = float ( numerator ) / denomiator if abs ( canceled - divided ) < 0.0001 : print ( \" %i / %i = %s / %s \" % ( numerator , \\ denomiator , str ( numerator )[( i + 1 ) % 2 ], \\ str ( denomiator )[( j + 1 ) % 2 ])) return True if __name__ == \"__main__\" : for i in xrange ( 10 , 100 ): if i % 10 == 0 : # those are not interesting continue for j in xrange ( i + 1 , 100 ): isCuriousFraction ( i , j ) Solving it without programming You can also solve this without programming at all: See post .","tags":"Code","title":"Project Euler: Problem 33"},{"url":"https://martin-thoma.com/project-euler-problem-32/","text":"The task in Problem 32 of Project Euler is: We shall say that an $n$-digit number is pandigital if it makes use of all the digits 1 to n exactly once; for example, the 5-digit number, 15234, is 1 through 5 pandigital. The product 7254 is unusual, as the identity, $39 \\cdot 186 = 7254$, containing multiplicand, multiplier, and product is 1 through 9 pandigital. Find the sum of all products whose multiplicand/multiplier/product identity can be written as a 1 through 9 pandigital. HINT: Some products can be obtained in more than one way so be sure to only include it once in your sum. How to solve it We have to get a check, if a number is pandigital. It could look like this: def isPandigitalString ( string ): \"\"\" Check if string contains a pandigital number. \"\"\" digits = len ( string ) if digits >= 10 : return False for i in xrange ( 1 , digits + 1 ): if str ( i ) not in string : return False return True We also need a check if a product of two numbers is 9-pandigital: def gives9PandigitalProduct ( a , b ): numbers = str ( a ) + str ( b ) + str ( a * b ) if len ( numbers ) != 9 : return False return isPandigitalString ( numbers ) Now you need to figure out how to go through all possible combinations: products = [] for a in xrange ( 0 , 100000 ): for b in xrange ( a , 100000 ): if len ( str ( a * b ) + str ( a ) + str ( b )) > 9 : break if gives9PandigitalProduct ( a , b ): products . append ( a * b ) print ( \" %i x %i = %i \" % ( a , b , a * b )) print ( sum ( set ( products ))) One-liner This is from Thaddeus Abiye from Ethiopia: print sum ( set ( map ( lambda x : int ( x [ 0 : 4 ]), filter ( lambda x : sorted ([ i for i in x ]) == map ( str , range ( 1 , 10 )),[ str ( a * b ) + str ( a ) + str ( b ) for a in range ( 1 , 2000 ) for b in range ( 1 , 100 )])))) It needs one line and 173 characters, but I think it's hard to read. Data about my solution It worked in less than a second. 28 LOC (including whitespaces and comments) 719 characters for this solution (including whitespace and comments)","tags":"Code","title":"Project Euler: Problem 32"},{"url":"https://martin-thoma.com/beweise-aus-der-booleschen-algebra/","text":"Definition Edward Vermilye Huntington hat eine sehr kompakte Definition boolescher Algebren erarbeitet: Sei \\(B\\) eine Menge und \\(\\sqcap: B \\times B \\rightarrow B\\) sowie \\(\\sqcup: B \\times B \\rightarrow B\\) VerknÃ¼fungen auf B. Weiter gelte: H1: Kommutativgesetze \\(\\forall a,b \\in B: a \\sqcap b = b \\sqcap a\\) \\(\\forall a,b \\in B: a \\sqcup b = b \\sqcup a\\) H2: Distributivgesetze \\(\\forall a,b,c \\in B: a \\sqcap (b \\sqcup c) = (a \\sqcap b) \\sqcup (a \\sqcap c)\\) \\(\\forall a,b,c \\in B: a \\sqcup (b \\sqcap c) = (a \\sqcup b) \\sqcup (a \\sqcap c)\\) H3: Neutrale Elemente \\(\\exists e \\in B \\forall a \\in B: a \\sqcap e = a\\) (e wird Einselement genannt) \\(\\exists n \\in B \\forall a \\in B: a \\sqcup n = a\\) (n wird Nullelement genannt) H4: KomplementÃ¤re Elemente \\(\\forall a \\in B: \\exists \\bar a: a \\sqcap \\bar a = n \\land a \\sqcup \\bar a = e\\) Dann wird \\((B, \\sqcap, \\sqcup)\\) eine boolesche Algebra gennant. Folgerungen Sei im folgendem immer \\(\\mathcal{B} = (B, \\sqcap, \\sqcup)\\) eine boolesche Algebra mit dem Einselement â€ž1\" und dem Nullelement â€ž0\". Eindeutigkeit des Nullelements Behauptung: Es exisitiert genau ein Nullelement fÃ¼r \\(\\mathcal{B}\\) . Beweis: direkt Die Existenz von mindestens einem Nullelement wird durch H3 garantiert. Seien \\(n_1, n_2\\) Nullelemente auf \\(\\mathcal{B}\\) . Dann gilt: \\begin{align} & \\forall a \\in B: a \\sqcup n_1 \\stackrel{H3}{=} a\\\\ \\Rightarrow & n_2 \\sqcup n_1 = n_2\\\\ \\stackrel{H3}{\\Rightarrow} & n_1 = n_2 \\blacksquare \\end{align} Eindeutigkeit des Einselements Behauptung: Es exisitiert genau ein Einselement fÃ¼r \\(\\mathcal{B}\\) . Beweis: direkt Die Existenz von mindestens einem Einselement wird durch H3 garantiert. Seien \\(e_1, e_2\\) Einselemente auf \\(\\mathcal{B}\\) . Dann gilt: \\begin{align} & \\forall a \\in B: a \\sqcap e_1 \\stackrel{H3}{=} a\\\\ \\Rightarrow & e_2 \\sqcup e_1 = e_2\\\\ \\stackrel{H3}{\\Rightarrow} & e_1 = e_2 \\blacksquare \\end{align} Eindeutigkeit der komplementÃ¤ren Elemente Behauptung: Die komplementÃ¤ren Elemente bzgl. \\(\\sqcup\\) sind eindeutig Beweis: direkt Sei \\(a \\in B\\) beliebig und es gelte: \\(a \\sqcup \\bar a_1 = 0\\) und \\(a \\sqcup \\bar a_2 = 0\\) sowie \\(a \\sqcap \\bar a_1 = 1\\) und \\(a \\sqcap \\bar a_2 = 1\\) Schritt 1 Es gilt: \\begin{align} \\bar a_1 \\sqcap (a \\sqcup \\bar a_2) &\\stackrel{H2}{=} (\\bar a_1 \\sqcap a) \\sqcup (\\bar a_1 \\sqcap \\bar a_2)\\\\ \\Leftrightarrow \\bar a_1 \\sqcap 1 &= 0 \\sqcup (\\bar a_1 \\sqcap \\bar a_2)\\\\ \\Leftrightarrow \\bar a_1 &= \\bar a_1 \\sqcap \\bar a_2 \\end{align} Schritt 2 AuÃŸerdem gilt: \\begin{align} \\bar a_2 \\sqcap (a \\sqcup \\bar a_1) &\\stackrel{H2}{=} (\\bar a_2 \\sqcap a) \\sqcup (\\bar a_2 \\sqcap \\bar a_1)\\\\ \\Leftrightarrow \\bar a_2 \\sqcap 1 &= 0 \\sqcup (\\bar a_2 \\sqcap \\bar a_1)\\\\ \\Leftrightarrow \\bar a_2 &= (\\bar a_2 \\sqcap \\bar a_1) \\stackrel{H1}{=} \\bar a_1 \\sqcap \\bar a_2 \\end{align} Aus den Ergebnissen von Schritt 1 und Schritt 2 folgt: \\(\\bar a_1 = \\bar a_2\\) . Das bedeutet, zu jedem \\(a \\in B\\) existiert genau ein Komplement. \\(\\blacksquare\\) Nullelement ungleich Einselement Behauptung: \\(0 \\neq 1\\) Beweis: Wegen (H3) und (H4) gilt: \\(\\exists 1 \\in B \\forall a \\in B: a \\sqcap 1 \\stackrel{H1}{=} 1 \\sqcap a = a\\) \\(\\exists 0 \\in B \\forall a \\in B: a \\sqcup 0 \\stackrel{H1}{=} 0 \\sqcup a = a\\) \\(\\forall a \\in B: \\exists \\bar a \\in B: a \\sqcap \\bar a \\stackrel{H1}{=} 0\\) \\(\\forall a \\in B: \\exists \\bar a \\in B: a \\sqcup \\bar a \\stackrel{H1}{=} 1\\) Annahme: 1 = 0 \\(\\Rightarrow \\forall a \\in B: \\exists \\bar a \\in B = a \\sqcap \\bar a = a \\sqcup \\bar a = 0 = 1\\) Hmmm ... irgendwie konnte man \\((0 = 1) \\Rightarrow (\\sqcap = \\sqcup)\\) zeigen ... aber wie genau? Extremalgesetze \\(\\forall a \\in B: 1 \\sqcup a = 1\\) \\(\\forall a \\in B: 0 \\sqcap a = 0\\) Wie beweist man das? Absorptionsgesetz Version 1 Voraussetzungen: Sei \\(\\mathcal{B} = (B, \\sqcap, \\sqcup)\\) eine boolesche Algebra. Behauptung: \\(\\forall a, b \\in B: a \\sqcup (a \\sqcap b) = a\\) Beweis: direkt \\(a \\sqcup (a \\sqcap b) \\stackrel{H3}{=} (a \\sqcap 1) \\sqcup (a \\sqcap b) \\stackrel{H3}{=} a \\sqcap (1 \\sqcup b) \\stackrel{\\text{Extremalgesetze}}{=} a \\sqcap 1 \\stackrel{H3}{=} a\\) Version 2 Voraussetzungen: Sei \\(\\mathcal{B} = (B, \\sqcap, \\sqcup)\\) eine boolesche Algebra. Behauptung: \\(\\forall a, b \\in B: a \\sqcap (a \\sqcup b) = a\\) Beweis: Duale Aussage zu Version 1 Version 3 Voraussetzungen: Sei \\(\\mathcal{B} = (B, \\sqcap, \\sqcup)\\) eine boolesche Algebra. Behauptung: \\(\\forall a, b \\in B: a \\sqcup (\\bar a \\sqcap b) \\stackrel{H2}{=} a \\sqcup b\\) Beweis: direkt \\(a \\sqcup (\\bar a \\sqcap b) \\stackrel{H2}{=} (a \\sqcup \\bar a) \\sqcap (a \\sqcup b) \\stackrel{H4}{=} 1 \\sqcap (a \\sqcup b) \\stackrel{H3}{=} a \\sqcup b \\blacksquare\\) KÃ¶rper Ist jede Boolesche Algebra ein KÃ¶rper? Ein KÃ¶rper ist eine Menge \\(V\\) mit zwei VerknÃ¼pfungen \\(\\oplus, \\otimes\\) : \\((V, \\oplus, \\otimes)\\) , fÃ¼r den gilt: \\((K, \\oplus)\\) ist abelsche Gruppe mit neutralem Element 0 \\((K \\setminus \\{0\\}, \\otimes)\\) ist abelsche Gruppe mit neutralem Element 1 Es gelten die Distributivgesetze: \\(\\forall a, b, c \\in V: a\\cdot (b+c) = a\\cdot b+a\\cdot c\\) \\(\\forall a, b, c \\in V: (a+b)\\cdot c= a\\cdot c+b\\cdot c\\) Es scheint relativ offensichtlich, dass jede boolesche Algebra ein KÃ¶rper ist. Allerdings muss man aufpassen. FÃ¼r die neutrale Elemente eines KÃ¶rpers \\(K = (V, \\oplus, \\otimes)\\) muss gelten: $\\forall a: 0 \\oplus a = a$ $\\forall a: 1 \\otimes a = a$ FÃ¼r eine boolesche Algebra \\(\\mathcal{B} = (B, \\sqcap, \\sqcup)\\) muss gelten (H3): $\\exists 1 \\in B \\forall a \\in B: a \\sqcap 1 = a$ $\\exists 0 \\in B \\forall a \\in B: a \\sqcup 0 = a$ FÃ¼r die Inversen von \\(K\\) muss gelten: $\\forall a \\exists \\bar a: a \\oplus \\bar a = 0$ $\\forall a \\exists \\bar a: a \\otimes \\bar a = 1$ FÃ¼r die Komplemente von \\(\\mathcal{B}\\) muss gelten: $\\forall a \\in B: \\exists \\bar a: a \\sqcap \\bar a = 0$ $\\forall a \\in B: \\exists \\bar a: a \\sqcup \\bar a = 1$ Das Komplement eines Elements verknÃ¼fpft mit \\(\\sqcap\\) ergibt also das neutrale Element von \\(\\sqcup\\) ! Offensichtlich ist, dass die Schaltalgebra mit den Operatoren XOR und AND, also \\((\\{0,1\\}, XOR, AND)\\) ein KÃ¶rper ist, da Sie offensichtlich isomorph zu \\(\\mathbb{Z}/2\\mathbb{Z}\\) ist. Behauptung: Alle booleschen Algebren mit drei oder mehr Elementen sind keine KÃ¶rper Beweis: ( danke an Chricho ) Sei \\(\\mathcal{B} = (B, \\sqcap, \\sqcup)\\) mit \\(|B| \\geq 3\\) . Sei \\(a \\in B\\) mit \\(0 \\neq a \\neq 1\\) . Es gilt: \\(\\forall b \\in B: a \\land b \\leq a \\lneq 1 \\Rightarrow a\\) hat kein Inverses \\(\\Rightarrow \\mathcal{B}\\) ist kein KÃ¶rper \\(\\blacksquare\\) Boolesche Algebren und die Schaltalgebra Die wohl bekannteste boolesche Algebra ist die Schaltalgebra: \\((\\{0,1\\}, \\lor, \\land, 0, 1)\\) Allerdings ist nicht jede Boolesche Algebra eine Schaltalgebra! Quellen Skript â€žTechnische Informatik - Digitaltechnik und Entwurfsverfahren\" von Dr.-Ing. Tamim Asfour. S.33 - 37 Folien von Dr.-Ing. Tamim Asfour Vorlesung von Dr.-Ing. Tamim Asfour","tags":"German posts","title":"Beweise aus der booleschen Algebra"},{"url":"https://martin-thoma.com/definitionen-aus-digitaltechnik/","text":"Dieser Blogpost ist vor allem fÃ¼r HÃ¶rer von Prof. Dr. Asfour im WS 2012 / 2013 interessant. Ich hÃ¶re momentan die Vorlesung bei ihm. Deshalb sind die Inhalte teilweise identisch oder zumindest sehr Ã¤hnlich. Dieser Blogpost soll nur mÃ¶glichst gute Definitionen liefern. Ich werde ihn vermutlich bis zum Ende des Semesters immer wieder erweitern. Boolesche Algebra Konjunktion : \\(\\land\\) Disjunktion : \\(\\lor\\) Sei $x$ eine Variable. L heiÃŸt Literal $:\\Leftrightarrow L \\in \\{x, \\bar x\\}$. Seien $L_1, \\dots, L_n$ Literale. $K(x_1, \\dots, x_n)$ heiÃŸt ein Produktterm $:\\Leftrightarrow K(x_1, \\dots, x_n) = \\bigwedge_{i=1}&#94;n L_i$ oder $K = 1$ oder $K=0$. Jeder Produktterm \\(K(x_1, \\dots, x_n)\\) kann so dargestellt werden, dass eine Variable \\(x\\) in hÃ¶chstens einem Literal vorkommt. Sei $K(x_1, \\dots, x_n)$ ein Produktterm und $y(x_1, \\dots x_n)$ eine boolesche Funktion. $K$ heiÃŸt Implikant von $y :\\Leftrightarrow (K \\Rightarrow y)$ Sei $K(x_1, \\dots, x_n)$ ein Implikant der boolesche Funktion $y(x_1, \\dots x_n)$. $K$ heiÃŸt Minterm von $y :\\Leftrightarrow$ FÃ¼r jede Variable $x_i$ in $y$ kommt genau ein mal in $K$ als Literal vor. Sei $y(x_1, \\dots x_n)$ eine boolesche Funktion und $x$ ein boolescher Ausdruck, der $y$ entspricht. $x$ heiÃŸt disjunktive Normalform (DNF) von $y :\\Leftrightarrow$ $x=\\bigvee_{i=0}&#94;k K_i, \\; k \\leq 2&#94;n - 1:\\quad K_i \\neq K_j \\Leftrightarrow i \\neq j$ Sei $D(x_1, \\dots, x_m)$ eine Disjunktion von Literalen $\\bigvee_{i=1}&#94;m L_i$ oder die Konstante â€ž0\" oder die Konstante â€ž1\". Sei weiter $y(x_1, \\dots x_n)$ eine boolesche Funktion. $D$ heiÃŸt Implikat von $y :\\Leftrightarrow \\bar D \\Rightarrow \\bar y$ Summenterm ist ein Synonym zu Implikat. Sei $y(x_1, \\dots x_n)$ eine boolesche Funktion und $D$ ein Implikat von $y$. $D$ heiÃŸt Maxterm von $y :\\Leftrightarrow$ Ein Literal jeder Variable $x_i$ der Funktion $y$ kommt in $D$ genau einmal vor. Beispiele: Minterm Maxterm 0 \\(\\bar a \\bar b \\bar c\\) \\(a \\lor b \\lor c\\) 1 \\(a \\bar b \\bar c\\) \\(\\bar a \\lor b \\lor c\\) 2 \\(\\bar a b \\bar c\\) \\(a \\lor \\bar b \\lor c\\) 3 \\(a b \\bar c\\) \\(\\bar a \\lor \\bar b \\lor c\\) 4 \\(\\bar a \\bar b c\\) \\(a \\lor b \\lor \\bar c\\) 5 \\(a \\bar b c\\) \\(\\bar a \\lor b \\lor \\bar c\\) 6 \\(\\bar a b c\\) \\(a \\lor \\bar b \\lor \\bar c\\) 0 \\(a b c\\) \\(\\bar a \\lor \\bar b \\lor \\bar c\\) Ein boolescher Ausdruck der Form $\\bigwedge_i \\bigvee_j (\\neg)x_{ij}$ wird konjunktive Normalform (KNF) genannt.","tags":"German posts","title":"Definitionen aus Digitaltechnik"},{"url":"https://martin-thoma.com/what-is-the-best-programming-language/","text":"There is no such thing as a best programming language. Sorry about that, I've just thought it would be a catchy title. I would rather choose my tools after I know the problem I have to solve. Some programming languages are very good at some tasks. I don't know any that is very good at every task. This comic illustrates what I mean: A fair test Bash The bash is great for tiny tasks where other programs are involved. Example Resizing all jpg-images in a given folder to a maximum resolution of 1600x1600 while maintaining the aspect ratio: for i in *.JPG ; do convert \" $i \" -resize 1600x1600 \" ${ i %.JPG } -resized.jpg\" ; done See Converting Files with Linux for more examples. Python Python does a incredibly well job for small problems. I don't have experience with big projects, but some have been done using Python (see list below). Python is dynamically typed, offers a lot of functions out of the box and is easy to learn and understand. You might argue that Python is executable Pseudocode as it is so easy to read. Additionally, it offers a very neat library for math functions with NumPy . Examples of Python-Code in applications include: PDF malware analysis BitTorrent My ProjectEuler Snippets â˜º Scripting within an application: GIMP Blender Websites and Services: GNU Mailman Reddit Trac Java Java is used in the economy for simple, but huge tasks . It is static and strong typed, has some widely used coding convetions , is easy to learn and has a big library. Here are some examples for programs written in Java: Mars Rovers ( source ) BitTorrent client Vuze Sites that have URLs like \" .do\", \" .jsp\" and \"...servlet...\" are most likely written in Java. Games: FreeCol Minecraft C++ C++ is easy to write and blazing-fast. See Performance of Matrix multiplication in Python, Java and C++ . Some projects done in C++ are: NASA flight software: 300k LOC ( source ) Chrome , Firefox Games: Cube 2: Sauerbraten UFO: Alien Invasion The Battle for Wesnoth OpenClonk ( Repository ) OpenLierox ( Repository ) Secret Maryo Chronicles ( Repository ) C See Is C still used? and a comment from Linus Torvalds . Programs done with C: Freeserf ( Repository ) See also 5 Ways to Tell Which Programming Languages are Most Popular OpenGameClones Matlab What is MATLAB good for? Why is it so used by universities? When is it better than Python? Do you know some more programs that are famous and should be in these lists? Preferably with an open repository?","tags":"Code","title":"What is the best programming language?"},{"url":"https://martin-thoma.com/error-correcting-codes/","text":"This blogpost is strongly related to this germand PDF of a pupils' competition in which I have participated in 2008. Today, we have a lot of data that is stored or transferred in a binary way. Once in a while an error occurs and single bits get switched from 0 to 1 or the other way around. Coding theory tries to find algorithms with which you can detect and correct errors. Introduction To keep it simple, we make a small example. We have \\begin{align} \\{A, B, C, D, E, F, G, H\\} &= \\mathcal{F}_3\\\\ \\{A', B', C', D', E', F', G', H'\\} &\\subsetneq \\mathcal{F}_8 \\end{align} \\begin{align} c_3 = \\{&(1,1,1,1,1,1),\\\\ &(0,0,0,0,1,1),\\\\ &(0,0,1,1,0,0),\\\\ &(0,1,0,1,0,1),\\\\ &(0,1,1,0,1,0),\\\\ &(1,0,0,1,1,0),\\\\ &(1,0,1,0,0,1),\\\\ &(1,1,0,0,0,0)\\} \\end{align} Hamming codes Hamming codes are a family of \\((2&#94;k - 1, 2&#94;{(2&#94;k -1)-k}, 3), \\quad k \\geq 2\\) codes. This means, every hamming code can only correct one error. The idea behind Hamming codes is to save in one bit if the number of a fixed set of positions of the message is even or odd. This is called parity and done with XOR. The parity-bit is saved at the end of the message (or, just another point of view: the positions that are powers of two (1, 2, 4, 8, ...) of each message are only parity bits. This are obviously \\(\\lceil \\log_2(\\text{length of code}) \\rceil = \\lceil \\log(2&#94;k - 1) \\rceil = k\\) ). Wikipedia has a really nice image for that: Parity-bits and data bits in a Hamming codeword Now, how are the parity-bits calculated? Well, think of each messages as a vector in \\(\\{0,1\\}&#94;{(2&#94;k - 1) - k}\\) . Then you define a matrix \\(G \\in \\{0,1\\}&#94;{2&#94;k - 1} \\times \\{0,1\\}&#94;{(2&#94;k - 1) - k}\\) . Now you can get the codewords \\(c\\) by multiplying the datawords \\(d\\) (messages) with \\(G\\) : \\(c = G \\cdot d\\) . This is the reason why Hamming-Codes are called \"linear codes\". They can be obtained by a linear function. How do I get the generator-matrix \\(G\\) ? I don't know it and my internet searches didn't reveal any solution. Do you know one?","tags":"My bits and bytes","title":"Error correcting Codes"},{"url":"https://martin-thoma.com/a-practical-approach-to-floats/","text":"If you make a computer science degree, you will have to learn how numbers are internally represented. Most of the time, you get explanations like the pictures below: IEEE 754 single precision Example of a floating point number You will (have to) learn how IEEE 754 floats are structured on a bit-wise level. But I also like to check if it is correct, what I've learned. So this is how you can check it: #include <stdint.h> #include <stdio.h> // printf #include <limits.h> // INT_MAX, UINT_MAX, ... #include <math.h> // needed for NAN union myUnion { uint32_t i ; // unsigned integer 32-bit type (on every machine) float f ; // a type you want to play with }; void printValue ( union myUnion u ) { printf ( \"uint32_t \\t : \\t %u \\n \" , u . i ); printf ( \"Bits \\t\\t : \\t \" ); for ( int i = 31 ; i >= 0 ; i -- ) { printf ( \"%i\" , ( u . i >> i ) % 2 ); if ( i != 0 && i % 4 == 0 ) { printf ( \".\" ); } if ( i == 31 || i == 23 ) { printf ( \"|\" ); } } printf ( \" \\n Number \\t\\t : \\t %0.10f \\n\\n \" , u . f ); } void setSign ( union myUnion * u , char sign ) { u -> i = ( u -> i & ( 0xffffffff - ( 1 << 31 ))) + ( sign << 31 ); } /** * The exponent has 8 bits. * When all bits are 0, you switch to denormalized numbers. * When all bits are 1, you get either NaN or infinity, depending on * your characteristic. If the characteristic is 0, you get infinity. * Otherwise NaN. */ void setExponent ( union myUnion * u , char exponent ) { u -> i = ( u -> i & ( 0xffffffff - ( 0xff << 23 ))) + ( exponent << 23 ); } /** * The mantissa has 23 bits. */ void setMantissa ( union myUnion * u , int mantissa ) { u -> i = ( u -> i & ( 0xffffffff - ( 0xff << 0 ))) + ( mantissa << 0 ); } int main () { union myUnion testVar ; printf ( \"Manual guessing \\n \" ); testVar . i = 0 ; setSign ( & testVar , 1 ); setExponent ( & testVar , 0x01 ); setMantissa ( & testVar , 0x00 ); printValue ( testVar ); printf ( \"What does UINT_MAX evaluate to? \\n \" ); testVar . i = UINT_MAX ; printValue ( testVar ); printf ( \"What does nan evaluate to? \\n \" ); testVar . f = NAN ; printValue ( testVar ); printf ( \"The example above and switched first bit on \\n \" ); testVar . i = 0xbf200000 ; printValue ( testVar ); } I think I have tried all interesting values. Have fun trying it yourself â˜º (hmm ... I could also try to make a visualization ... I will think about this when I have more time)","tags":"Code","title":"A practical approach to floats"},{"url":"https://martin-thoma.com/java-puzzle-14-integers/","text":"What is the output of the following script? public class SomeClass { public static void main ( String [] args ) { int x = 2147483647 ; // 2147483647 == 2**31 - 1 if ( x < 2 * x ) { System . out . println ( \"Everything's ok:\" ); } else { System . out . println ( \"It's weird:\" ); } System . out . println ( \"x = \" + x ); System . out . println ( \"2*x = \" + 2 * x ); } } . . . . . . . . . . . . . . . . . . . . . . Answer It's weird: x = 2147483647 2*x = -2 Explanation 2*x is out of Java Integer range, so it comes back at the other end.","tags":"Code","title":"Java Puzzle #14: Integers"},{"url":"https://martin-thoma.com/programmieren-tutorium/","text":"Programmieren ist ein Modul am KIT . Dieser Blogpost richtet sich also vor allem an Studenten des KIT, die im WS 2012/2013 dieses Modul belegen und mein Tutorium besuchen. Er wird regelmÃ¤ÃŸig aktualisiert. Vorlesung Es gab die Vorlesung mal online unter http://www.youtube.com/embed/videoseries?list=PL22ZNLSohCREsVdSWmjbuST0ba64OctHk&amp;hl=en_US , aber die wurde wohl entfernt ( #depublication ). Daten Es gibt momentan (Stand: 10.10.2012) 820 Studenten, in der Programmieren-Vorlesung: 530 Informatiker 130 Informationswirte 60 Wiederholer 70 andere FakultÃ¤ten 20 SchÃ¼ler-Studenten (Ich weiÃŸ, dass das in der Summe nur 810 Studenten sind. Aber leider hatte ich nur eine mÃ¼ndliche Quelle und kann es deshalb nicht ausbessern.) Folien Sind hier zu finden. Dort sind auch Code-Beispiele aus dem Tutorium. Die LaTeX-Quelldateien stehen auch zur VerfÃ¼gung. Wenn ihr diese verwendet, dann verlinkt bitte auf martin-thoma.com/programmieren-tutorium . Die EinverstÃ¤ndniserklÃ¤rung (Disclaimer) kÃ¶nnt ihr hier herunterladen. Tutorials Folgendes textbasierte Tutorial wurde mir von einem Studenten empfohlen: Java Blog Buch Aber hier sind Video-Tutorials zu finden. Ich habe gerade javatutorialhub.com gefunden. Das erweckt auch einen guten ersten Eindruck. Auf Udacity, einer Online-UniversitÃ¤t, gibt es eine EinfÃ¼hrung in die Programmierung mit Java . Artikel Ich habe ein paar Artikel geschrieben, die fÃ¼r euch interessant sein kÃ¶nnten: Tribonacci-Folge How to sort with Java? Links Uni-Links Praktomat Folien, ÃœbungsblÃ¤tter und Checkstyle (offiziell) Carsten Sinz Abschlussaufgaben-Praktomat (nur Ã¼ber VPN/KIT-Netz) WeiterfÃ¼hrende Links JavaDoc und Java API StackOverflow How To Design A Good API and Why it Matters FÃ¼r Tutoren Das SVN ist hier: https://s_thoma@svnserver.informatik.kit.edu/i12/svn/VeriAlg Wobei ihr natÃ¼rlich s_thoma durch euren ATIS-Account ersetzen mÃ¼sst.","tags":"German posts","title":"Programmieren Tutorium"},{"url":"https://martin-thoma.com/c-puzzle-2/","text":"What is the output of the following script? Why? How can it be fixed to get the expected output? #define __STDC_FORMAT_MACROS #include <inttypes.h> #include <stdio.h> int main () { uint64_t testvar ; testvar = 1 << 30 ; printf ( \"2&#94;30 = %\" PRIu64 \" \\n \" , testvar ); testvar = 1 << 31 ; printf ( \"2&#94;31 = %\" PRIu64 \" \\n \" , testvar ); return 0 ; } . . . . . . . . . . . . . . . . . Answer 2&#94;30 = 1073741824 2&#94;31 = 18446744071562067968 Expected output 2&#94;30 = 1073741824 2&#94;31 = 2147483648 Explanation 1<<30 does a bitshift for int , not for uint64_t How to fix it Add a typecast: #define __STDC_FORMAT_MACROS #include <inttypes.h> #include <stdio.h> int main () { uint64_t testvar ; testvar = 1 << 30 ; printf ( \"2&#94;30 = %\" PRIu64 \" \\n \" , testvar ); testvar = (( uint64_t ) 1 ) << 31 ; printf ( \"2&#94;31 = %\" PRIu64 \" \\n \" , testvar ); return 0 ; }","tags":"Code","title":"C Puzzle #2"},{"url":"https://martin-thoma.com/review-des-acer-travelmate-5744z/","text":"Vor ein paar Tagen ist mein Acer Travelmate 5744Z , das ich bei Amazon fÃ¼r 305,95 Euro bekommen habe, angekommen. Ich habe es mit â€žLinux\" als System gekauft. Wie sich herausstellte, ist MeeGo release 1.0 mit dem Kernel 2.6.37, installiert. Das System startet zwar in sensationellen 29 Sekunden, aber Ubuntu ist mir doch lieber. edit: argh - also mit Ubuntu 12.04 (und Lubuntu 12.04 sowie Ubuntu mit Gnome/Gnome Classic/Cinnamon) bin ich nicht zufrieden. Windows 7 hat tatsÃ¤chlich, ganz im Gegensatz zu allen Ubuntu-Arten, die Treiber CD benÃ¶tigt. Naja. Technische Daten Prozessor : Intel Pentium P6200 mit 2.13 GHz, 2 Kerne, 3 MB Cache (Quelle: ark.intel.com ) Arbeitsspeicher : 4GB DDR3 (3704 MiB laut lshw) Harddisk : WDC WD3200BPVT-2 (320 GB, 5400 RPM, 2.5-inch, 8MB cache) Display : 15,6\" mit max. 1366px x 768px. Matt, LED LCD; Maximale Helligkeit von 174 cd/mÂ² laut notebookcheck.com Grafikkarte : Intel HD Graphics (onboard) - Intel GMA HD Laufwerk : DVD-Super Multi DL drive LAN : NetLink BCM57780 Gigabit Ethernet PCIe, capacity: 1Gbit/s Gewicht : 2.5kg Akku : vermutlich 4.400 mAh Akkulaufzeit : 3.7 Std B x H x T : 38.1 cm x 2.57 - 3.38 cm x 25.3 cm Weiteres : Acer Nplify 802.11b/g/n: Acer Nplify, a high-throughput wireless solution, delivers superior performance and reliable connections while enabling emerging voice, video and data applications. SD-Kartenleser 3x USB 2.0 2,5 kg DVD-Brenner ist irgendwie nicht so toll zu Ã¶ffnen. Das war beim 5735Z besser. Linux Sorgenkinder Webcam : Funktioniert out of the box WLAN : Funktioniert out of the box (WTF, ich kann bei mir das Uni-WLAN sehen!?! - Ein AR9485 Wireless Network Adapter von Atheros Communications Inc.) Sound : Funktioniert out of the box (Lautsprecher und Buchse - die Lautsprecher sind nicht so toll, aber das ist bei einem Notebook ja zu erwarten) Mikrofon : Sehr leise, funktioniert aber out of the box Fazit Tolles Low-Budget Notebook, das einwandfrei unter Linux (und Windows) funktioniert! Insbesondere der LÃ¼fter ist extrem leise. Was ich gerne noch hÃ¤tte (aber bei diesem Preis nicht erwarten darf): Bluetooth","tags":"Cyberculture","title":"Review des Acer Travelmate 5744Z"},{"url":"https://martin-thoma.com/java-puzzle-13-absolute-value-weirdness/","text":"What does the following snippet output? public class SomeClass { public static void main ( String [] args ) { int a = - 10 ; int b = - 2147483648 ; // -2147483648 == -2**31 if ( Math . abs ( a ) < - 1 ) { System . out . println ( \"|a| < -1\" ); } else { System . out . println ( \"|a| >= -1\" ); } if ( Math . abs ( b ) < - 1 ) { System . out . println ( \"|b| < -1\" ); } else { System . out . println ( \"|b| >= -1\" ); } System . out . println ( \"|a| = \" + Math . abs ( a )); System . out . println ( \"|b| = \" + Math . abs ( b )); } } . . . . . . . . . . . . . . . . . . . . . . Answer |a| >= -1 |b| < -1 |a| = 10 |b| = -2147483648 Explanation Integer values range (in Java) from -2147483648 to 2147483647. This means, the absolute value of -2147483648 is not in the integer range. For more details, see this SO answer .","tags":"Code","title":"Java Puzzle #13: Absolute value weirdness"},{"url":"https://martin-thoma.com/burokratie-am-kit/","text":"Das KIT sieht sich gerne als Elite-UniversitÃ¤t. [ 1 ] Es werden Rankings in Vorlesungen zitiert und erst vor kurzem wurde von einigen Professoren in der Vorlesung der Verlust des Status der Elite-UniversitÃ¤t betrauert. [ 1 ] Ich weiÃŸ nicht, was die Kriterien fÃ¼r eine Elite-Uni nach der Exzellenzinitiative sind, aber ich kann mir einige notwendige Voraussetzungen vorstellen, die fÃ¼r mich eine Elite-Uni ausmachen: Lehre Vorlesungen, die anspruchsvollen Stoff gut strukturiert und aufbereitet vermitteln Ãœbungen, die den Stoff vertiefen und eventuell motivieren Tutorien, die offene Fragen beantworten und von kompetenten Tutoren gehalten werden Forschung: Hier kann ich mir nicht anmaÃŸen, gute Kriterien aufstellen zu kÃ¶nnen, da ich selbst noch nicht daran beteiligt bin. Wirtschaft: vgl. Forschung Damit die Personen, die an Lehre, Forschung und in der Wirtschaft beteiligt sind gut arbeiten kÃ¶nnen, muss die Organisation reibungsfrei verlaufen. Mir ist klar, dass bei 22.552 Studierenden (Stand: MÃ¤rz 2012) nicht immer alles reibungsfrei ablaufen kann. Auch der Bologna-Prozess scheint wohl immer noch Probleme nach sich zu ziehen. Aber fÃ¼r ein paar Probleme, die ich vor kurzem selbst erleben musste, habe ich kein VerstÃ¤ndnis. Diese Probleme sind - so scheint es mir - bÃ¼rokratischer und organisatorischer Natur: StudienbÃ¼ro Das StudienbÃ¼ro hat folgende Ã–ffnungszeiten: Mo-Mi: 10:00 - 12:00 Uhr Do: 13:30 - 15:30 Uhr Es hat also in der Woche nur 8 Stunden geÃ¶ffnet. Ich war heute (Mittwoch) um 9:40 Uhr StudienbÃ¼ro und es war bereits eine Schlange von ca. 20 Leuten vor der TÃ¼r. Als pÃ¼nktlich um 10:00 Uhr der Eingang geÃ¶ffnet wurde, reichte die Schlange bereits bis zum gegenÃ¼berliegenden GebÃ¤ude. Man muss nun beobachten, wie sich das im laufe des Semesters verhÃ¤lt, aber es ist schon ein deutliches Indiz dafÃ¼r, dass hier entweder MÃ¤ngel in der Organisation und Struktur des Studiums bzw. der damit verbundenen Software (z.B. QISPOS) vorliegen, oder zu wenig Personal vorhanden ist. Schalter und Schlangen Momentan sind Zettelrollen in verschiedenen Farben aufgestellt. Die Farben sind je nach Studiengang unterschiedlich. Auf jedem Zettel steht eine Nummer und diese wird aufgerufen. Dazu steht eine Frau an der TÃ¼r, ruft die Nummer und hÃ¤lt die TÃ¼r auf. Ich weiÃŸ nicht ob diese Frau noch irgendetwas anderes macht, aber es scheint nicht der Fall zu sein. Wenn sie in dieser Zeit einen weiteren Schalter betreuen wÃ¼rde und das Aufrufen wie bei der Bahn oder im Finanzamt Ã¼ber eine elektronische Anzeige geschehen wÃ¼rde, hÃ¤tte man vermutlich schon eine Effizienzsteigerung. Die aktuelle Nummer kÃ¶nnte man dann auch Ã¼ber einen Webdienst verfÃ¼gbar machen, sodass man in der Zwischenzeit auch etwas sinnvolleres machen kann. Nach ein paar Minuten wurde gefragt: \"Gibt es noch irgendjemanden der einen blauen Zettel hat?\". Es gab niemanden. Was passiert dann? Ist eine Arbeitskraft dann untÃ¤tig, obwohl noch 50 Leute auf Hilfe / Antworten warten? Freundlichkeit und Kompetenz Als ich dann endlich im StudienbÃ¼ro zu meinem Schalter gekommen bin, konnte ich mein Problem vorstellen. Ich versuche das mÃ¶glichst wortwÃ¶rtlich wiederzugeben: Das Modul \"Algorithmen I\" war nicht als bestanden markiert, obwohl ich die Klausur \"Algorithmen I\" bestanden habe, diese auch als bestanden im System stand und es keine weiteren Voraussetzungen gibt. Das habe ich der Angestellten so gesagt. Angestellte: â€žDa kann ich nichts machen, ich brauche erst ein Formular. Ohne Formular geht da nichts, da mÃ¼ssen sie zu Frau Gheta, ich muss 3 Schalter betreuen und habe dafÃ¼r keine Zeit.\" Was soll denn das? Ein kurzer Blick ins Modulhandbuch - ich konnte auch sagen an welcher Stelle - ein Blick auf meine Leistungen (die sie bereits aufgerufen hatte) und alles wÃ¤re klar geweisen. Also habe ich das Problem nochmals beschrieben Ich: â€žIch habe alle Teile des Moduls bestanden, warum ist dann das Modul nicht als bestanden markiert?\" Sie schaut in ihr System und sagt mir, dass ich noch nicht alles aus der Theoretischen Informatik bestanden habe. Warum hat sie plÃ¶tzlich mit theoretischer Informatik angefangen? Ich habe nichts von Theoretischer Informatik gesagt und mir ist klar, dass ich fÃ¼r das Fach noch nicht alles bestanden habe. Aber das hat doch nichts mit dem Modul zu tun. Obwohl ich die Ãœbungsscheine â€žLineare Algebra I\" und â€žLineare Algebra II\" fÃ¼r Mathematiker gemacht und bestanden habe, ist nur ein Ãœbungsschein â€žLineare Algebra I fÃ¼r die fachrichtung Informatik\" in QISPOS. Also sollte der Ãœbungsschein â€žLineare Algebra I fÃ¼r die fachrichtung Informatik\" in â€žLineare Algebra I\" umgewandelt werden und der Ãœbungsschein â€žLineare Algebra II\" hinzugefÃ¼gt werden. Ich habe beide Scheine in Papierform, vom Prof. unterschrieben, dabei gehabt und ihr gegeben. Angestellte legt die beiden Ãœbungsschein-BestÃ¤tigungen auf einen Ablagestapel Angestellte: â€žDafÃ¼r benÃ¶tigen sie eine BestÃ¤tigung.\" Ich: â€žAber ich habe Ihnen doch gerade die BestÃ¤tigung gegeben?!?\" Angestellte: â€žFÃ¼r eine Ummeldung muss ein anderes Formular ausgefÃ¼llt werden. Ich kann so nur die Ãœbungsscheine hinzufÃ¼gen.\" Na gut, dann habe ich nun wohl einen Ãœbungsschein zu viel ... Nach ein bisschen Diskutieren meint sie, ich hÃ¤tte wegen HM bereits einen Antrag gemacht. Ich habe niemals HM besucht und hatte bisher auch keine Probleme wegen HM vs. Analysis. Hoffentlich kommt das jetzt nicht dazu ... Insgesamt muss ich sagen, wurde ich unfreundlich behandet - ich hatte das GefÃ¼hl, direkt wieder rausgeworfen zu werden - und die Frau hat mir nicht zugehÃ¶rt. Kurz darauf bin ich zum â€žServicezentrum fÃ¼r Studium und Lehre\" gegangen. Dort hat mir Frau Metzig geholfen. Sie hat mein Problem verstanden. Nach wenigen Minuten, ohne langes Anstehen oder irgendwelche Formulare hat sie mir versichert, dass Sie sich um das Problem in den nÃ¤chsten zwei Tagen kÃ¼mmert. Schon nach 2 Stunden kam eine E-Mail an, in der sie mir mitteilte, dass es ein Systemfehler war. Mein Problem ist nun behoben. QISPOS QISPOS ist ein System von der HIS Hochschul-Informations-System GmbH , das am KIT fÃ¼r die PrÃ¼fungsverwaltung eingesetzt wird. Das bedeutet, hier meldet man sich an und ab, kann Noten und bestandene Module nachschauen. Auch Voraussetzungen fÃ¼r andere Module wie z.B. PSE werden hiermit Ã¼berprÃ¼ft. Dieses System muss ziemlich schwere Voraussetzungen erfÃ¼llen: Es muss funktionieren. Immer. Leider ist das nicht der Fall: PrÃ¼fungsanmeldungen klappen nicht. Es werden fehlende Voraussetzungen angezeigt, obwohl es keine Voraussetzungen gibt (ist mir mit Algorithmen passiert) Die Anmeldung fÃ¼r manche Module ist nicht mÃ¶glich, obwohl sie laut Modulhandbuch mÃ¶glich ist (z.B. Physiker und Mathe) Sonstige Systemfehler kommen vor: Das Modul Algorithmen wurde bei mir nicht als bestanden markiert, obwohl es offensichtlich bestanden war. Das sind jetzt nur ein paar Fehler, die mir persÃ¶nlich passiert sind. Es gibt bestimmt noch mehr. Und von unschÃ¶nen Dingen wie langen Ladezeiten, einer schlechten MenÃ¼fÃ¼hrung oder einer fehlenden Suchfunktion will ich mal gar nicht reden. Da frage ich mich schon, was das KIT dafÃ¼r bezahlt. Einfach gesagt, sehe ich zwei MÃ¶glichkeiten: Es wird sehr wenig bezahlt: Dann ist es kein Wunder, dass diese Probleme auftreten. Dann sollte man sich Ã¼berlegen, ob es nicht sinnvoll wÃ¤re, mehr zu investieren Man zahlt angemessen / viel fÃ¼r die geforderten Eigenschaften: In diesem Fall sollte man sich nach einem anderem Anbieter umsehen oder selbst eine Entwicklung starten. Ehrlich gesagt wundert es mich, dass es hierfÃ¼r keine Uni-Eigene LÃ¶sung gibt. Gibt es OpenSource in diesem Bereich? HÃ¤ufige Probleme - FAQ Als ich gewartet habe, sind mir zwei hÃ¤ufige Probleme aufgefallen: Defekte KIT-Card Keine Matrikelnummer Eine defekte KIT-Card sollte einfach Ã¼ber ein Online-Formular nachbestellbar sein. Ich sehe keinen Grund, warum man dazu in das StudienbÃ¼ro gehen sollte. Wenn jetzt, nach beginn der Vorlesungszeit, noch keine Matrikelnummer vorhanden ist, lÃ¤uft irgendwas schief. Da es bei vielen der Fall ist, kann es nicht an den Studenten liegen. Entweder wurden bestimmte voraussetzungen nicht deutlich genug gemacht (Ã  la: Es muss Formular XY zurÃ¼ckgeschickt werden, bevor eine Matrikelnummer ausgestellt wird), oder es der Prozess eine Matrikelnummer zu erstellen dauert zu lange. Falls das zu lange dauert, kann man entweder den Prozessablauf beschleunigen, oder mehr Personal einstellen. Eine einfache FAQ-Liste auf der Seite des StudienbÃ¼ros kÃ¶nnte schon helfen. So, jetzt habe ich einige Stunden mit BÃ¼rokratie, Organisation und diesem Bericht darÃ¼ber verbacht und etwas Frust abgebaut. Zeit, die ich in mein Studium hÃ¤tte stecken kÃ¶nnen. Vielleicht liest es ja jemand, der etwas Ã¤ndern kann. Habt ihr Ã¤hnliche Geschichten mit dem StudienbÃ¼ro erlebt? Habt ihr VerbesserungsvorschlÃ¤ge? Dann hinterlasst doch einfach einen Kommentar.","tags":"German posts","title":"BÃ¼rokratie am KIT"},{"url":"https://martin-thoma.com/java-puzzle-12-control-flow/","text":"What is the output of the following HelloWorld.java ? public class HelloWorld { public static void main ( String [] args ) { if ( 2 < 1 ); { System . out . println ( \"Yes\" ); } } } . . . . . . . . . . . Answer The output is \"Yes\". Explanation The ; means, that no block is executed. The { ... } is just a code block and not really related to the if -statement.","tags":"Code","title":"Java Puzzle #12: Control-flow"},{"url":"https://martin-thoma.com/learning-java/","text":"I've just found some YouTube clips by thenewboston in which he explains how to program in Java. I didn't watch them, but I took a look at some of them. Seems to be very easy to understand. He starts right from the beginning (that means: how do I install Java?) explains basic concepts like variables, program flow statements and user input and goes to GUI with Swing: See also C++ Beginner Tutorial : 54 Videos on YouTube from XoaX.net C++ OpenGL Beginner Tutorials : 54 Videos from XoaX.net","tags":"Code","title":"Learning Java"},{"url":"https://martin-thoma.com/java-puzzle-11-change-argument-of-foreach/","text":"What is the output of the following HelloWorld.java? import java.util.LinkedList ; public class HelloWorld { public static void main ( String [] args ) { LinkedList < Integer > list = new LinkedList < Integer >(); list . add ( 1 ); list . add ( 2 ); list . add ( 3 ); int i = 0 ; for ( Integer el : list ) { System . out . println ( el ); list . add ( el ); i ++; if ( i > 20 ) { break ; } } } } . . . . . . . . . . . . . . . . . . . . . . . . Answer 1 Exception in thread \"main\" java . util . ConcurrentModificationException at java . util . LinkedList$ListItr . checkForComodification ( LinkedList . java : 761 ) at java . util . LinkedList$ListItr . next ( LinkedList . java : 696 ) at HelloWorld . main ( HelloWorld . java : 10 )","tags":"Code","title":"Java Puzzle #11: Change argument of foreach"},{"url":"https://martin-thoma.com/manipulating-pdf-files/","text":"I just wanted to get some pages out of a bigger PDF file. The tool that can be used for this task is called pdftk . It is in the standard Ubuntu repsitory. Usage Split the file, so that every page becomes a new PDF file: pdftk myfile.pdf burst Extract pages 10 to 12 from bigPDF.pdf : pdftk bigPDF.pdf cat 10 -12 output output.pdf","tags":"Cyberculture","title":"Manipulating PDF files"},{"url":"https://martin-thoma.com/java-generics/","text":"Some months ago, I had to improve some Java code for university. They gave us a model of a windows like file system and we had to make the code \"cleaner\". I think I've overdone the application of generics, but it's a nice example for generics ;-) You can download the complete Eclipse project . Computer.java package edu.kit.filesystem ; import java.util.ArrayList ; import java.util.Vector ; public class Computer { public String computerName ; public Vector < HDD > hdds = new Vector < HDD >(); public Computer ( String companyName , HDD gf ) { this . computerName = companyName ; this . hdds . add ( gf ); } private void addDrive ( HDD drive ) { hdds . add ( drive ); } public void printContent () { for ( HDD hdd : hdds ) { System . out . println ( \"| HDD: \" + hdd . getName () + \" (\" + hdd . getDescription () + \")\" ); for ( Directory dir : hdd . get ( Directory . class )) { printContent ( dir , \"\" ); } for ( ZipArchiv zip : hdd . get ( ZipArchiv . class )) { printContent ( zip , \"\" ); } for ( File f : hdd . get ( File . class )) { printContent ( f , \"|-\" ); } } } private void printContent ( Node d , String ident ) { System . out . println ( \"|-\" + ident + \" \" + d . getName ()); ArrayList < Class <? extends Node >> list = new ArrayList < Class <? extends Node >>(); list . add ( Directory . class ); list . add ( ZipArchiv . class ); list . add ( File . class ); if ( d instanceof NodeContainer ) { NodeContainer e = ( NodeContainer ) d ; for ( Class <? extends Node > T : list ) { ArrayList <? extends Node > tmp = e . get ( T ); for ( Node n : tmp ) { printContent ( n , ident + \"-\" ); } } } } public static void main ( String [] args ) { // Create the computer HDD platte1 = new HDD ( \"C\" , \"Main disk\" ); Computer f = new Computer ( \"MyMainComputer\" , platte1 ); // we need a backup HDD platte2 = new HDD ( \"D\" , \"Backup disk\" ); f . addDrive ( platte2 ); // create main directories Directory v1 = new Directory ( \"temp\" , \"temporary files\" ); platte1 . addNode ( v1 ); v1 . addNode ( new Directory ( \"asdf\" , \"jkl&ouml;\" )); Directory v2 = new Directory ( \"Pictures\" , \"Holiday pictures\" ); platte1 . addNode ( v2 ); // Gib den Verzeichnissen ein paar Inhalte // Ein paar Archive im Temp ZipArchiv zip1 = new ZipArchiv ( \"fp-update.zip\" , \"Flashplayer Update\" ); v1 . addNode ( zip1 ); ZipArchiv zip2 = new ZipArchiv ( \"swt1-folien.zip\" , \"PDFs of SWT1\" ); v1 . addNode ( zip2 ); // pictures ZipArchiv barcelona = new ZipArchiv ( \"2010-Barcelona.zip\" , \"Holiday Barcelona 2010\" ); v2 . addNode ( barcelona ); ZipArchiv mallorca = new ZipArchiv ( \"2011-Mallorca.zip\" , \"Sonne satt\" ); v2 . addNode ( mallorca ); v2 . addNode ( new File ( \"ipdlogo.png\" , \"IPD\" )); // add some files to archives ZipArchiv b1 = new ZipArchiv ( \"BarcelonaBeach.zip\" , \"Strandbilder\" ); barcelona . addNode ( b1 ); b1 . addNode ( new File ( \"s1.jpg\" , \"Strand\" )); b1 . addNode ( new File ( \"s2.jpg\" , \"Mehr Strand\" )); b1 . addNode ( new File ( \"s3.jpg\" , \"Strand und Meer\" )); b1 . addNode ( new File ( \"s4.jpg\" , \"Noch mehr Strand\" )); File b2 = new File ( \"Picasso.jpg\" , \"Museum\" ); barcelona . addNode ( b2 ); File b3 = new File ( \"SagradaFamilia.jpg\" , \"Kirche\" ); barcelona . addNode ( b3 ); File b4 = new File ( \"CampNou.jpg\" , \"Fu&szlig;ball\" ); barcelona . addNode ( b4 ); File m1 = new File ( \"Strand.jpg\" , \"Strand\" ); mallorca . addNode ( m1 ); f . printContent (); } } Node.java package edu.kit.filesystem ; public abstract class Node { private String name ; private String description ; public String getName () { return name ; } public void setName ( String name ) { this . name = name ; } public String getDescription () { return description ; } public void setDescription ( String description ) { this . description = description ; } } NodeContainer.java package edu.kit.filesystem ; import java.util.ArrayList ; public interface NodeContainer { public < T > ArrayList < T > get ( Class < T > clazz ); public void addNode ( Node n ); } HDD.java package edu.kit.filesystem ; import java.util.ArrayList ; public class HDD extends Node implements NodeContainer { private final ArrayList < Node > nodes = new ArrayList < Node >(); public HDD ( String name , String beschreibung ) { this . setName ( name ); this . setDescription ( beschreibung ); } @SuppressWarnings ( \"unchecked\" ) public < T > ArrayList < T > get ( Class < T > clazz ) { ArrayList < T > allElements = new ArrayList < T >(); for ( Node o : nodes ) { if ( o . getClass () == clazz ) { allElements . add (( T ) o ); } } return allElements ; } public void addNode ( Node n ) { nodes . add ( n ); } } Directory.java package edu.kit.filesystem ; import java.util.ArrayList ; public class Directory extends Node implements NodeContainer { private final ArrayList < Node > nodes = new ArrayList < Node >(); public Directory ( String name , String description ) { this . setName ( name ); this . setDescription ( description ); } public void addNode ( Node n ) { nodes . add ( n ); } @SuppressWarnings ( \"unchecked\" ) public < T > ArrayList < T > get ( Class < T > clazz ) { ArrayList < T > allElements = new ArrayList < T >(); for ( Node o : nodes ) { if ( o . getClass () == clazz ) { allElements . add (( T ) o ); } } return allElements ; } } ZipArchiv.java package edu.kit.filesystem ; import java.util.ArrayList ; public class ZipArchiv extends File implements NodeContainer { private final ArrayList < Node > nodes = new ArrayList < Node >(); public ZipArchiv ( String name , String description ) { super ( name , description ); } public void addNode ( Node n ) { nodes . add ( n ); } @SuppressWarnings ( \"unchecked\" ) public < T > ArrayList < T > get ( Class < T > clazz ) { ArrayList < T > allElements = new ArrayList < T >(); for ( Node o : nodes ) { if ( o . getClass () == clazz ) { allElements . add (( T ) o ); } } return allElements ; } } File.java package edu.kit.filesystem ; public class File extends Node { public File ( String name , String beschreibung ) { this . setName ( name ); this . setDescription ( beschreibung ); } }","tags":"Code","title":"Java Generics"},{"url":"https://martin-thoma.com/balanzan-theme/","text":"I don't understand why all desktop environment seem to lack a good theme chooser/editor and good themes. I have one favorite theme - called \" Balanzan Theme \" which should be available in every distribution. The Balanzan Theme is part of the bisigi-project . According to the package , it is licensed under GPL. So I think I can upload some of its content here. Installation sudo add-apt-repository ppa:bisigi sudo apt-get update sudo apt-get install bisigi-themes Impression Impression of the Balanzan Theme Color Theme LXDE Background Foreground Normal windows: #F5EDD8 #101010 Text windows: #FFF #1A1A1A Selected items: #F4C256 #1A1A1A Tooltips: #F5F5B5 #000 Icon Theme Download the whole package , go to balazan-theme/icons and look into balazan.tar.bz2 . Here are some of the icons: Balanzan Icons Background The background is based on \" Lion Claar \" background by DamiÃ¡n Vila: Balanzan 4:3 wallpaper Balanzan 16:9 wallpaper","tags":"Cyberculture","title":"Balanzan Theme"},{"url":"https://martin-thoma.com/pse-am-kit/","text":"Da es zum Modul â€žPraxis der Software-Entwicklung\" vom KIT leider nur verstreut Informationen gibt (die noch dazu teilweise veraltet sind) versuche ich mal fÃ¼r das Wintersemester 2012/2013 ein paar Informationen zu sammeln und darzustellen. Allgemeines max 10k LOC (Java / C++ / C#) 2 $\\frac{\\text{Tage}}{\\text{Woche} \\cdot \\text{Teilnehmer}}$ sollte man einplanen (offiziell) Tools wollen sie sehen: Eclipse, GUI-Builder, JMetrics, Rational Architect, JCov Bis 18. November: Anmeldung in studium.kit.edu fÃ¼r PSE und Teamarbeit in der Software-Entwicklung Modulhandbuch: PSE Das Modul PSE wird als IN2INSWP bezeichnet und auf S. 37 beschrieben. Es findet jedes Semester statt und ist 6 ECTS-Punkte wert. Erfolgskontrolle Die Erfolgskontrolle erfolgt nach Â§ 4 Abs. 2 Nr. 3 SPO als benotete Erfolgskontrolle anderer Art. Die in den Anmerkungen genannten Artefakte werden separat benotet und gehen mit folgendem Prozentsatz in die Gesamtnote ein: Pflichtenheft 10% Entwurf 30% Implementierung 30% QualitÃ¤tssicherung 20% AbschlussprÃ¤sentation 10% Bedingungen Das Modul muss zusammen mit dem Modul Teamarbeit in der Software-Entwicklung [IN2INSWPS] belegt werden. Der erfolgreiche Abschluss der Module Grundbegriffe der Informatik [IN1INGI], Programmieren [IN1INPROG] und Softwaretechnik I [IN1INSWT1] wird vorausgesetzt. Lernziele Die Teilnehmer lernen, ein vollstÃ¤ndiges Softwareprojekt nach dem Stand der Softwaretechnik in einem Team mit ca. 5-7 Teilnehmern durchzufÃ¼hren. Ziel ist es insbesondere, Verfahren des Software-Entwurfs und der QualitÃ¤tssicherung praktisch einzusetzen, Implementierungskompetenz umzusetzen, und arbeitsteilig im Team zu kooperieren. Inhalt Erstellung des Pflichtenheftes incl. Verwendungsszenarien Objektorientierter Entwurf nebst Feinspezifikation Implementierung in einer objektorientierten Sprache Funktionale Tests und Ãœberdeckungstests Einsatz von Werkzeugen (z.B. Eclipse, UML, Java, Junit, Jcov) PrÃ¤sentation des fertigen Systems Anmerkungen Zur Struktur : Das Praktikum gliedert sich in die Phasen Pflichtenheft, Entwurf und Feinspezifikation, Implementierung, QualitÃ¤tssicherung, AbschlussprÃ¤sentation. Alle Phasen werden nach dem Stand der Softwaretechnik objektorientiert und werkzeugunterstÃ¼tzt durchgefÃ¼hrt. Zu jeder Phase muss das entsprechende Artefakt (Pflichtenheft, UML-Diagramme mit ErlÃ¤uterungen, vollstÃ¤ndiger Java-Quellcode, Testprotokolle, laufendes System) in einem Kolloquium prÃ¤sentiert werden. Das vollstÃ¤ndige System wird von den Betreuern auf FunktionalitÃ¤t, Bedienbarkeit und Robustheit geprÃ¼ft. Modulhandbuch: Teamarbeit in der Software-Entwicklung Das Modul â€žTeamarbeit in der Software-Entwicklung\" wird als IN2INSWPS auf S. 39 des Modulhandbuchs beschrieben. Es ist 2 ECTS-Punkte wert und besteht aus nur einer Lehrveranstaltung (Teamarbeit und PrÃ¤sentation in der Software-Entwicklung, S. 402) Erfolgskontrolle Die Erfolgskontrolle erfolgt als benotete Erfolgskontrolle anderer Art nach Â§ 4 Abs. 2 Nr. 3 SPO. Teilnehmer mÃ¼ssen als Team von ca. 5 Studierenden PrÃ¤sentationen zu den Software-Entwicklungsphasen Pflichtenheft, Entwurf, Implementierung, QualitÃ¤tssicherung sowie eine AbschlussprÃ¤sentation von je 15 Minuten erarbeiten. Teilnehmer mÃ¼ssen Dokumente zur Projektplanung, insbesondere QualitÃ¤tssicherungsplan und Implementierungsplan vorlegen und umsetzen. Bedinungen Das Modul kann nur in Verbindung mit dem Modul Praxis der Software-Entwicklung [IN2INSWP] absolviert werden. Der erfolgreiche Abschluss der Module Grundbegriffe der Informatik [IN1INGI] und Programmieren [IN1INPROG] wird vorausgesetzt. Lernziele Die Teilnehmer erwerben wichtige nicht-technische Kompetenzen zur DurchfÃ¼hung von Softwareprojekten im Team. Dazu gehÃ¶ren Sprachkompetenz und kommunikative Kompetenz sowie Techniken der Teamarbeit, der PrÃ¤sentation und der Projektplanung. Inhalt Auseinandersetzung mit der Arbeit im Team, Kommunikations-, Organisations- und Konfliktbehandungsstrategien; Erarbeitung von PrÃ¤sentationen zu Pflichtenheft, Entwurf, Implementierung, QualitÃ¤tssicherung, AbschlussprÃ¤sentation; Projektplanungstechniken (z.B. Netzplantechnik, Phasenbeauftragte). Anmerkungen Dieses Modul ergÃ¤nzt das Pflichtmodul Praxis der Software-Entwicklung [IN2INSWP]. Es ist ein Pflichtmodul. Studierende, die die SchlÃ¼sselqualifikationen bereits in vollem Umfang vorliegen, aber das Modul Praxis der Software-Entwicklung [IN2INSWP] noch nicht bestanden haben, kontaktieren bitte das Service-Zentrum Studium und Lehre. WebInscribe Man meldet sich vermutlich bald unter webinscribe.ira.uka.de/pse2012 an. Termine Diese Seite bietet ein paar weitere Informationen: Auftaktveranstaltung : Montag, 15.10.2012 um 15:45 Uhr im Audimax Bis 18. November : Anmeldung in studium.kit.edu fÃ¼r PSE und Teamarbeit in der Software-Entwicklun Themen Sind unter â€ž Aufgabenstellungen \" zu finden und ein paar davon hier nochmals mit Links: Name Teams #, LV-Nr. TM Abeck CampusCoach - Entwicklung eines Web-basierten Coaching-Systems 1 1, 24041 IFA Asfour Teleoperating eines humanoiden Roboters mit einem Android Tablet 1 # ITI Beckert Automatisches PrÃ¼fen von Programmeigenschaften 2 # TM Beigl Point and Click - Steuerung von Intelligenten Umgebungen mit Android und Kinect 4 # IOSB Beyerer Steuerung mobiler Roboter im vermischten Windows-Linux Netzwerk Ã¼ber ROS-Middleware 1 # Multispektrale Datenbank 1 # IPD BÃ¶hm Ein lokaler Energiemarktplatz fÃ¼r das Smart Grid 2 # Management personenbezogener Daten in Crowdsourcing-Szenarien 2 # Generating Meaningful Statistics on Access Behavior to Scientific Data Bases 2 # IBDS Dachsbacher Echtzeitcomputergrafik in der Spieleentwicklung 2 # TM Hartenstein Mein Fenster zur Welt â€“ Visualisierung von Netzwerk-Traffic 1 # ITEC Henkel Modulares Multimedia-Werkzeug zum Testen von Videoencodern 2 # IKS MÃ¼ller-Quade Broadcast-VerschlÃ¼sselung â€“ Pay-TV und andere Anwendungen 1 11 IPD Reussner Bewertungssoftware fÃ¼r die Mensa 4 # IFA Schulz Tablet-basiertes Memory-Spiel fÃ¼r Menschen mit Demenz 1 # ITI Sanders Entwicklung eines Routenplaners 1 # Flexibles Kartenrendering 1 # IPD Tichy Der Microsoft Imagine Cup 2013 ( en-Wiki ) 3 # 30 Teams bei 5-7 Personen/Team \\(\\Rightarrow\\) 150-210 Personen kÃ¶nnen dieses Semester PSE machen. Wir sind jedoch soweit ich weiÃŸ etwa 600...","tags":"German posts","title":"PSE am KIT"},{"url":"https://martin-thoma.com/python-puzzle-3-associativity/","text":"What is the output of 1 in [] in 'a' and what is the output of ( 1 in []) in 'a' or 1 in ([] in 'a' ) . . . . . . . . . . . . . . . . . . . . . . . . . Answer The first expression evaluates to False , because it gets evaluated as (1 in []) and ([] in 'a') ( Manual , Source ). The second two expressions are invalid; they throw an error.","tags":"Code","title":"Python Puzzle #3: Associativity"},{"url":"https://martin-thoma.com/sizes-in-latex/","text":"Here is an overview of sizes in LaTeX: TikZ TikZ thicknes Usage example: \\draw[ultra thick, blue,dashed](a -| current plot begin) -- (a); ultra thin very thin thin semithick thick very thick ultra thick more Text Usage example: \\Huge \\(\\varepsilon\\) \\tiny \\scriptsize \\footnotesize \\small \\normalsize \\large \\Large \\LARGE \\huge \\Huge Math Formulas Sizes of different math modes Usage example: \\(\\scriptstyle \\lim_{n \\rightarrow \\infty} (1 + \\frac{1}{n})&#94;n\\) \\scriptscriptstyle \\scriptstyle \\textstyle \\displaystyle Parentheses The size of brackets [ ] , (curly) braces { } and parentheses ( ) can be adjusted with these commands: $$ - 1 + x ( x \\big ( 1 + x \\Big ( 2 + x \\bigg ( 3 + x \\Bigg ( 4 + x \\Bigg ) \\bigg ) \\Big ) \\big ) ) $$ The result will look like this Sizes of parentheses","tags":"Code","title":"Sizes in LaTeX"},{"url":"https://martin-thoma.com/code-golf/","text":"Code golf is a type of recreational computer programming competition in which participants strive to achieve the shortest possible code that solves a certain problem. Source: Wikipedia I've recently found some very interesting code golf examples on codegolf.stackexchange.com : Snake Task : Recreate the classic snake Game. The shortest answer is written in Ruby in 316 characters , the longest is written in Java in 2239 characters . Here is a Python answer with 818 characters: import pygame as p from random import randint as r p . init (); l = 20 c = p . time . Clock () dp = p . display ; w = p . display . set_mode (( 500 , 500 )) C = p . Color ; b = C ( 0 , 0 , 0 ); g = C ( 0 , 255 , 0 ) D = ( 0 , 1 ); U = ( 0 , - 1 ); L = ( - 1 , 0 ); R = ( 1 , 0 ) S = [ R ]; d = R ; n = [] O = lambda t :{ U : D , R : L , D : U , L : R }[ t ] def Q ( e ): print \"Score: %i \" % ( len ( S ) - 1 ); p . quit () def K ( e ): global d ; _ = { 276 : L , 273 : U , 274 : D , 275 : R } . get ( e . key ,( 0 , 0 )); d = not _ == O ( d ) and _ or d def N ( S ):[ p . draw . rect ( w , g ,[ x [ 0 ] * l , x [ 1 ] * l , l , l ]) for x in S + n ] def M (): n = ( r ( 0 , 24 ), r ( 0 , 24 )); return n not in S and n or M () A = lambda s , o : tuple ( x + y for x , y in zip ( s , o )) n = [ M ()] while True : w . fill ( b );[{ 12 : Q , 2 : K } . get ( e . type , lambda e : e )( e ) for e in p . event . get ()] if not ( 0 <= S [ - 1 ][ 0 ] < 25 and 0 <= S [ - 1 ][ 1 ] < 25 ) or A ( S [ - 1 ], d ) in S : Q ( e ) if A ( S [ - 1 ], d ) in n : S . append ( A ( S [ - 1 ], d )); n = [ M ()] else : S . append ( A ( S [ - 1 ], d )); S . pop ( 0 ) N ( S ); dp . update (); c . tick ( 6 ) Matrix determinant Task : Calculate the determinant of a \\(n \\times n\\) matrix. Solution in J (61 characters): -/>([:+/#(([{.<:@[}.])[:*//._2,\\2#])])&amp;.>(|.;])\".];._2[1!:1[3 Solution in Python (198 characters): t = input () e = enumerate p = lambda t : t and (( b + [ a ], j + i ) for i , a in e ( t ) for b , j in p ( t [: i ] + t [ i + 1 :])) or [([], 0 )] print sum ( reduce ( lambda t ,( i , r ): t * r [ i ], e ( p ), 1 - i % 2 * 2 ) for p , i in p ([ t ] + [ input () for x in t [ 1 :]])) Factorial Task : Find the factorial of a number. J (12 characters): f=:*/@:>:@i. Python (27 characters): f = lambda x : 0 ** x or x * f ( x - 1 ) By the way, the shortest Java solution is 85 characters long&#94;&#94;.","tags":"Code","title":"Code golf"},{"url":"https://martin-thoma.com/crash-course-world-history/","text":"#32: Coal, Steam, and The Industrial Revolution A list Here is the YouTube Playlist : #1: The Agricultural Revolution #2: Indus Valley Civilization - Wikipedia #3: Mesopotamia #4: Ancient Egypt #5: The Persians & Greeks #6: Buddha and Ashoka #7: â€Ž2,000 Years of Chinese History! The Mandate of Heaven and Confucius #8: Alexander the Great and the Situation ... the Great? #9: The Silk Road and Ancient Trade #10: The Roman Empire. Or Republic. Or...Which Was It? #11: Christianity from Judaism to the Constantine #12: Fall of The Roman Empire...in the 15th Century #13: Islam, the Quran, and the Five Pillars All Without a Flamewar #14: The Dark Ages...How Dark Were They, Really? #15: The Crusades - Pilgrimage or Holy War? #16: Mansa Musa and Islam in Africa #17: Wait For It...The Mongols! #18: International Commerce, Snorkeling Camels, and The Indian Ocean Trade #19: Venice and the Ottoman Empire #20: Russia, the Kievan Rus, and the Mongols #21: Columbus, de Gama, and Zheng He! 15th Century Mariners #22: The Renaissance: Was it a Thing? #23: The Columbian Exchange #24: The Atlantic Slave Trade #25: The Spanish Empire, Silver, & Runaway Inflation #26: The Seven Years War #27: The Amazing Life and Strange Death of Captain Cook #28: Tea, Taxes, and The American Revolution #29: The French Revolution #30: Haitian Revolutions #31: Latin American Revolutions #32: Coal, Steam, and The Industrial Revolution #33: Capitalism and Socialism #34: Samurai, Daimyo, Matthew Perry, and Nationalism #35: Imperialism #36: Archdukes, Cynicism, and World War I","tags":"The Web","title":"Crash Course: World History"},{"url":"https://martin-thoma.com/aufgaben-zur-integralrechnung/","text":"Hier sind ein paar schÃ¶ne Aufgaben und ausfÃ¼hrliche LÃ¶sungsfindungsbeschreibungen zur Integralrechnung. Diesen Artikel werde ich ergÃ¤nzen, wenn ich weitere schÃ¶ne Aufgaben finde. Aufgabe 1 Aufgabenstellung : Berechne das bestimmte Integral \\(\\int_1&#94;2 \\frac{\\arctan(x)}{x&#94;2} dx\\) . Wissen : Partielle Integration Integration durch Substitution Partialbruchzerlegung \\((\\arctan(x))' = \\frac{1}{1+x&#94;2}\\) \\(\\arctan(1) = \\frac{1}{4}\\) Rechnung : Partielle Integration mit: \\(f(x) = \\arctan(x) \\rightarrow f'(x) = \\frac{1}{1+x&#94;2}\\) \\(g'(x)= x&#94;{-2} \\rightarrow g(x) = -x&#94;{-1}\\) \\begin{align} \\int_1&#94;2 \\frac{\\arctan(x)}{x&#94;2} dx &= \\left [ \\arctan(x) \\cdot (- \\frac{1}{x}) \\right ]_1&#94;2 - \\int_1&#94;2 \\frac{-1}{x \\cdot (1+x&#94;2)} dx\\\\ &= - \\frac{1}{2} \\arctan(2) + \\underbrace{\\arctan(1)}_{\\frac{1}{4}} + \\int_1&#94;2 \\frac{1}{x \\cdot (1+x&#94;2)} dx \\end{align} Partialbruchzerlegung mit: \\(\\frac{A}{x} + \\frac{B}{1+x&#94;2} = \\frac{1}{x \\cdot (1+x&#94;2)}\\\\ \\Leftrightarrow A \\cdot (1+x&#94;2) + B \\cdot x = 1\\\\ \\Leftrightarrow A + Bx + Ax&#94;2 = 1\\\\ \\Rightarrow A= 1 \\land B = -x:\\\\ \\frac{1}{x} + \\frac{-x}{1+x&#94;2} = \\frac{1}{x \\cdot (1+x&#94;2)}\\) \\begin{align} \\int_1&#94;2 \\frac{\\arctan(x)}{x&#94;2} dx &= \\frac{1}{4} - \\frac{1}{2} \\arctan(2) + \\int_1&#94;2 \\frac{1}{x} dx - \\int_1&#94;2 \\frac{x}{1+x&#94;2} dx\\\\ \\end{align} Substitution mit: \\(u := 1+x&#94;2\\) \\(\\frac{du}{dx} = u' = 2x \\rightarrow dx = \\frac{du}{2x}\\) \\begin{align} \\int_1&#94;2 \\frac{\\arctan(x)}{x&#94;2} dx &= \\frac{1}{4} - \\frac{1}{2} \\arctan(2) + \\left [ \\log x \\right ]_1&#94;2 - \\int_2&#94;5 \\frac{1}{2u} du\\\\ &= \\frac{1}{4} - \\frac{1}{2} \\arctan(2) + \\log 2 - \\frac{1}{2} \\int_2&#94;5 x dx\\\\ &= \\frac{1}{4} - \\frac{1}{2} \\arctan(2) + \\log 2 - \\frac{1}{2} \\left [ \\log(x) \\right ]_2&#94;5\\\\ &= \\frac{1}{4} - \\frac{1}{2} \\arctan(2) + \\log 2 - \\frac{1}{2} \\log 5 + \\frac{1}{2} \\log 2\\\\ &= \\frac{1}{4} - \\frac{1}{2} \\arctan(2) + \\frac{3}{2} \\log 2 - \\frac{1}{2} \\log 5\\\\ &= \\frac{1}{2} \\cdot \\left (\\frac{1}{2} - \\arctan(2) + 3 \\log 2 - \\log 5 \\right ) \\end{align} Kontrolle : Wolfram|Alpha Aufgabe 2 Diese Aufgabe war in der Analysis I-Klausur vom Herbst 2006 am KIT. Aufgabenstellung : Berechne das bestimmte Integral \\(\\displaystyle \\int_0&#94;1 \\frac{1}{(\\sqrt[3]{x}+2) \\cdot (\\sqrt[3]{x}+1)} dx\\) . Wissen : Integration durch Substitution Partialbruchzerlegung Logarithmusgesetze Rechnung : Kommt vielleicht spÃ¤ter noch.","tags":"German posts","title":"Aufgaben zur Integralrechnung"},{"url":"https://martin-thoma.com/integration-durch-substitution/","text":"Integration durch Substitution ist eine elementare Methode zum finden von Stammfunktionen von Integralen bzw. zum berechnen von Integralen. Unbestimmte Integrale Beispiel 1 \\(\\int e&#94;{2x} dx = ?\\) Substituiere \\(u = 2x\\) und \\(u'(x) = \\frac{du}{dx} = 2 \\Rightarrow dx = \\frac{du}{2}\\) Also: \\begin{align} \\int e&#94;{2x} dx &\\stackrel{sub}{=}\\\\ &= \\int e&#94;u \\frac{du}{2}\\\\ &= \\int \\frac{1}{2} e&#94;u du\\\\ &= \\frac{1}{2} \\int e&#94;u du\\\\ &= \\frac{1}{2} \\int e&#94;u du\\\\ &= \\frac{1}{2} e&#94;u + C \\\\ &\\stackrel{resub}{=} \\frac{1}{2} e&#94;{2x} + C \\end{align} Beispiel 2 \\(\\int (x-1)&#94;2 dx = ?\\) Substituiere \\(u = x-1\\) und \\(u'(x) = \\frac{ \\;\\mathrm{d}u}{dx} 1 \\Rightarrow dx = \\;\\mathrm{d}u\\) Also: \\begin{align} \\int (x-1)&#94;2 dx &\\stackrel{sub}{=}\\\\ &= \\int u&#94;2 \\;\\mathrm{d}u\\\\ &= \\frac{1}{3} u&#94;3 + C &\\stackrel{resub}{=} \\frac{1}{3} (x-1)&#94;3 + C \\end{align} Bestimmte Integrale Bei bestimmten Integralen muss man die Grenzen auch ersetzen. Beispiel 1 Dieses Beispiel stammt aus der Klausur â€žAnalysis I\" vom Herbst 2010. Berechne \\(\\int_1&#94;4 e&#94;{\\sqrt{x}} dx\\) . Substituiere: \\begin{align} u &= \\sqrt x\\\\ \\frac{\\;\\mathrm{d}u}{dx} &= u' = \\frac{1}{2\\sqrt{x}}\\\\ \\Leftrightarrow dx &= 2 \\sqrt{x} \\;\\mathrm{d}u = 2 u \\;\\mathrm{d}u \\end{align} . Es gilt: \\(\\int_1&#94;4 e&#94;{\\sqrt{x}} dx = \\int_1&#94;2 e&#94;u 2 u \\;\\mathrm{d}u = 2 \\int_1&#94;2 u \\cdot e&#94;u \\;\\mathrm{d}u\\) . Nun wird eine partielle Integration durchgefÃ¼hrt mit \\(f'(u)=e&#94;u\\) und \\(g(u)=u\\) : \\begin{align} 2 \\int_1&#94;2 u \\cdot e&#94;u \\;\\mathrm{d}u &= 2 ([e&#94;u \\cdot u]_1&#94;2 - \\int_1&#94;2 e&#94;u du) \\\\ &= 2((e&#94;2 \\cdot 2 - e) - [e&#94;u]_1&#94;2)\\\\ &= 2 \\cdot (2e&#94;2 -e - (e&#94;2 - e)) \\\\ &= 2 \\cdot e&#94;2 \\end{align}","tags":"German posts","title":"Integration durch Substitution"},{"url":"https://martin-thoma.com/partielle-integration/","text":"Die partielle Integration bietet eine schÃ¶ne MÃ¶glichkeit, Stammfunktionen von Integralen zu bestimmen. Dazu muss man folgende Regel kÃ¶nnen: Seien \\(f, g\\) stetig differenzierbare Funktionen. \\(\\displaystyle \\int_a&#94;b f'(x)\\cdot g(x)\\,\\mathrm{d}x = \\left [f(x)\\cdot g(x) \\right ]_{a}&#94;{b} - \\int_a&#94;b f(x)\\cdot g'(x)\\,\\mathrm{d}x\\) . Beispiel Folgendes Beispiel aus Wikipedia zeigt, wie man das geschickt nutzen kann: Aufgabe : Berechne \\(\\int \\sin(x) \\cdot \\cos(x) \\,\\mathrm{d}x\\) LÃ¶sung : Es sei \\(f(x) = \\cos(x)\\) und \\(g'(x)= \\sin(x)\\) . Es gilt: \\(f'(x) = - \\sin(x)\\) und \\(g(x)= - \\cos(x)\\) . Durch partielle Integration erhÃ¤lt man: $\\int \\sin(x) \\cdot \\cos(x) \\,\\mathrm{d}x = -\\cos&#94;2(x) - \\int \\sin(x) \\cdot \\cos(x) \\,\\mathrm{d}x. $ Addiert man auf beiden Seiten der Gleichung das Ausgangsintegral, ergibt sich: \\begin{align} 2 \\int \\sin(x) \\cdot \\cos(x) \\,\\mathrm{d}x &= - \\cos&#94;2(x)\\\\ \\Leftrightarrow \\int \\sin(x) \\cdot \\cos(x) \\,\\mathrm{d}x &= -\\tfrac12\\cos&#94;2(x) \\end{align}","tags":"German posts","title":"Partielle Integration"},{"url":"https://martin-thoma.com/konvergenz-von-reihen/","text":"Die folgenden Definitionen sind wortwÃ¶rtlich aus dem inoffiziellem Skript fÃ¼r Analysis I bei Herrn Dr. Schmoeger Ã¼bernommen worden. Dreiecksungleichung Ist $\\sum_{n=1}&#94;{\\infty}a_n$ absolut konvergent, so ist $\\sum_{n=1}&#94;{\\infty}a_n$ konvergent und es gilt: $\\left | \\sum_{n=1}&#94;{\\infty}a_n \\right | \\leq \\sum_{n=1}&#94;{\\infty} |a_n|$ Leibniz-Kriterium Sei $(a_n)_{n \\in \\mathbb{N}}$ eine monoton fallende, reelle Nullfolge. Dann konvergiert die alternierende Reihe $s = \\sum_{n=0}&#94;\\infty (-1)&#94;n a_n$. Wurzelkriterium Sei $(a_n)$ eine Folge und $\\alpha := \\lim \\sup \\sqrt[n]{|a_n|}$. $\\alpha < 1 \\Rightarrow \\sum_{n=1}&#94;{\\infty} a_n$ konvergiert absolut $\\alpha > 1 \\Rightarrow \\sum_{n=1}&#94;{\\infty} a_n$ divergiert $\\alpha = 1 \\Rightarrow$ keine Aussage Ã¼ber die Konvergenz von $\\sum_{n=1}&#94;{\\infty} a_n$ mÃ¶glich Majorantenkriterium Gilt $|a_n| \\leq b_n ~\\text{ffa } n \\in \\mathbb{N}$ und ist $\\sum_{n=1}&#94;{\\infty} b_n$ konvergent, so gilt: $\\sum_{n=1}&#94;{\\infty} a_n$ ist absolut konvergent. Minorantenkriterium Gilt $a_n \\geq b_n \\geq 0 ~\\text{ffa } n \\in \\mathbb{N}$ und ist $\\sum_{n=1}&#94;{\\infty} b_n$ divergent, so gilt: $\\sum_{n=1}&#94;{\\infty} a_n$ ist divergent. Quotientenkriterium Sei $(a_n)$ eine Folge in $\\mathbb{R}$ und $a_n \\ne 0 \\text{ ffa } \\mathbb{N}$. $\\alpha_n := \\frac{a_{n+1}}{a_n}$ (ffa $n \\in \\mathbb{N}$). Ist $|\\alpha_n| \\ge 1 \\text{ ffa } n \\in \\mathbb{N} \\Rightarrow \\sum a_n$ ist divergent. Es sei $(\\alpha_n)$ beschrÃ¤nkt, $\\beta := \\liminf |\\alpha_n|$ und $\\alpha := \\limsup |\\alpha_n|$. Ist $\\beta > 1 \\Rightarrow \\sum a_n$ ist divergent. Ist $\\alpha < 1 \\Rightarrow \\sum a_n$ ist absolut konvergent. Ist $\\alpha = \\beta = 1$, so ist keine allgemeine Aussage mÃ¶glich.","tags":"German posts","title":"Konvergenz von Reihen"},{"url":"https://martin-thoma.com/neil-degrasse-tyson/","text":"Neil deGrasse Tyson Neil deGrasse Tyson is an American astrophysicist and science communicator. He is currently the Frederick P. Rose Director of the Hayden Planetarium at the Rose Center for Earth and Space and a research associate in the department of astrophysics at the American Museum of Natural History. And he gives hilarious talks and interviews. Death By Black Hole Death By Giant Meteor Apophis is a near-Earth asteroid that caused a brief period of concern in December 2004 because initial observations indicated a small probability (up to 2.7%) that it would strike the Earth in 2029. How to Deflect a Killer Asteroid Earth Is Bad for Life My Man, Sir Isaac Newton","tags":"Cyberculture","title":"Neil deGrasse Tyson"},{"url":"https://martin-thoma.com/jordansche-normalform-4x4-matrizen/","text":"Hier sind \\begin{align} \\dim \\text{Eig}(-1) &= \\dim \\text{Kern}(A +1 \\cdot I) \\\\ &= \\dim \\text{Kern} \\begin{pmatrix} 2 & 2 & 47 & 11\\\\ 3 & 3 & 8 & 15\\\\ 0 & 0 & 4 & 1\\\\ 0 & 0 & 8 & 2 \\end{pmatrix}\\\\ &= \\dim \\text{Kern} \\begin{pmatrix} 1 & 1 & 1.5 & 0\\\\ 1 & 1 & -3 & 13\\\\ 0 & 0 & 1 & \\frac{1}{4}\\\\ 0 & 0 & 0 & 0 \\end{pmatrix}\\\\ &= \\dim \\text{Kern} \\begin{pmatrix} 1 & 1 & 1.5 & 0\\\\ 0 & 0 & -4.5 & 13\\\\ 0 & 0 & 1 & \\frac{1}{4}\\\\ 0 & 0 & 0 & 0 \\end{pmatrix}\\\\ &= \\dim \\text{Kern} \\begin{pmatrix} 1 & 1 & 1.5 & 0\\\\ 0 & 0 & 0 & 14 \\frac{1}{8}\\\\ 0 & 0 & 1 & \\frac{1}{4}\\\\ 0 & 0 & 0 & 0 \\end{pmatrix}\\\\ &= \\dim \\text{Kern} \\begin{pmatrix} 1 & 1 & 0 & 0\\\\ 0 & 0 & 0 & 0\\\\ 0 & 0 & 1 & 0\\\\ 0 & 0 & 0 & 1 \\end{pmatrix} = \\dim \\left [ \\begin{pmatrix}1\\\\-1\\\\0\\\\0 \\end{pmatrix}\\right ]\\\\ &= 1 \\end{align} Es gibt im Jordanblock zu \\begin{align} \\dim \\text{Eig}(1) &= \\dim \\text{Kern}(A-E)\\\\ &= \\dim \\text{Kern }\\begin{pmatrix} -2 & -2 & 2 & 2\\\\ 2 & -1 & 1 & 1\\\\ 2 & 1 & -1 & -1\\\\ 0 & -2 & 2 & 0 \\end{pmatrix}\\\\ &= \\dim \\text{Kern }\\begin{pmatrix} 1 & 1 & -1 & -1\\\\ 0 & -3 & 3 & 3\\\\ 0 & -1 & 1 & 1\\\\ 0 & 1 & -1 & 0 \\end{pmatrix}\\\\ &= \\dim \\text{Kern }\\begin{pmatrix} 1 & 0 & 0 & -1\\\\ 0 & 1 & -1 & 0\\\\ 0 & 0 & 0 & 0\\\\ 0 & 0 & 0 & 1 \\end{pmatrix} \\\\ &= \\dim \\left [\\begin{pmatrix}0\\\\1\\\\1\\\\0\\end{pmatrix} \\right ] = 1 \\end{align}J_B = \\begin{pmatrix} -1 & 0 & 0 & 0\\\\ 0 & -1 & 0 & 0\\\\ 0 & 0 & 1 & 1\\\\ 0 & 0 & 0 & 1 \\end{pmatrix}\\begin{align} K_2(1) &= \\text{Kern}(\\Omega(1)&#94;2) \\\\ &= \\text{Kern }\\begin{pmatrix} -2 & -2 & 2 & 2\\\\ 2 & -1 & 1 & 1\\\\ 2 & 1 & -1 & -1\\\\ 0 & -2 & 2 & 0 \\end{pmatrix}&#94;2 \\\\ &= \\text{Kern }\\begin{pmatrix} 4 & 4 & -4 & -4\\\\ -4 & 0 & 0 & 4\\\\ -4 & -4 & 4 & 4\\\\ 0 & 4 & -4 & 0 \\end{pmatrix}\\\\ &= \\text{Kern }\\begin{pmatrix}\\\\ 1 & 0 & 0 & -1\\\\ 0 & 1 & -1 & 0\\\\ 0 & 0 & 0 & 0\\\\ 0 & 0 & 0 & 0 \\end{pmatrix} \\\\ &= \\left [ \\begin{pmatrix}0\\\\1\\\\1\\\\0\\end{pmatrix}, \\begin{pmatrix}1\\\\0\\\\0\\\\1\\end{pmatrix} \\right ] \\end{align}K_2(1)\\begin{align} \\Omega &= \\begin{pmatrix} 0 & 0 & -1 & -1\\\\ -1 & -1 & 0 & 0\\\\ 0 & 0 & 1 & 1\\\\ 1 & 1 & 0 & 0 \\end{pmatrix}\\\\ \\Omega&#94;2 &= \\begin{pmatrix} -1 & -1 & -1 & -1\\\\ 1 & 1 & 1 & 1\\\\ 1 & 1 & 1 & 1\\\\ -1 & -1 & -1 & -1 \\end{pmatrix}\\\\ \\Omega&#94;3 &= \\begin{pmatrix} 0 & 0 & 0 & 0\\\\ 0 & 0 & 0 & 0\\\\ 0 & 0 & 0 & 0\\\\ 0 & 0 & 0 & 0 \\end{pmatrix} \\end{align}. \\begin{align} \\text{Eig}(1) &= K_1(1) = \\text{Kern}(\\Omega) \\\\ &= \\text{Kern} \\begin{pmatrix} 1 & 1 & 0 & 0\\\\ 0 & 0 & 0 & 0\\\\ 0 & 0 & 1 & 1\\\\ 0 & 0 & 0 & 0 \\end{pmatrix}\\\\ &= \\left [ \\begin{pmatrix}1\\\\-1\\\\0\\\\0\\end{pmatrix}, \\begin{pmatrix}0\\\\0\\\\1\\\\-1\\end{pmatrix} \\right ] \\end{align} \\begin{align} K_2(1) &= \\text{Kern}(\\Omega&#94;2) \\\\ &= \\text{Kern} \\begin{pmatrix} 1 & 1 & 1 & 1\\\\ 0 & 0 & 0 & 0\\\\ 0 & 0 & 0 & 0\\\\ 0 & 0 & 0 & 0 \\end{pmatrix}\\\\ &= \\left [ \\begin{pmatrix}1\\\\-1\\\\0\\\\0\\end{pmatrix}, \\begin{pmatrix}1\\\\0\\\\-1\\\\0\\end{pmatrix}, \\begin{pmatrix}1\\\\0\\\\0\\\\-1\\end{pmatrix} \\right ]\\\\ K_3(1) &= \\text{Kern}(\\Omega&#94;3) = \\mathbb{R}&#94;4\\\\ \\end{align}K_3(1) = \\mathbb{R}&#94;4$ ist das grÃ¶ÃŸte JordankÃ¤stchen von der GrÃ¶ÃŸe 3. Damit ergibt sich folgende Jordannormalform: $J = \\begin{pmatrix} 1 & 0 & 0 & 0\\\\ 0 & 1 & 1 & 0\\\\ 0 & 0 & 1 & 1\\\\ 0 & 0 & 0 & 1 \\end{pmatrix}$ Basiswechselmatrix bestimmen FÃ¼r jedes JordankÃ¤stchen der LÃ¤nge $i$ muss nun 1 Vektor gewÃ¤hlt werden und $i-1$ Vektoren mÃ¼ssen bestimmt werden. DafÃ¼r muss $\\Omega(\\lambda) := C - \\lambda \\cdot E$ bestimmt werden. Eigenwert 1: KÃ¤stchengrÃ¶ÃŸe 3 $b_1 \\in K_3(1) \\land b_1 \\notin K_2(1) \\Rightarrow b_1 \\in \\left [ \\begin{pmatrix}1\\\\0\\\\0\\\\0\\end{pmatrix} \\right ]$. WÃ¤hle $b_1 = \\begin{pmatrix}1\\\\0\\\\0\\\\0\\end{pmatrix}$. $b_2 = \\Omega(b_1) = \\begin{pmatrix}0\\\\-1\\\\0\\\\1\\end{pmatrix}$. $b_3 = \\Omega&#94;2(b_1) = \\Omega(b_2)= \\begin{pmatrix}-1\\\\1\\\\1\\\\-1\\end{pmatrix}$ KÃ¤stchengrÃ¶ÃŸe 1 $b_4 = \\begin{pmatrix}1\\\\-1\\\\0\\\\0\\end{pmatrix}$ Das 1-er KÃ¤stchen soll zuerst kommen, also muss $b_4$ zuerst in die Basiswechselmatrix. Unsere gesuchte Matrix $S$ fÃ¼r die oben angegebene JNF ist also: $S = \\begin{pmatrix} b_4 & b_3 & b_2 & b_1 \\end{pmatrix} = \\begin{pmatrix} 1 & -1 & 0 & 1\\\\ -1 & 1 & -1 & 0\\\\ 0 & 1 & 0 & 0\\\\ 0 & -1 & 1 & 0 \\end{pmatrix} $ Nun sollte $J = S&#94;{-1} \\cdot C \\cdot S$ gelten. Also, Schritt fÃ¼r Schritt: \\begin{align} S&#94;{-1} \\cdot C \\cdot S &= \\begin{pmatrix} 0 & -1 & 0 & -1\\\\ 0 & 0 & 1 & 0\\\\ 0 & 0 & 1 & 1\\\\ 1 & 1 & 1 & 1 \\end{pmatrix} \\cdot \\begin{pmatrix} 1 & 0 & -1 & -1\\\\ -1 & 0 & 0 & 0\\\\ 0 & 0 & 2 & 1\\\\ 1 & 1 & 0 & 1 \\end{pmatrix} \\cdot \\begin{pmatrix} 1 & -1 & 0 & 1\\\\ -1 & 1 & -1 & 0\\\\ 0 & 1 & 0 & 0\\\\ 0 & -1 & 1 & 0 \\end{pmatrix}\\\\ &= \\begin{pmatrix} 0 & -1 & 0 & -1\\\\ 0 & 0 & 2 & 1\\\\ 1 & 1 & 2 & 2\\\\ 1 & 1 & 1 & 1 \\end{pmatrix} \\cdot \\begin{pmatrix} 1 & -1 & 0 & 1\\\\ -1 & 1 & -1 & 0\\\\ 0 & 1 & 0 & 0\\\\ 0 & -1 & 1 & 0 \\end{pmatrix} \\\\ &= \\begin{pmatrix} 1 & 0 & 0 & 0\\\\ 0 & 1 & 1 & 0\\\\ 0 & 0 & 1 & 1\\\\ 0 & 0 & 0 & 1 \\end{pmatrix} \\end{align} Programmierung Hier habe ich mal fÃ¼r Leute, die kein Python haben, als Kommentar das Ergebnis prÃ¤sentiert. Ich denke damit ist klar, welchen Einfluss die Reihenfolge der Basisvektoren hat. \u0002wzxhzdk:0\u0003","tags":"German posts","title":"Jordansche Normalform: 4x4 Matrizen"},{"url":"https://martin-thoma.com/berechnung-der-euklidischen-normalform/","text":"Die euklidische Normalform einer linearen Isometrie, manchmal auch lineare Normalform gennant, hat folgende Gestalt: Euklidische Normalform Bei einer \\(n \\times n\\) -Matrix gilt also folgende Gleichung: \\(n = p + q + 2r\\) Bestimmung der Normalform Sei \\(\\Phi\\) eine lineare Isometrie eines euklidischen Vektorraumes. Dann habe \\(\\Phi\\) die Abbildungsmatrix \\(A\\) . Sei \\(B := A + A&#94;T\\) . Wenn man die euklidische Normalform bilden will, bestimmt man zuerst das charakteristische Polynom von \\(B\\) . Die Nullstellen davon sind die Eigenwerte. Die algebraische Vielfachheit des Eigenwertes 2 von \\(B\\) (die Potenz im charakteristischen Polynom) gibt die Anzahl der 1er an, genauso gibt die Vielfachheit des Eigenwertes -2 die Anzahl der -1er an. Die restlichen Eigenwerte \\(\\lambda_1, \\dots, \\lambda_r\\) geben die DrehkÃ¤stchen an. Es gilt: \\(\\cos \\omega = \\frac{\\lambda}{2}\\) \\(\\sin \\omega = \\sqrt{1 - \\frac{\\lambda&#94;2}{4}}\\) Mit diesen Angaben kann man direkt die euklidische Normalform angeben. Bestimmung der Transformationsmatrix EigenrÃ¤ume bestimmen Die EigenrÃ¤ume berechnet man wie gewohnt: \\(\\text{Eig}(\\lambda_i) = \\text{Kern}(B- \\lambda_i \\cdot E)\\) ONB bestimmen Nun wÃ¤hlt man fÃ¼r jeden Eigenraum eine Basis Orthonormalbasis aus Eigenvektoren. Das kann man mit dem Gram-Schmidtsches Orthogonalisierungsverfahren machen, also: WÃ¤hle ein beliebiges \\(w_1 \\in \\text{Eig}(\\lambda_i)\\) . $$w_j = v_j - \\sum_{i=1}&#94;{j-1} \\frac{\\langle v_j, w_i \\rangle}{\\langle w_i, w_i \\rangle} \\cdot w_i$$ Quellen Skript von Prof. Dr. Leuzinger, S. 228 ff. Klausur â€žLineare Algebra und analytische Geometrie\" vom FrÃ¼hjahr 2007, Aufgabe II.4","tags":"German posts","title":"Berechnung der euklidischen Normalform"},{"url":"https://martin-thoma.com/how-to-check-if-a-point-is-inside-a-rectangle/","text":"A rectangle I've just found this interesting question on StackExchange : If you have a rectangle ABCD and point P. Is P inside ABCD? The idea The idea how to solve this problem is simply beautiful. If the point is in the rectangle, it divides it into four triangles: Divided rectangle If P is not inside of ABCD, you end up with somethink like this: Point is outside of rectangle You might note that the area of the four triangles in is bigger than the area of the rectangle. So if the area is bigger, you know that the point is outside of the rectangle. Formulae If you know the coordinates of the points, you can calculate the area of the rectangle like this: \\(A_\\text{rectangle} = \\frac{1}{2} \\left| (y_{A}-y_{C})\\cdot(x_{D}-x_{B}) + (y_{B}-y_{D})\\cdot(x_{A}-x_{C})\\right|\\) The area of a triangle is: \\(A_\\text{triangle} = \\frac{1}{2} (x_1(y_2-y_3) + x_2(y_3-y_1) + x_3(y_1-y_2))\\) Python Please look at Jans comment. There is an error in my Python code, but I don't have the time to correct it. def isPinRectangle ( r , P ): \"\"\" r: A list of four points, each has a x- and a y- coordinate P: A point \"\"\" areaRectangle = 0.5 * abs ( # y_A y_C x_D x_B ( r [ 0 ][ 1 ] - r [ 2 ][ 1 ]) * ( r [ 3 ][ 0 ] - r [ 1 ][ 0 ]) # y_B y_D x_A x_C + ( r [ 1 ][ 1 ] - r [ 3 ][ 1 ]) * ( r [ 0 ][ 0 ] - r [ 2 ][ 0 ]) ) ABP = 0.5 * ( r [ 0 ][ 0 ] * ( r [ 1 ][ 1 ] - r [ 2 ][ 1 ]) + r [ 1 ][ 0 ] * ( r [ 2 ][ 1 ] - r [ 0 ][ 1 ]) + r [ 2 ][ 0 ] * ( r [ 0 ][ 1 ] - r [ 1 ][ 1 ]) ) BCP = 0.5 * ( r [ 1 ][ 0 ] * ( r [ 2 ][ 1 ] - r [ 3 ][ 1 ]) + r [ 2 ][ 0 ] * ( r [ 3 ][ 1 ] - r [ 1 ][ 1 ]) + r [ 3 ][ 0 ] * ( r [ 1 ][ 1 ] - r [ 2 ][ 1 ]) ) CDP = 0.5 * ( r [ 2 ][ 0 ] * ( r [ 3 ][ 1 ] - r [ 0 ][ 1 ]) + r [ 3 ][ 0 ] * ( r [ 0 ][ 1 ] - r [ 2 ][ 1 ]) + r [ 0 ][ 0 ] * ( r [ 2 ][ 1 ] - r [ 3 ][ 1 ]) ) DAP = 0.5 * ( r [ 3 ][ 0 ] * ( r [ 0 ][ 1 ] - r [ 1 ][ 1 ]) + r [ 0 ][ 0 ] * ( r [ 1 ][ 1 ] - r [ 3 ][ 1 ]) + r [ 1 ][ 0 ] * ( r [ 3 ][ 1 ] - r [ 0 ][ 1 ]) ) return areaRectangle == ( ABP + BCP + CDP + DAP ) Triangle The same idea can easily be adopted to triangles: #!/usr/bin/env python # -*- coding: utf-8 -*- class Point : \"\"\"Represents a two dimensional point.\"\"\" def __init__ ( self , x , y ): self . x = x self . y = y def __get__ ( self , obj , cls = None ): return obj def __repr__ ( self ): return \"P( %.2lf | %.2lf )\" % ( self . x , self . y ) def __str__ ( self ): return repr ( self ) class Triangle : \"\"\"Represents a triangle in R&#94;2.\"\"\" epsilon = 0.001 def __init__ ( self , a , b , c ): assert isinstance ( a , Point ) assert isinstance ( b , Point ) assert isinstance ( c , Point ) self . a = a self . b = b self . c = c def getArea ( self ): \"\"\"Get area of this triangle. >>> Triangle(Point(0.,0.), Point(10.,0.), Point(10.,10.)).getArea() 50.0 >>> Triangle(Point(-10.,0.), Point(10.,0.), Point(10.,10.)).getArea() 100.0 \"\"\" a , b , c = self . a , self . b , self . c return abs ( a . x * ( b . y - c . y ) + b . x * ( c . y - a . y ) + c . x * ( a . y - b . y )) / 2 def isInside ( self , p ): \"\"\"Check if p is inside this triangle.\"\"\" assert isinstance ( p , Point ) currentArea = self . getArea () pab = Triangle ( p , self . a , self . b ) pac = Triangle ( p , self . a , self . c ) pbc = Triangle ( p , self . b , self . c ) newArea = pab . getArea () + pac . getArea () + pbc . getArea () return ( abs ( currentArea - newArea ) < Triangle . epsilon ) if __name__ == \"__main__\" : import doctest doctest . testmod () Credits Thank you Teon Brooks for reporting an error (I wrote \"rectangles\" instead of \"triangles\")","tags":"Code","title":"How to check if a point is inside a rectangle"},{"url":"https://martin-thoma.com/bundeswettbewerb-informatik/","text":"Logo des BwInf Die erste Runde des 31. Bundeswettbewerb Informatik (kurz: BwInf) begann heute. Das bedeutet, bis zum 03.12.2012 haben SchÃ¼ler mal wieder die Chance zu zeigen, was sie in der Informatik drauf haben. Es gibt keine verpflichtende Anmeldung, nur die Einsendung. Wenn ihr diesen Beitrag also vor dem 03.12.2012 lest, kÃ¶nnt ihr noch teilnehmen. Die offiziellen Informationen zum Wettbewerb, dessen Ablauf , die Teilnahmebedingungen und die Aufgaben gibt es auf bundeswettbewerb-informatik.de . Das Folgende ist inoffiziell; es sind meine persÃ¶nlichen Erfahrungen. Ich habe selbst ein paar mal am Bundeswettbewerb teilgenommen und bin bei meiner letzten Teilnahme Bundessieger geworden. SpÃ¤ter habe ich MusterlÃ¶sungen erstellt und an der Korrektur der Erstrunden- und Zweitrundenaufgaben teilgenommen. Ich weiÃŸ also wovon ich rede. Aufbau des Wettbewerbs Der BwInf besteht aus drei Runden, in denen algorithmische Probleme gelÃ¶st werden mÃ¼ssen. Die ersten beiden Runden werden von zu Hause erledigt. DafÃ¼r habt ihr mehr als genug Zeit - jeweils Ã¼ber einen Monat. Die dritte Runde mÃ¼sst ihr vor Ort bestehen. Diese lÃ¤uft vollkommen anders ab, aber darÃ¼ber will ich mal noch nichts berichten. (Falls ihr unbedingt einen Bericht wollt, hier ist der von Tobias ). Nur wer in der ersten Runde mindestens drei von fÃ¼nf (+ 3 Junioraufgaben) Aufgaben weitgehend richtig gelÃ¶st hat, wird zur Zweiten zugelassen. Die Aufgaben der zweiten Runde sind prinzipiell Ã¤hnlich aufgebaut, jedoch deutlich schwerer zu lÃ¶sen. Immer wieder sind \\(\\mathcal{NP}\\) -vollstÃ¤ndige Probleme dabei. Warum sollte man teilnehmen? Programmiert ihr gerne? Habt ihr SpaÃŸ daran, an Aufgaben zu knobeln? Denkt ihr darÃ¼ber nach, wie man bereits gelÃ¶ste Probleme noch effizienter lÃ¶sen kann? Dann ist der Bundeswettbewerb auf jeden Fall etwas fÃ¼r euch! Selbst wenn ihr nicht alle Fragen Ã¼berzeugt mit einem â€žJa\" beantworten kÃ¶nnt, kÃ¶nnte der Bundeswettbewerb euch gefallen. Probier es einfach mal aus. Einen weiteren Anreitz bieten Preise: Die Bundessieger werden soweit ich weiÃŸ immer in die Studienstiftung aufgenommen und es gibt Geldpreise. Und noch ein Schlusswort zur Motivation: Eine gute Dokumentation zu schreiben ist anstrengend. Ich hatte hÃ¤ufig bei der Dokumentation keine Lust mehr, sie noch ein weiteres mal anzusehen. Sie nochmals zu verbessern. Aber die Arbeit lohnt sich. Wenn ihr sie fertig geschrieben habt, kÃ¶nnt ihr stolz darauf sein. Wie ein Sprichwort so schÃ¶n sagt: â€žOhne FleiÃŸ kein Preis.\" Tipps zur Aufgabenbearbeitung Zur LÃ¶sungsfindung Wenn ihr ein Skript habt, dass eventuell nicht sofort, aber nach ein paar Stunden die LÃ¶sung ausgeben sollte, dann vergesst nicht, auch eine Ausgabe mit Zwischenergebnissen dafÃ¼r einzubauen! Kaum etwas ist Ã¤rgerlicher, als ein Programm, das lange lÃ¤uft und am Ende keine Ausgabe macht oder sich aufhÃ¤ngt. Doku ist wichtig Bei der Korrektur wird zuerst die Dokumentation angesehen. NatÃ¼rlich ist die LÃ¶sungsidee wichtig, aber eine negativ bewertete Dokumentation ist Ã¤rgerlich. Also lest euch bitte die Dokumentation nochmals durch und Ã¼berprÃ¼ft, ob die wichtigen LÃ¶sungsideen verstÃ¤ndlich erklÃ¤rt wurden. Ich denke das ist wohl der einzige Aspekt, wo euch andere helfen kÃ¶nnen. Gerade Leute ohne Programmierkenntnis sollten eure LÃ¶sungsidee verstehen kÃ¶nnen. Mein Vater (der nicht programmieren kann) hat hÃ¤ufig meine Einseundungen nochmals auf Rechtschreib- und Grammatikfehler sowie auf fehlende ZusammenhÃ¤nge Ã¼berprÃ¼ft. Er konnte zwar nicht sagen, was dort nicht stimmt, hat aber hÃ¤ufig ... naja, sagen wir mal Stellen gefunden, bei denen meine Deutschlehrer wohl Zahnschmerzen hÃ¤tten (trifft wohl auch auf diesen Blog zu ;-) ) Also: Schreibt die Doku frÃ¼h. Ich habe sie geschrieben, wÃ¤hrend ich programmiert habe. Dann setzt irgendwann eine Version auf, von der ihr denkt, dass sie fertig ist. Wartet so ein, zwei Tage und lest sie euch nochmals durch (es ist wirklich erstaunlich, was man dann sieht). Dann sucht euch jemanden, der die Aufgabenstellung nicht kennt und nicht programmieren kann. Der Korrekturleser sollte das Deutsche natÃ¼rlich gut beherrschen. So ein Korrekturleser streicht nur mangelhafte Stellen in eurer endgÃ¼ltigen Version an, macht aber keine VerbesserungsvorschlÃ¤ge. Die mÃ¼sst ihr euch selbst Ã¼berlegen. Und dann ist man wirklich froh, wenn man das blÃ¶de Ding los ist. Eine Randbemerkung dazu noch: Ich habe mal einen kurzen Job als Programmierer fÃ¼r ein grÃ¶ÃŸeres Projekt Ã¼bernommen. Dabei gab es Ã¼ber 2GB, die grÃ¶ÃŸtenteils C++-Code und ein paar Testdaten waren (rechnet es aus, das ist VERDAMMT viel Code!). Die hatten keine Dokumentation! Ich habe bestimmt eine Woche nur damit verbracht, mich mehr oder weniger wahllos durch wirre Quelltexte zu klicken, weil ich noch nicht einmal wusse, wo ich genau anfangen soll. Ich glaube den Zweck einer Dokumentation versteht man erst nach einem solchem Erlebnis. Beispiele Die Beispiele werden leider hin und wieder vergessen und sind oft nicht aussagekrÃ¤ftig. Ãœberlegt euch: Welche Eingaben sind Standard-FÃ¤lle? Welche Eingaben sind SonderfÃ¤lle? Diese sollten unbedingt als Beispiele gezeigt werden, da es oft nicht klar ist, ob jemand in einer Einsendung daran gedacht hat. Mit SonderfÃ¤llen sind nicht falsche Eingaben gemeint - das ist fÃ¼r den Bundeswettbewerb unwichtig - sondern korrekt formatierte Eingaben, die etwas ungewÃ¶hnliches / schweres aufweisen. Die Beispiele sollen euch helfen, Probleme zu entdecken. Eventuell funktioniert eure Implementierung nicht so, wie ihr es euch vorstellt. Das kÃ¶nnt ihr damit feststellen. In diesem Zusammenhang solltet ihr euch das Konzept der testgetriebenen Entwicklung ansehen. Dabei schreibt man zuerst alle wichtigen TestfÃ¤lle, bevor man Ã¼berhaupt eine Zeile produktiven Codes schreibt. Beispielsweise fÃ¼r die Aufgabe â€žVerben\" wÃ¼rde ich heute so eine Herangehensweise wÃ¤hlen. Ach ja: Es kann sein, dass ihr ein Problem feststellt, dieses aber nicht beheben kÃ¶nnt. Dann solltet ihr es beschreiben. Es wird sowieso entdeckt. Man kann eurer LÃ¶sungsidee erkennen, welche schwÃ¤chen die Implementierung hat. Versionskontrolle Ich habe leider erst nach dem Bundeswettbewerb meine ersten Erfahrungen mit Versionskontrollsystemen gesammelt. Immer wenn ich eine Idee hatte, wie man das Problem anders angehen kÃ¶nnte, habe ich eine Kopie der aktuellen Version erstellt und auf der Kopie weiter gearbeitet. Diese LÃ¶sung ist jedoch in vielerlei Hinsicht einem Versionskontrollsystem - SVN und Git sind die bekanntesten - unterlegen. Man kann nicht so leicht eine Sicherung durchfÃ¼hren. Es ist unÃ¼bersichtlich, die wiederherstellung bei vielen Dateien ist schwer und man kann sich nicht so leicht die Unterschiede von verschiedenen Versionen anzeigen lassen. Zum vergleich: Hier kann man sich den Unterschied zweier Versionen auf code.google.com ansehen. Mit meld bekommt man Ã¤hnlich gute Ergebnisse auch auf dem eigenem Rechner. LaTeX LaTeX ist toll - aber keine Pflicht. Es werden leider relativ wenige Dokumentationen mit LaTeX erstellt. Dabei bietet LaTeX fÃ¼r den BwInf ein paar Vorteile: Das Ergebnis kann sich sehen lassen, LaTeX sieht einfach schÃ¶n aus. Man kann die Doku in die Versionskontrolle stecken. Man kann Quelltext automatisch einbinden lassen (siehe dazu ein Blogpost von mir). Und so bekommt man LaTeX: How to install the latest LaTeX Version . AuÃŸerdem ist die Kombination LaTeX+Versionskontrolle toll â˜º Die CD Ich weiÃŸ leider nicht, warum keine Online-Abgabe mÃ¶glich ist. Vielleicht, weil es einfacher ist. Eventuell aus SicherheitsgrÃ¼nden. Wenn man Papier und eine CD in der Hand hat, kann es nicht passieren, dass eine Runde im schlimmsten Szenario komplett ausfallen muss, weil der Server abgeraucht ist. Egal wie, ihr mÃ¼sst die CD erstellen. Dazu hÃ¤tte ich - aus Sicht eines Korrektors - ein paar Bitten: Die CD hat Ã¼ber 600 MB. Das ist deutlich mehr, als ihr braucht. Also schreibt doch bitte auch die Beispiele des BwInf darauf, sowie eine PDF-Datei eurer Doku. Das erleichtert die Korrektur ungemein, da man so die Doku durchsuchen kann. ÃœberprÃ¼ft, ob die CD auch wirklich gebrannt wurde, abgeschlossen wurde und sie lesbar ist. Wenn eure Dokumentation schlecht ist und die CD nicht lesbar ist, kann eventuell eine gute LÃ¶sungsidee schlecht bewertet werden. edit: Hier habe ich eine RÃ¼ckmeldung von Herrn Dr. Pohl erhalten. Es geht nicht um CD vs. Online-Abgabe sondern um CD und â€žgedruckte Dokumentation und CD\" vs. â€žOnline-Abgabe\". Die Korrektur von LÃ¶sungsideen auf einem Blatt Papier ist immer noch die einfachste und fÃ¼r den Leser die angenehmste. Ich schreibe als Korrektor hÃ¤ufig Anmerkungen in eure Dokumentation, damit der Zweitkorrektor leichter nachvollziehen kann, was ich mangelhaft oder auch sehr gut gefunden habe. AuÃŸerdem schreibe ich manchmal rein, was der Einsender gemeint hat (falls die Doku nicht so toll war und es nicht direkt ersichtlich ist). AuÃŸerdem ist es mit CDs einfacher, die Infrastruktur fÃ¼r die Korrektur aufzubauen. An den Bewertungswochenenden werden so ca. 30 frisch aufgesetzte, unvernetzte PCs benutzt (es lohnt sich also nicht, Viren zu schreiben). Bei einer Online-Abgabe mÃ¼ssten diese PCs Internet haben, was leider nicht immer zur VerfÃ¼gung steht. Oder sie mÃ¼ssten lokal, z.B. auf einem NAS, sein. Das ist alles etwas umstÃ¤ndlicher als einfach eine CD zu brennen. Ihr dÃ¼rft Ã¼brigens auch SD-Karten einschicken â˜º Vielen Dank an Herrn Dr. Pohl fÃ¼r die Hinweise! Die Programmiersprache Also eine Brainfuck -Einsendung muss jetzt nicht gerade sein (obwohl ich wirklich beeindruckt wÃ¤re). Aber eine Shakespeare -Einsendung wÃ¼rde ich mal toll finden â˜º Nein, im ernst: Ihr dÃ¼rft fast alles benutzen. Ich selbst kann Python, PHP, Java, C++ und C gut genug um jede Einsendung verstehen zu kÃ¶nnen. Ich weiÃŸ, dass wir immer Leute haben die Haskel/Objective CAML und vielleicht noch ein paar weitere funktionale Sprachen kÃ¶nnen. Auch Pascal, Delphi (Object Pascal), BASIC stellen kein Problem dar. Das ist jetzt keine vollstÃ¤ndige Liste; unter den Korrektoren gibt es einige, die auch exotische Sprachen kÃ¶nnen. Aber wenn euch klar ist, dass eure Sprache exotisch ist, dann solltet ihr besondere Sprachfeatures kommentieren. Ich habe damals meine Einsendung in PHP geschrieben, spÃ¤ter in Python. Warum PHP? Naja, es gibt ein super Tutorial fÃ¼r PHP . Welche Programmiersprache wÃ¼rde ich heute nehmen? Nun, es gibt keine Programmiersprache die fÃ¼r jeden Zweck gut ist. FÃ¼r kleine Probleme - und Bundeswettbewerbsaufgaben sind zwar schwer, aber doch recht Ã¼bersichtlich - eignet sich hÃ¤ufig Python gut. Falls es in der zweiten Runde auf Geschwindigkeit ankommt, ist wohl C++ eine Sprache der Wahl. FÃ¼r spÃ¤ter empfiehlt es sich, Java zu lernen. Aber ihr mÃ¼sst keine dieser Sprachen nehmen. Das ist ja das tolle am BwInf. Es steht euch frei, das zu wÃ¤hlen, was fÃ¼r euch das beste ist. Quelltext-Kommentare Trotz Doku sind Quelltextkommentare erwÃ¼nscht. Allerdings mÃ¼ssen Standard-Strukturen (if/else,for,while, Variablendeklarationen) nicht kommentiert werden! Ãœbertreibt es nicht, aber verwendet Kommentare, wenn einem AuÃŸenstehendem nicht direkt klar sein kann, was ihr macht. Java-Programmierer sollten definitiv die standard Sun Checkstyle und JavaDoc verwenden, Python-Programmierer sollten DocStrings kennen und verwenden. FÃ¼r alle anderen Sprachen muss man halt ein GefÃ¼hl entwickeln. Wer in C wild mit Pointern um sich wirft sollte tendenziell wohl mehr Kommentare machen als jemand, der Pythons Standardbefehle nutzt. Style-Guides Es ist nicht zwingend erforderlich, dass ihr euch an sogenannte Styel-Guides haltet. Allerdings ist es bei der Bewertung - und insbesondere spÃ¤ter, wenn ihr an echten Projekten mit anderen zusammen arbeitet - sehr hilfreich, wenn ihr euch an Konventionen haltet. Hier sind ein paar: C++ : von Google Java : Google oder Oracle Python : PEP8 , Online-Checker , NumpyDoc Was sollte man lernen? Falls ihr Informatik studieren wollt oder spÃ¤ter programmieren wollt, sind SVN und GIT unverzichtbar. AuÃŸerdem werdet ihr wohl mit Java und C++ in Kontakt kommen. Am KIT wird euch beigebracht, wie ihr mit Eclipse und checkstyle umgeht. Aber es wird auch erwartet, dass ihr es nutzt. Ich vermute, dass fÃ¼r viele wissenschaftliche VerÃ¶ffentlichungen im Natur- und Ingenieurswissenschaftlichen Bereich LaTeX kaum wegzudenken ist. (Ach ja: Ihr kÃ¶nnt auch Briefe mit LaTeX schreiben und komplexe Grafiken mit LaTeX erstellen !) Website-Empfehlungen Das meiste, was ihr wissen mÃ¼sst, kÃ¶nnt ihr Ã¼ber Wikipedia lernen. Ich habe mich z.B. mal durch die Kategorie:Algorithmus geklickt. Das ist nicht sonderlich zielfÃ¼hrend und sicher nicht jedermanns Sache, aber so habe ich mir einiges beigebracht. Ob es mir viel genutzt hat, kann ich nur schwer beurteilen. Wenn ihr Interessantes rund um die praktische Informatik in kleinen Portionen lernen wollt, ist der Newsletter von StackOverflow.com empfehlenswert. Der ist zwar auf englisch, aber ich glaube das Englisch ist einfach genug. AuÃŸerdem werdet ihr im Informatik-Bereich hÃ¤ufig auf englische Literatur, Websites, Manuals oder Spezifikationen treffen. Man muss sich vielleicht mal daran gewÃ¶hnen, mit leo einiges Ãœbersetzen, aber das gibt sich schnell. Es gibt Ã¼brigens von einigen UniversitÃ¤ten Online-Vorlesungen. Ich habe mir damals eine Vorlesung vom MIT komplett angesehen (das waren damals zwei Dozenten, von denen einer Prof. John Guttag war). Dieses Semester habe ich vom Stanford Algorithms: Design and Analysis durchgearbeitet. Die stellen sogar eine PDF-Urkunde mit deinen Ergebnissen aus. Udacity bietet in der Hinsicht auch interessante Kurse. Wenn ihr generell am Knobeln SpaÃŸ habt, kann ich sogenannte â€ž Challenge Websites \" empfehlen. Die Probleme sind (grÃ¶ÃŸtenteils) schneller zu lÃ¶sen als beim Bundeswettbewerb und man muss keine Doku schreiben. Buchempfehlungen FÃ¼r die zweite Runde kann ich â€žComputers and Intractability: A Guide to the Theory of NP-Completeness\" ( Link ) empfehlen. Es wird in der zweiten Runde hÃ¤ufig (immer?) erwartet, dass man auf die KomplexitÃ¤t des Problems bzw. das Laufzeitverhalten der eigenen LÃ¶sung eingeht. Wenn man das besonders gut macht, gibt es hin und wieder Bonuspunkte. Wenn ihr dieses Buch - das ganz eindeutig dem Bereich der Theoretischen Informatik zuzuordnen ist und fÃ¼r einen SchÃ¼ler bestimmt keine leichte LektÃ¼re ist - versteht und das Wissen Ã¼bertragen kÃ¶nnt, dann kÃ¶nntet ihr hier Boni erhalten. Aber wie gesagt, das zu verstehen und auf ein konkretes Problem zu Ã¼bertragen ist nicht leicht. Deutlich einfacher ist â€žTheoretische Informatik - kurz gefasst\". Das Buch gibt eine grundlegende Einleitung und ist auf deutsch. Und, nur um es nochmals zu betonen: Das sind persÃ¶nliche Erfahrungen und teilweise Bitten von jemanden, der es korrigiert. Wenn Teilnehmer meine Tipps nicht beachten, gibt es keinen Punktabzug und es gibt auch keine Bonuspunkte, wenn ihr sie beachtet. Aber ihr erleichtert ein paar Leuten die Korrektur, ihr lernt dabei eventuell was neues (LaTeX und GIT/SVN werdet ihr im Informatik-Studium noch benÃ¶tigen) und vielleicht fallen euch Fehler oder MÃ¤ngel in eurer LÃ¶sung auf. Falls ihr Fragen habt kann ich die auch gerne beantworten. Auf Ikhaya habe ich bereits ein paar beantwortet. Siehe auch bwinf-tipps.de tobias-thierer.de","tags":"German posts","title":"Bundeswettbewerb Informatik"},{"url":"https://martin-thoma.com/nobel-prize-in-physics-2009/","text":"Did you know how the election for a Nobel Prize works? Have you ever heard of a CCD ? I guess you know fiberoptics ? I've found this clip via forschungspreisen.de , a german blog about science. See also List of Nobel laureates List of Nobel laureates by country List of Nobel laureates by university affiliation","tags":"My bits and bytes","title":"Nobel Prize in Physics 2009"},{"url":"https://martin-thoma.com/how-to-reverse-engineer-a-function/","text":"I am currently improving many articles on Wikipedia as a preparation for some math exams. And I recently started to create images with LaTeX / TikZ. Today, I've found this image in the article about the Intermediate value theorem: Pixel-image of a function from Wikipedia Get special points As a first step, you should open the image with GIMP (or any other editor of your choice) and find the pixel-coordinates of special points: Cubic function in GIMP This function has a maximum at (123 | 105) and a minimum at (172 | 218) ... well, thats not correct. Note that the axis of GIMP starts at the upper left. So the y-axis is wrong. I have cropped and flipped the image vertically. Now you can read the minimum / maximum coordinates with GIMP: Cubic function cropped and flipped vertically The local maximum is at (79 | 133) and the local minimum is at (131 | 20). Form equations A cubic function generally looks like this: \\(f(x) = a \\cdot x&#94;3 + b \\cdot x&#94;2 + c \\cdot x + d\\) You have two points, so they have to fit to this equation: (I) \\(f(79) = 133\\) (II) \\(f(131) = 20\\) The derivative has to be zero in a minimum and a maximum, so you know two more equations: (III) \\(f'(79) = 0\\) (IV) \\(f'(131) = 0\\) Four linear equations and four variables. Now we can solve those equations. Get explicit equations As a first step, we write down the equations in an explicit form. You have to know the general derivate of a cubic function: \\(f'(x) = 3 a\\cdot x&#94;2 + 2 b \\cdot x + c\\) (I) \\(493039a + 6241b+79c + d = 133\\) (II) \\(2352637a + 17689b + 131c + d = 20\\) (III) \\(18723a + 158 b + c = 0\\) (IV) \\(51483 a + 262 b + c = 0\\) Solve the equations Now you have to solve the equations. I took Wolfram|Alpha , because the numbers are really ugly. If you like to do it by hand, you have to know how to use the Gaussian algorithm . Here is the exact solution: Exact solution of a cubic function with Wolfram|Alpah And here is an approximation: Approximate form with Wolfram|Alpha The LaTeX Code \\documentclass{article} \\usepackage[pdftex,active,tightpage]{preview} \\setlength\\PreviewBorder{2mm} \\usepackage{pgfplots} \\usepackage{units} \\pgfplotsset{compat=1.3}% <-- moves axis labels near ticklabels % (respects tick label widths) \\usepackage{tikz} \\usetikzlibrary{arrows, positioning, calc, intersections, decorations.markings} \\usepackage{xcolor} \\definecolor{horizontalLineColor}{HTML}{008000} \\definecolor{verticalLineColor}{HTML}{FF0000} \\begin{document} % Define this as a command to ensure that it is same in both cases \\newcommand*{\\ShowIntersection}[2]{ \\fill [name intersections={of=#1 and #2, name=i, total=\\t}] [red, opacity=1, every node/.style={above left, black, opacity=1}] \\foreach \\s in {1,...,\\t}{(i-\\s) circle (2pt) node [above left] {\\s}}; } \\begin{preview} \\begin{tikzpicture} \\begin{axis}[ label distance=0mm, width=8cm, height=7cm, % size of the image xmin= 40, % start the diagram at this x-coordinate xmax= 180, % end the diagram at this x-coordinate ymin=60, % start the diagram at this y-coordinate ymax=170, % end the diagram at this y-coordinate ylabel=y, xlabel=x, axis lines=left, tick style={draw=none}, xticklabels={,,}, yticklabels={,,} ] \\addplot[name path global=a, domain=55:161, dotted, blue, thick,samples=500, label=$y=f(x)$] {113/132078*x*x*x-11865/44026*x*x+1169437/44026*x-93155207/132078}; % ( 55 | 82.7344) and (161 | 156.011) are on the graph \\coordinate (b) at (axis cs: 55,170); \\coordinate (c) at (axis cs:161,170); \\coordinate (d) at (axis cs:161,82.7344); \\coordinate (e) at (axis cs:161,156.011); \\coordinate (a1) at (axis cs:55,111.494); \\coordinate (a2) at (axis cs:161,111.494); \\draw[verticalLineColor, thick, <->](a1) -- (a2); \\draw[verticalLineColor,dashed](b |- 0,0) -- (b); \\draw[verticalLineColor,dashed](c |- 0,0) -- (c); \\draw[horizontalLineColor,dashed, thick](d -| 0,0) -- (d); \\draw[horizontalLineColor,dashed, thick](e -| 0,0) -- (e); % (100 | 111.494) \\coordinate (f) at (axis cs:100, 111.494); \\draw[red,dashed](f |- 0,0) -- (f); \\end{axis} \\end{tikzpicture} \\end{preview} \\end{document} The result Cubic function intermediate value theorem - Result","tags":"Cyberculture","title":"How to reverse engineer a function"},{"url":"https://martin-thoma.com/konvergenz-von-folgen/","text":"Sei $(a_n)$ eine Folge. $(a_n)$ heiÃŸt konvergent $:\\Leftrightarrow \\exists_{a \\in \\mathbb{R}} \\forall_{ \\varepsilon > 0} \\exists_{n_0 = n_0(\\varepsilon) \\in \\mathbb{N}}: |a_n - a | < \\varepsilon~~~\\forall n \\geq n_0$. In diesem Fall heiÃŸt a der Grenzwert von $(a_n)$ und man schreibt: $\\displaystyle \\lim_{n \\rightarrow \\infty} (a_n) = a$. Ist $(a_n)$ nicht konvergent, so heiÃŸt $(a_n)$ divergent . Ich werde im Folgendem ein paar wichtige Hinweise geben, wie man konvergenz oder gegebenenfalls divergenz zeigen kann. Wichtige Folgen Konvergent \\(\\displaystyle e := \\lim_{n \\rightarrow \\infty}(1+\\frac{1}{n})&#94;n = \\lim_{n \\rightarrow \\infty} \\sum_{k=0}&#94;n \\frac{1}{n!}\\) . \\(\\displaystyle \\lim_{n \\rightarrow \\infty} \\frac{1}{n} = 0\\) . \\(\\displaystyle \\lim_{n \\rightarrow \\infty} \\sqrt[n]{c} = 1\\) , mit \\(c > 0\\) . \\(\\displaystyle \\lim_{n \\rightarrow \\infty} \\sqrt[n]{n} = 1\\) . Divergent \\(a_n = n\\) . \\(a_n = (-1)&#94;n\\) BeschrÃ¤nktheit und Monotonie Wenn man zeigen kann, dass eine Folge beschrÃ¤nkt ist und monoton steigt oder fÃ¤llt (und die Schranke in der richtigen Richtung liegt), dann konvergiert die Folge. Beispiel: Sei \\((a_n)_{n \\in \\mathbb{N}}\\) eine Folge und definiert durch \\(a_n := 2 + \\frac{1}{n}\\) . 0 ist eine untere Schranke fÃ¼r \\((a_n)_{n \\in \\mathbb{N}}\\) : \\(\\underbrace{2}_{\\geq 0} + \\underbrace{\\frac{1}{n}}_{\\geq 0} \\Rightarrow a_n \\geq 0\\) \\((a_n)_{n \\in \\mathbb{N}}\\) ist monoton fallend: Beweis von \\(a_n \\geq a_{n+1} ~~~ \\forall_{n \\in \\mathbb{N}}\\) : \\begin{align} 1 & \\geq 0 ~~~ \\forall_{n \\in \\mathbb{N}&#94;+} \\\\ \\Leftrightarrow 2n&#94;2 + 3n + 1 & \\geq 2 n&#94;2 + 3n ~~~ \\forall_{n \\in \\mathbb{N}&#94;+} \\\\ \\Leftrightarrow 2n&#94;2 + n + 2n + 1 & \\geq n \\cdot (2n + 3) ~~~ \\forall_{n \\in \\mathbb{N}&#94;+} \\\\ \\Leftrightarrow (2n + 1) \\cdot (n+1) & \\geq n \\cdot (2n + 2 + 1) ~~~ \\forall_{n \\in \\mathbb{N}&#94;+} \\\\ \\Leftrightarrow \\frac{2n+1}{n} & \\geq \\frac{2 \\cdot(n+1)+1}{n+1} ~~~ \\forall_{n \\in \\mathbb{N}&#94;+} \\\\ \\Leftrightarrow 2 + \\frac{1}{n} & \\geq 2 + \\frac{1}{n+1} ~~~ \\forall_{n \\in \\mathbb{N}&#94;+} \\\\ \\Leftrightarrow a_n & \\geq a_{n+1}~~~ \\forall_{n \\in \\mathbb{N}&#94;+} \\end{align} \\((a_n)_{n \\in \\mathbb{N}}\\) ist also monoton fallend und hat eine untere Schranke. \\((a_n)_{n \\in \\mathbb{N}}\\) konvergiert also. Beachte : Ich habe nicht die grÃ¶ÃŸte untere Schranke gewÃ¤hlt. Hatte ich das gemacht (und bewiesen, dass es keine grÃ¶ÃŸere untere Schranke gibt), dann hÃ¤tte ich sogar den Grenzwert bestimmt. Cauchy-Folgen In BanachrÃ¤umen kann man auch nachweisen, dass eine Folge eine Cauchy-Folge ist um Konvergenz zu zeigen. Sie muss dazu dieser Bedingung genÃ¼gen: \\(\\forall_{\\varepsilon > 0} \\exists_{n_0 \\in \\mathbb{N}}: \\forall_{n,m\\in\\mathbb{N}, n>n_0, m>n_0}: |a_m- a_n| < \\varepsilon\\) Beispiel: Mir fÃ¤llt gerade kein Beispiel ein, bei dem man die Konvergenz schÃ¶ner Ã¼ber das Cauchy-Kriterium zeigen kann als Ã¼ber die BeschrÃ¤nktheit / Monotonie. Falls dir eines einfÃ¤llt, kannst du es ja in den Kommentar schreiben. (mit [latex] \\lim_{n \\rightarrow \\infty} 123 [/latex] wird es auch als LaTeX dargestellt ;-)) Weiteres Bei Polynomen darf man den \"Ausklammer-Trick\" nicht vergessen: \\(a_n = \\frac{3 \\cdot n&#94;5 + 2 \\cdot n&#94;2 + 42}{1000 \\cdot n&#94;5 + n&#94;3} = \\frac{n&#94;5}{n&#94;5} \\cdot \\frac{3 + 2 \\cdot \\frac{1}{n&#94;3} + 42 \\cdot \\frac{1}{n&#94;5}}{1000 + \\frac{1}{n&#94;2}}= \\frac{3 + 2 \\cdot \\frac{1}{n&#94;3} + 42 \\cdot \\frac{1}{n&#94;5}}{1000 + \\frac{1}{n&#94;2}}\\) Das sieht zwar deutlich schlimmer aus als vorher, ist aber besser. Wir wissen, dass \\(\\displaystyle \\lim_{n \\rightarrow \\infty} \\frac{1}{n} = 0\\) gilt. Also gilt: \\(\\displaystyle a_n \\xrightarrow{n \\rightarrow \\infty} \\frac{3 + 2 \\cdot \\overbrace{\\frac{1}{n&#94;3}}&#94;{\\rightarrow 0} + 42 \\cdot \\overbrace{\\frac{1}{n&#94;5}}&#94;{\\rightarrow 0}}{1000 + \\underbrace{\\frac{1}{n&#94;2}}_{\\rightarrow 0}} = \\frac{3}{1000}\\)","tags":"German posts","title":"Konvergenz von Folgen"},{"url":"https://martin-thoma.com/peg-solitaire/","text":"SolitÃ¤r (auch Solitaire, Steck- oder Solohalma, Springer, Jumper, Nonnenspiel, Einsiedlerspiel) ist ein Brettspiel fÃ¼r eine Person. Das weitest verbreitete Spielfeld ist kreuzfÃ¶rmig und wird mit 32 Steinen auf 33 Felder gestartet. In der Mitte fehlt die Kugel, alle anderen 32 Felder sind besetzt. Die Bezeichnungen Peg Solitaire - Spielfeld Dieses Brett ist hier mit den Bezeichnungen fÃ¼r die Felder dargestellt. Der Buchstabe bezeichnet das Feld ( o ben, u nten, l inks, r echts, m ittig) und die Zahl die genaue Position, wenn man das Brett so dreht, dass das aktuelle Feld oben nur zwei Kugeln hat, sind in der obersten Zeile die Zahlen 1 und 2, in der mittigen 3, 4 und 5 und in der untersten 6, 7 und 8: Die Regeln Es gibt vier verschiedene SpielzÃ¼ge: Der Sprung nach oben, unten, links und rechts. Es muss immer mit einer Kugel Ã¼ber eine andere Kugel auf ein freies Feld gesprungen werden. Aufgabenstellung Wie muss man ziehen, damit die letzte Kugel in der Mitte ubrig bleibt? Die LÃ¶sung Der erste Zug muss mit einer 2er-Kugel gemacht werden. Sagen wir, es ist o4. l3 u3 r3 o3 o8 l8 u8 r8 o6 l6 u6 r6 l1 u1 r1 o1 o8 l8 u8 r8 Die momentane Situation sieht folgendermaÃŸen aus: Peg Solitaire: Board Situation Nun kann man u1 einmal im Krei (auf r3, r5, o1, l3, l5 und dann wieder auf u1) wandern lassen. Es bleibt eine T-Form Ã¼brig: Peg Solitaire: Board Situation 2 Nun muss nur noch m Ã¼ber l1, dann u4, r1 und schlieÃŸlich l4.","tags":"German posts","title":"Peg Solitaire"},{"url":"https://martin-thoma.com/jordansche-normalform-2x2-matrizen/","text":"Hier sind $2 \\times 2$ Beispiele zum Hauptartikel Wie berechnet man die Jordan'sche Normalform? . Beispiel 1 Gegeben sei die Matrix \\(A \\in \\mathbb{R}&#94;{2 \\times 2}\\) : $$A := \\begin{pmatrix} 11 & -4\\\\ 25 & -9 \\end{pmatrix}$$ . Jordannormalform bestimmen 1. Charakteristisches Polynom berechnen: \\(p_A(\\lambda) = (\\lambda - 1)&#94;2\\) . Daraus folgt: \\(\\lambda = 1\\) ist einziger Eigenwert \\(\\Rightarrow\\) 1 Jordanblock 2. Anzahl der JordankÃ¤stchen bestimmen: \\begin{align} \\dim E_{1} &= \\dim \\text{Kern}(A -1 \\cdot I) \\\\ &= \\dim \\text{Kern} \\begin{pmatrix} 10 & -4\\\\ 25 & -10 \\end{pmatrix}\\\\ &= \\dim \\text{Kern} \\begin{pmatrix} 10 & -4\\\\ 0 & 0 \\end{pmatrix}\\\\ &= \\dim \\left [ \\begin{pmatrix}2\\\\5\\end{pmatrix} \\right ] \\\\ &= 1 \\end{align} \\(\\Rightarrow\\) es gibt genau 1 JordankÃ¤stchen in diesem Jordanblock. $$\\Rightarrow J = \\begin{pmatrix}1 & 1\\\\ 0 & 1 \\end{pmatrix}$$ . Basiswechselmatrix bestimmen Basisvektoren fÃ¼r den Eigenwert 1 bestimmen: $$\\Omega = \\Phi_{| H_\\lambda} - \\lambda \\cdot id = \\begin{pmatrix} 10 & - 4\\\\ 25 & -10 \\end{pmatrix} $$ , $$K_1 = \\text{Kern } \\Omega&#94;1 = \\left [ \\begin{pmatrix}2 \\\\ 5 \\end{pmatrix} \\right ]$$ $$K_2 = \\text{Kern } \\Omega&#94;2 = \\text{Kern } (\\begin{pmatrix}10 & -4\\\\ 25 & -10 \\end{pmatrix} \\cdot \\begin{pmatrix}10 & -4\\\\ 25 & -10 \\end{pmatrix}) = \\text{Kern } (\\begin{pmatrix}0 & 0\\\\ 0 & 0 \\end{pmatrix}) = \\left[ \\begin{pmatrix}1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix}0 \\\\ 1 \\end{pmatrix} \\right]$$ $$K_2 \\stackrel{!}{=} U_1 \\oplus K_1 \\Rightarrow \\left [ \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\right ] ~~~ U_0 = K_1$$ Schema zum finden der Basiswechselmatrix WÃ¤hle $$b_1&#94;1 \\in U_1: b_1&#94;1 = \\begin{pmatrix}1 \\\\0 \\end{pmatrix} \\Rightarrow \\Omega(b_1&#94;1) = \\begin{pmatrix}10 \\\\ 25 \\end{pmatrix}$$ $$\\Rightarrow S = \\begin{pmatrix} 10 & 1 \\\\ 25 & 0 \\end{pmatrix}$$ $$\\Rightarrow S&#94;{-1} = \\begin{pmatrix} 0 & \\frac{1}{25} \\\\ 1 & -\\frac{2}{5} \\end{pmatrix}$$ $$A = S \\cdot J \\cdot S&#94;{-1}$$ $$\\Leftrightarrow \\begin{pmatrix} 11 & -4\\\\ 25 & -9 \\end{pmatrix} = \\begin{pmatrix} 10 & 1 \\\\ 25 & 0 \\end{pmatrix} \\cdot \\begin{pmatrix}1 & 1\\\\ 0 & 1 \\end{pmatrix} \\cdot \\begin{pmatrix} 0 & \\frac{1}{25} \\\\ 1 & -\\frac{2}{5} \\end{pmatrix}$$ Beispiel 2 Gegeben sei die Matrix \\(A \\in \\mathbb{R}&#94;{2 \\times 2}\\) : $$A := \\begin{pmatrix} 1 & 2\\\\ 3 & 6 \\end{pmatrix}$$ . Jordannormalform bestimmen 1. Charakteristisches Polynom berechnen: $$p_A(\\lambda) = \\det \\begin{pmatrix} 1 -\\lambda & 2\\\\ 3 & 6 - \\lambda \\end{pmatrix} = (1- \\lambda) \\cdot (6 - \\lambda) - 6 = 6-6\\lambda-\\lambda+\\lambda&#94;2-6=\\lambda&#94;2-7\\lambda = \\lambda \\cdot (\\lambda - 7)$$ Daraus folgt: 0 und 1 sind Eigenwerte. Sie haben jeweils die algebraischen Vielfachheit 1. Daraus folgt: Die Jordansche Normalform hat genau zwei JordanblÃ¶cke, die beide die GrÃ¶ÃŸe 1x1 haben. Daraus folgt: Beide JordanblÃ¶cke haben genau ein JordankÃ¤stchen der GrÃ¶ÃŸe 1x1. Daraus folgt: Die Jordansche Normalform der Matrix ist: $$J = \\begin{pmatrix} 0 & 0\\\\ 0 & 7 \\end{pmatrix}$$ Basiswechselmatrix bestimmen Basisvektoren fÃ¼r den Eigenwert 0 bestimmen: $$K_1 = \\text{Kern }(A- 0 \\cdot E) = \\text{Kern } \\begin{pmatrix} 1 & 2\\\\ 3 & 6 \\end{pmatrix} = \\left [ \\begin{pmatrix}2 \\\\ -1 \\end{pmatrix} \\right ] $$ Basisvektoren fÃ¼r den Eigenwert 7 bestimmen: $$K_1 = \\text{Kern }(A- 7 \\cdot E) = \\text{Kern } \\begin{pmatrix} -6 & 2\\\\ 3 & -1 \\end{pmatrix} = \\text{Kern } \\begin{pmatrix} 1 & -\\frac{1}{3}\\\\ 0 & 0 \\end{pmatrix} = \\left [ \\begin{pmatrix}1 \\\\ 3 \\end{pmatrix} \\right ] $$ Zusammensetzen: $$S = \\begin{pmatrix}2 & 1 \\\\ -1 & 3 \\end{pmatrix}$$ $$S&#94;{-1} = \\frac{1}{7} \\cdot \\begin{pmatrix}3 & -1 \\\\ 1 & 2 \\end{pmatrix}$$ Anmerkung Man hÃ¤tte Ã¼brigens jeden Vektor aus \\(\\left [ \\begin{pmatrix}2 \\\\ -1 \\end{pmatrix} \\right ] $</span> nehmen kÃ¶nnen. Angenommen, man hÃ¤tte den Vektor <span>\\) \\begin{pmatrix}-14 \\\\ 7 \\end{pmatrix} $ gewÃ¤hlt: $$S = \\begin{pmatrix}-14 & 1 \\\\ 7 & 3 \\end{pmatrix}$$ $$S&#94;{-1} = \\frac{1}{49} \\cdot \\begin{pmatrix}-3 & 1 \\\\ 7 & 14 \\end{pmatrix}$$ Das gleiche gilt natÃ¼rlich fÃ¼r jeden anderen gewÃ¤hlten Vektor. Die inverse Matrix Ã¤ndert sich selbstverstÃ¤ndlich, jedoch nicht die Jordansche Normalform oder die ursprÃ¼ngliche Matrix.","tags":"German posts","title":"Jordansche Normalform: 2x2 Matrizen"},{"url":"https://martin-thoma.com/wie-berechnet-man-die-jordansche-normalform/","text":"Dieser Artikel beschreibt, wie die Jordansche Normalform einer Matrix sowie die dazugehÃ¶rige Basiswechselmatrix gefunden werden kann. Dabei wird hier eine Jordansche Normalform erzeugt, bei der die 1er auf der oberen Nebendiagonale sind und die grÃ¶ÃŸten JordankÃ¤stchen zuerst kommen. Ich werde hier nicht erklÃ¤ren, warum es so funktioniert. Hier sind zwei Beispiele mit 2x2-Matrizen und Beispiele mit 4x4-Matrizen . Gegeben sei eine Matrix \\(A \\in \\mathbb{C}&#94;{n \\times n}\\) . Berechnung der Jordanschen Normalform Charakteristisches Polynom bestimmen Als ersten Schritt muss man das charakteristische Polynom \\(p_A(\\lambda)\\) der Matrix \\(A\\) bestimmen. â†’ Wie berechnet man das charakteristische Polynom? Zerlegung in Linearfaktoren Die Zerlegung des charakteristischen Polynoms \\(p_A(\\lambda)\\) in Linearfaktoren kann ziemlich schwer sein. DafÃ¼r muss man unbedingt die Mitternachtsformel \\(\\lambda_{1,2} = \\frac{-b \\pm \\sqrt{b&#94;2 - 4ac}}{2a}\\) kÃ¶nnen und eventuell wissen, wie eine Polynomdivision funktioniert. Eventuell muss man dazu auch Nullstellen erraten. Wenn es ums raten geht, wÃ¼rde ich folgendes ausprobieren: 0, 1, -1, 2, -2, 3, -3. Sobald man diese Zerlegung hat, kann man die Eigenwerte und die algebraische Vielfachheit der Eigenwerte direkt ablesen. Die Eigenwerte stehen in der Jordanmatrix auf der Diagonalen. Die algebraische Vielfachheit entspricht der SeitenlÃ¤nge des quadratischen Jordanblocks. Anzahl der JordankÃ¤stchen bestimmen Jeder Eigenwert hat genau einen Jordanblock. Jeder Jordanblock hat wiederum JordankÃ¤stchen. Das sieht so aus: ( J = \\left( \\begin{array}{*4{c}} A_{\\lambda_1} & & & 0\\\\ & A_{\\lambda_2} & & \\\\ & & \\ddots & \\\\ 0 & & & A_{\\lambda_k} \\end{array} \\right)) \\(A_{\\lambda_i}\\) sind die JordanblÃ¶cke zu den Eigenwerten \\(\\lambda_i\\) . Die Einzelnen JordanblÃ¶cke schauen etwa so aus: Einzelner Jordanblock mit zwei hervorgehobenen JordankÃ¤stchen Jedes JordankÃ¤stchen ist quadratisch, hat auf der Diagonalen den Eigenwert und auf der oberen Nebendiagonale 1er. Sonst sind nur 0er im JordankÃ¤stchen. AuÃŸerhalb der JordankÃ¤stchen sind im Jordanblock nur 0er. Insbesondere kÃ¶nnen also auf der oberen Nebendiagonalen des Jordanblocks 0er stehen! Es gilt: \\(\\text{geometrische Vielfachheit des Eigenwertes } \\lambda := \\dim E_\\lambda \\leq \\text{algebraische Vielfachheit des Eigenwertes } \\lambda\\) \\(\\dim E_\\lambda = \\dim \\text{Kern}(A - \\lambda \\cdot I) = \\text{Anzahl der JordankÃ¤stchen im Jordanblock zu } \\lambda\\) â†’ Wie bestimme ich den Kern einer linearen Abbildung? AuÃŸerdem gilt: Die GrÃ¶ÃŸe des grÃ¶ÃŸten JordankÃ¤stchens zum Eigenwert \\(\\lambda_i\\) ist gleich der Potenz, mit der der Linearfaktor \\((x-\\lambda_i)\\) im Minimalpolynom (leider NICHT das charakteristische Polynom â˜¹ ) vorkommt. Nun kann man hÃ¤ufig schon schlussfolgern, welche GrÃ¶ÃŸe die einzelnen JordankÃ¤stchen haben. ZusÃ¤tzlich haben Ã¤hnliche Matrizen die gleiche Spur, die gleiche Determinante und den gleichen Rang. Das kÃ¶nnte helfen um \"falsche\" Jordanmatrizen auszuschlieÃŸen. Damit ist die Jordansche Normalform der Matrix hÃ¤ufig schon bestimmt. GrÃ¶ÃŸe der JordankÃ¤stchen bestimmen Sei \\(\\Omega = \\Phi - \\lambda \\cdot id\\) und \\(K_k = \\text{Kern } ((\\Omega)&#94;k)\\) Man wÃ¤hle \\(q \\in N&#94;+\\) so, dass \\(\\dim K_q = \\dim K_{q+1} = \\dim K_{q+2} = ... = \\dim V\\) und q minimal. Dann gilt: q ist die lÃ¤nge des grÃ¶ÃŸten JordankÃ¤stchens in dem Jordanblock (und auÃŸerdem der Exponent im Minimalpolynom zum betrachteten Eigenwert \\(\\lambda\\) ). Es sei \\(a_0 = \\dim K_0 = 0, a_1 = \\dim K_1, a_i = \\dim K_i\\) mit \\(i \\in 0, ..., q\\) . Es gilt: Anzahl der KÃ¤stchen der GrÃ¶ÃŸe \\(1 \\times 1\\) : \\(2 \\cdot a_1 - a_0 - a_2\\) Anzahl der KÃ¤stchen der GrÃ¶ÃŸe \\(2 \\times 2\\) : \\(2 \\cdot a_2 - a_1 - a_3\\) Anzahl der KÃ¤stchen der GrÃ¶ÃŸe \\(3 \\times 3\\) : \\(2 \\cdot a_3 - a_2 - a_4\\) Anzahl der KÃ¤stchen der GrÃ¶ÃŸe \\(i \\times i\\) : \\(2 \\cdot a_i - a_{i-1} - a_{i+1}\\) Berechnung der Basiswechselmatrix Die Basiswechselmatrix wird manchmal auch Transformationsmatrix genannt. Es ist die invertierbare Matrix S, fÃ¼r die gilt: \\(A = S \\cdot J \\cdot S&#94;{-1}\\) Kerne bestimmen Bestimme \\(K_1, K_2, K_3, ... , K_q\\) , wobei \\(\\dim K_{q-1} < \\dim K_q = \\dim K_{q+1} = \\dim K_{q+2} ...\\) gilt. Man kann also bei \\(K_q\\) aufhÃ¶ren. FÃ¼r jedes \\(K_k\\) mit \\(k \\in 1, ..., q\\) bestimmt man eine mÃ¶glichst einfache Basis. Zusammensetzen An dieser Stelle sollte man wissen, wie groÃŸ die JordankÃ¤stchen sind. FÃ¼r ein JordankÃ¤stchen der GrÃ¶ÃŸe \\(i\\) wÃ¤hlt man einen Basisvektor \\(v_i\\) aus \\(K_i\\) , der jedoch nicht in \\(K_{i-1}\\) liegt. Die restlichen \\(i-1\\) Vektoren fÃ¼r dieses KÃ¤stchen erhÃ¤lt man, indem man die Abbildungsmatrix von \\(\\Omega&#94;{j}\\) , mit \\(j = 1, ..., i-1\\) , mit \\(v_i\\) multipliziert. Also: \\(v_j = (A - \\lambda \\cdot E)&#94;{i-j}\\) mit \\(j = 1, ..., i\\) Die Vektoren \\(v_j\\) schreibt man mit aufsteigenden Indizes in die geordete Basis. Beachte: Man wÃ¤hlt nur den Vektor \\(v_i\\) , alle anderen Vektoren fÃ¼r dieses KÃ¤stchen sind dadurch festgelegt! AuÃŸerdem schreibt man \\(v_i\\) erst am Ende in die Basis! Inverse Matrix bestimmen Sobald man \\(S\\) bestimmt hat, muss man nur noch das Inverse davon bestimmen: â†’ Wie bestimme ich das Inverse einer Matrix? Interessante Eigenschaften der JNF Im Zusammenhang mit der JNF (und einigen Klausuraufgaben) sind mir ein paar erwÃ¤hnenswerte Eigenschaften aufgefallen: Die Anzahl der JordankÃ¤stchen zum Eigenwert \\(\\lambda = 0\\) ist \\(n - \\text{Rang}(A)\\) . BegrÃ¼ndung : Die Anzahl der JordankÃ¤stchen zum Eigenwert \\(\\lambda\\) ist gleich der Dimension des Eigenraumes von \\(\\lambda\\) . Der Eigenraum zum Eigenwert 0 hat die besonderheit, dass es der Kern ist. Nach der Dimensionsformel gilt: \\(\\dim \\text{Kern}(\\Phi) + \\dim \\text{Bild}(\\Phi) = n = \\dim \\text{Kern} + \\text{ Rang}(A_\\Phi)\\) .","tags":"German posts","title":"Wie berechnet man die Jordan'sche Normalform?"},{"url":"https://martin-thoma.com/java-puzzle-10-multiple-interfaces/","text":"You have to following source code: A.java : public interface A { public int methodA ( double a , int b , char c ); public int methodB (); } B.java : public interface B { public int methodB (); public void methodC (); } test.java : public class test implements A , B { public static void main ( String [] args ) { test t = new test (); System . out . println ( t . methodA ( 1 , 2 , '3' )); System . out . println ( t . methodB ()); t . methodC (); } @Override public int methodA ( double a , int b , char c ) { return 42 ; } @Override public int methodB () { return 1337 ; } @Override public void methodC () { System . out . println ( \"methodC executed.\" ); } } What is the output? Does it compile? Is there a RuntimeException ? . . . . . . . . . . . . . . . . . Answer Output: 42 1337 methodC executed. Explanation If you use an Interface, it simply means you have to implement some methods. If more than one Interface forces you to implement the method, you still have to implement it only once. It just works fine.","tags":"Code","title":"Java Puzzle #10: Multiple Interfaces"},{"url":"https://martin-thoma.com/wie-bestimme-ich-den-kern-einer-linearen-abbildung/","text":"Definition Der Kern einer linearen Abbildung ist eine Menge von Vektoren. In diesem Artikel erklÃ¤re ich kurz und bÃ¼ndig, wie man den Kern einer linearen Abbildung bestimmt. Sei $\\Phi: V \\rightarrow W$ eine lineare Abbildung. Der Kern von $\\Phi$ ist die Menge aller Vektoren von V, die durch $\\Phi$ auf den Nullvektor $0 \\in W$ abgebildet werden, also: $\\text{Kern } \\Phi := \\{v \\in V | \\Phi(v) = 0\\}$ Vorgehen Jede lineare Abbildung \\(\\Phi\\) lÃ¤sst sich in dieser Form beschreiben: \\(\\Phi: V \\rightarrow W\\) mit \\(\\dim V = m\\) und \\(\\dim W = n\\) \\(\\Phi(x) = A \\cdot x, ~~~ A \\in R&#94;{n \\times m}, x \\in V\\) Also muss man, um den Kern von \\(\\Phi\\) zu bestimmen, nur das folgende homogene Gleichungssystem nach x auflÃ¶sen: \\(A \\cdot x = 0\\) In Wolfram|Alpha benÃ¶tigt man dafÃ¼r Ã¼brigens das SchlÃ¼sselwort null space . Hier ist Beispiel #2 in Wolfram|Alpha . Beispiel #1 Aufgabenstellung Sei \\(A \\in \\mathbb{R}&#94;{3 \\times 3}\\) und definiert als \\(A := \\begin{pmatrix} 1 & 2 & 3\\\\ 4 & 5 & 6\\\\ 7 & 8 & 9 \\end{pmatrix} \\) Sei \\(\\Phi: \\mathbb{R}&#94;3 \\rightarrow \\mathbb{R}&#94;3\\) eine lineare Abbildung und definiert als \\(\\Phi(x) := A \\cdot x\\) . Was ist der Kern von \\(\\Phi\\) ? Rechnung $ \\begin{pmatrix} 1 & 2 & 3\\\\ 4 & 5 & 6\\\\ 7 & 8 & 9 \\end{pmatrix} \\leadsto \\begin{pmatrix} 1 & 2 & 3\\\\ 0 & -3 & -6\\\\ 0 & -6 & -12 \\end{pmatrix} \\leadsto \\begin{pmatrix} 1 & 2 & 3\\\\ 0 & 1 & 2\\\\ 0 & 1 & 2 \\end{pmatrix} \\leadsto \\begin{pmatrix} 1 & 0 & -1\\\\ 0 & 1 & 2\\\\ 0 & 0 & 0 \\end{pmatrix} $ Man sieht direkt, dass die Matrix den Rang 2 hat. Also muss der LÃ¶sungsraum 1-dimensional sein. Mit dem -1-Trick kommt nam auf den LÃ¶sungsraum: \\(\\mathcal{L} = \\left [ \\begin{pmatrix} -1\\\\ 2\\\\ -1 \\end{pmatrix} \\right ]\\) Also: \\(\\text{Kern } \\Phi = \\left [ \\begin{pmatrix} -1\\\\ 2\\\\ -1 \\end{pmatrix} \\right ]\\) Beispiel #2 Aufgabenstellung Sei \\(A \\in \\mathbb{R}&#94;{5 \\times 5}\\) und definiert als \\(A := \\begin{pmatrix} -1 & -1 & -2 & -2 & -1\\\\ 3 & 0 & 2 & 1 & 2\\\\ 0 & 1 & 1 & 1 & 0\\\\ -1 & -1 & -2 & -2 & -1\\\\ 2 & 1 & 3 & 3 & 2 \\end{pmatrix} \\) Sei \\(\\varphi: \\mathbb{R}&#94;5 \\rightarrow \\mathbb{R}&#94;5\\) eine lineare Abbildung und definiert als \\(\\varphi(x) := A \\cdot x\\) . Was ist der Kern von \\(\\varphi\\) ? Rechnung \\( \\begin{pmatrix} -1 & -1 & -2 & -2 & -1\\\\ 3 & 0 & 2 & 1 & 2\\\\ 0 & 1 & 1 & 1 & 0\\\\ -1 & -1 & -2 & -2 & -1\\\\ 2 & 1 & 3 & 3 & 2 \\end{pmatrix} \\cdot \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\\\ x_5 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} \\) \\(\\leadsto \\begin{pmatrix} -1 & -1 & -2 & -2 & -1\\\\ 3 & 0 & 2 & 1 & 2\\\\ 0 & 1 & 1 & 1 & 0\\\\ -1 & -1 & -2 & -2 & -1\\\\ 2 & 1 & 3 & 3 & 2 \\end{pmatrix} \\leadsto \\begin{pmatrix} -1 & -1 & -2 & -2 & -1\\\\ 0 & -3 & -4 & -5 & -4\\\\ 0 & 1 & 1 & 1 & 0\\\\ 0 & 0 & 0 & 0 & 0\\\\ 0 & -1 & -1 & -1 & 0 \\end{pmatrix} \\) \\(\\leadsto \\begin{pmatrix} 1 & 1 & 2 & 2 & 1\\\\ 0 & 1 & 1 & 1 & 0\\\\ 0 & 0 & -1 & -2 & -1\\\\ 0 & 0 & 0 & 0 & 0\\\\ 0 & 0 & 0 & 0 & 0 \\end{pmatrix} \\leadsto \\begin{pmatrix} 1 & 0 & 0 & -1 & 0\\\\ 0 & 1 & 0 & -1 & -1\\\\ 0 & 0 & 1 & 2 & 1\\\\ 0 & 0 & 0 & 0 & 0\\\\ 0 & 0 & 0 & 0 & 0 \\end{pmatrix} \\) Die Matrix hat Rang 3, daraus folgt, dass die Dimension des LÃ¶sungsraumes 2 ist. Wieder Ã¼ber den -1-Trick kann man den LÃ¶sungsraum direkt ablesen: $\\mathcal{L} = \\left [ \\begin{pmatrix} -1\\\\ -1\\\\ 2\\\\ -1\\\\ 0 \\end{pmatrix} , \\begin{pmatrix} 0\\\\ -1\\\\ 1\\\\ 0\\\\ -1 \\end{pmatrix} \\right ] = \\text{Kern} \\varphi $","tags":"German posts","title":"Wie bestimme ich den Kern einer linearen Abbildung?"},{"url":"https://martin-thoma.com/der-kaiser-von-china-und-der-reis/","text":"Aufgabenstellung Der Kaiser von China spielt mit einem Bauern Schach. Nachdem er das Spiel verloren hat, ist der Kaiser groÃŸzÃ¼gig und will dem Bauern jeden Wunsch erfÃ¼llen. Der Bauer gibt sich bescheiden und verlangt fÃ¼r das erste Schachfeld ein Reiskorn, fÃ¼r das zweite zwei ReiskÃ¶rner, usw. Allgemein formuliert verlangt er fÃ¼r jedes Schachfeld doppelt so viele ReiskÃ¶rner wie fÃ¼r das Vorhergehende. Wieviel Reis muss der Kaiser von China abtreten? LÃ¶sung Ein Schachbrett hat \\(8 \\cdot 8 = 64\\) Felder. FÃ¼r das \\(i\\) -te Feld, \\(1 \\le i \\le 64\\) , muss der Kaiser \\(2&#94;{i-1}\\) ReiskÃ¶rner abgeben. Insgesamt muss er also \\(\\sum_{i=1}&#94;{64} 2&#94;{i-1}\\) ReiskÃ¶rner abgeben. Das sind \\(2&#94;{64} - 1 = 18446744073709551615 \\approx 1{,}84 \\cdot 10&#94;{19}\\) ReiskÃ¶rner. Vergleiche Wie viel sind 18.446.744.073.709.551.615 ReiskÃ¶rner? Erdabdeckung WÃ¼rde man die Erde gleichmÃ¤ÃŸig mit ReiskÃ¶rnern abdecken, wie hoch wÃ¤re diese Schicht? Die Erde hat eine OberflÃ¤che von ca. 510 Millionen \\(\\text{km}&#94;2\\) , ein Basmati-Reiskorn ist ca 6,5 mm lang, hat einen Durchmesser von ca. 1,5 mm und hat vereinfacht eine Kreiszylinderform. Daraus ergibt sich folgende Gleichung, bei der \\(x\\) die HÃ¶he der Reisschicht ist: $ \\begin{align} x \\cdot A_{Erde} &= (2&#94;{64}-1) \\cdot 6,5\\text{mm} \\cdot (1,5\\text{mm})&#94;2 \\cdot \\pi \\\\ x &= \\frac{(2&#94;{64}-1) \\cdot 6,5\\text{mm} \\cdot (1,5\\text{mm})&#94;2 \\cdot \\pi}{A_{Erde}} \\\\ x &= \\frac{(2&#94;{64}-1) \\cdot 45,9458\\text{mm}&#94;3}{510 \\cdot 10&#94;6 \\cdot 10&#94;{12} \\text{mm}&#94;2} \\\\ x &= \\frac{8,47550 \\cdot 10&#94;{20} \\text{mm}&#94;3}{510 \\cdot 10&#94;{18} \\text{mm}&#94;2} \\\\ x &= 1,662\\text{mm} \\end{align} $ Die Erde kÃ¶nnte also komplett mit ca. 1,662 mm Reis, also etwas mehr als einem Reiskorn, bedeckt werden. Reispackungen Den vorhergehenden Vergleich finde ich noch etwas unpraktisch. Wieviele Reispackungen wÃ¤ren das? Eine handelsÃ¼bliche Packung Reis beinhaltet ca. 1 kg Reis. Ein Reiskorn wiegt ca. 65 mg. $ \\begin{align} x &:= \\text{Reispackungen} \\\\ x \\cdot 1\\text{kg} &= 65\\text{mg} \\cdot (2&#94;{64}-1) \\\\ x \\cdot 10&#94;6\\text{mg} &= 1199038364791120854975\\text{mg} \\\\ x &\\approx 1,2 \\cdot 10&#94;{15} \\end{align} $ Reispackungen pro Person Auch \\(1,2 \\cdot 10&#94;{15}\\) ist noch zu groÃŸ, um sich etwas darunter vorstellen zu kÃ¶nnen. Wie viele Reispackungen wÃ¤ren das pro Person auf der Erde? $ \\begin{align} x &:= \\text{Reispackungen pro Mensch} \\\\ x &= \\frac{1,2 \\cdot 10&#94;{15}}{6,93 \\cdot 10&#94;9} \\\\ x &\\approx 1,7 \\cdot 10&#94;5 \\end{align} $ Jeder Mensch wÃ¼rde also 170.000 Packungen Reis von Kaiser von China bekommen. Um den tÃ¤glichen Kalorienbedarf zu decken werden ca. 1,1 kg Reis benÃ¶tigt. Es kÃ¶nnten also alle Menschen der Erde ca. 154.545 Tage, das sind Ã¼ber 423 Jahre, ernÃ¤hrt werden! Marktwert Reis kostet auf dem Weltmarkt ca. 600 US-Dollar pro metrischer Tonne ( Quelle ). $ \\begin{align} x &:= \\text{Marktwert} \\\\ x &= \\frac{1,2 \\cdot 10&#94;{15}}{1000} \\cdot 600 \\text{ US-Dollar}\\\\ x &= 720000000000000 \\end{align} $ Der Reis hÃ¤tte also einen Marktwert von 720 Billionen US-Dollar. Zum Vergleich: Das BIP der gesamten Welt, also die Summe der Werte aller GÃ¼ter und Dienstleistung, lag 2007 bei ca. 54 Billionen US-Dollar ( Quelle ).","tags":"German posts","title":"Der Kaiser von China und der Reis"},{"url":"https://martin-thoma.com/klausur-analysis-i-und-ii/","text":"Dieser Artikel richtet sich vor allem an Studenten, die im Sommersemester 2012 bei Herrn Prof. Dr. Schmoeger am KIT die Klausur Ã¼ber Analysis schreiben werden. Vorbereitung Analysis I Themen Definitionen und Beispiele : BeschrÃ¤nktheit, injektiv, surjektiv, bijektiv, endlich, unendlich, abzÃ¤hlbar, Ã¼berabzÃ¤hlbar Bernoullische Ungleichung : Ist $x \\geq -1$, so gilt: $(1+x)&#94;n \\geq 1 + nx~~~\\forall n \\in \\mathbb{N}&#94;+$ Binomischer Lehrsatz : $(a+b)&#94;n = \\sum_{k=0}&#94;{n} \\binom{n}{k} a&#94;{n-k} b&#94;k$ Folgen : Konvergenz (strenge) Monotonie Grenzwert Divergenz Konvergenzkriterien: Wurzelkriterium , Leibniz-Kriterium , Cauchy-Kriterium , Majorantenkriterium , Minorantenkriterium, Quotientenkriterium Eulersche Zahl : $\\displaystyle e := \\lim_{n \\rightarrow \\infty}(1+\\frac{1}{n})&#94;n = \\lim_{n \\rightarrow \\infty} \\sum_{k=0}&#94;n \\frac{1}{n!}$ HÃ¤ufungswert vs. HÃ¤ufungspunkt: â†’ Diskussion Oberer- und unterer Limes Unendliche Reihen Potenzreihe Stetigkeit GleichmÃ¤ÃŸige Stetigkeit : Definition, Beispiele HÃ¶here Ableitungen Integrale Riemann-Integral Uneigentliche Integrale Riemann-Stieltjes-Integral Partielle Integration $\\int_a&#94;b f'(x)\\cdot g(x)\\,\\mathrm{d}x = [f(x)\\cdot g(x)]_{a}&#94;{b} - \\int_a&#94;b f(x)\\cdot g'(x)\\,\\mathrm{d}x.$ Funktionen beschrÃ¤nkter Variation Totalvariation Zwischenwertsatz Mittelwertsatz Aufgabenstellungen Wahr/Falsch-Ankreuzaufgabe Grenzwert von Folgen bestimmen Konvergenzradius von Potenzreihen bestimmen Zeige, dass eine Funktion stetig ist. Ansatz: $f \\text{ ist stetig} :\\Leftrightarrow \\forall \\varepsilon > 0 \\ \\exists \\delta \\ \\forall x, z \\text{ mit } |x - z| < \\delta: |f(x)- f(z)| < \\varepsilon$ Zeige, dass eine Funktion differenzierbar ist. Ansatz: h-Methode $\\displaystyle \\lim_{h \\rightarrow 0} \\frac{f(x_0+h)-f(x_0)}{h}$ Funktionenfolgen auf punktweise und gleichmÃ¤ÃŸige Konvergenz untersuchen Allgemeine Eigenschaften der e-Funktion und der Winkelfunktionen Wert von Integralen bestimmen Analysis II Themen und Schlagworte Quadratische Formen Umkehrsatz Implizit definierte Funktionen Wege WeglÃ¤nge: $L(\\gamma) = \\int \\| \\gamma'(t) \\| dt$ Wegintegral: $\\int_\\gamma f(x, y, z) d(x,y,z) = \\int f(\\gamma(t)) \\cdot \\gamma'(t) dt$ Fixpunkte, Fixpunktsatz von Banach Jacobi-Matrix Extremwerte ... unter Nebenbedingungen Hessematrix Banachscher Fixpunktsatz Differentialgleichungen Systeme linearer Differentialgleichungen Anfangswertprobleme Fundamentalsystem Variation der Konstanten Satz von Picard-LindelÃ¶f Aufgabenstellungen Sind gegebene Mengen offen, abgeschlossen bzw. vollstÃ¤ndig? Rand einer Menge besttimmen Lokale und globale Extrema einer Funktion $f$ bestimmen. Ansatz: Gradient $\\nabla f$ bestimmen und gleich null setzen. Die Funktionswerte, die das erfÃ¼llen, sind die kritischen Punkte. In Hessematrix einsetzen und Definitheit prÃ¼fen. LÃ¶sung von nichtlinearen Gleichungssystem Differenzierbarkeit zeigen â†’ $\\displaystyle \\lim_{h \\rightarrow 0} \\frac{f(x_0+h)-f(x_0)- A \\cdot h}{\\|h\\|}$ LÃ¶sung eines Anfangswertproblems bestimmen â€žBeweisen Sie Existenz und Eindeutigkeit einer LÃ¶sung\" â†’ Picard-LindelÃ¶f Zeigen Sie die rektifizierbarkeit eines Weges $\\gamma$: â†’ Differenzierbarkeit zeigen, ableiten, stetigkeit der Ableitung zeigen. Lernplan Man sollte die ÃœbungsblÃ¤tter nochmals machen, die relevanten Kapitel im Skript fÃ¼r Analysis I und im Skript fÃ¼r Analysis II (Bachelor) durchlesen und Klausuren rechnen. (Aktuellere Skripte finden sich in meinem GitHub Repository . Allerdings muss man die PDF selbst erstellen.) Termine und Klausurablauf Datum : Dienstag, den 25. September 2012 von 08:00 bis 13:00 Uhr Ort : HÃ¶rsaaleinteilung - Ich bin im Hetz-HÃ¶rsaal . Dauer : 2 h Analysis I, 1 h Pause, 2 h Analysis II Punkte : 7 Aufgaben Ã  3 Punkte fÃ¼r Analysis I, 7 Aufgaben Ã  3 Punkte fÃ¼r Analysis II Bestehensgrenze : Wohl bei ca. 21 Punkten Ãœbungsschein : Ist im Studierendenportal eingetragen Bonuspunkte : Gibt es nicht. Ergebnisse Die Klausureinsicht ist am 24.10.2012 von 14:00 - 16:30 Uhr ( Quelle ).","tags":"German posts","title":"Klausur Analysis I und II"},{"url":"https://martin-thoma.com/mathe-aufgabe-blutspende/","text":"Aufgabenstellung Ein Mensch hat ca. 5 Liter Blut. Bei einer Blutspende wird in der Regel etwa ein halber Liter Blut entnommen. Bis zur nÃ¤chsten Blutspende ist wird dieses Blut wieder neu gebildet. Wie hÃ¤ufig muss Blut gespendet werden, bis 95% des ursprÃ¼nglichen Blutes gespendet wurde? Die natÃ¼rliche Neubildung von Blut auch ohne Blutspende wird vernachlÃ¤ssigt. Berechnung Die ersten Werte \\(f: \\mathbb{N}_0 \\rightarrow \\mathbb{R}_0&#94;+\\) sei die Menge des ursprÃ¼nglichen Blutes in Liter, das nach \\(x\\) Spenden gespendet wurde: \\(f(0) = 0\\) Beim ersten mal Blutspenden wird ein halber Liter des ursprÃ¼nglichen Blutes gespendet: \\(f(1) = 0{,}5 + f(0)\\) Beim zweiten mal Blutspenden werden 0,45 Liter des ursprÃ¼nglichen Blutes gespendet: \\(f(2) = \\frac{5-0{,}5}{5} \\cdot 0{,}5 \\text{ Liter} + f(1) + f(0) = 0{,}95 \\text{ Liter}\\) Beim dritten mal Blutspenden werden 0,405 Liter des ursprÃ¼nglichen Blutes gespendet: \\(f(3) = \\frac{5-0{,}95}{5} \\cdot 0{,}5 \\text{ Liter} + f(2) + f(1) + f(0) = 1{,}355 \\text{ Liter}\\) Eine rekursive Formel $$ \\begin{align} f(1) &= 0{,}5 \\\\ f(x) &= \\overbrace{\\underbrace{\\frac{5-f(x-1)}{5}}_{\\text{Anteil}} \\cdot 0{,}5}&#94;{\\text{neue Blutmenge}} + f(x-1) \\\\ &= 0{,}5 - \\frac{1}{10} \\cdot f(x-1) + f(x-1) \\\\ &= 0{,}5 + \\frac{9}{10} \\cdot f(x-1) \\end{align} $$ Dabei gilt: 0,5 ist die gespendete Blutmenge in Liter einer Spende \\(\\frac{9}{10} = \\frac{\\text{gespendete Blutmenge}}{\\text{gesamte Blutmenge}}\\) AuflÃ¶sen der Rekursion $$ \\begin{align} f(4) &= 0{,}5 + \\frac{9}{10} \\cdot (0{,}5 + \\frac{9}{10} \\cdot (0{,}5 + \\frac{9}{10} \\cdot 0{,}5))\\\\ &= 0{,}5 + \\frac{9}{10} \\cdot 0{,}5 + (\\frac{9}{10})&#94;2 \\cdot (0{,}5 + \\frac{9}{10} \\cdot 0{,}5)\\\\ &= 0{,}5 + \\frac{9}{10} \\cdot 0{,}5 + (\\frac{9}{10})&#94;2 \\cdot 0{,}5 + (\\frac{9}{10})&#94;3 \\cdot 0{,}5\\\\ &= 0{,}5 \\cdot (1 + \\frac{9}{10} + (\\frac{9}{10})&#94;2 + (\\frac{9}{10})&#94;3)\\\\ f(x)&= \\frac{1}{2} \\cdot \\sum_{i=0}&#94;{x} (\\frac{9}{10})&#94;i \\end{align} $$ AuflÃ¶sen des Summensymbols $$ \\begin{align} f(x) &= \\frac{1}{2} \\cdot \\sum_{i=0}&#94;{x} (\\frac{9}{10})&#94;i\\\\ &= \\frac{1}{2}\\cdot (\\frac{0{,}9&#94;{x+1} - 1}{0{,}9 - 1})\\\\ &= \\frac{1}{2}\\cdot (-10 \\cdot 0{,}9&#94;{x+1} + 10)\\\\ &= -5 \\cdot 0{,}9&#94;{x+1} + 5\\\\ &= 5 \\cdot (1 - 0{,}9&#94;{x+1}) \\end{align} $$ LÃ¶sung $$ \\begin{align} 0{,}95 \\cdot 5 &= 5 \\cdot (1- 0{,}9&#94;{x+1})\\\\ 0{,}95 &= 1 - 0{,}9&#94;{x+1}\\\\ 0{,}9&#94;{x+1} &= 0{,}05\\\\ \\ln(0{,}9) \\cdot {x+1} &= \\ln(0{,}05) \\\\ x &= \\frac{\\ln(0,05)}{\\ln(0{,}9)} - 1\\\\ x &= 27{,}43 \\end{align} $$ Antwort Nach dem 28. mal Blutspenden wurden 95% des ursprÃ¼nglichen Blutes gespendet.","tags":"German posts","title":"Mathe-Aufgabe: Blutspende"},{"url":"https://martin-thoma.com/project-euler-problem-26/","text":"The task in Problem 26 of Project Euler is: Find the value of d < 1000 for which $\\frac{1}{d}$ contains the longest recurring cycle in its decimal fraction part. How to solve Think about how you divide with pen and paper. How do you recognize that you have a cycle? You look at the rest. If you've seen the rest before, you are just about to get into the cycle. My solution This brute force solution finds the solution instantly. #!/usr/bin/python # -*- coding: utf-8 -*- import unittest def getCycle ( p , q ): assert p >= 0 assert q > 0 while p >= q : p -= q if p == 0 : # p/q is an integer return \"\" digits = {} # map rest to digit number # for 0.1234567, 1 is the digit #0, 2 digit #1, ... i = 0 cycle = \"\" rest = p while True : digits [ rest ] = i rest *= 10 tmp = rest / q rest -= tmp * q cycle += str ( tmp ) if rest in digits : return cycle [ digits [ rest ]:] i += 1 def euler26 ( maximum = 1000 ): maxCycleLength = 0 number = 1 for i in xrange ( 1 , maximum + 1 ): tmp = len ( getCycle ( 1 , i )) if tmp > maxCycleLength : maxCycleLength = tmp number = i return ( number , maxCycleLength ) class TestSequenceFunctions ( unittest . TestCase ): def setUp ( self ): self . seq = range ( 10 ) def test_simpleSequences ( self ): self . assertEqual ( getCycle ( 4 , 2 ), \"\" ) self . assertEqual ( getCycle ( 1 , 6 ), \"6\" ) for i in xrange ( 1 , 9 ): self . assertEqual ( getCycle ( i , 9 ), str ( i )) self . assertEqual ( getCycle ( 1 , 7 ), \"142857\" ) if __name__ == '__main__' : #unittest.main() print euler26 ( 1000 )","tags":"Code","title":"Project Euler: Problem 26"},{"url":"https://martin-thoma.com/ist-die-funktion-relation-wohldefiniert/","text":"Ich verstehe unter einer wohldefinierten Funktion / Relation die UnabhÃ¤ngigkeit von den ReprÃ¤sentanten. Wikipedia sagt dazu: Man kann in der Mathematik ein Objekt nicht nur durch eine Definitionsgleichung (explizit), sondern auch durch eine charakteristische Eigenschaft (implizit) definieren. WÃ¤hrend eine explizite Definition immer zulÃ¤ssig ist, ist eine implizite Definition nur unter der Bedingung zulÃ¤ssig, dass es tatsÃ¤chlich genau ein Objekt mit der angegebenen Eigenschaft gibt. Diese Bedingung nennt man die Wohldefiniertheit der impliziten Definition. Quelle: Wohldefiniertheit Beispiel 1 Sei \\(f:\\mathbb{Q} \\rightarrow \\mathbb{Q}\\) eine Abbildung und definiert durch: \\(f(\\frac{p}{q}) := \\frac{p}{q}\\) Frage : Ist \\(f\\) wohldefiniert? Antwort : Ja. Es sei \\(\\frac{p'}{q'}\\) die vollstÃ¤ndig gekÃ¼rzte Darstellung von \\(\\frac{p}{q}\\) . Also gilt: \\(p = p' \\cdot \\lambda \\land q = q' \\cdot \\lambda\\) mit \\(\\lambda \\in \\mathbb{R} \\setminus \\{0\\}\\) . \\(\\Rightarrow \\frac{p}{q} = \\frac{p' \\cdot \\lambda}{q' \\cdot \\lambda}\\) . \\(\\Rightarrow f(\\frac{p}{q}) = \\frac{p' \\cdot \\lambda}{q' \\cdot \\lambda} = \\frac{p'}{q'}\\) . \\(\\Rightarrow f(\\frac{p}{q})\\) ist unabhÃ¤ngig vom ReprÃ¤sentanten. \\(\\Rightarrow f\\) ist wohldefiniert \\(\\blacksquare\\) Beispiel 2 Sei \\(f:\\mathbb{Q} \\rightarrow \\mathbb{Q}\\) eine Abbildung und definiert durch: \\(f(\\frac{p}{q}) := \\frac{p+1}{q}\\) Frage : Ist \\(f\\) wohldefiniert? Antwort : Nein. \\(f(\\frac{0}{1}) = \\frac{0+1}{1} = 1 \\neq \\frac{1}{2} = \\frac{0+1}{2} = f(\\frac{0}{2}) \\blacksquare\\) Beispiel 3 Sei \\(f:\\mathbb{Q} \\rightarrow \\mathbb{Q}\\) eine Abbildung und definiert durch: \\(f(\\frac{p}{q}) := \\frac{p-q}{p+q}\\) Frage : Ist \\(f\\) wohldefiniert? Antwort : Ja. Es sei \\(\\frac{p'}{q'}\\) die vollstÃ¤ndig gekÃ¼rzte Darstellung von \\(\\frac{p}{q}\\) . Also gilt: \\(p = p' \\cdot \\lambda \\land q = q' \\cdot \\lambda\\) mit \\(\\lambda \\in \\mathbb{R} \\setminus \\{0\\}\\) . \\(\\Rightarrow f(\\frac{p}{q}) = f(\\frac{\\lambda \\cdot p'}{\\lambda \\cdot q'}) = \\frac{\\lambda \\cdot p' - \\lambda \\cdot q'}{\\lambda \\cdot p' + \\lambda \\cdot q'} = \\frac{\\lambda (p' - q')}{\\lambda (p' + q')} = \\frac{p' - q'}{p' + q'} \\blacksquare\\)","tags":"Cyberculture","title":"Ist die Funktion / Relation wohldefiniert?"},{"url":"https://martin-thoma.com/sichtweite-des-burdsch-chalifa/","text":"Aufgabenstellung Der Burdsch Chalifa war 2010 das hÃ¶chste GebÃ¤ude der Erde. Bis zur Spitze sind es 830 m. Angenommen, die Erde wÃ¤re eine perfekte Kugel mit einem Radius von 6370 km und die Sicht wÃ¤re nicht durch Nebel, Wolken oder sonstige Hindernisse eingeschrÃ¤nkt. Aus welcher Entfernung, die man Ã¼ber die Erde direkt zum Burdsch Chalifa zurÃ¼cklegt, kÃ¶nnte man den Burdsch Chalifa maximal sehen? Situationsskizze Gesucht ist die LÃ¤nge des neongrÃ¼n hervorgehobenen Kreisbogens x. Rechenweg \\begin{align} x &= \\text{Umfang} \\cdot \\frac{\\varphi}{360&#94;\\circ} \\\\ &= 2 \\cdot r \\cdot \\pi \\cdot \\frac{\\cos&#94;{-1}(\\frac{r}{r+h})}{360&#94;\\circ} \\\\ &= 2 \\cdot 6370 \\text{km} \\cdot \\pi \\cdot \\frac{\\cos&#94;{-1}(\\frac{6370}{6370,83})}{360&#94;\\circ} \\\\ &= 102,8 \\text{km} \\end{align} Antwort Bei optimalen, also unrealistischen, Bedingungen kÃ¶nnte man die Spitze des Burdsch Chalifa noch in 102,8 km entfernung sehen. Dies entspricht Ã¼brigens auch dem Punkt auf der ErdoberflÃ¤che, der vom Burdsch Chalifa am weitesten entfernt und zu sehen ist. Auch wenn nur die Luftlinie gemessen wird, sind es 102,8 km, da der Erdradius bedeutend grÃ¶ÃŸer als der Burdsch Chalifa ist. Laut Bildzeitung kann man die Spitze des Burdsch Chalifa noch in 95 km sehen. Erweiterung der Aufgabenstellung Das Dorf Mileiha liegt direkt Ã¶stlich vom Burdsch Chalifa (25Â° 11' 50'' N, 55Â° 16' 27'' O). Wie weit Ã¶stlich darf das Dorf maximal liegen, damit man die Spitze des Burdsch Chalifa bei optimalen Bedingungen noch sehen kann? Hinweis: Es gelten noch immer die gleichen Voraussetzungen wie im ersten Teil der Aufgabe. Situationsskizze Gesucht ist die grÃ¼n eingezeichnete Kurve, die sich Ã¼ber die ErdoberflÃ¤che krÃ¼mmt. Ihre LÃ¤nge sei x. Um diese zu berechnen, mÃ¼ssen wir wissen welchen Radius die KreisflÃ¤che hat, die entsteht, wenn man die Erde am 25. Breitengrad schneidet. Der Radius dieser KreisflÃ¤che sei \\(r_{25}\\) . Berechnung $ \\begin{align} \\text{Breitengrad} &= 25 + \\frac{11}{60} + \\frac{50}{60 \\cdot 60} \\\\ \\text{Breitengrad} &= \\frac{9071}{360} \\approx 25,1972 \\\\ \\cos(\\frac{9071}{360}) &= \\frac{r_{25,1972}}{6370\\text{km}} \\\\ r_{25,1972} &= \\cos(\\frac{9071}{360}) \\cdot 6370\\text{km} \\\\ r_{25,1972} &\\approx 5764\\text{km} \\end{align} $ Der soeben errechnete Radius kann einfach in die im ersten Abschnitt erarbeitete Formel eingesetzt werden: $ \\begin{align} x &= 2 \\cdot r \\cdot \\pi \\cdot \\frac{\\cos&#94;{-1}(\\frac{r}{r+h})}{360&#94;\\circ} \\\\ &= 2 \\cdot 5764 \\text{km} \\cdot \\pi \\cdot \\frac{\\cos&#94;{-1}(\\frac{5764}{5764,83})}{360&#94;\\circ} \\\\ &\\approx 97,8 \\text{km} \\end{align} $ Nun sollte man noch berÃ¼cksichtigen, dass die Beobachter wohl nicht auf der Erde kriechen, sondern ihre Augen in einer HÃ¶he von ca. 1,6m sind: $ \\begin{align} x &= 2 \\cdot 5764 \\text{km} \\cdot \\frac{\\pi}{360&#94;\\circ} \\cdot ( \\cos&#94;{-1}(\\frac{5764}{5764,83}) + \\cos&#94;{-1}(\\frac{5764}{5764,0016}) \\\\ &\\approx 102 \\text{km} \\end{align} $ Antwort Der am weitesten entfernte Punkt, der direkt Ã¶stlich vom Burdsch Chalifa steht und von dem aus die Spitze des Burdsch Chalifa unter optimalen Bedinungen noch erkannt werden kann, liegt ca. 102 km entfernt. Anmerkung: Mileiha liegt ca. 60 km vom Burdsch Chalifa entfernt. Er mÃ¼sste also von Mileiha zu sehen sein.","tags":"German posts","title":"Sichtweite des Burdsch Chalifa"},{"url":"https://martin-thoma.com/entwurfsmuster-beispiele/","text":"Singleton Zweck : Stelle sicher, dass es nur eine Instanz dieser Klasse gibt. Beispiel : java.lang.Runtime.getRuntime() public class Singleton { // an instance of a singleton private static Singleton instance = null ; // private default constructor to prevent the external creation // of more instances private Singleton () { } // static method which returns the instance public static synchronized Singleton getInstance () { if ( instance == null ) { instance = new Singleton (); } return instance ; } } Bequemlichkeitsklasse Zweck : Faulheit - mache Methodenaufrufe durch Ã¤nderbare default-Parameter einfacher. Das Bequemlichkeitsmuster ist einfach das Ãœberladen einer Methode: public class Bequemlichkeitsklasse { // convenience class int v1 , v2 , v3 ; int anfrage ( int p1 , int p2 , int p3 ) { return p1 * p2 * p3 ; } int anfrage ( int p1 ) { return anfrage ( p1 , v2 , v3 ); } int anfrage () { return anfrage ( v1 , v2 , v3 ); } void setzeZustand ( int p1 , int p2 , int p3 ) { v1 = p1 ; v2 = p2 ; v3 = p3 ; } } Schablonenmethode Siehe Java Puzzle #9: Template method pattern . Siehe auch Examples of GoF Design Patterns in Java","tags":"German posts","title":"Entwurfsmuster-Beispiele"},{"url":"https://martin-thoma.com/java-puzzle-9-template-method-pattern/","text":"The following Java Puzzle is an example for the template method pattern . It is a design pattern by the Gang of Four . What is the output of the following snippet: AbstractClass.java : public class AbstractClass { int templateMethod () { return simpleOperation1 () * simpleOperation2 (); } int simpleOperation1 () { return 2 ; } int simpleOperation2 () { return 3 ; } } ConcreteClass.java : public class ConcreteClass extends AbstractClass { @Override int simpleOperation1 () { return 5 ; } @Override int simpleOperation2 () { return 7 ; } } test.java : public class test { public static void main ( String [] args ) { ConcreteClass t = new ConcreteClass (); System . out . println ( t . templateMethod ()); } } . . . . . . . . . . . . . . . . . Answer 35 35 Explanation You can think of it like this: First, you create the empty class ConcreteClass . It has only the methods inherited by Object like the constructor , equals() and toString() . Then it gets extended by AbstractClass with templateMethod() , simpleOperation1() and simpleOperation2() . After that, the method overrides simpleOperation1() and simpleOperation2() , but templateMethod() uses them. It uses the methods that are now in ConcreteClass . I don't know what Java exactly does internally, but thats a good way to think about it. If somebody has more information, please share it as a comment!","tags":"Code","title":"Java Puzzle #9: Template method pattern"},{"url":"https://martin-thoma.com/java-puzzle-8-interfaces-and-visibility/","text":"What is the output of the following snippets: Shape.java : public interface Shape { public void draw (); private void calculateArea (); public void printArea (); } Rectangle.java public class Rectangle implements Shape { private final int x1 , x2 , y1 , y2 ; private int area ; public Rectangle ( int x1 , int y1 , int x2 , int y2 ) { this . x1 = x1 ; this . x2 = x2 ; this . y1 = y1 ; this . y2 = y2 ; } @Override public void calculateArea () { area = Math . abs (( x1 - x2 ) * ( y1 - y2 )); } @Override public void draw () { // TODO Auto-generated method stub } @Override public void printArea () { calculateArea (); System . out . println ( \"My area is \" + area + \".\" ); } } test.java : public class test { public static void main ( String [] args ) { Shape s = new Rectangle ( 0 , 0 , 1 , 1 ); s . printArea (); } } . . . . . . . . . . . . . . Answer My area is 1 . Explanation Interfaces may not implement anything. So it makes no sense to define private methods. Nevertheless it seems to be valid Java code.","tags":"Code","title":"Java Puzzle #8: Interfaces and Visibility"},{"url":"https://martin-thoma.com/short-educational-clips/","text":"Here are some clips which are interesting for education. For example, one of then explains the history of the English language in about 10 minutes. 60-Second Adventures in Thought United Kingdom, Great Britain and England History of English Electric Vocabulary DNA Song Wakko's 50 State Capitols Yakko's World The Monty Hall Problem See also TEDEducation","tags":"Cyberculture","title":"Short Educational Clips"},{"url":"https://martin-thoma.com/endliche-gruppen/","text":"Endliche Gruppen haben ein paar interessante Eigenschaften. Unter anderem gibt es nur zwei Gruppen mit vier Elementen. alle anderen Gruppen sind isomorph zu diesen Gruppen. Das zeige ich im folgendem. Gruppen mit vier Elementen Es gibt genau zwei Gruppen mit vier Elementen. Das sind: \\(G_1 = (\\mathbb{Z}/4\\mathbb{Z}, +)\\) und \\(G_2 = (\\mathbb{Z}/2\\mathbb{Z} \\times \\mathbb{Z}/2\\mathbb{Z}, +)\\) Beweis Teil 1: G 1 und G 2 sind Gruppen Eine Gruppe \\((A, \\circ)\\) mÃ¼ssen drei Eigenschaften erfÃ¼llen: (G1) AssoziativitÃ¤t : \\(\\forall a,b,c \\in A: (a \\circ b) \\circ c = a \\circ (b \\circ c)\\) (G2) Neutrales Element : \\(\\exists e \\in A \\forall a \\in A: e \\circ a = a \\circ e = a\\) (G3) Inverses Element : \\(\\forall a \\in A \\exists a&#94;{-1} \\in A: a \\circ a&#94;{-1} = a&#94;{-1} \\circ a = e\\) Die VerknÃ¼pfungstafel fÃ¼r \\(G_1\\) lautet: + 0 1 2 3 0 0 1 2 3 1 1 2 3 0 2 2 3 0 1 3 3 0 1 2 Man sieht direkt an der Tabelle, dass 0 das neutrale Element ist und jedes Element ein Inverses hat. FÃ¼r die AssoziativitÃ¤t fÃ¤llt mir nichts besseres ein, als die 64 MÃ¶glichkeiten alle auszuprobieren. Geht das kÃ¼rzer? Die VerknÃ¼pfungstafel fÃ¼r \\(G_2\\) lautet: + (0,0) (0,1) (1,0) (1,1) (0,0) (0,0) (0,1) (1,0) (1,1) (0,1) (0,1) (0,0) (1,1) (1,0) (1,0) (1,0) (1,1) (0,0) (0,1) (1,1) (1,1) (1,0) (0,1) (0,0) Das neutrale Element ist hier also (0,0) . Beweis Teil 2: Es gibt keine weiteren Gruppen HierfÃ¼r ist es sehr hilfreich zu wissen, dass die VerknÃ¼pfungstafel einer Gruppe immer alle Elemente sowohl in jeder Spalte, als auch in jeder Zeile hat. Dann kann man es Sudoku-mÃ¤ÃŸig beweisen. Folgendes Skelett gilt immer: + e a b c e e a b c a a b b c c #1: e auf (1,1) Wir haben nun folgende Tabelle: + e a b c e e a b c a a e c b b b c c c b \\(b + a = c\\) (da a und e in dieser Spalte sind und b in der Zeile ist) \\(c + a = b\\) (nur b fehlt in der Spalte) \\(a + b = c\\) (da a und e in dieser Zeile und b in der Spalte bereits vorkommt) \\(a + c = b\\) (nur b fehlt in der Zeile) #1.1: e auf (2,2) + e a b c e e a b c a a e c b b b c e a c c b a e $c + c = e$ (genau 1 e pro Zeile / Spalte) $b + c = a$ (nur a fehlt in der Zeile) $c + b = a$ (nur a fehlt in der Zeile) Diese LÃ¶sung enstpricht \\(G_2\\) . #1.2: a auf (2, 2) + e a b c e e a b c a a e c b b b c a e c c b e a $b + c = e$ (genau 1 e pro Zeile / Spalte) $c + b = e$ (genau 1 e pro Zeile / Spalte) $c + c = a$ (nur a fehlt in der Zeile) Das entspricht \\(G_1\\) . Das sieht man, wenn man ... ... die Spalte a und b tauscht ... die Zeilen a und b tauscht ... die Elemente a und b tauscht #2: b auf (1, 1) + e a b c e e a b c a a b c e b b c e a c c e a b $b + a = c$ (da $c + a \\neq c$ und c noch nicht in der Spalte ist, aber dennoch vorkommen muss) $c+a =e$ (genau 1 e pro Zeile / Spalte) $c+b = a$ (da c und e in der Zeile bereits vorkommen und b in der Spalte ist) $c+c = b$ (da der Rest schon in der Zeile ist) $b+b = e$ (da a und b in der Spalte sind, c in der Zeile) $b+c = a$ (da der Rest in der Zeile schon vorkommt) $a+b = c$ ( - \" - ) $a+c = e$ Das enspricht wieder \\(G_1\\) . #3: c auf (1, 1) + e a b c e e a b c a a c e b b b e c a c c b a e $a+b = e$ (a, c bereits in Zeile, b in Spalte) $a+c = b$ (a, c, e in Zeile) $b+a = e$ (a, c in Spalte, b in Zeile) $c+c = e$ (letztes e) $b+c = a$ (b, c, e in Spalte) $b+b = c$ (b, e, a in Zeile) $c+a = b$ (a, c, e in Spalte) $c+b = a$ (b, e, c in Spalte) Das entspricht \\(G_1\\) . Das sieht man, wenn man ... ... die Spalte b und c tauscht ... die Zeilen b und c tauscht ... die Elemente b und c tauscht","tags":"German posts","title":"Endliche Gruppen"},{"url":"https://martin-thoma.com/permutationen-und-transpositionen/","text":"Permutation Definition Es sei M eine endliche Menge. Eine bijektive Selbstabbildung von M heiÃŸt Permutation . Die Menge $S_M$ der Permutationen von M ist eine Gruppe bezÃ¼glich der Verkettung $\\circ$ von Abbildungen und heiÃŸt symmetrische Gruppe von M. Quelle: Skript von Herrn Prof. Dr. Leuzinger, KIT Allgemeines Es ist nun egal, ob ich die Permutationen von {1, 2, 3} oder {42, 1337, ABC} anschaue. Es sind einfach nur drei Objekte, die unterscheidbar sind. Um es einfacher zu machen, gehen wir nun von den Objekten {1, 2, ..., m} aus. Alle Permutationen dieser Objekte bilden eine Gruppe. Diese nennen wir \\(S_m\\) . Ein einzelnes Element aus \\(S_m\\) wird meist \\(\\pi\\) oder \\(\\sigma\\) genannt, also \\(\\pi \\in S_m\\) . Da \\(\\pi\\) eine Permutation ist, ist es insbesondere eine bijektive Selbstabbildung, also: $$M = {1, ..., m}$$ $$\\pi: M \\rightarrow M$$ $$i \\mapsto \\pi(i)$$ Kurz schreibt man auch: (\\pi = \\begin{pmatrix} 1 & 2 & 3 & ... & m\\\\ \\pi(1) & \\pi(2) & \\pi(3) & ... & \\pi(m) \\end{pmatrix} ) Anzahl der Permutationen Wenn ich n Elemente habe, die ich auf n PlÃ¤tze verteilen muss: Wie viele unterschiedliche Zuordnungen von Elementen zu den PlÃ¤tzen gibt es? Die Antwort ist \\(n! = 1 \\cdot 2 \\cdot ... (n - 1) \\cdot n = \\prod_{i=1}&#94;n i\\) . FÃ¼r das erste Element sind \\(n\\) PlÃ¤tze frei. Das Zweite kann nur noch auf \\((n-1)\\) PlÃ¤tze verteilt werden, ... , das letzte hat nur noch einen Platz zur \"Auswahl\". Erzeugung der Permutationen Angenommen, man muss in einem Test \\(S_3\\) explizit angeben. Wie geht das? Nun, zu erst erzeugt man alle Permutationen. DafÃ¼r rechnet man sich die Anzahl aus. Es gibt 3 Elemente, also \\(3 \\cdot 2 \\cdot 1 = 6\\) Permutationen: 1. _ 2. _ 3. _ 4. _ 5. _ 6. _ _ _ Nun zuerst zum ersten Element, der 1. Diese kann ich an die erste, die zweite oder die dritte Stelle verschieben. Also: 1. 1 _ 2. 1 _ 3. _ 1 4. _ 1 5. _ 1 6. _ 1 Nun zum zweiten Element, der 2. Wieder das gleiche Prinzip: Und nun nur noch das letzte EinfÃ¼llen: 1. 1 2 _ 2. 1 _ 2 3. 2 1 _ 4. _ 1 2 5. 2 _ 1 6. _ 2 1 1. 1 2 3 2. 1 3 2 3. 2 1 3 4. 3 1 2 5. 2 3 1 6. 3 2 1 Und nun noch als Menge in der mathematischen Schreibweise aufschreiben: (S_3 = \\left { \\underbrace{ \\begin{pmatrix} 1 & 2 & 3 \\\\ 1 & 2 & 3 \\end{pmatrix} } {\\pi_1}, \\underbrace{ \\begin{pmatrix} 1 & 2 & 3 \\\\ 1 & 3 & 2 \\end{pmatrix} } , \\underbrace{ \\begin{pmatrix} 1 & 2 & 3 \\\\ 2 & 1 & 3 \\end{pmatrix} } {\\pi_3}, \\underbrace{ \\begin{pmatrix} 1 & 2 & 3 \\\\ 3 & 1 & 2 \\end{pmatrix} } , \\underbrace{ \\begin{pmatrix} 1 & 2 & 3 \\\\ 2 & 3 & 1 \\end{pmatrix} } {\\pi_5}, \\underbrace{ \\begin{pmatrix} 1 & 2 & 3 \\\\ 3 & 2 & 1 \\end{pmatrix} } \\right }) Verkettung Was passiert, wenn ich die Permuation \\(\\pi_2\\) mit der Permutation \\(\\pi_3\\) verkette? Also: (\\pi_x(i) = \\pi_2(\\pi_3(i)) = \\begin{pmatrix}1 & 2 & 3\\\\ 3 & 1 & 2 \\end{pmatrix} = \\pi_6) Aber: (\\pi_y(i) = \\pi_3(\\pi_2(i)) = \\begin{pmatrix}1 & 2 & 3\\\\ 2 & 3 & 1 \\end{pmatrix} = \\pi_5 \\neq \\pi_6) Die Verkettung von Permutationen ist also nicht kommutativ! Es ergibt sich insgesamt folgende VerknÃ¼fungstabelle (gelesen wird: Zeile zuerst, Spalte spÃ¤ter): \\(\\pi_1\\) \\(\\pi_2\\) \\(\\pi_3\\) \\(\\pi_4\\) \\(\\pi_5\\) \\(\\pi_6\\) \\(\\pi_1\\) \\(\\pi_1\\) \\(\\pi_2\\) \\(\\pi_3\\) \\(\\pi_4\\) \\(\\pi_5\\) \\(\\pi_6\\) \\(\\pi_2\\) \\(\\pi_2\\) \\(\\pi_1\\) \\(\\pi_5\\) \\(\\pi_6\\) \\(\\pi_3\\) \\(\\pi_4\\) \\(\\pi_3\\) \\(\\pi_3\\) \\(\\pi_4\\) \\(\\pi_1\\) \\(\\pi_2\\) \\(\\pi_6\\) \\(\\pi_5\\) \\(\\pi_4\\) \\(\\pi_4\\) \\(\\pi_3\\) \\(\\pi_6\\) \\(\\pi_5\\) \\(\\pi_1\\) \\(\\pi_2\\) \\(\\pi_5\\) \\(\\pi_5\\) \\(\\pi_6\\) \\(\\pi_2\\) \\(\\pi_1\\) \\(\\pi_4\\) \\(\\pi_3\\) \\(\\pi_6\\) \\(\\pi_6\\) \\(\\pi_5\\) \\(\\pi_4\\) \\(\\pi_3\\) \\(\\pi_2\\) \\(\\pi_1\\) Man sieht nun, und das finde ich durchaus erstaunlich, man landet immer wieder in \\(S_3\\) . Durch die VerknÃ¼pfung von Permutationen kommt also immer wieder eine Permutation heraus! Das bedeutet, () ist unter dieser VerknÃ¼pfung abgeschlossen. Man kann nun auch noch sehen, jedes Element aus \\((S_3, \\circ)\\) ein inverses hat, da in jeder Zeile ein mal \\(\\pi_1\\) vorkommt. AuÃŸerdem ist \\((S_3, \\circ)\\) assoziativ. Kurz: \\((S_3, \\circ)\\) ist eine Gruppe, die jedoch nicht abelsch ist. Es wurde in der Vorlesung auch gezeigt, dass allgemein \\((S_m, \\circ)\\) eine Gruppe ist. Die Fehlstandszahl Es sei $\\pi \\in S_m$ eine Permutation. Die Fehlstandszahl $F(\\pi)$ von $\\pi$ ist die (eindeutige) Anzahl der FÃ¤lle, in denen fÃ¼r $i < k$ gilt $\\pi(i) > \\pi(k)$ . Die Permutationen mit gerader Fehlstandszahl $F(\\pi)$ heiÃŸen gerade, die Permutationen mit ungerader Fehlstandszahl heiÃŸen ungerade. Beispiele (\\pi_1 = \\begin{pmatrix} 1 & 2 & 3 \\\\ 1 & 2 & 3 \\end{pmatrix} ) hat die Fehlstandszahl 0. (\\pi_2 = \\begin{pmatrix} 1 & 2 & 3 \\\\ 1 & 3 & 2 \\end{pmatrix} ) hat die Fehlstandszahl 1, da \\(i = 2 < 3 = k\\) gilt, aber \\(\\pi_2(2) = 3 > 2 = \\pi_2(3)\\) . (\\pi_3 = \\begin{pmatrix} 1 & 2 & 3 \\\\ 2 & 1 & 3 \\end{pmatrix} ) hat die Fehlstandszahl 1. (\\pi_4 = \\begin{pmatrix} 1 & 2 & 3 \\\\ 3 & 1 & 2 \\end{pmatrix} ) hat die Fehlstandszahl 2. (\\pi_5 = \\begin{pmatrix} 1 & 2 & 3 \\\\ 2 & 3 & 1 \\end{pmatrix} ) hat die Fehlstandszahl 2. (\\pi_6 = \\begin{pmatrix} 1 & 2 & 3 \\\\ 3 & 2 & 1 \\end{pmatrix} ) hat die Fehlstandszahl 2. Transposition Eine Transposition ist eine Permutation aus $S_m$, bei der zwei verschiedene, fest gewahlte Zahlen $i, k \\in \\{1, 2, ..., m\\}$ vertauscht werden, wÃ¤hrend alle anderen Zahlen fest bleiben. Man schreibt fur diese Transposition auch kurz $(i~k)$. Transpositionen werden gerne mit \\(\\tau\\) abgekÃ¼rzt. Also: \\(\\pi_2 = (2~3), \\pi_3=(1~2), \\pi_6 = (1~3)\\) sind Transpositionen. \\(\\pi_1, \\pi_4, \\pi_5\\) sind keine Transpositionen. Es gilt: \\(\\tau \\circ \\tau = id\\) wir haben in der Vorlesung gezeigt: Jede Permutation \\(\\pi \\in S_m, m \\geq 2,\\) lÃ¤sst sich als Verkettung von Transpositionen darstellen. Beispiel: (\\sigma = \\begin{pmatrix}1 & 2 & 3 & 4 & 5 & 6 \\\\ 6 & 5 & 4 & 1 & 3 & 2\\end{pmatrix} = (1~6) \\circ (2~5) \\circ (3~4) \\circ (4~6) \\circ (5~6)) Gelesen wird das ganze von rechts nach links. Die Transposition \\((5~6)\\) wird also zuerst angewendet. Wie bei Abbildungen die verkettet werden halt auch. Die Fehlstandszahl von \\(\\sigma\\) ist 13 und die Anzahl der Transpositionen ist ungerade. Interessanterweise gilt auch \\(\\sigma = (1~4) \\circ (3~5) \\circ (2~6) \\circ (1~3) \\circ (1~2)\\) . AuÃŸerdem kann man beliebig hÃ¤ufig eine Transposition doppelt hinzufÃ¼gen, da es ja die IdentitÃ¤t ist. Die Darstellung einer Permutation als folge von Transpositionen ist also nicht eindeutig. Siehe auch Wikipedia: Permutation","tags":"German posts","title":"Permutationen und Transpositionen"},{"url":"https://martin-thoma.com/flags-of-the-earth/","text":"Flags of the Earth Go to the Game : Flags on Kongregate Task : Say which country the shown flag belongs to. How to play : Click on on of the 4 - 5 countries. My Record : 40 Flags and 12662 points.","tags":"Cyberculture","title":"Flags of the Earth"},{"url":"https://martin-thoma.com/klausur-lineare-algebra-i-ii/","text":"Dieser Artikel richtet sich vor allem an Studenten, die im Sommersemester 2012 bei Herrn Prof. Dr. Leuzinger am KIT die Klausur Ã¼ber Lineare Algebra und analytische Geometrie schreiben werden. Was ich im folgenden unter \"Themen\" schreibe, wurde von Prof. Dr. Leuzinger in der letzten Stunde aufgeschrieben. Das habe ich als Grundlage genommen und ergÃ¤nzt. Er gab folgende Tipps: Zeitplan aufstellen Aktiv lernen Ich kann als Tipp fÃ¼r die Klausur noch sagen: Wenn du eine Aufgabe (b) machst, Ã¼berleg dir, ob dir die Ergebnisse aus (a) helfen kÃ¶nnen! In den LA-Klausuren, die ich bisher gesehen habe, hat die vorangehende Teilaufgabe sehr hÃ¤ufig eine Hilfestellung geboten. Vorbereitung Lineare Algebra I Ihr solltet auf jeden Fall die Lernkontrolle: Lineare Algebra I machen. Themen Gruppen : Untergruppe, Homomorphismus/Isomorphismus, \\(GL(n, \\mathbb{K})\\) KÃ¶rper : \\(\\mathbb{R}, \\mathbb{C}, \\mathbb{Z}/p\\mathbb{Z}\\) (insbesondere \\(p=2\\) ) VektorrÃ¤ume : Basis, BasisergÃ¤nzungssatz, Dimension, Basiswechsel, \\(V \\cong \\mathbb{K}&#94;n\\) (fÃ¼r \\(\\dim V = n\\) ); \\(\\dim (U_1 \\oplus U_2) = \\dim U_1 + \\dim U_2\\) Lineare Abblidungen (Definitionen, Beispiele): Lineare Fortsetzung, \\(\\phi: V \\rightarrow W\\) Dimensionssatz \\(\\dim \\text{Bild} \\phi = \\dim V - \\dim \\phi&#94;2\\) \\(\\text{Hom}(V, W) \\cong \\mathbb{K}&#94;{m \\times n}\\) Abbildungsmatrix Dualraum : \\(W = \\mathbb{R}\\) , \\(V&#94;* = \\text{Hom}(V, \\mathbb{K})\\) \\(\\phi: V \\rightarrow W\\) A \\(\\phi: W* \\rightarrow V*\\) \\(A&#94;T\\) duale Basis, duale Abbildung Basiswechsel fÃ¼r Endomorphismen, Formel \\(\\tilde{A} = S&#94;{-1} A S\\) , S = Matrix des Basiswechsels Determinante : Laplacesche Entwicklungsformel (z.B. nach i-ter Spalte) \\(\\det A&#94;T = \\det A\\) \\(\\det(A \\cdot B) = \\det A \\cdot \\det B\\) \\(\\det(A&#94;{-1}) = \\frac{1}{\\det A}\\) \\(\\det \\begin{pmatrix}A & * \\\\0 & B\\end{pmatrix} = \\det A \\cdot det(B)\\) (\"KÃ¤stchensatz\") Bei beliebig groÃŸen Matrizen Ã  la \\(A \\in \\mathbb{R}&#94;{n \\times n}\\) gibt es ein paar Dinge, die beim Suchen der Determinante hilfreich sein kÃ¶nnen: Ist die Matrix symmetrisch? Falls ja, muss man sich nur die Zeilen anschauen. Falls nein, kÃ¶nnen die folgenden Tipps sowohl fÃ¼r die Zeilen als auch fÃ¼r die Spalten Ã¼berprÃ¼ft werden. NÃ¼tzt es etwas, wenn ich auf die letzte Zeile alle vorherigen Zeilen addiere? Was passiert, wenn ich Zeile \\(i\\) auf Zeile \\((i+1)\\) addiere fÃ¼r \\(i \\in 1, ..., (n-1)\\) ? Wie bestimme ich das Inverse einer Matrix? LÃ¶sungstheorie von LGSen (GauÃŸ-Algorithmus) Eigenwerte , Eigenvektoren ( \\(\\phi(x) = \\lambda x, x \\neq 0\\) ) charakteristisches Polynom \\(\\phi|_{[x]} = \\lambda_{id_{[x]}}\\) - Wie berechnet man das charakteristische Polynom? \\(\\mathbb{K} = \\mathbb{C} \\leadsto\\) Jordansche Normalform (Algorithmus) Aufgabenstellungen Mit diesen Aufgabentypen sollte man rechnen: Gegeben sind zwei UntervektorrÃ¤ume \\(U, V\\) des \\(\\mathbb{R}&#94;4\\) . Finden Sie jeweils eine Basis von \\(U, V, U \\cap V, U + V\\) . â†’ ErklÃ¤rung Bestimmen Sie alle LÃ¶sungen eines Gleichungssystems (auch in endlichen KÃ¶rpern wie \\(\\mathbb{Z} / 5 \\mathbb{Z}\\) !). Bestimmen Sie die Jordansche Normalform einter Matrix A. â†’ ErklÃ¤rung Good to know Ã„hnlichkeitsinvariante Matrizeneigenschaften: Rang Spur Determinante Jordansche Normalform Charakteristisches Polynom Wie findet man heraus, ob zwei Matrizen Ã¤hnlich sind? Wann sind Matrizen regulÃ¤r? Siehe auch Ãœbersicht Ã¼ber algebraische Strukturen Zusammenfassung auf next-indernet.com Lineare Algebra II Themen VektorrÃ¤ume mit Skalarprodukt (Definition, Beispiele, $\\mathbb{K} \\in \\{\\mathbb{R}, \\mathbb{C}\\}$) $G = G&#94;T$ ($\\mathbb{K} = \\mathbb{R}$) $G = \\bar{G}&#94;T$ ($\\mathbb{K} = \\mathbb{C}$) Basiswechsel $\\tilde{G} = S&#94;T G S$ (allgemeiner Basiswechsel) Basiswechsel $\\tilde{G} = S&#94;{-1} G S$ (fÃ¼r ONB, da $S&#94;{-1} = S&#94;T$) Skalarprodukt induziert eine Norm, $\\| x \\| = \\sqrt{\\langle x, x \\rangle}$ Parallelogramm-IdentitÃ¤t: $\\|a+b\\|&#94;2 + \\|a-b\\|&#94;2 = 2 \\cdot (\\|a\\|&#94;2 + \\|b\\|&#94;2)$ $\\cos \\omega(a,b) = \\frac{\\langle a, b \\rangle}{\\|a\\| \\cdot \\| b \\|}$ Orthogonal, ONB, Orthogonal-Komplement $x \\perp y$, $\\langle x, y \\rangle = 0$ orthogonale / unitÃ¤re Matrizen: $S \\cdot S&#94;T = E$ $\\det S \\cdot \\det S&#94;T = \\det E = 1$ $U \\cdot \\bar U&#94;T = E$ Gram-Schmidtsches Orthogonalisierungsverfahren : $w_j = v_j - \\sum_{i=1}&#94;{j-1} \\frac{\\langle v_j, w_i \\rangle}{\\langle w_i, w_i \\rangle} \\cdot w_i$ Projektion eines Vektors auf eine Ebene (ÃœB 4, A3) \"Gute\" Abbildungen bzgl. $\\langle, \\rangle: \\phi: V \\rightarrow V$ (Selbst-)adjungierte: $\\langle \\phi(x), y \\rangle = \\langle x, \\phi*(y) \\rangle \\rightarrow A = A&#94;T$ Lineare Isometrien $\\langle \\phi(x), \\phi(y) \\rangle \\rightarrow A$ orthogonal $\\varphi$ heiÃŸt lineare Isometrie $:\\Leftrightarrow \\langle \\varphi(x), \\varphi(y) \\rangle = \\langle x, y \\rangle$ Abbildungsmatrizen bzgl. ONB Spektralsatz: $\\phi s.a. \\Rightarrow \\phi \\text{ diagonalisierbar}, \\exists S \\in O(n) \\text{ mit } S&#94;{-1} A S = D$. Abbildungsmatrizen bzgl. ONB $\\phi$ s.a. Basis: ONB $\\Rightarrow$ Abb. Matrix symmetrisch, aber noch mehr: $\\exists$ ONB aus EV mit Abb. Matrix = Diagonalmatrix (Spektralsatz) $\\phi$ lin. Isometrie, Basis ONB $\\Rightarrow$ Abb. Matrix ist orthogonal / unitÃ¤r, aber noch mehr: $\\exists$ ONB mit Abb. in euklid NF Berechnung der euklidischen Normalform Kiterien fÃ¼r pos. definit (Ist geg. BF $\\beta$ ein SP?) Hauptachsentransformation $(V, \\langle , \\rangle)$ VR mit SP. $\\beta = $ Bilinearform kann man simultan diagonalisieren $\\exists$ ONB von $V$, so dass Matrix von $\\langle, \\rangle E_n$ (nach Definition von ONB) Hurwitz-Kriterium Affine / Euklidische Geometrie \\(\\operatorname{Aff}(\\mathbb{R}&#94;n), \\mathrm{Iso}(\\mathbb{R}&#94;n)\\) Gruppe der AffinitÃ¤t bzgl. Isometrie Lernplan Es empfiehlt sich, einen Lernplan aufzustellen. Wenn ich die ÃœbungsblÃ¤tter mache, dann lese ich mir zuerst die relevanten Kapitel im Skript durch. Termine und Klausurablauf Datum : Donnerstag, den 13. September 2012 von 08:00 bis 13:00 Uhr Ort : bei mir: Neue Chemie HÃ¶rsaal am Fasanengarten (â†’ HÃ¶rsaaleinteilung ) Dauer : 2 h LA I, 1 h Pause, 2 h LA II Punkte : 6 Aufgaben Ã  4 Punkte fÃ¼r LA I, 6 Aufgaben Ã  4 Punkte fÃ¼r LA II Geschwindigkeit : \\(\\frac{5 \\text{ Minuten}}{\\text{Punkt}}\\) Ãœbungsschein : Noch nicht im Studierendenportal (Stand: 11.09.2012) Bonuspunkte : Gibt es nicht. Nicht vergessen : Studentenausweis Leere BlÃ¤tter Essen und Trinken (4h Klausur!!!) Ein paar interessante Aussagen: In den letzten Jahren reichten 20 Punkte zum bestehen In den letzten Jahren wurde jeweils im LA I und in LA II der beste Teil doppelt bepunktet Es gab bisher nur eine Gesamtnote fÃ¼r LA I und II, man musste die beiden Tests also nicht einzeln bestehen. Ergebnisse Ich habe den Ãœbungsleiter mal angeschrieben. Das war seine Antwort: Der Termin ist normalerweise in der ersten Vorlesungswoche. Er wird auf der Kurshomepage rechtzeitig bekannt gegeben. Die Ergebnisse der Klausur werden am Freitag, den 05.10.2012, im AllianzgebÃ¤ude am schwarzen Brett neben 4A-09 ausgehÃ¤ngt. Das ist vermutlich im Allianzbau. Die Klausureinsicht findet am Montag, den 15.10.2012 von 15:00 - 16:30 Uhr im Raum 1C-03 im AllianzgebÃ¤ude statt.","tags":"German posts","title":"Klausur Lineare Algebra I + II"},{"url":"https://martin-thoma.com/globetrotter/","text":"Globetrotter - A game to learn cities and countries Go to the Game : Globetrotter XL on Kongregate Task : Find a city on a map How to play : You're given the name of a city and its country and a map. In the first levels this map has borders, but no names of countries or cities. In the later levels even the borders are not shown. My Record : Level 6, about 1400 points","tags":"Cyberculture","title":"Globetrotter"},{"url":"https://martin-thoma.com/java-puzzle-7-inheritance-and-visibility/","text":"You are given the following two classes: Animal.java : public class Animal { private final int height = 120 ; } Tiger.java : public class Tiger extends Animal { public int height ; } What is the output of the following three snippets: test1.java : public class test1 { public static void main ( String [] args ) { Tiger t = new Tiger (); System . out . println ( t . height ); } } test2.java : public class test2 { public static void main ( String [] args ) { Animal t = new Tiger (); System . out . println ( t . height ); } } test3.java : public class test3 { public static void main ( String [] args ) { Animal t = new Animal (); System . out . println ( t . height ); } } . . . . . . . . . . . . . . . . . . . . . . . . . . Answer test1.java : 0 test2.java : Exception in thread \"main\" java.lang.Error: Unresolved compilation problem: The field Animal.height is not visible at test.main ( test.java:4 ) test3.java : Exception in thread \"main\" java.lang.Error: Unresolved compilation problem: The field Animal.height is not visible at test.main ( test.java:4 )","tags":"Code","title":"Java Puzzle #7: Inheritance and Visibility"},{"url":"https://martin-thoma.com/java-puzzle-6-double-arithmetic/","text":"What is the output of the following snippet? public class test { public static void main ( String [] args ) { double a = 1.3378901234567877 ; double b = 0.0008901234567876 ; double c = a - b ; if ( c == 1.337 ) { System . out . println ( \"Hallo doubles!\" ); } else { System . out . println ( \"Oh no! Comparison failed!\" ); } } } . . . . . . . . . . . . . . . . . Solution Oh no! Comparison failed! Explanation Doubles are internally represented using the IEEE 754 standard ( source ). This means, doubles are not represented with arbitrary precision. Just execute this snippet: public class test { public static void main ( String [] args ) { double a = 1.3378901234567876 ; System . out . println ( \"a = \" + a ); double b = 0.0008901234567876 ; System . out . println ( \"b = \" + b ); double c = a - b ; System . out . println ( \"c = \" + c ); } } Output: a = 1 .3378901234567877 b = 8 .901234567876E-4 c = 1 .3370000000000002 Resolve problem Use an appropriate epsilon to compare floats/doubles: public class test { public static void main ( String [] args ) { double a = 1.3378901234567877 ; double b = 0.0008901234567876 ; double c = a - b ; double EPSILON = 0.000000000000001 ; if ( Math . abs ( c - 1.337 ) < EPSILON ) { System . out . println ( \"Hallo doubles!\" ); } else { System . out . println ( \"Oh no! Comparison failed!\" ); } } }","tags":"Code","title":"Java Puzzle #6: Double Arithmetic"},{"url":"https://martin-thoma.com/ubersicht-der-pfeile-in-uml/","text":"Folgende Pfeile werden in UML verwendet: Klassendiagramme Vererbung Class B erbt von Class A; Class A ist die Oberklasse Die Vererbung ist eines der wichtigsten Prinzipien der objektorientierten Programmierung. Sie zeigt eine \"ist ein\"-Beziehung an. Beispiele sind: Tiger ist eine GroÃŸkatze ist eine Katze ist ein Raubtier ist ein Tier . Auto ist ein Fortbewegungsmittel . Auto ist ein Luxusgut . Beachte dass Auto hier sowohl von Luxusgut , als auch von Fortbewegungsmittel erbt. Das geht in manchen Programmiersprachen (C++, Python), in anderen nicht (Java). Assoziation Assoziation Die Assoziation zeigt eine Verbindung an, z.B.: Person - Termin: Eine Person hat Termine; Termine gehÃ¶ren zu einer Person. Lehrer - SchÃ¼ler: Ein SchÃ¼ler hat Lehrer; Lehrer haben SchÃ¼ler. Auto - Fahrer: Ein Auto hat einen Fahrer; ein Fahrer hat ein Auto. In einer Datenbank wÃ¼rde man fÃ¼r diese Relationen eine weitere Tabelle erstellen. Also eine Tabelle fÃ¼r Personen, eine fÃ¼r Termine und eine fÃ¼r Person-Termin-VerknÃ¼pfungen. Aggregation Aggregation Die Aggregation ist eine spezielle Assoziation. Sie zeigt eine \"hat\"-Beziehung an. Dabei ist die Richtung wichtig und sollte angezeigt werden. Aggregationen sind z.B.: PKW hat RÃ¤der Eltern haben Kinder Buchladen hat BÃ¼cher Komposition Komposition Die Komposition zeigt eine notwendige \"ist-Teil-von\" Beziehung an. Das Teil kann also nicht ohne das Ganze existieren. Beispiele sind: Buch hat Buchseiten (Buchseiten gibt es nicht ohne Buch) Rechnung hat Posten (Rechnungsposten gibt es nicht ohne Rechnung) Graph hat Knoten (Knoten gibt es nicht ohne Graph) Weitere Die Benutzt-Relation wird als gestrichelter Pfeil mit nicht-ausgefÃ¼lltem Kopf dargestellt. Eine Implementierung wird als gestrichelter Pfeil mit rundem, nicht ausgefÃ¼lltem Kopf dargestellt. Objektdiagramme UML: instanceOf beziehung in einem Objektdiagramm Sequenzdiagramme Sequenzdiagramme haben wieder eigene Pfeile. UML Sequenzdiagramm Der Pfeil mit der ausgefÃ¼llten Spitze ist eine Synchrone Nachricht, der gestrichelte mit der nicht-ausgefÃ¼llten Spitze ist eine Antwort und der durchgezogenen Pfeil mit der nicht-ausgefÃ¼llten Spitze ist eine asynchrone Nachricht. ACHTUNG : In der Vorlesung bei Herrn Prof. Tichy hat die Antwort (Folie 42) auch keinen ausgefÃ¼llten Kopf, im gegensatz zu dem hier gezeigtem Bild! Siehe auch How to create UML class diagrams","tags":"German posts","title":"Ãœbersicht der Pfeile in UML"},{"url":"https://martin-thoma.com/java-puzzle-5-parallel-programming-part-2/","text":"What is the output of the following script: public class test { public static int globalVar ; public static void main ( String [] args ) { globalVar = 1 ; MyParallelClass a = new MyParallelClass (); MyParallelClass b = new MyParallelClass (); new Thread ( a ). start (); new Thread ( b ). start (); System . out . println ( globalVar ); } } public class MyParallelClass implements java . lang . Runnable { public int counter = 0 ; @Override public void run () { if ( test . globalVar > 0 ) { for ( int i = 0 ; i < 1000000 ; i ++) { counter ++; } test . globalVar --; } } } . . . . . . . . . . . . . . . . . Answer 0 , 1 or -1 . Explanaition First the simple ones: 0 is the result you would expect. One thread executes and reduces globalVar to 0 , the other one does nothing and then globalVar gets printed. If the main program is faster than any of the two threads, it prints 1 before globalVar gets reduced. Now the most interesting one: -1 . This is called a race condition . You have to know that globalVar-- is not an atomic operation. First you have to get the value, then you have to reduce it and after that you can save the value. This is an order of execution which would lead to a wrong value: First Thread Second Thread test.globalVar text checks if (globalVar > 0) looping ... looping ... execute test.globalVar--; text . checks if (globalVar > 0) execute all four bytecode commands of \"test.globalVar--;\" . text 1 1 0 -1 Resolve this problem Use join() if you don't want to get 1 as output. If you don't want to get -1 , you should take a look at the keyword synchronised . A side note With javap -c MyParallelClass you can view the bytecode of the class MyParallelClass . It looks like this: Compiled from \"MyParallelClass.java\" public class MyParallelClass extends java . lang . Object implements java . lang . Runnable { public int counter ; public MyParallelClass (); Code : 0 : aload_0 1 : invokespecial # 1 ; //Method java/lang/Object.\"<init>\":()V 4 : aload_0 5 : iconst_0 6 : putfield # 2 ; //Field counter:I 9 : return public void run (); Code : 0 : getstatic # 3 ; //Field test.globalVar:I 3 : ifle 38 6 : iconst_0 7 : istore_1 8 : iload_1 9 : ldc # 4 ; //int 1000000 11 : if_icmpge 30 14 : aload_0 15 : dup 16 : getfield # 2 ; //Field counter:I 19 : iconst_1 20 : iadd 21 : putfield # 2 ; //Field counter:I 24 : iinc 1 , 1 27 : goto 8 30 : getstatic # 3 ; //Field test.globalVar:I 33 : iconst_1 34 : isub 35 : putstatic # 3 ; //Field test.globalVar:I 38 : return } Some links to the reference: getstatic , iconst_1 , isub , putstatic The interesting part of the bytecode is: 30 : getstatic # 3 ; //Field test.globalVar:I 33 : iconst_1 34 : isub 35 : putstatic # 3 ; //Field test.globalVar:I You can see that the JVM has to execute 4 commands for test.globalVar--; . See also Atomic Access in Java Class Monitor monitorenter and monitorexit Package java.util.concurrent","tags":"Code","title":"Java Puzzle #5: Parallel Programming, Part 2"},{"url":"https://martin-thoma.com/shortfilms-part-ii/","text":"Here is the first part \" Shortfilms \". Here are some nice shortfilms in high quality. If you missed the first part, here is the article \" shortfilms \" (Part I). The Last Train Mac 'n' Cheese Electroshock Mytho Logique Impossible Present The Tale Of Mr. RÃªvus Holy Sheep Danger Planet","tags":"The Web","title":"Shortfilms, Part II"},{"url":"https://martin-thoma.com/swt-i-klausur/","text":"FÃ¼r die Klausur in Softwaretechnik I 2012 bei Herrn Prof. Dr. Tichy sollte man Folgendes auf jeden Fall wissen: Wie lautet der Aufbau des Wasserfallmodells? Was ist ein Sequenzdiagramm und wie sieht es aus? â†’ Antwort Wozu dient ein AktivitÃ¤tsdiagramm und wie sieht es aus? â†’ Antwort Wozu dienen die 21 Entwurfsmuster? â†’ Siehe mein Spiel und weiteres Spiel Wie sehen die Strukturmuster der 21 Entwurfmuster aus? â†’ Siehe Kapitel 3.5 Was wird zuerst erstellt: Das Lastenheft oder das Pflichtenheft? â†’ Antwort Welche zwei MÃ¶glichkeiten gibt es in Java, um eine Aufgabe parallel auszufÃ¼hren? Was sind die Vor- und Nachteile? â†’ Antwort Wie nennt man die SchlÃ¼sselwÃ¶rter der Art @Test , @Before und @BeforeClass ? Was bewirken diese SchlÃ¼sselwÃ¶rter in JUnit? â†’ Antwort Wozu dient JFrame? â†’ Antwort Hinweise In den 60 Minuten Bearbeitungszeit haben Sie keine Zeit zum \"Probemalen\" oder \"in SchÃ¶nschrift nochmal abschreiben\" vom Schmierblatt. Wenn es irgendwie geht, schreiben Sie Ihre LÃ¶sung gleich in lesbarer (!) Reinschrift. Die Farben rot und grÃ¼n dÃ¼rfen Sie nicht verwenden. Was mit Bleistift geschrieben oder nicht entzifferbar ist, werten wir nicht. Es sind keine Hilfsmittel erlaubt. Sie brauchen kein Papier mitzubringen. Aus dem Mailman-Verteiler von Herrn Karcher. Termine Datum : Montag, den 06.08.2012 um 14:00 Uhr Ort : A - E: HSaF (Geb. 50.35) F - K: Gerthsen (Geb. 30.21) L - Q: Benz (Geb. 10.21) Râ€“S: Gaede (Geb. 30.22) Tâ€“Z: Daimler (Geb. 10.21) Dauer : 60 min. Punkte : 60 Ãœbungsschein : Noch nicht im Studierendenportal (Stand: 02.08.2012) Bonuspunkte : Gibt es nicht, oder? Sitzplatzverteilung : ? Nicht vergessen Studentenausweis Kugelschreiber Klausurergebnisse Klausurergebnisse fÃ¼r SWT I Klausureinsicht : Montag, den 13.08.2012 von 14:00 bis 16:00 Uhr, SR 348, Infobau","tags":"German posts","title":"SWT I Klausur"},{"url":"https://martin-thoma.com/nature-by-numbers/","text":"A short movie inspired by numbers, geometry and nature.","tags":"Cyberculture","title":"Nature by Numbers"},{"url":"https://martin-thoma.com/java-puzzle-4-parallel-programming/","text":"What is the output of the following Java Snippet: public class MyParallelClass implements java . lang . Runnable { public String name ; public myParallelTry ( String name ) { this . name = name ; } @Override public void run () { System . out . println ( name ); } } public class test { public static void main ( String [] args ) { MyParallelClass a = new MyParallelClass ( \"A\" ); MyParallelClass b = new MyParallelClass ( \"B\" ); MyParallelClass c = new MyParallelClass ( \"C\" ); MyParallelClass d = new MyParallelClass ( \"D\" ); new Thread ( a ). start (); new Thread ( b ). start (); new Thread ( c ). start (); new Thread ( d ). start (); System . out . println ( \"-\" ); new Thread ( a ). start (); new Thread ( b ). start (); new Thread ( c ). start (); new Thread ( d ). start (); System . out . println ( \"-\" ); new Thread ( a ). start (); new Thread ( b ). start (); new Thread ( c ). start (); new Thread ( d ). start (); System . out . println ( \"-\" ); new Thread ( a ). start (); new Thread ( b ). start (); new Thread ( c ). start (); new Thread ( d ). start (); } } . . . . . . . . . . . . . . . . . . . . . . . Answer First Try Second Try Third Try \u0002wzxhzdk:2\u0003 \u0002wzxhzdk:3\u0003 \u0002wzxhzdk:4\u0003 Explanation If you start threads like this, you don't get any guarantee that they will finish their execution in order. If you want them to execute in block of four, you could use join() : public class test { public static void main ( String [] args ) { myParallelTry a = new myParallelTry ( \"A\" ); myParallelTry b = new myParallelTry ( \"B\" ); myParallelTry c = new myParallelTry ( \"C\" ); myParallelTry d = new myParallelTry ( \"D\" ); Thread tA = new Thread ( a ); tA . start (); Thread tB = new Thread ( b ); tB . start (); Thread tC = new Thread ( c ); tC . start (); Thread tD = new Thread ( d ); tD . start (); try { tA . join (); tB . join (); tC . join (); tD . join (); } catch ( InterruptedException e ) { e . printStackTrace (); } System . out . println ( \"-\" ); tA = new Thread ( a ); tA . start (); tB = new Thread ( b ); tB . start (); tC = new Thread ( c ); tC . start (); tD = new Thread ( d ); tD . start (); try { tA . join (); tB . join (); tC . join (); tD . join (); } catch ( InterruptedException e ) { e . printStackTrace (); } System . out . println ( \"-\" ); tA = new Thread ( a ); tA . start (); tB = new Thread ( b ); tB . start (); tC = new Thread ( c ); tC . start (); tD = new Thread ( d ); tD . start (); try { tA . join (); tB . join (); tC . join (); tD . join (); } catch ( InterruptedException e ) { e . printStackTrace (); } System . out . println ( \"-\" ); tA = new Thread ( a ); tA . start (); tB = new Thread ( b ); tB . start (); tC = new Thread ( c ); tC . start (); tD = new Thread ( d ); tD . start (); try { tA . join (); tB . join (); tC . join (); tD . join (); } catch ( InterruptedException e ) { e . printStackTrace (); } } } First Try Second Try Third Try \u0002wzxhzdk:6\u0003 \u0002wzxhzdk:7\u0003 \u0002wzxhzdk:8\u0003","tags":"Code","title":"Java Puzzle #4: Parallel Programming"},{"url":"https://martin-thoma.com/python-puzzle-2-none-and-false/","text":"Python automatically casts to boolean if you use another type of variable for a boolean expression. Here is an example: #!/usr/bin/python # -*- coding: utf-8 -*- if [ 1 ]: print ( \"Crazy, \" ) if 1 : print ( \"this \" ) if 2 : print ( \"is \" ) if True : print ( \"also \" ) if \"a string\" : print ( \"true.\" ) print ( \"\" ) if not None : print ( \"This \" ) if not False : print ( \"is \" ) if not 0 : print ( \"not \" ) if not []: print ( \"true.\" ) Everything gets printed. Now the riddle. What is the output of the following script: #!/usr/bin/python # -*- coding: utf-8 -*- if None == False : print ( \"None is false.\" ) else : print ( \"None and false are not equal.\" ) . . . . . . . . . . . . . . . . . . . . . . . . Answer None and false are not equal. Explanation Although None and False evaluate to False if they are used in a boolean expression, None is not the same as False .","tags":"Code","title":"Python Puzzle #2: None and False"},{"url":"https://martin-thoma.com/how-to-write-music-with-latex/","text":"It is possible to write music with LaTeX. My girlfriend was quite surprised of this, so I decided to write a little tutorial show some examples. Symbols Some basic music symbols \\documentclass [a4paper,12pt] { article } \\usepackage { wasysym } \\begin { document } \\eighthnote ~~~ \\halfnote ~~~ \\twonotes ~~~ \\fullnote ~~~ \\quarternote ~~~ $ \\natural $ ~~~ $ \\flat $ ~~~ $ \\sharp $ \\end { document } The harmony package offers some additional symbols: music symbols form the LaTeX-harmony package \\documentclass [a4paper,12pt] { article } \\usepackage { harmony } \\begin { document } \\noindent \\AAcht ~~~ \\Acht ~~~ \\AchtBL ~~~ \\AchtBR ~~~ \\AcPa \\\\ \\DD ~~~ \\DDohne ~~~ \\Dohne ~~~ \\Ds ~~~ \\DS \\\\ \\Ganz ~~~ \\GaPa ~~~ \\Halb ~~~ \\HaPa ~~~ \\Pu ~~~ \\Sech \\\\ \\SechBL ~~~ \\SechBl ~~~ \\SechBR ~~~ \\SePa ~~~ \\UB ~~~ \\Vier \\\\ \\ViPa ~~~ \\VM ~~~ \\Zwdr ~~~ \\ZwPa \\end { document } musixtex musixtex example \\documentclass [a4paper,12pt] { article } \\usepackage { musixtex } \\begin { document } \\noindent This is a clef: \\begin { music } \\trebleclef\\end { music } - a simple example \\\\ for the \\LaTeX {} package musixtex. \\end { document } ABC Preparation You have to have ABC installed. For Ubuntu-Users: sudo apt-get install abcm2ps Example \\documentclass [a4paper] { article } \\usepackage { abc } \\begin { document } You can create music sheets within the abc-environment: \\begin { abc } [name=c-dur] X: 1 % start of header K: C % scale: C major \"Text\"c2 G4 | (3FED c4 G2 | \\end { abc } \\end { document } compile with pdflatex --shell-escape myTexFile.tex to get this: ABC example for creating music sheets with LaTeX LilyPond Preparation Make sure that you have installed GNU LilyPond and LaTeX. Ubuntu-Users have to type sudo apt-get install lilypond to install Lilypond. Example From the Documentation Save the following source as lilybook.lytex : \\documentclass [a4paper] { article } \\begin { document } Documents for \\verb +lilypond-book+ may freely mix music and text. For example, \\begin { lilypond } \\relative c' { c2 g'2 \\times 2/3 { f8 e d } c'2 g4 } \\end { lilypond } Options are put in brackets. \\begin [fragment,quote,staffsize=26,verbatim] { lilypond } c'4 f16 \\end { lilypond } Larger examples can be put into a separate file, and introduced with \\verb + \\lilypondfile +. \\end { document } Compile it with these commands: lilypond-book --output = out --pdf lilybook.lytex cd out/ pdflatex lilybook mv lilybook.pdf ../lilybook.pdf cd .. rm -rf out For simplification, you can save this as compile.sh , execute chmod +x compile.sh and now you only have to enter ./compile.sh to generate the PDF. Output: Lilypond example - output was a PDF Further Reading ABC ABC-environment Documentation LilyPond LilyPond â€” Learning Manual Lilypond 2.14 Documentation Lilypond: Free, Beautiful Music Notation Engraving for Anyone by Peter Kirn Including Lilypond in LaTeX Beautiful example Creating a custom songbook with the songs package MusiXTeX If you've made some more complex examples with LaTeX, I'd be happy if you added them in the comments.","tags":"The Web","title":"How to write music with LaTeX"},{"url":"https://martin-thoma.com/die-lander-der-erde/","text":"LÃ¤nder der Erde Hier ist ein Spiel , bei dem man die LÃ¤nder der Erde eingeben muss. Es ist schon erschreckent, wie viele weiÃŸe Flecken hier sind. Punktzahl 26. Juli 2012 You scored 54/196 = 28%. This beats or equals 21.1% of test takers. The average score is 93. Viele afrikanische LÃ¤nder sind mir unbekannt. Habt ihr schon mal von Nauru oder Kiribati gehÃ¶rt? 02. August 2012 You scored 90/196 = 46%. This beats or equals 67.6% of test takers. The average score is 77. Your high score is 90. LÃ¤nder der Erde - zweiter Versuch","tags":"Cyberculture","title":"Die LÃ¤nder der Erde"},{"url":"https://martin-thoma.com/b-baume/","text":"Ein B-Baum ist eine Datenstruktur, die vor allem fÃ¼r Datenbanken (z.B. SQLite ) und Dateisysteme (z.B. ext3 ) eingesetzt wird. Im Folgenden sollte man immer im Hinterkopf behalten, dass an den SchlÃ¼sseln auch Werte - sog. Satellitendaten - hÃ¤ngen. Der Einfachheit halber lasse ich diese aber hier weg. Definition Die folgende Definition ist sinngemÃ¤ÃŸ aus \"Introduction to Algorithms\" von Thomas H. Cormen Ã¼bernommen. FÃ¼r einen B-Baum der Ordnung t , \\(t \\in \\mathbb{N} \\setminus \\{1\\}\\) , gilt: Jeder Knoten $x$ hat die folgenden Attribute: $n$, die Anzahl der SchlÃ¼ssel die im Knoten $x$ gespeichert wird, die $n$ SchlÃ¼ssel, die in aufsteigender Reihenfolge gespeichert werden (also $key_1 \\leq key_2 \\leq ... \\leq key_{n}$), $isLeaf$, ein boolscher Wert der True ist, falls $x$ ein Blatt ist und False ist, falls $x$ ein innerer Knoten ist Jeder innere Knoten hat $n + 1$ Zeiger $c_1, c_2, ... c_{n+1}$ auf seine Kinder. Blattknoten haben keine Kinder, also sind ihre $c_i$-Attribute undefiniert. Ein Knoten eines B-Baumes sieht also so aus: Node of a B-tree Die SchlÃ¼ssel $key_i$ setzen grenzen fÃ¼r die Werte der SchlÃ¼ssel, die in den einzelnen SubbÃ¤umen gespeichert sind. Falls $k_i$ ein SchlÃ¼ssel im Subbaum mit der Wurzel $c_i$ ist, dann gilt: $k_1 \\leq key_1 \\leq k_2 \\leq key_2 \\leq ... \\leq key_{n} \\leq k_{n} \\leq key_{n+1}$ Alle BlÃ¤tter haben die gleiche Tiefe. FÃ¼r die Anzahl der SchlÃ¼ssel eines Knotens gilt: Jeder Knoten (bis auf die Wurzel) hat mindestens t-1 SchlÃ¼ssel. Jeder Knoten hat hÃ¶chstens $2t - 1$ SchlÃ¼ssel. Stolperfallen Ein SchlÃ¼ssel ist etwas anderes als ein Zeiger! Folgerungen $(2) \\Rightarrow$ Die Wurzel hat min. 2 Kinder, falls der Baum nicht leer ist. $(2), (5.1) \\Rightarrow$ Jeder innere Knoten (bis auf die Wurzel) hat min. t Kinder. $(2), (5.2) \\Rightarrow$ Jeder innere Knoten hat maximal 2t Kinder. Wenn man an den Zeigern die Kinder in die Elterknoten zieht, sodass am Ende alle Knoten in der Wurzel sind, entsteht wegen (3) eine sortierte Liste. $ h \\leq \\log_t \\frac{n+1}{2}$ (Cormen, S. 489) Ein B-Baum hat in der Tiefe h min. $2t&#94;{h-1}$ Knoten. Besondere B-BÃ¤ume Ein B-Baum der Ordnung t = 2 wird auch 2-3-4-Baum genannt, da jeder Knoten entweder 2, 3 oder 4 Kinder hat. Ich habe ja ausgeschlossen, dass es einen B-Baum der Ordnung t = 1 gibt. Warum eigentlich? Aus (5.1) folgt: In einem B-Baum der Ordnung t = 1 mÃ¼ssten einzelne Knoten keine SchlÃ¼ssel haben. Das ist nicht sinnvoll. Also muss \\(t \\geq 2\\) gelten. Suchen eines SchlÃ¼ssels Das Suchen eines SchlÃ¼ssels funktioniert so: SEARCH - KEY ( node , key ): int i = 0 while i < node . n and node . key [ i ] . key < key : i += 1 if node . key [ i ] . key == key : # Schl&uuml;ssel ist gesuchter Schl&uuml;ssel return node . key [ i ] . satelittendaten else if node . isLeaf : # Erfolglose Suche return NIL else : # Rekursiv weitersuchen DISK - READ ( node . c [ i ]) return SEARCH - KEY ( node . c [ i ], key ) Es wird also zuerst der Knoten durchsucht und dann gegebenenfalls der passende Subbaum. Laut Vorlesung (Folie 97) gilt: Anzahl Zugriffe auf Hintergrundspeicher maximal: \\({\\cal O}(\\log_t(n))\\) Innerhalb eines Knotens: \\({\\cal O}(t)\\) Insgesamt also: \\({\\cal O}(t \\cdot \\log_t(n))\\) EinfÃ¼gen von SchlÃ¼sseln Wenn ein SchlÃ¼ssel in einen B-Baum eingefÃ¼gt werden soll, dann muss man insebesondere auf Regel (5.1) und (5.2) achten: Jeder Knoten enthÃ¤lt n SchlÃ¼ssel, mit \\(t-1 \\leq n \\leq 2t -1\\) . Die Idee ist, dass man das Blatt sucht, in dem der SchlÃ¼ssel sein mÃ¼sste. Falls noch Platz ist, kann man den SchlÃ¼ssel einfach einfÃ¼gen. Falls nicht, muss man das Blatt aufsplitten. Beispiel zu Fall 1: Es ist noch Platz Abb. 2: B-Baum der Ordnung t = 2 In den B-Baum aus Abb. 2 soll nun der SchlÃ¼ssel 16 eingefÃ¼gt werden. In einem B-Baum der Ordnung 2 hat jeder Knoten mindestens einen und hÃ¶chstens 3 SchlÃ¼ssel. Egal wo wir also landen wÃ¼rden, es wÃ¼rde noch in diesen Baum passen. Wir landen aber im Knoten rechts unten, da \\(11 < 16\\) ist. Das Ergebnis ist also: Abb. 3: B-Baum der Ordnung t = 2 Beispiel zu Fall 2: KnotenÃ¼berlauf Will man nun in den B-Baum der Ordnung 2 aus Abb. 3 den SchlÃ¼ssel 17 hinzufÃ¼gen, so gibt es einen \"KnotenÃ¼berlauf\". Der SchlÃ¼ssel mÃ¼sste in den Knoten rechts unten. Damit hÃ¤tte dieser 4 SchlÃ¼ssel, er darf aber nur 3 haben. Also splitten wir zuerst den Knoten. SchlÃ¼ssel 15 wandert zu dem Elternknoten hoch, die beiden einzelnen SchlÃ¼ssel bilden eigene Knoten. Damit man sieht, was mit den SchlÃ¼sseln geschehen wÃ¼rde, wenn der Baum grÃ¶ÃŸer wÃ¤re, habe ich diese mal eingefÃ¤rbt: Abb. 4: B-Baum der Ordnung t = 2 Nun ist man beim EinfÃ¼gen von 17 wieder in Fall 1. Das Ergebnis sieht so aus: Abb. 5: B-Baum der Ordnung t = 2 NatÃ¼rlich kann es auch passieren, dass beim hochwandern des mittleren Knoten (15 von Abb. 3 nach Abb. 4) der Elternknoten Ã¼berlÃ¤uft. Dann muss halt auch dieser gesplittet werden. Wenn die Wurzel Ã¼berlÃ¤uft, muss eine neue Wurzel erstellt werden. Dann kann die alte Wurzel gesplittet werden. Die Laufzeit des EinfÃ¼gens ist in \\({\\cal O}(t \\cdot \\log_t(n))\\) . LÃ¶schen eines SchlÃ¼ssels Falls sich der SchlÃ¼ssel in einem Blatt befindet, kann man ihn einfach lÃ¶schen. Allerdings muss man darauf achten, dass mindestens t-1 SchlÃ¼ssel im Knoten verbleiben. Ist der SchlÃ¼ssel in einem inneren Knoten ist das ganze schwerer. Fall 1: SchlÃ¼ssel in Blatt Der Einfachste Fall ist der 1. Fall des EinfÃ¼gens , nur umgekehrt. Also aus dem B-Baum aus Abb. 3 die 16 entfernen. Dann entsteht der B-Baum aus Abb. 2. Fall 2 - 3 FÃ¼r die anderen FÃ¤lle habe ich leider kein kleines Beispiel und will deshalb auf die ErklÃ¤rung verzichten. Falls ihr da Hilfe braucht: Cormen, dritte Ausgabe, S. 499ff war sehr hilfreich. ( Link - Warum auch immer der eine PDF-Datei vom Buch hat. Die KIT-Bibliothek hat leider keine Online-Version.) Trivia [...] standard B-trees had numerous characteristics that were at odds with the ext2 design philosophy of simplicity and robustness. For example, XFS's B-tree implementation was larger than all of ext2 or ext3's source files combined. Source: ext2.sourceforge.net Beispiel FÃ¼gt man die SchlÃ¼ssel 2, 4, 6, 8, 10, 12 in einen anfangs leeren B-Baum ein, entwickelt sich dieser wie folgt: Entwicklung eines B-Baumes der Ordnung t = 3 Die grauen Felder sind fÃ¼r Zeiger reserviert. Ist kein Zeiger eingezeichnet, dann ist es ein NIL-Zeiger. Siehe auch Which datastructure do nodes of B-Trees use? What is a good open source B-tree implementation in C? - Da kann man mal sehen wie es wirklich funktioniert â˜º Red Black Tree vs. B Tree When to choose RB tree, B-Tree or AVL tree?","tags":"German posts","title":"B-BÃ¤ume"},{"url":"https://martin-thoma.com/die-landau-symbole/","text":"Definitionen \\( \\begin{eqnarray*} {\\cal O}(g(n)) &:= \\{f(n) | \\exists_{c > 0} \\exists_{n_0 > 0} \\forall_{n \\geq n_0}: f(n) < c \\cdot g(n) \\} \\\\ {\\cal o}(g(n)) &:= \\{f(n) | \\forall_{c > 0} \\exists_{n_0 > 0} \\forall_{n \\geq n_0}: f(n) < c \\cdot g(n) \\} \\\\ \\Omega (g(n)) &:= \\{f(n) | \\exists_{c > 0} \\exists_{n_0 > 0} \\forall_{n \\geq n_0}: f(n) > c \\cdot g(n) \\} \\\\ \\omega (g(n)) &:= \\{f(n) | \\forall_{c > 0} \\exists_{n_0 > 0} \\forall_{n \\geq n_0}: f(n) > c \\cdot g(n) \\} \\\\ \\end{eqnarray*} $ $\\Theta (g(n)) := \\{f(n) | \\exists_{c_0 > 0} \\exists_{c_1 > 0} \\exists_{n_0 > 0} \\forall_{n > n_0}: c_0 \\cdot g(n) < f(n) < c_1 \\cdot g(n) \\}\\) Wichtige Aussagen der Mengen \\begin{align} f(n) \\in {\\cal O}(g(n)) &\\Leftrightarrow g(n) \\in \\Omega(f(n)) \\\\ f(n) \\in {\\cal o}(g(n)) &\\Leftrightarrow g(n) \\in \\omega(f(n)) \\\\ f(n) \\in {\\cal O}(g(n)) \\land f(n) \\in \\Omega(g(n)) &\\Leftrightarrow f(n) \\in \\Theta(g(n)) \\\\ f(n) \\in o(g(n)) &\\Leftrightarrow \\lim \\frac{f(n)}{g(n)} = 0 \\\\ f(n) \\in \\Theta ( g(n)) &\\Leftrightarrow g(n) \\in \\Theta(f(n)) \\\\ f(n) \\in \\omega(g(n)) &\\Leftrightarrow \\lim \\frac{g(n)}{f(n)} = 0 \\end{align} Logarithmusgesetze \\begin{align} \\log(x \\cdot y) &= \\log(x) + \\log(y) \\\\ \\log(\\frac{x}{y}) &= \\log(x) &ndash; \\log(y) \\\\ \\log(x&#94;r) &= r \\cdot \\log(x) \\end{align} Wichtige Beziehungen von Funktionen \\({\\cal O}(1) \\subsetneq {\\cal O}(\\log n) \\subsetneq {\\cal O}(n) \\subsetneq {\\cal O}(n&#94;{2.1}) \\subsetneq {\\cal O} \\subsetneq (n&#94;{2.2}) {\\cal O}(n&#94;{100}) \\subsetneq {\\cal O}(n!) \\subsetneq {\\cal O}(2&#94;n)\\) \\({\\cal O}(2&#94;n) \\subsetneq {\\cal O}(2&#94;{2n}) \\subsetneq {\\cal O}(3&#94;n) \\subsetneq {\\cal O}(n&#94;n) \\subsetneq {\\cal O}(n&#94;{(n&#94;2)}) \\subsetneq\\) Beispiele Im Folgenden gelte immer: \\(f: \\mathbb{N} \\rightarrow \\mathbb{R&#94;+}\\) und \\(g:\\mathbb{N} \\rightarrow \\mathbb{R&#94;+}\\) Nummer 1 Voraussetzungen : Sei \\(f(n) := \\sqrt{2}&#94;{\\lg(n)}\\) und \\(g(n) := n \\cdot \\lg(n)\\) . Behauptung : \\(f \\in {\\cal O}(g(n))\\) Beweis : \\(f(n) = \\sqrt{2}&#94;{\\lg(n)} = 10&#94;{\\lg(\\sqrt{2}&#94;{\\lg(n)})} = 10&#94;{\\lg(\\sqrt{2}) \\cdot \\lg(n)} = n&#94;{\\lg(\\sqrt{2})}= n&#94;{\\frac{1}{2} \\cdot \\lg(2)} < n&#94;1 = n\\) Es gilt: \\(n \\in {\\cal O}(n \\cdot \\lg(n)) = {\\cal O}(g(n))\\) \\(\\Rightarrow f(n) \\in {\\cal O}(g(n)) \\blacksquare\\) Nummber 2 Voraussetzungen : Sei \\(f(n) := \\sqrt{5}&#94;{\\log_3(n)}\\) und \\(g(n) := n&#94;2\\) . Behauptung : \\(f \\in {\\cal o}(g(n))\\) Beweis : \\(f(n) = \\sqrt{5}&#94;{\\log_3(n)} = 3&#94;{\\log_3(\\sqrt{5}&#94;{\\log_3(n)})} = 3&#94;{\\log_3(5) \\cdot \\log_3(n)} = n&#94;{\\log_3(5)} < n&#94;{\\log_3(9)} = n&#94;{\\log_3(3&#94;2)} = n&#94;2\\) Sei \\(\\varepsilon > 0\\) . Dann gilt: \\(n&#94;{2- \\varepsilon} \\in o(n&#94;2) \\Rightarrow f(n) \\in o(g(n)) \\blacksquare\\)","tags":"German posts","title":"Die Landau-Symbole"},{"url":"https://martin-thoma.com/plotting-graphs-with-pgfplots-latex-and-tikz/","text":"I guess many of you might need to plot functions or data once. So I've made one example that shows much of the features you might need: You can see how to change the axis' from normal linear scale to logarithmic scale. Some axis-manipulations were used. I have used a CSV-file to import and plot data. The red line was drawn with a mathematical function. Best of all: I didn't use anything which is not in LaTeX â˜º (Well, the generation of the CSV-file doesn't count. I just wanted to include such an example for physicists who might need to plot results of experiments). The complete source is in the Birthday Paradox Archive . Result Plot of the birthday paradox LaTeX-Code The following LaTeX-Code used TikZ and PGFplots: % Plot of the probability that two people out of n people have the % same birthday. % Author: Martin Thoma % Source: ../plotting-graphs-with-pgfplots/ \\documentclass { article } \\usepackage [pdftex,active,tightpage] { preview } \\setlength\\PreviewBorder { 2mm } \\usepackage { pgfplots } \\usepackage { tikz } \\usetikzlibrary { arrows, positioning, calc } \\begin { document } \\begin { preview } \\begin { tikzpicture } \\begin { axis } [ width=15cm, height=8cm, % size of the image grid = major, grid style= { dashed, gray!30 } , %xmode=log,log basis x=10, %ymode=log,log basis y=10, xmin=0, % start the diagram at this x-coordinate xmax=62, % end the diagram at this x-coordinate ymin=0, % start the diagram at this y-coordinate ymax=1.1, % end the diagram at this y-coordinate /pgfplots/xtick= { 0,5,...,60 } , % make steps of length 5 extra x ticks= { 23 } , extra y ticks= { 0.507297 } , axis background/.style= { fill=white } , ylabel=probability of at least one birthday-collision, xlabel=people, tick align=outside] % import the correct data from a CSV file \\addplot table [id=exp] { data.csv } ; % mark x=23 \\coordinate (a) at (axis cs:23,0.507297); \\draw [blue, dashed, thick] (a -| current plot begin) -- (a); \\draw [blue, dashed, thick] (a |- current plot begin) -- (a); % plot the stirling-formulae \\addplot [domain=0:60, red, thick] { 1-(365/(365-x)) &#94; (365.5-x)*e &#94; (-x) } ; \\end { axis } \\end { tikzpicture } \\end { preview } \\end { document } I generate the images directly with this Makefile: SOURCE = birthday-paradox DELAY = 80 DENSITY = 300 WIDTH = 500 make : pdflatex $( SOURCE ) .tex -output-format = pdf make clean clean : rm -rf $( TARGET ) *.class *.html *.log *.aux gif : pdfcrop $( SOURCE ) .pdf convert -verbose -delay $( DELAY ) -loop 0 -density $( DENSITY ) $( SOURCE ) -crop.pdf $( SOURCE ) .gif make clean png : make make svg inkscape $( SOURCE ) .svg -w $( WIDTH ) --export-png = $( SOURCE ) .png transparentGif : convert $( SOURCE ) .pdf -transparent white result.gif make clean svg : #inkscape $(SOURCE).pdf --export-plain-svg=$(SOURCE).svg pdf2svg $( SOURCE ) .pdf $( SOURCE ) .svg # Necessary, as pdf2svg does not always create valid svgs: inkscape $( SOURCE ) .svg --export-plain-svg = $( SOURCE ) .svg See also Plotting function graphs with LaTeX Plotting examples Mathematics examples tex.stackexchange.com","tags":"Code","title":"Plotting graphs with PGFplots (LaTeX and Tikz)"},{"url":"https://martin-thoma.com/why-to-study-math/","text":"Math is beautiful See also: Different sizes of infinity Beauty in Maths: math animation no.7 - 5D Visualization of three equations Math is important If you are interested in natural science, you will defenitely need math. Here are a few examples where math is directly needed: Computer Science : All kinds of animations, stochastics is needed often, cryptography needs number theory Physics : a lot of analysis seems to be needed, differential equations are used if processes are depend on time Chemistry , Biology , Medicine , Psychology : again stochastics for interpreting results of experiments economic science : modelling - I don't know anything about economic science, but I've heard they need differential equations Although I guess you could continue this list, but the most important reason is that it teaches you how to think logically. Jobs are better What you earn with a math-degree ;-) Math is worth a lot of money Math is fun Only topologists really understand this joke, I guess... The top 10 signs you're a mathematician/computer scientist Money Not knowing mathematics can cost you money. An obvious example is:","tags":"Cyberculture","title":"Why to study math?"},{"url":"https://martin-thoma.com/ubersicht-uber-datenstrukturen/","text":"Diese Ãœbersicht beinhaltet grundlegende Datenstrukturen. Es gibt weitaus mehr Datenstrukturen (z.B. Bloomfilter ), als ich hier erwÃ¤hne. Diese Datenstrukturen wurden in der Vorlesung Algorithmen I bei Frau Zitterbart am KIT erklÃ¤rt. Array Array Ein Array, auch Feld genannt, ist eine Datenstruktur. Charakteristika: Ein Array hat eine feste, nicht verÃ¤nderbare GrÃ¶ÃŸe. Der Zugriff auf jedes beliebige Element erfolgt in konstanter Zeit - ist also insbesondere unabhÃ¤ngig von der GrÃ¶ÃŸe! Dynamische Arrays Dynamische Arrays sind wie normale Arrays, nur dass sie wachsen kÃ¶nnen. Sobald ein Element eingefÃ¼gt werden soll, dass nicht mehr ins Array passen wÃ¼rde, allokiert man ein doppelt so groÃŸes Array und kopiert die Elemente um. In Java ist es ein Vector bzw. eine ArrayList , in C++ Vektoren . Hashtabelle In der Informatik bezeichnet man eine spezielle Indexstruktur als Hashtabelle (englisch hash table oder hash map) bzw. Streuwerttabelle. Als Indexstruktur werden Hashtabellen verwendet um Datenelemente in einer groÃŸen Datenmenge aufzufinden. Zu Hashtabellen alternative Index-Datenstrukturen sind beispielsweise Baumstrukturen (wie etwa ein B+-Baum) und die Skip-List. Hashtabellen zeichnen sich durch einen Ã¼blicherweise konstanten Zeitaufwand bei EinfÃ¼ge- bzw. Entfernen-Operationen aus. Beim Einsatz einer Hashtabelle zur Suche in Datenmengen spricht man auch von einem Hashverfahren oder Streuspeicherverfahren. Quelle: Hashtabelle Hashtabellen werden hier benutzt: Python 3.2.3: Modules/_pickle.c Java OpenJDK 7: java.util.HashTable und sehr viele mehr benutzen es (Properties.java, Dictionary.java, Enum.java, ...) Sie garantieren eine amortisierte Laufzeit von \\({\\cal O}(1)\\) fÃ¼r Suchen, LÃ¶schen und EinfÃ¼gen. Folgende Begriffe sollte man kennen: Divisions-Rest-Methode : \\(h(k) = k \\mod m\\) Multiplikationsmethode : \\(h(k) = \\lfloor A \\cdot k \\mod 1 \\rfloor\\) , mit z.B. \\(A \\approx \\frac{\\sqrt{5}-1}{2}\\) offenes Hashing Doppeltes Hashing : \\(h(k, i) = (h_1(k) + i \\cdot h_2(k)) \\mod m\\) Lineares und quadratische Sondieren Belegungsfaktor: \\(\\alpha = \\frac{\\text{Anzahl gespeicherter Elemente}}{\\text{Anzahl der Slots}}\\) PrimÃ¤re und sekundÃ¤re Clusterbildung Stack Stack a capacity of 5 elements and size of 4. Stacks, auch \" Stapelspeicher \" oder \"Kellerspeicher\" genannt, sind eine elementare Datenstruktur. Es sollte sie in jeder Sprache geben. In Java ist es in java.util.Stack , in Python sind es Listen und natÃ¼rlich gibt es auch in C++ Stacks . Wie man am Bild sehr schÃ¶n sehen kann, definiert ein Stack keine Ordnung Ã¼ber die Elemente. Wenn ein neues Element kommt, wird es auf den Stack gelegt. Man kann auch nur das oberste Element - in diesem Fall a - vom Stack nehmen. Deshalb werden Stacks auch als LIFO-Speicher ( L ast I n F irst O ut) bezeichnet. Stacks werden mit dynamischen Arrays realisiert. Dazu mal ein kleines Beispiel: import java.util.Stack ; public class test { public static void main ( String [] args ) { Stack < Integer > s = new Stack < Integer >(); s . add ( 12 ); s . push ( 13 ); for ( int i = 0 ; i < 100 ; i ++) { s . push ( i ); System . out . printf ( \"size: %d \\t capacity: %d\\n\" , s . size (), s . capacity ()); } while ( s . size () > 0 ) { System . out . printf ( \"Element: %d \\t size: %d \\t capacity: %d\\n\" , s . pop (), s . size (), s . capacity ()); } } } Ausgabe: size: 3 capacity: 10 size: 4 capacity: 10 size: 5 capacity: 10 size: 6 capacity: 10 size: 7 capacity: 10 size: 8 capacity: 10 size: 9 capacity: 10 size: 10 capacity: 10 size: 11 capacity: 20 size: 12 capacity: 20 size: 13 capacity: 20 size: 14 capacity: 20 size: 15 capacity: 20 size: 16 capacity: 20 size: 17 capacity: 20 size: 18 capacity: 20 size: 19 capacity: 20 size: 20 capacity: 20 size: 21 capacity: 40 size: 22 capacity: 40 size: 23 capacity: 40 size: 24 capacity: 40 size: 25 capacity: 40 size: 26 capacity: 40 size: 27 capacity: 40 size: 28 capacity: 40 size: 29 capacity: 40 size: 30 capacity: 40 size: 31 capacity: 40 size: 32 capacity: 40 size: 33 capacity: 40 size: 34 capacity: 40 size: 35 capacity: 40 size: 36 capacity: 40 size: 37 capacity: 40 size: 38 capacity: 40 size: 39 capacity: 40 size: 40 capacity: 40 size: 41 capacity: 80 size: 42 capacity: 80 size: 43 capacity: 80 size: 44 capacity: 80 size: 45 capacity: 80 size: 46 capacity: 80 size: 47 capacity: 80 size: 48 capacity: 80 size: 49 capacity: 80 size: 50 capacity: 80 size: 51 capacity: 80 size: 52 capacity: 80 size: 53 capacity: 80 size: 54 capacity: 80 size: 55 capacity: 80 size: 56 capacity: 80 size: 57 capacity: 80 size: 58 capacity: 80 size: 59 capacity: 80 size: 60 capacity: 80 size: 61 capacity: 80 size: 62 capacity: 80 size: 63 capacity: 80 size: 64 capacity: 80 size: 65 capacity: 80 size: 66 capacity: 80 size: 67 capacity: 80 size: 68 capacity: 80 size: 69 capacity: 80 size: 70 capacity: 80 size: 71 capacity: 80 size: 72 capacity: 80 size: 73 capacity: 80 size: 74 capacity: 80 size: 75 capacity: 80 size: 76 capacity: 80 size: 77 capacity: 80 size: 78 capacity: 80 size: 79 capacity: 80 size: 80 capacity: 80 size: 81 capacity: 160 size: 82 capacity: 160 size: 83 capacity: 160 size: 84 capacity: 160 size: 85 capacity: 160 size: 86 capacity: 160 size: 87 capacity: 160 size: 88 capacity: 160 size: 89 capacity: 160 size: 90 capacity: 160 size: 91 capacity: 160 size: 92 capacity: 160 size: 93 capacity: 160 size: 94 capacity: 160 size: 95 capacity: 160 size: 96 capacity: 160 size: 97 capacity: 160 size: 98 capacity: 160 size: 99 capacity: 160 size: 100 capacity: 160 size: 101 capacity: 160 size: 102 capacity: 160 Element: 99 size: 101 capacity: 160 Element: 98 size: 100 capacity: 160 Element: 97 size: 99 capacity: 160 Element: 96 size: 98 capacity: 160 Element: 95 size: 97 capacity: 160 Element: 94 size: 96 capacity: 160 Element: 93 size: 95 capacity: 160 Element: 92 size: 94 capacity: 160 Element: 91 size: 93 capacity: 160 Element: 90 size: 92 capacity: 160 Element: 89 size: 91 capacity: 160 Element: 88 size: 90 capacity: 160 Element: 87 size: 89 capacity: 160 Element: 86 size: 88 capacity: 160 Element: 85 size: 87 capacity: 160 Element: 84 size: 86 capacity: 160 Element: 83 size: 85 capacity: 160 Element: 82 size: 84 capacity: 160 Element: 81 size: 83 capacity: 160 Element: 80 size: 82 capacity: 160 Element: 79 size: 81 capacity: 160 Element: 78 size: 80 capacity: 160 Element: 77 size: 79 capacity: 160 Element: 76 size: 78 capacity: 160 Element: 75 size: 77 capacity: 160 Element: 74 size: 76 capacity: 160 Element: 73 size: 75 capacity: 160 Element: 72 size: 74 capacity: 160 Element: 71 size: 73 capacity: 160 Element: 70 size: 72 capacity: 160 Element: 69 size: 71 capacity: 160 Element: 68 size: 70 capacity: 160 Element: 67 size: 69 capacity: 160 Element: 66 size: 68 capacity: 160 Element: 65 size: 67 capacity: 160 Element: 64 size: 66 capacity: 160 Element: 63 size: 65 capacity: 160 Element: 62 size: 64 capacity: 160 Element: 61 size: 63 capacity: 160 Element: 60 size: 62 capacity: 160 Element: 59 size: 61 capacity: 160 Element: 58 size: 60 capacity: 160 Element: 57 size: 59 capacity: 160 Element: 56 size: 58 capacity: 160 Element: 55 size: 57 capacity: 160 Element: 54 size: 56 capacity: 160 Element: 53 size: 55 capacity: 160 Element: 52 size: 54 capacity: 160 Element: 51 size: 53 capacity: 160 Element: 50 size: 52 capacity: 160 Element: 49 size: 51 capacity: 160 Element: 48 size: 50 capacity: 160 Element: 47 size: 49 capacity: 160 Element: 46 size: 48 capacity: 160 Element: 45 size: 47 capacity: 160 Element: 44 size: 46 capacity: 160 Element: 43 size: 45 capacity: 160 Element: 42 size: 44 capacity: 160 Element: 41 size: 43 capacity: 160 Element: 40 size: 42 capacity: 160 Element: 39 size: 41 capacity: 160 Element: 38 size: 40 capacity: 160 Element: 37 size: 39 capacity: 160 Element: 36 size: 38 capacity: 160 Element: 35 size: 37 capacity: 160 Element: 34 size: 36 capacity: 160 Element: 33 size: 35 capacity: 160 Element: 32 size: 34 capacity: 160 Element: 31 size: 33 capacity: 160 Element: 30 size: 32 capacity: 160 Element: 29 size: 31 capacity: 160 Element: 28 size: 30 capacity: 160 Element: 27 size: 29 capacity: 160 Element: 26 size: 28 capacity: 160 Element: 25 size: 27 capacity: 160 Element: 24 size: 26 capacity: 160 Element: 23 size: 25 capacity: 160 Element: 22 size: 24 capacity: 160 Element: 21 size: 23 capacity: 160 Element: 20 size: 22 capacity: 160 Element: 19 size: 21 capacity: 160 Element: 18 size: 20 capacity: 160 Element: 17 size: 19 capacity: 160 Element: 16 size: 18 capacity: 160 Element: 15 size: 17 capacity: 160 Element: 14 size: 16 capacity: 160 Element: 13 size: 15 capacity: 160 Element: 12 size: 14 capacity: 160 Element: 11 size: 13 capacity: 160 Element: 10 size: 12 capacity: 160 Element: 9 size: 11 capacity: 160 Element: 8 size: 10 capacity: 160 Element: 7 size: 9 capacity: 160 Element: 6 size: 8 capacity: 160 Element: 5 size: 7 capacity: 160 Element: 4 size: 6 capacity: 160 Element: 3 size: 5 capacity: 160 Element: 2 size: 4 capacity: 160 Element: 1 size: 3 capacity: 160 Element: 0 size: 2 capacity: 160 Element: 13 size: 1 capacity: 160 Element: 12 size: 0 capacity: 160 Wenn man das ausfÃ¼hrt, sieht man es recht schnell. Alternativ schaut man in die Dokumentation und liest: The Stack class represents a last-in-first-out (LIFO) stack of objects. It extends class Vector with five operations that allow a vector to be treated as a stack. Operation Worst-Case-Laufzeit Anmerkungen Push ${\\cal O}(1)$ Ein Element auf den Stack legen Pop ${\\cal O}(1)$ Das oberste Element von der Liste nehmen Ein Stack lÃ¤sst sich als doppelt verkettete, zyklische Liste implementieren. Warteschlangen Warteschlangen, auch Queues genannt, sind Stacks sehr Ã¤hnlich. Beide unterstÃ¼tzen prinzipiell nur zwei Operationen. Bei Stacks nanne es sich PUSH und POP, bei Warteschlangen heiÃŸt es ENQUEUE und DEQUEUE. Im Unterschied zum Stack wird bei der Warteschlange das Element nicht von oben wieder weggenommen, sondern von hinten. Das Bild einer Warteschlange ist hier sehr passend. Operation Worst-Case-Laufzeit Anmerkungen Enqueue ${\\cal O}(1)$ Ein Element auf den Stack legen Dequeue ${\\cal O}(1)$ Das oberste Element von der Liste nehmen Eine Warteschlange lÃ¤sst sich als doppelt verkettete, zyklische Liste implementieren. Verkettete Listen Wie bei allen Datenstrukturen, kann man fÃ¼r verkettete Listen mehr Operationen definieren und umsetzen, als ich hier aufliste. Eine gute Menge von Operationen wird durch das Java List Interface vorgegeben. Einfach verkettete Liste Singly linked list Sei \\(n\\) die Anzahl der Elemente der Liste. Operation Worst-Case-Laufzeit Anmerkungen Suchen \\({\\cal O}(n)\\) â†’ Element ist am Ende der Liste Minimum \\({\\cal O}(n)\\) â†’ Element ist am Ende der Liste Maximum \\({\\cal O}(n)\\) â†’ Element ist am Ende der Liste EinfÃ¼gen am Anfang \\({\\cal O}(1)\\) Wahlfreies EinfÃ¼gen \\({\\cal O}(n)\\) LÃ¶schen \\({\\cal O}(n)\\) â†’ Suchen VorgÃ¤nger \\({\\cal O}(n)\\) Nachfolger \\({\\cal O}(1)\\) Doppelt verkettete Liste Doubly linked list Sei \\(n\\) die Anzahl der Elemente der Liste. Operation Worst-Case-Laufzeit Anmerkungen Suchen \\({\\cal O}(n)\\) â†’ Element ist am Ende der Liste Minimum \\({\\cal O}(n)\\) â†’ Element ist am Ende der Liste Maximum \\({\\cal O}(n)\\) â†’ Element ist am Ende der Liste EinfÃ¼gen am Anfang \\({\\cal O}(1)\\) Wahlfreies EinfÃ¼gen \\({\\cal O}(n)\\) LÃ¶schen \\({\\cal O}(n)\\) â†’ Suchen VorgÃ¤nger \\({\\cal O}(1)\\) Nur hier ist die doppelt-verkettete Liste besser als die einfach verkettete Liste. Nachfolger \\({\\cal O}(1)\\) BÃ¤ume In der Vorlesung wurden BÃ¤ume sehr unprÃ¤zise eingefÃ¼hrt. Ich versuche das mal etwas prÃ¤ziser zu machen: Sei \\(G = (V, E)\\) ein gerichteter Graph. \\(G\\) heiÃŸt gerichteter Baum \\(: \\Leftrightarrow \\exists_{r \\in V} \\forall_{x \\in V}:\\) Es exisitert genau ein Pfad von \\(r\\) nach \\(x\\) . Sei $G = (V, E)$ ein gerichteter Baum und sei $r \\in V$ das $r$ aus der Definition. $r$ heiÃŸt Wurzel von $G$. ACHTUNG: Die folgende Definition habe ich mir ausgedacht! NICHT IN DER KLAUSUR VERWENDEN! Sei \\(E \\subseteq V \\times V\\) eine Menge ungerichteter Kanten. Dann bezeichne \\(G(E) := \\{(v, w) | \\{v, w\\} \\in E\\}\\) die Menge aller zugehÃ¶rigen gerichteten Kanten. Sei $U = (V, E)$ ein ungerichteter Graph. $U$ heiÃŸt ein ungerichteter Baum $:\\Leftrightarrow \\exists$ gerichteten Baum $G = (V, E')$ mit $E' \\subsetneq G(E)$. Sei $G = (V, E)$ ein Baum und $x, y \\in V$. $x$ heiÃŸt Elternknoten von $y :\\Leftrightarrow x$ liegt auf dem Pfad von der Wurzel nach $y$ direkt vor $y$. Sei $G = (V, E)$ ein Baum und $x, y \\in V$. $x$ heiÃŸt Kindknoten von $y :\\Leftrightarrow y$ ist Elternknoten von $x$. BinÃ¤re BÃ¤ume Binary tree datastructure Sei $G = (V, E)$ ein Baum. $G$ heiÃŸt binÃ¤rer Baum $:\\Leftrightarrow \\forall_{x \\in V}: x$ hat hÃ¶chstens zwei Kindknoten. Ich beziehe mich im folgenden auf ungerichtete, binÃ¤re BÃ¤ume. Soll heiÃŸen, jeder Knoten kennt seine Kinder- und seinen Vaterknoten. Wie wÃ¼rde man das implementieren? Im Prinzip wie eine doppelt verkettete Liste. Jeder Knoten hat einen Zeiger auf den Eltern-Knoten und zwei Zeiger auf die Kindknoten. Operation Worst-Case-Laufzeit Anmerkungen Suchen \\({\\cal O}(|V| + |E|)\\) â†’ Graphentraversierung Minimum \\({\\cal O}(|V| + |E|)\\) â†’ Graphentraversierung Maximum \\({\\cal O}(|V| + |E|)\\) â†’ Graphentraversierung EinfÃ¼gen \\({\\cal O}(|V|)\\) LÃ¶schen \\({\\cal O}(|V| + |E|)\\) â†’ Suchen VorgÃ¤nger \\({\\cal O}(1)\\) ImplementierungsabhÃ¤ngig! Nachfolger \\({\\cal O}(1)\\) SuchbÃ¤ume Binary search tree Dieser Baum hat die gleichen Werte wie der Baum oberhalb, aber es gilt nun: Der Wert aller Knoten links vom aktuellen Konten ist kleiner oder gleich dem des aktuelle, der Wert aller Knoten rechts davon ist echt grÃ¶ÃŸer. Ich beschrÃ¤nke mich hier auf binÃ¤re SuchbÃ¤ume. Damit ergeben sich folgende Laufzeiten: Sei \\(G = (V, E)\\) ein beliebiger binÃ¤rer Suchbaum. Jeder Knoten kennt seine Kinder- und seinen Vaterknoten. Operation Worst-Case-Laufzeit Anmerkungen Suchen \\({\\cal O}(|V|)\\) â†’ Verkettete Liste Minimum \\({\\cal O}(|V|)\\) â†’ Verkettete Liste Maximum \\({\\cal O}(|V|)\\) â†’ Verkettete Liste EinfÃ¼gen \\({\\cal O}(|V|)\\) â†’ Verkettete Liste LÃ¶schen \\({\\cal O}(|V|)\\) â†’ Verkettete Liste VorgÃ¤nger \\({\\cal O}(1)\\) ImplementierungsabhÃ¤ngig! Nachfolger \\({\\cal O}(1)\\) Rot-Schwarz-BÃ¤ume Red Black Tree Sei \\(G = (V, E)\\) ein binÃ¤rer Suchbaum. G heiÃŸt Rot-Schwarz-Baum \\(: \\Leftrightarrow\\) FÃ¼r G gilt: Jeder Knoten ist entweder Rot oder Schwarz. Der Wurzelknoten ist schwarz. Die Blattknoten sind schwarz. Ein Knoten ist rot \\(\\Rightarrow\\) Beide Kinder sind schwarz. \\(\\forall x \\in V:\\) Alle Pfade von x zu einem Blatt haben die gleiche Anzahl schwarzer Knoten. Operation Worst-Case-Laufzeit Anmerkungen Suchen ${\\cal O}(\\lg n)$ Minimum ${\\cal O}(\\lg n)$ Maximum ${\\cal O}(\\lg n)$ EinfÃ¼gen ${\\cal O}(\\lg n)$ LÃ¶schen ${\\cal O}(\\lg n)$ VorgÃ¤nger ${\\cal O}(1)$ Nachfolger ${\\cal O}(1)$ Eine Python-Implementation ist hier zu finden: https://github.com/MartinThoma/algorithms Heaps Ein binÃ¤rer Min-Heap Ich beschrÃ¤nke mich im folgenden auf binÃ¤re Min-Heaps . Operation Worst-Case-Laufzeit Anmerkungen Suchen \\({\\cal O}(n)\\) â†’ Falls als array dargestellt, einfach alle Elemente des Arrays durchlaufen Minimum \\({\\cal O}(1)\\) Extract-Minimum \\({\\cal O}(\\log n)\\) â†’ Heapify Maximum \\({\\cal O}(n)\\) â†’ Suche EinfÃ¼gen \\({\\cal O}(\\log n)\\) â†’ Heapify LÃ¶schen \\({\\cal O}(\\log n)\\) â†’ Heapify (bei bekannter Position des Elements, sonst siehe Suche) VorgÃ¤nger \\({\\cal O}(1)\\) Hat keine besondere Bedeutung in Heaps. Nachfolger \\({\\cal O} (1)\\) Hat keine besondere Bedeutung in Heaps. B-BÃ¤ume B-Baum der Ordnung 2 B-Baum der Ordnung 3 Ein B-Baum ist ein immer vollstÃ¤ndig balancierter Baum, der Daten sortiert nach SchlÃ¼sseln speichert. Er kann binÃ¤r sein, ist aber im Allgemeinen kein BinÃ¤rbaum. Das EinfÃ¼gen, Suchen und LÃ¶schen von Daten in B-BÃ¤umen ist in amortisiert logarithmischer Zeit mÃ¶glich. B-BÃ¤ume wachsen â€“ und schrumpfen â€“ anders als viele SuchbÃ¤ume von den BlÃ¤ttern hin zur Wurzel. Quelle: Wikipedia Die beiden abgebildeten B-BÃ¤ume sind entstanden, indem die Zahlen von 0 bis 19 in aufsteigener Reihenfolge eingefÃ¼gt wurden. FÃ¼r einen B-Baum der Ordnung t, \\(t \\geq 2\\) , gilt: Alle Pfade von der Wurzel zu einem Blatt sind gleich lang. Die Wurzel hat mindestens 2, hÃ¶chstens 2t Kinder. Alle anderen inneren Knoten haben mindestens t, hÃ¶chstens 2t Kinder. Jeder Knoten mit i Kindern hat i-1 SchlÃ¼ssel. Die beiden B-BÃ¤ume habe ich mit diesem Script erstellt. Mehr zu B-BÃ¤umen gibt es in diesem Artikel Ã¼ber B-BÃ¤ume . Tries Trie Bildquelle: Wikipedia Ein Trie ist ein spezieller digitaler Baum. Ein Trie oder PrÃ¤fixbaum ist eine Datenstruktur, die in der Informatik zum Suchen nach Zeichenketten verwendet wird. Es handelt sich dabei um einen speziellen Suchbaum zur gleichzeitigen Speicherung mehrerer Zeichenketten. Quelle: Wikipedia Wo werden Tries genutzt? Python charmap encoder ( source ) Der Normalizer scheint Tries zu verwenden.","tags":"German posts","title":"Ãœbersicht Ã¼ber Datenstrukturen"},{"url":"https://martin-thoma.com/swing-ii-how-to-arrange-objects/","text":"Without GUI Objects can be arranged with GridBagLayout and GridBagConstraints . This is an example: Code: import java.awt.GridBagConstraints ; import java.awt.GridBagLayout ; import java.awt.Insets ; import java.awt.MouseInfo ; import java.awt.Point ; import javax.swing.JButton ; import javax.swing.JFrame ; import javax.swing.JPanel ; import javax.swing.JTextField ; public class test { public static void main ( String [] args ) { // Open the window where the mouse pointer is Point location = MouseInfo . getPointerInfo (). getLocation (); int x = ( int ) location . getX (); int y = ( int ) location . getY (); JFrame frame = new JFrame ( \"My title!\" ); frame . setLocation ( x , y ); frame . setVisible ( true ); frame . setSize ( 200 , 200 ); frame . setDefaultCloseOperation ( JFrame . EXIT_ON_CLOSE ); JPanel panel = new JPanel ( new GridBagLayout ()); frame . add ( panel ); //set the size of the window to the maximum //frame.setExtendedState(frame.getExtendedState() | // Frame.MAXIMIZED_BOTH); JButton button1 = new JButton ( \"1\" ); JButton button2 = new JButton ( \"2\" ); JButton button3 = new JButton ( \"3\" ); JButton button4 = new JButton ( \"4\" ); JButton button5 = new JButton ( \"5\" ); JButton button6 = new JButton ( \"6\" ); JButton button7 = new JButton ( \"7\" ); JButton button8 = new JButton ( \"8\" ); JButton button9 = new JButton ( \"9\" ); Insets i = new Insets ( 5 , 5 , 5 , 5 ); JTextField tf = new JTextField ( 13 ); GridBagConstraints cText = new GridBagConstraints (); cText . gridx = 0 ; cText . gridy = 0 ; cText . gridwidth = GridBagConstraints . REMAINDER ; cText . insets = i ; panel . add ( tf , cText ); GridBagConstraints c1 = new GridBagConstraints (); c1 . gridx = 0 ; c1 . gridy = 1 ; c1 . insets = i ; panel . add ( button1 , c1 ); GridBagConstraints c2 = new GridBagConstraints (); c2 . gridx = 1 ; c2 . gridy = 1 ; c2 . insets = i ; panel . add ( button2 , c2 ); GridBagConstraints c3 = new GridBagConstraints (); c3 . gridx = 2 ; c3 . gridy = 1 ; c3 . insets = i ; panel . add ( button3 , c3 ); GridBagConstraints c4 = new GridBagConstraints (); c4 . gridx = 0 ; c4 . gridy = 2 ; c4 . insets = i ; panel . add ( button4 , c4 ); GridBagConstraints c5 = new GridBagConstraints (); c5 . gridx = 1 ; c5 . gridy = 2 ; c5 . insets = i ; panel . add ( button5 , c5 ); GridBagConstraints c6 = new GridBagConstraints (); c6 . gridx = 2 ; c6 . gridy = 2 ; c6 . insets = i ; panel . add ( button6 , c6 ); GridBagConstraints c7 = new GridBagConstraints (); c7 . gridx = 0 ; c7 . gridy = 3 ; c7 . insets = i ; panel . add ( button7 , c7 ); GridBagConstraints c8 = new GridBagConstraints (); c8 . gridx = 1 ; c8 . gridy = 3 ; c8 . insets = i ; panel . add ( button8 , c8 ); GridBagConstraints c9 = new GridBagConstraints (); c9 . gridx = 2 ; c9 . gridy = 3 ; c9 . insets = i ; panel . add ( button9 , c9 ); } } Google WindowBuilder Goole offers a free Eclipse plugin called WindowBuilder : WindowBuilder is a powerful and easy to use bi-directional Java GUI designer that makes it very easy to create Java GUI applications without spending a lot of time writing code to display simple forms. Installation They offer great installation instructions ! (The download takes a while. Time to make a cup of tea.) Editing You have to open your project with the window builder: Open existing SWING-file with Window Builder The Window-Builder-View looks like this: Eclipse WindowBuilder View You can easily resize the window: Resize a window with WindowBuilder Positioning single components is also simple: Position a single component with WindowBuilder Adding a menu bar worked fine: MenuBar added with WindowBuilder See also How to Use GridBagLayout Which Swing layout(s) do you recommend?","tags":"Code","title":"Swing II: How to arrange Objects"},{"url":"https://martin-thoma.com/how-to-use-swing/","text":"Swing is a Java package for creating graphical user interfaces (GUI). I will give you complete, runnable examples how you could use Swing. All examples are done in test.java Basic examples JFrame The basic class is JFrame : import javax.swing.JFrame ; public class test { public static void main ( String [] args ) { JFrame frame = new JFrame ( \"My title!\" ); frame . setVisible ( true ); frame . setSize ( 200 , 200 ); frame . setDefaultCloseOperation ( JFrame . EXIT_ON_CLOSE ); } } You will get: JPanel You add your elements to a JPanel: import javax.swing.JButton ; import javax.swing.JFrame ; import javax.swing.JLabel ; import javax.swing.JPanel ; public class test { public static void main ( String [] args ) { JFrame frame = new JFrame ( \"My title!\" ); frame . setVisible ( true ); frame . setSize ( 300 , 150 ); frame . setDefaultCloseOperation ( JFrame . EXIT_ON_CLOSE ); JPanel panel = new JPanel (); frame . add ( panel ); JLabel label = new JLabel ( \"my label\" ); panel . add ( label ); JButton button = new JButton ( \"my button\" ); panel . add ( button ); } } It looks like this: Action Listeners This is the most simple example of an ActionListener . When you click on the button, it creates a new JFrame. import java.awt.event.ActionEvent ; import java.awt.event.ActionListener ; import javax.swing.JButton ; import javax.swing.JFrame ; import javax.swing.JLabel ; import javax.swing.JPanel ; public class test { public static void main ( String [] args ) { JFrame frame = new JFrame ( \"My title!\" ); frame . setVisible ( true ); frame . setSize ( 300 , 150 ); frame . setDefaultCloseOperation ( JFrame . EXIT_ON_CLOSE ); JPanel panel = new JPanel (); frame . add ( panel ); JLabel label = new JLabel ( \"my label\" ); panel . add ( label ); JButton button = new JButton ( \"my button\" ); panel . add ( button ); button . addActionListener ( new MyAction ()); } static class MyAction implements ActionListener { @Override public void actionPerformed ( ActionEvent e ) { JFrame frame2 = new JFrame ( \"clicked\" ); frame2 . setVisible ( true ); frame2 . setSize ( 200 , 200 ); } } } See also Java 7 Swing Documentation Trail: Creating a GUI With JFC/Swing Continue with part II: How to arrange Objects with Swing","tags":"Code","title":"Swing I: How to use Swing"},{"url":"https://martin-thoma.com/how-to-parse-command-line-arguments-in-java/","text":"If you are using Eclipse, you might want to add your arguments. To specify them, go to: Run â†’ Run Configurations ... â†’ Arguments args4j args4j is a small Java class library that makes it easy to parse command line options/arguments in your CUI application. Source: args4j.kohsuke.org Lets see how easy it really is. Requirements First, you have to get the package. It is not in my Ubuntu-Version, but Ubuntu Quantal will have args4j . The package is called libargs4j-java . If you can't install it this way, you have to download args4j . Currently, it is args4j-2.0.21.jar . You can add this as an external jar to Eclipse: Right-click on your project. Select \"Properties\" Type \"java build path\" in the input field at the upper left corner of the window. Now it should look like this: Project properties in Eclipse - Libraries Now you have to click on \"Add External Jar\" and add the args4j.jar file. Source Example As always in Java, you add another class for parsing your command line values. I've called it CommandLineValues.java and it does only check for the command line argument -i FILE or --input FILE . import java.io.File ; import org.kohsuke.args4j.CmdLineException ; import org.kohsuke.args4j.CmdLineParser ; import org.kohsuke.args4j.Option ; /** * This class handles the programs arguments. */ public class CommandLineValues { @Option ( name = \"-i\" , aliases = { \"--input\" }, required = true , usage = \"input file with two matrices\" ) private File source ; private boolean errorFree = false ; public CommandLineValues ( String ... args ) { CmdLineParser parser = new CmdLineParser ( this ); parser . setUsageWidth ( 80 ); try { parser . parseArgument ( args ); if (! getSource (). isFile ()) { throw new CmdLineException ( parser , \"--input is no valid input file.\" ); } errorFree = true ; } catch ( CmdLineException e ) { System . err . println ( e . getMessage ()); parser . printUsage ( System . err ); } } /** * Returns whether the parameters could be parsed without an * error. * * @return true if no error occurred. */ public boolean isErrorFree () { return errorFree ; } /** * Returns the source file. * * @return The source file. */ public File getSource () { return source ; } } Here is some part of the main file: public static void main ( String [] args ) { CommandLineValues values = new CommandLineValues ( args ); CmdLineParser parser = new CmdLineParser ( values ); try { parser . parseArgument ( args ); } catch ( CmdLineException e ) { System . exit ( 1 ); } // Now you can use the command line values List < ArrayList < ArrayList < Integer >>> matrices = read ( values . getSource ()); ArrayList < ArrayList < Integer >> A = matrices . get ( 0 ); ArrayList < ArrayList < Integer >> B = matrices . get ( 1 ); int [][] C = ijkAlgorithm ( A , B ); printMatrix ( C ); } Usage Examples If you do not specify the required parameters, you get a quite good error message: moose@pc07:~/Desktop$ java -jar matrix-multiplication.jar Option \"-i (--input)\" is required -i ( --input ) FILE : input file with two matrices Help is not automatically generated: moose@pc07:~/Desktop$ java -jar matrix-multiplication.jar --help \"--help\" is not a valid option -i ( --input ) FILE : input file with two matrices If you want to have default parameters, you simply assign the values to the attributes: @Option ( name = \"-l\" , aliases = { \"--leafsize\" }, required = false , usage = \"input file with two matrices\" ) private int leafsize = 32 ; Note: How can I prevent Eclipse from adding the 'final' for certain lines of Java code? Commons CLI Installation As for args4j, they offer a jar file which is in commons-cli-1.2-bin.tar.gz on the download-page . If you just want to test if you have the required packages, copy this piece of code to Eclipse: public class CommandLineValues { CommandLineParser parser = new BasicParser (); } If you get the following error, you don't have the required org.apache.commons.cli : Java error mentioned by Eclipse: Missing org.apache.commons.cli Usage examples I have not found a single, complete and working usage example. See also Is there a good command line argument parser for Java? - A lot of other command line parsers are mentioned for Java. args4j JavaDoc Apache CLI JavaDoc","tags":"Code","title":"How to parse command line arguments in Java"},{"url":"https://martin-thoma.com/how-to-parse-command-line-arguments-in-python/","text":"Argparse The argparse module makes it easy to write user-friendly command-line interfaces. The program defines what arguments it requires, and argparse will figure out how to parse those out of sys.argv. The argparse module also automatically generates help and usage messages and issues errors when users give the program invalid arguments. Installation I had to install python-argparse on my old Ubuntu machine before I could use it. Usage As far as I've just tried it, you can use argparse very similar to optparse. See this diff for my switch from optparse to argparse for a simple script. It is very easy to add command line options argument (if you require an option, it would not be an option any more, would it? I'll try to call them arguments from now on): #!/usr/bin/env python # -*- coding: utf-8 -*- from argparse import ArgumentParser parser = ArgumentParser () # Add more options if you like parser . add_argument ( \"-f\" , \"--file\" , dest = \"myFilenameVariable\" , help = \"write report to FILE\" , metavar = \"FILE\" ) parser . add_argument ( \"-q\" , \"--quiet\" , action = \"store_false\" , dest = \"verbose\" , default = True , help = \"don't print status messages to stdout\" ) args = parser . parse_args () print ( args . myFilenameVariable ) Every option has some values like: dest : You will access the value of option with this variable help : This text gets displayed whey someone uses --help . default : If the command line argument was not specified, it will get this default value. action : Actions tell optparse what to do when it encounters an option on the command line. action defaults to store . These actions are available: store : take the next argument (or the remainder of the current argument), ensure that it is of the correct type, and store it to your chosen destination dest. store_true : store True in dest if this flag was set. store_false : store False in dest if this flag was set. store_const : store a constant value append : append this option's argument to a list count : increment a counter by one callback : call a specified function nargs : ArgumentParser objects usually associate a single command-line argument with a single action to be taken. The nargs keyword argument associates a different number of command-line arguments with a single action. required : Mark a command line argument as non-optional (required). choices : Some command-line arguments should be selected from a restricted set of values. These can be handled by passing a container object as the choices keyword argument to add_argument(). When the command line is parsed, argument values will be checked, and an error message will be displayed if the argument was not one of the acceptable values. type : Use this command, if the argument is of another type (e.g. int or float). argparse automatically generates a help text. So if you call python myScript.py --help you will get something like that: usage: ikjMultiplication.py [ -h ] [ -i FILE ] ikjMatrix multiplication optional arguments: -h, --help show this help message and exit -i FILE input file with two matrices Example 1: Fibonacci It is absolutely no problem to calculate the 100,000st Fibonacci number. #!/usr/bin/env python # -*- coding: utf-8 -*- def mul ( A , B ): a , b , c = A d , e , f = B return a * d + b * e , a * e + b * f , b * e + c * f def pow ( A , n ): if n == 1 : return A if n & 1 == 0 : return pow ( mul ( A , A ), n // 2 ) else : return mul ( A , pow ( mul ( A , A ), ( n - 1 ) // 2 )) def fib ( n ): if n < 2 : return n return pow (( 1 , 1 , 0 ), n - 1 )[ 0 ] if __name__ == \"__main__\" : import argparse parser = argparse . ArgumentParser ( description = \"Fibonacci-Script\" ) parser . add_argument ( \"-n\" , metavar = 'N' , type = int , help = \"print the N-th fibonacci number\" ) args = parser . parse_args () print fib ( args . n ) Note that it uses type=int not type=\"int\" as it was in optparse. Example 2: less #!/usr/bin/env python # -*- coding: utf-8 -*- def mul ( A , B ): a , b , c = A d , e , f = B return a * d + b * e , a * e + b * f , b * e + c * f def pow ( A , n ): if n == 1 : return A if n & 1 == 0 : return pow ( mul ( A , A ), n // 2 ) else : return mul ( A , pow ( mul ( A , A ), ( n - 1 ) // 2 )) def fib ( n ): if n < 2 : return n return pow (( 1 , 1 , 0 ), n - 1 )[ 0 ] if __name__ == \"__main__\" : import argparse parser = argparse . ArgumentParser ( description = \"less script\" ) parser . add_argument ( \"-f\" , \"--file\" , dest = \"filename\" , help = \"write report to FILE\" , metavar = \"FILE\" ) parser . add_argument ( \"-n\" , dest = \"n\" , default = 10 , type = int , help = \"how many lines get printed\" ) parser . add_argument ( \"-q\" , \"--quiet\" , action = \"store_false\" , dest = \"verbose\" , default = True , help = \"don't print status messages to stdout\" ) args = parser . parse_args () if args . verbose : print ( \"Will open file now and print %i lines.\" % args . n ) f = open ( args . filename , 'r' ) for i in xrange ( args . n ): print f . readline () Example 3: copy-paste template This is how I use it most of the time. I want to show defaults in help: #!/usr/bin/env python # -*- coding: utf-8 -*- \"\"\"Example for a simple program with a command line parser.\"\"\" import os def is_valid_file ( parser , arg ): \"\"\" Check if arg is a valid file that already exists on the file system. Parameters ---------- parser : argparse object arg : str Returns ------- arg \"\"\" arg = os . path . abspath ( arg ) if not os . path . exists ( arg ): parser . error ( \"The file %s does not exist!\" % arg ) else : return arg def get_parser (): \"\"\"Get parser object for script xy.py.\"\"\" from argparse import ArgumentParser , ArgumentDefaultsHelpFormatter parser = ArgumentParser ( description = __doc__ , formatter_class = ArgumentDefaultsHelpFormatter ) parser . add_argument ( \"-f\" , \"--file\" , dest = \"filename\" , type = lambda x : is_valid_file ( parser , x ), help = \"write report to FILE\" , metavar = \"FILE\" ) parser . add_argument ( \"-n\" , dest = \"n\" , default = 10 , type = int , help = \"how many lines get printed\" ) parser . add_argument ( \"-q\" , \"--quiet\" , action = \"store_false\" , dest = \"verbose\" , default = True , help = \"don't print status messages to stdout\" ) return parser if __name__ == \"__main__\" : args = get_parser () . parse_args () Optparse Deprecated since version 2.7: The optparse module is deprecated and will not be developed further; development will continue with the argparse module. Parsing command line arguments with optparse was very easy, but as it is deprecated and argparse works almost the same way, I will not make any examples. Just use argparse. See also Why use argparse rather than optparse? Python argparse and bash completion","tags":"Code","title":"How to parse command line arguments in Python"},{"url":"https://martin-thoma.com/java-puzzle-3-rounding/","text":"The puzzle What is the output of the following script: public class test { public static void main ( String [] args ) { double x = 0.4999999999999999 ; double y = 0.49999999999999992 ; double z = 0.49999999999999994 ; System . out . println ( x + \" rounded is \" + Math . round ( x )); System . out . println ( y + \" rounded is \" + Math . round ( y )); System . out . println ( z + \" rounded is \" + Math . round ( z )); } } . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Answer 0 .4999999999999999 rounded is 0 0 .49999999999999994 rounded is 1 0 .49999999999999994 rounded is 1 Explanation It's a bug . See also: Why does Math.round(0.49999999999999994) return 1","tags":"Code","title":"Java Puzzle #3: Rounding"},{"url":"https://martin-thoma.com/java-puzzle-2-integers-and-floats/","text":"Basics As you might know, Americans measure the temperature in Fahrenheit . I'm not quite sure, but I guess the rest of the world uses Celsius . 0Â° C is the temperature when water freezes. 100Â° C is the temperature when water boils. 0Â° F is the lowest temperature of the winter 1708/1709 in GdaÅ„sk . 32Â° F is the temperature when water boils. If you want to calculate the temperature \\(T_C\\) in Â°C from \\(T_F\\) in Â°F you can use this formula: \\(T_C = (T_F &minus; 32) &middot; \\frac{5}{9}\\) The puzzle What is the output of the following script? public class test { static double fahrenheitToCelsius ( double fahrenheit ) { return ( fahrenheit - 32 ) * ( 5 / 9 ); } public static void main ( String [] args ) { double fahrenheit = 100 ; double celsius = fahrenheitToCelsius ( fahrenheit ); System . out . format ( \"%.2f&deg; Fahrenheit is %.2f&deg; C\\n\" , fahrenheit , celsius ); fahrenheit = 30 ; celsius = fahrenheitToCelsius ( fahrenheit ); System . out . format ( \"%.2f&deg; Fahrenheit is %.2f&deg; C\\n\" , fahrenheit , celsius ); } } . . . . . . . . . . . . . . . . . . . . . . . . . Answer 100 .00 & deg ; Fahrenheit is 0 .00 & deg ; C 30 .00 & deg ; Fahrenheit is -0.00 & deg ; C Explanation The problem is integer division. public class test { public static void main ( String [] args ) { System . out . format ( \"5 / 9 = %.2f\\n\" , ( double ) ( 5 / 9 )); } } This outputs: 5 / 9 = 0 .00 So you are multiplying with \\(\\pm 0\\) instead of \\(0.55555\\) .","tags":"Code","title":"Java Puzzle #2: Integers and Floats"},{"url":"https://martin-thoma.com/algorithmen-klausur/","text":"FÃ¼r die Klausur in Algorithmen I sollte man Folgendes auf jeden Fall wissen: Wie sind die Landau-Symbole \\(\\cal O(f(n)), \\Theta(f(n)), \\Omega(f(n))\\) definiert? â†’ Antwort Wie lautet das Master-Theorem? â†’ Antwort Wie funktioniert der Bellman-Ford-Algorithmus und was macht er? â†’ Antwort Wie funktioniert der Dijkstra-Algorithmus und was macht er? â†’ Antwort Wie funktioniert der Algorithmus von Kruskal und was macht er? â†’ Antwort Wie funktioniert der Algorithmus von Prim und was macht er? â†’ Antwort Was ist ein Heap, ein B-Baum, ein Digitaler Baum und was ein Suchbaum? â†’ Antwort Sei \\(A :=\\) {Insertionsort, Quicksort, Mergesort, Heapsort, Selectionsort}. Beantworte und begrÃ¼nde fÃ¼r \\(x \\in A\\) folgende Fragen: Wie funktioniert x? Ist x stabil? Arbeitet x in-place? Hat x im Worst-Case optimales Laufzeitverhalten? Hat x im Worst-Case optimales Speicherplatzverhalten? â†’ Antwort Wie funktioniert Radixsort? â†’ Antwort Warum ist Radixsort und Countingsort nur schlecht mit den Sortieralgorithmen aus vergleichbar? Welches Worst-Case Laufzeitverhalten hat die Breitensuche , welches die Tiefensuche ? Some Random Facts Das ist ein Graph, bei dem der Algorithmus von Dijkstra fehlschlÃ¤gt: Minimales Beispiel fÃ¼r einen Graphen, bei dem der Dijkstra-Algorithmus fehlschlÃ¤gt. Termine Datum : Dienstag, der 31.07.2012 um 17:00 Uhr Ort : Die Sitze sind alphabetisch nach Ihrem Nachnamen eingeteilt: A-C HÃ¶rsaal am Fasanengarten(50.35) D-J Gerthsen HÃ¶rsaal(30.21) K-O Audimax(30.95) P-R Daimler(10.21) S Benz(10.21) T-V Tulla(11.40) W-Z Neue Chemie(30.46) Dauer : 120 min. ( Quelle ) Punkte : 60 Ãœbungsschein : Gibt es nicht. Bonuspunkte gibt es auch nicht. Sitzplatzverteilung : hier Nicht vergessen Studentenausweis Kugelschreiber Klausurergebnisse Die Klausurergebnisse hÃ¤ngen im SCC, 3. OG, aus. Klausureinsicht : 23.08.2012 und 24.08.2012","tags":"German posts","title":"Algorithmen-Klausur"},{"url":"https://martin-thoma.com/ubersicht-uber-sortieralgorithmen/","text":"Eine Ãœbersicht Ã¼ber gÃ¤ngige Sortieralgorithmen: Vergleichsbasiert Name Laufzeit stabil in-place B AVG W Selectionsort $\\Theta (n&#94;2)$ $\\Theta (n&#94;2)$ $\\Theta (n&#94;2)$ [1] Bubblesort $\\Theta (n)$ $\\cal{O}(n&#94;2)$ $\\Theta (n&#94;2)$ Insertionsort $\\Theta (n)$ $\\Theta (n&#94;2)$ $\\Theta (n&#94;2)$ Quicksort $\\Theta (n \\cdot log(n))$ $\\Theta (n \\cdot log(n))$ $\\Theta (n&#94;2)$ Heapsort $\\cal{O}(n \\cdot log(n))$ $\\cal{O}(n \\cdot log(n))$ $\\cal{O}(n \\cdot log(n))$ Mergesort $\\Theta (n \\cdot log(n))$ $\\Theta (n \\cdot log(n))$ $\\Theta (n \\cdot log(n))$ [2] Timsort $\\Theta (n)$ $\\cal{O}(n \\cdot log(n))$ $\\cal{O}(n \\cdot log(n))$ Ich habe - bis auf Timsort - jeden dieser Algorithmen in Python implementiert, siehe Python-Code fÃ¼r Sortieralgorithmen . [1] : Beispiel: A = [2, 2, 1] [2] : in der regel nicht in-place, kann aber auch in-place implementiert werden. Nicht Vergleichsbasiert Es sei \\(n\\) die Anzahl der Zahlen, \\(d\\) die maximale Anzahl der Stellen \\(k\\) die Anzahl der mÃ¶glichen Zeichen (die Basis). Dann gilt: Name Worst-Case Laufzeit stabil in-place Radixsort \\(\\cal{O}(d \\cdot (n+k))\\) Countingsort \\(\\cal{O}(n+k)\\) Siehe auch Sorting Algorithm Animations : Eine tolle Website, die veranschaulicht, wie verschiedene Sortieralgorithmen funktionieren. What different sorting algorithms sound like","tags":"German posts","title":"Ãœbersicht Ã¼ber Sortieralgorithmen"},{"url":"https://martin-thoma.com/how-to-search-for-mathematical-symbols-in-latex/","text":"Detexify The easiest way to search for a math symbol is Detexify . This webservices allows you to draw the symbol. It looks like this: Detexify - A webservice for finding LaTeX symbols. Symbol tables Arrows $\\rightarrow$ \\rightarrow $\\leftarrow$ \\leftarrow $\\Rightarrow$ \\Rightarrow $\\Leftarrow$ \\Leftarrow $\\leftrightarrow$ \\leftrightarrow $\\Leftrightarrow$ \\Leftrightarrow $\\nRightarrow$ \\nRightarrow $\\nrightarrow$ \\nrightarrow $\\leadsto$ \\leadsto $\\mapsto$ \\mapsto . . . . Greek $\\alpha$ \\alpha $\\beta$ \\beta $\\gamma$ \\gamma $\\delta$ \\delta $\\zeta$ \\zeta $\\eta$ \\eta $\\theta$ \\theta $\\epsilon, \\varepsilon$ \\epsilon, \\varepsilon $\\iota$ \\iota $\\kappa$ \\kappa $\\lambda$ \\lambda $\\mu$ \\mu $\\nu$ \\nu $\\xi$ \\xi o o $\\pi$ \\pi $\\rho$ \\rho $\\sigma$ \\sigma $\\tau$ \\tau $\\upsilon$ \\upsilon $\\phi$ \\phi $\\chi$ \\chi $\\psi$ \\psi $\\omega, \\Omega$ \\omega, \\Omega $\\Phi$ \\Phi $\\varphi$ \\varphi . . . . $\\Lambda$ \\Lambda $\\Delta$ \\Delta . . . . Operations $\\cdot$ \\cdot $\\oplus$ \\oplus $\\times$ \\times $\\nabla$ \\nabla $\\pm$ \\pm $\\mp$ \\mp $\\cup$ \\cup $\\cap$ \\cap Relations $\\approx$ \\approx $\\sim$ \\sim $\\cong$ \\cong $\\neq$ \\neq Calligraphic Letters $\\cal{O}$ \\cal{O} $\\mathfrak{M}$ \\mathfrak{O} $\\mathfrak{R}$ \\mathfrak{R} Sets $\\mathbb{N}$ \\mathbb{N} $\\mathbb{Z}$ \\mathbb{Z} $\\mathbb{R}$ \\mathbb{R} $\\mathbb{C}$ \\mathbb{C} $\\mathbb{A}$ \\mathbb{A} $\\cap$ \\cap $\\cup$ \\cup $\\in$ \\in $\\subseteq$ \\subseteq $\\subsetneq$ \\subsetneq $\\notin$ \\notin $\\bigcup$ \\bigcup Other You might need \\qed , \\qedsymbol , \\blacksquare for proofs. It is the Tombstone \\(\\blacksquare\\) I've recently needed \\(\\dots, \\ddots, \\vdots\\) ( \\dots , \\ddots , \\vdots ) for a visualization in a matrix. Note that you can write ... instead of \\dots , but you'll lose the semantics. See also List of symbols - 164 pages of symbols Displaying a formula","tags":"My bits and bytes","title":"How to search for mathematical symbols in LaTeX"},{"url":"https://martin-thoma.com/when-is-matrix-multiplication-commutative/","text":"Matrix multiplication in general is not commutative. Here is an example: \\(A, B \\in R&#94;{2 \\times 2}\\) $$A := \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}$$ $$B := \\begin{pmatrix} 5 & 6 \\\\ 7 & 8 \\end{pmatrix}$$ $$A \\cdot B = \\begin{pmatrix} 19 & 22 \\\\ 43 & 50 \\end{pmatrix} \\neq \\begin{pmatrix} 23 & 34 \\\\ 31 & 46 \\end{pmatrix} = B \\cdot A$$ When is 2x2 matrix multiplication commutative? $$\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\cdot \\begin{pmatrix} e & f \\\\ g & h \\end{pmatrix} = \\begin{pmatrix} ae + bg & af + bh \\\\ ce + dg & cf + dh \\end{pmatrix}$$ $$\\begin{pmatrix} e & f \\\\ g & h \\end{pmatrix} \\cdot \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} = \\begin{pmatrix} ae + cf & be + df \\\\ ag + ch & bg + dh \\end{pmatrix}$$ So you get four equations: $$\\begin{eqnarray*} I) & ae + bg &= ae + cf &\\Leftrightarrow bg = cf \\\\ II) & af + bh &= be + df\\\\ III) & ce + dg &= ag + ch\\\\ IV) & cf + dh &= bg + dh &\\Leftrightarrow cf = bg \\end{eqnarray*}$$ You might note that (I) is the same as (IV). So you have those equations: $$\\begin{eqnarray*} I) & bg = cf \\\\ II) & af + bh &= be + df & \\Leftrightarrow f (a - d) = b (e - h)\\\\ III) & ce + dg &= ag + ch & \\Leftrightarrow g (a - d) = c (e - h) \\end{eqnarray*}$$ Case #1: a != d and e != h $$\\begin{eqnarray*} I) & bg &= cf \\\\ II) & \\frac{f}{g} &= \\frac{b}{c} \\Leftrightarrow cf = bg \\end{eqnarray*}$$ Now (I) and (II) are essentially the same. So we only demand that \\( bg = cf\\) and \\(a \\neq d\\) and \\(e \\neq h\\) for commutative matrix multiplication of \\(2 \\times 2\\) matrices. Case #2.1: a == d \\begin{eqnarray*} I) & bg &= cf \\\\ II) & 0 &= b (e - h)\\\\ III) & 0 &= c (e - h) \\end{eqnarray*} So you end up with: ( \\(e = h\\) and \\(bg = cf\\) ) or ( \\(b = c = 0\\) ) Case #2.2: e == h \\begin{eqnarray*} I) & bg &= cf \\\\ II) & f (a - d) &= 0\\\\ III) & g (a - d) &= 0 \\end{eqnarray*} So you end up with: ( \\(a = d\\) and \\(bg = cf\\) ) or ( \\(f = g = 0\\) ) Special Cases Matrix multiplication is always commutative if ... ... one matrix is the Identity matrix . ... one matrix is the Zero matrix . ... both matrices are \\(2 \\times 2\\) rotation matrices . (basically case #2) ... both matrices are Diagonal matrices . Simultaneous diagonalization Two matrices \\(A, B \\in R&#94;{n \\times n}\\) are called simultaneous diagonalizable \\(: \\Leftrightarrow\\) one matrix \\(S \\in R&#94;{n \\times n}\\) exists, such that \\(D_A = S&#94;{-1} \\cdot A \\cdot S\\) and \\(D_B = S&#94;{-1} \\cdot B \\cdot S\\) with \\(D_A\\) and \\(D_B\\) are diagonal matrices. Statement : \\(A, B \\in \\mathbb{R}&#94;{n \\times n}\\) are simultaneous diagonalizable \\(\\Rightarrow A \\cdot B = B \\cdot A\\) Proof : As A and B are simultaneous diagonalizable, a matrix \\(T \\in \\mathbb{R}&#94;{n \\times n}\\) exists, such that \\(D_A = S&#94;{-1} \\cdot A \\cdot S\\) and \\(D_B = S&#94;{-1} \\cdot B \\cdot S\\) with \\(D_A\\) and \\(D_B\\) are diagonal matrices. \\begin{align} \\Rightarrow A \\cdot B &= S \\cdot D_A S&#94;{-1} \\cdot S \\cdot D_B \\cdot S&#94;{-1} \\\\ &= S \\cdot D_A \\cdot D_B \\cdot S&#94;{-1} \\\\ &= S \\cdot D_B \\cdot D_A \\cdot S&#94;{-1} \\\\ &= S \\cdot D_B \\cdot S&#94;{-1} \\cdot S \\cdot D_A \\cdot S&#94;{-1} \\\\ &= B \\cdot A \\blacksquare \\end{align} Statement : \\(A \\cdot B = B \\cdot A \\nRightarrow A, B \\in \\mathbb{R}&#94;{n \\times n}\\) are simultaneous diagonalizable. Proof : by Counter-Example $$\\begin{pmatrix}0 & 1 \\\\ 0 & 0\\end{pmatrix} \\cdot \\begin{pmatrix}1 & 0 \\\\ 0 & 1\\end{pmatrix} = \\begin{pmatrix}1 & 0 \\\\ 0 & 1\\end{pmatrix} \\cdot \\begin{pmatrix}0 & 1 \\\\ 0 & 0\\end{pmatrix}$$ but \\begin{pmatrix}0 & 1 \\\\ 0 & 0\\end{pmatrix} is not diagonalizable. \\(\\blacksquare\\) See also When is matrix multiplication commutative? on math.stackexchange.com","tags":"Mathematics","title":"When is matrix multiplication commutative?"},{"url":"https://martin-thoma.com/goto-in-python-java-and-c/","text":"GOTO is a statement of the early beginnings of programming. It is rarely used in high-level code today. Code that makes use of it is called Spaghetti code by some people. I have almost never seen goto statements in code, so I've been curious about them. GOTO from xkcd.com Python Python does NOT offer GOTO. However, somebody made a GOTO module for April Fools' Day. See goto in Python if you're still interested. Java Java has no goto statement. Studies illustrated that goto is (mis)used more often than not simply \"because it's there\". Eliminating goto led to a simplification of the language--there are no rules about the effects of a goto into the middle of a for statement, for example. Studies on approximately 100,000 lines of C code determined that roughly 90 percent of the goto statements were used purely to obtain the effect of breaking out of nested loops. As mentioned above, multi-level break and continue remove most of the need for goto statements. Source: java.sun.com C++ GOTO works in C++. Here is a minimal example: Minimal Example #include <iostream> using namespace std ; int main (){ int test = 0 ; start :; if ( test > 10 ) { goto end ; } else { test += 7 ; goto start ; } end :; cout << \"test: \" << test << endl ; return 0 ; } Output: test: 14 Euclidean GCD algorithm Most of you might know the euclidean algorithm for calculating the greatest common divisor in a version like this one: #include <iostream> using namespace std ; int euclidGCD ( int a , int b ) { while ( b != 0 ) { int m = a % b ; a = b ; b = m ; } return a ; } int main (){ // Outputs 20 cout << \"GCD of 340 and 32760: \" << euclidGCD ( 340 , 32760 ) << endl ; return 0 ; } Here is a goto-version that works perfectly fine: #include <iostream> using namespace std ; int euclidGCD ( int a , int b ) { if ( b > a ) goto b_larger ; while ( 1 ) { a = a % b ; if ( a == 0 ) return b ; b_larger : b = b % a ; if ( b == 0 ) return a ; } } int main (){ cout << \"GCD of 340 and 32760: \" << euclidGCD ( 340 , 32760 ) << endl ; return 0 ; } Source: literateprograms.org Try bad things You can't jump into a function: #include <iostream> using namespace std ; int myFunction ( int i ) { i += 1 ; inFunctionLabel :; i += 1 ; return i ; } int main (){ int test = 0 ; goto inFunctionLabel ; cout << \"test: \" << test << endl ; return 0 ; } Compiler error: gotoExample.cpp: In function & lsquo ; int myFunction ( int ) & rsquo ; : gotoExample.cpp:7: warning: label & lsquo ; inFunctionLabel & rsquo ; defined but not used gotoExample.cpp: In function & lsquo ; int main () & rsquo ; : gotoExample.cpp:15: error: label & lsquo ; inFunctionLabel & rsquo ; used but not defined So goto is at least bound to its scope.","tags":"Code","title":"GOTO in Python, Java and C++"},{"url":"https://martin-thoma.com/java-puzzle-1-pre-and-postincrement/","text":"The puzzle What is the output of the following piece of code? public class test { public static void main ( String [] args ) { int i = 1 ; i += ++ i + i ++ + ++ i ; int j = 1 ; j += ++ j + j ++ + ++ j ; int k = 1 ; k += k ++ + k ++ + ++ k ; int m = 1 ; System . out . println ( \"i = \" + i ); System . out . println ( \"j = \" + j ); System . out . println ( \"k = \" + k ); System . out . println ( \"m = \" + ( m += 1 )); } } . . . . . . . . . . . . . . . . . . . . . . Answer The output is: i = 9 j = 9 k = 8 m = 2 Explanation Part one First, take a look at statements of this structure: i += s where i is the integer and s is a statement (e.g. ++i ). This gets evaluated to i = a + s Source: docs.oracle.com Part two Lets take a look at pre- and postincrement in Java. You can quite easily figure out what the different increments do by this snippet: public class test { public static void main ( String [] args ) { int i = 0 ; int j = 0 ; int k = 0 ; System . out . println ( \"i = \" + ++ i ); System . out . println ( \"i = \" + i ); System . out . println ( \"j = \" + j ++); System . out . println ( \"j = \" + j ); System . out . println ( \"k = \" + ( k += 1 )); } } Output: i = 1 i = 1 j = 0 j = 1 k = 1 Line 7 adds +1 to i and returns the value. Line 10 returns the value of j and adds +1 to j . Line 13 adds +1 to k and returns k . Lets return to the original puzzle. Java parses your code from left to right ( Source 1 , Source 2 ). Most important: Evaluation of an expression can also produce side effects, because expressions may contain embedded assignments, increment operators, decrement operators, and method invocations. So: int i = 1 ; i += ++ i + i ++ + ++ i ; is the same as i = (( i + (++ i )) + ( i ++)) + (++ i ); The first ++i increments i to 2 and returns 2. So you have: i = 2 ; i = (( 1 + 2 ) + ( i ++)) + (++ i ); The i++ returns 2, as it is the new value of i , and increments i to 3: i = 3 ; i = (( 1 + 2 ) + 2 ) + ++ i ; The second ++i increments i to 4 and returns 4: i = 4 ; i += (( 1 + 2 ) + 2 ) + 4 ; So you end up with 9 . A parse tree of this evaluation would look like this: Parse tree The explanation for the other three ones is similar. See also Increment and decrement operators Why avoid increment (\"++\") and decrement (\"--\") operators in JavaScript? Pre- and postincrement in Java","tags":"Code","title":"Java Puzzle #1: Pre- and Postincrement"},{"url":"https://martin-thoma.com/what-is-a-fractal/","text":"[...] Fractals are typically self-similar patterns, where self-similar means they are \"the same from near as from far\". [...] The definition of fractal goes beyond self-similarity per se to exclude trivial self-similarity and include the idea of a detailed pattern repeating itself. Source: Fractal , Wikipedia Examples The Rensselaer Polytechnic Institute made an applet which allows you to create fractals by yourself. So I've tried this one as a starter: Martin Fractal #1 Martin Fractal #2 Martin Fractal #3 You might know this one: Snowflake fractal #1 Snowflake fractal #2 Snowflake fractal #3 Snowflake fractal #4 Fractals in Nature Fractals seem to appear quite often in nature. I have just re-created one that I have seen recently: Leaf fractal #1 Leaf fractal #2 Leaf fractal #3 Leaf fractal #4 Leaf fractal #5 Leaf fractal #6 Leaf fractal #9 Mandelbrot set The Mandelbrot set is maybe the best known fractal, although it is not a fractal in my opinion. It does never repeat itself. See also Fractal Mandelbrot set Visualization of a fractal TED Talk: Ron Eglash on African fractals","tags":"Cyberculture","title":"What is a fractal?"},{"url":"https://martin-thoma.com/my-latex-tikz-template/","text":"Sometimes I would like to create a single picture with Tikz for later usage on Wikipedia or my Blog. This is my LaTeX Tikz template I use in such a situation: The templates latex-document.tex \\documentclass [varwidth=true, border=2pt] { standalone } \\usepackage { tikz } \\usetikzlibrary { arrows,positioning } \\begin { document } \\begin { tikzpicture } % Your Codes should be here \\end { tikzpicture } \\end { document } Standalone Preview-Environment \\documentclass { article } \\usepackage [pdftex,active,tightpage] { preview } \\setlength\\PreviewBorder { 2mm } \\usepackage { tikz } \\usetikzlibrary { arrows,positioning } \\begin { document } \\begin { preview } \\begin { tikzpicture } % Your Codes should be here \\end { tikzpicture } \\end { preview } \\end { document } Makefile SOURCE = latex-document.tex DELAY = 80 DENSITY = 300 make : pdflatex $( SOURCE ) .tex -output-format = pdf make clean clean : rm -rf $( TARGET ) *.class *.html *.log *.aux animatedGif : pdfcrop $( SOURCE ) .pdf convert -verbose -delay $( DELAY ) -loop 0 -density $( DENSITY ) $( SOURCE ) -crop.pdf $( SOURCE ) .gif make clean transparentGif : convert $( SOURCE ) .pdf -transparent white result.gif make clean svg : pdf2svg $( SOURCE ) .pdf $( SOURCE ) .svg # Necessary, as pdf2svg does not always create valid svgs: inkscape $( SOURCE ) .svg --export-plain-svg = $( SOURCE ) .svg # Alternatively, only this one (produces worse results): #inkscape $(SOURCE).pdf --export-plain-svg=$(SOURCE).svg Requirements LaTeX ( How to install the latest LaTeX Version ) make Inkscape pdf2svg Test if you meet these requirements Make sure that you have a valid LaTeX installation. pdflatex --version should output something like: pdfTeX 3 .1415926-2.3-1.40.12 ( TeX Live 2011 ) kpathsea version 6 .0.1 Copyright 2011 Peter Breitenlohner ( eTeX ) /Han The Thanh ( pdfTeX ) . There is NO warranty. Redistribution of this software is covered by the terms of both the pdfTeX copyright and the Lesser GNU General Public License. For more information about these matters, see the file named COPYING and the pdfTeX source. Primary author of pdfTeX: Peter Breitenlohner ( eTeX ) /Han The Thanh ( pdfTeX ) . Compiled with libpng 1 .5.2 ; using libpng 1 .5.2 Compiled with zlib 1 .2.5 ; using zlib 1 .2.5 Compiled with xpdf version 3 .02pl5 Make sure you can execute Makefiles. make --version should output something like this: GNU Make 3 .81 Copyright ( C ) 2006 Free Software Foundation, Inc. This is free software ; see the source for copying conditions. There is NO warranty ; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. This program built for i486-pc-linux-gnu The command inkscape --version should return: Inkscape 0 .47 r22583 ( Apr 4 2010 ) And pdf2svg --version should return: Usage: pdf2svg <in file.pdf> <out file.svg> [ <page no> ] How to use it You have to place the Makefile in the same folder as latex-document.tex. If you have done this and if you meet the requirements, you can execute: make : Generates a PDF file from latex-document.tex make svg : Generates a SVG file from the generated PDF file make transparentGif : Generates a transparent Gif from the PDF file make animatedGif : If you have used multiple slides, this will create an animated Gif file. See How to visualize Graph algorithms with LaTeX for an example. See also How to print Source Code with LaTeX Briefe mit LaTeX schreiben (A template for letters) Plotting function graphs with LaTeX","tags":"Code","title":"My LaTeX Tikz Template"},{"url":"https://martin-thoma.com/cpp-operator-overloading/","text":"Operator overloading is heavily used in math. One of the most famous examples I know is \"+\". If you add two elements from \\(\\mathbb{N}\\) you will use the same character \"+\" as you use for adding two numbers from \\(\\mathbb{R}\\) . You even use the plus-sign if you add matrices (which is obviously something different than adding single numbers). In some programming languages, like C++, you can overload operators by yourself. First simple example Imagine you wanted to store some data - lets say the prename, surname and age - about people you know. This could be done in a struct . After you've stored it, you would like to print this information. Obviously, you don't want to do something like this: for ( int i = 0 ; i < 4 ; i ++ ) { cout << \"Person(\" << myArray [ i ]. prename << \" \" << myArray [ i ]. surname << \", \" << myArray [ i ]. age << \")\" ; } If you wanted to print this information more than one time, you would have to add this long line every time. A toString() method like the one Java uses would be nice. In C++, you don't have toString, but you can overload the << operator! This is how it works: #include <iostream> using namespace std ; typedef struct person { // attributes string prename ; string surname ; int age ; // constructor person ( string p , string s , int age ) : prename ( p ), surname ( s ), age ( age ) {} } Person ; // \"toString\" for C++ std :: ostream & operator << ( std :: ostream & strm , const person & a ) { return strm << \"Person(\" << a . prename << \" \" << a . surname << \", \" << a . age << \")\" ; } int main (){ Person Martin ( \"Martin\" , \"Thoma\" , 22 ); Person Andreas ( \"Andreas\" , \"Thoma\" , 22 ); Person AndiOld ( \"Andreas\" , \"Berger\" , 30 ); Person AndiYoung ( \"Andreas\" , \"Berger\" , 22 ); Person myArray [] = { Martin , Andreas , AndiOld , AndiYoung }; for ( int i = 0 ; i < 4 ; i ++ ) { cout << myArray [ i ] << endl ; } return 0 ; } Sorting You can sort by overloading < . You can use a sort by adding #include <algorithm> to your program and using sort(array, array + elements); This is how it looks like: #include <iostream> #include <algorithm> using namespace std ; typedef struct person { // attributes string prename ; string surname ; int age ; // constructor person ( string p , string s , int age ) : prename ( p ), surname ( s ), age ( age ) {} } Person ; // \".equals()\" for C++ bool operator < ( const Person & a , const Person & b ){ if ( ! ( a . prename == b . prename )) { return a . prename < b . prename ; } else if ( ! ( a . surname < b . surname )) { return a . surname < b . surname ; } else { return a . age < b . age ; } } // \"toString\" for C++ std :: ostream & operator << ( std :: ostream & strm , const person & a ) { return strm << \"Person(\" << a . prename << \" \" << a . surname << \", \" << a . age << \")\" ; } int main (){ Person Martin ( \"Martin\" , \"Thoma\" , 22 ); Person Andreas ( \"Andreas\" , \"Thoma\" , 22 ); Person AndiOld ( \"Andreas\" , \"Berger\" , 30 ); Person AndiYoung ( \"Andreas\" , \"Berger\" , 22 ); Person myArray [] = { Martin , Andreas , AndiOld , AndiYoung }; sort ( myArray , myArray + 4 ); for ( int i = 0 ; i < 4 ; i ++ ) { cout << myArray [ i ] << endl ; } return 0 ; } By the way, if you don't define < you get something like this: In file included from / usr / include / c ++/ 4.4 / algorithm : 62 , from operators . cpp : 2 : / usr / include / c ++/ 4.4 / bits / stl_algo . h : In function & lsquo ; const _Tp & std :: __median ( const _Tp & , const _Tp & , const _Tp & ) [ with _Tp = person ] & rsquo ; : / usr / include / c ++/ 4.4 / bits / stl_algo . h : 2268 : instantiated from & lsquo ; void std :: __introsort_loop ( _RandomAccessIterator , _RandomAccessIterator , _Size ) [ with _RandomAccessIterator = Person * , _Size = int ] & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 5220 : instantiated from & lsquo ; void std :: sort ( _RAIter , _RAIter ) [ with _RAIter = Person * ] & rsquo ; operators . cpp : 34 : instantiated from here / usr / include / c ++/ 4.4 / bits / stl_algo . h : 89 : error : no match for & lsquo ; operator <& rsquo ; in & lsquo ; __a < __b & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 90 : error : no match for & lsquo ; operator <& rsquo ; in & lsquo ; __b < __c & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 92 : error : no match for & lsquo ; operator <& rsquo ; in & lsquo ; __a < __c & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 96 : error : no match for & lsquo ; operator <& rsquo ; in & lsquo ; __a < __c & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 98 : error : no match for & lsquo ; operator <& rsquo ; in & lsquo ; __b < __c & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : In function & lsquo ; _RandomAccessIterator std :: __unguarded_partition ( _RandomAccessIterator , _RandomAccessIterator , _Tp ) [ with _RandomAccessIterator = Person * , _Tp = person ] & rsquo ; : / usr / include / c ++/ 4.4 / bits / stl_algo . h : 2268 : instantiated from & lsquo ; void std :: __introsort_loop ( _RandomAccessIterator , _RandomAccessIterator , _Size ) [ with _RandomAccessIterator = Person * , _Size = int ] & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 5220 : instantiated from & lsquo ; void std :: sort ( _RAIter , _RAIter ) [ with _RAIter = Person * ] & rsquo ; operators . cpp : 34 : instantiated from here / usr / include / c ++/ 4.4 / bits / stl_algo . h : 2209 : error : no match for & lsquo ; operator <& rsquo ; in & lsquo ; * __first < __pivot & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 2212 : error : no match for & lsquo ; operator <& rsquo ; in & lsquo ; __pivot < * __last & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : In function & lsquo ; void std :: __insertion_sort ( _RandomAccessIterator , _RandomAccessIterator ) [ with _RandomAccessIterator = Person * ] & rsquo ; : / usr / include / c ++/ 4.4 / bits / stl_algo . h : 2178 : instantiated from & lsquo ; void std :: __final_insertion_sort ( _RandomAccessIterator , _RandomAccessIterator ) [ with _RandomAccessIterator = Person * ] & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 5222 : instantiated from & lsquo ; void std :: sort ( _RAIter , _RAIter ) [ with _RAIter = Person * ] & rsquo ; operators . cpp : 34 : instantiated from here / usr / include / c ++/ 4.4 / bits / stl_algo . h : 2106 : error : no match for & lsquo ; operator <& rsquo ; in & lsquo ; __val < * __first & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : In function & lsquo ; void std :: __heap_select ( _RandomAccessIterator , _RandomAccessIterator , _RandomAccessIterator ) [ with _RandomAccessIterator = Person * ] & rsquo ; : / usr / include / c ++/ 4.4 / bits / stl_algo . h : 5067 : instantiated from & lsquo ; void std :: partial_sort ( _RAIter , _RAIter , _RAIter ) [ with _RAIter = Person * ] & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 2256 : instantiated from & lsquo ; void std :: __introsort_loop ( _RandomAccessIterator , _RandomAccessIterator , _Size ) [ with _RandomAccessIterator = Person * , _Size = int ] & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 5220 : instantiated from & lsquo ; void std :: sort ( _RAIter , _RAIter ) [ with _RAIter = Person * ] & rsquo ; operators . cpp : 34 : instantiated from here / usr / include / c ++/ 4.4 / bits / stl_algo . h : 1906 : error : no match for & lsquo ; operator <& rsquo ; in & lsquo ; * __i < * __first & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : In function & lsquo ; void std :: __unguarded_linear_insert ( _RandomAccessIterator , _Tp ) [ with _RandomAccessIterator = Person * , _Tp = person ] & rsquo ; : / usr / include / c ++/ 4.4 / bits / stl_algo . h : 2112 : instantiated from & lsquo ; void std :: __insertion_sort ( _RandomAccessIterator , _RandomAccessIterator ) [ with _RandomAccessIterator = Person * ] & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 2178 : instantiated from & lsquo ; void std :: __final_insertion_sort ( _RandomAccessIterator , _RandomAccessIterator ) [ with _RandomAccessIterator = Person * ] & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 5222 : instantiated from & lsquo ; void std :: sort ( _RAIter , _RAIter ) [ with _RAIter = Person * ] & rsquo ; operators . cpp : 34 : instantiated from here / usr / include / c ++/ 4.4 / bits / stl_algo . h : 2067 : error : no match for & lsquo ; operator <& rsquo ; in & lsquo ; __val < * __next & rsquo ; In file included from / usr / include / c ++/ 4.4 / bits / stl_algo . h : 62 , from / usr / include / c ++/ 4.4 / algorithm : 62 , from operators . cpp : 2 : / usr / include / c ++/ 4.4 / bits / stl_heap . h : In function & lsquo ; void std :: __adjust_heap ( _RandomAccessIterator , _Distance , _Distance , _Tp ) [ with _RandomAccessIterator = Person * , _Distance = int , _Tp = person ] & rsquo ; : / usr / include / c ++/ 4.4 / bits / stl_heap . h : 394 : instantiated from & lsquo ; void std :: make_heap ( _RAIter , _RAIter ) [ with _RAIter = Person * ] & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 1904 : instantiated from & lsquo ; void std :: __heap_select ( _RandomAccessIterator , _RandomAccessIterator , _RandomAccessIterator ) [ with _RandomAccessIterator = Person * ] & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 5067 : instantiated from & lsquo ; void std :: partial_sort ( _RAIter , _RAIter , _RAIter ) [ with _RAIter = Person * ] & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 2256 : instantiated from & lsquo ; void std :: __introsort_loop ( _RandomAccessIterator , _RandomAccessIterator , _Size ) [ with _RandomAccessIterator = Person * , _Size = int ] & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 5220 : instantiated from & lsquo ; void std :: sort ( _RAIter , _RAIter ) [ with _RAIter = Person * ] & rsquo ; operators . cpp : 34 : instantiated from here / usr / include / c ++/ 4.4 / bits / stl_heap . h : 232 : error : no match for & lsquo ; operator <& rsquo ; in & lsquo ; * ( __first + (( unsigned int )((( unsigned int ) __secondChild ) * 12u ))) < * ( __first + (((( unsigned int ) __secondChild ) + 0xffffffffffffffffffffffffffffffffu ) * 12u )) & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_heap . h : In function & lsquo ; void std :: __push_heap ( _RandomAccessIterator , _Distance , _Distance , _Tp ) [ with _RandomAccessIterator = Person * , _Distance = int , _Tp = person ] & rsquo ; : / usr / include / c ++/ 4.4 / bits / stl_heap . h : 244 : instantiated from & lsquo ; void std :: __adjust_heap ( _RandomAccessIterator , _Distance , _Distance , _Tp ) [ with _RandomAccessIterator = Person * , _Distance = int , _Tp = person ] & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_heap . h : 394 : instantiated from & lsquo ; void std :: make_heap ( _RAIter , _RAIter ) [ with _RAIter = Person * ] & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 1904 : instantiated from & lsquo ; void std :: __heap_select ( _RandomAccessIterator , _RandomAccessIterator , _RandomAccessIterator ) [ with _RandomAccessIterator = Person * ] & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 5067 : instantiated from & lsquo ; void std :: partial_sort ( _RAIter , _RAIter , _RAIter ) [ with _RAIter = Person * ] & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 2256 : instantiated from & lsquo ; void std :: __introsort_loop ( _RandomAccessIterator , _RandomAccessIterator , _Size ) [ with _RandomAccessIterator = Person * , _Size = int ] & rsquo ; / usr / include / c ++/ 4.4 / bits / stl_algo . h : 5220 : instantiated from & lsquo ; void std :: sort ( _RAIter , _RAIter ) [ with _RAIter = Person * ] & rsquo ; operators . cpp : 34 : instantiated from here / usr / include / c ++/ 4.4 / bits / stl_heap . h : 134 : error : no match for & lsquo ; operator <& rsquo ; in & lsquo ; * ( __first + (( unsigned int )((( unsigned int ) __parent ) * 12u ))) < __value & rsquo ; Equality You can also define == for your structs. I know this example does NOT make any sense. But it is an example you can work with: #include <iostream> using namespace std ; typedef struct person { // attributes string prename ; string surname ; int age ; // constructor person ( string p , string s , int age ) : prename ( p ), surname ( s ), age ( age ) {} } Person ; // \"comperator\" for C++ bool operator == ( const Person & a , const Person & b ){ return a . age == 30 ; } int main (){ Person Martin ( \"Martin\" , \"Thoma\" , 22 ); Person Andreas ( \"Andreas\" , \"Thoma\" , 22 ); Person AndiOld ( \"Andreas\" , \"Berger\" , 30 ); Person AndiYoung ( \"Andreas\" , \"Berger\" , 22 ); Person myArray [] = { Martin , Andreas , AndiOld , AndiYoung }; for ( int i = 0 ; i < 4 ; i ++ ) { cout << ( myArray [ i ] == myArray [ i ]) << endl ; } return 0 ; } Casting You can also define casts: #include <iostream> using namespace std ; typedef struct person { // attributes string prename ; string surname ; int age ; // constructor person ( string p , string s , int age ) : prename ( p ), surname ( s ), age ( age ) {} // prefix operator int () { return age ; } } Person ; int main (){ Person Martin ( \"Martin\" , \"Thoma\" , 22 ); Person Andreas ( \"Andreas\" , \"Thoma\" , 22 ); Person AndiOld ( \"Andreas\" , \"Berger\" , 30 ); Person AndiYoung ( \"Andreas\" , \"Berger\" , 22 ); Person myArray [] = { Martin , Andreas , AndiOld , AndiYoung }; for ( int i = 0 ; i < 4 ; i ++ ) { cout << int ( myArray [ i ]) << endl ; } return 0 ; } Adding new operators I like Python very much. Python allows me to get the power of a number like this: a = 2 ** 10 # 1024 Lets try it for C++: Doesn't work #include <iostream> using namespace std ; // does NOT work // operators.cpp:7: error: expected initializer before &lsquo;*&rsquo; token int operator ** ( int a , int b ){ int power = 1 ; for ( int i = 0 ; i < b ; i ++ ) { power *= a ; } return power ; } int main (){ cout << 2 ** 10 << endl ; return 0 ; } I guess it doesn't work as it would be very difficult to distinguish something like this: a = a * * b ; a = a ** b ; If you try to use a $ you get: operators . cpp : 16 : 13 : error : invalid suffix \"$10\" on integer constant If you try to use a Â§ you get: operators . cpp : 7 : error : stray & lsquo ; \\ 302 & rsquo ; in program operators . cpp : 7 : error : stray & lsquo ; \\ 247 & rsquo ; in program operators . cpp : 16 : error : stray & lsquo ; \\ 302 & rsquo ; in program operators . cpp : 16 : error : stray & lsquo ; \\ 247 & rsquo ; in program operators . cpp : 7 : error : expected type - specifier before & lsquo ;( & rsquo ; token You are also not allowed to redefine * : operators . cpp : 7 : error : & lsquo ; int operator * ( int , int ) & rsquo ; must have an argument of class or enumerated type Works You can wrap the integer like this: #include <iostream> using namespace std ; typedef struct integer { int inner ; // constructor integer ( int i ) : inner ( i ) {} } Integer ; int operator &#94; ( Integer a , Integer b ){ int power = 1 ; for ( int i = 0 ; i < b . inner ; i ++ ) { power *= a . inner ; } return power ; } int main (){ cout << ( Integer ( 2 ) &#94; Integer ( 10 )) << endl ; // outputs 1024 return 0 ; } See also A class for dealing with fractions - which includes 7 examples for operator overloading Operators in C and C++ The General Syntax of operator overloading in C++ . sbi, Stack Overflow. The Three Basic Rules of Operator Overloading in C++ . sbi, Stack Overflow. Overloading operators . C++-Reference.","tags":"Code","title":"C++ Operator overloading"},{"url":"https://martin-thoma.com/mathe-puzzle-1-verschleierung/","text":"Die folgende Funktion ist sehr bekannt. Wie lautet ihr Name? Seien \\(\\oplus, \\otimes: \\mathbb{R} \\times \\mathbb{R} \\rightarrow \\mathbb{R}\\) VerknÃ¼fungen auf \\(\\mathbb{R}\\) und definiert durch: \\(\\oplus(a, b) := a + b\\) \\(\\otimes(a, b) := a - b\\) Sei \\(O:\\mathbb{N} \\rightarrow \\mathbb{R}\\) eine Abbildung und definiert durch \\(O(0) := 0, O(0&#94;0) := 0&#94;0, O(o) := O(o \\otimes 0&#94;0) \\oplus O(o \\otimes 0&#94;0 \\otimes 0&#94;0)\\) . . . . . . . . AuflÃ¶sung gibts weiter unten - die Abbildung ist wirklich sehr bekannt â˜º . . . . . . . . . . . . . . . . . . . . Schreiben wir das doch mal um. Wenn wir schon die normale Addition bzw. Subtraktion des KÃ¶rpers \\(\\mathbb{R}\\) benutzen, kÃ¶nnen wir auch die gewohnten Symbole verwenden: \\(O:\\mathbb{N} \\rightarrow \\mathbb{R}\\) \\(O(0) := 0, O(0&#94;0) := 0&#94;0, O(o) := O(o - 0&#94;0) + O(o - 0&#94;0 - 0&#94;0)\\) Nun sind wir es gewohnt, dass die Funktionen \\(f\\) heiÃŸen und die Variablen x: \\(f:\\mathbb{N} \\rightarrow \\mathbb{R}\\) \\(f(0) := 0, f(0&#94;0) := 0&#94;0, f(x) := f(x - 0&#94;0) + f(x - 0&#94;0 - 0&#94;0)\\) AuÃŸerdem ist \\(0&#94;0 = 1\\) : \\(f:\\mathbb{N} \\rightarrow \\mathbb{R}\\) \\(f(0) := 0, f(1) := 1, f(x) := f(x - 1) + f(x - 1 - 1)\\) Das ist wiederum: AuÃŸerdem ist \\(0&#94;0 = 1\\) : \\(f:\\mathbb{N} \\rightarrow \\mathbb{R}\\) \\(f(0) := 0\\) , \\(f(1) := 1\\) , \\(f(x) := f(x - 1) + f(x - 2)\\) Diese Folge wird Fibonacci-Folge genannt. Es ist schon sehr erstaunlich, wie beeinflussbar wir von Symbolen und Konventionen sind. Und weil sie so schÃ¶n sind, hier noch ein kurzes Video zu den Fibonacci-Zahlen:","tags":"German posts","title":"Mathe Puzzle #1: Verschleierung"},{"url":"https://martin-thoma.com/how-to-create-your-own-python-module/","text":"A python module is a container for some definitions and statements. You generally call it like this: import math or like that from math import ceil or import math as mymath Python modules can also be written in C or C++, but I'll only explain how to write the module in Python. Modules can be written in C++ for performance reasons. Just take a look at /usr/lib/python3.1/lib-dynload with all the *.so files (shared libraries). Python Paths When you try to import a module, Python looks at these directories in the given order: the PYTHONPATH the current working directory the default search path You get your PYTHONPATH and your default search path like this: import os os . environ [ 'PATH' ] . split ( os . pathsep ) os . environ [ 'PYTHONPATH' ] . split ( os . pathsep ) Example I've just searched for a Python module for primes. It seems as if no such module existed. So I wrote the module primes.py . \"\"\" This module offers some functions related to primes. \"\"\" def miller_rabin ( n ): import random \"\"\" Source: http://en.literateprograms.org/ Miller-Rabin_primality_test_(Python) \"\"\" d = n - 1 s = 0 while d % 2 == 0 : d >>= 1 s += 1 for repeat in xrange ( 20 ): a = 0 while a == 0 : a = random . randrange ( n ) if not miller_rabin_pass ( a , s , d , n ): return False return True def miller_rabin_pass ( a , s , d , n ): a_to_power = pow ( a , d , n ) if a_to_power == 1 : return True for i in xrange ( s - 1 ): if a_to_power == n - 1 : return True a_to_power = ( a_to_power * a_to_power ) % n return a_to_power == n - 1 def getPrimeFactors ( n ): \"\"\"Return the prime factors of n. If the result is small enough to fit in an int, return an int. Else return a long. >>> [getPrimeFactors(n) for n in range(11)] [[], [], [2], [3], [2, 2], [5], [2, 3], [7], [2, 2, 2], [3, 3], [2, 5]] >>> getPrimeFactors(36) [2, 2, 3, 3] \"\"\" import math if not n >= 0 : raise ValueError ( \"n must be >= 0\" ) if math . floor ( n ) != n : raise ValueError ( \"n must be exact integer\" ) elif n <= 2147483647 : n = int ( n ) else : n = long ( n ) fact = [] if n == 0 : return fact while n % 2 == 0 : fact . append ( 2 ) n /= 2 if n == 1 : return fact if miller_rabin ( n ): fact . append ( n ) return fact check = 3 rootn = n ** 0.5 while n != 1 : while n % check == 0 : fact . append ( check ) n /= check check += 2 return fact if __name__ == \"__main__\" : import doctest doctest . testmod () See also Modules Modularisierung (German) What's the difference between a Python module and a Python package? Packages: Creating a Package An Introduction to Distutils","tags":"Code","title":"How to create your own Python module"},{"url":"https://martin-thoma.com/wie-berechnet-man-die-cholesky-zerlegung/","text":"Sei \\(A \\in \\mathbb{R}&#94;{n \\times n}\\) eine symmetrische, positiv definite Matrix. Dann existiert eine Zerlegung \\(A = S \\cdot D \\cdot S&#94;T\\) , wobei \\(S\\) eine unipotente Dreiecksmatrix ist und D eine positiv definite Diagonalmatrix. Berechnung der Cholesky-Zerlegung Hier ein paar Ausschnitte, aus der englischen Wikipedia: Einfach von links oben nach rechts unten die Werte nach folgender Formel berechnen: \\(D_j = A_{jj} - \\sum_{k=1}&#94;{j-1} S_{jk}&#94;2 D_k\\) \\(S_{ij} = \\frac{1}{D_j} \\left( A_{ij} - \\sum_{k=1}&#94;{j-1} S_{ik} S_{jk} D_k \\right), \\qquad\\text{for } i>j\\) Programmierer-Hinweise Implementierung Eine Python-Implementierung sieht so aus: #!/usr/bin/env python # -*- coding: utf-8 -*- def getSD ( A ): \"\"\" @param A: eine quadratische, reele, positiv definite Matrix @return: Die Matrizen S und D, f&uuml;r die gilt: A = S * D * S&#94;T \"\"\" n = len ( A ) S = [[ 0 for j in range ( n )] for i in range ( n )] D = [[ 0 for j in range ( n )] for i in range ( n )] for i in range ( n ): S [ i ][ i ] = 1.0 for j in range ( n ): _summe = sum ( S [ j ][ k ] ** 2 * D [ k ][ k ] for k in range ( j )) D [ j ][ j ] = A [ j ][ j ] - _summe _summe = sum ( S [ i ][ k ] * S [ j ][ k ] * D [ k ][ k ] for k in range ( j )) S [ i ][ j ] = 1.0 / D [ j ][ j ] * ( A [ i ][ j ] - _summe ) return S , D Bibliotheken Ich habe mich mal nach Bibliotheken umgesehen, die die Cholesky-Zerlegung direkt beherrschen. NumPy kann es natÃ¼rlich: from numpy import linalg print ( linalg . cholesky ([[ 5 , 1 ],[ 1 , 1 ]])) Gibt aus: array ([[ 2 .23606798, 0 . ] , [ 0 .4472136 , 0 .89442719 ]]) Das ist NICHT die Zerlegung \\(A = S \\cdot D \\cdot S&#94;T\\) , sondern \\(A = G \\cdot G&#94;T\\) . Interessanterweise hat NumPy das nicht direkt selbst implementiert ( NumPy-Quelle ). Man greift auf LAPACK zurÃ¼ck, was in FORTRAN 90 programmiert wurde ( LAPACK-Quelle )! Wolfram|Alpha Auch Wolfram|Alpha kennt \"cholesky decomposition\": Beispiel . Allerdings sieht es schon bei \\(3 \\times 3\\) -Matrizen schlecht aus. Numerik In Numerik haben wir bei Herrn Dr. WeiÃŸ folgendes als Cholesky-Zerlegung kennen gelernt: Sei \\(A \\in \\mathbb{R}&#94;{n \\times n}\\) eine symmetrische, positiv definite Matrix. Dann existiert eine Zerlegung \\(A = \\bar L \\cdot \\bar{L}&#94;T\\) , wobei \\(\\bar L\\) eine untere Dreiecksmatrix ist. Wenn man wie gewohnt eine LR-Zerlegung der Matrix \\(A\\) durchfÃ¼hrt, erhÃ¤lt man zwei Matrizen \\(L, R \\in \\mathbb{R}&#94;{n \\times n}\\) , wobei gilt: \\(R = D \\cdot L&#94;T\\) , wobei \\(D\\) eine positiv definite Diagonalmatrix ist. Offensichtlich gilt: \\(\\bar L = L \\cdot D&#94;{\\frac{1}{2}}\\) . Die Cholesky-Zerlegung kann man folgendermaÃŸen berechnen: Berechnung der Cholesky-Zerlegung in Pseudocode In Python sieht das dann so aus: def getL ( A ): n = len ( A ) L = [[ 0 for i in range ( n )] for j in range ( n )] print ( L ) print ( \"\" ) for k in range ( n ): L [ k ][ k ] = ( A [ k ][ k ] - sum ([ L [ k ][ i ] ** 2 for i in range ( k )])) ** 0.5 for i in range ( k + 1 , n ): L [ i ][ k ] = ( A [ i ][ k ] - sum ([ L [ i ][ j ] * L [ k ][ j ] for j in range ( k )])) \\ / L [ k ][ k ] return L Siehe auch Cholesky decomposition (Englisch) Cholesky-Zerlegung","tags":"German posts","title":"Wie berechnet man die Cholesky-Zerlegung?"},{"url":"https://martin-thoma.com/george-carlin/","text":"George Carlin is a great American stand-up comedian. Here are some of his clips: Airplane Announcements War Our Similarities","tags":"My bits and bytes","title":"George Carlin"},{"url":"https://martin-thoma.com/latex-versioning-a-great-experience/","text":"Some people keep asking me questions like \"Why do you use LaTeX?\" - \"Wouldn't it be faster to do it with Word?\" Here is the answer: Versioning : I do quite often create repositories for documentation (e.g. on GITHub). Versioning LaTeX-files is much better than versioning Word-files, as LaTeX is line-based. Versioning is my way to solve the following problems: Dead end : Once in a while I stuck while writing. I tried to improve some part of the documentation, but it didn't work. So I want to jump back. It is much more convenient to jump back in a versioning system than to press CTRL + Z often or to create copies of the old version. Versioning : This might sound strange, but versioning was a problem for me as I wrote my \"Facharbeit\" (a thesis you have to write in Germany at the end of secondary school). I had so many backups that I didn't know what was the original. If you use a versioning system, you can have everything in one place. Simpler collaboration : Some weeks ago I had to prepare a presentation about graph algorithms with three fellow students. We just met once to decide how to split the project. After that, everybody could work on his part while everybody could see the progress. We had no need of merging the documents. (See GITHub-Repository ) Simpler proofreading : The proofreader can make a fork of the repository with the documentation and make changes on his copy. After that, the writer can make a diff and see if he wants to take those changes. You can't forget small changes of the proofreader (like a \",\" you forgot / you made too much) with diffs. Backups : I've been ultra-paranoid as I wrote my thesis for secondary school. I regularly sent a copy to my father per Email and I had at least two copies on different data storage mediums. I wouldn't have needed this if I used versioning with GITHub. (I trust in the reliability of the service GITHub offers) Accessibility : To open LaTeX, you only need a text editor. If you want to complie it, you have to get one of many free LaTeX distributions like TeX-Live. After compiling it you get a PDF. PDFs look always the same, so you don't have the problem of shifted margins. Speed : I can write mathematical formulae much faster with LaTeX than with Word. Professional look : You can quite often see if a presentation / documentation was written with LaTeX or with Word. I think the LaTeX-Documentations do look much more professional. Source Code Inclusion : You can include and highlight source code directly within LaTeX. No need for copy and paste (see How to print Source Code with LaTeX , How to print MIPS assembly code in LaTeX ) Great Visualizations : You can create great visualizations directly within LaTeX (see , How to draw a finite-state machine , Plotting function graphs with LaTeX and Complex LaTeX visualizations (Tikz) ) I guess some might not know what a diff is or how it can look like. diff is a program that compares text files. This is an example with two text files. Each of them has 100 paragraphs: moose@pc07:~/Desktop$ diff file1.txt file2.txt 127 ,128d126 < And here is another one. < 189c187 < Ut wisi enim ad minim veniam, quis nostrud exerci tation ullamcorper suscipit lobortis nisl ut aliquip ex ea commodo consequat. Duis autem vel eum iriure dolor in hendrerit in vulputate velit esse molestie consequat, vel illum dolore eu feugiat nulla facilisis at vero eros et accumsan et iusto odio dignissim qui blandit praesent luptatum zzril delenit augue dui s dolore te feugait nulla facilisi. --- > Ut wisi enim ad minim veniam, quis nostrud exerci tation ullamcorper suscipit lobortis nisl ut aliquip ex ea commodo consequat. Duis autem vel eum iriure dolor in hendrerit in vulputate velit esse molestie consequat, vel illum dolore eu feugiat nulla facilisis at vero eros et accumsan et iusto odio dignissim qui blandit praesent luptatum zzril delenit augue duis dolore te feugait nulla facilisi. 191c189 < Nam liber tempor cum soluta nobis eleifend option congue nihil imperdiet doming id quod mazim placerat facer possim assum. Lorem ipsum dolor sit amet, consectetuer adipiscing elit, sed diam nosnummy nibh euismod tincidunt ut laoreet dolore magna aliquam erat volutpat. Ut wisi enim ad minim veniam, quis nostrud exerci tation ullamcorper suscipit lobortis nisl ut aliquip ex ea commodo consequat. --- > Nam liber tempor cum soluta nobis eleifend option congue nihil imperdiet doming id quod mazim placerat facer possim assum. Lorem ipsum dolor sit amet, consectetuer adipiscing elit, sed diam nonummy nibh euismod tincidunt ut laoreet dolore magna aliquam erat volutpat. Ut wisi enim ad minim veniam, quis nostrud exerci tation ullamcorper suscipit lobortis nisl ut aliquip ex ea commodo consequat. If you use meld it looks like this: My LaTeX configuration First, you have to install the latest LaTeX-Version: How to install the latest LaTeX Version . I like editing the source code directly very much. To do so, I use gEdit. When I press Ctrl + M , my LaTeX document gets saved, compiled and the temporary files are thrown away. If you want this, you should follow these instructions. Create a \"Makefile\" (a file called this way) with this content in the folder where your LaTeX file is: make : pdflatex matrix.tex -output-format = pdf make clean clean : rm -rf $( TARGET ) *.class *.html *.log *.aux Enable the Plugin \"External Tools\" Go to Preferences â†’ Plugins â†’ External Tools â†’ Configure Plugin Click on the New Page icon Insert \"make\" into the Edit-Window Create the Shortcut Key. I've added Ctrl + M . See also Why use version control systems for writing a paper instead of Dropbox","tags":"Cyberculture","title":"LaTeX + Versioning = A great Experience"},{"url":"https://martin-thoma.com/complex-latex-visualizations-tikz/","text":"You can create some very complex visualizations with LaTeX. Take a look at these: Circumscribed polygons and circles Used matlab Source: texample.net Mosaic from Pompeii Source: texample.net Plane Sections of the Cylinder - Dandelin Spheres Source: texample.net Example: Dipolar magnetic field Source: texample.net Gamma interaction Source: texample.net A complete graph Source: texample.net Mandala Source: texample.net Pascal's triangle and Sierpinski triangle Source: texample.net Seismic focal mechanism in 3D view Source: texample.net Membrane-like surface Source: texample.net Computer science mindmap Source: texample.net Spherical and cartesian grids Source: texample.net Do you know more? Please leave a comment! See also Penrose tiling in TikZ Lindenmayer systems How to draw nanotubes with TeX","tags":"Code","title":"Complex LaTeX visualizations (Tikz)"},{"url":"https://martin-thoma.com/perfect-number-check-and-rot-13-encryption-in-mips-assembly-code/","text":"Perfect number check The perfect number check in MIPS is quite easy to realize. Here is some pythonic Pseudocode n = input () # read a positive integer n from the user sumOfDivisors = 0 for i in range ( 1 , n ): # go from 1 to n-1 if n % i == 0 : # if i is a divisor sumOfDivisors += i if sumOfDivisors == n : print \"1\" else : print \"0\" And here is the MIPS-Code: ##################################################################### # Perfect number check # # @param int the number you would like to check # # @result int 0 if the number is not perfect, otherwise 1 # ##################################################################### .data prompt: .asciiz \"Positive integer you would like to check : \" output: .asciiz \"Is a perfect number (1: Yes, 0: No): \" .text .globl main main: li $v0 , 4 # | la $a0 , prompt # | syscall # |=> Print string \"prompt\" li $v0 , 5 # | syscall # |=> Ask for integer A # Initialise variables move $s0 , $v0 # => Store A in $s0 li $s1 , 0 # => The sum of all proper divisors of A li $s2 , 1 # => start here with checks for devisors s: bgeu $s2, $s0, eval # while $s2 < $s0 rem $t0, $s0, $s2 # $t0 = $s0 % $s2 bne $t0, $0, w addu $s1, $s1, $s2 # $s1 += $s2 w: addi $s2, $s2, 1 # $s2++ j s; # /endwhile eval: seq $s0, $s0, $s1 # Compare the sum of divisors with A li $v0 , 4 # | la $a0 , output # | syscall # |=> Print string \"output\" la $v0 , 1 # | move $a0 , $s0 # | syscall # |=> Print $s0 jr $ra ROT-13 encryption The basic idea for encrypting a string with ROT-13 is to loop over all characters and use the ASCII-Table to shift them. Here is the ROT-13 MIPS-Code: ##################################################################### # @param string a &#92;&#48; terminated string # # @return string the ROT-13 encrypted string # ##################################################################### .data prompt: .asciiz \"Please enter string: \" output: .asciiz \"ROT-13: \" plain: .space 64 .text .globl main main: li $v0, 4 # | la $a0, prompt # | syscall # |=> Print string \"prompt\" li $v0, 8 # | la $a0, plain # | => Ask for string plain li $a1, 64 # | syscall # | => read a string with max. 64 chars li $t2, 10 # Stop by \\n # Loop over all characters la $t1, ($a0) #=>$t1:the current adress that gets modified s: lb $t0, ($t1) # => $t0: the current value (char) beq $t0, $t2, out # while $t1 != '\\n' li $t3, 64 bge $t3, $t0, w # if $t0 <= 64: jump to w li $t3, 123 bge $t0, $t3, w # if $t0 >= 123: jump to w li $t3, 90 bge $t3, $t0, big # if $t0 <= 90: jump to big li $t3, 96 bge $t3, $t0, w # if $t0 <= 96: jump to w j small w: addi $t1, $t1, 1 # $t1++ j s; # /endwhile small: addi $t0, -84 # -97 + 13 rem $t0, $t0, 26 # $t0 %= 26 addi $t0, 97 sb $t0, ($t1) j w big: addi $t0, -52 # -65 + 13 rem $t0, $t0, 26 # $t0 %= 26 addi $t0, 65 sb $t0, ($t1) j w out: li $v0, 4 # | la $a0, output # | syscall # |=> Print string \"output\" la $v0, 4 # | la $a0, plain # | syscall # |=> Print plain jr $ra A syntax-highlighted version of both code pieces is here: MIPS Assembly Code for a perfect number check and ROT-13 encryption . See also SPIM MIPS Simulator How to print MIPS assembly code in LaTeX Add MIPS syntax highlighting to gEdit Archive with MIPS assembly Code and LaTeX file","tags":"Code","title":"Perfect number check and ROT-13 encryption in MIPS-assembly code"},{"url":"https://martin-thoma.com/matrix-multiplication-python-java-cpp/","text":"This is Part I of my matrix multiplication series. Part I was about simple matrix multiplication algorithms and Part II was about the Strassen algorithm. Part III is about parallel matrix multiplication. This post is about simple implementations of matrix multiplications. The goal of this post is to find out how easy it is to implement a matrix multiplication in Python, Java and C++. Additionally, I want to get to know how good these solutions are. The second post will be an implementation of the Strassen algorithm for matrix multiplication. Strassen algorithm does matrix multiplication in \\(\\cal O(n&#94;{log_2(7)+o(1)}) \\approx \\cal O(n&#94;{2.807})\\) instead of \\(\\cal O(n&#94;3)\\) . I am quite sure this will outperform almost every other change. See Part II: The Strassen algorithm in Python, Java and C++ . The third post will be about parallel programming. I have two cores and I want to see if it will be significantly faster if I use both of them. The implementations I will post all scripts for this test and I've added a GIT repository , so feel free to test it on your machine. I am also happy if you post some of your solutions with running times â˜º I am quite sure that my Java and C++ code can be written much better. If you know how, please leave a comment. If you know other languages, you could create a script for these. I focus on Python, Java and C++ as they are very often used. I have implemented these three types of algorithms for this post: ijk-algorithm : This is a simple, straight forward implementation of a matrix multiplication. I've used the definition of matrix multiplication. I didn't use multiple threads. ikj-algorithm : just like the ijk-algorithm, but I've switched two of the three the for-loops. Library-functions : I always prefer libraries over self-implemented solutions. I think they are faster than anything I could come up with in a reasonable amount of time. If you post a solution, please consider these restrictions: Input : The input file should get passed with the parameter -i , e.g.: python -i 2000.in or java Shell -i 2000.in The standard value for the command line parameter -i should be \"2000.in\" (a \\(2000 \\times 2000\\) matrix) The user should not have to give the size of the matrix! The two square-matrices that should get multiplied are ... ... read from a text-file. ... represented like this: Every line of one matrix is one line in the text-file. Newlines are only \"\\n\". Every number is separated by \"\\t\". The both matrices are separated by one newline. Output : The result has to get printed to standard output. The result has to be formatted like the input (tabs for separation of number, \\n for marks a new line) The Tests I will check the speed of a multiplication of two big matrices following for Python, Java and C++ for all algorithms like this: time python scriptABC.py -i ../2000.in > result.txt diff result.txt bigMatrix.out The bigMatrix.out was produced by the Python ijk-implementation. I make the diff to test if the result is correct. The Setting I created two \"random\" matrices \\(A, B \\in \\mathbb{N}&#94;{2000 \\times 2000}\\) with this script. The file that was created needs about 29.7 MB and is also in the GIT-Hub repository. But you can also create the matrices with this script: #!/usr/bin/python # -*- coding: utf-8 -*- import random random . seed ( 1234 ) def createRandomMatrix ( n ): maxVal = 1000 # I don't want to get Java / C++ into trouble matrix = [] for i in xrange ( n ): matrix . append ([ random . randint ( 0 , maxVal ) for el in xrange ( n )]) return matrix def saveMatrix ( matrixA , matrixB , filename ): f = open ( filename , 'w' ) for i , matrix in enumerate ([ matrixA , matrixB ]): if i != 0 : f . write ( \" \\n \" ) for line in matrix : f . write ( \" \\t \" . join ( map ( str , line )) + \" \\n \" ) n = 3 matrixA = createRandomMatrix ( n ) matrixB = createRandomMatrix ( n ) saveMatrix ( matrixA , matrixB , \"2000.in\" ) All scripts are tested on my computer: Acer TravelMate 5735Z CPU 2x Pentium(R) Dual-Core CPU T4500 @2.30GHz RAM 4 GB Video Card Intel GMA 4500MHD System Ubuntu 10.10.04 LTS Python I've used Python 2.6.5. ijk-algorithm #!/usr/bin/python # -*- coding: utf-8 -*- from optparse import OptionParser parser = OptionParser () parser . add_option ( \"-i\" , dest = \"filename\" , default = \"2000.in\" , help = \"input file with two matrices\" , metavar = \"FILE\" ) ( options , args ) = parser . parse_args () def read ( filename ): lines = open ( filename , 'r' ) . read () . splitlines () A = [] B = [] matrix = A for line in lines : if line != \"\" : matrix . append ( map ( int , line . split ( \" \\t \" ))) else : matrix = B return A , B def printMatrix ( matrix ): for line in matrix : print \" \\t \" . join ( map ( str , line )) def standardMatrixProduct ( A , B ): n = len ( A ) C = [[ 0 for i in xrange ( n )] for j in xrange ( n )] for i in xrange ( n ): for j in xrange ( n ): for k in xrange ( n ): C [ i ][ j ] += A [ i ][ k ] * B [ k ][ j ] return C A , B = read ( options . filename ) C = standardMatrixProduct ( A , B ) printMatrix ( C ) real 56m49.266s user 56m30.524s sys 0m2.980s ikj-algorithm def ikjMatrixProduct ( A , B ): n = len ( A ) C = [[ 0 for i in xrange ( n )] for j in xrange ( n )] for i in xrange ( n ): for k in xrange ( n ): for j in xrange ( n ): C [ i ][ j ] += A [ i ][ k ] * B [ k ][ j ] return C real 44m36.507s user 44m13.458s sys 0m2.000s Psyco ikj-algorithm Psyco is a just in time compiler, which makes my scripts MUCH faster. It is very simple to use. Add these two lines at the top of the ikj-script: import psyco psyco . full () real 6m14.820s user 6m12.959s sys 0m0.620s Amazing, isn't it? Libraries NumPy NumPy-Version: 1.3.0 (Current version is 1.6.2, see Wiki ) #!/usr/bin/python # -*- coding: utf-8 -*- import numpy from optparse import OptionParser parser = OptionParser () parser . add_option ( \"-i\" , dest = \"filename\" , default = \"2000.in\" , help = \"input file with two matrices\" , metavar = \"FILE\" ) ( options , args ) = parser . parse_args () def read ( filename ): lines = open ( filename , 'r' ) . read () . splitlines () A = [] B = [] matrix = A for line in lines : if line != \"\" : matrix . append ( map ( int , line . split ( \" \\t \" ))) else : matrix = B return A , B def printMatrix ( matrix ): matrix = numpy . array ( matrix ) for line in matrix : print \" \\t \" . join ( map ( str , line )) A , B = read ( options . filename ) A = numpy . matrix ( A ) B = numpy . matrix ( B ) C = A * B # easy and intuitive, isn't it? printMatrix ( C ) real 1m38.425s user 1m36.066s sys 0m0.520s SciPy You might need to install python-scitools . #!/usr/bin/python # -*- coding: utf-8 -*- import numpy import scipy from optparse import OptionParser parser = OptionParser () parser . add_option ( \"-i\" , dest = \"filename\" , default = \"2000.in\" , help = \"input file with two matrices\" , metavar = \"FILE\" ) ( options , args ) = parser . parse_args () def read ( filename ): lines = open ( filename , 'r' ) . read () . splitlines () A = [] B = [] matrix = A for line in lines : if line != \"\" : matrix . append ( map ( int , line . split ( \" \\t \" ))) else : matrix = B return A , B def printMatrix ( matrix ): matrix = numpy . array ( matrix ) for line in matrix : print \" \\t \" . join ( map ( str , line )) A , B = read ( options . filename ) A = scipy . matrix ( A ) B = scipy . matrix ( B ) C = A * B # easy and intuitive, isn't it? printMatrix ( C ) real 1m35.795s user 1m33.438s sys 0m0.488s Conclusion for Python Python execution times for matrix multiplication Using NumPy is by far the easiest and fastest option. I've needed about five minutes for each of the non-library scripts and about 10 minutes for the NumPy/SciPy scripts. By the way, it is useless to combine Psyco and NumPy. It gets a little bit faster (1 minute and 28 seconds), but this could also be a random effect. If you execute it many times, you will see that the execution time is never the same. Java I am using this Java version: $ java -version java version \"1.6.0_20\" OpenJDK Runtime Environment ( IcedTea6 1 .9.13 ) ( 6b20-1.9.13-0ubuntu1~10.04.1 ) OpenJDK Server VM ( build 19 .0-b09, mixed mode ) ijk-algorithm import java.io.BufferedReader ; import java.io.FileReader ; import java.io.IOException ; import java.util.LinkedList ; import java.util.List ; import java.util.ArrayList ; public class Shell { static List < ArrayList < ArrayList < Integer >>> read ( String filename ) { ArrayList < ArrayList < Integer >> A = new ArrayList < ArrayList < Integer >>(); ArrayList < ArrayList < Integer >> B = new ArrayList < ArrayList < Integer >>(); String thisLine ; try { BufferedReader br = new BufferedReader ( new FileReader ( filename )); // Begin reading A while (( thisLine = br . readLine ()) != null ) { if ( thisLine . trim (). equals ( \"\" )) { break ; } else { ArrayList < Integer > line = new ArrayList < Integer >(); String [] lineArray = thisLine . split ( \"\\t\" ); for ( String number : lineArray ) { line . add ( Integer . parseInt ( number )); } A . add ( line ); } } // Begin reading B while (( thisLine = br . readLine ()) != null ) { ArrayList < Integer > line = new ArrayList < Integer >(); String [] lineArray = thisLine . split ( \"\\t\" ); for ( String number : lineArray ) { line . add ( Integer . parseInt ( number )); } B . add ( line ); } br . close (); } catch ( IOException e ) { System . err . println ( \"Error: \" + e ); } List < ArrayList < ArrayList < Integer >>> res = new LinkedList < ArrayList < ArrayList < Integer >>>(); res . add ( A ); res . add ( B ); return res ; } static int [][] ijkAlgorithm ( ArrayList < ArrayList < Integer >> A , ArrayList < ArrayList < Integer >> B ) { int n = A . size (); // initialise C int [][] C = new int [ n ][ n ]; for ( int i = 0 ; i < n ; i ++) { for ( int j = 0 ; j < n ; j ++) { for ( int k = 0 ; k < n ; k ++) { C [ i ][ j ] += A . get ( i ). get ( k ) * B . get ( k ). get ( j ); } } } return C ; } static void printMatrix ( int [][] matrix ) { for ( int [] line : matrix ) { int i = 0 ; StringBuilder sb = new StringBuilder ( matrix . length ); for ( int number : line ) { if ( i != 0 ) { sb . append ( \"\\t\" ); } else { i ++; } sb . append ( number ); } System . out . println ( sb . toString ()); } } public static void main ( String [] args ) { String filename ; if ( args . length < 2 ) { filename = \"2000.in\" ; } else { filename = args [ 1 ]; } List < ArrayList < ArrayList < Integer >>> matrices = read ( filename ); ArrayList < ArrayList < Integer >> A = matrices . get ( 0 ); ArrayList < ArrayList < Integer >> B = matrices . get ( 1 ); int [][] C = ijkAlgorithm ( A , B ); printMatrix ( C ); } } real 27m21.295s user 26m53.877s sys 0m4.368s Note: Java is not C++! If you use Vector instead of ArrayList , you get these results: real 82m26.754s user 80m42.003s sys 0m24.598s One reason might be that Vector is synchronized. ikj-algoirthm I've only switched line 60 and line 61. real 2m9.478s user 1m26.369s sys 0m39.162s Library: JAMA I've searched in Google for \"java matrix multiplication\". The first 10 results were only implementations of the ijk-algorithm. Although the ijk-algorithm is very easy, most of the results were only questions where people tried to implement it. After some search (20 minutes minimum) I've found JAMA . They also have a documentation . You might need to install this for the following code: sudo apt-get install libjama-* import java.io.BufferedReader ; import java.io.FileReader ; import java.io.IOException ; import java.util.ArrayList ; import java.util.LinkedList ; import java.util.List ; import Jama.Matrix ; public class Shell { static List < ArrayList < ArrayList < Double >>> read ( String filename ) { ArrayList < ArrayList < Double >> A = new ArrayList < ArrayList < Double >>(); ArrayList < ArrayList < Double >> B = new ArrayList < ArrayList < Double >>(); String thisLine ; try { BufferedReader br = new BufferedReader ( new FileReader ( filename )); // Begin reading A while (( thisLine = br . readLine ()) != null ) { if ( thisLine . trim (). equals ( \"\" )) { break ; } else { ArrayList < Double > line = new ArrayList < Double >(); String [] lineArray = thisLine . split ( \"\\t\" ); for ( String number : lineArray ) { line . add (( double ) Integer . parseInt ( number )); } A . add ( line ); } } // Begin reading B while (( thisLine = br . readLine ()) != null ) { ArrayList < Double > line = new ArrayList < Double >(); String [] lineArray = thisLine . split ( \"\\t\" ); for ( String number : lineArray ) { line . add (( double ) Integer . parseInt ( number )); } B . add ( line ); } } catch ( IOException e ) { System . err . println ( \"Error: \" + e ); } List < ArrayList < ArrayList < Double >>> res = new LinkedList < ArrayList < ArrayList < Double >>>(); res . add ( A ); res . add ( B ); return res ; } static int [][] ijkAlgorithm ( ArrayList < ArrayList < Integer >> A , ArrayList < ArrayList < Integer >> B ) { int n = A . size (); // initialise C int [][] C = new int [ n ][ n ]; for ( int i = 0 ; i < n ; i ++) { for ( int j = 0 ; j < n ; j ++) { for ( int k = 0 ; k < n ; k ++) { C [ i ][ j ] += A . get ( i ). get ( k ) * B . get ( k ). get ( j ); } } } return C ; } static void printMatrix ( Matrix matrix , int n ) { for ( int i = 0 ; i < n ; i ++) { for ( int j = 0 ; j < n ; j ++) { if ( j != 0 ) { System . out . print ( \"\\t\" ); } System . out . printf ( \"%.0f\" , matrix . get ( i , j )); } System . out . println ( \"\" ); } } public static void main ( String [] args ) { String filename ; if ( args . length < 2 ) { filename = \"2000.in\" ; } else { filename = args [ 1 ]; } List < ArrayList < ArrayList < Double >>> matrices = read ( filename ); ArrayList < ArrayList < Double >> A = matrices . get ( 0 ); ArrayList < ArrayList < Double >> B = matrices . get ( 1 ); int n = A . size (); double [][] Aarray = new double [ n ][ n ]; double [][] Barray = new double [ n ][ n ]; for ( int i = 0 ; i < n ; i ++) { for ( int j = 0 ; j < n ; j ++) { Aarray [ i ][ j ] = A . get ( i ). get ( j ); Barray [ i ][ j ] = B . get ( i ). get ( j ); } } Matrix AM = new Matrix ( Aarray ); Matrix BM = new Matrix ( Aarray ); Matrix CM = AM . times ( BM ); printMatrix ( CM , n ); } } real 1m36.506s user 0m51.367s sys 0m45.043s It took me about two hours to get it work. I had to add the JAMA-JAR to eclipse, export my project as a JAR and run it with time java -jar jama-shell.jar -i ../2000.in > jama-result.out I still have no idea how to compile it with bash only. Conclusion for Java Java execution times for matrix multiplication You should definitely know if some Java-datastructures are synchronised or not. And you should know how the computer / caches work. C++ I have gcc 4.4.3 and compiled everything with these options: g++ -std = c++98 -Wall -O3 -g myScript.cpp -o $( PROBLEM ) .out -pedantic ijk-algorithm #include <sstream> #include <string> #include <fstream> #include <iostream> #include <vector> using namespace std ; struct Result { vector < vector < int > > A ; vector < vector < int > > B ; }; Result read ( string filename ) { vector < vector < int > > A , B ; Result ab ; string line ; ifstream infile ; infile . open ( filename . c_str ()); int i = 0 ; while ( getline ( infile , line ) & amp ; & amp ; ! line . empty ()) { istringstream iss ( line ); A . resize ( A . size () + 1 ); int a , j = 0 ; while ( iss >> a ) { A [ i ]. push_back ( a ); j ++ ; } i ++ ; } i = 0 ; while ( getline ( infile , line )) { istringstream iss ( line ); B . resize ( B . size () + 1 ); int a ; int j = 0 ; while ( iss >> a ) { B [ i ]. push_back ( a ); j ++ ; } i ++ ; } infile . close (); ab . A = A ; ab . B = B ; return ab ; } vector < vector < int > > ijkalgorithm ( vector < vector < int > > A , vector < vector < int > > B ) { int n = A . size (); // initialise C with 0s vector < int > tmp ( n , 0 ); vector < vector < int > > C ( n , tmp ); for ( int i = 0 ; i < n ; i ++ ) { for ( int j = 0 ; j < n ; j ++ ) { for ( int k = 0 ; k < n ; k ++ ) { C [ i ][ j ] += A [ i ][ k ] * B [ k ][ j ]; } } } return C ; } void printMatrix ( vector < vector < int > > matrix ) { vector < vector < int > >:: iterator it ; vector < int >:: iterator inner ; for ( it = matrix . begin (); it != matrix . end (); it ++ ) { for ( inner = it -> begin (); inner != it -> end (); inner ++ ) { cout << * inner ; if ( inner + 1 != it -> end ()) { cout << \" \\t \" ; } } cout << endl ; } } int main ( int argc , char * argv []) { string filename ; if ( argc < 3 ) { filename = \"2000.in\" ; } else { filename = argv [ 2 ]; } Result result = read ( filename ); vector < vector < int > > C = ijkalgorithm ( result . A , result . B ); printMatrix ( C ); return 0 ; } real 1m40.439s user 1m38.642s sys 0m0.280s ikj-algorithm Again, I've only switched line 61 and 62. real 0m15.172s user 0m14.877s sys 0m0.248s Library: Boost If you want to compile these scripts, you might have to install the boost libraries first. On Ubuntu you can enter: sudo apt-get install libboost-math* #include <sstream> #include <string> #include <fstream> #include <iostream> #include <vector> #include <boost/numeric/ublas/matrix.hpp> #include <boost/numeric/ublas/io.hpp> using namespace std ; struct Result { boost :: numeric :: ublas :: matrix < int > A ; boost :: numeric :: ublas :: matrix < int > B ; }; int getMatrixSize ( string filename ) { string line ; ifstream infile ; infile . open ( filename . c_str ()); getline ( infile , line ); return count ( line . begin (), line . end (), '\\t' ) + 1 ; } void printMatrix ( boost :: numeric :: ublas :: matrix < int > matrix ) { for ( unsigned int i = 0 ; i < matrix . size1 (); i ++ ) { for ( unsigned int j = 0 ; j < matrix . size2 (); j ++ ) { cout << matrix ( i , j ); if ( j + 1 != matrix . size2 ()) { cout << \" \\t \" ; } } cout << endl ; } } Result read ( string filename ) { Result ab ; string line ; ifstream infile ; infile . open ( filename . c_str ()); // get dimension getline ( infile , line ); int n = getMatrixSize ( filename ); boost :: numeric :: ublas :: matrix < int > A ( n , n ), B ( n , n ); // process first line istringstream iss ( line ); int a , i = 0 , j = 0 ; while ( iss >> a ) { A ( i , j ) = a ; j ++ ; } i ++ ; while ( getline ( infile , line ) & amp ; & amp ; ! line . empty ()) { istringstream iss ( line ); j = 0 ; while ( iss >> a ) { A ( i , j ) = a ; j ++ ; } i ++ ; } i = 0 ; while ( getline ( infile , line )) { istringstream iss ( line ); j = 0 ; while ( iss >> a ) { B ( i , j ) = a ; j ++ ; } i ++ ; } infile . close (); ab . A = A ; ab . B = B ; return ab ; } int main ( int argc , char * argv []) { string filename ; if ( argc < 3 ) { filename = \"2000.in\" ; } else { filename = argv [ 2 ]; } Result result = read ( filename ); boost :: numeric :: ublas :: matrix < int > C ; C = boost :: numeric :: ublas :: prod ( result . A , result . B ); printMatrix ( C ); return 0 ; } real 4m15.388s user 4m10.272s sys 0m0.588s Library: Blitz This is a great example of useless library. I've installed the library: sudo apt-get install libblitz* Then I wanted to use it. Well, I have no clue how I could exactly use it! See my StackOverflow Question: Is a documentation of Blitz++ matrices available? Conclusion for C++ C++ execution times for matrix multiplication Again, it brings a performance boost if you know how your CPU works. I was very astonished, that the library Boost is slower (actually MUCH slower) than my simplest approach was. Conclusion If I want to create a working piece of code in a minimum amount of time, I will always take Python. It has been very easy to solve this task with the given restrictions. But C++ is amazing when speed is important. It was astonishingly difficult to find working code examples for this task for Java and C++. I was searching for libraries and found some, but the search results were not satisfying. See also Boost Matrix multiplication Rosetta Code: Matrix multiplication (Implementations in 63 programming languages!) Why is matrix multiplication faster with numpy than with ctypes in Python? Why is boosts matrix multiplication slower than mine? Continue reading with Part II: The Strassen algorithm in Python, Java and C++","tags":"Code","title":"Part I: Performance of Matrix multiplication in Python, Java and C++"},{"url":"https://martin-thoma.com/python-puzzle-1-list-multiplication/","text":"Basic concepts Image you had to multiply two small matrices in Python. You could just use the definition of a matrix product: \\(A, B \\in \\mathbb{R}&#94;{n \\times n}\\) : \\(C = A \\cdot B, C \\in \\mathbb{R}&#94;{n \\times n}\\) where the components of C are definied by \\(c_{i,j} = \\sum_{k=1}&#94;n a_{i,k} \\cdot b_{k, j}\\) Note that this means: \\( \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix} \\cdot \\begin{pmatrix} 5 & 6 \\\\ 7 & 8 \\end{pmatrix} = \\begin{pmatrix} 19 & 22 \\\\ 43 & 50 \\end{pmatrix} \\) You might also have heard of Pythons overloaded multiplication: print ([ 0 ] * 4 ) print ([[ 0 ] * 4 ] * 4 ) print ( \"abc\" * 4 ) Output: [0, 0, 0, 0] [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]] abcabcabcabc Question What do you think does the following piece of Python-Code print? #!/usr/bin/python # -*- coding: utf-8 -*- def standardMatrixProduct ( A , B ): n = len ( A ) C = [[ 0 ] * n ] * n for i in xrange ( n ): for j in xrange ( n ): for k in xrange ( n ): C [ i ][ j ] += A [ i ][ k ] * B [ k ][ j ] return C A = [[ 1 , 2 ], [ 3 , 4 ]] B = [[ 5 , 6 ], [ 7 , 8 ]] print standardMatrixProduct ( A , B ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Answer [[32, 32], [32, 32]] Python creates only one list and makes pointers to it! So this is one that works: def standardMatrixProduct ( A , B ): n = len ( A ) C = [[ 0 for i in xrange ( n )] for j in xrange ( n )] for i in xrange ( n ): for j in xrange ( n ): for k in xrange ( n ): print C C [ i ][ j ] += A [ i ][ k ] * B [ k ][ j ] return C","tags":"Code","title":"Python Puzzle #1: List multiplication"},{"url":"https://martin-thoma.com/duolingo-learn-a-language-online/","text":"Duolingo is a great online protal for learning new languages online. They currently support German, Spanish, French, Portuguese, Italian and Chinese. Here is a short explanation of Duolingo: The inventor of duolingo, Luis von Ahn, did also a great TED-Talk in which he explains the concepts: Now some screenshots to give you a feeling what Duolingo offers: Achievements in Duolingo Translation in Duolingo Duolingo analyses your errors. Speech to text task in Duolingo Duolingo: Photo to language Multiple choice in Duolingo A lection in Duolingo Level mastered â˜º I have 3 invitations left. If you like to test Duolingo, simply post a comment with your email-address. The first three will get the invitations.","tags":"The Web","title":"Duolingo - Learn a Language Online"},{"url":"https://martin-thoma.com/how-print-mips-assembly-code-latex/","text":"If you like to print highlighted MIPS assembly code in LaTeX, you can use the listings package. Sadly, no MIPS language file exits by default in LaTeX, but awg has created one and provides it on his blog. Just download mips.sty (thanks to Adam Gordon !) and place it in your project folder. Then you can create a project like this: Highlight MIPS Assembly code with LaTeX listings. \\documentclass [a4paper,12pt] { article } \\usepackage { amssymb } % needed for math \\usepackage { amsmath } % needed for math \\usepackage [utf8] { inputenc } % this is needed for german umlauts \\usepackage [ngerman] { babel } % this is needed for german umlauts \\usepackage [T1] { fontenc } % this is needed for correct output of umlauts in pdf \\usepackage [margin=2.5cm] { geometry } %layout \\usepackage { listings } % needed for the inclusion of source code \\usepackage { mips } % the following is needed for syntax highlighting \\usepackage { color } \\definecolor { dkgreen }{ rgb }{ 0,0.6,0 } \\definecolor { gray }{ rgb }{ 0.5,0.5,0.5 } \\definecolor { mauve }{ rgb }{ 0.58,0,0.82 } \\lstset { % language=[mips]Assembler, % the language of the code basicstyle= \\footnotesize , % the size of the fonts that are used for the code numbers=left, % where to put the line-numbers numberstyle= \\tiny\\color { gray } , % the style that is used for the line-numbers stepnumber=1, % the step between two line-numbers. If it's 1, each line % will be numbered numbersep=5pt, % how far the line-numbers are from the code backgroundcolor= \\color { white } , % choose the background color. You must add \\usepackage{color} showspaces=false, % show spaces adding particular underscores showstringspaces=false, % underline spaces within strings showtabs=false, % show tabs within strings adding particular underscores frame=single, % adds a frame around the code rulecolor= \\color { black } , % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here)) tabsize=4, % sets default tabsize to 2 spaces captionpos=b, % sets the caption-position to bottom breaklines=true, % sets automatic line breaking breakatwhitespace=false, % sets if automatic breaks should only happen at whitespace title= \\lstname , % show the filename of files included with \\lstinputlisting; % also try caption instead of title keywordstyle= \\color { blue } , % keyword style commentstyle= \\color { dkgreen } , % comment style stringstyle= \\color { mauve } , % string literal style escapeinside= { \\%* }{ *) } , % if you want to add a comment within your code morekeywords= { *,... } % if you want to add more keywords to the set } % this is needed for forms and links within the text \\usepackage { hyperref } %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Variablen % %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\newcommand { \\authorName }{ Martin Thoma } \\newcommand { \\tags }{ \\authorName , my, tags } \\title { Aufgabe 5 } \\author { \\authorName } \\date { \\today } %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % PDF Meta information % %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\hypersetup { pdfauthor = { \\authorName } , pdfkeywords = { \\tags } , pdftitle = { This is the title } } %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % THE DOCUMENT BEGINS % %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\begin { document } \\lstinputlisting { aufgabe-5.s } \\end { document } See also How to print Source Code with LaTeX\" Typesetting MIPS Assembly Code in LaTeX Add MIPS syntax highlighting to gEdit","tags":"Code","title":"How to print MIPS assembly code in LaTeX"},{"url":"https://martin-thoma.com/add-mips-syntax-highlighting-gedit/","text":"I have to code some little programs in MIPS assembly language for university. So I liked to have some syntax highlighting for my favorite editor: gEdit. The following steps were tested on Ubuntu 10.04.4 LTS. This adds MIPS syntax highlighting to gEdit and every editor, that uses gtksourceview. Create the following file: /usr/share/gtksourceview-2.0/language-specs/sal.lang Source: GITHub: Xodarap / Mips-Assembly-Syntax-Highlighting Copy and paste the following: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <!-- Author: Ben West Copyright (C) 2010 Ben West edited by Martin Thoma This library is free software; you can redistribute it and/or modify it under the terms of the GNU Library General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version. This library is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Library General Public License for more details. You should have received a copy of the GNU Library General Public License along with this library; if not, write to the Free Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA. --> <!-- Somewhat copied and pasted from nasm.lang --> <language id= \"mal\" _name= \"MAL\" version= \"2.0\" _section= \"Others\" > <metadata> <property name= \"mimetypes\" > text/mal </property> <property name= \"globs\" > *.s </property> <property name= \"line-comment-start\" > # </property> </metadata> <styles> <style id= \"comment\" _name= \"Comment\" map-to= \"def:comment\" /> <style id= \"error\" _name= \"Error\" map-to= \"def:error\" /> <style id= \"string\" _name= \"String\" map-to= \"def:string\" /> <style id= \"preprocessor\" _name= \"Preprocessor\" map-to= \"def:preprocessor\" /> <style id= \"opcode\" _name= \"Opcode\" map-to= \"def:keyword\" /> <style id= \"register\" _name= \"Register\" map-to= \"def:special-char\" /> <style id= \"type\" _name= \"Data Type\" map-to= \"def:type\" /> <style id= \"escaped-character\" _name= \"Escaped Character\" map-to= \"def:special-char\" /> <style id= \"decimal\" _name= \"Decimal number\" map-to= \"def:decimal\" /> <style id= \"hexadecimal\" _name= \"Hexadecimal number\" map-to= \"def:base-n-integer\" /> <style id= \"label\" _name= \"Label\" map-to= \"def:identifier\" /> </styles> <default-regex-options case-sensitive= \"false\" /> <definitions> <define-regex id= \"escaped-character\" extended= \"true\" > \\\\( # leading backslash [\\\\\\\"\\'] # escaped character ) </define-regex> <context id= \"mal\" > <include> <context id= \"preprocessor\" style-ref= \"preprocessor\" > <prefix> &#94;\\. </prefix> <keyword> data </keyword> <keyword> text </keyword> </context> <context id= \"comment\" style-ref= \"comment\" end-at-line-end= \"true\" > <start> # </start> <include> <context ref= \"def:in-line-comment\" /> </include> </context> <context id= \"string\" style-ref= \"string\" end-at-line-end= \"true\" > <start> \" </start> <end> \" </end> <include> <context id= \"escaped-characterw\" style-ref= \"escaped-character\" > <match> \\%{escaped-character} </match> </context> </include> </context> <context id= \"string2\" style-ref= \"string\" end-at-line-end= \"true\" > <start> ' </start> <end> ' </end> <include> <context id= \"escaped-characters\" style-ref= \"escaped-character\" > <match> \\%{escaped-character} </match> </context> </include> </context> <context id= \"hexadecimal-number\" style-ref= \"hexadecimal\" > <match extended= \"true\" > (? &amp; lt;![\\w\\.]) [+-]?0x[0-9a-fA-F]+ (?![\\w\\.]) </match> </context> <context id= \"decimal\" style-ref= \"decimal\" > <match extended= \"true\" > (? &amp; lt;![\\w\\.]) [0-9]+ (?![\\w\\.]) </match> </context> <context id= \"registers\" style-ref= \"register\" > <match extended= \"true\" > (\\$ ( \\d|[12]\\d|3[12]| (ra)| ([vk][01])| (a[0-3t])| (t[0-9])| (s[0-7p])| ([gsf]p)| (zero) ) )\\b </match> </context> <context id= \"label\" style-ref= \"label\" > <match extended= \"true\" > &#94;\\w+: </match> </context> <!-- Opcodes --> <context id= \"opcodes_simple\" style-ref= \"opcode\" > <!-- MAL Opcodes --> <keyword> la </keyword> <keyword> li </keyword> <keyword> lw </keyword> <keyword> lb </keyword> <keyword> lbu </keyword> <keyword> sw </keyword> <keyword> sb </keyword> <keyword> add(\\.s)? </keyword> <keyword> sub(\\.s)? </keyword> <keyword> mul(\\.s)? </keyword> <keyword> div(\\.s)? </keyword> <keyword> rem </keyword> <keyword> and </keyword> <keyword> or </keyword> <keyword> xor </keyword> <keyword> nor </keyword> <keyword> not </keyword> <keyword> move </keyword> <keyword> sll </keyword> <keyword> srl </keyword> <keyword> sra </keyword> <keyword> l\\.s </keyword> <keyword> s\\.s </keyword> <keyword> mov\\.s </keyword> <keyword> cvt\\.s\\.w </keyword> <keyword> cvt\\.w\\.s </keyword> <keyword> mfc0 </keyword> <keyword> mtc0 </keyword> <keyword> mfc1 </keyword> <keyword> mtc1 </keyword> <keyword> b </keyword> <keyword> beq </keyword> <keyword> bne </keyword> <keyword> blt </keyword> <keyword> bgt </keyword> <keyword> ble </keyword> <keyword> bge </keyword> <keyword> bltz </keyword> <keyword> bgtz </keyword> <keyword> blez </keyword> <keyword> bgez </keyword> <keyword> bnez </keyword> <keyword> beqz </keyword> <keyword> j </keyword> <keyword> jr </keyword> <keyword> jal </keyword> <keyword> jalr </keyword> <keyword> getc </keyword> <keyword> putc </keyword> <keyword> puts </keyword> <keyword> done </keyword> <keyword> syscall </keyword> <keyword> andi </keyword> </context> <context id= \"types\" style-ref= \"type\" > <prefix> \\. </prefix> <keyword> byte </keyword> <keyword> word </keyword> <keyword> asciiz </keyword> <keyword> ascii </keyword> <keyword> float </keyword> </context> </include> </context> </definitions> </language> That's it. See also Wikipedia: MIPS architecture Wikibooks: MIPS Assembly SPIM (a MIPS simulator)","tags":"Code","title":"Add MIPS syntax highlighting to gEdit"},{"url":"https://martin-thoma.com/python-one-liners-for-project-euler/","text":"Today, I've been trying to get used to Pythons functional programming tools by solving Project-Euler tasks. To make them more interesting, I've solved them in one line. But I realized, that it is difficult to read online as only about 70 characters get displayed without a scrollbar. So I made multi-line solutions out of them. These snippets are also good examples what's possible to do with Python and to show that Python is fast. Problem 24 What is the millionth lexicographic permutation of the digits 0, 1, 2, 3, 4, 5, 6, 7, 8 and 9? from itertools import permutations , islice print next ( islice ( permutations ( \"0123456789\" ), 999999 , 999999 + 1 )) Problem 29 How many distinct terms are in the sequence generated by $a&#94;b$ for $2 \\leq a \\leq 100$ and $2 \\leq b \\leq 100$? d = lambda top : len ( set ([ a ** b for a in xrange ( 2 , top + 1 ) for b in xrange ( 2 , top + 1 )])) Problem 34 145 is a curious number, as 1! + 4! + 5! = 1 + 24 + 120 = 145. Find the sum of all numbers which are equal to the sum of the factorial of their digits. Note: as 1! = 1 and 2! = 2 are not sums they are not included. from math import factorial l = lambda n : reduce ( lambda x , y : int ( x ) + factorial ( int ( y )), [ d for d in \"0\" + str ( n )]) print ( reduce ( lambda x , y : x + y , filter ( lambda x : x == l ( x ), xrange ( 3 , 100000 )))) Problem 36 The decimal number, 585 = 10010010012 (binary), is palindromic in both bases. Find the sum of all numbers, less than one million, which are palindromic in base 10 and base 2. palindrom = lambda x : str ( x ) == str ( x )[:: - 1 ] and str ( bin ( x ))[ 2 :] == str ( bin ( x ))[ 2 :][:: - 1 ] d = lambda top : reduce ( lambda x , y : x + y , filter ( palindrom , xrange ( 0 , top + 1 ))) Problem 48 The series, $1&#94;1 + 2&#94;2 + 3&#94;3 + ... + 10&#94;{10} = 10405071317$. Find the last ten digits of the series, $1&#94;1 + 2&#94;2 + 3&#94;3 + ... + 1000&#94;{1000}$. d = lambda top : str ( reduce ( lambda x , y : x + y , [ i ** i for i in xrange ( 1 , top + 1 )]))[ - 10 :] Problem 52 Find the smallest positive integer, x, such that 2x, 3x, 4x, 5x, and 6x, contain the same digits in some order. digits = lambda n , p : set ( str ( n * p )) d = lambda n : all ( digits ( n , 1 ) == digits ( n , x ) for x in range ( 2 , 7 )) print ( filter ( d , xrange ( 0 , 1000000 ))) Problem 53 How many values of $\\binom{n}{r}$, for $1 \\leq r \\leq n \\leq 100$, exceed one-million? from math import factorial as f print ( sum (( f ( i ) / ( f ( j ) * f ( i - j ))) > 1000000 for i in range ( 1 , 101 ) for j in range ( 1 , i ))) Problem 56 Considering natural numbers of the form, $a&#94;b$, finding the maximum digital sum. print max ([ sum ([ int ( c ) for c in str ( a ** b )]) for a in xrange ( 1 , 100 ) for b in xrange ( 1 , 100 )]) Problem 97 Find the last ten digits of the non-Mersenne prime: $28433 \\cdot 2&#94;{7830457} + 1$. print ( 28433 * ( 2 ** 7830457 ) + 1 ) % ( 10 ** 10 )","tags":"Cyberculture","title":"Python one-liners for Project Euler"},{"url":"https://martin-thoma.com/functional-programming-in-python/","text":"Python has a few functional programming tools: Lambda functions and the three higher-order functions map, filter and reduce. I'll explain them now and I'll give some usage examples. lambda A lambda creates an anonymous function , that means a function without a name. A lambda may have any number of arguments. Here are some examples for lambdas: f = lambda x : x * x print ( f ( 7 )) Output: 49 g = lambda x , y : x + y * y + abs ( x ) print ( g ( 1 , 1 ), g ( 1 , - 1 ), g ( - 1 , 1 ), g ( 10 , 6 ), g ( - 10 , 6 )) Output: (3, 3, 1, 56, 36) h = lambda myVar , anotherVar : set ([ myVar , anotherVar ]) print ( h ( 1 , 2 ), h ( 'a' , 1 ), h ( 'a' , 'a' ), h ( 1 , 1 )) Output: (set([1, 2]), set(['a', 1]), set(['a']), set([1])) Sometimes you would like to get an if-statement in a lambda. So imagine you would like to make a lambda function like this: def f ( x ): if x == 0 : return 42 elif x == 1 : return 1337 else : return 0 This is the way you would do it: f = lambda x : x == 0 and 42 or x == 1 and 1337 or 0 (Thanks to Ikke's blog for the hint!) map(function, sequence) Map is a function with two parameters. The first parameter is another function, the second is a sequence. Map returns a list. It only applies function to every item of the sequence. Here are some examples: def square ( x ): return x * x l = map ( square , [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ]) l = [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] This is equivalent to: l = map ( lambda x : x * x , range ( 1 , 11 )) You can also use more than one list: a = range ( - 10 , 10 ) b = range ( 0 , 20 ) l = map ( lambda x , y : x * y , a , b ) Output: [0, -9, -16, -21, -24, -25, -24, -21, -16, -9, 0, 11, 24, 39, 56, 75, 96, 119, 144, 171] reduce(function, sequence) You can quite often reduce problems to an operation on two elements. Reduce takes two elements from sequence, uses function on them and saves the result. Then it takes the result and another element of the sequence and uses function... Example: Imagine you would like to get the sum of a list. Then you need to add two elements of the list, save the result and add another element, save the result, add another element, ... r = reduce ( lambda x , y : x + y , [ 1 , 2 , 63 , 3 , 5 ]) r = 74 You can calculate the factorial n! like this: fac = lambda n : reduce ( lambda x , y : x * y , range ( 1 , n + 1 )) print ( fac ( 2 )) print ( fac ( 3 )) print ( fac ( 10 )) Output: 2 6 3628800 filter(function, sequence) filter gets all elements from sequence, where function returns true: def is_prime ( element ): if element == 2 : return True elif element <= 1 or element % 2 == 0 : return False else : for i in range ( 3 , element , 2 ): if element % i == 0 : return False return True my_list = [ 4 , 4 , 9 , 12 , 13 , 2 , 7 , 9 , 11 , 11 ] r = filter ( is_prime , my_list ) r = [13, 2, 7, 11, 11] Some more examples Task: What is the sum of digits of \\(2&#94;n, n \\in \\mathbb{N}\\) ? sumOfDigits = lambda exp : reduce ( lambda x , y : x + y , map ( lambda x : int ( x ), str ( 2 ** exp )) ) print ( sumOfDigits ( 2 )) print ( sumOfDigits ( 3 )) print ( sumOfDigits ( 4 )) print ( sumOfDigits ( 10000 )) Output: 4 8 7 13561 Task: Encode and decode a string in the following way: Split Words by spaces. Every plaintext character gets a two-digit numerical representation in base 16. A is 01, B is 02 and Z is 1A. # Thanks to lebenf: http://stackoverflow.com/a/3226719/562769 chunks = lambda l , n : [ l [ x : x + n ] for x in range ( 0 , len ( l ), n )] decodeWord = lambda s : \"\" . join ( map ( lambda x : chr ( int ( x , 16 ) + 64 ), chunks ( s , 2 ))) decode = lambda s : \" \" . join ( map ( decodeWord , s . split ( \" \" ))) encodeWord = lambda p : \"\" . join ( map ( lambda x : \" %.2X \" % ( ord ( x ) - 64 ), p )) encode = lambda p : \" \" . join ( map ( encodeWord , p . split ( \" \" ))) cipher = encode ( \"HELLO WORLD\" ) print ( \"Cipher Text: %s \" % cipher ) print ( \"Plain Text: %s \" % decode ( cipher )) See also Wikipedia: Lambda calculus filter map reduce Python-Kurs: Lambda, filter, reduce und map (German)","tags":"Code","title":"Functional Programming in Python"},{"url":"https://martin-thoma.com/warum-kann-der-mond-keine-atmosphare-haben/","text":"Ich lese gerade das Buch 2025 von Frank SchÃ¤tzing, in dem es um den Abbau des Isotops 3 He geht. Es wird auch kurz erwÃ¤hnt, dass es auf dem Mond keine AtmosphÃ¤re geben kann. Warum ist das so? Die kurze Antwort Der Mond ist leicht. Er Ã¼bt deshalb eine weitaus geringere Anziehungskraft aus, als die Erde. Deshalb ist die Geschwindigkeit, die benÃ¶tigt wird um den Mond zu verlassen auch um einiges niedriger als die Fluchtgeschwindigkeit der Erde. Gleichzeitig ist es auf dem Mond sehr heiÃŸ, die einzelnen Gas-Teilchen bewegen sich also sehr schnell. Das bedeutet, sie kÃ¶nnen den Mond verlassen. Die lange Antwort Definitionen und GrÃ¶ÃŸen Die AtmosphÃ¤re bezeichnet die gasfÃ¶rmige HÃ¼lle um einen HimmelskÃ¶rper. Die Fluchtgeschwindigkeit Der Mond hat Temperaturen von bis zu 130 Â°C. Das sind 403,15 Kelvin. Die Masse des Mondes betrÃ¤gt \\(7,349 \\cdot 10&#94;{22} kg\\) , der Radius betrÃ¤gt 1738 km. Die Atommasse von Sauerstoff betrÃ¤gt \\(15,999 u\\) . Mittlere Geschwindigkeit eines Gases Die mittlere Geschwindigkeit eines Gases berechnet sich wie folgt: \\(E_{Kin} = \\bar E_i\\) \\(\\Leftrightarrow \\frac{1}{2} \\cdot m \\cdot v&#94;2 = \\frac{3}{2} \\cdot k \\cdot T\\) , wobei k die Boltzmann-Konstante ist und T die thermodynamische Temperatur \\(\\Leftrightarrow v&#94;2 = \\frac{3 \\cdot k \\cdot T}{m}\\) Da wir die mittlere Geschwindigkeit eines Gasteilchens wollen, mÃ¼ssen wir die Maxwell-Geschwindigkeitsverteilung beachten: \\(\\Rightarrow \\bar v = \\sqrt{\\frac{8}{2 \\cdot \\pi}} \\sqrt{\\frac{3 \\cdot k \\cdot T}{m}}\\) \\(\\Leftrightarrow \\sqrt{\\frac{12 \\cdot k \\cdot T}{\\pi \\cdot M \\cdot u}}\\) , mit M als Atommasse und u als atomare Masseneinheit . Berechnung der Fluchtgeschwindigkeit \\(v_{fl} = \\sqrt{\\frac{2 \\cdot G \\cdot m}{r}}\\) , wobei G die Gravitationskonstante , m die Masse des HimmelskÃ¶rpers und r dessen Radius. Siehe auch: 1. Kosmische Geschwindigkeit . Berechnung Nun benÃ¶tigen wir noch folgende Faustregel: Eine Faustregel besagt, dass sich in der AtmosphÃ¤re eines Planeten nur solche Gase befinden, deren mittlere Geschwindigkeit kleiner als ein Sechstel der Fluchtgeschwindigkeit fÃ¼r diesen Planeten ist. Quelle: Leifi-Physik \\(v_{fl}(\\text{Mond}) \\approx \\sqrt{\\frac{2 \\cdot (6,67384 \\cdot 10&#94;{-11} \\cdot \\frac{m&#94;3}{kg \\cdot s&#94;2}) \\cdot (7,349 \\cdot 10&#94;{22} kg)}{1738000 m}} \\approx 2375,70 \\frac{m}{s}\\) \\(\\Rightarrow \\frac{1}{6} v_{fl}(\\text{Mond}) \\approx 395,95\\) Die mittlere Geschwindigkeit von Sauerstoff bei 130 Â°C ist: \\(\\bar v (O_2, \\text{Mond}) \\approx \\sqrt{\\frac{12 \\cdot (1,3806488 \\cdot 10&#94;{-23}) \\cdot (130 + 273,15)}{\\pi \\cdot (2 \\cdot 15,999) \\cdot (1,660538921 \\cdot 10&#94;{-27})}} \\cdot \\frac{m}{s} \\approx 632,56 \\frac{m}{s}\\) Achtung: Ein SauerstoffmolekÃ¼l hat 2 Atome! \\(\\Rightarrow \\frac{1}{6} v_{fl}(\\text{Mond}) < \\bar v (O_2, \\text{Mond}) \\Rightarrow\\) Langfristig kann es keine sauerstoffhaltige AtmosphÃ¤re auf dem Mond geben.","tags":"German posts","title":"Warum kann der Mond keine AtmosphÃ¤re haben?"},{"url":"https://martin-thoma.com/cool-features-of-python/","text":"A friend wanted to know why I enjoy programming in Python so much more than programming in other languages. So I will describe some special features of Python which make it much easier to quickly implement algorithms. I also made drafts how the tasks would be solved in most programming languages. When I say most, I mean most languages that are widely spread (so C/C++/Java is much more important than almost any other languages combined). I know that those tasks would be solved completely different in functional programming languages. Rapid, readable programming Intuitive looping through lists You can loop through every list-like datastructure like this: for element in list : print ( element ) Arbitrary Integer size Description : Print the sum of the digits of \\(2&#94;{100000}\\) . Java : import java.math.BigInteger ; public class test { public static void main ( String [] args ) { BigInteger a = new BigInteger ( \"2\" ); a = a . pow ( 100000 ); int sum = 0 ; for ( int i = 0 ; i < a . toString (). length (); i ++) { sum += a . toString (). charAt ( i ); } System . out . println ( sum ); } } Python : (was much faster in both computation and programming time!) big = 2 ** 100000 sumOfDigits = 0 for digit in str ( big ): sumOfDigits += int ( digit ) print ( sumOfDigits ) Python has no need for a special class as it has arbitrary length integers (see source ) Swich values of variables Description : You want to make sure, that variable a is smaller than b ( \\(a < b\\) ). Most languages : tmp = a a = min ( a , b ) b = max ( tmp , b ) Python : a , b = min ( a , b ), max ( a , b ) Return more than one variable Description : Evaluate \\(f: \\mathbb{R}&#94;2 \\rightarrow \\mathbb{R}&#94;3, f(x, y) := (x&#94;2, y&#94;2, x+y)\\) Most languages : double function ( double x , double y ) { double returnValues [ 3 ]; returnValues [ 0 ] = x * x ; returnValues [ 1 ] = y * y ; returnValues [ 2 ] = x + y ; return returnValues ; } double values [ 3 ] = function ( 4 , 5 ); printf ( \"Part 1: %.2f \" , values [ 0 ]); printf ( \"Part 3: %.2f \" , values [ 2 ]); Python : def function ( x , y ): return ( x * x , y * y , x + y ) a , b , c = function ( 4 , 5 ) print ( \"Part 1: %.2f \" % a ) print ( \"Part 3: %.2f \" % b ) This is called \"Argument Unpacking\". In fact it does return only one variable (a tuple), but it creating the tuple is so easy that it does not feel like creating another variable. Short initialisation Description : Get a string representation of a list from the standard library Java : import java.util.LinkedList ; import java.util.List ; public class test { public static void main ( String [] args ) { List < Integer > myList = new LinkedList < Integer >(); myList . add ( 1 ); myList . add ( 3 ); myList . add ( 3 ); myList . add ( 7 ); System . out . println ( myList ); } } Python : myList = [ 1 , 3 , 3 , 7 ] print ( myList ) Both get the same result. Chaining Comparisons Description: You would like to check if \\(x \\in [-5, 42]\\) . Most languages : if (- 5 <= x & amp ;& amp ; x <= 42 ) Python : if - 5 <= x <= 42 : Enumeration Description : You have a list and you would like to print it, prefixed with the index in the list. Java : List myList = ( List initialisation and assignment , multiple lines ) int i = 0 ; for ( int element : myList ) { System . out . printf ( \"%i: %i\" , i , element ); i ++; } Python : myList = [ 1 , 3 , 3 , 7 ] for nr , element in enumerate ( myList ): print ( \" %i : %i \" % ( nr , element )) Named String formatting Python allows you to give parameters names: print ( \"The %(foo)s is %(bar)i .\" % { 'foo' : 'answer' , 'bar' : 42 }) any() and all() Description : You have a very long list and you want to know, if a prime is in this list. Most languages : List myList = ( List initialisation and assignment of many values ) boolean isPrimePresent = false ; for ( int element : myList ) { if ( isPrime ( element )) { isPrimePresent = true ; break ; } } if (! isPrimePresent ) { System . out . println ( \"The list did not containe a prime.\" ); } Python : myList = [ 4 , 4 , 9 , 12 ] if not any ( isPrime ( x ) for x in myList ): print ( \"The list did not contain a prime\" ) See also: StackOverflow answer from steveha . Testing and Documentation Doctest You can write Documentation and Unit-Tests at the same time! Take a look at doctest â€” Test interactive Python examples . Sphinx Documentation can be generated from partially docstrings, partially rst files with Sphinx . It can be uploaded to pythonhosted.org just like neurolab did it (see also sphinx ). The Rest Lists and Generators I already wrote an article about Python Lists and Python Generators . I love Pythons lists â˜º for ... else Description : You have a very long list and you want to know, if a prime is in this list. Most languages : List myList = ( List initialisation and assignment of many values ) boolean isPrimePresent = false ; for ( int element : myList ) { if ( isPrime ( element )) { isPrimePresent = true ; break ; } } if (! isPrimePresent ) { System . out . println ( \"The list did not containe a prime.\" ); } Python : myList = [ 1 , 3 , 3 , 7 ] for element in myList : if isPrime ( element ): break else : print ( \"The list did not containe a prime.\" ) Step through lists Description : Print only every n-th element of an iterable. for element in myList [:: n ]: print elemenet Dynamically add properties to objects and classes class Node ( object ): value = 3 a = Node () b = Node () print a . value \"\"\" colorize the node! \"\"\" #print a.color ==> AttributeError # thats ok, although the object originally had no attribute \"color\" a . color = \"white\" print a . color # You can even add a property to the class Node . special = \"here is it\" print b . special Imaginary numbers Python directly supports usage of imaginary numbers: ( 2j + 1 ) ** 2 Output: (-3+4j) Read also An Informal Introduction to Python","tags":"Code","title":"Cool features of Python"},{"url":"https://martin-thoma.com/latex-vorlage-fur-den-semesterbericht-der-studienstiftung/","text":"Stipendiaten der Studienstiftung des deutschen Volkes mÃ¼ssen jedes Semester einen Studienbericht schreiben. Damit sich andere Stipendiaten nicht auch jedes mal die Vorlage erstellen mÃ¼ssen, stelle ich meine LaTeX-Vorlage hier bereit. Wenn ihr VerbesserungsvorschlÃ¤ge habt, kÃ¶nnt ihr mir gerne eine E-Mail schreiben (info@martin-thoma.de) oder einen Kommentar hinterlassen. Wozu dient der Semesterbericht? Im Daidalosnet steht dazu: Der Studienbericht bietet Gelegenheit, Ã¼ber die wesentlichen Inhalte und Erfahrungen des letzten Semesters nachzudenken sowie die beiden Leser - den Vertrauensdozenten und den Referenten - zu informieren und an Reflexionen und Bewertungen teilnehmen zu lassen. Ohne die Berichte wÃ¤re die Studienstiftung weniger oder kaum in der Lage, ein aktuelles Wissenschaftliches Programm zu bieten und die Stipendiaten verlÃ¤sslich zu beraten. Nach der LektÃ¼re des Berichtes sollten die Leser ein Bild vom Verlauf des Studiums und von fachlichen und auÃŸerfachlichen AktivitÃ¤ten gewonnen haben. Ein Umfang von zwei bis drei Seiten ist angemessen. Wer bekommt wann den Studienbericht? Stipendiaten, die in den ersten vier Fachsemestern (vor Antragsstellung auf WeiterfÃ¶rderung) aufgenommen werden, schreiben jeweils zum 1. MÃ¤rz und 1. September Semesterberichte (im Jahr der Antragsstellung auf WeiterfÃ¶rderung: zusammen mit dem Antrag bereits zum 1. August); alle anderen Stipendiaten schreiben den Jahresbericht zum 1. September . Mit dem Semesterbericht fÃ¼r das WS 2012/2013 soll der Bericht nicht mehr an den zustÃ¤ndigen Referenten bzw. Vertrauensdozenten geschickt werden, sondern direkt ins Daidalosnet geladen werden: Bitte laden Sie Ihren Bericht als PDF-Dokument im Daidalosnet hoch. Sie finden die Eingabemaske in Ihrem eigenen Kurzprofil (\" Meine Einstellungen \" unten rechts) - hier ist in der unteren BildschirmhÃ¤lfte die Rubrik \" Studienberichte \" zu finden. Wenn Sie hier einen als \"offen\" gekennzeichneten Eintrag finden, mÃ¼ssen Sie uns einen Bericht zukommen lassen - bitte folgen Sie dem Link in der Zeile unter \"offen\", um zur Eingabemaske zu gelangen. Sowohl Ihr/e Referent/in als auch Ihr/e Vertrauensdozent/in erhalten automatisch eine Kopie des Berichts per E-Mail. Wer ist mein zustÃ¤ndiger Referent bzw. mein Vertrauensdozent? Logge dich im daidalosnet ein. Klicke rechts unten auf \"Meine Einstellungen\". Klicke auf \"Gespeicherte Daten\". Nun sollte \"Referent/in\" sowie \"aktueller Vertrauensdozent\" dort stehen. Die Vorlage Hier ist die Vorlage mit Blindtext als PDF . Makefile: DOKUMENT = semesterbericht-martin-thoma-ws-2011 make : pdflatex $( DOKUMENT ) .tex -output-format = pdf pdflatex $( DOKUMENT ) .tex -output-format = pdf make clean clean : rm -rf $( TARGET ) *.class *.html *.log *.aux *.out LaTeX: \\documentclass [a4paper,12pt] { article } \\usepackage { amssymb } % needed for math \\usepackage { amsmath } % needed for math \\usepackage [utf8] { inputenc } % this is needed for umlauts \\usepackage [ngerman] { babel } % this is needed for umlauts \\usepackage [T1] { fontenc } % this is needed for correct output of umlauts in pdf \\usepackage [margin=2.5cm,headheight=40pt] { geometry } %layout \\usepackage { fancyhdr } % needed for the footer \\usepackage { lastpage } % needed for the footer \\usepackage { hyperref } % links im text \\usepackage { color, colortbl } % farbige Tabellenzellen \\usepackage { tabularx } \\clubpenalty = 10000 % Schusterjungen verhindern \\widowpenalty = 10000 % Hurenkinder verhindern %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Hier eigene Daten einfÃ¼gen % %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\newcommand { \\Jahr }{ 2011/2012 } % Typ: \"2011 / 2012\" oder \"2012\" \\newcommand { \\Semester }{ Wintersemester } % \"Wintersemester\" oder \"Sommersemester\" \\newcommand { \\Datum }{ \\today } % Wann wurde der Bericht erstellt? \\newcommand { \\Semesteranzahl }{ 1 } % Das Fachsemester als Zahl \\newcommand { \\Gesamtsemesterzahl }{ 6 } % Die gesamte Anzahl an Semestern \\newcommand { \\Abschluss }{ Bachelor } \\newcommand { \\Studienfach }{ Informatik } \\newcommand { \\University }{ KIT } \\newcommand { \\Nachname }{ Thoma } \\newcommand { \\Vorname }{ Martin } \\newcommand { \\Strasse }{ Musterstra & szlig;e } \\newcommand { \\Hausnummer }{ 123 } \\newcommand { \\PLZ }{ 76131 } \\newcommand { \\Ort }{ Karlsruhe } \\newcommand { \\Email }{ info@martin-thoma.de } \\newcommand { \\Vertrauensdozent }{ Prof. Dr. <a href='../images/2012/06/semesterbericht-ws-2011.pdf'>Semesterbericht WS 2011</a>Mustermann } \\newcommand { \\Referent }{ Dr. Alice Brown } %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\hypersetup { pdfauthor = { \\Vorname ~ \\Nachname } , pdfkeywords = { Studienstiftung; KIT; \\Vorname ~ \\Nachname } , pdftitle = { Semesterbericht von~ \\Vorname ~ \\Nachname ~-~ \\Semester ~ \\Jahr } } \\pagestyle { fancy } \\fancyhf {} \\renewcommand { \\headrulewidth }{ 0pt } \\renewcommand { \\footrulewidth }{ 0pt } \\fancyhead [R] { \\includegraphics [width=5cm] { logo _ sdv }} % https://martin-thoma.com/images/2016/07/logo_sdv.jpg \\fancyfoot [R] { Seite~ \\thepage ~von \\pageref { LastPage }} \\definecolor { LightCyan }{ rgb }{ 0.88,1,1 } \\pagenumbering { arabic } \\begin { document } \\title { Semesterbericht Ã¼ber das \\Semester \\Jahr } \\author { \\Vorname \\Nachname } \\date { \\Datum } \\section* { Semesterbericht Ã¼ber das \\Semester ~ \\Jahr } \\begin { tabularx }{ \\textwidth }{ @ {} llllX } Name, Vorname: & \\Nachname , \\Vorname & UniversitÃ¤t & \\University \\\\ Semesteradresse: & \\Strasse ~ \\Hausnummer & Studienfach & \\Studienfach \\\\ & \\PLZ ~ \\Ort ~~~~~~~ & Semesterzahl & \\Semesteranzahl ~von~ \\Gesamtsemesterzahl \\\\ & & Geplanter Abschluss & \\Abschluss \\\\ & & Vertrauensdozent & \\Vertrauensdozent \\\\ E-Mail & \\Email & Referent & \\Referent \\\\ \\end { tabularx } %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Hier bitte Text einfÃ¼gen! % %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\subsection* { Einleitende Zusammenfassung } \\subsubsection* { 1. Auf diesem Stand ist jetzt mein Studium: } Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. \\subsubsection* { 2. Das war fÃ¼r mich au & szlig;erhalb des Studiums von gro & szlig;er Bedeutung: } Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Duis autem vel eum iriure dolor in hendrerit in vulputate velit esse molestie consequat, vel illum dolore eu feugiat nulla facilisis at vero eros et accumsan et iusto odio dignissim qui blandit praesent luptatum zzril delenit augue duis dolore te feugait nulla facilisi. Lorem ipsum dolor sit amet, consectetuer adipiscing elit, sed diam nonummy nibh euismod tincidunt ut laoreet dolore magna aliquam erat volutpat. Ut wisi enim ad minim veniam, quis nostrud exerci tation ullamcorper suscipit lobortis nisl ut aliquip ex ea commodo consequat. Duis autem vel eum iriure dolor in hendrerit in vulputate velit esse molestie consequat, vel illum dolore eu feugiat nulla facilisis at vero eros et accumsan et iusto odio dignissim qui blandit praesent luptatum zzril delenit augue duis dolore te feugait nulla facilisi. Nam liber tempor cum soluta nobis eleifend option congue nihil imperdiet doming id quod mazim placerat facer \\subsubsection* { 3. FÃ¼r das nÃ¤chste Semester habe ich folgende PlÃ¤ne: } Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. \\newpage Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam: \\begin { table } [h] \\begin { tabular }{ | l | c | c | l | } \\hline \\textbf { Modulbezeichnung } & \\textbf { SWS } & \\textbf { LP } & \\textbf { Klausur } \\\\ \\hline \\hline \\rowcolor { yellow } Lineare Algebra und Analytische Geometrie & 8 & 9 & Im SS 2012 \\\\ \\rowcolor { yellow } Analysis I & 8 & 9 & Im SS 2012 \\\\ \\rowcolor { yellow } Grundbegriffe der Informatik & 5 & 4 & Am 05. MÃ¤rz 2012 \\\\ \\rowcolor { yellow } Programmieren & 4 & 5 & Abschlussaufgabe lÃ¤uft \\\\ \\rowcolor { LightCyan } Betriebssysteme und Systemarchitektur & 6 & 6 & Am 26. MÃ¤rz 2012 \\\\ \\rowcolor { LightCyan } Theoretische Grundlagen der Informatik & 6 & 6 & Benotung steht aus \\\\ \\rowcolor { LightCyan } Wahrscheinlichkeitstheorie fÃ¼r Informatiker & 3 & 4,5 & mit 1,3 bestanden \\\\ \\hline \\hline Gesamt & 40 & 43,5 & \\\\ \\hline \\end { tabular } \\begin { tabular }{ | l | l | l | l | } \\hline \\cellcolor { yellow } & Teil der OrientierungsprÃ¼fung & \\cellcolor { LightCyan } & Pflichtmodul des 3. Semesters \\\\ \\hline \\end { tabular } \\end { table } Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Duis autem vel eum iriure dolor in hendrerit in vulputate velit esse molestie consequat, vel illum dolore eu feugiat nulla facilisis at vero eros et accumsan et iusto odio dignissim qui blandit praesent luptatum zzril delenit augue duis dolore te feugait nulla facilisi. Lorem ipsum dolor sit amet, consectetuer adipiscing elit, sed diam nonummy nibh euismod tincidunt ut laoreet dolore magna aliquam erat volutpat. Ut wisi enim ad minim veniam, quis nostrud exerci tation ullamcorper suscipit lobortis nisl ut aliquip ex ea commodo consequat. Duis autem vel eum iriure dolor in hendrerit in vulputate velit esse molestie consequat, vel illum dolore eu feugiat nulla facilisis at vero eros et accumsan et iusto odio dignissim qui blandit praesent luptatum zzril delenit augue duis dolore te feugait nulla facilisi. Nam liber tempor cum soluta nobis eleifend option congue nihil imperdiet doming id quod mazim placerat facer. \\\\ \\\\ \\Ort , der \\Datum\\\\ \\\\ \\Vorname ~ \\Nachname \\end { document }","tags":"German posts","title":"LaTeX-Vorlage fÃ¼r den Semesterbericht der Studienstiftung"},{"url":"https://martin-thoma.com/how-many-ipv6-adresses-exist/","text":"Some general information A typical IPv4 address in a local network looks like this: 192.168.0.1 This is 11000000 10101000 00000000 00000001 in binary octets. You can easily see that it has 32 bits. As one bit may have two values - 0 or 1 - there are \\(2&#94;{32} = 4,294,967,296 \\approx 4.3 \\cdot 10&#94;9\\) possible addresses. The internet needs IP-addresses to know which information should be sent to whom. So only 4.3 billion devices can be connected to the internet. Devices are home computers (your PCs), servers (of big companies like Google or Facebook), Smartphones. So we are currently getting out of addresses. To solve this problem, IPv6 was introduced. Pure Numbers IPv6 has 128 bit. This means there are the number of addresses is: \\(2&#94;{128} = 340282366920938463463374607431768211456 \\approx 3.4 \\cdot 10&#94;{38}\\) Quite a lot. Playing with numbers Imagine the world had 10 billion people ( \\(10,000,000 = 10 \\cdot 10&#94;9 = 10&#94;{10}\\) ). Imagine everyone bought 6 smartphones, 5 computers, 1 car, 4 tablet, 4 car radios in every year. That would be 20 internet devices for every person every year. Now you could give every device a unique address for much, much more than billion billion years! The sun is going to get a red giant in about 4 billion years, so this is nothing we have to worry about. Calculation: \\(\\frac{2&#94;{128}}{10&#94;{10} \\cdot 20} \\approx 1.7 \\cdot 10&#94;{34}\\) See also Wikipedia: Internet Protocol UbuntuUsers: IPv6 (German)","tags":"The Web","title":"How many IPv6 adresses exist?"},{"url":"https://martin-thoma.com/vectors-in-cpp/","text":"Minimal Example #include <iostream> #include <vector> #include <algorithm> using namespace std ; int main () { // create an empty vector vector < int > myVector ; // insert one element myVector . push_back ( 5 ); // insert another element myVector . push_back ( 4 ); // insert more elements myVector . push_back ( 1337 ); myVector . push_back ( 42 ); myVector . push_back ( 31415 ); // insert an element which was there before myVector . push_back ( 5 ); // get the number of elements (length/size) of the vector cout << myVector . size () << endl ; // get the third element cout << \"third element: \" << myVector [ 2 ] << endl ; // removes the element at position number 6 myVector . erase ( myVector . begin () + 5 ); // removes the element with the value 4 myVector . erase ( remove ( myVector . begin (), myVector . end (), 4 ), myVector . end ()); // iterate over the vector vector < int >:: iterator myIt ; for ( myIt = myVector . begin (); myIt != myVector . end (); myIt ++ ){ cout << * myIt << \" \" ; } cout << endl ; return 0 ; } Output: third element: 1337 5 1337 42 31415 Vector initialization // create a vector with 100 zeroes vector < int > myVector ( 100 ); // create a vector which has 42 times the integer 100 vector < int > myVector ( 42 , 100 ); Nested Vectors #include <iostream> #include <vector> using namespace std ; int main () { // create an empty vector vector < vector < int > > myVector ( 4 ); // add elements myVector [ 0 ]. push_back ( 1 ); myVector [ 0 ]. push_back ( 2 ); myVector [ 1 ]. push_back ( 3 ); // iterate over the vector vector < vector < int > >:: iterator myIt ; vector < int >:: iterator innerIt ; for ( myIt = myVector . begin (); myIt != myVector . end (); myIt ++ ){ cout << \"Inner vector: \" ; for ( innerIt = myIt -> begin (); innerIt != myIt -> end (); innerIt ++ ) { cout << * innerIt << \" \" ; } cout << endl ; } return 0 ; } Output: Inner vector: 1 2 Inner vector: 3 Inner vector: Inner vector: Initialize nested vectors vector < int > myInnerVector ( 5 , 3 ); vector < vector < int > > myVector ( 8 , myInnerVector ); Output with the script above: Inner vector: 3 3 3 3 3 Inner vector: 3 3 3 3 3 Inner vector: 3 3 3 3 3 Inner vector: 3 3 3 3 3 Inner vector: 3 3 3 3 3 Inner vector: 3 3 3 3 3 Inner vector: 3 3 3 3 3 Inner vector: 3 3 3 3 3 You could also do it this way: vector < vector < int > > myVector ( 8 , vector < int > ( 5 , 3 )); Some more Reverse the order With reverse ( source ): #include <algorithm> #include <vector> using namespace std ; int main () { vector < int > myvector ; vector < int >:: iterator it ; // set some values: for ( int i = 1 ; i < 10 ; ++ i ) myVector . push_back ( i ); // 1 2 3 4 5 6 7 8 9 reverse ( myVector . begin (), myVector . end ()); // 9 8 7 6 5 4 3 2 1 // print out content: cout << \"myVector contains:\" ; for ( it = myVector . begin (); it != myVector . end (); ++ it ) cout << \" \" << * it ; cout << endl ; return 0 ; } See also C++ Reference: General information and example Iterating over 2-dimensional STL vector C++","tags":"Code","title":"Vectors in C++"},{"url":"https://martin-thoma.com/sets-in-c/","text":"#include <iostream> #include <set> #include <iterator> using namespace std ; int main () { // create an empty set of integers set < int > mySet ; // insert one element mySet . insert ( 5 ); // insert another element mySet . insert ( 4 ); // insert more elements mySet . insert ( 1337 ); mySet . insert ( 42 ); mySet . insert ( 31415 ); // insert an element which was there before mySet . insert ( 5 ); // check if 4 is in set bool is_in = mySet . find ( 4 ) != mySet . end (); cout << \"4 is in mySet: \" << is_in << endl ; is_in = mySet . find ( 6 ) != mySet . end (); cout << \"6 is in mySet: \" << is_in << endl ; // iterate over the set set < int >:: iterator myIt ; for ( myIt = mySet . begin (); myIt != mySet . end (); myIt ++ ){ cout << * myIt << \" \" ; } return 0 ; } As find is logarithmic in size() (source: C++ Reference ), the membership test is also in \\({\\cal O}(log(n))\\) . Sets of structs If you want to create a set of structs, you have to create a comperator: bool operator < ( const Edge & amp ; left , const Edge & amp ; right ) { return left . uniqueEdge < right . uniqueEdge ; } See also C++ Reference: general information and example How to check that an element is in a std::set?","tags":"Code","title":"Sets in C++"},{"url":"https://martin-thoma.com/stacks-in-cpp/","text":"Minimum Example #include <iostream> #include <stack> using namespace std ; int main (){ stack < int > myStack ; myStack . push ( 5 ); cout << \"Size of stack: \" << myStack . size () << endl ; myStack . push ( 4 ); // get the element on the top cout << \"Top: \" << myStack . top () << endl ; // it does NOT automatically pop! cout << \"Top: \" << myStack . top () << endl ; // pop has NO return value! myStack . pop (); cout << \"Top: \" << myStack . top () << endl ; return 0 ; } Maximum number of elements #include <iostream> #include <stack> using namespace std ; int main () { stack < int > s ; for ( unsigned int i = 0 ; i < 1000000 ; i ++ ) { for ( unsigned int j = 0 ; j < 100 ; j ++ ) { s . push ( i ); } } cout << \"Size of stack: \" << s . size () << endl ; } Size of stack: 100000000 100,000,000 could be added without any problems. See also C++ Reference: general information and example General information about the datastructure stack","tags":"Code","title":"Stacks in C++"},{"url":"https://martin-thoma.com/c-puzzle-1/","text":"What is the output of the following programm? #include <stdio.h> int * f () { int i = 5 ; return & i ; } void g () { int j = 42 ; j ++ ; } int main () { int * x = f (); g (); printf ( \"x = %d \\n \" , * x ); g (); printf ( \"x = %d \\n \" , * x ); return 0 ; } Short Answer It depends on your compiler flags! If you compile it with no optimization, you might get 43: $ gcc -O0 cpuzzle-1.c ; ./a.out aufgabe-3.c: In function & lsquo ; f & rsquo ; : aufgabe-3.c:5: warning: function returns address of local variable x = 43 x = 43 If you compile it with 03 Optimization, you might get 5. $ gcc -O3 cpuzzle-1.c ; ./a.out aufgabe-3.c: In function & lsquo ; f & rsquo ; : aufgabe-3.c:5: warning: function returns address of local variable x = 5 x = 5 Long answer The general answer Lets analyse this code line by line. Line 3 - 7 is a function f that returns a pointer to an integer. The pointer points to a local variable. As far as I know it is not defined what value should be there after you leave the function (has anybody a source for that?). The variable is a so called local or automatic variable and is located on the stack frame. Line 9 - 14 is a function g that doesn't take any parameter and doesn't return anything. This function should not have any influence on the behavior of the program. It puts 42 on the stack and increases it by one. Line 17 calls f and stores the returned function pointer in the variable x. Line 18 calls g. Remember that g should not have any influence on the other program. But you saved a pointer to a local variable which is not in the scope of the main function. So g is allowed to use the space which was previously used by the local variable i in the function f. It uses this space for j = 42 and increases it by 1. So if you access the address of the former variable i in f you will get 43. Actual assembly code You still want to get more into detail? Ok ... First you should get your assembly code. If you're running a Linux machine, you can type this into the console: gcc -S -O0 cpuzzle-1.c ; gcc cpuzzle-1.c -o cpuzzle ; mv cpuzzle-1.s cpuzzle-1-O0.s This will create a file called \"cpuzzle-1.s\" which contains the assembly code for the non-optimized version. Rename it into \"cpuzzle-1-O0.c\". Then the same for O3: gcc -S -O3 cpuzzle-1.c ; gcc cpuzzle-1.c -o cpuzzle ; mv cpuzzle-1.s cpuzzle-1-O3.s Now you can compare those two with meld or any other diff Tool: C Puzzle #1 - Assembly code part 1 The O3 code got an additional .p2align 4,,15 .p2align 4,,15 means: When allocating memory, align it such that each new section must start at a location with 4 0's at the end (i.e. a multiple of 16 bytes), except for if more than 15 bytes must be skipped. Quoted from MooseBoy It makes sense to store the data this way, as your computer can only access blocks. If one piece of data is half in one block, half in the other, you have to make to (slow) memory-accesses. C Puzzle #1 - Assembly code part 2 (the main) It is quite difficult to talk about it, so I made some annotations to this code. I have to admit that I don't know why the compiler does most of the optimizations â˜¹ C Puzzle #1, Assembly code part 1: Annotated C Puzzle #1, Assembly code part 2: Annotated You might also be interested in __printf_chk . An implementation is here . What you should have learned Never return pointers to local variables / variables in the wrong scope. See also Wikipedia: Stack frame Call Stack Scope Get your programs assembly code and more information Der \"Stack Frame\" (German article about the stack frame)","tags":"Code","title":"C Puzzle #1"},{"url":"https://martin-thoma.com/how-do-bitmasks-work/","text":"What are Bitmasks? In computer science, a mask is data that is used for bitwise operations. Essentially it is a variable. They are very often used in C programs. Bit operators These are the bit operators: ~ Bitwise NOT (not to be confused with Logical NOT â€˜!') & Bitwise AND (not to be confused with Logical AND â€˜&&') | Bitwise OR (again, not to be confused with Logical OR â€˜||') &#94; Bitwise XOR << Bitwise left shift >> Bitwise right shift This is how the operators work: Bit A Bit B A & B A | B A &#94; B ~A A << B A >> B 0 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 0 2 0 Some examples Lets say I have any variable named \"variable\" with 32 bit. Get the last bit: return variable & amp ; 1 ; Get the first bit: return variable >> 31 ; Get the bits 4 - 14 (11 bits): return ( variable >> 4 ) & amp ; (( 1 << 11 ) - 1 ); Getting the pow(2,11): return 1 << 11 ; See also What does a type followed by _t (underscore-t) represent? . Jonathan Leffler, Stackoverflow. Why does mode_t use 4 byte? . Niklas B., Stackoverflow.","tags":"Code","title":"How do Bitmasks work?"},{"url":"https://martin-thoma.com/how-to-visualize-graph-algorithms-with-latex/","text":"Tkiz is a very powerful TeX package. You can easily create visualizations of graphs and graph algorithms (if you have a template ;-) ). This post should give you a template to visualize graph algorithms with LaTeX. I recently found a great animation of Prim's algorithm done by Kjell Magne Fauske . I've edited his source files to show an eulerian path. This is how it looks like: LaTeX (Tikz) animation of an eulerian path This animation was automatically created. See Archive and the intermediate PDF . The ideas Draw the Graph If you want to visualize a graph algorithm, you should first try to get the image of the graph with Tikz. First include all packages / create the general structure of the document: \\documentclass [hyperref={pdfpagelabels=false}] { beamer } \\usepackage { lmodern } \\usepackage [utf8] { inputenc } % this is needed for german umlauts \\usepackage [ngerman] { babel } % this is needed for german umlauts \\usepackage [T1] { fontenc } % this is needed for correct output of umlauts in pdf \\usepackage { verbatim } \\usepackage { tikz } \\usetikzlibrary { arrows,shapes } % see http://deic.uab.es/~iblanes/beamer_gallery/index_by_theme.html \\usetheme { Frankfurt } \\usefonttheme { professionalfonts } \\begin { document } \\begin { frame } Your content will be here. \\end { frame } \\end { document } Simple graphs could look like this: \\begin { figure } \\begin { tikzpicture } [->,scale=1.8, auto,swap] % Draw the vertices. \\node (a) at (0,0) { $ a ( this is text ) $ } ; \\node (b) at (0,1) { $ b $ } ; \\node (c) at (1,1) { $ c $ } ; \\node (d) at (1,0) { $ d $ } ; \\node (e) at (3,1) { $ d $ } ; % Connect vertices with edges and draw weights \\path (a) edge node {} (b); \\path (b) edge node {} (c); \\path (c) edge node {} (d); \\path (d) edge node {} (a); \\end { tikzpicture } \\end { figure } You should get something similar to this: Simple example graph created with LaTeX and Tikz Animate Animations can be created with Tikz by working with layers. You don't want to redraw the whole graph every time. Most of the time you want to overlay/underlay some parts of the graph. This can be achieved by declaring a new layer: \\pgfdeclarelayer { NAME } Then you need to tell PGF which layers are to use in the next figure: \\pgfsetlayers { LAYER LIST } The layer main should always be part of the list. Here is an example: \\pgfdeclarelayer { background } \\pgfdeclarelayer { foreground } \\pgfsetlayers { background,main,foreground } Now the magic begins. You consecutively add frames to the layer: \\begin { pgfonlayer }{ background } \\path <2->[draw,line width=5pt,-,red!50] (a.center) edge node {} (b.center); \\path <10->[draw,line width=5pt,-,red!50] (b.center) edge node {} (d.center); \\path <12->[draw,line width=5pt,-,red!50] (d.center) edge node {} (e.center); \\end { pgfonlayer } The number (2, 10 and 12 in this example) indicate the frame in which it should be added. This is the absolute frame, but 1 is the first frame of the figure environment! Status quo \\documentclass [hyperref={pdfpagelabels=false}] { beamer } \\usepackage { lmodern } \\usepackage [utf8] { inputenc } % this is needed for german umlauts \\usepackage [ngerman] { babel } % this is needed for german umlauts \\usepackage [T1] { fontenc } % this is needed for correct output of umlauts in pdf \\usepackage { verbatim } \\usepackage { tikz } \\usetikzlibrary { arrows,shapes } % see http://deic.uab.es/~iblanes/beamer_gallery/index_by_theme.html \\usetheme { Frankfurt } \\usefonttheme { professionalfonts } \\begin { document } \\pgfdeclarelayer { background } \\pgfdeclarelayer { foreground } \\pgfsetlayers { background,main,foreground } \\begin { frame } \\begin { figure } \\begin { tikzpicture } [->,scale=1.8, auto,swap] % Draw the vertices. \\node (a) at (0,0) { $ a ( this is text ) $ } ; \\node (b) at (0,1) { $ b $ } ; \\node (c) at (1,1) { $ c $ } ; \\node (d) at (1,0) { $ d $ } ; \\node (e) at (3,1) { $ d $ } ; % Connect vertices with edges and draw weights \\path (a) edge node {} (b); \\path (b) edge node {} (c); \\path (c) edge node {} (d); \\path (d) edge node {} (a); \\begin { pgfonlayer }{ background } \\path <2->[draw,line width=5pt,-,red!50] (a.center) edge node {} (b.center); \\path <10->[draw,line width=5pt,-,red!50] (b.center) edge node {} (d.center); \\path <12->[draw,line width=5pt,-,red!50] (d.center) edge node {} (e.center); \\end { pgfonlayer } \\end { tikzpicture } \\end { figure } \\end { frame } \\end { document } Simplify it You can make some definitions, e.g.: draw,line width=5pt,-,red!50 can be replaced by \\tikzstyle { selected edge } = [draw,line width=5pt,-,red!50] You can make loops: % Draw the vertices. \\foreach \\pos / \\identifier / \\name in {{ (0,0)/a/a (this is text) } , { (0,1)/b/b } , { (1,1)/c/c } , { (1,0)/d/d } , { (3,1)/e/d }} \\node ( \\identifier ) at \\pos { $ \\name $ } ; The whole, working template \\documentclass [hyperref={pdfpagelabels=false}] { beamer } \\usepackage { lmodern } \\usepackage [utf8] { inputenc } % this is needed for german umlauts \\usepackage [ngerman] { babel } % this is needed for german umlauts \\usepackage [T1] { fontenc } % this is needed for correct output of umlauts in pdf \\usepackage { verbatim } \\usepackage { tikz } \\usetikzlibrary { arrows,shapes } % Define some styles for graphs \\tikzstyle { vertex } =[circle,fill=black!25,minimum size=20pt,inner sep=0pt] \\tikzstyle { selected vertex } = [vertex, fill=red!24] \\tikzstyle { blue vertex } = [vertex, fill=blue!24] \\tikzstyle { edge } = [draw,thick,-] \\tikzstyle { weight } = [font= \\small ] \\tikzstyle { selected edge } = [draw,line width=5pt,-,red!50] \\tikzstyle { ignored edge } = [draw,line width=5pt,-,black!20] % see http://deic.uab.es/~iblanes/beamer_gallery/index_by_theme.html \\usetheme { Frankfurt } \\usefonttheme { professionalfonts } % disables bottom navigation bar \\beamertemplatenavigationsymbolsempty % http://tex.stackexchange.com/questions/23727/converting-beamer-slides-to-animated-images \\setbeamertemplate { navigation symbols }{} % \\begin { document } \\pgfdeclarelayer { background } \\pgfsetlayers { background,main } \\begin { frame } \\begin { figure } \\begin { tikzpicture } [->,scale=1.8, auto,swap] % Draw the vertices. First you define a list. \\foreach \\pos / \\name in {{ (0,0)/a } , { (0,2)/b } , { (1,2)/c } , { (1,0)/d } , { (2,1)/e } , { (3,1)/f } , { (4,2)/g } , { (5,2)/h } , { (4,0)/i } , { (5,0)/j }} \\node [vertex] ( \\name ) at \\pos { $ \\name $ } ; % Connect vertices with edges and draw weights \\foreach \\source / \\dest / \\pos in { a/b/, b/c/, c/d/, d/a/, c/e/bend left, d/e/, e/c/, e/f/, f/g/, f/i/, g/f/bend right, i/f/bend left, g/h/, h/j/, j/i/, i/g/ } \\path ( \\source ) edge [ \\pos ] node {} ( \\dest ); % Start animating the edge selection. % For convenience we use a background layer to % highlight edges. This way we don't have to worry about % the highlighting covering weight labels. \\begin { pgfonlayer }{ background } \\foreach \\source / \\dest / \\fr / \\pos in { d/a/1/, a/b/2/, b/c/3/, c/d/4/, d/e/5/, e/c/6/, c/e/7/bend left, e/f/8/, f/g/9/, g/f/10/bend right, f/i/11/, i/g/12/, g/h/13/, h/j/14/, j/i/15/, i/f/16/bend left } \\path < \\fr ->[selected edge] ( \\source .center) edge [ \\pos ] node {} ( \\dest .center); \\end { pgfonlayer } \\end { tikzpicture } \\end { figure } Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et. \\end { frame } \\end { document } Resources TikZ and pgf: Manual for version 1.18 TeXamples.net : Great page with many Tikz-Examples The beamer class","tags":"Code","title":"How to visualize Graph algorithms with LaTeX"},{"url":"https://martin-thoma.com/how-to-create-uml-class-diagrams/","text":"Dia Creating UML diagrams with Dia works like a charm! It provides some default tools. You should simply try it. Dia is a free tool. Take a look at these screenshots: Create a class for a class diagram in Dia Edit class properties in Dia Customizing associations in Dia - adding multiplicities is so much easier in Dia than in MetaUML! A quick example for a class diagram created with Dia LaTeX I only know MetaUML for creating class diagrams entirely in LaTeX. Does anybody know something different? Of course, you can include a diagram created with Dia: Export the diagram as PNG (antialized) Add something like that to your tex-file: \\includegraphics[width=180mm]{myDiagramm.png} MetaUML A MetaUML class diagram looks like that in code (saved as myMetaDiagram.mp): input metauml; beginfig(1); Class.World(\"World\") (\"-age: int\", \"#ressources: List\") (\"+sayHello(): void\"); Class.NoHuman(\"Human\") (\"-birthday: Date\", \"-nickname: String\", \"-secret: String\") (\"+code(language: Language): Program\"); leftToRight(50)(World, NoHuman); drawObjects(World, NoHuman); link(aggregation)(NoHuman.w -- World.e); item(iAssoc)(\"1\")(obj.n = .2[World.e,NoHuman.w]); item(iAssoc)(\"has >\")(obj.n = .5[World.e,NoHuman.w]); item(iAssoc)(\"0..*\")(obj.n = .8[World.e,NoHuman.w]); endfig; end You have to execute mpost before you can compile LaTeX. A working example is in this UML Archive . It looks like that in your generated PDF file: MetaUML class diagram See also Wikipedia: Class diagram , Dia Dia: Dia und UML MetaUML: Tutorial, Reference and Test Suite Freies Magazin, Mai 2012: Astah â€“ Kurzvorstellung des UML-Programms (German)","tags":"My bits and bytes","title":"How to create UML class diagrams"},{"url":"https://martin-thoma.com/google-code-jam-2012-round-1c-2012/","text":"4230 tried the first problem, but only 3189 people are listed in the scoreboard . Problem 1 ( Diamond Inheritance ): Small Set: 3077/4230 users (73%) Large Set: 2387/3044 users (78%) Problem 2 ( Out of Gas ): Small Set: 471/766 users (61%) Large Set: 73/253 users (29%) Problem 3 ( Box Factory ): Small Set: 1071/1810 users (59%) Large Set: 308/788 users (39%) Diamond Inheritance #!/usr/bin/python # -*- coding: utf-8 -*- import psyco psyco . full () testcases = input () def line2intlist ( line ): list = line . split ( ' ' ) numbers = [ int ( x ) for x in list ] return numbers def getAnswer ( classDict , N ): for startPoint in xrange ( 1 , N ): reachable = [ startPoint ] justAppended = [ startPoint ] while len ( justAppended ) > 0 : newJustAppended = [] for node in justAppended : for new in classDict [ node ]: if new in reachable : return \"Yes\" else : newJustAppended . append ( new ) reachable . append ( new ) justAppended = newJustAppended return \"No\" for i in xrange ( 0 , testcases ): N = input () classDict = {} for classNr in xrange ( 1 , N + 1 ): liste = line2intlist ( raw_input ()) classDict [ classNr ] = liste [ 1 :] print ( \"Case # %i : %s \" % ( i + 1 , getAnswer ( classDict , N ))) See also Wikipedia: Google Code Jam Google Code Jam Statistics","tags":"Code","title":"Google Code Jam 2012 â€“ Round 1C 2012"},{"url":"https://martin-thoma.com/google-code-jam-2012-round-1b-2012/","text":"5614 tried the first problem, but only 3281 people are listed in the scoreboard. So quite a lot tried to solve a problem, but couldn't even solve one. I think these problems were much harder than the ones from Round 1A 2012 . Problem 1 ( Safety in Numbers ): Small Set: 2695/5614 users (48%) Large Set: 2016/2686 users (75%) Problem 2 ( Tide Goes In, Tide Goes Out ): Small Set: 684/894 users (77%) Large Set: 620/671 users (92%) Problem 3 ( Equal Sums ): Small Set: 2261/2534 users (89%) Large Set: 149/854 users (17%) Safety in Numbers I tried this approach: X is the sum of all points given by judges. The visitors have an equal amount of points to give. \\(P_i\\) is the number of total points of contestant i. \\(J_i\\) is the number of points of contestant i by the judges. \\(V_i\\) is the percentage of the visitors points contestant i gets. So: \\(P_i = J_i + V_i * X\\) You don't know \\(V_i\\) and \\(P_i\\) . You have to get the minimal value of \\(V_i\\) to guarantee that contestant \\(i\\) will not to be eliminated. So you have to create some kind of \"worst case\" for contestant i, if he gets \\(V_i \\cdot X\\) visitor-points. The worst case is that the minimum of all remaining visitors is as high as possible. So if you think of them as players, they will always try to get a equal number of points. If they can get an equal number of points, you can make these (in)equations: \\(average = (X - p_i)/(N-1)\\) \\(p_i + V_i \\cdot X \\geq avg + \\frac{1-V_i}{N-1} \\cdot X\\) \\(V_i \\cdot X - \\frac{1-V_i}{N-1} \\cdot X \\geq avg - p_i\\) \\(V_i X (N-1) - (1-V_i) \\cdot X \\geq (N-1) \\cdot (avg - p_i)\\) \\(V_i X (N-1) - X +V_i \\cdot X \\geq (N-1) \\cdot (avg - p_i)\\) \\(V_i X (N-1) +V_i \\cdot X \\geq (N-1) \\cdot (avg - p_i) + X\\) \\(V_i \\geq (N-1) \\cdot ((avg - p_i) + X)/(X (N-1) +X)\\) \\(V_i \\geq (N-1) \\cdot ((avg - p_i) + X)/(X ((N-1) +1))\\) \\(V_i \\geq \\frac{N-1}{X \\cdot N} \\cdot (avg - p_i + X)\\) Unfortunately, its possible that the other players can't get an equal number of points. So this approach is useless in this case. Here is an approach with an approximation, which also works for the large input set. #include <iostream> #include <cstdio> using namespace std ; int main () { int testcases , N , sum ; int s [ 1011 ]; cin >> testcases ; for ( int caseNr = 1 ; caseNr <= testcases ; caseNr ++ ) { cin >> N ; /** the sum of all points of all contestants*/ sum = 0 ; for ( int i = 0 ; i < N ; i ++ ) { cin >> s [ i ]; sum += s [ i ]; } printf ( \"Case #%d:\" , caseNr ); for ( int contestant = 0 ; contestant < N ; contestant ++ ) { // approximate the minimum for each contestant double low = 0 , high = 1 ; // increase the accuracy 100 times for ( int j = 0 ; j < 100 ; j ++ ) { double mid = ( low + high ) / 2 ; double me = s [ contestant ] + mid * sum ; double remaining = 1 - mid ; for ( int k = 0 ; k < N & amp ; & amp ; remaining > 0 ; k ++ ) { if ( k != contestant & amp ; & amp ; s [ k ] < me ) { // the contestant k needs at least // this part of all audience votes remaining -= ( me - s [ k ]) / sum ; } } if ( remaining > 0 ) { low = mid ; } else { high = mid ; } } printf ( \" %.6lf\" , low * 100 ); } printf ( \" \\n \" ); } } Tide Goes In, Tide Goes Out This one could be solved with Graphs. You calculate one Graph, where every node is one cell. Every cell / node is connected to adjacent cells. Every cell has a value which is the time when you can enter them. After you've created the graph, you can make something like that: graph = createGraph ( floorHeight , ceilingHeight ) endReached = False nodesReached = [] while ( not endReached ): tmp = getMinimumAdjacentNode ( graph , nodesReached ) nodesReached . append ( tmp ) return maxTime ( nodesReached ) Equal Sums A trivial solution for the small one is to try every combination. You might want to take a look at Pythonss itertools.combinations() . See also Wikipedia: Google Code Jam Google Code Jam Statistics","tags":"Code","title":"Google Code Jam 2012 â€“ Round 1B 2012"},{"url":"https://martin-thoma.com/how-to-print-source-code-with-latex/","text":"I often need to print source code. Some years ago for a German competition called \"Bundeswettbewerb Informatik\", now for projects at my university. If you use LaTeX, you can simply include the source code into your document! Here are three examples with listings and minted. I've also included example PDF files. listings Minimal example LaTeX Java Source Code: listings Here is an minimal example how you could print Source Code with LaTeX: \\documentclass [a4paper,12pt] { article } \\usepackage { amssymb } % needed for math \\usepackage { amsmath } % needed for math \\usepackage [utf8] { inputenc } % this is needed for german umlauts \\usepackage [ngerman] { babel } % this is needed for german umlauts % this is needed for correct output of umlauts in pdf \\usepackage [T1] { fontenc } \\usepackage [margin=2.5cm] { geometry } %layout \\usepackage { listings } % needed for the inclusion of source code % this is needed for forms and links within the text \\usepackage { hyperref } %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % THE DOCUMENT BEGINS % %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\begin { document } \\lstinputlisting [language=Java] { Othello.java } \\end { document } My Template If you want to customize a little bit more and if you want to get highlighted (colorized) source code, you could use the following template. It looks like this as a PDF-file . \\documentclass [a4paper,12pt] { article } \\usepackage { amssymb } % needed for math \\usepackage { amsmath } % needed for math \\usepackage [utf8] { inputenc } % this is needed for german umlauts \\usepackage [ngerman] { babel } % this is needed for german umlauts \\usepackage [T1] { fontenc } % this is needed for correct output of umlauts in pdf \\usepackage [margin=2.5cm] { geometry } %layout \\usepackage { listings } % needed for the inclusion of source code % the following is needed for syntax highlighting \\usepackage { color } \\definecolor { dkgreen }{ rgb }{ 0,0.6,0 } \\definecolor { gray }{ rgb }{ 0.5,0.5,0.5 } \\definecolor { mauve }{ rgb }{ 0.58,0,0.82 } \\lstset { % language=Java, % the language of the code basicstyle= \\footnotesize , % the size of the fonts that are used for the code numbers=left, % where to put the line-numbers numberstyle= \\tiny\\color { gray } , % the style that is used for the line-numbers stepnumber=1, % the step between two line-numbers. If it's 1, each line % will be numbered numbersep=5pt, % how far the line-numbers are from the code backgroundcolor= \\color { white } , % choose the background color. You must add \\usepackage{color} showspaces=false, % show spaces adding particular underscores showstringspaces=false, % underline spaces within strings showtabs=false, % show tabs within strings adding particular underscores frame=single, % adds a frame around the code rulecolor= \\color { black } , % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here)) tabsize=4, % sets default tabsize to 2 spaces captionpos=b, % sets the caption-position to bottom breaklines=true, % sets automatic line breaking breakatwhitespace=false, % sets if automatic breaks should only happen at whitespace title= \\lstname , % show the filename of files included with \\lstinputlisting; % also try caption instead of title keywordstyle= \\color { blue } , % keyword style commentstyle= \\color { dkgreen } , % comment style stringstyle= \\color { mauve } , % string literal style escapeinside= { \\%* }{ *) } , % if you want to add a comment within your code morekeywords= { *,... } % if you want to add more keywords to the set } % this is needed for forms and links within the text \\usepackage { hyperref } %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Variablen % %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\newcommand { \\authorName }{ Martin Thoma } \\newcommand { \\tags }{ \\authorName , my, tags } \\title { This is the title } \\author { \\authorName } \\date { \\today } %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % PDF Meta information % %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\hypersetup { pdfauthor = { \\authorName } , pdfkeywords = { \\tags } , pdftitle = { This is the title } } %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % THE DOCUMENT BEGINS % %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\begin { document } \\lstinputlisting [language=Java] { Othello.java } \\end { document } Supported Languages The LaTeX listings package provides quite a lot of language and dialects. Each bold dialect is the default dialect: First the interesting ones: Assembler (Motorola68k, x86masm) bash C ( ANSI , Handel, Objective, Sharp) C++ (ANSI, GNU, ISO , Visual) Java (empty, AspectJ) Python SQL TeX (AlLaTeX, common, LaTeX, plain , primitive) XML And the rest: ABAP (R/2 4.3, R/2 5.0, R/3 3.1, R/3 4.6C, R/3 6.10 ), ACSL, Ada ( 2005 , 83, 95), Algol (60, 68 ), Ant, Awk ( gnu , POSIX), Basic (Visual), Caml ( light , Objective), CIL, Clean, Cobol (1974, 1985 , ibm), Comal 80, command.com (WinXP), Comsol, csh, Delphi, Eiffel, Elan, erlang, Euphoria, Fortran (77, 90, 95 ), GCL, Gnuplot, Haskell, HTML, IDL (empty, CORBA), inform, JVMIS, ksh, Lingo, Lisp (empty, Auto), Logo, make (empty, gnu), Mathematica (1.0, 3.0, 5.2 ), Matlab, Mercury, MetaPost, Miranda, Mizar, ML, Modula-2, MuPAD, NASTRAN, Oberon-2, OCL (decorative, OMG), Octave, Oz, Pascal (Borland6, Standard, XSC), Perl, PHP, PL/I, Plasm, PostScript, POV, Prolog, Promela, PSTricks, R, Reduce, Rexx, RSL, Ruby, S (empty, PLUS), SAS, Scilab, sh, SHELXL, Simula ( 67 , CII, DEC, IBM), SPARQL, tcl (empty, tk), VBScript, Verilog, VHDL (empty, AMS), VRML (97), XSLT minted Minted needs the package pygments: sudo apt-get install python-pygments Supported Languages Minted supports quite a lot of languages. You can get the supported languages with this command: moose@pc07:~$ pygmentize -L lexers This is my output: Pygments version 1.2.2, (c) 2006-2008 by Georg Brandl. Lexers: ~~~~~~~ * Cucumber, cucumber, Gherkin, gherkin: Gherkin (filenames *.feature) * abap: ABAP (filenames *.abap) * antlr: ANTLR [a lot more gets supported, I've shortened it] * apacheconf, aconf, apache: ApacheConf (filenames .htaccess, apache.conf, apache2.conf) * applescript: AppleScript (filenames *.applescript) * as, actionscript: ActionScript (filenames *.as) * as3, actionscript3: ActionScript 3 (filenames *.as) * aspx-cs: aspx-cs (filenames *.aspx, *.asax, *.ascx, *.ashx, *.asmx, *.axd) * aspx-vb: aspx-vb (filenames *.aspx, *.asax, *.ascx, *.ashx, *.asmx, *.axd) * asy: Asymptote (filenames *.asy) * basemake: Makefile * bash, sh: Bash (filenames *.sh, *.ebuild, *.eclass) * bat: Batchfile (filenames *.bat, *.cmd) * bbcode: BBCode * befunge: Befunge (filenames *.befunge) * boo: Boo (filenames *.boo) * brainfuck, bf: Brainfuck (filenames *.bf, *.b) * c-objdump: c-objdump (filenames *.c-objdump) * c: C (filenames *.c, *.h) * cheetah, spitfire: Cheetah (filenames *.tmpl, *.spt) * clojure, clj: Clojure (filenames *.clj) * cmake: CMake (filenames *.cmake) * common-lisp, cl: Common Lisp (filenames *.cl, *.lisp, *.el) * console: Bash Session (filenames *.sh-session) * control: Debian Control file (filenames control) * cpp, c++: C++ (filenames *.cpp, *.hpp, *.c++, *.h++, *.cc, *.hh, *.cxx, *.hxx) * cpp-objdump, c++-objdumb, cxx-objdump: cpp-objdump (filenames *.cpp-objdump, *.c++-objdump, *.cxx-objdump) * csharp, c#: C# (filenames *.cs) * css: CSS (filenames *.css) [a lot more gets supported, I've shortened it] * cython, pyx: Cython (filenames *.pyx, *.pxd, *.pxi) * d-objdump: d-objdump (filenames *.d-objdump) * d: D (filenames *.d, *.di) * delphi, pas, pascal, objectpascal: Delphi (filenames *.pas) * diff, udiff: Diff (filenames *.diff, *.patch) * django, jinja: Django/Jinja * dpatch: Darcs Patch (filenames *.dpatch, *.darcspatch) * dylan: Dylan (filenames *.dylan) * erb: ERB * erl: Erlang erl session (filenames *.erl-sh) * erlang: Erlang (filenames *.erl, *.hrl) * evoque: Evoque (filenames *.evoque) * fortran: Fortran (filenames *.f, *.f90) * gas: GAS (filenames *.s, *.S) * genshi, kid, xml+genshi, xml+kid: Genshi (filenames *.kid) * genshitext: Genshi Text * glsl: GLSL (filenames *.vert, *.frag, *.geo) * gnuplot: Gnuplot (filenames *.plot, *.plt) * go: Go (filenames *.go) * groff, nroff, man: Groff (filenames *.[1234567], *.man) * haskell, hs: Haskell (filenames *.hs) * html: HTML (filenames *.html, *.htm, *.xhtml, *.xslt) [a lot more gets supported, I've shortened it] * ini, cfg: INI (filenames *.ini, *.cfg, *.properties) * io: Io (filenames *.io) * irc: IRC logs (filenames *.weechatlog) * java: Java (filenames *.java) * js, javascript: JavaScript (filenames *.js) [a lot more gets supported, I've shortened it] * jsp: Java Server Page (filenames *.jsp) * lhs, literate-haskell: Literate Haskell (filenames *.lhs) * lighty, lighttpd: Lighttpd configuration file * llvm: LLVM (filenames *.ll) * logtalk: Logtalk (filenames *.lgt) * lua: Lua (filenames *.lua) * make, makefile, mf, bsdmake: Makefile (filenames *.mak, Makefile, makefile, Makefile.*, GNUmakefile) * mako: Mako (filenames *.mao) * mako: Mako (filenames *.mao) * matlab, octave: Matlab (filenames *.m) * matlabsession: Matlab session * minid: MiniD (filenames *.md) * modelica: Modelica (filenames *.mo) * moocode: MOOCode (filenames *.moo) * mupad: MuPAD (filenames *.mu) * mxml: MXML (filenames *.mxml) * myghty: Myghty (filenames *.myt, autodelegate) * mysql: MySQL * nasm: NASM (filenames *.asm, *.ASM) * newspeak: Newspeak (filenames *.ns2) * nginx: Nginx configuration file * numpy: NumPy * objdump: objdump (filenames *.objdump) * objective-c, objectivec, obj-c, objc: Objective-C (filenames *.m) * ocaml: OCaml (filenames *.ml, *.mli, *.mll, *.mly) * ooc: Ooc (filenames *.ooc) * perl, pl: Perl (filenames *.pl, *.pm) * php, php3, php4, php5: PHP (filenames *.php, *.php[345]) * pot, po: Gettext Catalog (filenames *.pot, *.po) * pov: POVRay (filenames *.pov, *.inc) * prolog: Prolog (filenames *.prolog, *.pro, *.pl) * py3tb: Python 3.0 Traceback (filenames *.py3tb) * pycon: Python console session * pytb: Python Traceback (filenames *.pytb) * python, py: Python (filenames *.py, *.pyw, *.sc, SConstruct, SConscript) * python3, py3: Python 3 * ragel: Ragel [a lot more gets supported, I've shortened it] * raw: Raw token data * rb, ruby: Ruby (filenames *.rb, *.rbw, Rakefile, *.rake, *.gemspec, *.rbx) * rbcon, irb: Ruby irb session * rebol: REBOL (filenames *.r, *.r3) * redcode: Redcode (filenames *.cw) * rhtml, html+erb, html+ruby: RHTML (filenames *.rhtml) * rst, rest, restructuredtext: reStructuredText (filenames *.rst, *.rest) * scala: Scala (filenames *.scala) * scheme, scm: Scheme (filenames *.scm) * smalltalk, squeak: Smalltalk (filenames *.st) * smarty: Smarty (filenames *.tpl) * sourceslist, sources.list: Debian Sourcelist (filenames sources.list) * splus, s, r: S (filenames *.S, *.R) * sql: SQL (filenames *.sql) * sqlite3: sqlite3con (filenames *.sqlite3-console) * squidconf, squid.conf, squid: SquidConf (filenames squid.conf) * tcl: Tcl (filenames *.tcl) * tcsh, csh: Tcsh (filenames *.tcsh, *.csh) * tex, latex: TeX (filenames *.tex, *.aux, *.toc) * text: Text only (filenames *.txt) * trac-wiki, moin: MoinMoin/Trac Wiki markup * vala, vapi: Vala (filenames *.vala, *.vapi) * vb.net, vbnet: VB.net (filenames *.vb, *.bas) * vim: VimL (filenames *.vim, .vimrc) [...] (a lot of XML) [...] * xml: XML (filenames *.xml, *.xsl, *.rss, *.xslt, *.xsd, *.wsdl) * xslt: XSLT (filenames *.xsl, *.xslt) * yaml: YAML (filenames *.yaml, *.yml) Example LaTeX Java Source Code: minted This is the PDF-file produced by the following LaTeX-Code: \\documentclass [a4paper,12pt] { article } \\usepackage { amssymb } % needed for math \\usepackage { amsmath } % needed for math \\usepackage [utf8] { inputenc } % this is needed for german umlauts \\usepackage [ngerman] { babel } % this is needed for german umlauts \\usepackage [T1] { fontenc } % this is needed for correct output of umlauts in pdf \\usepackage [margin=2cm] { geometry } %layout \\usepackage { minted } % needed for the inclusion of source code \\begin { document } \\renewcommand { \\theFancyVerbLine }{ \\sffamily\\textcolor [rgb] { 0.5,0.5,0.5 }{ \\scriptsize\\arabic { FancyVerbLine }}} \\inputminted [linenos, numbersep=5pt, tabsize=4, frame=lines, label=Othello.java] { java }{ Othello.java } \\end { document } Material All files can be found in LaTeX-Source-Code Archive . See also WikiBook: LaTeX/Packages/Listings CTAN lisings documentation CTAN minted documentation You might also want to try texdoc listings This command will show a manual as a PDF.","tags":"Code","title":"How to print Source Code with LaTeX"},{"url":"https://martin-thoma.com/google-code-jam-2012-round-1a-2012/","text":"3691 people are listed in the scoreboard, but 3851 tried the first problem. So I guess the number of contestants might even be higher. Problem 1 ( Password Problem ): Small Set: 3511/3851 users (91%) Large Set: 2329/3376 users (69%) Problem 2 ( Kingdom Rush ): Small Set: 1912/3466 users (55%) Large Set: 1617/1848 users (88%) Problem 3 ( Cruise Control ): Small Set: 65/312 users (21%) Large Set: 22/42 users (52%) Just as last time, you can execute these scripts by python jam.py < A-small-practice.in > results.txt Passwords This works only for the small input set: #!/usr/bin/python # -*- coding: utf-8 -*- def line2floatlist ( line ): \"\"\" Convert integers in one line, separated by space to a list of integers. \"\"\" list = line . split ( ' ' ) numbers = [ float ( x ) for x in list ] return numbers def prob ( A , B , probabilities ): typesMin = float ( 'inf' ) for i in xrange ( 0 , A + 1 ): probKorrect = 1.0 for el in probabilities [ 0 :( len ( probabilities ) - i )]: probKorrect *= el probWrong = 1.0 - probKorrect remainingTypes = i + ( B - A + i ) + 1 remainingTypesErr = remainingTypes + B + 1 types = probKorrect * remainingTypes \\ + probWrong * remainingTypesErr #print types if types < typesMin : typesMin = types if ( 1 + B + 1 ) < typesMin : typesMin = ( 1 + B + 1 ) return round ( typesMin , 6 ) #return typesMin if __name__ == \"__main__\" : testcases = input () for caseNr in xrange ( 0 , testcases ): A , B = raw_input () . split ( \" \" ) A = int ( A ) B = int ( B ) probabilities = line2floatlist ( raw_input ()) #print ((A+1), B) #print probabilities print ( \"Case # %i : %.6lf \" % ( caseNr + 1 , prob ( A , B , probabilities ))) Kingdom Rush My solution works only for the small input set: #!/usr/bin/python # -*- coding: utf-8 -*- from copy import deepcopy def line2intlist ( line ): \"\"\" Convert integers in one line, separated by space to a list of integers. \"\"\" list = line . split ( ' ' ) numbers = [ int ( x ) for x in list ] return numbers def isSolvable ( starDict ): \"\"\" Is it possible to solve this one? \"\"\" intList = [] for index in starDict : wasInFor = True one , two = starDict [ index ] intList . append ( one ) intList . append ( two ) intList . sort () for levelVar in xrange ( 0 , len ( intList )): if levelVar < intList [ levelVar ]: return False return True def king ( starDict , myLevel = 0 , myCompetes = 0 , partially = []): somethingChanged = True while somethingChanged : removeList = [] somethingChanged = False #all where i can do both for index in starDict : one , two = starDict [ index ] if two <= myLevel : removeList . append ( index ) somethingChanged = True #remove them for index in removeList : myCompetes += 1 del starDict [ index ] if index in partially : myLevel += 1 partially . remove ( index ) else : myLevel += 2 if starDict : minCompetes = float ( 'inf' ) for index in starDict : one , two = starDict [ index ] if one <= myLevel and ( index not in partially ): starDictTmp = deepcopy ( starDict ) partiallyTmp = deepcopy ( partially ) partiallyTmp . append ( index ) tmpCompetes = king ( starDictTmp , myLevel + 1 , myCompetes + 1 , partiallyTmp ) if tmpCompetes < minCompetes : minCompetes = tmpCompetes myCompetes = minCompetes return myCompetes if __name__ == \"__main__\" : testcases = input () for caseNr in xrange ( 0 , testcases ): levels = input () stars = [] for i in xrange ( 0 , levels ): stars . append ( line2intlist ( raw_input ())) #make stars dictionary starDict = {} level = 1 for el in stars : starDict [ level ] = deepcopy ( el ) level += 1 if not isSolvable ( starDict ): print ( \"Case # %i : Too Bad\" % ( caseNr + 1 )) else : print ( \"Case # %i : %s \" % ( caseNr + 1 , king ( starDict ))) Cruise Controll Only 22 people have a perfect solution for this one. This is the solution of royf: import itertools import math import numpy def read_word ( f ): return next ( f ) . strip () def read_int ( f , b = 10 ): return int ( read_word ( f ), b ) def read_letters ( f ): return list ( read_word ( f )) def read_digits ( f , b = 10 ): return [ int ( x , b ) for x in read_letters ( f )] def read_words ( f , d = ' ' ): return read_word ( f ) . split ( d ) def read_ints ( f , b = 10 , d = ' ' ): return [ int ( x , b ) for x in read_words ( f , d )] def read_arr ( f , R , reader = read_ints , * args , ** kwargs ): res = [] for i in range ( R ): res . append ( reader ( f , * args , ** kwargs )) return res def solve ( solver , fn , out_fn = None ): in_fn = fn + '.in' if out_fn is None : out_fn = fn + '.out' with open ( in_fn , 'r' ) as fi : with open ( out_fn , 'w' ) as fo : T = read_int ( fi ) for i in range ( T ): case = read_case ( fi ) res = solver ( case ) write_case ( fo , i , res ) ################################################################################ def read_case ( f ): N = read_int ( f ) Cs = [] for i in range ( N ): ( C , S , P ) = read_words ( f ) Cs . append (( C , int ( S ), int ( P ))) return ( N , Cs ) def write_case ( f , i , res ): f . write ( 'Case # %d : ' % i ) f . write ( ' %s ' % res ) f . write ( ' \\n ' ) ################################################################################ INF = float ( 'inf' ) import heapq def solve_small ( case ): ( N , Cs ) = case col = [] for i in range ( N ): ( c1 , s1 , p1 ) = Cs [ i ] for j in range ( i + 1 , N ): ( c2 , s2 , p2 ) = Cs [ j ] if s1 == s2 : if abs ( p1 - p2 ) < 5 : heapq . heappush ( col , ( - 1 , True , i , j )) continue t1 = ( p2 - p1 + 5 ) / ( s1 - s2 ) t2 = ( p2 - p1 - 5 ) / ( s1 - s2 ) if t1 > t2 : ( t1 , t2 ) = ( t2 , t1 ) if t2 < 0 : continue if t1 < 0 : t1 = - 1 heapq . heappush ( col , ( t1 , True , i , j )) heapq . heappush ( col , ( t2 , False , i , j )) l = [ None ] * N act = [] for i in range ( N ): act . append ( set ()) cnt = 0 while col : ( t , c , i , j ) = heapq . heappop ( col ) if c : act [ i ] . add ( j ) act [ j ] . add ( i ) else : act [ i ] . remove ( j ) act [ j ] . remove ( i ) if t == - 1 : l [ i ] = Cs [ i ][ 0 ] == 'L' l [ j ] = Cs [ j ][ 0 ] == 'L' continue if c : if l [ i ] is None : if l [ j ] is None : l [ i ] = ( cnt , True ) l [ j ] = ( cnt , False ) cnt += 1 elif l [ j ] is True : l [ i ] = False elif l [ j ] is False : l [ i ] = True else : ( k , b ) = l [ j ] l [ i ] = ( k , not b ) elif l [ i ] is True : if l [ j ] is None : l [ j ] = False elif l [ j ] is True : return t elif l [ j ] is False : pass else : ( k , b ) = l [ j ] for x in range ( N ): if isinstance ( l [ x ], tuple ) and l [ x ][ 0 ] == k : l [ x ] = b != l [ x ][ 1 ] elif l [ i ] is False : if l [ j ] is None : l [ j ] = True elif l [ j ] is True : pass elif l [ j ] is False : return t else : ( k , b ) = l [ j ] for x in range ( N ): if isinstance ( l [ x ], tuple ) and l [ x ][ 0 ] == k : l [ x ] = b == l [ x ][ 1 ] else : ( k , b ) = l [ i ] if l [ j ] is None : l [ j ] = ( k , not b ) elif l [ j ] is True : for x in range ( N ): if isinstance ( l [ x ], tuple ) and l [ x ][ 0 ] == k : l [ x ] = b != l [ x ][ 1 ] elif l [ j ] is False : for x in range ( N ): if isinstance ( l [ x ], tuple ) and l [ x ][ 0 ] == k : l [ x ] = b == l [ x ][ 1 ] else : ( k_ , b_ ) = l [ j ] if k == k_ : if b == b_ : return t else : continue for x in range ( N ): if isinstance ( l [ x ], tuple ) and l [ x ][ 0 ] == k : l [ x ] = ( k_ , not b &#94; b_ &#94; l [ x ][ 1 ]) else : #end col if not act [ i ]: l [ i ] = None if not act [ j ]: l [ j ] = None return 'Possible' solve_large = solve_small ##def solve_large(case): DEBUG = 'i' from run import * See also Wikipedia: Google Code Jam Google Code Jam Statistics","tags":"Code","title":"Google Code Jam 2012 â€“ Round 1A 2012"},{"url":"https://martin-thoma.com/latex-vorlage-fur-ein-lastenheft/","text":"Ich habe gerade mal schnell eine Vorlage fÃ¼r ein Lastenheft mit LaTeX erstellt. Dieses Lastenheft beinhaltet sogar ein kleines Use-Case Beispiel, das mit MetaUML realisiert wurde. Hier ist die PDF , hier der LaTeX-Code . Das Lastenheft kÃ¶nnt ihr unter Linux einfach mit dem Befehl make erstellen, wenn ihr in diesem Ordner seid. Ã„nderungsvorschlÃ¤ge sind willkommen! Ich werde die hier gespeicherte Version wohl noch einige male updaten. Siehe auch Softwaretechnik I , S. 36 Beispiel der Uni Paderborn Jet Another SWT-I Resume , ab S. 8","tags":"German posts","title":"LaTeX-Vorlage fÃ¼r ein Lastenheft"},{"url":"https://martin-thoma.com/eclipse-fur-swt-i-einrichten/","text":"SWT I ist das Modul Softwaretechnik I am KIT . Dieser Blogpost richtet sich also vor allem an Studenten des KIT von Herrn Prof. Dr. Tichy . Ich arbeite auÃŸerdem mit Ubuntu Linux. Die momentan aktuellste Version nennt sich Oneiric Ocelot und kann bei UbuntuUsers heruntergeladen werden. Das System kÃ¶nnte z.B. in VirtualBox installiert werden. Installation FÃ¼r die Installation von Java, Subversion (SVN), Eclipse und Checkstyle samt Dokumentation muss folgendes in der Konsole eingegeben werden: sudo apt-get install openjdk-6-jre openjdk-6-jdk openjdk-6-source openjdk-6-demo openjdk-6-doc openjdk-6-jre-headless openjdk-6-jre-lib subversion libapache2-svn eclipse checkstyle checkstyle-doc Dann werden etwa 276 MB an Archiven heruntergeladen und 662 MB an zusÃ¤tzlichen Packeten installiert. Bei meiner Internetverbindung (DSL 1000 â˜¹ ) hat das ca 40 Minuten gedauert. CheckStyle Siehe eclipse-cs.sourceforge.net mit detaillierten Installationsanweisungen . Subversive Siehe eclipse.org: Download Suversive . Diese ErklÃ¤rung ist aber nicht so toll. Nach der Installation und dem Neustart von Eclipse muss man das \"Subversive Connector Kit\" auswÃ¤hlen. Kurz in der Konsole bash svn --version eingeben. Bei mir ist anscheinend Subversion in der Version 1.6.12 installiert. Also wÃ¤hle ich \"SVN Kit 1.3.7\". Zuerst muss man den SVN Connector installieren: http://community.polarion.com/projects/subversive/download/eclipse/2.0/update-site/ Das macht man wie mit CheckStyle. Dann muss man Subversive installieren: http://download.eclipse.org/technology/subversive/0.7/update-site/ Auch hier macht man es wie mit CheckStyle. Sobald alles klappt, sieht es etwa so aus: Subversive plugin in Eclipse Commit mit Subversive unter Eclipse Grundeinstellungen Als erstes sollte man mal auf \"Window\" -> \"Open Perspective\" -> \"Java\" klicken. Siehe auch Ubuntu Downloads Oracle Java - Manuelle Installation unter Ubuntu . Weitere UbuntuUsers Artikel: Eclipse , Subversion Software Versioning Cheat Sheet (Subversion / GIT) Wikipedia: Eclipse , Subversion Wiki Books: Java Standard: Erste Schritte (habe ich NICHT gelesen! Aber fÃ¼r unsere Physiker ist das eventuell hilfreich.)","tags":"German posts","title":"Eclipse fÃ¼r SWT I einrichten"},{"url":"https://martin-thoma.com/wie-berechnet-man-das-charakteristische-polynom/","text":"Will man das charakteristische Polynom einer Abbildungsmatrix berechnen, so muss man zuerst sicher im Umgang mit Determinanten sein. Rechenregeln fÃ¼r Determinanten Man darf eine Zeile mit einer Konstanten a multiplizieren , muss dann aber die Determinante durch a teilen: $ det \\begin{pmatrix} 3 & 2 & 12 & 5 \\\\ 2 & 1 & 6 & 4 \\\\ 2 & 0 & 2 & -3\\\\ 2 & 2 & 7 & 4 \\end{pmatrix} \\begin{array}{c} | \\cdot 2 \\\\ | \\cdot 3 \\\\ | \\cdot 3 \\\\ | \\cdot 3 \\end{array} = \\frac{1}{2} \\cdot (\\frac{1}{3})&#94;3 \\cdot det \\begin{pmatrix} 6 & 4 & 24 & 10 \\\\ 6 & 3 & 18 & 12 \\\\ 6 & 0 & 6 & -9\\\\ 6 & 6 & 21 & 12 \\end{pmatrix} $ Man darf zwei Zeilen / Spalten tauschen , muss dann aber die Determinante mit (-1) multiplizieren: \\(det \\begin{pmatrix} 6 & 4 & 24 & 10 \\\\ 6 & 3 & 18 & 12 \\\\ 6 & 0 & 6 & -9\\\\ 6 & 6 & 21 & 12 \\end{pmatrix} \\begin{array}{c} \\cdot \\\\ \\cdot \\\\ \\leftarrow \\\\ \\leftarrow \\end{array} = - det \\begin{pmatrix} 6 & 4 & 24 & 10 \\\\ 6 & 3 & 18 & 12 \\\\ 6 & 6 & 21 & 12 \\\\ 6 & 0 & 6 & -9 \\end{pmatrix} = det \\begin{pmatrix} 6 & 24 & 4 & 10 \\\\ 6 & 18 & 3 & 12 \\\\ 6 & 21 & 6 & 12 \\\\ 6 & 6 & 0 & -9 \\end{pmatrix} \\) Man darf eine Zeile mit einer Konstanten multiplizieren und auf eine beliebige andere Zeile addieren (wie beim Gauss-Verfahren) Man darf eine Zeile und eine Spalte zugleich entfernen (Entwicklung nach Spalte / Zeile xy), muss dann aber folgendermaÃŸen ausgleichen: Entwicklung nach der k-ten Spalte: \\(D(a_1, ... , a_n) = \\sum_{j=1}&#94;{n}(-1)&#94;{k+j}a_{jk}D_{jk}\\) Entwicklung nach der i-ten Zeile: \\(det A = \\sum_{k=1}&#94;n (-1)&#94;{i+k}a_{ik}D_{ik}\\) Direkt entfernen, ohne etwas weiteres zu beachten, kann man die Zeile, wenn in dieser Zeile nur eine 1 steht und diese 1 an einer ungeraden Spalte (1, ..., n) ist. Eine Spalte kann man direkt entfernen, wenn in der Spalte nur an einer Stelle eine 1 steht und diese 1 an einer ungeraden Zeile (1, ..., n) steht. Berechnung des charakteristischen Polynoms Das charakteristische Polynom einer Abbildungsmatrix A ist der Wert folgender Determinanten: \\(det(\\lambda \\cdot E_n - A)\\) , wobei \\(E_n\\) die Einheitsmatrix ist. Beispiel Siehe Wikipedia . Berechnung am PC Mit Wolfram|Alpha kann man das charakteristische Polynom berechnen und auch direkt die Eigenwerte . Wozu das Ganze? An dem charakteristischem Polynom kann man direkt die Eigenwerte ablesen. Existiert eine Basis aus Eigenvektoren fÃ¼r den Vektorraum, dann ist eine Matrix diagonalsiierbar. Wenn eine Matrix in Diagonalform ist, dann kann man damit besonders gut rechnen. Siehe auch Wikipedia: Determinante , Charakteristisches Polynom , Eigenwertproblem , Diagonalmatrix Skript von Herrn Prof. Dr. Leuzinger, S. 131 - 142: Determinanten.","tags":"German posts","title":"Wie berechnet man das charakteristische Polynom?"},{"url":"https://martin-thoma.com/software-versioning-cheat-sheet/","text":"This Software Versioning Cheat Sheet has very basic information aboout the installation and usage of Subversion and Git. (The LaTeX Source Code is here.) If you're at the KIT and you have SWT, then you'll probably need this command: svn checkout https://svn.ipd.kit.edu/lehre/vorlesung/SWT1/SS12/stud/ SWT/ --username swt1 You will be asked for a password. I hope you remember it. SVN svn co URL LocalTarget --username yourUserName Source: svn checkout svn up Source: svn update svn log -l 4 Source: svn log Updating the repository You can update a SVN repository with this command: svn up [ path ] If you need to execute the command often, you might want to define an alias. aliases are shorthands for long commands in the bash. To create a permanent one, add the following line to your ~/.bashrc file: alias swt = 'svn up /home/moose/Studium/SWT' Now you only have to enter \"swt\" to execute \"svn up /home/moose/Studium/SWT\". Nice diffs You can modify your config file: gedit ~/.subversion/config and change diff-cmd to meld . Compare revisions svn diff -r 63 :64 compares revision number 63 with revision number 64 with the tool you defined (see Nice diffs). Git Global configuration $ git config --global user.name \"Martin Thoma\" $ git config --global user.email info@martin-thoma.de $ git config --global color.ui true Nice diffs If you want a GUI for git diff , then you should do the following: Install meld: sudo apt-get install meld Got to /bin and create a Shell-Script called git-meld with the following content: #!/bin/bash meld \" $2 \" \" $5 \" Make it executable: chmod +x git-meld Add it to your git configuration: git config --global diff.external git-meld Enjoy this experience when entering git diff : Using Meld with GIT See also jeetworks.org for some other solutions. Image diffs Aki Koskinen posted a nice article on how to make image diffs with git . I only changed the diff program to StanAngeloffs simple-imagediff.py The most important steps are: Tell git what images are: $ git config --global core.attributesfile '~/.gitattributes' $ cat .gitattributes *.gif diff = image *.jpg diff = image *.png diff = image Tell git how to deal with images in diffs: $ git config --global diff.image.command 'simple-imagediff' Add simple-imagediff as an executable: $ cat ~/. local / bin / simple - imagediff #!/usr/bin/env python # Simple Image Diffs # ================== # # How to Install # -------------- # # Download the script somewhere on $PATH as 'simple-imagediff' with +x: # # $ cd ~/bin # $ wget -O simple-imagediff https://raw.github.com/gist/1716699/simple-imagediff.py # $ chmod +x simple-imagediff # # Prerequisites # ------------- # # The script should work out-of-the box on Ubuntu 11.10. On other OS'es you may # need to install PIL and Gtk3. # # Git Setup # --------- # # In ~/.gitconfig, add: # # [diff \"image\"] # command = simple-imagediff # # In your project, create .gitattributes file and add (this enables the custom # diff tool above): # # *.gif diff=image # *.jpg diff=image # *.png diff=image # # Try It # ------ # # $ git diff path/to/file.png # # NOTE: file.png must be versioned and the working copy must be different. import os import sys import Image from gi.repository import Gdk , Gtk class SimpleImageDiffWindow ( Gtk . Window ): def __init__ ( self , left , right ): Gtk . Window . __init__ ( self , title = \"Simple Image Diff ( %s , %s )\" % ( left , right )) self . set_default_size ( 640 , 480 ) align = Gtk . Alignment () align . set_padding ( 10 , 10 , 10 , 10 ) box = Gtk . HBox ( homogeneous = True , spacing = 10 ) box . add ( self . _create_image_box ( left )) box . add ( self . _create_image_box ( right )) align . add ( box ) self . add ( align ) self . resize ( 1 , 1 ) self . set_position ( Gtk . WindowPosition . CENTER ) def _create_image_box ( self , image_file ): box = Gtk . VBox ( spacing = 10 ) frame = Gtk . Frame () image = Gtk . Image () image . set_from_file ( image_file ) title = Gtk . Label ( label = \"W: %d px | H: %d px\" % Image . open ( image_file ) . size ) frame . add ( image ) box . pack_start ( frame , True , True , 0 ) box . pack_end ( title , False , False , 10 ) return box def _halt ( message , code ): sys . stderr . write ( \"[ERROR] %s \\n \" % message ) sys . exit ( 0 << code ) def _verify_file_exists ( target ): if not os . path . exists ( target ): _halt ( \"The file ' %s ' does not exists.\" % target , 2 ) if __name__ == '__main__' : if len ( sys . argv ) < 3 : _halt ( 'Not enough arguments.' , 1 ) _verify_file_exists ( sys . argv [ 1 ]) _verify_file_exists ( sys . argv [ 2 ]) app = SimpleImageDiffWindow ( sys . argv [ 1 ], sys . argv [ 2 ]) app . connect ( 'delete-event' , Gtk . main_quit ) app . show_all () Gtk . main () GitHub Preparation Read the guide \" Generating SSH keys \" for more information on SSH and \" Getting Started - First-Time Git Setup \" for Git-specific questions. cd ~/.ssh ssh-keygen -t rsa -C \"info@martin-thoma.de\" git config --global user.name \"Martin Thoma\" git config --global user.email info@martin-thoma.de Clone Clone a GITHub repository: git clone git@github.com:MartinThoma/matrix-multiplication.git Snippets Reset a single file to the latest revision on the server: git checkout HEAD file/to/restore Get the latest diff: git diff HEAD @ { 1 } Resources Version Control with Subversion : a great explanation how to use subversion, e.g. svn export StackOverflow: Which files should be put under version controll? GitHub: Remotes","tags":"Code","title":"Software Versioning Cheat Sheet"},{"url":"https://martin-thoma.com/url-shortener/","text":"URL shortening services are Websites, which offer redirections from one of their pages with short URLs to your page (with a long URL). URL shortening services are great when you need to print URLs. I don't like them on Websites / in e-mails as I can't see the target, but I don't want to type so much when I get a URL in my real live. These services should be used more often in my university. It's ridiculous that all students have to note very long URLs in the first few days. It's not a real problem, but using URL shorteners would be better. I'll describe some services in the following article. bitly Long URL: https://lists.ira.uni-karlsruhe.de/mailman/listinfo/swt1-vorlesung (66 characters) Short URL: http://bit.ly/HKEKD0 (20 characters) Custom URL: http://bit.ly/SWT-List (22 characters, but you need to sign up for free) Bitly does not re-use old links ( source ). You get additional information by adding a + sing at the end: http://bit.ly/HKEKD0+ , http://bit.ly/SWT-List+ TinyURL Long URL: https://lists.ira.uni-karlsruhe.de/mailman/listinfo/swt1-vorlesung (66 characters) Short URL: http://tinyurl.com/87oscxb (26 characters) Custom URL: http://tinyurl.com/SWT-List (27 characters) Goo.gl Long URL: https://lists.ira.uni-karlsruhe.de/mailman/listinfo/swt1-vorlesung (66 characters) Short URL: http://goo.gl/z5cp0 (19 characters) Custom URL: Not possible This service is owned by Google. Links do not expire and nobody can change them ( source ). Quality Properties I think you can make a very simple list of quality properties of URL shorteners: User Interface The user interface should be minimalistic. Goo.gl is a good example, bitly and tinyurl are still ok: Goo.gl url shortener Tinyurl url shortener Bit.ly url shortener Choose your own name If possible, the user should be able to choose the name of the short URL. NEVER change short URL Short URLs should live forever and never change. Preview Adding '?preview' should give you a preview of the URL The preview should be the default option. Only if the user actively deactivated that - which can be stored with a cookie - preview should not be shown. This is especially important in case of JavaScript in the URL / probably malicious websites See also URL Toolbox: 90+ URL Shortening Services - if you wish to see some more Wikipedia: bitly TinyURL URL shortening Did I miss quality measures?","tags":"The Web","title":"URL shortener"},{"url":"https://martin-thoma.com/eigenwerte-eigenvektoren-und-eigenraume/","text":"Eigenwerte sind Elemente des KÃ¶rpers \\(\\mathbb{K}\\) zu einem Endomorphismus \\(\\Phi:V \\rightarrow V\\) , die folgende Eigenschaft erfÃ¼llen: \\(\\Phi(x) = \\lambda x\\) mit \\(x \\in V\\) und \\(x \\neq 0\\) Alle Vektoren x sind Eigenvektoren zu diesem Eigenwert. Zusammen mit dem Null-Vektor bilden alle Eigenvektoren zu einem Eigenwert einer linearen Abbildung \\(\\Phi\\) einen Eigenraum . Diesen Eigenraum bezeichnet man mit \\(E_\\lambda\\) . Interessante SÃ¤tze $E_{\\lambda_1} \\cap E_{\\lambda_2} = \\emptyset$ Ein Endomorphismus $\\Phi$ eines n-dimensionalen $\\mathbb{K}$-Vektorraumes hat hÃ¶chstens n Eigenwerte. Eine lineare Abbildung $\\Phi$ ist genau dann diagonalisierbar, wenn es eine Basis von V aus Eigenvektoren gibt. Wenn eine lineare Abbildung eines n-dimensionalen Vektorraums n verschiedene Eigenwerte hat, so ist sie diagonalisierbar. Beispiele Etwas einfaches Sei \\(\\Phi:\\mathbb{R}&#94;3 \\rightarrow \\mathbb{R}&#94;3\\) definiert durch \\(\\Phi(x) := x $. Dann ist $\\lambda = 1\\) der einzige Eigenwert. Der gesamte \\(\\mathbb{R}&#94;3 \\setminus \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} \\) besteht ausschlieÃŸlich aus Eigenvektoren zu diesem Eigenwert. Also ist der dazugehÃ¶rige Eigenraum der gesamte \\(\\mathbb{R}&#94;3\\) . Noch immer leicht Sei \\(\\Phi:\\mathbb{R}&#94;3 \\rightarrow \\mathbb{R}&#94;3\\) definiert durch \\(\\Phi(x) := ax $ mit $a \\in \\mathbb{R} \\setminus \\{0\\}\\) . Dann ist \\(\\lambda = a\\) der einzige Eigenwert. Der gesamte \\(\\mathbb{R}&#94;3 \\setminus \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} \\) besteht ausschlieÃŸlich aus Eigenvektoren zu diesem Eigenwert. Also ist der dazugehÃ¶rige Eigenraum der gesamte \\(\\mathbb{R}&#94;3\\) . Etwas schwerer Sei \\(\\Phi:\\mathbb{R}&#94;3 \\rightarrow \\mathbb{R}&#94;3\\) definiert durch $\\Phi(x) := \\begin{pmatrix} 1 & 2 & 3\\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9 \\end{pmatrix} x $. Die Eigenwerte sind laut Wolfram|Alpha : \\(\\lambda_1 = \\frac{3}{2} (5+\\sqrt{33})\\) , Eigenvektor: \\(v_1 = \\begin{pmatrix}-\\frac{13}{11}+\\frac{1}{22} (15+3 \\sqrt{33}) \\\\ -\\frac{1}{11}+\\frac{1}{44} (15+3 \\sqrt{33}) \\\\ 1\\end{pmatrix} \\) \\(\\lambda_2 = \\frac{3}{2} (5-\\sqrt{33})\\) , Eigenvektor: \\(v_2 = \\begin{pmatrix}-\\frac{13}{11}+\\frac{1}{22} (15+3 \\sqrt{33}) \\\\ -\\frac{1}{11}+\\frac{1}{44} (15-3 \\sqrt{33}) \\\\ 1\\end{pmatrix} \\) \\(\\lambda_3 = 0\\) , Eigenvektor: \\(v_3 = \\begin{pmatrix}1 \\\\ -2 \\\\ 1\\end{pmatrix} \\) - der Kern von \\(\\Phi\\) (siehe Wolfram|Alpha ) Wozu das Ganze? Mit Eigenwerten (bzw. Vektoren) kann man Ã¼berprÃ¼fen, ob eine lineare Abbildung diagonalisierbar ist. Eine lineare Abbildung in Form einer Diagonalmatrix ist besonders leicht zu berechnen. Es ist also wÃ¼nschenswert, die Abbildungsmatrix in Diagonalform zu bringen. Kennt jemand noch weitere GrÃ¼nde, warum Eigenwerte / Vektoren / RÃ¤ume interessant sind? Siehe auch Wikipedia: Eigenwertproblem Albrecht Beutelspacher: Lineare Algebra. 7 Auflage. Vieweg+Teubner Verlag, Wiesbaden 2010, ISBN 978-3-528-66508-1, S. 202-207. Enrico Leuzinger: Skript zur Linearen Algebra I. S. 143-147.","tags":"German posts","title":"Eigenwerte, Eigenvektoren und EigenrÃ¤ume"},{"url":"https://martin-thoma.com/lernkontrolle-lineare-algebra-i/","text":"Hier sind ein paar Fragen zur Linearen Algebra I und die Antworten dazu. Die LaTeX-Dokumente gibts natÃ¼rlich auch. Bei ein paar Fragen, bin ich mir nicht sicher wie die Antwort lautet. Ich habs immer dazu geschrieben. Wenn ihr Fehler findet, hinterlasst bitte einfach hier einen Kommentar. Ich verbessere es dann. Wenn ihr gute Beispiele / Gegenbeispiele oder sogar weitere Fragen habt, kÃ¶nnt ihr das auch gerne in den Kommentaren schreiben. Material und Quellen Einige Fragen (und dazugehÃ¶rige Antworten) sind so, oder so Ã¤hnlich, in folgendem Buch zu finden, das ich sehr weiterempfehlen kann: Albrecht Beutelspacher: Lineare Algebra, ISBN 978-3-528-66508-1.","tags":"German posts","title":"Lernkontrolle: Lineare Algebra I"},{"url":"https://martin-thoma.com/google-code-jam-2012-qualification-round/","text":"I've passed the Qualification Round of Google Code Jam 2012. I've learned, that I am not allowed to submit the large dataset after the first 8 minutes. 18,365 programmers took part in this contest. 15,692 had at least 20 points and advanced to the First Rounds. These are my solutions: Problem A: Speaking in Tongues This one was easy. It's a simple substitution cipher : #!/usr/bin/python # -*- coding: utf-8 -*- def decode ( ciphertext , key = \"ynficwlbkuomxsevzpdrjgthaq\" , alphabet = \"abcdefghijklmnopqrstuvwxyz\" ): dic = {} for i in range ( 0 , len ( key )): dic [ key [ i ]] = alphabet [ i ] plaintext = \"\" for l in ciphertext : if l in dic : l = dic [ l ] plaintext += l return plaintext if __name__ == \"__main__\" : testcases = input () for caseNr in xrange ( 0 , testcases ): cipher = raw_input () print ( \"Case # %i : %s \" % ( caseNr + 1 , decode ( cipher ))) A minimalistic python solution for this one was suggested by Niklas B. He makes use of Lambdas , str.translate() and str.maketrans() : #!/usr/bin/python # -*- coding: utf-8 -*- import string as s testcases = input () key = \"ynficwlbkuomxsevzpdrjgthaq\" decode = lambda c : s . translate ( c , s . maketrans ( key , s . ascii_lowercase )) for i in range ( 0 , testcases ): print decode ( raw_input ()) Problem B: Dancing With the Googlers #!/usr/bin/python # -*- coding: utf-8 -*- from math import ceil , floor def line2intlist ( line ): list = line . split ( ' ' ) numbers = [ int ( x ) for x in list ] return numbers def getDist ( points , isSurprising = False ): p = floor ( points / 3.0 ) trip = [ p , p , p ] if 3 * p < points : trip [ 0 ] += 1 if ( 3 * p + 1 ) < points : trip [ 1 ] += 1 trip . sort ( reverse = True ) if isSurprising and ( trip [ 1 ] == trip [ 0 ]) and trip [ 1 ] > 0 : trip [ 1 ] -= 1 trip [ 0 ] += 1 trip . sort ( reverse = True ) return trip def maxGooglers ( nrOfGooglers , surprising , p , points ): mg = 0 surp = 0 for pi in points : trip = getDist ( pi , True ) if ceil ( pi / 3.0 ) >= p : mg += 1 elif trip [ 0 ] >= p : surp += 1 mg += min ( surp , surprising ) return mg if __name__ == \"__main__\" : testcases = input () for caseNr in xrange ( 0 , testcases ): originalList = line2intlist ( raw_input ()) nrOfGooglers = originalList [ 0 ] surprising = originalList [ 1 ] p = originalList [ 2 ] points = originalList [ 3 :] print ( \"Case # %i : %i \" % ( caseNr + 1 , maxGooglers ( nrOfGooglers , surprising , p , points ))) Problem C: Recycled Numbers The small dataset of this one was easy, but I had to change my code a bit to make it work for the large dataset. Sadly, I didn't know that I only have 8 minutes to get it work â˜¹ I've tried cPickle for the 2,000,000 list. It took 128.7 MB and 1 minute 6.287s for the large data set after it was pickled. Without pickling it took 1 minute 31.900s. #!/usr/bin/python # -*- coding: utf-8 -*- try : import cPickle as pickle except : import pickle def line2intlist ( line ): list = line . split ( ' ' ) numbers = [ int ( x ) for x in list ] return numbers def binomialCoefficient ( n , k ): if k < 0 or k > n : return 0 if k > n - k : # take advantage of symmetry k = n - k c = 1 for i in range ( k ): c = c * ( n - ( k - ( i + 1 ))) c = c // ( i + 1 ) return c #return n * (n - 1) / 2 def rot ( num , rot ): num = str ( num ) num = num [ len ( num ) - rot : len ( num )] + num [ 0 : len ( num ) - rot ] return int ( num ) def getRotList ( num ): \"\"\" Only return bigger rotated ones \"\"\" rotList = [ num ] for i in xrange ( 1 , len ( str ( num ))): tmp = rot ( num , i ) if tmp not in rotList and len ( str ( tmp )) == len ( str ( num )): rotList . append ( tmp ) return sorted ( rotList ) def inBorder ( rotations , A , B ): count = 0 for el in rotations : if A <= el and el <= B : count += 1 return count def recycled ( A , B , liste ): pairs = 0 minList = range ( 0 , B + 1 ) for tmpList in liste [ A : B + 1 ]: if minList [ tmpList [ 0 ]]: nrInBorder = inBorder ( tmpList , A , B ) pairs += binomialCoefficient ( nrInBorder , 2 ) minList [ tmpList [ 0 ]] = 0 return pairs if __name__ == \"__main__\" : liste = [] try : liste = pickle . load ( open ( \"save.p\" , \"rb\" )) except IOError : for i in xrange ( 0 , 2000001 ): tmp = getRotList ( i ) liste . append ( tmp ) pickle . dump ( liste , open ( \"save.p\" , \"wb\" )) testcases = input () for caseNr in xrange ( 0 , testcases ): A , B = line2intlist ( raw_input ()) print ( \"Case # %i : %i \" % ( caseNr + 1 , recycled ( A , B , liste ))) Problem D: Hall of Mirrors This one was very hard. I had some ideas, but none of them seemed to work. This is a solution based on the solution of \"dwenzel\". At the moment, I've only made some comments and broke some lines to let them fit into my blog. This solution needs about 2 minutes 42 seconds for the small input set and 2 minutes 12 seconds for the large input set. You might also be interested in the official Contest Analysis with some hints to this challenge. #!/usr/bin/python # -*- coding: utf-8 -*- from math import floor , ceil , sqrt precision = 0.01 def line2intlist ( line ): list = line . split ( ' ' ) numbers = [ int ( x ) for x in list ] return numbers def seeReflection ( x , v , m , d ): cur_y = x [ 0 ] cur_x = x [ 1 ] vy = v [ 0 ] vx = v [ 1 ] dist = 0 while dist <= d + precision : if abs ( cur_x - x [ 1 ]) < precision and \\ abs ( cur_y - x [ 0 ]) < precision and dist > 0 : return True if vy == 0 : if vx < 0 : cur_x -= 0.5 else : cur_x += 0.5 if abs ( cur_x - round ( cur_x )) < precision : tmp = int ( floor ( cur_y )) if vx < 0 and m [ tmp ][ int ( round ( cur_x ) - 1 )] == 1 : vx = - vx elif vx > 0 and m [ tmp ][ int ( round ( cur_x ))] == 1 : vx = - vx dist += 0.5 elif vx == 0 : if vy < 0 : cur_y -= 0.5 else : cur_y += 0.5 if abs ( cur_y - round ( cur_y )) < precision : tmp = int ( floor ( cur_x )) if vy < 0 and m [ int ( round ( cur_y ) - 1 )][ tmp ] == 1 : vy = - vy elif vy > 0 and m [ int ( round ( cur_y ))][ tmp ] == 1 : vy = - vy dist += 0.5 else : # Find how far is the next time we hit something # .0 or .5 if vy < 0 : dy = cur_y - floor ( cur_y ) else : dy = ceil ( cur_y ) - cur_y if dy > 0.5 + precision : dy -= 0.5 elif dy < precision : dy += 0.5 if vx < 0 : dx = cur_x - floor ( cur_x ) else : dx = ceil ( cur_x ) - cur_x if dx > 0.5 + precision : dx -= 0.5 elif dx < precision : dx += 0.5 # See which will come up first ty = dy / abs ( vy ) tx = dx / abs ( vx ) if ty > tx : t = tx else : t = ty dy = vy * t dx = vx * t cur_y = cur_y + dy cur_x = cur_x + dx dist += sqrt ( dy * dy + dx * dx ) roundy = round ( cur_y ) roundx = round ( cur_x ) ybounce = False xbounce = False if abs ( cur_y - roundy ) < precision and \\ abs ( cur_x - roundx ) < precision : # Case we're at a corner neighbors = [] intx = int ( roundx ) inty = int ( roundy ) neighbors . append ( m [ inty - 1 ][ intx - 1 ] % 2 ) neighbors . append ( m [ inty - 1 ][ intx ] % 2 ) neighbors . append ( m [ inty ][ intx ] % 2 ) neighbors . append ( m [ inty ][ intx - 1 ] % 2 ) sum = 0 for neighbor in neighbors : sum += neighbor if sum == 1 : if vy < 0 : nexty = inty - 1 else : nexty = inty if vx < 0 : nextx = intx - 1 else : nextx = intx if m [ nexty ][ nextx ] == 1 : return False elif sum == 3 : vy = - vy vx = - vx elif sum == 2 : if neighbors [ 0 ] == neighbors [ 1 ]: vy = - vy elif neighbors [ 0 ] == neighbors [ 3 ]: vx = - vx elif abs ( cur_y - roundy ) < precision : # Case we're middle of a top/bottom edge if vy < 0 : inty = int ( roundy - 1 ) else : inty = int ( roundy ) intx = int ( floor ( cur_x )) if m [ inty ][ intx ] == 1 : vy = - vy elif abs ( cur_x - roundx ) < precision : # Case we're middle of a top/bottom edge if vx < 0 : intx = int ( roundx - 1 ) else : intx = int ( roundx ) inty = int ( floor ( cur_y )) if m [ inty ][ intx ] == 1 : vx = - vx return False def getMap ( H , W ): map = [] for el in xrange ( 0 , H ): line = raw_input () tmp = [] for char in line : if char == '.' : tmp . append ( 0 ) elif char == '#' : tmp . append ( 1 ) else : tmp . append ( 2 ) map . append ( tmp ) return map def process_case ( m , H , W , D ): vectors = set () ratios = set () for i in range ( D + 1 ): for j in range ( 1 , D + 1 ): if i <= j and i * i + j * j <= D * D : ratio = float ( i ) / float ( j ) if ratio not in ratios : vectors . add (( i , j )) vectors . add (( i , - j )) vectors . add (( - i , j )) vectors . add (( - i , - j )) vectors . add (( j , i )) vectors . add (( j , - i )) vectors . add (( - j , i )) vectors . add (( - j , - i )) ratios . add ( ratio ) x = None for i in range ( H ): for j in range ( W ): if x == None and m [ i ][ j ] == 2 : x = ( i + 0.5 , j + 0.5 ) count = 0 for vector in vectors : if seeReflection ( x , vector , m , D ): count += 1 return count if __name__ == \"__main__\" : testcases = input () for caseNr in xrange ( 0 , testcases ): H , W , D = line2intlist ( raw_input ()) map = getMap ( H , W ) print ( \"Case # %i : %i \" % ( caseNr + 1 , process_case ( map , H , W , D ))) See also Wikipedia: Google Code Jam Google Code Jam Statistics","tags":"Code","title":"Google Code Jam 2012 - Qualification Round"},{"url":"https://martin-thoma.com/php-a-strange-language/","text":"Automatic conversion Strings to numbers $ php -a php > var_dump(123 == '123ax'); bool(true) php > var_dump('123' == '123ax'); bool(false) MD5 hashes This one seems to be fixed. It doesn't work in PHP Version 5.4.6-1ubuntu1.2 (released 16.08.2012). It was a problem in PHP 5.3.5 (released 06.01.2011) PHP converts strings automatically to a float if it is possible. This might lead to problems. See this example from phpsadness : <?php $password = \"ximaz\" ; $hash = \"61529519452809720693702583126814\" ; // = md5(\"ximaz\") if ( md5 ( $password ) == $hash ) { print \"Allowed! \\n \" ; } $wrong_hash = \"61529519452809720000000000000000\" ; if ( $wrong_hash == $hash ) { print \"Wrong hash got correct! \\n \" ; } ?> See also: Comparison Operators Bug #54547: wrong equality of string numbers Bug #62097: New behavior of string == has a compatibility problem Versionsgeschichte von PHP (German) Inconsistency Starting and ending PHP The following snippet is valid PHP-code: <?php </ script > ?> Source: StackOverflow.com (You can find some explanations there.) Underscores Some functions use underscores between words, while others do not: gettype vs. get_class Order of Arguments strpos ( string $haystack , mixed $needle [...] ) stristr ( string $haystack , mixed $needle [...] ) in_array ( mixed $needle , array $haystack [...] ) array_search ( mixed $needle , array $haystack [...] ) Sorting function pivot($arr) { return ($arr[0] + end($arr)) / 2; } $arr = array(1, 5, 7, 2, 3, 4, 8, 9, 6); echo pivot(sort($arr)); This doesn't work. If you don't know why, you should take a look at sort . Argument order mktime ([$hour [, $minute [, $second [, $month [, $day [, $year [, $is_dst]]]]]]]) array_fill array_fill doesn't allow 0 as $number . <?php $number = 2 ; $arr = array_fill ( 0 , $number , 42 ); print_r ( $arr ); ?> Array ( [0] => 42 [1] => 42 ) Strange loop Loops themselves should not change anything. So take a look at this: <?php $array = array ( 'foo' , 'bar' ); var_dump ( $array ); foreach ( $array as & amp ; $foo ); var_dump ( $array ); ?> Output: array(2) { [0]=> string(3) \"foo\" [1]=> string(3) \"bar\" } array(2) { [0]=> string(3) \"foo\" [1]=> &amp;string(3) \"bar\" } Boolean evaluation <?php $a = array ( '7.1' ); $arr1 = array ( 'foo' => 'foo' , 'bar' => 'bar' , ); $arr2 = array ( 'bar' => 'bar' , 'foo' => 'foo' , ); if ( \"a\" ) { echo \"This \" ;} if ( true ) { echo \"is \" ;} if ( 9 ) { echo \"PHP. \" ;} if ( 07 ) { echo \"Oktal \" ;} if ( 010 == 8 ) { echo \"is \" ;} if ( \"8\" == 8 ) { echo \"also \" ;} if ( array ( 0 )) { echo \"true. \" ;} if ( $x = 1 ) { echo \"Like \" ;} if ( in_array ( '7.10' , $a )) { echo \"that \" ;} if ( $arr1 == $arr2 ) { echo \"one \" ;} if ( 0 == 'x' ) { echo \"is true.\" ;} if ( \"\" ) { echo \"false \" ;} if ( 0 ) { echo \"false\" ;} if ( 08 ) { echo \"false\" ;} if ( array ()) { echo \"false\" ;} if ( $x = 0 ) { echo \"false\" ;} if ( $arr1 === $arr2 ) { echo \"false\" ;} ?> Make a Guess Try to guess what the following prints: <?php for ( $i = 'a' ; $i <= 'z' ; ++ $i ) echo \" $i \" ; // I just need four NULLs to demo this. $a = array_fill ( 0 , 4 , NULL ); $a [ 0 ] ++ ; ++ $a [ 1 ]; $a [ 2 ] -- ; -- $a [ 3 ]; var_dump ( $a ); $b [ 0 ] ++ ; ++ $b [ 1 ]; $b [ 2 ] -- ; -- $b [ 3 ]; var_dump ( $b ); ?> Did you guess the following? a b c d e f g h i j k l m n o p q r s t u v w x y z aa ab ac ad ae af ag ah ai aj ak al am an ao ap aq ar as at au av aw ax ay az ba bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd ce cf cg ch ci cj ck cl cm cn co cp cq cr cs ct cu cv cw cx cy cz da db dc dd de df dg dh di dj dk dl dm dn do dp dq dr ds dt du dv dw dx dy dz ea eb ec ed ee ef eg eh ei ej ek el em en eo ep eq er es et eu ev ew ex ey ez fa fb fc fd fe ff fg fh fi fj fk fl fm fn fo fp fq fr fs ft fu fv fw fx fy fz ga gb gc gd ge gf gg gh gi gj gk gl gm gn go gp gq gr gs gt gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie if ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq or os ot ou ov ow ox oy oz pa pb pc pd pe pf pg ph pi pj pk pl pm pn po pp pq pr ps pt pu pv pw px py pz qa qb qc qd qe qf qg qh qi qj qk ql qm qn qo qp qq qr qs qt qu qv qw qx qy qz ra rb rc rd re rf rg rh ri rj rk rl rm rn ro rp rq rr rs rt ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk sl sm sn so sp sq sr ss st su sv sw sx sy sz ta tb tc td te tf tg th ti tj tk tl tm tn to tp tq tr ts tt tu tv tw tx ty tz ua ub uc ud ue uf ug uh ui uj uk ul um un uo up uq ur us ut uu uv uw ux uy uz va vb vc vd ve vf vg vh vi vj vk vl vm vn vo vp vq vr vs vt vu vv vw vx vy vz wa wb wc wd we wf wg wh wi wj wk wl wm wn wo wp wq wr ws wt wu wv ww wx wy wz xa xb xc xd xe xf xg xh xi xj xk xl xm xn xo xp xq xr xs xt xu xv xw xx xy xz ya yb yc yd ye yf yg yh yi yj yk yl ym yn yo yp yq yr ys yt yu yv yw yx yy yz array(4) { [0]=> int(1) [1]=> int(1) [2]=> NULL [3]=> NULL } array(4) { [0]=> int(1) [1]=> int(1) [2]=> NULL [3]=> NULL } Function names are NOT case sensitive function add($a, $b) { return $a + $b; } $foo = add(1, 2); $Foo = Add(3, 4); echo \"foo is $foo\"; // outputs foo is 3 echo \"Foo is $Foo\"; // outputs Foo is 7 Source: StackOverflow PHP Logo Add ?=PHPE9568F34-D428-11d2-A769-00AA001ACF42 to any PHP script and take a look at the output. For example at Wikipedia . Sources phpsadness.com PHP: a fractal of bad design (thanks to knallisworld.de ) phpwtf.org","tags":"Code","title":"PHP: A strange language"},{"url":"https://martin-thoma.com/project-euler-problem-142/","text":"Project Euler is a series of challenging mathematical/computer programming problems that will require more than just mathematical insights to solve. Although mathematics will help you arrive at elegant and efficient methods, the use of a computer and programming skills will be required to solve most problems. The motivation for starting Project Euler, and its continuation, is to provide a platform for the inquiring mind to delve into unfamiliar areas and learn new concepts in a fun and recreational context. Today, I would like to discuss problem 142. I've seen a post from Santiago Alessandri , so I liked to do the task by myself. The task is: Find the smallest x + y + z with integers \\(x > y > z > 0\\) such that x + y, x - y, x + z, x - z, y + z, y - z are all perfect squares. I don't want to post the solution (if you want to cheat, I guess you could easily Google it), but some thoughts that might help you to get in the right direction. First thought: Brute-force Brute-force is the easiest way that could give you the solution. So I wrote this piece of code: #!/usr/bin/python # -*- coding: utf-8 -*- import sys from math import sqrt def is_square ( integer ): root = sqrt ( integer ) if int ( root + 0.5 ) ** 2 == integer : return True else : return False for x in xrange ( 3 , 1000 ): print x for y in xrange ( 2 , x ): for z in xrange ( 1 , y ): if ( x > y and y > z ): if ( is_square ( x + y ) and is_square ( x - y ) and is_square ( x + z ) and is_square ( x - z ) and is_square ( y + z ) and is_square ( y - z )): print ( \" %i - %i - %i \" % ( x , y , z )) sys . exit () This is quite fast until you reach about 500. So this is not a good way to solve it. Apply some math You can formalize the task like this: Find the smallest \\(x, y, z \\in \\mathbb{N}\\) , so that: \\(x > y > z > 0\\) \\(a = x + y\\) \\(b = x - y\\) \\(c = x + z\\) \\(d = x - z\\) \\(e = y + z\\) \\(f = y - z\\) With \\(a, b, c, d, e, f \\in Squares\\) . Now you can make the following conclusions: \\(\\overset{A.1, A.2, A.3}{\\implies} a > b\\) \\(\\overset{A.1, A.4, A.5}{\\implies} c > d\\) \\(\\overset{A.1, A.6, A.7}{\\implies} e > f\\) \\(a > c\\) : \\(y > z\\) \\(\\Leftrightarrow x + y > x + z\\) \\(\\Leftrightarrow a > c\\) \\(c > e\\) : \\(x > y\\) \\(\\Leftrightarrow x + z > y + z\\) \\(c > e\\) a is the biggest element (see B.1, B.4, B.6) \\(b < c\\) : \\(-y < z\\) \\(\\Leftrightarrow x - y < x + z\\) \\(b < c\\) c is the second biggest element (see B.7, B.2, B.5, B.8) \\(b < d\\) : \\( y > z\\) \\(\\Leftrightarrow -y < -z\\) \\(\\Leftrightarrow x - y < x - z\\) \\(b < d\\) \\(d > f\\) : \\( x > y\\) \\(\\Leftrightarrow x - z > y - z\\) \\(d > f\\) I can't tell anything about the relationship between: d and e b and f b and e Lets conclude: Graph that visualizes the situation of the squares of Euler 142 You also know: \\(x = \\frac{a - b}{2} \\implies \\text{ (a - b) has to be even} \\implies \\text{a and b have the same parity.}\\) The same argumentation can be used for (c, d) and (e, f). \\(x > y > z > 0 \\land a = x + y \\implies a \\geq 5\\) . With this in mind you don't have to loop over three variables but only over two. This is much faster. As z is over 1000 you need it. My new script took about 1.5 minutes. Material Some material like the LaTeX-file can be found in the Project Euler 142 Archive .","tags":"Code","title":"Project Euler: Problem 142"},{"url":"https://martin-thoma.com/the-best-advertising-campaigns/","text":"Jobs in Town FedEx FedEx vs UPS Mr. Clean Mr. Clean Advertising Tip Ex TipEx advertising National Geographic Channel National Geographic Channel Advertising Tampax Tampax advertising 3M Security Glass 3M Security Glass Coffee Coffee advertising Funeral ad Funeral advertising Ravensburger Ravensburger Puzzle advertising","tags":"Cyberculture","title":"The Best Advertising Campaigns"},{"url":"https://martin-thoma.com/amazing-animals/","text":"Some animals are truly amazing. Just take a look at them. I've also included some video clips of funny individuals. Axoltotl Axoltol The axoltotl is capable of the regeneration of entire lost appendages in a period of months, and, in certain cases, more vital structures. Some have indeed been found restoring the less vital parts of their brains. They can also readily accept transplants from other individuals, including eyes and parts of the brainâ€”restoring these alien organs to full functionality. In some cases, axolotls have been known to repair a damaged limb as well as regenerating an additional one, ending up with an extra appendage that makes them attractive to pet owners as a novelty. In metamorphosed individuals, however, the ability to regenerate is greatly diminished. The axolotl is therefore used as a model for the development of limbs in vertebrates. Platypus Platypus Together with the four species of echidna, the platypus is one of the five extant species of monotremes, the only mammals that lay eggs instead of giving birth to live young. It is one of the few venomous mammals . Mimic Octopus The mimic octopus has a strong ability to mimic other creatures. It grows up to 60 cm (2 feet) in length. Its normal colouring consists of brown and white stripes or spots. Lyrebird A Lyrebirds are most notable for their superb ability to mimic natural and artificial sounds from their environment. Lyrebirds have unique plumes of neutral coloured tailfeathers. Chimpanzee Ants Individuals Einstein le perroquet Dog, Cat and Rat Genius dog climbs fence Cat gets caught barking","tags":"My bits and bytes","title":"Amazing Animals"},{"url":"https://martin-thoma.com/how-chrome-could-be-improved/","text":"Google Chrome is the browser of my choice. It is fast, has developer tools and looks great. But it could be improved. I'll describe some features I miss. Disable sound for tabs Sometimes I watch a movie while I play a flash game. Some flash games don't offer an option to mute them. So I would like to get the possibility to disable sound for one tab. It could look like this. Disable the sound of a tab Spell checker I write Blogs in German and in English. So I would like a spell-checker option at the bottom-left corner to switch languages: Spell checker HTML5 Form Elements HTML5 brought many cool new form elements to the web. If you like, take a look at my list of HTML5 input types . Chrome should support all of them! Note that Chrome does support these types according to html5test.com . But I can't see any difference between type=url and type=text. That's not supporting the new types! By the way, at the moment Chrome scores 385 points + 13 bonus points. The best browser currently scores 425 points + 25 bonus points. Opera 11.01 Native date input type Internal PDF-Reader Internal PDF reader of Chrome Rotate PDF Some PDF files I receive are rotated by 90Â°. It would be great if I could, as in every PDF viewer, rotate this. A common shortcut is Ctrl+Arrow key. Page numbers It would be great, if I could enter the number of the page I want to view. For example in the URL by adding \"#123\" for page 123. Security Extensions Auto-Disable extensions for https. Only PayPal, Amazon, Ebay, GMail and my bank accounts work with https. I don't need my addons for these sites and I would appreciate if I could auto-disable them for https. Password Reuse Visualizer Firefox offers a tool which helps to identify passwords, that get reused often. It is called \" Password Reuse Visualizer \" and looks like this: Password Reuse Visualizer Material I've used famfamfam slik icons . For the menus I've used Sans, 14pt, no hinting but Antialiasing. If someone has better options, it would be great if you posted it as a comment. If you just want to see if your problem has already been submitted, go to the issue-list .","tags":"The Web","title":"How Chrome could be improved"},{"url":"https://martin-thoma.com/wie-berechne-ich-das-multiplikativ-inverse-einer-komplexen-zahl/","text":"Im Folgenden werde ich kurz und bÃ¼ndig erklÃ¤ren, wie man das multiplikativ Inverse einer komplexen Zahl berechnet. Beispiel Berechne das multiplikativ Inverse zur komplexen Zahl \\((\\frac{1}{10} + \\frac{1}{5}i)\\) . Das Ergebnis ist von der Form \\((c + di) \\in \\mathbb{C}\\) . Es muss folgende Gleichung erfÃ¼llen: \\((\\frac{1}{10} + \\frac{1}{5}i) \\cdot (c + di) = 1\\) \\(\\Leftrightarrow (\\frac{1}{10} \\cdot c - \\frac{1}{5} d) + (\\frac{1}{5} c + \\frac{1}{10} d)i = 1\\) \\(\\Leftrightarrow (\\frac{1}{10} \\cdot c - \\frac{1}{5} d) = 1 \\land (\\frac{1}{5} c + \\frac{1}{10} d) = 0\\) \\(\\Leftrightarrow \\left( \\begin{array}{c c | c} \\frac{1}{10} & -\\frac{1}{5} & 1 \\\\ \\frac{1}{5} & \\frac{1}{10} & 0 \\end{array} \\right) \\Leftrightarrow \\left( \\begin{array}{c c | c} \\frac{1}{10} & -\\frac{1}{5} & 1 \\\\ 0 & \\frac{1+4}{10} & -2 \\end{array} \\right) = \\left( \\begin{array}{c c | c} \\frac{1}{10} & -\\frac{1}{5} & 1 \\\\ 0 & \\frac{1}{2} & -2 \\end{array} \\right)\\) \\(\\Leftrightarrow \\left( \\begin{array}{c c | c} \\frac{1}{10} & -\\frac{1}{5} & 1 \\\\ 0 & 1 & -4 \\end{array} \\right) \\Leftrightarrow \\left( \\begin{array}{c c | c} \\frac{1}{10} & 0 & 1 - \\frac{4}{5} \\\\ 0 & 1 & -4 \\end{array} \\right) = \\left( \\begin{array}{c c | c} \\frac{1}{10} & 0 & \\frac{1}{5} \\\\ 0 & 1 & -4 \\end{array} \\right)\\) \\(\\Leftrightarrow \\left( \\begin{array}{c c | c} 1 & 0 & 2 \\\\ 0 & 1 & -4 \\end{array} \\right)\\) Das Ergebnis lautet also: Das multiplikativ Inverse zu \\((\\frac{1}{10} + \\frac{1}{5}i)\\) ist \\((2 -4i)\\) . Allgemein Berechne das multiplikativ Inverse zur komplexen Zahl \\((a + bi)\\) . Das Ergebnis ist von der Form \\((c + di) \\in \\mathbb{C}\\) . Es muss folgende Gleichung erfÃ¼llen: \\((a + bi) \\cdot (c + di) = 1\\) \\(\\Leftrightarrow (a c - b d) + (b c + a d)i = 1\\) \\(\\Leftrightarrow (a c - b d) = 1 \\land (b c + a d) = 0\\) Fall 1: a ungleich 0 \\(\\Leftrightarrow \\left( \\begin{array}{c c | c} a & -b & 1 \\\\ b & a & 0 \\end{array} \\right) \\Leftrightarrow \\left( \\begin{array}{c c | c} a & -b & 1 \\\\ 0 & a + \\frac{b&#94;2}{a} & - \\frac{b}{a} \\end{array} \\right) = \\left( \\begin{array}{c c | c} a & -b & 1 \\\\ 0 & \\frac{a&#94;2 + b&#94;2}{a} & - \\frac{b}{a} \\end{array} \\right)\\) \\(\\Leftrightarrow \\left( \\begin{array}{c c | c} a & -b & 1 \\\\ 0 & 1 & -\\frac{b}{a&#94;2 + b&#94;2} \\end{array} \\right) \\Leftrightarrow \\left( \\begin{array}{c c | c} a & 0 & 1 - \\frac{b&#94;2}{a&#94;2 + b&#94;2} \\\\ 0 & 1 & -\\frac{b}{a&#94;2 + b&#94;2} \\end{array} \\right) \\Leftrightarrow \\left( \\begin{array}{c c | c} 1 & 0 & (1 - \\frac{b&#94;2}{a&#94;2 + b&#94;2})/a \\\\ 0 & 1 & -\\frac{b}{a&#94;2 + b&#94;2} \\end{array} \\right)\\) \\(= \\left( \\begin{array}{c c | c} 1 & 0 & (\\frac{a&#94;2 + b&#94;2 - b&#94;2}{a&#94;2 + b&#94;2})/a \\\\ 0 & 1 & -\\frac{b}{a&#94;2 + b&#94;2} \\end{array} \\right) = \\left( \\begin{array}{c c | c} 1 & 0 & \\frac{a}{a&#94;2 + b&#94;2} \\\\ 0 & 1 & -\\frac{b}{a&#94;2 + b&#94;2} \\end{array} \\right)\\) Das Ergebnis lautet also: Das multiplikativ Inverse zu \\((a + bi)\\) ist also in diesem Fall \\((\\frac{a}{a&#94;2 + b&#94;2} - \\frac{b}{a&#94;2 + b&#94;2}i)\\) . Fall a gleich 0 \\(\\Leftrightarrow - b d = 1 \\land b c= 0\\) \\(\\implies c = 0 \\land d = - \\frac{1}{b}\\) Das multiplikativ Inverse zu \\((bi)\\) ist also in diesem Fall \\((0 - \\frac{1}{b}i)\\) = (\\frac{0}{0&#94;2 + b&#94;2} - \\frac{b}{0&#94;2 + b&#94;2}i)$. Ergebnis Ganz allgemein kann man fÃ¼r das multiplikativ Inverse einer beliebigen komplexen Zahl also folgendes Angeben: \\((\\frac{a}{a&#94;2 + b&#94;2} - \\frac{b}{a&#94;2 + b&#94;2}i)\\) . Siehe auch Wikipedia: Komplexe Zahlen , Inverses Element","tags":"German posts","title":"Wie berechne ich das multiplikativ Inverse einer komplexen Zahl?"},{"url":"https://martin-thoma.com/how-to-install-the-latest-latex-version/","text":"I recently had some problems with TikZ because of my outdated LaTeX-Version. Ubuntu does only provide TeX Live 2009. The latest one is TeX Live 2013. As Ubuntu doesn't provide the latest LaTeX-Code, I'll explain how to install it by yourself on an Ubuntu System. What is LaTeX? LaTeX is a document markup language. So with LaTeX you're able to write math formula like \\(\\sum_{i=0}&#94;\\infty \\frac{1}{2&#94;i} = 2\\) . The term LaTeX refers only to the language in which documents are written, not to the editor used to write those documents. In order to create a document in LaTeX, a .tex file must be created using some form of text editor. While most text editors can be used to create a LaTeX document, a number of editors have been created specifically for working with LaTeX. A number of TeX distributions are available, including TeX Live (multiplatform) and MiKTeX (Windows). When I write \"LaTeX\" I think of \"TeX Live\". LaTeX: an Hello World example This is the template I use when I want to write a minimal LaTeX PDF document. You can use it as an example. \\documentclass [a4paper,10pt] { article } \\usepackage { amssymb } % needed for math \\usepackage { amsmath } % needed for math \\usepackage { amsthm } % needed for proof environment \\usepackage [utf8] { inputenc } % this is needed for umlauts \\usepackage [ngerman] { babel } % this is needed for umlauts \\usepackage [T1] { fontenc } % this is needed for correct output of umlauts in pdf \\usepackage { geometry } \\geometry { top=1cm,left=1cm,right=1cm,bottom=1cm } \\pdfinfo { /Author (Martin Thoma) /Title (Analysis I) /Subject (Analysis I) /Keywords (Analysis I; Venn-Diagramm) } \\newtheorem* { vor }{ Voraussetzung } \\newtheorem* { beh }{ Behauptung } \\begin { document } \\section { Hello World } Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. \\subsection { This is an subsection } Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Duis autem vel eum iriure dolor in hendrerit in vulputate velit esse molestie consequat, vel illum dolore eu feugiat nulla facilisis at vero eros et accumsan et iusto odio dignissim qui blandit praesent luptatum zzril delenit augue duis dolore te feugait nulla facilisi. Lorem ipsum dolor sit amet, consectetuer adipiscing elit, sed diam nonummy nibh euismod tincidunt ut laoreet dolore magna aliquam erat volutpat. Ut wisi enim ad minim veniam, quis nostrud exerci tation ullamcorper suscipit lobortis nisl ut aliquip ex ea commodo consequat. Duis autem vel eum iriure dolor in hendrerit in vulputate velit esse \\end { document } If LaTeX is available on your system, you can create the PDF file from this myDocument.tex file with this command: pdflatex myDocument.tex -output-format = pdf This will create a .log file, an .aux file Here is the LaTeX template with the resulting PDF. Install the latest LaTeX Follow the instructions on tug.org . It's a Network installation, so it will need Internet access. It needs to download about 2 GB so it will take some time. But everything is done automatically. You should remove your old installation before you start the new one: sudo apt-get purge texlive-* sudo apt-get autoremove wget http://mirror.ctan.org/systems/texlive/tlnet/install-tl-unx.tar.gz tar -zxvf install-tl-unx.tar.gz cd install-tl-* sudo ./install-tl I After you've started your installation, you can choose options (O). Then you should choose \"create symlinks in standard directories\" (L). If you didn't do so, add the path to your PATH (See How to add a directory to my path? , How do I add a directory to MANPATH or INFOPATH? and Reload .profile ): PATH = $PATH :/usr/local/texlive/2013/bin/i386-linux/ That's it. So my .profile got these additional lines: if [ -d \"/usr/local/texlive/2013/bin/i386-linux\" ] ; then PATH=\"/usr/local/texlive/2013/bin/i386-linux:$PATH\" fi if [ -d \"/usr/local/texlive/2013/bin/x86_64-linux\" ] ; then PATH=\"/usr/local/texlive/2013/bin/x86_64-linux:$PATH\" fi if [ -d \"/usr/local/texlive/2013/texmf/doc/man\" ] ; then MANPATH=\"/usr/local/texlive/2013/texmf/doc/man:$MANPATH\" fi if [ -d \"/usr/local/texlive/2013/texmf/doc/info\" ] ; then INFOPATH=\"/usr/local/texlive/2013/texmf/doc/info:$INFOPATH\" fi edit: I've just installed TeX-Live 2013 and had to do this: moose@pc07:/usr/bin$ rm latex moose@pc07:/usr/bin$ sudo ln -s /usr/local/texlive/2013/bin/i386-linux/pdflatex latex You can try if your installation works by latex --version : pdfTeX 3.1415926-1.40.10-2.2 (TeX Live 2009/Debian) kpathsea version 5.0.0 Copyright 2009 Peter Breitenlohner (eTeX)/Han The Thanh (pdfTeX). There is NO warranty. Redistribution of this software is covered by the terms of both the pdfTeX copyright and the Lesser GNU General Public License. For more information about these matters, see the file named COPYING and the pdfTeX source. Primary author of pdfTeX: Peter Breitenlohner (eTeX)/Han The Thanh (pdfTeX). Compiled with libpng 1.2.42; using libpng 1.2.42 Compiled with zlib 1.2.3.3; using zlib 1.2.3.3 Compiled with poppler version 0.12.4 If an old version is shown, you might want to see where it is located: which latex Update cd /usr/local/texlive/2013/bin/i386-linux sudo ./tlmgr update --self sudo ./tlmgr update --all See also Wikipedia: LaTeX , TeX Live Wikibooks: LaTeX , LaTeX-Kompendium (German) UbuntuUsers (German): LaTeX","tags":"My bits and bytes","title":"How to install the latest LaTeX Version"},{"url":"https://martin-thoma.com/incredible-optical-illusions/","text":"Some really great and short examples of illusions. If you want an explanation of them, I have added a link to the corresponding Wikipedia article. Checker shadow illusion Checker shadow illusion Checker shadow illusion : The pieces A and B are of the same color. Ebbinghaus illusion Ebbinghaus illusion Ebbinghaus illusion : the first central circle seems to be smaller than the second central circle although they are of identical size. The MÃ¼ller-Lyer illusion is simmilar. Fraser spiral illusion Fraser spiral illusion Although you think you see a spiral, there are only concentric circles. This illusion is known as Fraser spiral illusion . Grid illusion Grid illusion Dark dots seem to appear and disappear in the Grid illusion . Jastow illusion Jastrow illusion In Jastow illusion , the two figures are identical, although the lower one appears to be larger. ZÃ¶llner illusion ZÃ¶llner illusion In the figure of ZÃ¶llner illusion the black lines seem to be unparallel, but in reality they are parallel. Hering illusion Hering illusion Hering illusion : Two straight and parallel lines look as if they were bowed outwards. Spinning Dancer This image is the only animated one in this post. Spinning Dancer Spinning Dancer : If the foot touching the ground is perceived to be the left foot, the dancer appears to be spinning clockwise (if seen from above); if it is taken to be the right foot, then she appears to be spinning counterclockwise. Illusory motion Illusory motion Illusory motion : This image is not animated! CafÃ© wall illusion CafÃ© wall illusion CafÃ© wall illusion : the parallel straight dividing lines between staggered rows with alternating black and white \"bricks\" appear to be sloped","tags":"The Web","title":"Incredible Optical Illusions"},{"url":"https://martin-thoma.com/learn-how-to-type/","text":"keybr keybr.com is another service that helps you to learn how to type.","tags":"The Web","title":"Learn how to type"},{"url":"https://martin-thoma.com/eigenschaften-von-abbildungsmatrizen/","text":"Eine Abbildungsmatrix beschreibt eine lineare Abbildungs zwischen zwei endlichdimensionalen VektorrÃ¤umen. Sie ist abhÃ¤ngig von der Basis des Urraums und des Zielraumes. Formale Definition Eine Lineare Abbildung \\(\\Phi\\) muss folgende Eigenschaften erfÃ¼llen: \\(\\Phi: V \\rightarrow W\\) ist eine Abbildung \\(\\forall x, y \\in W : \\Phi(x+y) = \\Phi(x) + \\Phi(y)\\) \\(\\forall x \\in W : \\forall a \\in \\mathbb{K}: \\Phi(a \\cdot x) = a \\cdot \\Phi(x)\\) Sei V ein n-dimensionaler \\(\\mathbb{K}\\) -Vektorraum mit der Basis \\(B = \\{b_1, b_2, ..., b_n\\}\\) und W ein m-dimensonaler \\(\\mathbb{K}\\) -Vektorraum mit der Basis \\(C = \\{c_1, c_2, ..., c_m\\}\\) . Sei \\(\\Phi:V \\rightarrow W\\) eine lineare Abbildung. Dann ordnen wir der linearen Abbildung \\(\\Phi\\) in folgender Weise eine Matrix A zu: \\(\\Phi (b_k) = \\sum_{i=1}&#94;{m} a_{ik}c_i, ~~ k = 1, ..., n, ~~ a_{ik}\\in \\mathbb{K}\\) Dann gilt: \\(\\Phi(x) = A \\cdot x ~~~\\text{ mit } x \\in V\\) Diese Matrix A nennt man Abbildungsmatrix . Beispiele Sei \\(\\Phi: \\mathbb{R}&#94;4 \\rightarrow \\mathbb{R}&#94;3\\) . Nullzeile \\(A_1 = \\left . \\underbrace{ \\begin{pmatrix} 0 &amp; 0 &amp; 0 &amp; 0 \\\\1 &amp; 2 &amp; 3 &amp; 4 \\\\5 &amp; 6 &amp; 7 &amp; 8 \\end{pmatrix} }_\\text{dim V} \\right \\} \\text{dim W}\\) Standardbasis Sei \\(B_S = ( \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} , \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix} , \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix} , \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix} )\\) und \\(C_S = ( \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} , \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} , \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} )\\) Also sind B und C die geordnete Standardbasis des \\(\\mathbb{R}&#94;4\\) bzw. des \\(\\mathbb{R}&#94;3\\) . Was macht nun eine Abbildung \\(\\Phi\\) mit der Matrix \\(A_1\\) ? Ich denke ist ist leicht ersichtlich, dass bei einer Abbildungsmatrix dieser Form die erste Komponente des Bildvektors immer 0 ist. \\(\\Phi_1( \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{pmatrix} ) = \\begin{pmatrix} 0 \\\\ 30 \\\\ 70 \\end{pmatrix} \\) (siehe Wolfram|Alpha ) \\(\\Phi_1( \\begin{pmatrix} 5 \\\\ -2 \\\\ 7 \\\\ -1 \\end{pmatrix} ) = \\begin{pmatrix} 0 \\\\ 18 \\\\ 54 \\end{pmatrix} \\) (siehe Wolfram|Alpha ) Andere Basis Sei \\(B_1 = ( \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{pmatrix} , \\begin{pmatrix} 1 \\\\ 3 \\\\ 3 \\\\ 7 \\end{pmatrix} , \\begin{pmatrix} 3 \\\\ 1 \\\\ 4 \\\\ 1 \\end{pmatrix} , \\begin{pmatrix} 2 \\\\ 7 \\\\ 1 \\\\ 8 \\end{pmatrix} )\\) und \\(C_1 = ( \\begin{pmatrix} 2 \\\\ 3 \\\\ 5 \\end{pmatrix} , \\begin{pmatrix} 3 \\\\ 5 \\\\ 7 \\end{pmatrix} , \\begin{pmatrix} 5 \\\\ 7 \\\\ 11 \\end{pmatrix} )\\) Auch hier schauen wir uns wieder die Abbildung \\(\\Phi\\) mit der Abbildungsmatrix \\(A_1\\) an. \\(\\Phi_1(\\underbrace{ \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{pmatrix} }_\\text{in Basis C}) = A_1 \\cdot \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{pmatrix} = \\underbrace{ \\begin{pmatrix} 0 \\\\ 30 \\\\ 70 \\end{pmatrix} }_\\text{in Basis B}\\) Auch hier ist also die erste Komponente jedes Bildvektors 0. Allerdings haben die Bildvektoren nun eine andere Basis. Sie werden sozusagen anders interpretiert. Nullspalte \\(A_2 = \\begin{pmatrix} 0 &amp; 1 &amp; 2 &amp; 3 \\\\0 &amp; 4 &amp; 5 &amp; 6 \\\\0 &amp; 7 &amp; 8 &amp; 9 \\end{pmatrix} \\) Nun mal wieder zwei Beispiel-Abbildungen: \\(\\Phi_2( \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{pmatrix} ) = \\begin{pmatrix} 20 \\\\ 47 \\\\ 74 \\end{pmatrix} \\) (siehe Wolfram|Alpha ) \\(\\Phi_2( \\begin{pmatrix} 100 \\\\ 2 \\\\ 3 \\\\ 7 \\end{pmatrix} ) = \\begin{pmatrix} 20 \\\\ 47 \\\\ 74 \\end{pmatrix} \\) (siehe Wolfram|Alpha ) Wenn die Abbildungsmatrix eine Nullspalte hat, ist es egal was der abzubildende Vektor als Eintrag an dieser Stelle hat. Basiswechsel bei Abbildungen Ich habe ja gerade veranschaulicht, dass bei einem Basiswechsel zwar die Abbildung gleich bleibt, es aber dennoch unterschiedliche Vektoren sind. Sie mÃ¼ssen halt unterschiedlich interpretiert werden. Nun kÃ¶nnte man die Abbildung, also insbesondere die Matrix, so Ã¤ndern, dass die Vektoren, die man als \"gleich\" interpretieren wÃ¼rde, gleich abgebildet werden. Wir suchen also eine neue Abbildungsmatrix \\(A_1'\\) , die die gleiche Abbildung beschreibt wie \\(A_1\\) mit den Standardbasen, nur von \\(B_1\\) nach \\(C_1\\) . Wenn man das machen will, kann man sich den Vorgang wie eine Ansammlung von Funktionen (im Sinne der Informatik) betrachten. Wir haben eine Funktion, die die Abbildung von der Standardbasis in die Standardbasis beschreibt. Als Input bekommen wir einen Vektor in der Basis \\(B_1\\) und herauskommen soll ein Vektor in der Basis \\(C_1\\) . Wir mÃ¼ssen also den Input-Vektor von der Basis \\(B_1\\) in die Standardbasis umwandeln und den Output-Vektor der gegebenen Funktion von der Standardbasis in die Basis \\(C_1\\) konvertieren. Dazu bestimmen wir zuerst die Basiswechselmatrix \\(T_S&#94;{B1}\\) von der Basis \\(B_1\\) in die Standardbasis. Das ist genau die Basis selbst: $$T_{B1}&#94;S = \\begin{pmatrix} 1 & 1 & 3 & 2 \\\\ 2 & 3 & 1 & 7 \\\\ 3 & 3 & 4 & 1 \\\\ 4 & 7 & 1 & 8 \\end{pmatrix}$$ (siehe alten Blogpost ) Und die Basiswechselmatrix \\(T_S&#94;{C1}\\) von der Standardbasis in die Basis \\(C_1\\) . Das ist das Inverse der Basis \\(C_1\\) : $$ T_S&#94;{C1} = \\frac{1}{2} \\cdot \\begin{pmatrix} -6 & -2 & 4 \\\\ -2 & 3 & -1 \\\\ 4 & -1 & -1 \\end{pmatrix} $$ Insgesamt sieht das dann so aus: \\(T_S&#94;{C1} \\cdot (A_1 \\cdot (T_{B1} \\cdot x))\\) . Da fÃ¼r die Matrixmultiplikation das Assoziativgesetz gilt, kann man das vereinfachen: $$ A_1â€² = T_S&#94;{C1} \\cdot A_1 \\cdot T_{B1}&#94;S = \\begin{pmatrix} 110 & 156 & 93 & 195 \\\\ 10 & 16 & 3 & 15 \\\\ -50 & -72 & -39 & -87 \\end{pmatrix} $$ (siehe Wolfram|Alpha ) Ein Test ob es stimmen kann: z.B. sind \\( \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{pmatrix} _S = 1 \\cdot \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{pmatrix} + 0 \\cdot \\begin{pmatrix} 1 \\\\ 3 \\\\ 3 \\\\ 7 \\end{pmatrix} + 0 \\cdot \\begin{pmatrix} 3 \\\\ 1 \\\\ 4 \\\\ 1 \\end{pmatrix} + 0 \\cdot \\begin{pmatrix} 2 \\\\ 7 \\\\ 1 \\\\ 8 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} _{B_1} $ und $ \\begin{pmatrix} 0 \\\\ 30 \\\\ 70 \\end{pmatrix} _S = 110 \\cdot \\begin{pmatrix} 2 \\\\ 3 \\\\ 5 \\end{pmatrix} + 10 \\cdot \\begin{pmatrix} 3 \\\\ 5 \\\\ 7 \\end{pmatrix} -50 \\cdot \\begin{pmatrix} 5 \\\\ 7 \\\\ 11 \\end{pmatrix} = \\begin{pmatrix} 110 \\\\ 10 \\\\ -50 \\end{pmatrix} _{C_1}\\) \\( \\begin{pmatrix} 110 &amp; 156 &amp; 93 &amp; 195 \\\\ 10 &amp; 16 &amp; 3 &amp; 15 \\\\ -50 &amp; -72 &amp; -39 &amp; -87 \\end{pmatrix} \\cdot \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} _{B_1} = \\begin{pmatrix} 110 \\\\ 10 \\\\ -50 \\end{pmatrix} \\) (siehe Wolfram|Alpha ) Ich habe keine Ahnung, wie man nur mit den Basen B und C und der Abbildungsmatrix \\(A_1'\\) wieder auf die Abbildungsmatrix \\(A_1\\) kommt. Ich habe auf Stackexchange mal nachgefragt, aber das ist nicht von Erfolg gekrÃ¶nt gewesen. Anzahl der Abbildungsmatrizen FÃ¼r jede lineare Abbildungen \\(\\Phi: V \\rightarrow W\\) (wobei V und W endliche VektorrÃ¤ume sind) gibt es eine Abbildungsmatrix. Wie sieht dann die Abbildungsmatrix folgender Abbildung aus? Sei \\(V:= \\{p \\in \\mathbb{R}[t] | deg(t) \\leq 5 \\}\\) der Vektorraum aller Polynome in t mit reellen Koeffizienten und Grad \\( \\leq 5\\) . Sei \\(F: V \\rightarrow V\\) die Shift-Abbildung \\((Fp)(t) = p(t+1)\\) (Quelle: Matheraum.de ) Wenn V allerdings der \\(\\mathbb{Z}/ 2 \\mathbb{Z}\\) und W der \\(\\mathbb{Z}/ 3 \\mathbb{Z}\\) Ã¼ber jeweils den KÃ¶rper \\(\\mathbb{Z}/ 2 \\mathbb{Z}\\) sind, dann ist die Abbildungsmatrix eine 1x1 Matrix. Das eine Element dieser 1x1 Matrix kann zwei verschiedene Werte - 0 und 1 - annehmen. Selbst wenn W der \\(\\mathbb{Z}/ 41 \\mathbb{Z}\\) wÃ¤re, wÃ¼rde es nur zwei verschiedene Abbildungen geben. Wenn V der \\(\\mathbb{Z}/ 3 \\mathbb{Z}\\) und W der \\(\\mathbb{Z}/ 2 \\mathbb{Z}\\) ist, dann gibt es nur eine lineare Abbildung \\(\\Phi: V \\rightarrow W\\) (die Nullabbildung). Die Abbildungsmatrix \\( \\begin{pmatrix}1\\end{pmatrix} \\) bezeichnet keine lineare Abbildung \\(\\Phi\\) , da 2 in V ist, aber nicht in W. Es scheint also so zu sein, dass man im Allgemeinen nichts Ã¼ber die Anzahl der linearen Abbildungen sagen kann. Dies und das Zwei lineare Abbildungen kÃ¶nnen hintereinander ausgefÃ¼hrt werden, indem ihre Matrizen multipliziert werden: \\(\\Phi_1 : V \\rightarrow W, \\Phi_1(x) := A_1 \\cdot x\\) \\(\\Phi_2 : W \\rightarrow X, \\Phi_2(x) := A_2 \\cdot x\\) \\(\\Phi_2 \\circ \\Phi_1 : V \\rightarrow X, x \\mapsto \\Phi_2 \\circ \\Phi_1(x) := \\Phi_2(\\Phi_1(x)) = A_2 \\cdot (A_1 \\cdot x) = (A_2 \\cdot A_1) \\cdot x\\) Der Rang der Abbildungsmatrix entspricht der Dimension des Bildes der Abbildung. Siehe auch Wikipedia: Vektorraum , Abbildungsmatrix , Rang Wie bestimme ich die Basiswechselmatrix? Skript von Prof. Dr. Leunzinger, ab S. 101 (im passwortgeschÃ¼tzten VAB )","tags":"German posts","title":"Eigenschaften von Abbildungsmatrizen"},{"url":"https://martin-thoma.com/wie-bestimme-ich-das-inverse-einer-matrix/","text":"Nicht alle Matrizen sind invertierbar. Matrizen, die invertierbar sind, nennt man auch regulÃ¤r. Die Menge aller invertierbaren \\(n \\times n\\) â€“Matrizen Ã¼ber einem GrundkÃ¶rper (oder Grundring) K bildet eine Gruppe bezÃ¼glich der Matrixmultiplikation, die allgemeine lineare Gruppe \\(GL_n(K)\\) . Das Inverse einer Matrix A wird berechnet, indem eine Matrix (A|E) gebildet wird und mit dem GauÃŸschem Eliminationsverfahren in \\((E | A&#94;{-1})\\) aufgelÃ¶st wird. Beispiel Ein Inverses existiert \\(\\left( \\begin{array}{c c c c | c c c c} 4 & 2 & 4 & 2 & 1 & 0 & 0 & 0 \\\\ 3 & 1 & 4 & 1 & 0 & 1 & 0 & 0\\\\ 2 & 7 & 1 & 8 & 0 & 0 & 1 & 0\\\\ 0 & 1 & 1 & 2 & 0 & 0 & 0 & 1 \\end{array} \\right) \\rightsquigarrow \\left( \\begin{array}{c c c c | c c c c} 2 & 1 & 2 & 1 & \\frac{1}{2} & 0 & 0 & 0 \\\\ 0 & -\\frac{1}{2} & 1 & -\\frac{1}{2} & -\\frac{3}{4} & 1 & 0 & 0\\\\ 0 & 6 & -1 & 7 & -\\frac{1}{2} & 0 & 1 & 0\\\\ 0 & 1 & 1 & 2 & 0 & 0 & 0 & 1 \\end{array} \\right)\\) \\(\\rightsquigarrow&#94;* \\frac{1}{8} \\begin{pmatrix} 12 & -12 & -2 & 2 \\\\ -16 & 18 & 5 & -13 \\\\ -8 & 10 & 1 & -1 \\\\ 12 & -14 & -3 & 11 \\end{pmatrix} \\) (siehe Wolfram|Alpha ) Kein Inverses existiert Matrizen, zu denen kein Inverses existiert, werden singulÃ¤r genannt. Das ist ein Beispiel: \\( \\begin{pmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 1 & 0 \\end{pmatrix} \\) (siehe Wolfram|Alpha ) Sobald also erkennbar ist, dass beim Eliminationsverfahren eine Nullzeile auftritt, kann man abbrechen. Matrizen, die nicht quadratisch sind, haben kein Inverses: \\( \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 0 & 0 & 2 \\end{pmatrix} \\) (siehe Wolfram|Alpha ) Siehe auch Wikipedia: RegulÃ¤re Matrix , GauÃŸsches Eliminationsverfahren Skript von Prof. Dr. Leuzinger, ab S. 53","tags":"German posts","title":"Wie bestimme ich das Inverse einer Matrix?"},{"url":"https://martin-thoma.com/wie-bestimme-ich-die-basiswechselmatrix/","text":"Eine Basiswechselmatrix oder auch Ãœbergangsmatrix dient dem Basiswechsel. Angenommen man hat zwei Basen des \\(\\mathbb{R}&#94;2\\) -Vektorraumes: $$B = \\{\\overbrace{\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}}&#94;{b_1}, \\overbrace{\\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix}}&#94;{b_2} \\}$$ und $$\\bar B = \\{\\underbrace{\\begin{pmatrix} 3 \\\\ 5 \\end{pmatrix}}_{\\bar b_1}, \\underbrace{\\begin{pmatrix} 8 \\\\ 13 \\end{pmatrix}}_{\\bar b_2} \\}$$ Sei nun \\(v := \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\) ein Vektor zur Standardbasis. Da \\(B\\) und \\(\\bar B\\) auch Basen des \\(\\mathbb{R}&#94;2\\) sind, kann man v auch zu diesen Basen darstellen: \\(\\Theta_{B}(v) = \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix} \\) und \\(\\Theta_{\\bar B}(v) = \\begin{pmatrix} -5 \\\\ 2 \\end{pmatrix} \\) Wie kann man nun diese neue Darstellung berechnen? Nun, wir bestimmen eine Matrix A fÃ¼r die gilt: \\(A \\cdot \\Theta_B(v) = \\Theta_{\\bar B}(v) ~~~ \\forall v \\in \\mathbb{R}&#94;2\\) . Diese Matrix findet man, indem man beide geordneten Basen nebeneinander schreibt und die rechte Seite \"durchgauÃŸt\": (\\left( \\begin{array}{c c | c c} 1 & 2 & 3 & 8 \\\\ 2 & 3 & 5 & 13 \\end{array} \\right) \\rightsquigarrow \\left( \\begin{array}{c c | c c} \\frac{1}{3} & \\frac{2}{3} & 1 & \\frac{8}{3} \\\\ 2 & 3 & 5 & 13 \\end{array} \\right) \\rightsquigarrow \\ \\left( \\begin{array}{c c | c c} \\frac{1}{3} & \\frac{2}{3} & 1 & \\frac{8}{3} \\\\ \\frac{6-5}{3} & \\frac{9-10}{3} & 0 & \\frac{39-8 \\cdot 5}{3} \\end{array} \\right) \\rightsquigarrow \\left( \\begin{array}{c c | c c} \\frac{1}{3} & \\frac{2}{3} & 1 & \\frac{8}{3} \\\\ \\frac{1}{3} & -\\frac{1}{3} & 0 & -\\frac{1}{3} \\end{array} \\right) \\rightsquigarrow \\ \\left( \\begin{array}{c c | c c} \\frac{9}{3} & -\\frac{6}{3} & 1 & 0 \\\\ \\frac{1}{3} & -\\frac{1}{3} & 0 & -\\frac{1}{3} \\end{array} \\right) \\rightsquigarrow \\left( \\begin{array}{c c | c c} 3 & -2 & 1 & 0 \\\\ -1 & 1 & 0 & 1 \\end{array} \\right)) Links steht die geordnete Basis B und rechts die geordnete Basis \\(\\bar B\\) , also (von | nach) und rechts wendet man GauÃŸ an. Nun noch die Kontrolle, ob es stimmen kann: $$\\underbrace{\\begin{pmatrix} 3 & -2 \\\\ -1 & 1 \\end{pmatrix}}_{A_{B \\bar B}} \\cdot \\underbrace{\\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix}}_{\\Theta_{B}(v)} = \\underbrace{\\begin{pmatrix} -5 \\\\ 2 \\end{pmatrix}}_{\\Theta_{\\bar B}(v)}$$ Siehe auch Wikipedia: Basiswechsel (Vektorraum) , Standardbasis Skript von Prof. Dr. Leuzinger, ab S. 82","tags":"German posts","title":"Wie bestimme ich die Basiswechselmatrix?"},{"url":"https://martin-thoma.com/typography-word-as-image/","text":"Challenge: Create an image out of a word, using only the letters in the word itself. Rule: Use only the graphic elements of the letters without adding outside parts.","tags":"Cyberculture","title":"Typography: Word as Image"},{"url":"https://martin-thoma.com/computer-science-jokes/","text":"You have to read What is your best programmer joke? , What was the strangest coding standard rule that you were forced to follow? and What is the best comment in source code you have ever encountered? Hello World Cartoon Programming is like sex: One mistake and you have to support it for the rest of your life. Write 500 words on board with C++ What's the difference between drug dealers and computer programmers? Drug Dealers Computer Programmers Refer to their clients as \"users\". Refer to their clients as \"users\". \"The first one's free!\" \"Download a free trial versionâ€¦\" Have important South-East Asian connections (to help move the stuff). Have important South-East Asian connections (to help debug the code). Strange jargon: \"Stick,\" \"Rock,\" \"Dime bag,\" \"E\". Strange jargon: \"SCSI,\" \"RTFM,\" \"Java,\" \"ISDN\". Realize that there's tons of cash in the 14- to 25-year-old market. Realize that there's tons of cash in the 14- to 25-year-old market. Job is assisted by the industry's producing newer, more potent mixes. Job is assisted by industry's producing newer, faster machines. Often seen in the company of pimps and hustlers. Often seen in the company of marketing people and venture capitalists. Their product causes unhealthy addictions. DOOM. Quake. FarmVille. CS. â€˜Nuff said. Do your job well, and you can sleep with sexy movie stars who depend on you. Damn! Damn! DAMN!!! xkcd: Compiling ME: You should really think about a new monitor. CLIENT: I would, but I don&rsquo;t want to lose my icons. (Source: Clients From Hell) Computer Science Major - possibly from abstrusegoose There are 10 types of people: those who understand binary, and those who do not understand it. Why people seem to have freetime More Jokes! Bash.org Bastard Operator from Hell Clients From Hell cs.cmu.edu","tags":"Cyberculture","title":"Computer Science Jokes"},{"url":"https://martin-thoma.com/abschlussaufgaben-programmieren/","text":"Hinweis : Dieser Blogpost ist vermutlich nur fÃ¼r Informatik-Studenten am KIT im WS 2011 / 2012 interessant! Hier ein paar Hinweise zu den Abschlussaufgaben aus dem Forum. Dabei habe ich die Antworten von jgraf, mmohr und praktomat genommen. Allgemeines Was wir absolut nicht sehen wollen sind grosse Methoden, die verstreut Ã¼ber den ganzen Code diverse returns enthÃ¤lt. Eventuell sollte man diese Methode dann ohnehin in Hilfsmethoden aufteilen. Parameter: Die Anzahl der Parameter muss exakt stimmen. Sind zu Ã¼berzÃ¤hlige Parameter vorhanden, muss ein Fehler ausgegeben werden. toString/equals: Sollte nur fÃ¼r Klassen geschrieben werden, bei denen es Sinn macht. Vor allem auf eins aufpassen: Wenn man equals Ã¼berschreibt, dann sollte man auch hashCode Ã¼berschreiben (siehe docs.oracle.com ) bzw, beliebige suche nach \"equals hashCode\"). Mir fallen spontan wenige FÃ¤lle ein, wo es keinen Sinn macht, equals()/hashCode() oder toString() zu Ã¼berschreiben. Die Shell ist vielleicht so ein Fall, oder auch Utility-Klassen. Verbergt die tatsÃ¤chlichen Typen, woimmer es mÃ¶glich ist! Also z.B. private Map meineMap = new HashMap (); Frage: DÃ¼rfen Strings direkt im Programmcode stehen, oder sollten diese gesammelt am Beginn einer Klasse stehen? Antwort: Kommt darauf an, wenn Sie mehr als eimal verwendet werden, dann sollte man Konstanten daraus machen. Frage: Soll die Shell nur korrekte Werte an den eigentlichen LittlePraktomat Ã¼bergeben, also alle Fehlerquellen bereits in der Shell-Klasse abgefangen werden oder soll der LittlePraktomat Exceptions werfen, die in der Shell dann gefangen werden? Oder soll beides gemacht werden? Antwort: Die Ã¶ffentlichen Methoden einer Klasse sind deren Schnittstelle. In den Javadoc Kommentaren sollte stehen, wie diese Schnittstelle zu verwenden ist. Also welcher Art die Eingaben sein mÃ¼ssen und wie die Ausgaben aussehen. Wenn sich ein Aufrufer nicht and diese Vereinbarung hÃ¤lt, dann sollte die Methode der Schnittstelle eine Exception werfen (IllegalArgument, NullPointer, ...). Diese Exceptions sollten normalerweise nie vom Aufrufer gefangen werden. Sie sollen das Program kontrolliert zum Absturz bringen. Die Logik dahinter ist folgende: Wenn eine IllegalArgumentException (oder Ã¤hnliches) fliegt, dann wurde eine Schnittstelle falsch verwendet. Der Aufrufer der Schnittstelle hat aber vor dem Aufruf sicher zu stellen, dass alle Forderungen der Schnittstelle eingehalten werden. D.h. wenn eine solche Exception auftritt liegt ein Programmierfehler vor. Mit Hilfe des Exceptionstacktrace kann der Entwickler diesen realtiv bequem finden und beheben. Es ist also beides zu machen, die Shell (der Aufrufer) hat vor dem Verwenden der Praktomat-Schnittstelle sicher zu stellen, dass alle Eingaben korrekt sind. Sind die Eingaben falsch, dann wird eine Fehlermeldung ausgegeben. Die Praktomat-Schnittstelle schÃ¼tzt sich vor falscher Verwendung mit Hilfe von Exceptions. Tests Ihr mÃ¼sst eine Tests.txt mit abgeben. Die ist wie ein Beispiel aufgebaut und sollt wichtige Eingaben / Ausgaben enthalten, die eventuell zu Fehlern fÃ¼hren kÃ¶nnten. Da ihr sie ja sowieso schreibt, kÃ¶nnt ihr euer Programm auch auf eure Tests.txt Ã¼berprÃ¼fen. Ich habe mir dazu folgendes kleines Python-Script zum Vergleichen gebastelt und vergleiche dann den normalisierten realen Output mit hilfe von Meld mit dem erwartetem Output. Also folgendes in der Bash: python checkTests.py meld ../tmp/createdOutputNormalized.txt ../tmp/compareTo.txt Ihr mÃ¼sst halt noch die Pfade anpassen. Abschlussaufgabe 1 Folgendes zum LittlePraktomat: Falls die Namen von Personen etwas anderes als Kleinbuchstaben haben (also z.B. GroÃŸbuchstaben!) soll ein Fehler ausgegeben werden. Ã¤Ã¶Ã¼ mÃ¼ssen nicht als Kleinbuchstaben erkannt werden, a-z reicht. Abschlussaufgabe 2 Folgendes zu Othello : Wer sehr schnell die Aufgabe erledigt hatte (also noch am ersten Tag), dem fehlen hier eventuell ein paar Sachen. Habt ihr den hole-Befehl? Falls ja, ist alles ok. Sonst solltet ihr nochmals rein schauen und eure LÃ¶sung nochmals hochladen, weil eine veraltete Aufgabenstellung zu beginn hochgeladen wurde. Eine gÃ¼ltige SpielfeldgrÃ¶ÃŸe MUSS gerade breite / hÃ¶he haben, grÃ¶ÃŸer als 0x0 sein und kleiner gleich 26x98 sein. Ein gÃ¼ltiges Rechteck MUSS die erste Koordinate links oben und die zweite rechts unten haben! Es gibt folgende Befehle: newGame [ ] hole move print abort possibleMoves quit Daten Abschlussaufgabe 1 : 01.02.2012 - 12.03.2012 FunktionalitÃ¤t: 0 - 7 Punkte Programmiermethodik: 0 - 7 Punkte Endnote = (2 Â· FunktionalitÃ¤t + Programmiermethodik) Abschlussaufgabe 2 : 13.02.2012 - 26.03.2012, 13:00 Uhr FunktionalitÃ¤t: 0 - 7 Punkte Programmiermethodik: 0 - 7 Punkte Endnote = (2 Â· FunktionalitÃ¤t + Programmiermethodik) Ergebnisse Mir wird, wenn ich im Abschlussaufgaben-Praktomat auf \"Home\" klicke, bereits angezeigt, dass es anscheinend maximal 24 Punkte auf die \"AbschluÃŸaufgabe 1: Little Praktomat\" gibt. Bin ja mal gespannt, wann es Ergebnisse gibt. Es gab jeweils auf FunktionalitÃ¤t und Programmiermethodik 14 Punkte, wobei die Punktzahl der FunktionalitÃ¤t verdoppelt wurde. Damit kommen wir insgesamt auf 2 * (14*2 + 14)= 84 Punkte. Der NotenschlÃ¼ssel ist wie folgt: Bewertungspunkte Gesamtnote 82,0 - 84,0 1,0 78,0 - 81,5 1,3 74,0 - 77,5 1,7 70,0 - 73,5 2,0 66,0 - 69,5 2,3 62,0 - 65,5 2,7 58,0 - 61,5 3,0 54,0 - 57,5 3,3 50,0 - 53,5 3,7 46,0 - 49,5 4,0 0 - 45,5 5,0 - nicht bestanden Meine Abgabe LittlePraktomat: Klassendiagramm + JavaDoc + Java Source Code Othello: JavaDoc + Java Source Code Fehlerquellen Es wurde bemÃ¤ngelt, dass ich wenig Kommentare hab. Ich finde, ich habe wahnsinnig viele ... LittlePraktomat Test 4 : Eingabe: list-solutions 99999999999999999999 Exception in thread \"main\" java.lang.NumberFormatException - die Zahl ist zu groÃŸ Test 7 : Aus BlÃ¶dheit nicht bestanden ... ich habe eine Funktion (das wechseln von Tutoren) nicht Ã¼berprÃ¼ft. Othello Test 6 b : Direkt nach dem Start des Programms \"hole A1:A1\" hat eine (meiner eigenen) Exceptions geworfen ... bzw. mit korrekter Angabe, wo der Fehler liegt ... also auch Dummheit argh","tags":"German posts","title":"Abschlussaufgaben Programmieren"},{"url":"https://martin-thoma.com/how-to-fill-holes-in-your-wall-ceiling/","text":"Do-it-yourself - Some random tools (Thumbnail) I've decided to fill some holes in my ceiling and my wall today. I don't want to paint my room the next time as it is too cold at the moment, but the holes were really ugly. I've added a photo of them. So I went to the next hardware store and asked what could be done. I thought I needed to use gypsum which is gray, so it wouldn't look very good. Additionally you can buy gypsum only in 1.5 kg bags. Situation before Holes in the ceiling The tools The guy at the hardware store suggested to use acrylic paint. So I did. These were the tools I needed: Acrylic paint : about 4.00 Euro some masking tape a putty knife Masking tape and putty knife Acrylic paint One special problem As I had a wall plug in my ceiling I needed to remove it before I could start. I could not simply push it into the wall (it didn't work, I've tried it). And removing this special wall plug isn't that easy. This is how it looks like in the wall: Wall plug So I tried to stretch it: Stretching the wall plug with the hammer didn't work Stretching the wall plug with a wrench worked ... ... kind of Filling the hole First you need to clean both holes so that the acrylic paint can stick. Then you have to use the masking tape to get a clean border: Use the masking tape You have to use the putty knife to get a clean, smooth surface with the acrylic paint. Maybe you need to fill the hole repeatedly with acrylic paint. As soon as the surface looks okay, you can stop. Now remove the masking tape and then wait some hours until the acrylic paint is dry. The time you have to wait depends on the acrylic paint you use, but mine is dry enough for painting after 4 - 6 hours. Situation afterwards Afterwards, it looks like this: Filled hole in the ceiling Hmm ... well ... it looks different when I look at it. I can barely see it as it's not that bright at the ceiling. Nether the less, I will have to paint in the summer.","tags":"My bits and bytes","title":"How to fill holes in your wall / ceiling"},{"url":"https://martin-thoma.com/briefe-mit-latex-schreiben/","text":"Ich muss immer wieder mal KÃ¼ndigungsschreiben aufsetzen. DafÃ¼r will ich eigentlich keine Zeit verschwenden, aber es sollte schon gut aussehen. Also habe ich mir gerade mal eine Vorlage fÃ¼r KÃ¼ndigungsschreiben mit LaTeX und dem scrlttr2 Paket erstellt. Allerdings benutze ich noch die alten KOMA-Variablen. Ich finde mit KOMAold (siehe Beispiel-PDF alt und neu ) sieht es einfach besser aus als mit dem neuen. Obwohl der Unterschied nicht wirklich groÃŸ ist. Hier ist das Archiv mit beiden LaTeX-Dateien, einer Make-Datei und beiden PDF-Dateien. LaTeX \\documentclass [a4paper, 12pt, KOMAold] { scrlttr2 } \\usepackage [utf8] { inputenc } % this is needed for umlauts \\usepackage [ngerman] { babel } % this is needed for umlauts \\usepackage [T1] { fontenc } % needed for right umlaut output in pdf \\usepackage [ngerman, num] { isodate } % get DD.MM.YYYY dates % Anpassen %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\newcommand { \\Vorname }{ Martin } % Vorname % \\newcommand { \\Nachname }{ Thoma } % Nachname % \\newcommand { \\Strasse }{ Parkstra & szlig;e } % Deine Stra&szlig;e % \\newcommand { \\Hausnummer }{ 17 } % Deine Hausnummer % \\newcommand { \\PLZ }{ 76131 } % Deine PLZ % \\newcommand { \\Ort }{ Karlsruhe } % Dein Ort % \\newcommand { \\Kundennr }{ 123456 } % Deine Kundennummer % % \\newcommand { \\Empfaenger }{ DB Fernverkehr AG } % Der EmpfÃ¤nger % \\newcommand { \\EStrasse }{ BahnCard-Service } % Stra&szlig;e des EmpfÃ¤ngers % \\newcommand { \\EPLZ }{ 60643 } % PLZ des EmpfÃ¤ngers % \\newcommand { \\EOrt }{ Frankfurt am Main } % Ort des EmpfÃ¤ngers % % \\newcommand { \\DocTitle }{ KÃ¼ndigung des Bahn-Abos } %Titel des Dokuments% % Datum der KÃ¼ndigung % \\newcommand { \\Kuendigungsdatum }{ nÃ¤chstmÃ¶glichen Termin } % %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % pdfinfo \\pdfinfo { /Author ( \\Nachname , \\Vorname ) /Title ( \\DocTitle ) /Subject ( \\DocTitle ) /Keywords (KÃ¼ndigung) } % set letter variables \\signature { \\Vorname ~ \\Nachname } \\customer { \\Kundennr } \\backaddress { \\Vorname ~ \\Nachname , \\Strasse ~ \\Hausnummer , \\PLZ ~ \\Ort } % Begin document %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\begin { document } \\begin { letter }{ \\Empfaenger \\\\ \\EStrasse \\\\ \\EPLZ ~ \\EOrt } \\date { \\today } %Change this if you want a different date than today \\subject { KÃ¼ndigung } \\opening { Sehr geehrte Damen und Herren, } hiermit kÃ¼ndige ich meinen Vertrag fÃ¼r die Kundennummer \\Kundennr ~ zum \\Kuendigungsdatum . \\\\ \\noindent Ich bitte um eine BestÃ¤tigung der KÃ¼ndigung. \\closing { Mit freundlichen GrÃ¼ & szlig;en, } \\end { letter } \\end { document } Ach ja, weiÃŸ jemand wie man die EinrÃ¼ckung der Unterschrift verhindert?","tags":"German posts","title":"Briefe mit LaTeX schreiben"},{"url":"https://martin-thoma.com/definitionen-aus-gbi/","text":"Formale Sprachen A heiÃŸt Alphabet \\(:\\Leftrightarrow\\) A ist eine endliche, nicht leere Menge aus Zeichen. w heiÃŸt Wort aus \\(A&#94;* : \\Leftrightarrow\\) w ist eine endliche Aneinanderreihung von Zeichen aus A L heiÃŸt formale Sprache \\(: \\Leftrightarrow L \\subseteq A&#94;*\\) G heiÃŸt formale Grammatik \\(: \\Leftrightarrow G = (N, T, S, P)\\) wobei: N die endliche Menge der Nichtterminalsymbole bezeichne, T die endliche Menge der Terminalsymbole mit \\(N \\cap T = \\emptyset\\) bezeichne, \\(S \\in N\\) das Startsymbol, \\(P \\subseteq N \\times (N \\cup T)&#94;*\\) die endliche Menge der Produktionen bezeichne. Es seien \\(L_1\\) und \\(L_2\\) formale Sprachen und \\(n \\in \\mathbb{N}\\) . Dann: \\(L_1 \\cdot L_2 :\\Leftrightarrow \\{w_1 w_2 | w_1 \\in L_1 \\land w_2 \\in L_2\\}\\) \\(L_1 \\cup L_2 :\\Leftrightarrow \\{w | w \\in L_1 \\lor w \\in L_2\\}\\) \\(L_1 \\cap L_2 :\\Leftrightarrow \\{w | w \\in L_1 \\land w \\in L_2\\}\\) \\(L_1 \\setminus L_2 :\\Leftrightarrow \\{w | w \\in L_1 \\land w \\notin L_2\\}\\) \\(L_1&#94;0 :\\Leftrightarrow \\{ \\varepsilon\\}\\) \\(L_1&#94;1 :\\Leftrightarrow L\\) \\(L_1&#94;n :\\Leftrightarrow L_1&#94;{n-1} \\cdot L_1\\) \\(L_1&#94;* :\\Leftrightarrow \\bigcup_{i=0}&#94;\\infty L_1&#94;i\\) \\(L_1&#94;+ :\\Leftrightarrow L_1&#94;* \\setminus L_1&#94;0 = \\bigcup_{i=1}&#94;\\infty L_1&#94;i\\) Kodierungstheorie Seien \\(L_A, L_B\\) formale Sprachen und \\(c: L_A \\rightarrow L_B\\) . c heiÃŸt codierung \\(: \\Leftrightarrow\\) c ist injektiv. \\(L_B\\) heiÃŸt prÃ¤fixfrei \\(: \\Leftrightarrow \\forall_{u, v, w \\in L_B}: uv = w \\Rightarrow u = \\varepsilon \\lor v = \\varepsilon\\) Sei \\(h:A* \\rightarrow B*\\) eine Abbildung. h heiÃŸt Homomorphismus \\(:\\Leftrightarrow h(\\varepsilon) = \\varepsilon \\land \\forall_{x \\in A} \\forall_{w \\in A*}: h(xw) = h(x)h(w)\\) Abbildungen und Relationen Seien A und B Mengen. R heiÃŸt binÃ¤re Relation von A in B \\(:\\Leftrightarrow R \\subseteq A \\times B\\) Sei im Folgendem R eine binÃ¤re Relation von A in B. R ist linkstotal \\(:\\Leftrightarrow \\forall_{a \\in A} : \\exists_{b \\in B} : (a, b) \\in R\\) R ist rechtseindeutig \\(:\\Leftrightarrow \\forall_{a \\in A} : \\forall_{b_1, b_2 \\in B: b_1 \\neq b_2} : (a, b_1) \\in R \\Rightarrow (a, b_2) \\notin R\\) R heiÃŸt Abbildung \\(:\\Leftrightarrow\\) R ist linkstotal und rechtseindeutig. FÃ¼r Abbildungen schreibt man auch: \\(R: A \\rightarrow B\\) . R heiÃŸt linkseindeutig \\(:\\Leftrightarrow \\forall_{(a_1, b_1) \\in R} : \\forall_{(a_2, b_2) \\in R} : (a_1, b_1) \\in R \\Rightarrow (a_2, b_2) \\notin R\\) R heiÃŸt injektiv \\(:\\Leftrightarrow\\) R ist eine linkseindeutige Abbildung. R heiÃŸt rechtstotal \\(:\\Leftrightarrow \\forall_{b \\in B} : \\exists_{a \\in A} : (a, b) \\in R\\) R heiÃŸt surjektiv \\(:\\Leftrightarrow\\) R ist eine rechtstotale Abbildung. R heiÃŸt bijektiv \\(:\\Leftrightarrow\\) R ist eine injektive und surjektive Abbildung R heiÃŸt reflexiv \\(:\\Leftrightarrow \\forall_{x \\in A} : (x, x) \\in R\\) R heiÃŸt symmetrisch \\(:\\Leftrightarrow (x, y) \\in R \\rightarrow (y, x) \\in R\\) R heiÃŸt antisymmetrisch \\(:\\Leftrightarrow (x, y) \\in R \\land (y, x) \\in R \\Rightarrow x = y\\) R heiÃŸt transitiv \\(:\\Leftrightarrow (x, y) \\in R \\land (y, z) \\in R \\Rightarrow (x, z) \\in R\\) R heiÃŸt Halbordnung \\(:\\Leftrightarrow\\) R ist reflexiv, antisymmetrisch und transitiv. Eine Halbordnung ist ein Spezialfall der Ordnungsrelation. R heiÃŸt Ã„quivalenzrelation \\(:\\Leftrightarrow\\) R ist reflexiv, symmetrisch und transitiv. Sei C eine Menge und \\(S \\subseteq B \\times C\\) . \\(S \\circ R = \\{(x,z) \\in M_1 \\times M_3 | \\exists y \\in M_2: (x, y) \\in R \\land (y, z) \\in S\\}\\) Sei M eine Menge und \\(R \\subseteq M \\times M\\) eine Halbordnung. Dann heiÃŸt M halbgeordnet bzw. \\((M, R)\\) halbgeordnete Menge. Sei \\(T \\subseteq M\\) . \\(x \\in T\\) heiÃŸt minimales Element von T \\(:\\Leftrightarrow\\) Es gibt kein \\(y \\in T\\) mit xRy und \\(x \\neq y\\) . \\(x \\in T\\) heiÃŸt kleinstes Element von T \\(:\\Leftrightarrow\\) \\(\\forall_{y \\in T}: xRy\\) . Das maximale Element und das grÃ¶ÃŸte Element werden analog definiert. R heiÃŸt vollstÃ¤ndige Halbordnung \\(:\\Leftrightarrow\\) R ist eine Halbordnung, besitzt ein kleinstes Element und jede aufsteigende Kette besitzt ein Supremum. R heiÃŸt Totalordnung \\(:\\Leftrightarrow \\forall_{a,b \\in M} : aRb \\lor bRa\\) Sei \\(\\equiv \\subseteq M \\times M\\) eine Ã„quivalenzrelation, \\(f : M \\rightarrow M\\) eine Funktion und \\(\\diamond\\) eine binÃ¤re Operation auf der Menge M. \\(f\\) heiÃŸt vertrÃ¤glich \\(: \\Leftrightarrow \\forall_{x,y \\in M} : x \\equiv y \\Rightarrow f(x) \\equiv f(y)\\) \\(\\diamond\\) heiÃŸt vertrÃ¤glich \\(: \\Leftrightarrow \\forall_{x_1, x_2,y_1, y_2 \\in M} : x_1 \\equiv x_2 \\land y_1 \\equiv y_2 \\Rightarrow x_1 \\diamond y_1 \\equiv x_2 \\diamond y_2\\) KomplexitÃ¤tstheorie Seien \\(f : \\mathbb{N_0} \\rightarrow \\mathbb{R}&#94;+, g : \\mathbb{N_0} \\rightarrow \\mathbb{R}&#94;+\\) Funktionen, die die Laufzeit von Algorithmen beschreiben. \\({\\cal O}(f(n)) = \\{g(n) | \\exists_{n_0 \\in \\mathbb{N}_0} : \\exists_{c \\in \\mathbb{R}&#94;+} : \\forall_{n \\geq n_0}: g(n) \\leq c \\cdot f(n)\\}\\) \\(\\Omega(f(n)) = \\{g(n) | \\exists_{n_0 \\in \\mathbb{N}_0} : \\exists_{c \\in \\mathbb{R}&#94;+} : \\forall_{n \\geq n_0}: g(n) \\geq c \\cdot f(n)\\}\\) \\(\\Theta(f(n)) = \\Omega(f(n)) \\cap {\\cal O}(f(n))\\) Graphentheorie G heiÃŸt Graph \\(: \\Leftrightarrow G = (V, E)\\) , wobei V eine endliche Menge an Knoten ist und \\(E \\subseteq V \\times V\\) die Menge der Kanten bezeichne. Sei G = (V, E) ein Graph. G heiÃŸt ungerichteter Graph \\(: \\Leftrightarrow \\forall_{v_n, v_m \\in V} : (v_n, v_m) \\in E \\Rightarrow (v_m, v_n) \\in E\\) G heiÃŸt gerichteter Graph \\(: \\Leftrightarrow\\) G ist nicht ungerichtet. G heiÃŸt streng zusammenhÃ¤ngend \\(: \\Leftrightarrow \\forall_{x, y \\in V}:\\) Es gibt einen Pfad von x nach y. G heiÃŸt vollstÃ¤ndig \\(: \\Leftrightarrow \\forall_{x, y \\in V}: (x, y) \\in E\\) p heiÃŸt Pfad in G von \\(v_0\\) nach $v_n: \\Leftrightarrow p = (v_0, ..., v_n): \\forall_{i \\in \\mathbb{G} n}: (v_i, v ) \\in E $ Ein Knoten \\(r \\in V\\) heiÃŸt Wurzel \\(: \\Leftrightarrow \\forall_{x \\in V}:\\) Es gibt genau einen Pfad von r nach x. G heiÃŸt Baum \\(: \\Leftrightarrow \\exists r \\in V: \\forall_{x \\in V}\\) Es gibt genau einen Pfad von r nach x.","tags":"German posts","title":"Definitionen aus GBI"},{"url":"https://martin-thoma.com/get-your-programs-assembly-code-and-more-information/","text":"I've talked today with a fellow student about some system internals and we weren't sure what actually happens. So I needed the assembly code of some example programs. General Information It is important to know that I will use AT&T syntax in this article! This is AT&T Syntax: movl %esp, %ebp And this is Intel Syntax: MOVL EBP, ESP Pointers %esp : Stack pointer for top address of the stack. %ebp : Stack base pointer for holding the address of the current stack frame. %eax : Accumulator The size of the eax register will always be 32 bit, regardless of the system's register size. [6] $ Dollar and % Percentage signs \\(i, with $i \\in mathbb{N}\\) , is a constant and percentages mean registers. [10] [11] Instruction pushl : To push the source operand onto the stack [1] movl , : moves a long [2] call : Calls function (which might be printf, putchar, ...) subl $16, %esp : allocate a local variable [3] ret : transfers control back to the place where the current function was called. [3] leave : sets the stack pointer to the base frame address, effectively releasing the whole frame [4] andl $-16, %esp : Ands the stack with fffffff0 which effectivly aligns it on a 16 byte boundary. Access to aligned values on the stack are much faster than if they were unaligned. [5] jmp : Jump to target label. jbe : Jump below or equal. I am not quite sure what is compared ... can anybody help me? leal : Load effective address. [9] The LEA instruction never reads memory, it only computes the address that would be read by another instruction and stores this address in its first register operand. Suffixes Many instructions have suffixes. This is what they mean [6] : b: byte (8 bit) s: short (16 bit integer) or single (32-bit floating point) w: word (16 bit) l: long (32 bit integer or 64-bit floating point) q: quad (64 bit) t: ten bytes (80-bit floating point) Simple example C-Code This program simply outputs #include <stdio.h> int main ( void ) { printf ( \"%i\" , 1337 * 42 ); return 0 ; } Assembly Now I compile it and I save the assembly code: gcc -S test.c ; gcc test.c -o test This gives me test.s (the assembly code) and an executable called \"test\". .file \"test.c\" .section .rodata .LC0: .string \"%i\" .text .globl main .type main, @function main: pushl %ebp movl %esp, %ebp andl $-16, %esp subl $16, %esp movl $.LC0, %eax movl $56154, 4(%esp) movl %eax, (%esp) call printf movl $0, %eax leave ret .size main, .-main .ident \"GCC: (Ubuntu 4.4.3-4ubuntu5) 4.4.3\" .section .note.GNU-stack,\"\",@progbits This is code of the GNU Assembler . I guess other assemblers might produce other code. Could anybody please give me an example of other assemblers? The first and most important thing you might notice is that neither \"1337\" nor \"42\" appear in the assembly code, but 56154 which is 1337*42. I didn't use any optimization options! You might also notice that constants begin with a dollar sign and registers (esp, ebp) begin with a percent sign. The following ones are called assembly directives. They tell the assembler what to do next. .file , .section , .size and .ident are such directives. .data might be the most well-known one and tells the assembler to store something in the data segment of the program. .LC0 is a label for the immediately following string. .globl indicates that the following label (in this case \"main\") is a global symbol. Line 14: I'm not quite sure why you need the 4. I thought the integer size could be the reason (see variable sizes in C ), but as I used a string it still worked. As I used a character, it disappeared. Further information objdump gives even more information! Archive header information: objdump -a test test: file format elf32-i386 test File header information: objdump -f test test: file format elf32-i386 architecture: i386, flags 0x00000112: EXEC_P, HAS_SYMS, D_PAGED start address 0x08048330 Object specific file header contents: objdump -p test test: file format elf32-i386 Program Header: PHDR off 0x00000034 vaddr 0x08048034 paddr 0x08048034 align 2**2 filesz 0x00000100 memsz 0x00000100 flags r-x INTERP off 0x00000134 vaddr 0x08048134 paddr 0x08048134 align 2**0 filesz 0x00000013 memsz 0x00000013 flags r-- LOAD off 0x00000000 vaddr 0x08048000 paddr 0x08048000 align 2**12 filesz 0x000004d8 memsz 0x000004d8 flags r-x LOAD off 0x00000f0c vaddr 0x08049f0c paddr 0x08049f0c align 2**12 filesz 0x00000108 memsz 0x00000110 flags rw- DYNAMIC off 0x00000f20 vaddr 0x08049f20 paddr 0x08049f20 align 2**2 filesz 0x000000d0 memsz 0x000000d0 flags rw- NOTE off 0x00000148 vaddr 0x08048148 paddr 0x08048148 align 2**2 filesz 0x00000044 memsz 0x00000044 flags r-- STACK off 0x00000000 vaddr 0x00000000 paddr 0x00000000 align 2**2 filesz 0x00000000 memsz 0x00000000 flags rw- RELRO off 0x00000f0c vaddr 0x08049f0c paddr 0x08049f0c align 2**0 filesz 0x000000f4 memsz 0x000000f4 flags r-- Dynamic Section: NEEDED libc.so.6 INIT 0x080482bc FINI 0x080484ac HASH 0x0804818c GNU_HASH 0x080481b4 STRTAB 0x08048224 SYMTAB 0x080481d4 STRSZ 0x0000004c SYMENT 0x00000010 DEBUG 0x00000000 PLTGOT 0x08049ff4 PLTRELSZ 0x00000018 PLTREL 0x00000011 JMPREL 0x080482a4 REL 0x0804829c RELSZ 0x00000008 RELENT 0x00000008 VERNEED 0x0804827c VERNEEDNUM 0x00000001 VERSYM 0x08048270 Version References: required from libc.so.6: 0x0d696910 0x00 02 GLIBC_2.0 Display the contents of the section headers: objdump -h test test: file format elf32-i386 Sections: Idx Name Size VMA LMA File off Algn 0 .interp 00000013 08048134 08048134 00000134 2**0 CONTENTS, ALLOC, LOAD, READONLY, DATA 1 .note.ABI-tag 00000020 08048148 08048148 00000148 2**2 CONTENTS, ALLOC, LOAD, READONLY, DATA 2 .note.gnu.build-id 00000024 08048168 08048168 00000168 2**2 CONTENTS, ALLOC, LOAD, READONLY, DATA 3 .hash 00000028 0804818c 0804818c 0000018c 2**2 CONTENTS, ALLOC, LOAD, READONLY, DATA 4 .gnu.hash 00000020 080481b4 080481b4 000001b4 2**2 CONTENTS, ALLOC, LOAD, READONLY, DATA 5 .dynsym 00000050 080481d4 080481d4 000001d4 2**2 CONTENTS, ALLOC, LOAD, READONLY, DATA 6 .dynstr 0000004c 08048224 08048224 00000224 2**0 CONTENTS, ALLOC, LOAD, READONLY, DATA 7 .gnu.version 0000000a 08048270 08048270 00000270 2**1 CONTENTS, ALLOC, LOAD, READONLY, DATA 8 .gnu.version_r 00000020 0804827c 0804827c 0000027c 2**2 CONTENTS, ALLOC, LOAD, READONLY, DATA 9 .rel.dyn 00000008 0804829c 0804829c 0000029c 2**2 CONTENTS, ALLOC, LOAD, READONLY, DATA 10 .rel.plt 00000018 080482a4 080482a4 000002a4 2**2 CONTENTS, ALLOC, LOAD, READONLY, DATA 11 .init 00000030 080482bc 080482bc 000002bc 2**2 CONTENTS, ALLOC, LOAD, READONLY, CODE 12 .plt 00000040 080482ec 080482ec 000002ec 2**2 CONTENTS, ALLOC, LOAD, READONLY, CODE 13 .text 0000017c 08048330 08048330 00000330 2**4 CONTENTS, ALLOC, LOAD, READONLY, CODE 14 .fini 0000001c 080484ac 080484ac 000004ac 2**2 CONTENTS, ALLOC, LOAD, READONLY, CODE 15 .rodata 0000000b 080484c8 080484c8 000004c8 2**2 CONTENTS, ALLOC, LOAD, READONLY, DATA 16 .eh_frame 00000004 080484d4 080484d4 000004d4 2**2 CONTENTS, ALLOC, LOAD, READONLY, DATA 17 .ctors 00000008 08049f0c 08049f0c 00000f0c 2**2 CONTENTS, ALLOC, LOAD, DATA 18 .dtors 00000008 08049f14 08049f14 00000f14 2**2 CONTENTS, ALLOC, LOAD, DATA 19 .jcr 00000004 08049f1c 08049f1c 00000f1c 2**2 CONTENTS, ALLOC, LOAD, DATA 20 .dynamic 000000d0 08049f20 08049f20 00000f20 2**2 CONTENTS, ALLOC, LOAD, DATA 21 .got 00000004 08049ff0 08049ff0 00000ff0 2**2 CONTENTS, ALLOC, LOAD, DATA 22 .got.plt 00000018 08049ff4 08049ff4 00000ff4 2**2 CONTENTS, ALLOC, LOAD, DATA 23 .data 00000008 0804a00c 0804a00c 0000100c 2**2 CONTENTS, ALLOC, LOAD, DATA 24 .bss 00000008 0804a014 0804a014 00001014 2**2 ALLOC 25 .comment 00000023 00000000 00000000 00001014 2**0 CONTENTS, READONLY Display DWARF info in the file: objdump --dwarf test test: file format elf32-i386 Contents of the .eh_frame section: 00000000 ZERO terminator By the way, ELF is an executable file format and DWARF is a debugging file format. I guess they had to think quite long to find this backronym . Fibonacci C-Code This is the most simple version of Fibonacci I could find: [7] #include <stdio.h> unsigned int fib ( unsigned int n ) { return n < 2 ? n : fib ( n - 1 ) + fib ( n - 2 ); } int main ( void ) { printf ( \"%i\" , fib ( 13 )); return 0 ; } Assembly .file \"test.c\" .text .globl fib .type fib, @function fib: pushl %ebp movl %esp, %ebp pushl %ebx subl $20, %esp cmpl $1, 8(%ebp) jbe .L2 movl 8(%ebp), %eax subl $1, %eax movl %eax, (%esp) call fib movl %eax, %ebx movl 8(%ebp), %eax subl $2, %eax movl %eax, (%esp) call fib leal (%ebx,%eax), %eax jmp .L3 .L2: movl 8(%ebp), %eax .L3: addl $20, %esp popl %ebx popl %ebp ret .size fib, .-fib .section .rodata .LC0: .string \"%i\" .text .globl main .type main, @function main: pushl %ebp movl %esp, %ebp andl $-16, %esp subl $16, %esp movl $13, (%esp) call fib movl $.LC0, %edx movl %eax, 4(%esp) movl %edx, (%esp) call printf movl $0, %eax leave ret .size main, .-main .ident \"GCC: (Ubuntu 4.4.3-4ubuntu5) 4.4.3\" .section .note.GNU-stack,\"\",@progbits References â†‘ : PUSHL Instruction . The University of Auckland, Department of Computer Science. â†‘ : IA-32 Assembly for Compiler Writers . Douglas Thain, Associate Professor, University of Notre Dame, Department of Computer Science and Engineering. â†‘ : From C To Assembly Language . Hiran Ramankutty, Linux Gazett, Issue 94. â†‘ : About leave in x86 assembly . zneak, Stackoverflow. â†‘ : GCC's assembly output of an empty program on x86, win32 . nos, Stackoverflow. â†‘ : Why would one use \"movl $1, %eax\" as opposed to, say, \"movb $1, %eax\" . Jason, Stackoverflow. â†‘ : Fibonacci numbers (C) . Literate Programs. â†‘ : The 68000's Instruction Set , page 27. Literate Programs. â†‘ : LEAL Assembler instruction . Nils Pipenbrinck, Stackoverflow â†‘ : What does this dollar sign mean in __asm? . Zimbabao, Stackoverflow â†‘ : What do the dollar ($) and percentage (%) signs represent in assembly intel x86? . Necrolis, Stackoverflow","tags":"Code","title":"Get your programs assembly code and more information"},{"url":"https://martin-thoma.com/creating-pdf-forms-with-latex/","text":"I've just stumbled across a full, working example how to create a html form within an LaTeX document. You can fill this form within your PDF-Reader. Here is the example PDF-file . It looks like this in Chromes PDF reader: PDF LaTeX form in Chrome \\documentclass [a4paper,12pt] { article } \\usepackage { amssymb } % needed for math \\usepackage { amsmath } % needed for math \\usepackage [utf8] { inputenc } % this is needed for german umlauts \\usepackage [ngerman] { babel } % this is needed for german umlauts \\usepackage [T1] { fontenc } % this is needed for correct output of umlauts in pdf \\usepackage [margin=2.5cm] { geometry } %layout \\usepackage { hyperref } % this is needed for forms and links within the text \\hypersetup { pdfauthor = { Martin Thoma } , pdfkeywords = { Martin Thoma, exmple, LaTeX, form } , pdftitle = { An example for a LaTeX form } } \\begin { document } \\title { An example for a LaTeX form } \\author { Martin Thoma } \\date { \\today } \\section { An example for a \\LaTeX ~form } \\begin { Form } [action=mailto:info@example.com,encoding=html,method=post] \\subsection { Some general information: } \\begin { tabbing } xxxxxxxxxx: \\= \\kill % This is needed for the right tab width Name: \\> \\TextField [name=name,width=3cm,charsize=12pt] { \\mbox {}} Prename: \\TextField [name=vor,width=3cm,charsize=12pt] { \\mbox {}} \\\\ City: \\> \\ChoiceMenu [combo,name=city,width=5cm,charsize=12pt,default=Karlsruhe] { \\mbox {}} { Chemnitz,Dresden,Leipzig,Berlin,Hamburg,Karlsruhe,M & uuml;nchen } \\\\ Sex: \\> \\ChoiceMenu [radio,default=f,name=sex,charsize=14pt] { \\mbox {}}{ Male=m,Female=f } \\end { tabbing } \\subsection { Education: } \\CheckBox [name=highschool,charsize=12pt] { High School } \\CheckBox [name=college,charsize=12pt] { College } \\CheckBox [name=university,charsize=12pt] { University } \\\\ \\Submit { Submit } \\Reset { Clear } \\hfill ~ \\\\ \\end { Form } \\end { document } You can save this as pdf-form.tex and run this command in Linux: pdflatex pdf-form.tex -output-format = pdf It seems as if the \\ChoiceMenu radio option is buggy at the moment. Does anybody know how to fix that? edit: Hmm ... it works in Chromes PDF reader, but not in Document Viewer. Mayby Document Viewer is buggy. Sources TeX Users Group: PDF and HTML forms Teil 2: LATEX und PDF - TU Chemnitz (German) Dokumentation der HU Berlin (German)","tags":"My bits and bytes","title":"Creating pdf-forms with LaTeX"},{"url":"https://martin-thoma.com/gbi-klausur/","text":"FÃ¼r die Klausur in den Grundbegriffe der Informatik (GBI) sollte man Folgendes auf jeden Fall wissen: Wie funktionieren Induktionsbeweise? â†’ Antwort Was ist ein Alphabet, eine formale Sprache und was eine formale Grammatik? â†’ Antwort Was bedeuten fÃ¼r zwei Formale Sprachen \\(L_1, L_2\\) folgende binÃ¤ren Operationen: \\(\\cdot, \\cup, \\cap, \\setminus, L_1&#94;3, L&#94;+, L&#94;*\\) ? â†’ Antwort Was ist eine Abbildung, was eine Relation? â†’ Antwort Was ist InjektivitÃ¤t, SurjektivitÃ¤t, BijektivitÃ¤t, ReflexivitÃ¤t, Symmetrie, Antisymmetrie und TransitivitÃ¤t? â†’ Antwort Wie ist eine Ã„quivalenzrelation, eine Ordnungsrelation, eine Halbordnung und eine Totalordnung definiert? â†’ Antwort Wie ist ein minimales Element und wie das kleinste Element einer Halbordnung definiert? â†’ Antwort Wie sind die Landau-Symbole \\(\\cal O(f(n)), \\Theta(f(n)), \\Omega(f(n))\\) definiert? â†’ Antwort und Nachtrag Was ist eine Turingmaschine und wie gibt man eine Konfiguration davon an? Wie ist ein Graph definiert und wie ein Baum? â†’ Antwort Wann sind zwei Graphen isomorph? Was ist eine Pfad, eine Schlinge, ein Kreis und ein Zyklus? Wann ist ein Graph zusammenhÃ¤ngend und wann vollstÃ¤ndig / streng zusammenhÃ¤ngend? Was ist eine Adjazenzmatrix und was ist eine Wegematrix? Wie lautet die Wahrheitstabelle von \\(A \\Rightarrow B\\) ? Wie unterscheiden sich Mealy- und Moore-Automaten? Welche Sprachen akzeptieren sie und wie stellt man sie dar? Was ist eine Huffman-Kodierung und wie stellt man sie dar? Was haben alle WÃ¶rter einer Ã„quivalenzklasse der Nerode-Relation gemeinsam? Was ist ein Hasse-Diagramm? Wie lautet das Master-Theorem? â†’ Antwort Wenn die Antwort auf eine dieser Fragen noch unklar ist, sollte man sich das Skript nochmals anschauen. Was man auf jeden Fall Ã¼ben sollte, sind die Aufgaben zu Turingmaschinen. Das kommt sicher dran und man ist sicher zu langsam, wenn man nicht ein paar Aufgaben dazu macht. Some Random Facts Ein Mebibyte (MiB) sind $2&#94;{20}$ Byte, ein Megabyte (MB) sind $10&#94;6$ Byte. $\\{\\varepsilon\\} \\neq \\emptyset = \\{\\}$ $\\cal P(\\emptyset) = \\{\\emptyset\\} = \\{\\{\\}\\}$ und $|{\\cal P}(\\emptyset)| = 1$, aber $|\\emptyset| = 0$. $Num_2(111)$ ist die Zahl 7, $Repr_2$(die Zahl 7) = 111 $\\langle \\emptyset \\rangle = \\{\\}$ und $\\langle \\emptyset * \\rangle = \\{\\varepsilon\\}$ Ein paar Beziehungen von KomplexitÃ¤tsklassen: ${\\cal O}(\\log(n)) \\subsetneq {\\cal O}(n)$ ${\\cal O}(n&#94;{2.1}) \\subsetneq {\\cal O}(n&#94;{2.2})$ ${\\cal O}(n&#94;{100}) \\subsetneq {\\cal O}(n!)$ ${\\cal O}(2&#94;n) \\subsetneq {\\cal O}(n!) \\subsetneq {\\cal O}(n&#94;n) \\subsetneq {\\cal O}(2&#94;{n&#94;2})$ ${\\cal O}((n&#94;n)&#94;n) \\subsetneq {\\cal O}(n&#94;{(n&#94;3)})$ Logarithmusgesetze: $\\log(x \\cdot y) = \\log(x) + \\log(y)$ $\\log(\\frac{x}{y}) = \\log(x) - \\log(y)$ $\\log(x&#94;r) = r \\cdot \\log(x)$ Ein minimaler Endlicher Automat zu einer regulÃ¤re Sprache L hat n ZustÃ¤nde $\\Leftrightarrow$ Es gibt n Ã„quivalenzklassen bzgl. der Nerode-Relation zu L. Der Index der Nerode-Relation zu einer Sprache L ist nicht endlich $\\Leftrightarrow$ L ist nicht regulÃ¤r $S \\circ R = \\{(x, z) \\in M_1 \\times M_3 | \\exists y \\in M_2: (x, y) \\in R \\land (y, z) \\in S\\}$ r ist Wurzel von $G = (V, E) \\Leftrightarrow \\forall x \\in V : $ Es gibt genau einen Pfad von r nach x. Zum Ãœben habe ich mal eine \"Klausur\" erstellt. Hier ist die PDF und hier die LaTeX -Datei. GroÃŸ-O-Notation Beh : \\(\\mathcal{O}(n!) \\nsubseteq \\mathcal{O}(2&#94;n)\\) Bew : z.Z.: \\(n! \\notin \\mathcal{O}(2&#94;n)\\) Annahme: \\(\\exists c \\in \\mathbb{R}: n! \\leq c \\cdot 2&#94;n\\) \\(n! \\leq c \\cdot 2&#94;n\\\\ \\Leftrightarrow \\frac{n!}{2&#94;n} \\leq c\\\\ \\Leftrightarrow \\frac{\\Pi_{i=1}&#94;n i}{\\Pi_{i=1}&#94;n 2} \\leq c\\\\ \\Leftrightarrow \\Pi_{i=1}&#94;n \\frac{i}{2} \\leq c\\) Es gilt: \\(\\Pi_{i=1}&#94;n \\frac{i}{2} = \\frac{1}{2} \\cdot 1 \\cdot \\frac{3}{2} \\Pi_{i=4}&#94;n \\frac{i}{2} \\ge \\frac{3}{4} \\cdot 2&#94;n $ $\\Rightarrow \\forall c \\in \\mathbb{R} \\exists n_0 \\in \\mathbb{N} \\forall n \\geq n_0: n! \\geq c \\cdot 2&#94;n\\) Offensichtlich ist also \\(\\mathcal{O}(n!) \\nsubseteq \\mathcal{O}(2&#94;n)\\) . Formalismen Ableitungen benutzen Doppelpfeile, Ableitungsregeln einfache Pfeile. Bei ungerichteten Graphen werden die Kanten also Mengen mit zwei Elementen beschrieben, bei gerichteten als Tupel. Termin Alle wichtigen Informationen stehen auf der Klausurseite . Datum : 05.03.2012 um 11:00 Uhr. Anwesend sollte man ab ca. 10:30 - 10:40 Uhr sein. Ort : Liste der Zuweisung - Das sind ganze 729 Matrikelnummern! (Ich schreib im Benz). Dauer : 120 min. Punkte : 40 - 50, mit der HÃ¤lfte hat man auf jeden Fall bestanden. Nicht vergessen : Studentenausweis Nachklausur : am 18.09.2012. Hinweise sind hier . Ergebnisse Die Ergebnisse sind nun hier verfÃ¼gbar. Das ist eine Notenverteilung, die mir ein Kommilitone zugeschickt hat: GBI Ergebnisse","tags":"German posts","title":"GBI-Klausur"},{"url":"https://martin-thoma.com/stuxnet/","text":"The following clip is a nice, short explanation of Stuxnet , a computer worm discovered in June 2010:","tags":"The Web","title":"Stuxnet"},{"url":"https://martin-thoma.com/portal-still-alive-typography-clip/","text":"","tags":"Cyberculture","title":"Portal - Still Alive typography clip"},{"url":"https://martin-thoma.com/7-mind-blowing-artists-you-didnt-know/","text":"Anamorphic Art Anamorphosis is a distorted projection or perspective requiring the viewer to use special devices or occupy a specific vantage point to reconstitute the image. Here is a good example by Felice Varini : Anamorphic Art - Source: illusion.scene360.com Pavement Drawings Pavement Drawings can be combined with anamorphic art. One great artist I've found is Julian Beever . Here is one example: Pavement Drawing by Julian Beever Hand Painting You might already know body painting. Guido Daniele does something very simmilar he calls \"Hand Painting\". Here is one example: Hand Painting by Guido Daniele Hair Sculptures Willard Wigan is a sculptor from Birmingham, England, who makes microscopic art. His sculptures are typically placed in the eye of a needle or on the head of a pin. A single sculpture can be as small as 0.005 mm. Here is an example from his gallery : Harry Potter by Willard Wigan Sand Art It is amazing what can be done with sand. Sudarsan Pattnaik created this sculpture: Sand Art: Global Warming by Sudarshan Pattnaik Origami Robert J. Lang seems to invest a serious amount of time in Origami . His gallery of mammals is very impressive. Here is a moose: Origami moose by Robert J. Lang Domino Day This is not done by one artist, but it should be mentioned:","tags":"My bits and bytes","title":"7 mind-blowing artists you didn't know"},{"url":"https://martin-thoma.com/tgi-klausur/","text":"Ich habe im WS 2011/2012 bei Frau Prof. Dr. Wagner die TGI-Klausur am KIT geschrieben. HierfÃ¼r entstand dieser Artikel. FÃ¼r die Klausur in den Theoretischen Grundlagen der Informatik sollte man Folgendes auf jeden Fall wissen: Wie konstruiert man mittels Potenzmengen einen Ã¤quivalenten deterministischen endlichen Automaten zu einem Nichtdeterministischen? â†’ Antwort Wie bringt man eine Grammatik in Chomsky-Normalform ? â†’ Antwort . Was macht der CYK-Algorithmus und wie funktioniert er? â†’ siehe Beispiel ab Folie 15 Was ist die Chomsky-Hirarchie , welche Grammatiken gibt es und mit welchen Operationen sind sie Abgeschlossen ? â†’ Antwort . Was ist das Post'sche Korrespondenzproblem? Welche KomplexitÃ¤tsklassen sind $\\cal P, NP, NPC, DTAPE, NTAPE, NPI$? â†’ Antwort Wie sind Kellerautomaten definiert, wann sind sie formal nicht-deterministisch und in welcher Beziehung stehen sie zur Greibach-Normalform? Wie formt man einen Kellerautomaten von einem akzeptierenden Endzustand in einen mit leerem Stack um? â†’ Antwort . Wie lautet das Pumping-Lemma (fÃ¼r regulÃ¤re und kontextfreie Sprachen? Wie lautet Ogdens Lemma ? Und wie benutzt man diese fÃ¼r Beweise? â†’ Antwort Wie beweist man NP-VollstÃ¤ndigkeit ? Some Random Facts \"aaa\" ist in der Sprache aller Worter, die zwei mal \"aa\" enthalten. [1] Die Grammatik $G_1(\\{S\\}, \\{\\varepsilon\\}, \\{S \\rightarrow \\varepsilon\\},S)$ erzeugt die Sprache $L(G_1) = \\{\\varepsilon\\}$. [2] Die Grammatik $G_2(\\{S\\}, \\{\\varepsilon\\}, \\{\\},S)$ erzeugt die Sprache $L(G_2) = \\{\\}$. $L_1 := \\{aba, bab, ab\\}, L_2 := \\{bb,ab,ba\\}$. Dann ist $L_1 / L_2 = \\{\\varepsilon, a, b\\}$ und $L_1 \\setminus L_2 = \\{aba, bab\\}$ [3] $PKP \\notin \\cal NPC$ [4] Es kann sein, dass die Ableitung eines Wortes nicht eindeutig ist, aber der Syntaxbaum eindeutig ist. FÃ¼r jedes Wort w gibt es einen DEA, der w akzeptiert [5] $L' \\alpha L$ bedeutet, dass L' polynomial transformierbar in L ist. $L' \\alpha_T L$ bedeutet, dass L' Turing-reduzierbar in L ist. Termin Datum : Mittwoch, der 22.02.2012 um 14:00 Uhr (siehe Vorlesungswebsite ) Ort : Steht hier . Ich schreibe im Tulla, manche noch im Gaede und andere im HS a. F., Daimler oder Benz. Laut dieser Liste schreiben 295 Personen diese Klausur! Dauer : 120 min. (siehe erste Folie ) Punkte : Bisher waren es meist ca. 60, von denen man 20 zum Bestehen benÃ¶tigt hat. Ãœbungsschein : Liste der 195 Leute, die ihn bestanden haben. Der Ãœbungsschein bringt einen Klausurbonus. Allerdings habe ich keine Ahnung, wie hoch dieser ist. edit: +0,3 zur Klausurnot (Danke Alexander â˜º) Ach ja, ich habe \" Yet Another Info 3 Resume \" noch gar nicht verlinkt. Das ist sehr kurz und hat viele wichtige Informationen. Klausurergebnisse Die Klausurergebnisse sind nun Ã¶ffentlich . Die Liste scheint nach Matrikelnummer sortiert zu sein ... tolle Anonymisierung, da wir ja auch im Saal nach Matrikelnummern sortiert waren. Und falls irgendjemand es vergessen hat: Hier ist die Ã¶ffentliche Liste der Matrikelnummern . Tja, so werden wir verschaukelt was den Datenschutz angeht. edit: Das Leck scheint ausgebessert worden zu sein. Nun sind die Noten nach Klausur-ID sortiert. Sehr schÃ¶n â˜º Notenverteilung der TGI Klausur im WS 2011/2012 am KIT Einzelnachweise â†‘ : 2. Klausur WS 2003/2004, Aufgabe 1a â†‘ : 1. Klausur WS 2003/2004, Aufgabe 5 â†‘ : 1. Klausur WS 2007/2008, Aufgabe 3c â†‘ : 1. Klausur WS 2007/2008, Aufgabe 5 â†‘ : 1. Klausur WS 2010/2011, Aufgabe 5","tags":"German posts","title":"TGI-Klausur"},{"url":"https://martin-thoma.com/kellerautomat/","text":"Ein Kellerautomat ist ein Endlicher Automat mit einem Stack (\"Kellerspeicher\"). Er wird mit PDA (pushdown automaton) bzw. NPDA (nondeterministic pushdown automaton) abgekÃ¼rzt. Laut Wikipedia verwendet die Gleitkommaeinheit einen PDA. Dazu habe ich allerdings keine Quelle, das ist also mit Vorsicht zu genieÃŸen. Ein weiterer Einsatzzweck ist die Syntaxanalyse einer Tokenfolge. Das kann fÃ¼r Compiler oder Interpreter von Interesse sein. Definitionen Der Kellerautomat ist als 7-Tupel definiert: \\((Q, \\Sigma, \\Gamma, q_0, Z_0, \\delta, F)\\) , wobei Q: endliche Zustandsmenge \\(\\Sigma\\) : endliches Eingabealphabet \\(\\Gamma\\) : endliches STACK-Alphabet \\(q_0 \\in Q\\) : Anfangszustand \\(Z_0 \\in \\Gamma\\) : Initialisierung des STACK \\(\\delta: Q \\times (\\Sigma \\cup \\{\\varepsilon\\}) \\times \\Gamma \\rightarrow 2&#94;{Q \\times \\Gamma&#94;*}\\) . \\(F \\subseteq Q\\) : Menge der akzeptierenden EndzustÃ¤nde. Bemerkenswert ist hierbei, dass F leer sein kann. Dies ist mÃ¶glich, da ein PDA auch durch leeren Stack akzeptieren kann. Die ZustandsÃ¼berfÃ¼hrungsfunktion ist etwas umstÃ¤ndlich beschrieben. Dort steht, dass jede Regel folgende Form hat: \\(\\delta(\\text{Zustand}, \\text{Eingabesymbol}, \\text{Stacksymbol}) = (\\text{Neuer Zustand}, \\text{Neuer Stack})\\) Die Konfiguration eines PDA ist ein Tripel \\((q, w, \\alpha)\\) , wobei \\(q \\in Q\\) : aktueller Zustand \\(w \\in \\Sigma&#94;*\\) : der Teil der Eingabe, der noch nicht gelesen wurde \\(\\alpha \\in \\Gamma&#94;*\\) : der STACK-Inhalt Ein PDA ist deterministisch \\(: \\Leftrightarrow |\\delta(q, a, Z)| + |\\delta(q, \\varepsilon, Z)| \\leq 1 ~~~ \\forall_{q \\in Q, a \\in \\Sigma, Z \\in \\Gamma}\\) . Anschaulich Du hast einen Kartenstapel (deine Eingabe, auf der du immer nur ein Zeichen lesen darfst), einen Stapel fÃ¼r Notizzettel, wobei am Anfang nur ein Notizzettel dort liegt und immer nur ein Symbol auf dem Zettel steht (dein Stack, der mit \\(Z_0 \\in \\Gamma\\) initialisiert ist), einen Zustand und eine Menge Regeln ( \\(\\delta\\) ). Nun schaust du dir in jedem Schritt die oberste Karte auf dem Kartenstapel an und legst sie weg. Des Weiteren schaust du dir deine oberste Notiz an und legst sie weg und Ã¼berprÃ¼fst deinen Zustand. Aus diesen Informationen schlussfolgerst du, was du als nÃ¤chstes machst. Du kannst dir aussuchen in welchen Zustand du gehen willst und was du noch auf deinen Notiz-Stapel tun willst. Du kannst auch einfach nichts auf den Notiz-Stapel legen. Beispiele Sei \\(L = \\{w \\in \\{0,1,2\\}&#94;* | w = 0&#94;i1&#94;j2&#94;j ~~~ i, j \\in \\mathbb{N}\\}\\) \\((\\{q_0, q_1, q_2\\}, \\{0, 1, 2\\}, \\{1, \\#\\}, q_0, \\#, \\delta, \\emptyset)\\) mit $\\delta(q_0, 0, #) = {(q_0, #), (q_1, #)}, $ $\\delta(q_1, 1, #) = {(q_1, 1)}, $ $\\delta(q_1, 1, 1) = {(q_1, 11)}, $ $\\delta(q_1, 2, 1) = {(q_2, \\varepsilon)}, $ $\\delta(p, a, Z) = \\emptyset $ sonst. Der Kellerautomat akzeptiert durch leeren STACK. Aus diesem Grund legen wir am Anfang auch immer wieder # auf den Stack. Sonst wÃ¼rde der PDA zu frÃ¼h akzeptieren. Da \\(|\\delta(q_0, 0, \\#) = 2 > 1|\\) ist dieser Kellerautomat Nicht-Deterministisch. Umformungen Akzeptierender Endzustand â†’ leerer STACK Siehe Skript von Prof. Dr. Dorothea Wagner, S. 107. Gegeben sei ein Kellerautomat \\({\\cal K}_1 (Q_1, \\Sigma, \\Gamma_1, \\delta_1, q_0&#94;1, Z_0&#94;1, F_1)\\) der durch akzeptierenden Endzustand akzeptiert. Wir wollen einen neuen Automaten \\({\\cal K}_2 (Q_2, \\Sigma, \\Gamma_2, \\delta_2, q_0&#94;2, Z_0&#94;2, F_2)\\) der durch leeren STACK akzeptiert. Idee : Wir fÃ¼hren einen neuen Zustand \\(q_E\\) ein, bei dessen Erreichen wir den STACK leeren. Um zu verhindern, dass der STACK zwischenzeitlich leer wird, legen wir zu beginn das STACK-Symbol \\(Z_0&#94;2\\) ab. Formal : \\(Q_2 := Q_1 \\cup \\{q_0&#94;2, q_E\\}\\) , wobei \\(q_0&#94;2\\) der neue Anfangszustand von \\({\\cal K}_2\\) ist. \\(\\Gamma_2 := \\Gamma_1 \\cup \\{Z_0&#94;2\\}\\) , wobei \\(Z_0&#94;2\\) den STACK initialisiert. Die Menge \\(\\delta_2(q, a, Z)\\) fÃ¼r \\(a \\in \\Sigma \\cup \\{\\varepsilon\\}\\) und \\(Z \\in \\Gamma_2\\) sei durch folgende Bedingungen festgelegt: Sorge fÃ¼r die gleiche Anfangssituation: \\(\\delta_2(q_0&#94;2, \\varepsilon, Z_0&#94;2) = \\{(q_0&#94;1, Z_0&#94;1Z_0&#94;2)\\}\\) Falls der Zustand, das gelesene Zeichen und das STACK-Symbol im \"alten\" Automaten sind, dann wie gehabt: \\(\\delta_2(q, a, Z) = \\delta_1(q, a, Z) \\text{f&uuml;r } (q \\in Q_1, a \\neq \\varepsilon, Z \\in \\Gamma_1) \\lor (q \\in Q_1 \\setminus F_1, a = \\varepsilon, Z \\in \\Gamma_1)\\) Sorge dafÃ¼r, dass die STACK-Leerungsregel aufgerufen wird, falls der Zustand akzeptierend ist: \\(\\delta_2(q, \\varepsilon, Z) = \\delta_1(q, \\varepsilon, Z) \\cup \\{(q_E, \\varepsilon)\\} \\text{f&uuml;r } q \\in F_1, Z \\in \\Gamma_2\\) Diese Regel leert den STACK: \\(\\delta_2(q_E, \\varepsilon, Z) = \\{(q_E, \\varepsilon)\\} \\text{ f&uuml;r } Z \\in \\Gamma_2\\) Leerer STACK â†’ akzeptierender Endzustand Siehe Skript von Prof. Dr. Dorothea Wagner, S. 107. Gegeben sei ein Kellerautomat \\({\\cal K}_1 (Q_1, \\Sigma, \\Gamma_1, \\delta_1, q_0&#94;1, Z_0&#94;1, F_1)\\) der durch leeren STACK akzeptiert. Wir wollen einen neuen Automaten \\({\\cal K}_2 (Q_2, \\Sigma, \\Gamma_2, \\delta_2, q_0&#94;2, Z_0&#94;2, F_2)\\) der durch akzeptierenden Endzustand akzeptiert. Idee : Wir legen ein zusÃ¤tzliches Symbol \\(Z_0&#94;2\\) auf den STACK. Wird \\(Z_0&#94;2\\) gelesen, ist der STACK noch nicht leer, aber man kann in einen akzeptierenden Zustand \\(q_F\\) wechseln. Formal : \\(Q_2 := Q_1 \\cup \\{q_0&#94;2, q_F\\}\\) , wobei \\(q_0&#94;2\\) Anfangszustand von \\({\\cal K}_2\\) ist und \\(F_2 := \\{q_F\\}\\) \\(\\Gamma_2 := \\Gamma_1 \\cup \\{Z_0&#94;2\\}\\) , wobei \\(Z_0&#94;2\\) Initialisierung des STACKS von \\({\\cal K}_2\\) ist und \\(\\delta_2\\) festgelegt durch: Zuerst sorgen wir dafÃ¼r, dass \\(Z_0&#94;2\\) ganz unten im STACK ist: $$\\delta_2(q_0&#94;2, a, X) = \\begin{cases} \\{q_0&#94;1, Z_0&#94;1, Z_0&#94;2\\} & \\text{falls } a= \\varepsilon \\text{ und } X = Z_0&#94;2\\\\ \\emptyset & \\text{sonst} \\end{cases}$$ Dann wie gehabt: \\(\\delta_2(q, a, Z) = \\delta_1(q, a, Z) \\text{, falls } q \\in Q_1, a \\in \\Sigma \\cup \\{\\varepsilon\\} \\text{ und } Z \\in \\Gamma_1\\) Und am Schluss auch akzeptieren: \\(\\delta_2(q, \\varepsilon, Z_0&#94;2) = \\{(q_F, \\varepsilon)\\} \\text{ f&uuml;r } q \\in Q_1\\) . Dies und das Ein Kellerautomat mit zwei STACKs ist TuringmÃ¤chtig. (â†’ Zweikellerautomat ) Ein NPDA erkennt genau die kontextfreien Sprachen. Ein PDA erkennt manche kontextfreie Sprachen, aber nicht alle. (Genauer: Deterministisch kontextfreie Sprache ) Zu jedem PDA, der eine Sprache L durch einen akzeptierenden Endzustand akzeptiert, kann ein PDA konstruiert werden, der L mit leerem STACK akzeptiert (und umgekehrt). FÃ¼r jede Grammatik G in Greibach-Normalform gibt es einen PDA. Siehe auch Wikipedia: Kellerautomat Theoretische Grundlagen der Informatik : Skript von Prof. Dr. Dorothea Wagner, ab S. 105 Sprachen, Automaten und Grammatiken: Ein Ãœberblick","tags":"German posts","title":"Kellerautomat"},{"url":"https://martin-thoma.com/komplexitatsklassen-in-der-informatik-ein-uberblick/","text":"KomplexitÃ¤tsklassen werden in der Theoretischen Informatik verwendet um den Ressourcenbedarf von Algorithmen bzw. Problemen einzuordnen. Meist betrachtet man die Laufzeit- und die SpeicherplatzkomplexitÃ¤t, aber es wÃ¤re prinzipiell auf Vorstellbar, dass man andere Kriterien nutzt. Ich werde in diesem Artikel mal kurz die in der Vorlesung behandelten Klassen vorstellen. Da es umstÃ¤ndlich ist, werde ich im Folgenden nur noch von Problemen reden. Gemeint sind aber meist auch formale Sprachen und Algorithmen. Die Klasse P In der Klasse \\(\\cal P\\) sind alle Probleme, die mit einer deterministischen Turingmaschine in polynomialzeit lÃ¶sbar sind. Das sind also alle Probleme, fÃ¼r die es einen Algorithmus gibt, der in \\(\\cal O(n&#94;i), i \\in \\mathbb{N}_0\\) ist. Wenn es allerdings noch keinen Algorithmus gibt, der ein Problem in polynomialzeit lÃ¶st, kann das Problem dennoch in \\(\\cal P\\) liegen. Dann muss es einen besseren Algorithmus zur LÃ¶sung des Problems geben. Die Klasse NP In der Klasse \\(\\cal NP\\) sind alle Probleme, die mit einer nicht-deterministischen Turingmaschine in polynomialzeit lÃ¶sbar sind. Das besondere an einer nicht-determinisitschen Turingmaschine ist das Orakelmodul. Es liefert einfach die LÃ¶sung. Wie es das macht, wissen wir nicht. Irgendwie geht es halt. Diese LÃ¶sung muss in polynomialzeit von einer deterministischen Turingmaschine verifiziert werden. Was liegt dann nicht in \\(\\cal NP\\) ? Das Orakelmodul hÃ¶rt sich so mÃ¤chtig an, dass eventuell alle Probleme in \\(\\cal NP\\) liegen kÃ¶nnten. Weit gefehlt. Suchprobleme liegen hÃ¤ufig (aber nicht immer) auÃŸerhalb von \\(\\cal NP\\) . Das sind dann Probleme mit einer Fragestellung Ã  la \"Gib eine optimale Tour durch eine gegebene Menge an StÃ¤dten an\". Wenn das Orakel-Modul eine solche Tour liefert, muss der deterministische Teil noch schauen, ob es eventuell eine lÃ¤ngere Tour gibt. Die wohl berÃ¼hmteste Fragestellung der Theoretischen Informatik lautet nun: P vs. NP : Gibt es Probleme, die in NP liegen, aber nicht in P? Es ist wohl anschaulich klar, dass gilt: \\(\\cal P \\subset NP\\) . P vs. NP ist die Frage, ob \\(\\cal P = NP\\) oder \\(\\cal P \\subsetneq NP\\) . Oder nochmals anders formuliert: \\(\\cal NP \\setminus P \\stackrel{?}{=} \\emptyset\\) Die Klasse NPC Die Klasse der NP-VollstÃ¤ndigen Probleme ist echt in NP, also \\(\\cal NPC \\subsetneq NP\\) . Das besondere an \\(\\cal NPC\\) ist, dass jedes Probleminstanz in \\(\\cal NP\\) in eine Instanz eines beliebigen Problems in \\(\\cal NPC\\) umgewandelt werden kann. Das es ein solches Problem gibt, hat Cook 1971 mit SAT gezeigt. Cook hat also anschaulich folgendes gemacht: SAT ist in NPC FÃ¼r alle folgenden Beweise, dass ein Problem in \\(\\cal NPC\\) liegt, wurde der Satz von Cook verwendet. Laut diesem Satz (dessen Beweis wahnsinning lang ist) lÃ¤sst sich jede Probleminstanz von Problemen in \\(\\cal NP\\) sich in eine Instanz von SAT umwandeln. Es reicht also zu zeigen, dass sich eine beliebige SAT-Instanz I in eine Instanz I' des neuen Problems in polynomialzeit umwandeln lÃ¤sst. Diese beiden Instzanzen mÃ¼ssen in folgender Beziehung stehen: FÃ¼r I existiert eine LÃ¶sung \\(\\Leftrightarrow\\) fÃ¼r I' existiert eine LÃ¶sung: Beweis, dass 3-SAT in NPC liegt Sobald man von einem Problem sicher weiÃŸ, dass es in \\(\\cal NPC\\) liegt, kann man natÃ¼rlich auch etwas anderes als SAT verwenden. Im Bezug auf P vs. NP ist es vor allem interessant. Wenn ein Problem nicht in P, aber in NP liegt, dann ist sicher jedes Problem in NPC auÃŸerhalb von P. Also: \\(\\cal P \\neq NP \\Rightarrow P \\cap NPC = \\emptyset\\) . Warum? Angenommen es existiert ein Problem P fÃ¼r das gilt: \\(P \\in \\cal NP\\) \\(P \\notin \\cal P\\) \\(P \\notin \\cal NPC\\) Dann gibt es eine polynomielle Transformation von jeder Instanz von P in eine Probleminstanz von einem beliebigem Problem in \\(\\cal NPC\\) . Damit kann jedes Problem in \\(\\cal NPC\\) nicht mehr in \\(\\cal P\\) liegen, da sonst auch \\(P \\in \\cal P\\) . NPI, co-P und co-NP Formal gilt: \\(\\cal NPI := NP \\setminus (P \\cup NPC)\\) . Es sind also alle Probleme, die innerhalb von \\(\\cal NP\\) sind, aber auÃŸerhalb von \\(\\cal P\\) und noch nicht in \\(\\cal NPC\\) in \\(\\cal NPI\\) . Es ist also so eine Art \"Zwischenklasse\". Um es etwas anschaulicher zu machen, habe ich mal folgendes Bildchen erstellt: P vs. NP: Die Klassen P, NP, NPC und NPI im Ãœberblick Bemerkenswert ist folgende Aussage: Im Fall \\(\\cal P = NP\\) ist auch \\({\\cal P} \\setminus \\{\\emptyset, \\Sigma&#94;*\\} = {\\cal NPC}\\) (siehe Nachklausur von 2007 / 2008, Frage 5). Warum stimmt das? Damit ein Problem \\(\\in \\cal NPC\\) ist, muss es nur eine polynomielle Transformation von jedem Problem in NP auf das eine Problem geben. Das ist offensichtlich der Fall, wenn man alle Probleme in NP in polynomieller Zeit lÃ¶sen kann. In diesem Fall kann man das Entscheidungsproblem lÃ¶sen und eine Ja-Instanz auf eine beliebige andere Ja-Instanz abbilden und analog Nein-Instanzen auf Nein-Instanzen abbilden. Da \\(\\emptyset\\) keine Ja-Instanz hat und \\(\\Sigma\\) keine Nein-Instanz hat, muss man diese herausnehmen. Formal gilt: \\(\\text{co-}{\\cal P} := \\{L \\in \\Sigma&#94;* | L&#94;C \\in {\\cal P}\\}\\) und analog \\(\\text{co-}{\\cal NP} := \\{L \\in \\Sigma&#94;* | L&#94;C \\in {\\cal NP}\\}\\) . Folgende Aussage finde ich dazu sehr interessant: \\(L \\in {\\cal NPC} \\land L \\in \\text{co-}{\\cal NP} \\Rightarrow {\\cal NP} = \\text{co-}{\\cal NP}\\) D-TAPE und N-TAPE Im Skript wurde das seltsam geschrieben ( \\(\\cal DTAPE\\) ). Ich habe so nicht mehr erkannt, dass es TAPE heiÃŸen soll. In der Klausur sollte man sich davon nicht irritieren lassen. Formal: \\(D-TAPE(s(n)) := \\{L | \\text{Es existiert eine determinitistische TM, die L mit Platzbedarf s(n) akzeptiert.}\\}\\) \\(N-TAPE(s(n)) := \\{L | \\text{Es existiert eine nicht-determinitistische TM, die L mit Platzbedarf s(n) akzeptiert.}\\}\\) Quellen und Material Theoretische Grundlagen der Informatik : Skript von Prof. Dr. Dorothea Wagner Die Bilder stehen hier zur VerfÃ¼gung: Material zu den KomplexitÃ¤tsklassen","tags":"German posts","title":"KomplexitÃ¤tsklassen in der Informatik: Ein Ãœberblick"},{"url":"https://martin-thoma.com/konstruktion-der-chomsky-normalform/","text":"Dieser Artikel kÃ¶nnte inhaltliche Fehler beinhalten. Bitte lest euch die Kommentare durch. Die Chomsky-Normalform ist eine bestimmte Art, eine kontextfreie Grammatik zu formulieren. Dabei haben nur die Produktionsregeln eine festgelegte Form, alles andere ist wie immer. Die Chomsky-Normalform kommt bei dem CYK-Algorithmus, der das Wortproblem fÃ¼r kontextfreie Grammatiken lÃ¶st, zum Einsatz. Jede kontextfreie Grammatik kann in Chomsky-Normalform gebracht werden. Die Chomsky-Normalform Das Besondere an der Chomsky-Normalform ist, dass alle Regeln der Grammatik \\(G (V, \\Sigma, P, S)\\) folgende Form haben: \\(A \\rightarrow BC\\) oder \\(A \\rightarrow a\\) . Dabei sind \\(A, B, C \\in V\\) und \\(a \\in \\Sigma\\) . Falls die Grammatik in der Lage ist, das Leere Wort \\(\\varepsilon\\) zu erzeugen, dann fÃ¼gt man folgende Sonderregel hinzu: \\(S' \\rightarrow S | \\varepsilon\\) . Dabei darf S' niemals auf der rechten Seite einer Produktion stehen. Eine Eigenschaft der Chomsky-Normalform ist, dass jedes Wort aus \\(2 \\cdot |w| - 1\\) Ableitungen gebildet werden kann. (Falls das leere Wort gebildet werden kann sind es \\(2 \\cdot |w|\\) Ableitungen fÃ¼r jedes nicht-leere Wort und eine Ableitung fÃ¼r das leere Wort) In jedem Ableitungsschritt erhÃ¤lt man entweder ein Terminal, oder ein weiteres Nicht-Terminal. Konstruktion der CNF Aus einer Grammatik \\(G (V, \\Sigma, P, S)\\) kann mit folgenden vier Schritten eine Grammatik \\(G' (V', \\Sigma, P', S)\\) in Chomsky-Normalform (CNF) erstellt werden: Schritt 1 Immer wenn ein Symbol aus \\(\\Sigma\\) in einer Produktion steht, wird dieses durch \\(Y_a\\) ersetzt und eine neue Produktion \\(Y_a \\rightarrow a\\) zu P' hinzugefÃ¼gt. Es ist somit sichergestellt, dass alle Regeln entweder nur Nicht-Terminale auf der rechten Seite der Produktion stehen haben oder \\(\\varepsilon\\) oder dass dort ein einzelnes Terminal steht. Schritt 2 Immer wenn mehr als zwei Variablen auf der rechten Seite stehen, werden diese durch neue ersetzt. Sagen wir es stehen rechts m Variablen. Dann fÃ¼hrt man m - 2 neue Variablen ein, fÃ¼gt diese zu V' hinzu, und macht aus einer Regel \\(A \\rightarrow B_1 B_2 ... B_m\\) die Regeln \\(A \\rightarrow B_1 C_1, C_1 \\rightarrow B_2 C_2, ..., C_{i+1} \\rightarrow B_i C_i ... C_{m-2} \\rightarrow B_{m-3} C_{m-3}\\) . An dieser Stelle ist sichergestellt, dass alle Regeln entweder nur ein oder zwei Nicht-Terminale auf der rechten Seite der Produktion stehen haben oder \\(\\varepsilon\\) oder dass dort ein einzelnes Terminal steht. Schritt 3 Nun wollen wir alle \\(\\varepsilon\\) -ÃœbergÃ¤nge entfernen. Um dies zu erreichen, suchen wir alle Regeln, die nach \\(\\varepsilon\\) abbilden, also von der Form \\(A \\rightarrow \\varepsilon\\) sind. Dabei streichen wir die Regeln \\(A \\rightarrow \\varepsilon\\) . Falls A nun nicht mehr auf der linken Seite auftaucht, streichen wir es Ã¼berall aus der rechten Seite. Falls dabei eine Regel zu \\(B \\rightarrow \\varepsilon\\) wird, streichen wir auch diese. Das wiederholen wir so lange, bis keine \\(\\varepsilon\\) -ÃœbergÃ¤nge mehr vorhanden sind. Am Ende fÃ¼gen wir die Regel \\(S' \\rightarrow S | \\varepsilon\\) hinzu, falls die Grammatik auf das leere Wort abbilden konnte. Nun ist sichergestellt, dass alle Regeln entweder nur ein oder zwei Nicht-Terminale auf der rechten Seite der Produktion stehen haben oder dass dort ein einzelnes Terminal steht. Allerdings kann es noch Kreise in der Ableitung geben, die man entfernen kann. Schritt 4 In diesem Schritt entfernen wir eventuell vorhandene Kettenregeln, also Regeln der Form \\(A_1 \\rightarrow A_2 \\rightarrow A_3 \\rightarrow A_u \\rightarrow A_1\\) . Diese findet man mit einer Tiefensuche. Dann ersetzt man alle \\(A_2, ..., A_u\\) durch \\(A_1\\) . Die Regel \\(A_1 \\rightarrow A_1\\) kann entfernt werden, da sie ja nichts Ã¤ndert. Beispiele Die Sprache der Palindrome Gegeben sei folgende Grammatik: \\(G(\\underbrace{\\{S\\}}_{V}, \\underbrace{\\{a,b\\}}_{\\Sigma}, S, P)\\) mit \\(P = \\{S \\rightarrow \\varepsilon | a | b | aSa | bSb \\}\\) . Schritt 1 \\(S \\rightarrow \\varepsilon | Y_a | Y_b | Y_aSY_a | Y_bSY_b\\) \\(Y_a \\rightarrow a\\) \\(Y_b \\rightarrow b\\) Schritt 2 \\(S \\rightarrow \\varepsilon | Y_a | Y_b | Y_aC_1 | Y_bC_2\\) \\(C_1 \\rightarrow SY_a\\) \\(C_2 \\rightarrow SY_b\\) \\(Y_a \\rightarrow a\\) \\(Y_b \\rightarrow b\\) Schritt 3 \\(S \\rightarrow Y_a | Y_b | Y_aC_1 | Y_bC_2\\) \\(C_1 \\rightarrow SY_a\\) \\(C_2 \\rightarrow SY_b\\) \\(Y_a \\rightarrow a\\) \\(Y_b \\rightarrow b\\) \\(S' \\rightarrow S | \\varepsilon\\) Schritt 4 Keine Kettenregel vorhanden. Ergebnis Nun werden noch einzelne Nicht-Terminale durch die mÃ¶glichen Terminale ersetzt und man ist fertig. Damit ist die Grammatik: \\(G_{CNF} (\\{S, S', Y_a, Y_b, C_1, C_2\\}, \\{a,b\\}, S', P'))\\) mit folgenden Produktionen P': \\(P' = \\{S \\rightarrow a | b | Y_aC_1 | Y_bC_2,\\) \\(~ C_1 \\rightarrow SY_a,\\) \\(~ C_2 \\rightarrow SY_b,\\) \\(~ Y_a \\rightarrow a,\\) \\(~ Y_b \\rightarrow b,\\) \\(~ S' \\rightarrow S | \\varepsilon\\}\\) Sie ist also nicht schÃ¶ner oder einfacher geworden, hat aber eine bestimmte Struktur erhalten. WeiterfÃ¼hrende Links und Quellen Wikipedia Uwe SchÃ¶ning: Theoretische Informatik- kurz gefasst . 5. Auflage. Spektrum Akademischer Verlag, Heidelberg 2008 , ISBN 978-3-8274-1824-1, S. 44, DNB 986529222 . KIT: Skript von Prof. Dr. Dorothea Wagner, S. 98 Ãœbung vom 02.02.2012 - Hier ist ein sehr gutes, detailliertes Beispiel!","tags":"German posts","title":"Konstruktion der Chomsky-Normalform"},{"url":"https://martin-thoma.com/minimierung-eines-automaten-mittels-aquivalenzklassenkonstruktion/","text":"Wenn ein Endlicher Automat gegeben ist, kann durch die Konstruktion von Ã„quivalenzklassen sehr einfach ein Automat mit gleichem Akzeptanzverhalten und minimaler Anzahl an ZustÃ¤nden gefunden werden. DafÃ¼r benÃ¶tigt man im Wesentlichen sogar nur drei Schritte. Der Algorithmus ÃœberflÃ¼ssige ZustÃ¤nde streichen : Manche ZustÃ¤nde sind nicht erreichbar. Diese kÃ¶nnen offensichtlich gestrichen werden. Akzeptierende von nichtakzeptierenden ZustÃ¤nden trennen : Alle akzeptierenden ZustÃ¤nde werden in eine Ã„quivalenzklasse gepackt, alle ZustÃ¤nde die nicht akzeptieren kommen in eine andere Klasse. ZustÃ¤nde trennen : FÃ¼r jedes Zeichen des Eingabealphabets $\\Sigma$ schreibt man sich auf, in welchen Zustand der Zustand fÃ¼hrt. Wenn zwei ZustÃ¤nde in verschiedene Klassen fÃ¼hren, werden diese getrennt. Dies wiederholt man so lange, bis man ein mal alle Zeichen aus $\\Sigma$ durchgegangen ist, ohne dass ZustÃ¤nde getrennt wurden. Beispiel Gegeben sei folgender Endlicher Automat A: \\(A = (\\{0,1\\}, \\{S, A, B, C, D, E, F, G, H, I\\}, S, \\sigma, \\{D\\})\\) mit folgender Ãœbergangsfunktion \\(\\sigma\\) : Endlicher Automat mit Ã¼berflÃ¼ssigen ZustÃ¤nden Es ist offensichtlich, dass I nicht erreicht werden kann. Da der Graph gerichtet ist, kann man schnell sehen, dass auch H und G nicht erreicht werden kÃ¶nnen. Algorithmisch kann man diese ZustÃ¤nde durch eine Tiefensuche bestimmen. Nach Schritt 1 haben wir also den Automaten \\(A_1 = (\\{0,1\\}, \\{S, A, B, C, D, E, F\\}, S, \\sigma, \\{D\\})\\) : Keine Ã¼berflÃ¼ssen ZustÃ¤nde im Endlichen Automaten In Schritt 2 erstellen wir also zuerst eine Ã„quivalenzklasse der ZustÃ¤nde: \\(\\{S, A, B, C, D, E, F\\}\\) . Die akzeptierenden ZustÃ¤nde werden von den nicht akzeptierenden getrennt: \\(\\{D\\}, \\{S, A, B, C, E, F\\}\\) In Schritt 3 gehen wir nun immer wieder die Zeichen \"0\" und \"1\" aus \\(\\Sigma\\) durch: In welche Klassen fÃ¼hrt \"0\"? C wird also von \\(\\{S, A, B, E, F\\}\\) getrennt. Wir haben folgende Klassen: \\(\\{C\\}, \\{D\\}, \\{S, A, B, E, F\\}\\) \"1\" trennt nun \"A\" von \\(\\{S, B, E, F\\}\\) : \"0\" trennt nun \"S\" von \\(\\{B, E, F\\}\\) : Wir haben nun die Ã„quivalenzklassen \\(\\{S\\}, \\{A\\}, \\{C\\}, \\{D\\}, \\{B, E, F\\}\\) . Im nÃ¤chsten Schritt sehen wir, dass \"1\" nicht mehr trennt und \"0\" auch nicht nochmals etwas trennt. Wir sind also fertig. Die ZustÃ¤nde B, E und F kÃ¶nnen zu einem zusammengefasst werden. Ich nenne ihn mal T (fÃ¼r Trash, da man in diesem Zustand niemals mehr akzeptieren kann). Damit ist unser minimaler Endlicher Automat folgender: LaTeX Das ist der LaTeX-Code fÃ¼r die Automaten: \\ documentclass { scrartcl } \\ usepackage { amsmath } \\ usepackage { tikz } \\ usepackage { pst - node } \\ usetikzlibrary { arrows , automata } \\ begin { document } \\ begin { tikzpicture }[ >= stealth ',shorten >=1pt,auto,node distance=2cm] \\ node [ initial , state ] ( S ) { $ S $ }; \\ node [ state ] ( A ) [ below of = S , left of = S ] { $ A $ }; \\ node [ state ] ( B ) [ below of = A ] { $ B $ }; \\ node [ state ] ( C ) [ below of = A , right of = A ] { $ C $ }; \\ node [ state , accepting ] ( D ) [ right of = A , below of = S ] { $ D $ }; \\ node [ state ] ( E ) [ below of = C ] { $ E $ }; \\ node [ state ] ( F ) [ below of = B ] { $ F $ }; \\ node [ state ] ( G ) [ left of = B ] { $ G $ }; \\ node [ state ] ( H ) [ right of = S ] { $ H $ }; \\ node [ state ] ( I ) [ left of = A ] { $ I $ }; \\ path [ -> ] ( S ) edge node { 0 , 1 } ( A ); \\ path [ -> ] ( A ) edge node { 0 } ( B ); \\ path [ -> ] ( A ) edge node { 1 } ( C ); \\ path [ -> ] ( B ) edge node { 0 , 1 } ( F ); \\ path [ -> ] ( C ) edge node { 0 } ( D ); \\ path [ -> ] ( C ) edge node { 1 } ( E ); \\ path [ -> ] ( D ) edge node { 0 , 1 } ( S ); \\ path [ -> ] ( E ) edge [ loop right ] node { 0 , 1 } ( E ); \\ path [ -> ] ( F ) edge [ loop left ] node { 0 , 1 } ( F ); \\ path [ -> ] ( G ) edge node { 0 } ( B ); \\ path [ -> ] ( G ) edge node { 1 } ( F ); \\ path [ -> ] ( H ) edge node { 0 , 1 } ( S ); \\ path [ -> ] ( I ) edge [ loop above ] node { 0 , 1 } ( I ); \\ end { tikzpicture } Ueberfluessige weg : \\ begin { tikzpicture }[ >= stealth ',shorten >=1pt,auto,node distance=2cm] \\ node [ initial , state ] ( S ) { $ S $ }; \\ node [ state ] ( A ) [ below of = S , left of = S ] { $ A $ }; \\ node [ state ] ( B ) [ below of = A ] { $ B $ }; \\ node [ state ] ( C ) [ below of = A , right of = A ] { $ C $ }; \\ node [ state , accepting ] ( D ) [ right of = A , below of = S ] { $ D $ }; \\ node [ state ] ( E ) [ below of = C ] { $ E $ }; \\ node [ state ] ( F ) [ below of = B ] { $ F $ }; \\ path [ -> ] ( S ) edge node { 0 , 1 } ( A ); \\ path [ -> ] ( A ) edge node { 0 } ( B ); \\ path [ -> ] ( A ) edge node { 1 } ( C ); \\ path [ -> ] ( B ) edge node { 0 , 1 } ( F ); \\ path [ -> ] ( C ) edge node { 0 } ( D ); \\ path [ -> ] ( C ) edge node { 1 } ( E ); \\ path [ -> ] ( D ) edge node { 0 , 1 } ( S ); \\ path [ -> ] ( E ) edge [ loop right ] node { 0 , 1 } ( E ); \\ path [ -> ] ( F ) edge [ loop left ] node { 0 , 1 } ( F ); \\ end { tikzpicture } Minimal : \\ begin { tikzpicture }[ >= stealth ',shorten >=1pt,auto,node distance=2cm] \\ node [ initial , state ] ( S ) { $ S $ }; \\ node [ state ] ( A ) [ below of = S , left of = S ] { $ A $ }; \\ node [ state ] ( B ) [ below of = A ] { $ T $ }; \\ node [ state ] ( C ) [ below of = A , right of = A ] { $ C $ }; \\ node [ state , accepting ] ( D ) [ right of = A , below of = S ] { $ D $ }; \\ path [ -> ] ( S ) edge node { 0 , 1 } ( A ); \\ path [ -> ] ( A ) edge node { 0 } ( B ); \\ path [ -> ] ( A ) edge node { 1 } ( C ); \\ path [ -> ] ( B ) edge [ loop left ] node { 0 , 1 } ( B ); \\ path [ -> ] ( C ) edge node { 0 } ( D ); \\ path [ -> ] ( C ) edge node { 1 } ( B ); \\ path [ -> ] ( D ) edge node { 0 , 1 } ( S ); \\ end { tikzpicture } \\ end { document } Und hier die Bilder mit den Pfeilchen: \\ documentclass { article } \\ usepackage { amsmath } \\ usepackage { tikz } \\ usetikzlibrary { calc , shapes } \\ newcommand { \\ tikzmark }[ 1 ]{ \\ tikz [ overlay , remember picture ] \\ node ( #1) {};} \\ newcommand { \\ DrawBoxi }[ 5 ]{ \\ begin { tikzpicture }[ overlay , remember picture , - latex , shorten >= 5 pt , shorten <= 5 pt , out = 70 , in = 130 ] \\ draw [ distance = 0.9 cm , #1] (s.north) to (a.north); % \\ draw [ distance = 0.45 cm , #2] (a.north) to (b.north); \\ draw [ distance = 0.7 cm , #3] (b.north) to (f.north); % \\ draw [ distance = 1.1 cm , #4] (c.north) to (d.north); \\ draw [ distance = 0.45 cm , #5] (e.north) to (e.north); \\ draw [ distance = 0.45 cm , #5] (f.north) to (f.north); \\ end { tikzpicture } } \\ newcommand { \\ DrawBoxii }[ 5 ]{ \\ begin { tikzpicture }[ overlay , remember picture , - latex , shorten >= 5 pt , shorten <= 5 pt , out = 70 , in = 130 ] \\ draw [ distance = 0.45 cm , #1] (s.north) to (a.north); \\ draw [ distance = 0.8 cm , #2] (a.north) to (c.north); \\ draw [ distance = 0.9 cm , #3] (b.north) to (f.north); \\ draw [ distance = 0.45 cm , #5] (e.north) to (e.north); \\ end { tikzpicture } } \\ begin { document } Schritt 3 - 1.0 : \\ begin { gather * } % \\ { D \\ tikzmark { d } \\ } ~ \\ { S \\ tikzmark { s }, A \\ tikzmark { a }, B \\ tikzmark { b }, C \\ tikzmark { c }, E \\ tikzmark { e }, F \\ tikzmark { f } \\ } \\ DrawBoxi { red }{ blue }{ green }{ purple }{ orange } \\\\ \\ end { gather * } Schritt 3 - 1.1 : \\ begin { gather * } % \\ { C \\ tikzmark { c } \\ } ~ \\ { D \\ tikzmark { d } \\ } ~ \\ { S \\ tikzmark { s }, \\ tikzmark { a } A , B \\ tikzmark { b }, E \\ tikzmark { e }, F \\ tikzmark { f } \\ } \\ DrawBoxii { red }{ blue }{ green }{ purple }{ orange } \\\\ \\ end { gather * } Schritt 3 - 2.0 : \\ begin { gather * } \\ { \\ tikzmark { a } A \\ } ~ \\ { C \\ tikzmark { c } \\ } ~ \\ { D \\ tikzmark { d } \\ } ~ \\ { \\ tikzmark { s } S , \\ tikzmark { b } B , E \\ tikzmark { e }, F \\ tikzmark { f } \\ } \\ DrawBoxi { red }{ blue }{ green }{ purple }{ orange } \\\\ \\ end { gather * } \\ end { document }","tags":"German posts","title":"Minimierung eines Automaten mittels Ã„quivalenzklassenkonstruktion"},{"url":"https://martin-thoma.com/linux-memory-consumption/","text":"free I've you want to check your memory consumption on a Linux machine, you can use free. moose@pc07:~$ free -m total used free shared buffers cached Mem: 3952 2832 1119 0 117 1565 -/+ buffers/cache: 1150 2802 Swap: 8656 0 8656 This means: I have a total of 3952 MB RAM , used and free should be clear, shared is memory which is shared between processes, e.g. shared libraries. The \"buffers\" entry tells you how much of your RAM is being used for disk buffering. Over 8 GB got swapped out. top top will give you something like Windows' task manager in the command line. If you press \"M\" it gets sorted by memory utilization: top sorted by memory utilization pmap pmap reports a memory map of a process. Lets make an example. Eclipse has the process ID (pid) 4526 at the moment. pmap 4526 gives the following output: 4526 : /usr/lib/eclipse/eclipse Address Kbytes Mode Offset Device Mapping 08048000 16 r-x-- 0000000000000000 008 :00001 eclipse 0804c000 4 r---- 0000000000003000 008 :00001 eclipse 0804d000 4 rw--- 0000000000004000 008 :00001 eclipse 096c4000 11608 rw--- 0000000000000000 000 :00000 [ anon ] 62e40000 43776 rw--- 0000000000000000 000 :00000 [ anon ] 65900000 130944 rw--- 0000000000000000 000 :00000 [ anon ] 6d8e0000 87424 rw--- 0000000000000000 000 :00000 [ anon ] 72e40000 262144 rw--- 0000000000000000 000 :00000 [ anon ] 82e40000 44800 rw--- 0000000000000000 000 :00000 [ anon ] 85a00000 512 ----- 0000000000000000 000 :00000 [ anon ] 85a80000 216832 rw--- 0000000000000000 000 :00000 [ anon ] 92e40000 6312 r--s- 0000000000001000 008 :00001 classes.jsa 9346a000 3928 rw--- 0000000000000000 000 :00000 [ anon ] 93840000 7412 rw--- 000000000062b000 008 :00001 classes.jsa 93f7d000 4876 rw--- 0000000000000000 000 :00000 [ anon ] 94440000 904 rw--- 0000000000d68000 008 :00001 classes.jsa 94522000 3192 rw--- 0000000000000000 000 :00000 [ anon ] 94840000 32 r-xs- 0000000000e4a000 008 :00001 classes.jsa 94848000 4064 rw--- 0000000000000000 000 :00000 [ anon ] b17f5000 44 r--s- 0000000000070000 008 :00001 org.eclipse.jdt.junit_3.5.2.r352_v20100113-0800.jar b1800000 144 rw--- 0000000000000000 000 :00000 [ anon ] b1824000 880 ----- 0000000000000000 000 :00000 [ anon ] b1909000 12 ----- 0000000000000000 000 :00000 [ anon ] b190c000 312 rwx-- 0000000000000000 000 :00000 [ anon ] b195a000 12 ----- 0000000000000000 000 :00000 [ anon ] b195d000 312 rwx-- 0000000000000000 000 :00000 [ anon ] b19ab000 12 ----- 0000000000000000 000 :00000 [ anon ] b19ae000 312 rwx-- 0000000000000000 000 :00000 [ anon ] b19fc000 12 ----- 0000000000000000 000 :00000 [ anon ] b19ff000 312 rwx-- 0000000000000000 000 :00000 [ anon ] b1a4d000 16 r-x-- 0000000000000000 008 :00001 libattr.so.1.1.0 b1a51000 4 r---- 0000000000003000 008 :00001 libattr.so.1.1.0 b1a52000 4 rw--- 0000000000004000 008 :00001 libattr.so.1.1.0 b1a53000 24 r-x-- 0000000000000000 008 :00001 libfam.so.0.0.0 b1a59000 4 r---- 0000000000006000 008 :00001 libfam.so.0.0.0 b1a5a000 4 rw--- 0000000000007000 008 :00001 libfam.so.0.0.0 b1a5b000 24 r-x-- 0000000000000000 008 :00001 libacl.so.1.1.0 b1a61000 4 r---- 0000000000006000 008 :00001 libacl.so.1.1.0 b1a62000 4 rw--- 0000000000007000 008 :00001 libacl.so.1.1.0 b1a63000 48 r-x-- 0000000000000000 008 :00001 libfile.so b1a6f000 4 r---- 000000000000b000 008 :00001 libfile.so b1a70000 4 rw--- 000000000000c000 008 :00001 libfile.so b1a71000 100 r--s- 0000000000000000 008 :00001 mime.cache b1a8a000 12 r-x-- 0000000000000000 008 :00001 libgpg-error.so.0.4.0 b1a8d000 4 r---- 0000000000002000 008 :00001 libgpg-error.so.0.4.0 [ ... ] b755a000 4 r--s- 0000000000001000 008 :00001 runtime_registry_compatibility.jar b755b000 4 rw--- 0000000000000000 000 :00000 [ anon ] b755c000 28 r-x-- 0000000000000000 008 :00001 libvorbisfile.so.3.3.2 b7563000 4 r---- 0000000000006000 008 :00001 libvorbisfile.so.3.3.2 b7564000 4 rw--- 0000000000007000 008 :00001 libvorbisfile.so.3.3.2 b7565000 16 r-x-- 0000000000000000 008 :00001 libcanberra-gtk-module.so b7569000 4 ----- 0000000000004000 008 :00001 libcanberra-gtk-module.so b756a000 4 r---- 0000000000004000 008 :00001 libcanberra-gtk-module.so b756b000 4 rw--- 0000000000005000 008 :00001 libcanberra-gtk-module.so b756c000 44 r-x-- 0000000000000000 008 :00001 eclipse_1208.so b7577000 4 r---- 000000000000a000 008 :00001 eclipse_1208.so b7578000 4 rw--- 000000000000b000 008 :00001 eclipse_1208.so b7579000 252 r---- 0000000000000000 008 :00001 LC_CTYPE b75b8000 1144 r---- 0000000000000000 008 :00001 LC_COLLATE b76d6000 4 rw--- 0000000000000000 000 :00000 [ anon ] b76d7000 1356 r-x-- 0000000000000000 008 :00001 libc-2.11.1.so b782a000 4 ----- 0000000000153000 008 :00001 libc-2.11.1.so b782b000 8 r---- 0000000000153000 008 :00001 libc-2.11.1.so b782d000 4 rw--- 0000000000155000 008 :00001 libc-2.11.1.so b782e000 16 rw--- 0000000000000000 000 :00000 [ anon ] b7832000 8 r-x-- 0000000000000000 008 :00001 libdl-2.11.1.so b7834000 4 r---- 0000000000001000 008 :00001 libdl-2.11.1.so b7835000 4 rw--- 0000000000002000 008 :00001 libdl-2.11.1.so b7836000 84 r-x-- 0000000000000000 008 :00001 libpthread-2.11.1.so b784b000 4 r---- 0000000000014000 008 :00001 libpthread-2.11.1.so b784c000 4 rw--- 0000000000015000 008 :00001 libpthread-2.11.1.so b784d000 8 rw--- 0000000000000000 000 :00000 [ anon ] b784f000 4 r---- 0000000000000000 000 :00000 [ anon ] b7850000 4 r---- 0000000000000000 008 :00001 LC_NUMERIC b7851000 4 r---- 0000000000000000 008 :00001 LC_TIME b7852000 4 r---- 0000000000000000 008 :00001 LC_MONETARY b7853000 4 r---- 0000000000000000 008 :00001 SYS_LC_MESSAGES b7854000 4 r---- 0000000000000000 008 :00001 LC_PAPER b7855000 4 r---- 0000000000000000 008 :00001 LC_NAME b7856000 4 r---- 0000000000000000 008 :00001 LC_ADDRESS b7857000 4 r---- 0000000000000000 008 :00001 LC_TELEPHONE b7858000 4 r---- 0000000000000000 008 :00001 LC_MEASUREMENT b7859000 28 r--s- 0000000000000000 008 :00001 gconv-modules.cache b7860000 4 r---- 0000000000000000 008 :00001 LC_IDENTIFICATION b7861000 8 rw--- 0000000000000000 000 :00000 [ anon ] b7863000 4 r-x-- 0000000000000000 000 :00000 [ anon ] b7864000 108 r-x-- 0000000000000000 008 :00001 ld-2.11.1.so b787f000 4 r---- 000000000001a000 008 :00001 ld-2.11.1.so b7880000 4 rw--- 000000000001b000 008 :00001 ld-2.11.1.so bfa49000 12 ----- 0000000000000000 000 :00000 [ anon ] bfa4d000 304 rwx-- 0000000000000000 000 :00000 [ stack ] bfa99000 4 rw--- 0000000000000000 000 :00000 [ anon ] mapped: 927836K writeable/private: 881752K shared: 13572K So at the moment eclipse is using 927MB of virtual memory. But it need \"only\" about 186 MB real, physical memory. According to virtualthreads.blogspot.com all data segments have the access rights rw--- and all code segments have the rights r-x--. vmstat Virtual memory statistics gives you the following information: Here is the example: moose@pc07:~$ vmstat procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu---- r b swpd free buff cache si so bi bo in cs us sy id wa 0 0 0 1120696 119948 1599112 0 0 21 35 416 116 12 5 82 1 --memory-- swpd : sum of the used virtual memory. free : amount of unused physical memory. buff : amount of physical memory which gets used as disc-buffer. cache : amount of physical memory which gets used as cache. --swap-- si : amount of memory which gets loaded from hdd to your RAM. If this is positive, you need more RAM. so : amount of memory which gets loaded from RAM to hdd. --io-- bi : input of block devices bo : output of block devices --system-- in : Number of interrupts per second cs : Context-switches per second --cpu-- us : CPU time spent for user processes sy : CPU time spent for kernel processes id : idle processor time wa : Waiting for input / output Sources LinuxWiki (German) cyberciti.biz","tags":"Code","title":"Linux Memory Consumption"},{"url":"https://martin-thoma.com/wt-klausur/","text":"Morgen schreibe ich eine Klausur in Wahrscheinlichkeitstheorie. Zum GlÃ¼ck dÃ¼rfen wir das Skript und Notizen mitnehmen. Diesen netten, kleinen Zettel mit Formeln habe ich gerade erstellt. Falls ihr die LaTeX-Datei anpassen wollt, kÃ¶nnt ihr sie hier herunterladen. Hier noch ein paar Hinweise: Klausur Informatik: 08. Februar 2012, 17.45 â€“ 19.15 Uhr . Teilnehmer mit Nachnamen Aa -- Kon schreiben die Klausur im Audimax, Geb. 30.95 Teilnehmer mit Nachnamen Kor -- Zz schreiben die Klausur im Gerthsen-HÃ¶rsaal, Geb. 30.21 Material Skript im Skripteverkauf Visual Information Theory Nicht vergessen Skript + Mitschrift Studentenausweis Taschenrechner Kugelschreiber","tags":"German posts","title":"Wahrscheinlichkeitstheorie - Klausur (Info)"},{"url":"https://martin-thoma.com/stop-acta/","text":"Stopp ACTA! What is ACTA? The Anti-Counterfeiting Trade Agreement (ACTA) is a trade agreement between the following states: United States: signed 1 October 2011 in Tokyo Australia: signed 1 October 2011 in Tokyo Canada: signed 1 October 2011 in Tokyo Japan: signed 1 October 2011 in Tokyo Morocco: signed 1 October 2011 in Tokyo New Zealand: signed 1 October 2011 in Tokyo Singapore: signed 1 October 2011 in Tokyo South Korea: signed 1 October 2011 in Tokyo European Union and 22 Member States: signed on 26 January 2012; final enactment into law is on hold pending a debate in the European Parliament in June 2012. Germany: not signed yet Cyprus: not signed yet Estonia: not signed yet Netherlands: not signed yet Slovakia: not signed yet Mexico: Switzerland: Those countries describe it as a response \"to the increase in global trade of counterfeit goods and pirated copyright protected works.\" It would create a governing body outside international institutions such as the World Trade Organization (WTO), the World Intellectual Property Organization (WIPO) or the United Nations. The scope of ACTA includes counterfeit goods, generic medicines and copyright infringement on the Internet. An official Summary of Key Elements Under Discussion published November 2009 states that \"ACTA aims to build on existing international rules in the area of intellectual property, in particular on the TRIPS Agreement, and is intended to address a number of enforcement issues where participants have identified that an international legal framework does not exist or needs to be strengthened.\" On 10 March 2010, the European Parliament adopted a resolution criticizing the ACTA with 663 in favor of the resolution and 13 against, arguing that \"in order to respect fundamental rights, such as the right to freedom of expression and the right to privacy\" certain changes in the ACTA content and the process should be made. Who is for ACTA? Well, I guess the signing government and parliaments. I've also heard that MPAA is for ACTA ( source ). Who is against ACTA? Electronic Frontier Foundation (EFF) Chaos Computer Club several pirate partys, e.g. the German Piratenpartei ( source ) And why? treaty will restrict fundamental civil and digital rights: freedom of expression communication privacy removal of \"legal safeguards that protect Internet Service Providers from liability for the actions of their subscribers\" in effect giving ISPs no option but to comply with privacy invasions See also Wikpedia: ACTA (big parts of my article are from this wiki-article) open letter 1 Save the Internet STOPP ACTA French MEP quits and slams ACTA process as â€˜a charade'","tags":"My bits and bytes","title":"Stop ACTA"},{"url":"https://martin-thoma.com/sprachen-automaten-und-grammatiken/","text":"Die folgende Tabelle gibt einen Ãœberblick Ã¼ber formale Sprachen, die Automaten die sie akzeptieren und die Grammatiken, die sie erzeugen. Dabei haben die Grammatiken die Form \\(G = (V, \\Sigma, P, S)\\) : V: Die Menge der Nicht-Terminale. FÃ¼r sie benutze ich GroÃŸbuchstaben. \\(\\Sigma\\) : Die Menge der Terminale. FÃ¼r sie benutze ich Kleinbuchstaben. P: Die Produktion, also die Regeln mit denen die Grammatik die Sprache erzeugt. Nur diese hat unterschiedliche Bedingungen, je nach dem welchem Typ die Grammatik angehÃ¶rt. S: Das Startsymbol aus \\(\\Sigma\\) . Typ Bezeichnung Regeln Abgeschlossen unter Modell $\\cup$ $\\cap$ $\\cdot$ ${}&#94;C$ 0 semientscheidbar alles D. Turingmaschine , ND. Turingmaschine 1 kontextsensitiv $u \\rightarrow v, |a| \\leq |v|$ (ND.?) LÃ¤ngenbeschrÃ¤nkter Automat 2 kontextfrei $A \\rightarrow v$ ND. Kellerautomat 3 regulÃ¤r $A \\rightarrow \\varepsilon, A \\rightarrow aB$ Endliche Automaten ( Moore , Mealy , Akzeptoren ) Legende: Typ.: Der Typ der Grammatik in der Chomsky-Hierarchie D.: \"Deterministisch\" ND.: \"Nicht Deterministisch\" semi-entscheidbar entscheidbar , es kann also in endlicher Zeit entschieden werden, ob ein Wort in der Sprache liegt (vgl. Wortproblem ). Nicht-Abeschlossenheit der Kontextfreien Sprachen: $$L_1 = \\{a&#94;jb&#94;ic&#94;i | j \\in \\mathbb{N}_0, i \\in \\mathbb{N}_0\\}$$ $$L_2 = \\{a&#94;ib&#94;ic&#94;j | j \\in \\mathbb{N}_0, i \\in \\mathbb{N}_0\\}$$ $$L_1 \\cap L_2 = \\{a&#94;ib&#94;ic&#94;i | i \\in \\mathbb{N}_0\\}$$ $$(L_1 \\cup L_2)&#94;C = L_1&#94;C \\cap L_2&#94;C$$ Weitere Aussagen Sei L eine Sprache. \\(L \\in {\\cal L_3} \\Leftrightarrow\\) Es existiert ein regulÃ¤rer Ausdruck fÃ¼r L. \\(L \\in {\\cal L_3} \\Leftrightarrow\\) Die Anzahl der Ã„quivalenzklassen der Nerode-Relation bzgl. der Sprache ist endlich. \\(L \\in {\\cal L_3} \\Rightarrow\\) Das Pumping-Lemma ist erfÃ¼llt. FÃ¼r regulÃ¤re Sprachen ist das Leerheitsproblem ( \\(L(G) \\stackrel{?}{=} \\emptyset\\) ) entscheidbar. FÃ¼r regulÃ¤re Sprachen ist das Endlichkeitsproblem ( \\(L(G) \\stackrel{?}{<} \\infty\\) ) entscheidbar. FÃ¼r kontextfreie Sprachen ist das Leerheitsproblem entscheidbar. FÃ¼r kontextfreie Sprachen ist das Endlichkeitsproblem entscheidbar. FÃ¼r Typ 0 und Typ 1 Sprachen ist das Leerheitsproblem nicht entscheidbar. \\(L \\in {\\cal L_2} \\Leftrightarrow L\\) wird von einem nichtdeterministischem Kellerautomaten erkannt. Quellen Uwe SchÃ¶ning: Theoretische Informatik- kurz gefasst . 5. Auflage. Spektrum Akademischer Verlag, Heidelberg 2008 , ISBN 978-3-8274-1824-1, DNB 986529222 . Tutorium, Skript, Vorlesung: Theoretische Grundlagen der Informatik am KIT bei Prof. Dr. Dorothea Wagner","tags":"German posts","title":"Sprachen, Automaten und Grammatiken: Ein Ãœberblick"},{"url":"https://martin-thoma.com/plotting-function-graphs-with-latex/","text":"It's crazy how much time I have wasted today just for searching for a working example how to plot a function within LaTeX. Here are two complete examples which worked for me. I have used this command to generate the PDF-file: pdflatex latex.tex -output-format = pdf gnuplot gnuplot \\documentclass { article } \\usepackage { tikz } \\usepackage { pgfplots } \\begin { document } \\begin { tikzpicture } \\begin { axis } \\addplot +[id=parable,domain=-5:5] gnuplot { 4*x**2 - 5 } node[pin=180: { $ 4 x&#94; 2 - 5 $ } ] {} ; \\end { axis } \\end { tikzpicture } \\end { document } tikzpicture tikzpicture \\documentclass { article } \\usepackage { tikz } \\begin { document } \\begin { tikzpicture } \\draw [very thin,color=gray] (0.0,0.0) grid (1.8,3.8); \\draw [->] (-0.5,0) -- (2,0) node[right] { $ x $ } ; \\draw [->] (0,-0.5) -- (0,4) node[above] { $ y $ } ; \\draw [domain=0:1/3,red] plot ( \\x ,3*3* \\x ); \\draw [domain=1/3:2/3,red] plot ( \\x ,2*3-3*3* \\x ); \\draw [domain=2/3:1.5,red] plot ( \\x ,0); \\draw [domain=0:1/4,orange] plot ( \\x ,4*4* \\x ); \\draw [domain=1/4:2/4,orange] plot ( \\x ,2*4-4*4* \\x ); \\draw [domain=2/4:1.5,orange] plot ( \\x ,0); \\end { tikzpicture } \\end { document } Floating text If you want to wrap the text around the graph, you can use wrapfigure: \\documentclass { article } \\usepackage { tikz } \\usepackage { pgfplots } \\usepackage { wrapfig } \\begin { document } \\begin { wrapfigure }{ r }{ .2 \\textwidth } \\begin { center } \\begin { tikzpicture } \\draw [->] (-0.5,0) -- (2,0) node[right] { $ x $ } ; \\draw [->] (0,-0.5) -- (0,4) node[above] { $ y $ } ; \\draw [domain=0:1/3,red] plot ( \\x ,3*3* \\x ); \\draw [domain=1/3:2/3,red] plot ( \\x ,2*3-3*3* \\x ); \\draw [domain=2/3:1.5,red] plot ( \\x ,0); \\draw [domain=0:1/4,orange] plot ( \\x ,4*4* \\x ); \\draw [domain=1/4:2/4,orange] plot ( \\x ,2*4-4*4* \\x ); \\draw [domain=2/4:1.5,orange] plot ( \\x ,0); \\end { tikzpicture } \\end { center } \\end { wrapfigure } Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis congue dictum elit. Morbi ultricies laoreet massa, sed sagittis lorem laoreet et. Donec at erat non sem tristique rutrum vel vel justo. Vestibulum tincidunt pulvinar mi, a congue purus dignissim vel. Ut porttitor dignissim neque eget rutrum. Nunc gravida varius semper. Quisque et purus quam. Quisque ultricies tristique magna sit amet egestas. Mauris bibendum lacus semper justo consectetur blandit vitae non nisi. Etiam non augue nec est facilisis tempor. Nullam non diam vel erat fermentum gravida. Proin tincidunt turpis lobortis ante elementum suscipit. Curabitur congue, dolor fringilla feugiat blandit, quam libero euismod purus, eget commodo erat nibh a augue. Vestibulum ut tellus ac arcu semper facilisis. \\end { document } PSTricks I have found some very nice example images , but no working LaTeX-Code. Read more Wikibooks: LaTeX/Floats, Figures and Captions Manual for pgfplots with lots of examples (as images and LaTeX in over 300 pages!) TeXample.net: GNUPLOT basics , Parameterized plots , Pgfplots","tags":"My bits and bytes","title":"Plotting function graphs with LaTeX"},{"url":"https://martin-thoma.com/check-computer-hardware-for-linux-compatibility/","text":"Linux users who are not very skilled have a big problem: If they want to buy a new computer or new hardware, it is very difficult for them to find out if something works or not. I'll give you some hints how you could find it out: Debian device driver check & report This site checks your whole system. You only need to boot a Linux system (e.g. via LiveCD ) and execute: bash lspci -n in the terminal (which pops up if you type Ctrl + Alt + T). Copy it, paste it into the provided form and you will get a list of your hardware and simply \"Yes\" if this component works with Debian. Linux HCL The Linux HCL provides a lot of hand-written reviews of users. Here is my review of my notebook . UbuntuUsers German users might want to take a look at the wiki-article \" Hardwaredatenbanken \".","tags":"Cyberculture","title":"Check Computer / Hardware for Linux-compatibility"},{"url":"https://martin-thoma.com/impact-of-sopa-protests/","text":"It seems as if the SOPA protests were quite effective. 162 Millionen visitors of Wikipedia did see the message. Zuckerbergs Facebook post got half a million Likes. Thousands bloggers downloaded protest plugins which blacked out their blog. Members of Congress position on SOPA/PIPA (found on boingboing.net ) See also SOPA Opera : Where Do Your Members of Congress Stand on SOPA and PIPA? ArsTechnica : PIPA support collapses, with 13 new Senators opposed Wikipedia : Protests against SOPA and PIPA German News: heise , heise , Golem , Golem","tags":"The Web","title":"Impact of SOPA protests"},{"url":"https://martin-thoma.com/sopa-protests/","text":"Some of the biggest sites in the internet are currently calling US citizens up to protest. SOPA - the Stop Online Piracy Act - is endangering some key aspects of the internet. I am a little bit disappointed that Google had no special doodle today and twitter had no message at all â˜¹ Well, at least did Google offer some information . Here is a neat explanation of SOPA: Wikipedia Completely blacked out: Twitter: #WikipediaBlackout By the way, if you disable JavaScript you can view Wikipedia as always. German Wiki German Wikipedia SOPA protests The Oatmeal The Oatmeal has also completely blacked out its website: Oatmeals SOPA protest Zachstronaut zachstronaut.com offers an interactive one: SOPA - Zachstronaut protests Boing Boing Boing Boing is completely blacked out: SOPA - BoingBoing protest Tucows Tucows - a site with $80.939 million USD revenue - offers some information and a link on the top. They normally offer shareware and freeware: SOPA Tucowsinc Notes Many big companies (AOL, eBay, Facebook, Google, LinkedIn, mozilla, twitter, Yahoo, zynga) wrote a letter to the Committee on the Judiciary. Participate If you want to participate, take a look at SOPAstrike.com , americancensorship.org or #striketools . Additional Paper of the Electronic Frontier Foundation and web page Position of dyn.com Position of xkcd","tags":"The Web","title":"SOPA protests"},{"url":"https://martin-thoma.com/bachelor-informatik-1-semester-was-bisher-geschah/","text":"Die erste HÃ¤lfte des Semesters ist nun vorbei und es wird Zeit zu wiederholen, was man wissen sollte. Eventuell ist diese Liste fÃ¼r ein paar Kommilitonen von nutzen. Wenn man gerade eines der Module macht, sollte man alles wissen, was in den Links steht. Naja, vielleicht nicht alles, aber man sollte auf jeden Fall die Begriffe im Schlaf definieren kÃ¶nnen. Die Links sind meist deutsche Wiki-Artikel, manchmal auch englische. Je nach dem, was ich besser fand. Einiges hÃ¤tte ich bei vielen Modulen schreiben kÃ¶nnen, z.B. der Beweis durch Induktion. Ich habe mir dann einfach eines ausgesucht und es nur da hinein geschrieben. Das ist eh schon lang genug. 1. Semester Analysis I Fachbegriffe VerknÃ¼pfungseigenschaften : Kommutativgesetz , Assoziativgesetz , Distributivgesetz Relationen : InjektivitÃ¤t , SurjektivitÃ¤t , BijektivitÃ¤t , LinkstotalitÃ¤t, Rechtseindeutigkeit, ReflexivitÃ¤t , Antisymmetrie , Symmetrie , TransitivitÃ¤t , Ordnungsrelation , Ã„quivalenzrelation Mengeneigenschaften : AbzÃ¤hlbarkeit , ÃœberabzÃ¤hlbarkeit , endlich, unendlich, BeschrÃ¤nktheit Folgeneigenschaften : Supremum , Infimum, Minimum, Maximum, Konvergenz, Divergenz, Grenzwert , Limes superior, Limes inferior, Monotonie Beweis durch vollstÃ¤ndige Induktion Teilfolgen , HÃ¤ufungswerte Reihen : Monotoniekriterium, Dreiecksungleichung Umordnungen und Produktreihen Potenzreihen , Konvergenzradius g-adische Entwicklungen Funktionen : Grenzwerte, HÃ¤ufungspunkte, Stetigkeit , abgeschlossen, offen, gleichmÃ¤ÃŸige Konvergenz , gleichmÃ¤ÃŸige Stetigkeit , Lipschitz-Stetigkeit SÃ¤tze Satz von Bolzano-WeierstraÃŸ Cauchy-Kriterium Leibniz-Kriterium Majorantenkriterium und Minorantenkriterium Wurzelkriterium Quotientenkriterium Riemannscher Umordnungssatz Formeln $\\binom{n}{k} + \\binom{n}{k-1} = \\binom{n+1}{k}$ $a&#94;{n+1} - b&#94;{n+1} = (a - b) \\sum_{k=0}&#94;{n} a&#94;{n-k} b&#94;{k}$ Bernoullische Ungleichung : $x \\geq -1: (1+x)&#94;n \\geq 1 + nx ~ \\forall n \\in \\mathbb{N}$ Binomischer Lehrsatz : $(a+b)&#94;n = \\sum_{k=0}&#94;{n} \\binom{n}{k}a&#94;{n-k} b&#94;k ~ \\forall n \\in \\mathbb{N}$ Wichtige Grenzwerte $\\sqrt[n\\,]{n} \\rightarrow 1 (n \\rightarrow \\infty)$ $e = \\lim_{n \\to \\infty} (1+\\frac{1}{n})&#94;n = \\lim_{n \\to \\infty} \\sum_{k=0}{n} \\frac{1}{k!}$ Wichtige Reihen Harmonische Reihe : $\\sum_{n=1}&#94;\\infty \\frac{1}{n}$ (Divergent) Geometrische Reihe : $\\sum_{n=0}&#94;{\\infty} x&#94;n (x \\in \\mathbb{R})$. Konvergiert, falls |x| < 1 gegen $\\frac{1}{1-x}$ Alternierende Harmonische Reihe : $\\sum_{n=1}&#94;{\\infty} (-1)&#94;{n+1} \\frac{1}{n}$ $e&#94;x = \\sum_{n=0}{\\infty} \\frac{x&#94;n}{x!}$ Kosinus: $cos(x) = \\sum_{n=0}{\\infty} (-1)&#94;n \\cdot \\frac{x&#94;{2n}}{(2n)!} (x \\in \\mathbb{R})$ Sinus: $sin(x) = \\sum_{n=0}&#94;{\\infty} (-1)&#94;n \\cdot \\frac{x&#94;{2n+1}}{(2n+1)!} (x \\in \\mathbb{R}$ Cosinus Hyperbolikus: $cosh(x) = \\frac{1}{2} (e&#94;x + e&#94;{-x}) (x \\in \\mathbb{R})$ Sinus Hyperbolikus: $sinh(x) = \\frac{1}{2} (e&#94;x - e&#94;{-x}) (x \\in \\mathbb{R})$ Links und Materialien Skript MIT OpenCourseWare Lineare Algebra Algebraische Strukturen Gruppen : Definition Beispiele: alle Ringe und KÃ¶rper Ringe : Definition Beispiele: alle KÃ¶rper Gegenbeispiele: $(\\mathbb{N}, +, \\cdot)$ KÃ¶rper : Definition Beispiele: $(\\mathbb{Q}, +, \\cdot), (\\mathbb{R}, +, \\cdot), (\\mathbb{C}, +, \\cdot), (\\mathbb{Z}/p\\mathbb{Z}, +, \\cdot)$ Gegenbeispiele: $(\\mathbb{Z}, +, \\cdot)$ VektorrÃ¤ume : Definition Beispiele: $\\mathbb{R}&#94;2, \\mathbb{R}&#94;3, ... , \\mathbb{R}&#94;n,$ Ring der Polynome Algorithmen GauÃŸsches Eliminationsverfahren : Was bedeuten Nullzeilen? Wann hat das LGS keine / eine / viele LÃ¶sungen? Welche Operationen erlaubt der Algorithmus? Matrixmultiplikation Dies und das Permutationen und Transpositionen, Identische Abbildung Direkte Summe Schnitt zweier VektorrÃ¤ume berechnen Was bedeuten die folgenden Symbole: $\\subseteq, \\subset, \\subsetneq, \\cup, \\setminus, \\cap, \\emptyset$ Regeln von de Morgan : $(A \\cup B)&#94;C = A&#94;C \\cap B&#94;C$ und $(A \\cap B)&#94;C = A&#94;C \\cup B&#94;C$ Homomorphismen , Isomorphismen ( Automorphismus ) Charakteristik , Lineare HÃ¼lle , Erzeugendensystem , Basis , Standardbasis , Basiswechsel Links und Materialien MIT OpenCourseWare ( Video Lectures ) Programmieren Nur grundlagen in Java: Objekt Klasse Instanz Methode Getter und Setter Rekursion Zugriffsmodifikatoren: public, protected, private abstract Javadoc .equals, .toString Grundbegriffe der Informatik Aussagenlogik Was bedeuten die folgenden Symbole: $\\Rightarrow, \\Leftrightarrow, \\neg, \\land, \\lor, \\forall, \\exists$ Formale Sprachen Wo ist der Unterschied zwischen $\\varepsilon$ und $\\emptyset$? Alphabet , Wort , Grammatik , Sprache Graphen gerichtete , ungerichtete und gewichtete Graphen Baum , Wurzel , BinÃ¤rbaum Schleife , Schlinge, Kreis Dies und das Zusicherungen, Schleifeninvariante Huffman-Codierung Algorithmus von Warshall , Adjazenzmatrix Landau-Symbole : $\\cal O, \\Omega, \\Theta$ Mealy-Automat und Moore-Automat 3. Semester Betriebssysteme Dies und das POSIX policy and mechanism multiprogramming and Batch processing Zombie and Orphan , fork , fork bomb Memory layout of a process (Stack, Heap, BSS, data, rodata, text) (synchroner / asynchroner) Interrupt , Excaption, Trap, System Call Multithreaded Programming Deadlock Mutual exclusion, hold and wait, No preemption Critical section , semaphore , mutex , binary semaphore Spinlock Progress, Bounded waiting Race Condition Cache Cache CPU cache Write through und write back policy LokalitÃ¤tseigenschaft Scheduling scheduler Gantt chart turnaround time, response time, waiting time Starvation hardware requirements of preemptitive scheduling dispatcher Memory Management TLB: Translation Lookaside Buffer Swapping: Roll out, Roll in Allocation Relocation Segmentation Paging First-fit, Best-fit, Worst-fit External Fragmentation, Internal Fragmentation Compile Time, Load time, Execution time Segment table Theoretische Grundlagen der Informatik Automaten DEA : $(Q, \\Sigma, \\delta: Q \\times \\Sigma \\rightarrow Q, s \\in Q, F \\subseteq Q)$ NEA : $(Q, \\Sigma, \\delta: Q \\times \\Sigma \\rightarrow 2&#94;Q, s \\in Q, F \\subseteq Q)$, wobei $2&#94;Q$ die Potenzmenge von Q ist. Ã„quivalenz von DEA und NEA sowie die Konstruktion Turingmaschine : $(Q, \\Sigma, \\square, \\Gamma, s \\in Q, \\delta: Q \\times \\Gamma \\rightarrow Q \\times \\Gamma \\times \\{L, R, N\\}, F \\subseteq Q)$ Church'che These Satz von Rice Orakelmodul, Orakelband und Orakel-Turingmaschine Sprachen und Probleme Kleene'scher Abschluss : $L&#94;*$ Positiver Abschluss: $L&#94;+$ Produktsprache: $L_1 \\cdot L_2$ Komplementsprache: $L&#94;C := \\Sigma&#94;* \\setminus L$ RegulÃ¤re Sprachen : Alle von einem DEA erkannten Sprachen. Pumping-Lemma Nerode-Relation Entscheidbarkeit , Berechenbarkeit Diagonalsprache , Halteproblem , Universelle Sprache, Postsches Korrespondenzproblem Entscheidungsprobleme, Optimalwertprobleme , Optimierungsprobleme, Suchprobleme SAT , TSP , 3-SAT , CLIQUE , 3COLOR , EXACT COVER , SUBSET SUM , PARTITION Approximationen, ApproximationsgÃ¼te KomplexitÃ¤tsklassen P und co-P NP und co-NP NPC und Satz von Cook P vs. NP : Wie kÃ¶nnte es bewiesen / wiederlegt werden? $\\cal NPI := NP \\setminus (P \\cup NPC)$ NP-schwer Wahrscheinlichkeitstheorie Hier haben wir ja die \"Wahrscheinlichkeitstheorie und Statistik fÃ¼r Studierende der Informatik und des Ingenieurwesens\" von Prof. Dr. N. Henze und Priv.-Doz. Dr. D. Kadelka. Das haben wir vermutlich auch schon durchgearbeitet. Da dieses Skript sehr ausfÃ¼hrlich ist und in die Klausur mitgenommen werden darf, sehe ich eigentlich keinen Bedarf an weiteren ErklÃ¤rungen. Es ist allerdings sehr zu empfehlen, die 11 ÃœbungsblÃ¤tter im VAB (Vorlesungsarbeitsbereich, PasswortgeschÃ¼tzt unter studium.kit.edu) zu machen!","tags":"German posts","title":"Bachelor Informatik, 1. Semester: Was bisher geschah"},{"url":"https://martin-thoma.com/wie-bildet-man-den-schnitt-zweier-vektorraume/","text":"Angaben Gegeben sind zwei UntervektorrÃ¤ume des \\(\\mathbb{R}&#94;4\\) : \\(U_1 := \\left [ \\begin{pmatrix} 2 \\\\ 5 \\\\ 3 \\\\ 17 \\end{pmatrix} , \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{pmatrix} , \\begin{pmatrix} 1 \\\\ 3 \\\\ 3 \\\\ 7 \\end{pmatrix} , \\begin{pmatrix} -1 \\\\ 1 \\\\ -1 \\\\ 1 \\end{pmatrix} \\right ]\\) \\(U_2 := \\left [ \\begin{pmatrix} 0 \\\\ 0 \\\\ 4 \\\\ 2 \\end{pmatrix} , \\begin{pmatrix} 3 \\\\ 1 \\\\ 4 \\\\ 1 \\end{pmatrix} , \\begin{pmatrix} 2 \\\\ 7 \\\\ 1 \\\\ 8 \\end{pmatrix} , \\begin{pmatrix} 36 \\\\ 126 \\\\ 8 \\\\ 139 \\end{pmatrix} \\right ]\\) . Aufgabe Finde eine Basis fÃ¼r \\(U_1 \\cap U_2\\) . Zusatzaufgabe: Finde eine Basis fÃ¼r \\(U_1 + U_2\\) . Basis finden Will man eine mÃ¶glichst einfache Basis, also ein minimales Erzeugendensystem mit mÃ¶glichst kleinen Zahlen zu einem gegebenem Vektorraum finden, so kann man das GauÃŸsche Eliminationsverfahren auf die erzeugenden Vektoren anwenden. Dazu transponiert man die Vektoren: \\(\\left( \\begin{array}{c c c c | c} 2 & 5 & 3 & 17 & 0\\\\ 1 & 2 & 3 & 4 & 0\\\\ 1 & 3 & 3 & 7 & 0\\\\ -1 & 1 &-1 & 1 & 0 \\end{array} \\right)\\) Da im GauÃŸsche Eliminationsverfahren nur das Vertauschen von Zeilen, die Multiplikation einer Zeile mit einer Konstanten und die Addition von Zeilen zugelassen sind, bleibt die rechte Spalte immer Null. Sie kann also weggelassen werden: \\(\\left( \\begin{array}{c c c c} 2 & 5 & 3 & 17\\\\ 1 & 2 & 3 & 4\\\\ 1 & 3 & 3 & 7\\\\ -1 & 1 &-1 & 1 \\end{array} \\right) \\rightsquigarrow \\left( \\begin{array}{c c c c} 1 &-1 & 1 &-1\\\\ 0 & 3 & 2 & 5\\\\ 0 & 4 & 2 & 8\\\\ 0 & 7 & 1 & 19 \\end{array} \\right) \\rightsquigarrow \\left( \\begin{array}{c c c c} 1 &-1 & 1 &-1\\\\ 0 & 1 & \\frac{1}{2} & 2\\\\ 0 & 0 & \\frac{1}{2} & -1\\\\ 0 & 0 & -\\frac{5}{2} & 5 \\end{array} \\right) \\rightsquigarrow $ $\\left( \\begin{array}{c c c c} 1 &-1 & 1 &-1\\\\ 0 & 1 & \\frac{1}{2} & 2\\\\ 0 & 0 & 1 & -2\\\\ 0 & 0 & -5 & 10 \\end{array} \\right) \\rightsquigarrow \\left( \\begin{array}{c c c c} 1 & 0 & 0 & 4\\\\ 0 & 1 & 0 & 3\\\\ 0 & 0 & 1 & -2\\\\ 0 & 0 & 0 & 0 \\end{array} \\right)\\) Die Basis fÃ¼r \\(U_1\\) ist also \\(\\left \\{ \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 4 \\end{pmatrix} , \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 3 \\end{pmatrix} , \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\\\ -2 \\end{pmatrix} \\right \\}\\) Ich habe gerade keine Lust, das ganze fÃ¼r \\(U_2\\) noch vorzurechnen. Es kommt \\(\\left( \\begin{array}{c c c c} 1 & 0 & 0 & -\\frac{29}{38}\\\\ 0 & 1 & 0 & \\frac{49}{38}\\\\ 0 & 0 & 1 & \\frac{1}{2}\\\\ 0 & 0 & 0 & 0 \\end{array} \\right)\\) heraus, siehe Wolfram|Alpha . Die Basis fÃ¼r \\(U_2\\) ist also \\(\\left \\{ \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ -\\frac{29}{38} \\end{pmatrix} , \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ \\frac{49}{38} \\end{pmatrix} , \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\\\ \\frac{1}{2} \\end{pmatrix} \\right \\}\\) Zassenhaus-Algorithmus Bemerkung: Ich habe fÃ¼r den Zassenhaus-Algorithmus leiter die falsche Basis genommen. Der Rechenfehler zieht sich bis zum Ende durch. Wenn ich mal Zeit habe, werde ich es korrigieren (Alternativ: Wenn es jemand von euch macht, kann er den TeX-Code ja als Kommentar bereitstellen). Man transponiert die Basisvektoren von \\(U_1\\) und \\(U_2\\) und schreibt sie in eine Matrix: \\(\\left( \\begin{array}{c | c} U_1&#94;T & U_1&#94;T \\\\ \\hline U_2&#94;T & 0 \\end{array} \\right)\\) . NatÃ¼rlich nimmt man fÃ¼r \\(U_1\\) die einfachere der beiden Basen. Dann lÃ¶st man das ganze wieder mit GauÃŸ: \\(\\left( \\begin{array}{c c c c | c c c c} 1 & 0 & 0 & 4 & 1 & 0 & 0 & 4 \\\\ 0 & 1 & 0 & 3 & 0 & 1 & 0 & 3 \\\\ 0 & 0 & 1 &-2 & 0 & 0 & 1 &-2 \\\\ \\hline 1 & 0 & 0 & - \\frac{29}{38} & 0 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & \\frac{49}{38} & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 1 & \\frac{1}{38} & 0 & 0 & 0 & 0 \\end{array} \\right) \\rightsquigarrow \\left( \\begin{array}{c c c c | c c c c} 1 & 0 & 0 & 4 & 1 & 0 & 0 & 4 \\\\ 0 & 1 & 0 & 3 & 0 & 1 & 0 & 3 \\\\ 0 & 0 & 1 &-2 & 0 & 0 & 1 &-2 \\\\ \\hline 0 & 0 & 0 & - \\frac{181}{38} & -1 & 0 & 0 & -4 \\\\ 0 & 0 & 0 & - \\frac{65}{38} & 0 & -1 & 0 & -3 \\\\ 0 & 0 & 0 & 1 & 0 & 0 & - \\frac{38}{75} & \\frac{76}{75} \\end{array} \\right) \\rightsquigarrow $ $\\left( \\begin{array}{c c c c | c c c c} 1 & 0 & 0 & 4 & 1 & 0 & 0 & 4 \\\\ 0 & 1 & 0 & 3 & 0 & 1 & 0 & 3 \\\\ 0 & 0 & 1 &-2 & 0 & 0 & 1 &-2 \\\\ 0 & 0 & 0 & 1 & 0 & 0 & - \\frac{38}{75} & \\frac{76}{75} \\\\ \\hline 0 & 0 & 0 & 0 & -1 & 0 & \\frac{181}{75} & \\frac{62}{75} \\\\ 0 & 0 & 0 & 0 & 0 & -1 & - \\frac{13}{15} & \\frac{26}{15} \\end{array} \\right) \\rightsquigarrow \\left( \\begin{array}{c c c c | c c c c} 1 & 0 & 0 & 4 & 1 & 0 & 0 & 4 \\\\ 0 & 1 & 0 & 3 & 0 & 1 & 0 & 3 \\\\ 0 & 0 & 1 &-2 & 0 & 0 & 1 &-2 \\\\ 0 & 0 & 0 & 1 & 0 & 0 & - \\frac{38}{75} & \\frac{76}{75} \\\\ \\hline 0 & 0 & 0 & 0 & -1 & 0 & 181 & 62 \\\\ 0 & 0 & 0 & 0 & 0 & 1 & 13 & - 26 \\end{array} \\right)\\) Rechts unten steht nun die Basis fÃ¼r \\(U_1 \\cap U_2 = \\left [ \\left \\{ \\begin{pmatrix} -1 \\\\ 0 \\\\ 181 \\\\ 62 \\end{pmatrix} , \\begin{pmatrix} 0 \\\\ 1 \\\\ 13 \\\\ -26 \\end{pmatrix} \\right \\} \\right ]\\) . ZusÃ¤tzlich steht links oben die Basis fÃ¼r \\(U_1 + U_2\\) . Wenn man das noch etwas umformt ist es die Standardbasis des \\(\\mathbb{R}&#94;4\\) . Methode 2 Angabe \\(U_1 = \\left [ \\left \\{ \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 4 \\end{pmatrix} , \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 3 \\end{pmatrix} , \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\\\ -2 \\end{pmatrix} \\right \\} \\right ]\\) , \\(U_2 = \\left [ \\left \\{ \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ -\\frac{29}{38} \\end{pmatrix} , \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ \\frac{49}{38} \\end{pmatrix} , \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\\\ \\frac{1}{38} \\end{pmatrix} \\right \\} \\right ]\\) Rechnung Es gilt: \\(x \\in U_1 \\cap U_2\\) \\(\\Leftrightarrow x \\in U_1 \\land x \\in U_2\\) \\(\\Leftrightarrow x = a \\cdot x_1 + b \\cdot x_2 + c \\cdot x_3 = d \\cdot y_1 + e \\cdot y_2 + f \\cdot y_3\\) mit \\(a, b, c, d, e, f \\in \\mathbb{R}\\) . \\( \\begin{pmatrix} 1 & 0 & 0 & 1 & 0 & 0\\\\ 0 & 1 & 0 & 0 & 1 & 0\\\\ 0 & 0 & 1 & 0 & 0 & 1\\\\ 4 & 3 & 2 & -\\frac{29}{38} & \\frac{49}{38} & \\frac{1}{38} \\end{pmatrix} \\rightsquigarrow \\begin{pmatrix} 1 & 0 & 0 & 1 & 0 & 0\\\\ 0 & 1 & 0 & 0 & 1 & 0\\\\ 0 & 0 & 1 & 0 & 0 & 1\\\\ 0 & 0 & 0 & -\\frac{181}{38} & -\\frac{65}{38} & -\\frac{75}{38} \\end{pmatrix} \\) \\(\\rightsquigarrow \\begin{pmatrix} 1 & 0 & 0 & 1 & 0 & 0\\\\ 0 & 1 & 0 & 0 & 1 & 0\\\\ 0 & 0 & 1 & 0 & 0 & 1\\\\ 0 & 0 & 0 & 1 & \\frac{65}{181} & \\frac{75}{181} \\end{pmatrix} \\rightsquigarrow \\begin{pmatrix} 1 & 0 & 0 & 0 & -\\frac{65}{181} & -\\frac{75}{181}\\\\ 0 & 1 & 0 & 0 & 1 & 0\\\\ 0 & 0 & 1 & 0 & 0 & 1\\\\ 0 & 0 & 0 & 1 & \\frac{65}{181} & \\frac{75}{181} \\end{pmatrix} \\) Nun fÃ¼hrt der -1 - Trick zu dieser LÃ¶sung: \\(\\mathcal{L} = \\left [ \\left \\{ \\begin{pmatrix} -\\frac{65}{181} \\\\ 1 \\\\ 0 \\\\ \\frac{65}{181} \\\\ -1 \\\\ 0\\end{pmatrix} , \\begin{pmatrix} -\\frac{75}{181} \\\\ 0 \\\\ 1 \\\\ \\frac{75}{181} \\\\ 0 \\\\ -1 \\end{pmatrix} \\right } \\right ] = \\left [ \\left { \\begin{pmatrix} -65 \\\\ 181 \\\\ 0 \\\\ 65 \\\\ -181 \\\\ 0\\end{pmatrix} , \\begin{pmatrix} -75 \\\\ 0 \\\\ 181 \\\\ 75 \\\\ 0 \\\\ -181 \\end{pmatrix} \\right \\} \\right ]\\) Das ist also die LÃ¶sung fÃ¼r Belegungen von a, b, c, d, e, f, sodass der resultierende Vektor sowohl in \\(U_1\\) , als auch in \\(U_2\\) ist. Allerdings sieht es so aus, als hÃ¤tte ich mich irgendwo verrechnet ... Sieht jemand den Fehler? Siehe auch Interaktiver Zassenhaus-Algorithmus","tags":"German posts","title":"Wie bildet man den Schnitt zweier VektorrÃ¤ume?"},{"url":"https://martin-thoma.com/frauenquote-am-kit/","text":"Die Frauenquote am KIT wird oft genannt, allerdings hatte ich bisher nur grobe Zahlen. Nun habe ich eine zuverlÃ¤ssige Quelle mit Zahlen zum WS 2011/2012. Das ist die Frauenquote: Insgesamt: 26,6% (unter Deutschen: 25,3%; unter AuslÃ¤ndern: 33,5%) FakultÃ¤t fÃ¼r Architektur: 63,7 % FakultÃ¤t fÃ¼r Geisteswissenschaften: 62,2 % FakultÃ¤t fÃ¼r Chemie + Bio: 53,4 % FakultÃ¤t fÃ¼r Mathematik: 36,1 % FakultÃ¤t fÃ¼r Bauingenieur, Bio- und Umweltwissenschaften: 34,2 % FakultÃ¤t fÃ¼r Chemieingenieurwesen und Verfahrenstechnik: 30,1 % FakultÃ¤t fÃ¼r Wirtschaftswissenschaften: 23,9 % FakultÃ¤t fÃ¼r Informatik + Wirtschaftswissenschaften: 23,7 % FakultÃ¤t fÃ¼r Physik: 18,0 % FakultÃ¤t fÃ¼r Elektrotechnik und Informationstechnik: 10,9 % FakultÃ¤t fÃ¼r Maschinenbau: 10,6 % FakultÃ¤t fÃ¼r Informatik: 9,4 % FakultÃ¤t fÃ¼r Maschinenbau + Elektrotechnik und Informationstechnik: 8,7 % (diese FakultÃ¤t hat allerdings nur 23 Personen ...) 70,4 % der Studenten kommen Ã¼brigens aus Baden-WÃ¼rttemberg. Siehe auch Mythos MÃ¤nnerstadt: Wie mÃ¤nnlich ist Karlsruhe?","tags":"German posts","title":"Frauenquote am KIT"},{"url":"https://martin-thoma.com/sell/acer-notebook/","text":"Acer Travelmate 5744Z â‚¬ 200.00 , VerfÃ¼gbar Beschreibung: Siehe Review des Acer Travelmate 5744Z Als Betriebssystem wurde ein Ubuntu 16.04 (MATE) frisch aufgesetzt. MÃ¤ngel: LÃ¼fter muss mal gereinigt werden, da er manchmal rattert.","tags":"Sell","title":"Acer Travelmate 5744Z"},{"url":"https://martin-thoma.com/sell/external-hdd/","text":"Externe Festplatte â‚¬ 30.00 , VerfÃ¼gbar Beschreibung: Festplatte ist in Ordnung; ich habe nur inzwischen eine grÃ¶ÃŸere mit USB 3. Intenso 1TB Memory Station Black 163 g Artikelnummer: 6002560 Geek-Stuff ATA device, with non-removable media Model Number: ST1000LM024 HN-M101MBB Serial Number: S************0 Firmware Revision: 2AR10001 Transport: Serial, ATA8-AST, SATA 1 .0a, SATA II Extensions, SATA Rev 2 .5, SATA Rev 2 .6, SATA Rev 3 .0 Standards: Used: unknown ( minor revision code 0x0028 ) Supported: 8 7 6 5 Likely used: 8 Configuration: Logical max current cylinders 16383 16383 heads 16 16 sectors/track 63 63 -- CHS current addressable sectors: 16514064 LBA user addressable sectors: 268435455 LBA48 user addressable sectors: 1953525168 Logical Sector size: 512 bytes Physical Sector size: 4096 bytes Logical Sector-0 offset: 0 bytes device size with M = 1024 *1024: 953869 MBytes device size with M = 1000 *1000: 1000204 MBytes ( 1000 GB ) cache/buffer size = 8192 KBytes Form Factor: 2 .5 inch Nominal Media Rotation Rate: 5400 Capabilities: LBA, IORDY ( can be disabled ) Queue depth: 32 Standby timer values: spec ' d by Standard, no device specific minimum R/W multiple sector transfer: Max = 16 Current = ? Advanced power management level: disabled Recommended acoustic management value: 254 , current value: 254 DMA: mdma0 mdma1 mdma2 udma0 udma1 udma2 udma3 udma4 udma5 *udma6 Cycle time: min = 120ns recommended = 120ns PIO: pio0 pio1 pio2 pio3 pio4 Cycle time: no flow control = 120ns IORDY flow control = 120ns Commands/features: Enabled Supported: * SMART feature set Security Mode feature set * Power Management feature set * Write cache * Look-ahead * Host Protected Area feature set * WRITE_BUFFER command * READ_BUFFER command * NOP cmd * DOWNLOAD_MICROCODE Advanced Power Management feature set Power-Up In Standby feature set * SET_FEATURES required to spinup after power up SET_MAX security extension * Automatic Acoustic Management feature set * 48 -bit Address feature set * Device Configuration Overlay feature set * Mandatory FLUSH_CACHE * FLUSH_CACHE_EXT * SMART error logging * SMART self-test * General Purpose Logging feature set * 64 -bit World wide name * IDLE_IMMEDIATE with UNLOAD * WRITE_UNCORRECTABLE_EXT command * { READ,WRITE } _DMA_EXT_GPL commands * Segmented DOWNLOAD_MICROCODE * Gen1 signaling speed ( 1 .5Gb/s ) * Gen2 signaling speed ( 3 .0Gb/s ) * Native Command Queueing ( NCQ ) * Phy event counters * Idle-Unload when NCQ is active * NCQ priority information DMA Setup Auto-Activate optimization Device-initiated interface power management * Software settings preservation * SMART Command Transport ( SCT ) feature set * SCT Read/Write Long ( AC1 ) , obsolete * SCT Write Same ( AC2 ) * SCT Error Recovery Control ( AC3 ) * SCT Features Control ( AC4 ) * SCT Data Tables ( AC5 ) Security: Master password revision code = ***** supported not enabled not locked not frozen not expired: security count supported: enhanced erase 202min for SECURITY ERASE UNIT. 202min for ENHANCED SECURITY ERASE UNIT. Checksum: correct","tags":"Sell","title":"Externe Festplatte"},{"url":"https://martin-thoma.com/wandering-through-the-depths-of-find/","text":"find is a very mighty tool. It allows you to apply a very detailed search syntax. Every Linux user should know how to use it. Very basic usage \\( find /home -iname &#039;Tux*&#039;\" title=\"\\) find /home -iname 'Tux*'\" width=\"500\" height=\"100\" class=\"alignnone size-full wp-image-2671\" /> I told you I would start with the very basics, didn't I? So, you can need the option -iname if you want to do basic matching against the filename. The * can be used as a placeholder. Redirecting errors You might get some \"Permission denied\" errors. They are very bothersome if you combine commands in the bash. So you redirect them to /dev/null, a special file which discards everything it gets: Real life example I am also a developer who likes to have good names for constants, database tables and variables. Sometimes, like today, I think it's time to change a database table a bit. It got a lot more rows and the old name doesn't really fit any longer. I used a constant for the table name in all scripts. This constant was SOFTWARE_USER_TABLE and should now be USER_INFO_TABLE. So I have to search recursively and case-sensitive in my project and replace all occurrences in all strings by the new string. Except for .svn-directories, of course. The easiest way to achieve this is via find, xargs and sed: find . -path '*/.svn' -prune -o -type f -print0 | xargs -0 sed -i 's/SOFTWARE_USER_TABLE/USER_INFO_TABLE/g' Now the explanation of the different commands: find: .: search in the current working directory -path '*/.svn' -prune': If a directory starting with .svn is in the path to the file, skip it -o: atlernative (OR) -type f: only search for files -print0: print the full file name on the standard output, followed by a null character (instead of the newline character that -print uses). This allows file names that contain newlines or other types of white space to be correctly interpreted by programs that process the find output. This option corresponds to the -0 option of xargs. xargs -0: exchanges the arguments. -0 means that input items are terminated by a null character instead of by whitespace, and the quotes and backslash are not special (every character is taken lit erally). Disables the end of file string, which is treated like any other argument. Useful when input items might contain white space, quote marks, or backslashes. The GNU find -print0 option produces input suitable for this mode. sed: -i: edit the given file in-place. If you would not use -i, it would just print everything in standard output /g: edit the file globally. If you would not use g, sed would only replace the first occurrence of SOFTWARE_USER_TABLE Snippets move all files in subdirectories to a single directory: find -type f -exec mv {} collection/ \\; find all files which are bigger than 20MB and print their location and size. Maybe you could use du for this one, but I don't know how: find / -type f -size +20000k -exec ls -lh {} \\; 2 >/dev/null | awk '{ print $5 \":\\t\" $8 }' find files in the home folder owned by alice: find /home -user alice Further reading Note that you should use grep if you want to search for patterns in single files. man page Wikipedia","tags":"Code","title":"Wandering through the depths of find"},{"url":"https://martin-thoma.com/surprising-c-errors/","text":"Those errors might be surprising and a good exercise for C beginners: Empty printf #include <stdio.h> int main () { printf ( \"\" ); return 0 ; } error: zero-length gnu_printf format string Macros #include <stdio.h> #define MY_MACRO printf(\"Hello World\\n\"); int main () { if ( 1 ) MY_MACRO ; else printf ( \"Crazy, huh? \\n \" ); return 0 ; } macro.c: In function & lsquo ; main & rsquo ; : macro.c:8: error: & lsquo ; else & rsquo ; without a previous & lsquo ; if & rsquo ; Single and Double quotes #include <stdio.h> int main () { printf ( ' hello , world \\ n ' ); return 0 ; } macro.c:5:9: warning: character constant too long for its type macro.c: In function & lsquo ; main & rsquo ; : macro.c:5: warning: passing argument 1 of & lsquo ; printf & rsquo ; makes pointer from integer without a cast /usr/include/stdio.h:339: note: expected & lsquo ; const char * __restrict__ & rsquo ; but argument is of type & lsquo ; int & rsquo ; macro.c:5: warning: format not a string literal and no format arguments Thanks to drpaulcarter.com for this example: int main () { const char * myPointer = 'A' ; ( void ) myPointer ; return 0 ; } macro.c: In function & lsquo ; main & rsquo ; : macro.c:3: warning: initialization makes pointer from integer without a cast Pointers #include <string.h> int main () { char * myPointer ; strcpy ( myPointer , \"Hello World!\" ); return 0 ; } macro.c: In function & lsquo ; main & rsquo ; : macro.c:7: warning: & lsquo ; myPointer & rsquo ; is used uninitialized in this function Loops int main () { int x = 42 ; while ( x > 0 ); x -- ; return 0 ; } No compiler error, but an infinite loop. Null terminator of Strings #include <stdio.h> #include <stdlib.h> #include <string.h> int main () { char myArray [ 20 ]; printf ( \"Characters: %i \\n \" , strlen ( myArray )); strcpy ( myArray , \"abc\" ); printf ( \"Characters: %i \\n \" , strlen ( myArray )); strcpy ( myArray , \"Hello World!\" ); printf ( \"Characters: %i \\n \" , strlen ( myArray )); printf ( \"String: -%s- \\n \" , myArray ); printf ( \"Size: %i Byte \\n\\n \" , sizeof ( myArray )); char * myString = malloc ( strlen ( myArray )); strcpy ( myString , myArray ); printf ( \"String: -%s- \\n \" , myString ); printf ( \"Size: %i Byte \\n \" , sizeof ( myString )); printf ( \"Characters: %i \\n\\n \" , strlen ( myString )); char * breakIt = malloc ( strlen ( myString )); strcpy ( breakIt , myString ); printf ( \"String: -%s- \\n \" , breakIt ); printf ( \"Size: %i Byte \\n \" , sizeof ( breakIt )); printf ( \"Characters: %i \\n \" , strlen ( breakIt )); return 0 ; } Again, you don't get a compiler error, but some strange results: Characters: 0 Characters: 3 Characters: 12 String: -Hello World!- Size: 20 Byte String: -Hello World!- Size: 4 Byte Characters: 12 String: -Hello World!\u0011- Size: 4 Byte Characters: 13 Further reading C Preprocessor and macros Pointer initialisation strcpy , strlen","tags":"Code","title":"Surprising C errors"},{"url":"https://martin-thoma.com/what-seems-to-be-wrong-in-the-us-some-caricatures/","text":"I am not the first person you should ask if you want to know something about the United States. I've never been there and I know only one American. But I am reading quite a lot of websites which publish regularly political caricatures. This post is simply a collection of different caricatures I've stumbled over. For most of them I had to search the source, so I hope you will enjoy them. If you are the owner of one of these websites and don't want me to publish your caricatures, I'll remove them. But I will also remove the link to your website. We are the 99% We are the 99% is a political slogan of \"Occupy\" protesters. It refers to the vast concentration of wealth among the top 1% of income earners compared to the other 99%, and indicates that most people are paying the price for the mistakes of a tiny minority. We are the 99% - Caricature from mattbors.com (mattbors.com has some more caricatures from the occupy protesters) Wall Street - Demonstrators vs. Bankers (from Startribune.com ) Dessert - the american style (from David Horsey ) Some of the best caricatures are made by David Horsey . Republicans The Republican Party is one of the two major contemporary political parties in the United States, along with the Democratic Party. Founded by anti-slavery expansion activists in 1854, it is often called the GOP (Grand Old Party). The party's platform generally reflects American conservatism in the U.S. political spectrum and is considered center-right, in contrast to the center-left Democratic Party. The Principled Pachyderm (from M. Wuerker ) Tea Party The Tea Party movement is an American populist political movement that is generally recognized as conservative and libertarian, and has sponsored protests and supported political candidates since 2009. It endorses reduced government spending, opposition to taxation in varying degrees, reduction of the national debt and federal budget deficit, and adherence to an originalist interpretation of the United States Constitution. Tea Party and big gouvernment Phil Hands has also made a nice one, but I've only found a page which clearly states \"pay per use\". What a pity! I've just found the category tea party of theweek.com . Education Education in China, Africa and the U.S. (from inconsequentiallogic.com ) University student dept (By Jeff Parker Â© 2006 Florida Today) National debt National dept (from flatoday.net ) I was very astonished that I did not find much about torture (e.g. waterboarding ), human and civil rights (e.g. Guantanamo Bay , death penalty ) and the widespread ownership of arms (see 2nd Amendment , List of countries by intentional homicide rate ). Do you know some good sites with caricatures? What do you think are the problems of Europe / Germany?","tags":"My bits and bytes","title":"What seems to be wrong in the U.S. - some caricatures"},{"url":"https://martin-thoma.com/adding-a-ppa-in-ubuntu/","text":"PPAs ( Personal Package Archive ) provide additional resources. They are small repositories you can add to get some special content. You can add them with Bash: sudo add-apt-repository ppa:<repository-name> Lets make an example: If you want to install Clipgrab , you add the repository first: sudo add-apt-repository ppa:clipgrab Then you have to update your sources: sudo apt-get update Now you can install clipgrab the usual way: sudo apt-get install clipgrab Further Reading Repositories and the CommandLine Clipgrab (German)","tags":"Cyberculture","title":"Adding a ppa in Ubuntu"},{"url":"https://martin-thoma.com/vrms-virtual-richard-m-stallman/","text":"Richard Stallman I've just installed vrms - the virtual richard Stallman :D Richard Stallman is an American software freedom activist and computer programmer. He launched the GNU Project to create a free Unix-like operating system, and he has been the project's lead architect and organizer. With the launch of the GNU Project, he initiated the free software movement; he founded the Free Software Foundation. $ vrms Non-free packages installed on pc07 rar Archiver for .rar files selfhtml German HTML reference and tutorial unrar Unarchiver for .rar files ( non-free version ) Contrib packages installed on pc07 nvidia-common Find obsolete NVIDIA drivers ttf-mscorefonts-installer Installer for Microsoft TrueType core fonts 3 non-free packages, 0 .2% of 1869 installed packages. 2 contrib packages, 0 .1% of 1869 installed packages. Thanks to trompetenkaefers blog for the post!","tags":"Code","title":"vrms - virtual Richard M. Stallman"},{"url":"https://martin-thoma.com/how-to-use-magic-rescue/","text":"I've just searched an image I have created some time ago. I knew that I've put it on one of my USB-Sticks, but it seems as if I had deleted it. So how could I get the image back? Magic rescue is a program for recovering deleted files. It doesn't simply open your trash can, but it searches files which were deleted, but not overwritten. Installation sudo apt-get install magicrescue Basic usage $ magicrescue Usage: magicrescue [ -I FILE ] [ -M MODE ] [ -O [ +- =][ 0x ] OFFSET ] [ -b BLOCKSIZE ] -d OUTPUT_DIR -r RECIPE1 [ -r RECIPE2 [ ... ]] DEVICE1 [ DEVICE2 [ ... ]] -b Only consider files starting at a multiple of BLOCKSIZE. -d Mandatory. Output directory for found files. -r Mandatory. Recipe name, file or directory. -I Read input file names from this file ( \"-\" for stdin ) -M Produce machine-readable output to stdout. -O Resume from specified offset ( hex or decimal ) in the first device. You need recipes to use Magic Rescue. These are the basic ones: moose@pc07:/usr/share/magicrescue/recipes$ ls avi flac gzip mp3-id3v1 nikon-raw ppm canon-cr2 gimp-xcf jpeg-exif mp3-id3v2 perl zip elf gpl jpeg-jfif msoffice png Where is my USB-Stick? $ sudo fdisk -l [ sudo ] password for moose: Disk /dev/sda: 320 .1 GB, 320072933376 bytes 255 heads, 63 sectors/track, 38913 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes Sector size ( logical/physical ) : 512 bytes / 512 bytes I/O size ( minimum/optimal ) : 512 bytes / 512 bytes Disk identifier: 0x00065e10 Device Boot Start End Blocks Id System /dev/sda1 * 1 37810 303704064 83 Linux /dev/sda2 37810 38914 8864769 5 Extended /dev/sda5 37810 38914 8864768 82 Linux swap / Solaris Disk /dev/sdc: 2067 MB, 2067267584 bytes 2 heads, 63 sectors/track, 32044 cylinders Units = cylinders of 126 * 512 = 64512 bytes Sector size ( logical/physical ) : 512 bytes / 512 bytes I/O size ( minimum/optimal ) : 512 bytes / 512 bytes Disk identifier: 0x005f4d47 Device Boot Start End Blocks Id System /dev/sdc1 * 1 32045 2018800 b W95 FAT32 Usage sudo magicrescue -r png -r jpeg-jfif -r gimp-xcf \\ -r jpeg-exif -d /home/moose/output/ /dev/sdc1 Just got the image back â˜º","tags":"Code","title":"How to use magic rescue"},{"url":"https://martin-thoma.com/comparing-programming-languages/","text":"Compare programming languages If you want to compare programming languages, I can recommend the following links: literateprograms.org , Rosetta Code , 99-bottles-of-beer.net , Comparison of programming languages (basic instructions) , Comparison of programming languages In particular, I like the following pages: Fibonacci numbers ( literateprograms , rosettacode ) Hello World ( literateprograms , rosettacode ) If you want to learn a new language you can look at the implementation of one problem and learn how the new language can be used.","tags":"Code","title":"Comparing programming languages"},{"url":"https://martin-thoma.com/openid-autodiscovery/","text":"OpenID is a web technology that gives the users the possibility to use one website for authentication on another web service. The OpenID Attribute Exchange makes registration processes simpler, as the user can automatically allow the website to get some information like the e-mail address, the gender and the full name. The next step to an even simpler login process would be autodiscovery. This means there would be no need to do anything for logging in. You simply have to go to the website and be logged at your OpenID provider (e.g. Google). This is quite easily possible if the user was logged in before. You leave a cookie that gives you the information which OpenID he uses. So you simply don't let him logout. I don't know if it is a good idea to do so. The registration process is much trickier. Due to the same origin policy , you can't read other cookies than those you have set. So you can't check if there is a cookie from Google, Facebook or Yahoo. You could try if the user has a Google account, as Google uses a discovery URL (https://www.google.com/accounts/o8/id) instead of the usual OpenID (something like https://me.yahoo.com/martinthoma). So, by chance you will be able to let a user register without forcing him to interact in any way with your website. He has to allow your website to get his data at his OpenID provider, though. Further reading Wikipedia: OpenID : an open standard that describes how users can be authenticated in a decentralized manner, eliminating the need for services to provide their own ad hoc systems and allowing users to consolidate their digital identities Yadis : a communications protocol for discovery of services such as OpenID, OAuth, and XDI connected to a Yadis ID OpenID Attribute Exchange 1.0 : Specification Guide to Running a User Account System : by Eric Sachs of Google's Identity team","tags":"The Web","title":"OpenID autodiscovery"},{"url":"https://martin-thoma.com/configurig-gedit-for-developers/","text":"gedit is a very lightweight text editor. It supports syntax highlighting for every programming language I can think of and is highly customizable. It belongs to GNOME, but it is also available for Windows. This is how it looks like: gedit screenshot You might want to install gedit-plugins: sudo apt-get install gedit-plugins External Tools gedit allows you to run external command line tools by pressing shortcuts. You can find the external tools plugins in your preferences: gedit external tools You can assign shortcuts by clicking into an input field and simply using the shortcut once: external tools java Java #!/bin/sh cd $GEDIT_CURRENT_DOCUMENT_DIR if javac $GEDIT_CURRENT_DOCUMENT_NAME ; then java ${ GEDIT_CURRENT_DOCUMENT_NAME % \\. java } else echo \"Failed to compile\" fi Code Comment This neat little plugin detects which programming language you are using. If you select a code block and press ctrl+m it gets marked as a comment. If you press ctrl+shift+m a block of comments gets \"decommented\" to a block of code. It uses # for Python and // for Java. Bracket Completion Well, I guess the name is meaningful, isn't it? As soon as you type a bracket - (, [ or { it gets completed with }, ] or ). Better Python Console The Better Python Console Plugin allows you to press F5 and execute the current code in an interactive Python console. This means, you can access the current variables! You install it by extracting and copying the whole folder (with plugins!) to ~/gnome2/gedit. What could be better The design could be similar to Chrome â˜º So they could have some nicer tabs. Nothing really important. I really miss comment folding since I have to write Java code with a lot of Doc comments Further reading and resources Official Website : You can find the Windows Binary here. External Tools 13 Gedit Plugins to Make It a More Useful Text Editor : Seems as if you could also have a class browser in gedit","tags":"Cyberculture","title":"Configurig gEdit for developers"},{"url":"https://martin-thoma.com/for-loops-in-different-programming-languages/","text":"If you have to learn a new programming language it is most of the time quite easy. You know the structures and the way you have to think if you want to solve a problem. The first time it might be hard, but the more languages you learn the more similarities you'll recognize. I also have to learn a special variant of pseudocode at the moment. It is quite hard to know what pseudocode does if it isn't unambiguously defined. I had problems with for loops for example. For loops have some properties you simply have to define: Scoping : Does the loop counter still exist after the loop was executed? Copy or reference : Does the loop statement work with a copy or with a reference of the variables in the loop body? Last value of i : What is the last value of i? General structure A for loop usually consists of an initialization part, a condition and an iteration step: The structure of a for loop. Pythons special structure Python uses a generator or lists to loop: #!/usr/bin/python # -*- coding: utf-8 -*- for i in xrange ( 0 , 10 ): print ( \"In loop: %i \" % i ) print ( \"Out of loop: %i \" % i ) Scoping Does the loop counter still exist after the loop was executed? Yes : JavaScript, PHP, Python No : C, C++, Java Copy or reference Does the loop statement work with a copy or with a reference of the variables in the loop body? Does the programming language use the same variable as in the for condition (reference) or does it use another one (copy)? You can test this if you add something to i in the body. Copy : Python Reference : C, C++, Java, JavaScript, PHP Python iterates over a generator. This means that you can't really compare Pythons for-loop to other programming languages' for loops. Last value of i What is the last value of i? 9 : C, C++, Java (Inside the loop), Python (Outside of the loop) 10 : JavaScript, PHP (Outside of the loop) foreach Many languages provide a special for loop. This special for loop is sometimes called \"foreach\" as you iterate over each element in a collection (e.g. an array). Java int [] array = new int [ 5 ]; array [ 0 ] = 0 ; array [ 1 ] = 1 ; array [ 2 ] = 2 ; array [ 3 ] = 3 ; array [ 4 ] = 4 ; for ( int item : array ) { System . out . println ( \"Foreach: \" + item ); } JavaScript var array = new Array ( 0 , 1 , 2 , 3 , 4 ); for ( var value in array ) { document . write ( 'Foreach: ' + value + '<br/>' ); } PHP $array = array(0, 1, 2, 3, 4); foreach ($array as $key=>$value) { echo \"Foreach: $value<br/>\"; } Python array = [ 0 , 1 , 2 , 3 , 4 ] for value in array : print \"Foreach: %i \" % value More information If you want to see the code, you can download this zip archive . It is quite astonishing, but Wikipedia has a very long article about for loops .","tags":"Code","title":"for loops in different programming languages"},{"url":"https://martin-thoma.com/checkstyle/","text":"<li></li> I have to go to a programming course at KIT at the moment where we are taught how to program with Java. They create exercises which get evaluated automatically. One part of the evaluation is checkstyle. So it is a good idea to test the files on my machine before uploading them. Installation You can install it on an Ubuntu system with this command: sudo apt-get install checkstyle Usage You can call checkstyle with this command: checkstyle -c /usr/share/checkstyle/sun_checks.xml YourCode.java Another example would be: checkstyle -c /path/to/config/Progr_WS11_Checkstyle1.xml KITBook.java It will generate some output similar to this: Starting audit... KITBook.java:173:64: '{' is not preceded with whitespace. KITBook.java:174:69: '-' is not preceded with whitespace. KITBook.java:174:70: '-' is not followed by whitespace. Audit done . Resolve warnings [ warning ] /usr/bin/checkstyle: No java runtime was found [ warning ] /usr/bin/checkstyle: No JAVA_CMD set for run_java, falling back to JAVA_CMD = java You have to set the path: JAVA_CMD = /usr/lib/jvm/java-6-sun/bin/java export JAVA_CMD Check all files in a folder checkstyle -c /home/moose/Downloads/Progr_WS11_Checkstyle1.xml -r . Checkstyle and eclipse Go to H elp â†’ Install New S oftware ... Install new software or plugins in eclipse Install http://eclipse-cs.sf.net/update/ as a new \"repository\". After you have installed the plugin, you have to activate it for your project. To do so, you have to go to P roject â†’ P roperties and check Checkstyle active for this project . Then you have to change to the Local Check Configurations tab and load your personal checkstyle xml files. Checkstyle properties in eclipse Click on New , give it a name and click on import . Go back to the main tab and use your personal checkstyle. You will have to rebuild the project. You might want to use more than one checkstyle file. You can do that if you uncheck Use simple configuration : Multiple Checkstyle files in Eclipse Now you can set File Set Configuration to All , select your Check Configuration , click on OK and enable it in the Main tab. Further reading and resources Wikipedia Official Website KIT If you are a student at KIT and you can download the KIT checkstyle-files from zvi.ipd.kit.edu . If you can't do it from home via VPN, you could use SSH. These commands work fine on Ubuntu and I guess on every Linux machine. If you use Windows, you will have to install Putty or something similar. Login with your personal account that begins with u. I'll use uabcd in this example. ssh uabcd@rzstud.stud.uni-karlsruhe.de Then download the files with wget: wget ftp://ftp.ira.uka.de/pub/ZVI/KIT/programmieren_ws11/material/Progr_WS11_Checkstyle1.xml wget ftp://ftp.ira.uka.de/pub/ZVI/KIT/programmieren_ws11/material/Progr_WS11_Checkstyle2.xml Now you can exit the bash with exit and download the files from your account with scp : scp uabcd@rzstud.stud.uni-karlsruhe.de:~/Progr_WS11_Checkstyle1.xml ~/Progr_WS11_Checkstyle1.xml scp uabcd@rzstud.stud.uni-karlsruhe.de:~/Progr_WS11_Checkstyle1.xml ~/Progr_WS11_Checkstyle1.xml","tags":"Code","title":"Checkstyle"},{"url":"https://martin-thoma.com/how-to-create-a-color-scheme/","text":"Here are some nice online tools to create color schemes Color Rotate Color Rotate Color Scheme Designer Color Scheme Designer Color Jack Color Jack Pictaculous Pictaculous - A color Palette Generator 4096 Color Wheel 4096 Color Wheel Kuler kuler Colour Lovers COLOURlovers Color Blender Color Blender","tags":"The Web","title":"How to create a color scheme"},{"url":"https://martin-thoma.com/pumping-lemma/","text":"RegulÃ¤re Sprachen kÃ¶nnen von endlichen Automaten erkannt werden. Das bedeutet, dass eine endliche Anzahl an ZustÃ¤nden ausreicht, um ein Wort der Sprache zu akzeptieren. Wenn also eine Sprache \\(L = \\{a&#94;i b&#94;{2i} | i \\in \\mathbb{N}\\}\\) beschrieben wird, mÃ¼sste gezÃ¤hlt werden, wie oft a vorkommt. a kann aber beliebig oft vorkommen. Das ist ein Indiz dafÃ¼r, dass es sich nicht um eine regulÃ¤re Sprache handelt. Das Pumping-Lemma ist ein notwendiges, aber kein hinreichendes Kriterium fÃ¼r regulÃ¤re Sprachen. Daraus folgt, dass eine nicht-regulÃ¤re Sprache eventuell durch das Lemma entlarvt werden kann. Allerdings muss nicht jede Sprache, die das Pumping-Lemma erfÃ¼llt, regulÃ¤r sein. Dies kann man durch einen Widerspruchsbeweis zeigen. Dabei nimmt man an, dass die Behauptung falsch ist. Dann zeigt man, dass man durch die Annahme zu einem Widerspruch kommt. Beispiel Voraussetzung : \\(L_2 = \\{a&#94;i b&#94;j c&#94;k | i \\lt j \\lt k\\}\\) . Behauptung : \\(L_2\\) ist nicht regulÃ¤r. Beweis : (durch Widerspruch) Annahme : \\(L_2\\) sei regulÃ¤r. Aus dem Pumping-Lemma folgt: \\(\\exists n \\in \\mathbb{N}: \\forall w \\in \\{w \\in L_2 | |w| \\geq n\\}: $ $\\exists \\text{ Darstellung } uvx = w \\text{ mit } v \\neq \\varepsilon \\land |uv| \\leq n\\) fÃ¼r die gilt: \\(uv&#94;i x \\in L_2 \\forall i \\in \\mathbb{N}_0\\) In Worten: Wenn man ein Wort in L hat, dass mindestens so lang ist wie ein bestimmtes n, dann kann man dieses Wort in Teilworte u, v und x zerlegen. Bei dieser Zerlegung ist v niemals leer. Wenn man nun den Teil des Wortes, der in v steckt wiederholt, muss das Wort immer noch in \\(L_2\\) sein. Sei \\(n \\in \\mathbb{N}\\) die Konstante aus dem Pumping-Lemma. Betrachte nun \\(w = a&#94;n b&#94;{n+1} c&#94;{n+2}\\) . Offensichtlich gilt \\(w \\in L_2\\) . Da \\(|uv| \\leq n\\) muss in v mindestens ein a sein. \\(\\Rightarrow uv&#94;2 x = a&#94;{n+2 \\cdot i} b&#94;{n+1} c&#94;{n+2}, i \\geq 1 $ $\\Rightarrow uv&#94;2x \\notin L_2 $ $\\Rightarrow \\text{Widerspruch} $ $\\Rightarrow \\text{Die Annahme war falsch.} $ $\\Rightarrow L_2\\) ist nicht regulÃ¤r. Bemerkung : Eigentlich ist es ein Beweis durch Kontraposition. Man weiÃŸ, es gilt: \\(L \\in {\\cal L_3} \\Rightarrow $ L erf&uuml;llt das Pumping-Lemma. Daraus folgt: L erf&uuml;llt nicht das Pumping-Lemma $\\Rightarrow L \\notin {\\cal L_3}\\) . Um zu beweisen, dass L das Pumping-Lemma nicht erfÃ¼llt, benutzt man meist einen Widerspruchsbeweis wie oben. Material Ich habe mal ein paar Beispiele fÃ¼r Ogdens Lemma und das Pumping-Lemma gesammelt.","tags":"German posts","title":"Eine Sprache ist nicht regulÃ¤r - Beweis mit dem Pumping-Lemma"},{"url":"https://martin-thoma.com/python-generators/","text":"Python has a quite mighty tool: Generators. Generators help you to program iterators. They look almost like normal functions, but they have yield as a special keyword. yield is used instead of return. Imagine you wanted to display n Fibonacci numbers. This could be your normal approach: #!/usr/bin/python # -*- coding: utf-8 -*- def fibonacci ( n ): \"\"\" Build and return a list of the first n >= 2 Fibonacci numbers \"\"\" fibList = [ 1 , 1 ] while len ( fibList ) < n : newFib = fibList [ - 1 ] + fibList [ - 2 ] fibList . append ( newFib ) return fibList for nr , fib in enumerate ( fibonacci ( 100 )): print ( \"The %i -th Fibonacci-Nr is %i \" % ( nr , fib )) The disadvantage of this approach is that you have to keep every element of the sequence in memory. Of course, you could write something like this: #!/usr/bin/python # -*- coding: utf-8 -*- def fib ( n ): \"\"\" Calculate the n-th fibonacci number. \"\"\" if n == 0 : return 0 elif n == 1 : return 1 else : return fib ( n - 1 ) + fib ( n - 2 ) for nr in xrange ( 1 , 100 ): print ( \"The %i -th Fibonacci-Nr is %i \" % ( nr , fib ( nr ))) This needs much less memory, but much more time. You have to recalculate the first few fibonacci numbers every time. A generator could look like this: #!/usr/bin/python # -*- coding: utf-8 -*- def fibGenerator (): \"\"\" A python fibonacci generator \"\"\" a , b = 1 , 1 while 1 : yield a a , b = b , a + b myGenerator = fibGenerator () for nr in xrange ( 1 , 100 ): print ( \"The %i -th Fibonacci-Nr is %i \" % ( nr , myGenerator . next ())) Further Reading Python documentation Python Wiki","tags":"Code","title":"Python Generators"},{"url":"https://martin-thoma.com/wie-fuhre-ich-einen-induktionsbeweis/","text":"Der Induktionsbeweis eignet sich hÃ¤ufig, wenn es um Aussagen Ã¼ber die NatÃ¼rlichen Zahlen \\(\\mathbb{N}\\) geht, allerdings kann er auch fÃ¼r die ganzen Zahlen \\(\\mathbb{Z}\\) verwendet werden. Prinzip Der Gedanke hinter dem Induktionsbeweis ist, dass man sehr leicht fÃ¼r ein einzelnes Element zeigen kann, dass eine Aussage gilt. Diese Aussage ist die Behauptung. Dann zeigt man allgemein, wenn die Aussage fÃ¼r eine Zahl gilt muss sie auch fÃ¼r die nÃ¤chste Zahl gelten. Wenn man also fÃ¼r n = 1 zeigt dass die Aussage A(n) korrekt ist, dann gilt sie fÃ¼r alle positiven Zahlen. Aufbau Induktionsanfang (I.A.): Zeige, dass die Aussage fÃ¼r ein bestimmtes $n_0$ (also z.B. $n_0 = 0$) gilt. DafÃ¼r muss man einfach nur einsetzen. Induktionsvorraussetzung (I.V.)): \"Sei $n \\in \\mathbb{N}$ beliebig, aber fest und es gelte: \" Induktionsschluss (I.S.): Ausgehend von I.V. ist zu zeigen, dass die Aussage fÃ¼r $n_0 + 1$ gilt. Beispiele IdentitÃ¤ten Es gibt viele IdentitÃ¤ten, die sich gut mit einem Induktionsbeweis zeigen lassen: Bei den folgenden IdentitÃ¤ten sei \\(n \\in \\mathbb{N}\\) . GauÃŸsche Summenformel Behauptung : \\(\\sum_{k=1}&#94;n k = \\frac{1}{2} \\cdot n \\cdot (n+1)\\) Beweis : durch vollstÃ¤ndige Induktion I.A. : Sei n = 1. Dann: \\(\\sum_{k=1}&#94;1 k = 1 = \\frac{1}{2} \\cdot 1 \\cdot (1+1)\\) I.V. : Sei \\(n \\in \\mathbb{N}\\) beliebig, aber fest und es gelte: \\(\\sum_{k=1}&#94;n k = \\frac{1}{2} \\cdot n \\cdot (n+1)\\) I.S. : \\(\\sum_{k=1}&#94;{n+1} k = \\sum_{k=1}&#94;{n} k + (n+1) \\stackrel{I.V.}{=} \\frac{1}{2} \\cdot n \\cdot (n+1) + (n+1) = $ $= \\frac{1}{2} \\cdot (n&#94;2 + n) + (n+1) = \\frac{1}{2} \\cdot (n&#94;2 + 3n + 2) = \\frac{1}{2} \\cdot (n+1)(n+2) \\blacksquare\\) Weitere $\\sum_{k=1}&#94;n k&#94;3 = \\frac{1}{4}n&#94;2 (n+1)&#94;2$ Fibonacci: $f(m+n) = f(n+1) \\cdot f(m) + f(n) \\cdot f(m-1)$ Binomischer Satz Das folgende habe ich als Mitschrift der Vorlesung \"Analysis I\" am KIT gemacht: Seien $a, b \\in \\mathbb{R}.$ Dann gilt fÃ¼r alle $n \\in \\mathbb{N}$: $(a+b)&#94;{n+1} = (a+b)(a+b)&#94;n = (a+b) \\underbrace{\\sum_{k=0}&#94;{n} \\binom{n}{k} a&#94;{n-k} b&#94;k}_\\text{Binomischer Lehrsatz}$ I.A. : \\(n=1: \\sum_{k=0}&#94;{1}\\binom{1}{k} a&#94;{1-k} b&#94;k = (a+b)&#94;n\\) I.V. : Sei \\(n \\in \\mathbb{N}\\) und es gelte \\((a+b)&#94;{n+1} = (a+b)(a+b)&#94;n = (a+b) \\sum_{k=0}&#94;{n} \\binom{n}{k} a&#94;{n-k} b&#94;k\\) I.S. : \\begin{align} (a+b)&#94;{k+1} &= (a+b)(a+b)&#94;n \\\\ &= (a+b) \\sum_{k=0}&#94;{n} \\binom{n}{k} a&#94;{n-k} b&#94;k \\\\ &= \\sum_{k=0}&#94;{n} \\binom{n}{k} a&#94;{n+1-k} b&#94;k + \\sum_{k=0}&#94;n \\binom{n}{k} a&#94;{n-k} b&#94;{k+1} \\\\ &= \\underbrace{\\binom{n}{0}}_{\\binom{n+1}{0}} a&#94;{n+1} + \\sum_{k=1}&#94;n \\binom{n}{k} a&#94;{n+1-k} b&#94;k + \\underbrace{\\sum_{k=0}&#94;{n-1} \\binom{n}{k} a&#94;{n-k} b&#94;{k+1}}_\\text{Vorbemerkung} + \\binom{n}{n} b&#94;{n+1} \\\\ &= \\binom{n+1}{0} a&#94;{n+1} + \\sum_{k=1}&#94;{n} [\\binom{n}{k} + \\binom{n}{k-1}] a&#94;{n+1} b&#94;k + \\binom{n+1}{n+1} b&#94;{n+1} \\\\ &= \\sum_{k=0}&#94;{n+1} \\binom{n+1}{k} a&#94;{n+1-k} b&#94;k \\end{align} Rekursive Folgen Der Grenzwert rekursiv definierter Folgen lÃ¤sst sich hÃ¤ufig sehr schÃ¶n mit mehreren Induktionsbeweisen beweisen. Finde fÃ¼r dich heraus: Ist die Folge monoton steigend oder fallend? ist 0 oder 1 eine untere / obere Schranke? gibt es andere untere oder obere Schranken? Beweise, dass du eine obere / untere Schranke gefunden hast Beweise, dass die Folge monoton steigt / fÃ¤llt Mache den Ansatz: Sei $a$ der Grenzwert der Folge $(a_n)_{n \\in \\mathbb{N}}$ mit $a_n = f(a_{n-1})$. Dann gilt: $a = f(a)$. LÃ¶se dann nach $a$ auf. Eine Folge in der das wunderbar klappt ist folgende: Sei \\((a_n)_{n \\in \\mathbb{N}}\\) eine Folge und definiert durch: \\(a_0 = 2,~~~~~ a_n = \\sqrt[3]{a_n&#94;2+a_n-1}\\) . Strukturelle Induktion Bei der vollstÃ¤ndigen Induktion iteriert man Ã¼ber eine natÃ¼rliche Zahl und gelangt so, ab einer festen natÃ¼rlichen Zahl \\(n_0\\) zu jeder beliebigen grÃ¶ÃŸeren natÃ¼rlichen Zahl. Die strukturelle Induktion nutzt allerdings nicht direkt Zahlen, sondern strukturen. Man hat eine sog. \"Atomare Struktur\" bzw. \"Atomares Element\", also in einem gewissen Sinn das oder die kleinsten Teilchen, gegeben. Diese Teilchen erfÃ¼llen die Aussage. Nun zeigt man, dass aus den Atomaren Elementen alle Strukturen gebildet werden kÃ¶nnen, Ã¼ber die in der Behauptung die Aussage getroffen wird und dass die Aussage bei jeder neuen Struktur richtig ist. Insbesondere bietet sich die strukturelle Induktion bei komplexen Graphen, aussagelogischen Formeln und WÃ¶rtern an. Beispiele Voller, vollstÃ¤ndiger BinÃ¤rbaum Sei G(V, E) ein BinÃ¤rbaum. G ist ein voller BinÃ¤rbaum \\(: \\Leftrightarrow\\) alle inneren Knoten von G haben den Verzweigungsgrad 2 G ist ein voller, vollstÃ¤ndiger BinÃ¤rbaum \\(: \\Leftrightarrow\\) G ist ein voller BinÃ¤rbaum und alle BlÃ¤tter haben die gleiche HÃ¶he Behauptung \\({\\cal B} (n)\\) : Jeder volle, vollstÃ¤ndige BinÃ¤rbaum der HÃ¶he \\(n, n \\in \\mathbb{N}\\) hat \\(2&#94;{n-1} - 1\\) innere Knoten. Beweis : durch strukturelle Induktion I.A. : zeige \\({\\cal B} (1)\\) . Ein voller, vollstÃ¤ndiger BinÃ¤rbaum der HÃ¶he n = 1 besteht nur aus einem Knoten. Er hat also \\(0 = 2&#94;{n-1} - 1 = 2&#94;{1-1} - 1 = 2&#94;0 - 1 = 1 - 1 = 0\\) innere Knoten. I.V. : FÃ¼r beliebige, aber feste volle, vollstÃ¤ndige BinÃ¤rbÃ¤ume G der HÃ¶he n gilt: G hat \\(2&#94;{n-1} - 1\\) innere Knoten. I.S. : zeige \\({\\cal B} (n+1)\\) FÃ¼r jeden vollen, vollstÃ¤ndigen BinÃ¤rbaum der HÃ¶he \\(n+1\\) gibt es einen Teilgraphen T, der ein voller, vollstÃ¤ndiger BinÃ¤rbaum der HÃ¶he n ist. \\(\\stackrel{I.V.}{\\Rightarrow}\\) T hat \\(2&#94;{n-1} - 1\\) innere Knoten. Das sind auch innere Knoten von G. Da die HÃ¶he von G um eins hÃ¶her ist als die von T und sowohl G als auch T volle, vollstÃ¤dige BinÃ¤rbaume sind, kommen zu jedem der \\(2&#94;{n-1}\\) BlÃ¤tter aus T noch 2 BlÃ¤tter. Dadurch hat G genau \\(2&#94;{n-1}\\) innere Knoten mehr als T \\(\\Rightarrow\\) G hat \\(2&#94;{n-1}-1+2&#94;{n-1} = 2&#94;n - 1\\) innere Knoten \\(\\blacksquare\\) Aussagenlogische AusdrÃ¼cke Die Idee habe ich aus dem Matheboard von \"MoeMoeson\". Bei diesem Beweis bin ich mir aber nicht sicher, ob es tatsÃ¤chlich strukturelle Induktion ist :-/ Definition: Aussagenlogischer Ausdruck Jede Variable \\(p_i, i \\in \\mathbb{N}\\) ist ein aussagenlogischer Ausdruck Ã¼ber V. Sind A und B aussagenlogische AusdrÃ¼cke Ã¼ber V, so sind auch \\(\\neg A, A \\land B, A \\lor B, A \\Rightarrow B, A \\Leftrightarrow B, (A)\\) . Ein Wort Ã¼ber V ist nur dann ein aussagenlogischer Ausdruck Ã¼ber V, falls dies aufgrund endlich oftmaliger Anwendung von (i) und (ii) der Fall ist. Behauptung Jeder aussagenlogischer Ausdruck endet entweder auf eine Variable oder auf eine schlieÃŸende Klammer. Beweis : durch strukturelle Induktion I.A. : Jeder aussagenlogischer Ausdruck aus (i) endet auf eine Variable. I.V. : FÃ¼r beliebige, aber feste aussagenlogische AusdrÃ¼cke A gilt: A endet auf eine Variable oder eine schlieÃŸende Klammer. I.S. : Ein aussagenlogischer Ausdruck kann nur durch endlich hÃ¤ufige Anwendung von (i) und (ii) erzeugt werden (vgl. (iii)). (i) erfÃ¼llt die Bedingung laut I.V., (ii) auch. \\(\\blacksquare\\) Behauptung FÃ¼r jeden aussagenlogischen Ausdruck A gibt es einen Ã¤quivalenten aussagenlogischen Ausdruck B, der nur \\(\\neg\\) und \\(\\land\\) als Operatoren verwendet. Beweis : durch strukturelle Induktion I.A. : Seien \\(p_1, p_2\\) aussagenlogische Variablen. Dann gilt: \\(p_1 \\lor p_2 = \\neg (\\neg p_1 \\land \\neg p_2)\\) \\(p_1 \\Leftrightarrow p_2 = \\neg (p_1 \\land \\neg p_2) \\land \\neg (\\neg p_1 \\land p_2)\\) \\(p_1 \\Rightarrow p_2 = p_1 \\land \\neg p_2\\) FÃ¼r alle weiteren AusdrÃ¼cke aus (i) und (ii) gilt die Behauptung offensichtlich. I.V. : FÃ¼r beliebige, aber feste aussagenlogische AusdrÃ¼cke A gilt: Es gibt einen Ã¤quivalenten aussagenlogischen Ausdruck B, der nur \\(\\neg\\) und \\(\\land\\) als Operatoren verwendet. I.S. : Ein aussagenlogischer Ausdruck kann nur durch endlich hÃ¤ufige Anwendung von (i) und (ii) erzeugt werden (vgl. (iii)). (i) und (ii) erfÃ¼llen die Bedingung laut I.V.. \\(\\blacksquare\\) Unendlich - Wann Induktion nicht funktioniert Mit Induktion kann man Aussagen fÃ¼r beliebig groÃŸe/kleine ganze Zahlen treffen. Allerdings eben nur fÃ¼r ganze Zahlen. Unendlich ist keine ganze Zahl. Also kann man auch keine Aussagen fÃ¼r \"unendliche Aussagen\" treffen. Hier ein Beispiel: Sei A eine Menge. A heiÃŸt offen \\(:\\Leftrightarrow \\forall_{x \\in A} : \\exists_{\\delta = \\delta(x) > 0} : U_\\delta(x) \\subseteq A\\) Es gilt: U und V sind offene Mengen \\(\\Rightarrow U \\cap V\\) ist offen.* Nun kÃ¶nnte man den Trugschluss machen, dass der Schnitt unendlich vieler offener Mengen auch offen ist. Der falsche Induktionsbeweis wÃ¼rde in etwa so aussehen: Voraussetungen: Seien \\(M_i, i \\in \\mathbb{N}_0\\) offene Mengen. Sei M eine Menge und definiert durch \\(M := \\displaystyle \\bigcap_{i=0}&#94;\\infty M_i\\) . Behauptung : M ist offen. Beweis : durch vollstÃ¤ndige Induktion I.A. : Sei n = 1. Dann: \\(\\cap_{i=0}&#94;1 M_i = M_0 \\cap M_1\\) ist laut * offen. I.V. : Sei \\(n \\in \\mathbb{N}\\) beliebig, aber fest und es gelte: \\(\\displaystyle \\bigcap_{i=0}&#94;n M_i\\) ist offen. I.S. : \\(\\displaystyle \\bigcap_{i=0}&#94;{n+1} M_i = \\bigcap_{i=0}&#94;{n} M_i \\cap M_{n+1}\\) . Nun gilt: \\(\\displaystyle \\bigcap_{i=0}&#94;{n} M_i\\) ist per I.V. offen. \\(M_{n+1}\\) ist per Vorraussetzung offen. Der Schnitt von beiden ist wegen * offen. Da n beliebig groÃŸ werden kann, ist auch M offen \\(\\blacksquare\\) Allerdings gilt: \\(\\displaystyle \\bigcap_{n=1}&#94;\\infty \\left (1 - \\frac{1}{n}, 2+\\frac{1}{n} \\right) = [1, 2]\\) , also ein Gegenbeispiel. Der \"Beweis\" ist also offensichtlich falsch. Wo ist aber der Fehler? Man hat gezeigt, dass beliebig viele Schnitte von offenen Mengen wieder offen sind. Die Behauptung sagt aber, dass unendlich viele Schnitte offener Mengen wieder offen sind. Es gibt also einen unterschied zwischen \"beliebig viel\" und \"unendlich\". Weitere Ãœbungen KIT, GBI: Zusatzblatt 2 , Ãœbungsaufgabe 16 - LÃ¶sungen KIT, GBI: Zusatzblatt 3 , Ãœbungsaufgabe 26 d) und 38 d) - LÃ¶sungen Otto Forster: Ãœbungsbuch zur Analysis I, 5. Auflage, S. 3 - 6. ISBN 978-3-8348-1252-0. Quellen Otto Forster: Analysis I, 10. Auflage, S. 1 - 11. ISBN 978-3-8348-1251-3. (Sehr zu empfehlen!) Folien zur GBI-Ãœbung am KIT Vorlesung vom 11.01.2012 Analysis I Skript (inoffiziell)","tags":"German posts","title":"Wie fÃ¼hre ich einen Induktionsbeweis?"},{"url":"https://martin-thoma.com/pradikatenlogik-aussagen-formalisieren/","text":"Es ist hÃ¤ufig von Vorteil, wenn man Aussagen formalisieren kann. Es ist beispielsweise gar nicht so leicht das exakte Gegenteil einer Aussage zu finden. Allgemeines zur PrÃ¤dikatenlogik x sei im folgenden eine Aussage \\(\\neg x\\) : Die Negation der Aussage x \\(\\exists x\\) : Es existiert mindestens ein x (Quantor) \\(\\forall x\\) : Alle x (Quantor) \\(\\land\\) : und (eine VerknÃ¼fung zweier Aussagen) \\(\\lor\\) : oder (eine VerknÃ¼fung zweier Aussagen). Im Deutschen wird oder meistens exklusiv, also im Sinne \"entweder ... oder ...\" verwendet. Dieses oder ist inklusiv, also \"entweder ... oder ... oder beides\". Ich habe die Symbole bewusst in diesen Paragraphen angeordnet. Wird die Negation eines Ausdrucks gebildet, werden alle Symbole im Inneren durch das jeweils andere Symbol ersetzt. Beispielsweise wird das logische \"und\" zu einem \"oder\". Ein kleiner Nachtrag: Was macht man, wenn man sagen will, dass eine Aussage A fÃ¼r genau ein Element x einer Menge M gilt? \\(\\exists x \\in M: A(x) \\land \\forall (y \\in M, y \\neq x): \\neg A(y)\\) Karlsruher und die Verkehrsmittel Folgendes Beispiel hatte ich in einem Tutorium am KIT: (i) Alle Karlsruher fahren mit dem Rad oder der StraÃŸenbahn. Was ist das Gegenteil dieser Aussage? Folgendes wÃ¤re denkbar: Kein Karlsruher fÃ¤hrt mit dem Rad oder der StraÃŸenbahn. Kein Karlsruher fÃ¤hrt mit dem Rad und der StraÃŸenbahn. Alle Karlsruher fahren mit dem Rad und der StraÃŸenbahn. Alle Karlsruher fahren nicht mit dem Rad und der StraÃŸenbahn. Es fahren nicht alle Karlsruher mit dem Rad oder der StraÃŸenbahn. Es fahren nicht alle Karlsruher mit dem Rad und der StraÃŸenbahn. ... Nun wurde mir beigebracht, dass folgendes eine \"saubere\" Formalisierung der ersten Aussage ist: Sei K die Menge aller Karlsruher. Sei F Aussageform auf K und definiert durch \\(F(k) := \\text{\"k f&auml;hrt mit dem Fahrrad\"} (k \\in K)\\) Sei analog S Aussageform auf K mit \\(S(k) := \\text{\"k f&auml;hrt mit der Stra&szlig;enbahn\"}\\) Dann lautet (i) formalisiert: \\(\\forall k \\in K: F(k) \\lor S(k)\\) (sprich: \"FÃ¼r alle k in K gilt: F von k oder S von k\") Negiert: \\(\\exists k \\in K: \\neg F(k) \\land \\neg S(k)\\) (sprich: \"Es existiert mindestens ein k in K fÃ¼r das gilt: Es ist F von k nicht wahr und zugleich S von k nicht wahr.\") Ãœbersetzt man das in einen schÃ¶neren deutschen Satz kann man sagen: Mindestens ein Karlsruher fÃ¤hrt weder mit dem Rad noch mit der Bahn. Wenn man das nun auf die oben angegebenen LÃ¶sungen bezieht, kÃ¶nnte es Aussage 5 oder 6 sein. Der SinngemÃ¤ÃŸ muss es heiÃŸen: Es fahren nicht alle Karlsruher entweder mit dem Rad, der StraÃŸenbahn oder beidem. Ich tendiere stark dazu, Satz 5 zu nehmen. Allerdings bin ich mir nicht sicher, ob mein SprachgefÃ¼hl mich tÃ¤uscht. WÃ¶chentliches Fernsehprogramm Noch ein Beispiel aus meinem Tutorium: (ii) Im Fernsehen lÃ¤uft jede Woche \"Die Simpsons\", \"Die Ludolfs\" und \"Telekolleg\". Sei W die Menge aller Wochen. Sei A Aussageform auf W. A(w) := In der Woche w lÃ¤uft \"Die Simpsons\". \\(w \\in W\\) B(w) := In der Woche w lÃ¤uft \"Die Ludolfs\". \\(w \\in W\\) C(w) := In der Woche w lÃ¤uft \"Telekolleg\". \\(w \\in W\\) Dann lautet (ii) formalisiert: \\(\\forall w \\in W: A(w) \\land B(w) \\land C(w)\\) Negiert: \\(\\exists w \\in W: \\neg A(w) \\lor \\neg B(w) \\lor \\neg C(w)\\) Teilbarkeit Nun mal etwas eigenes: (iii) Jede gerade Zahl ist durch zwei teilbar. Sei M die Menge der geraden Zahlen. Dann lautet (iii) formalisiert: \\(\\forall m \\in M: x = \\frac{m}{2} \\implies x \\in \\mathbb{N}\\) Weitere Materialien Uni Dortmund : 15 Seiten zum Formalisieren vom Aussagen TU-Berlin (Aufgabe 4 - \" Jeder, der ein gutes Gehor hat, kann richtig singen[...]\")","tags":"German posts","title":"PrÃ¤dikatenlogik: Aussagen formalisieren"},{"url":"https://martin-thoma.com/konstruktion-eines-deterministischen-endlichen-automaten-aus-einem-nicht-deterministischem/","text":"Der nicht-deterministische endliche Automat zu dem regulÃ¤rem Ausdruck \\((a \\cup (ab(b)&#94;\\text{*}ba))&#94;\\text{*}\\) ist folgender: \\(Q = \\{S, q_1, q_2\\}\\) \\(\\Sigma = \\{a, b\\}\\) \\(\\delta = \\text{siehe Grafik}\\) \\(F = \\{S\\}\\) \\(NEA = \\left( Q, \\Sigma, \\delta, S, F \\right)\\) Nondeterministic finite-state machine Will man daraus nun den endlichen Automaten konstruieren, lÃ¤uft das im Prinzip Ã¼ber eine Potenzmengenkonstruktion. Zuerst defnieren wir: \\(\\tilde{S} = E(S) = \\{S\\}\\) Dann erstellen wir folgende Tabelle: \\(\\tilde{S}\\) {S} a b Dann Ã¼berprÃ¼ft man, welche ZustÃ¤nde erreicht werden kÃ¶nnen, wenn man vom jedem Zustand in der Startmenge (hier also nur S) a einliest. Das ist in diesem Fall q1 oder S. Also haben wir eine weitere Zustandsmenge {q1, S}. Diese wird als neue Spalte in unsere Tabelle geschrieben: \\(\\tilde{S}\\) {S} {q1, S} a {q1, S} b Nun geht man also jede Spalte, von links nach rechts durch. FÃ¼r jede Spalte wird jede Zeile, von oben nach unten, Ã¼berprÃ¼ft. Mit jeder ÃœberprÃ¼fung kann eine neue Zustandsmenge als Spalte hinzukommen. Die Anzahl der Zeilen ist eine Kopfzeile + die Anzahl der Zeichen im Eingabealphabet. Am Ende schaut die Tablle wie folgt aus: \\(\\tilde{S}\\) {S} {q1, S} \\(\\emptyset\\) {q2} {q1, q2} a {q1, S} {q1, S} \\(\\emptyset\\) \\(\\emptyset\\) {S} b \\(\\emptyset\\) {q2} \\(\\emptyset\\) {q1, q2} {q1, q2} \\(\\tilde{Q} = \\{\\{S\\}, \\{q_1, S\\}, \\{q_2\\}, \\{q_1, q_2\\}\\}\\) \\(\\tilde{F} = \\{\\{S\\}, \\{q_1, S\\}\\}\\) Die Ãœbergangsfunktion wurde mit dieser Tabelle schon hinreichend dargestellt. Nun folgt eine Darstellung der deterministischen Variante des nichtdeterministischen Automaten: Deterministic Finite State machine (create from a non-deterministic version) Material Die .gv sieht so aus: digraph finite_state_machine { rankdir=LR; size=\"8,5\" node [shape = doublecircle, label=\"{S}\"] S; node [shape = doublecircle, label=\"{q1, S}\"] q1S; node [shape = circle, label=\"{q2}\"] q2; node [shape = circle, label=\"{q1, q2}\"] q1q2; node [shape = circle, label=\"{}\"] T; node [shape = point ]; qi qi -> S; S -> q1S [ label = \"a\" ]; S -> T [ label = \"b\" ]; q1S -> q1S [ label = \"a\"]; q1S -> q2 [ label = \"b\"]; q2 -> T [ label = \"a\"]; q2 -> q1q2 [ label = \"b\"]; q1q2 -> S [ label = \"a\"]; q1q2 -> q1q2 [ label = \"b\"]; T -> T [label = \"a, b\"]; } Unter Linux kann man mit GraphViz mit folgendem Befehl die Datei erstellen: dot -Tpng graph.gv -o deterministic-fsm.png","tags":"German posts","title":"Konstruktion eines deterministischen endlichen Automaten aus einem nicht-deterministischem"},{"url":"https://martin-thoma.com/how-to-draw-a-finite-state-machine/","text":"Finite-state machines are necessary to show that some problems are computable (or not). As I am currently learning something about them, I would like to be able to plot those finite automatons automatically. I will use graphviz . Nondeterministic finite-state machine Nondeterministic finite-state machine This image is created from a gv-file. I saved it as fsm.gv: digraph finite _ state _ machine { rankdir=LR; size=\"8,5\" node [shape = doublecircle]; S; node [shape = point ]; qi node [shape = circle]; qi -> S; S -> q1 [ label = \"a\" ]; S -> S [ label = \"a\" ]; q1 -> S [ label = \"a\" ]; q1 -> q2 [ label = \"b\" ]; q2 -> q1 [ label = \"b\" ]; q2 -> q2 [ label = \"b\" ]; } To create a graph (or the picture of the nondeterministic finite-state machine) you have to enter the following command in Ubuntu Linux: dot -Tpng fsm.gv -o myFiniteStateMachine.png Deterministic finite-state machine Deterministic finite-state machine digraph finite _ state _ machine { rankdir=LR; size=\"8,5\" node [shape = doublecircle, label=\" { f } \", fontsize=12] f; node [shape = doublecircle, label=\" { q2, f } \", fontsize=10] q2f; node [shape = circle, label=\"S\", fontsize=14] S; node [shape = circle, label=\" { q1 } \", fontsize=12] q1; node [shape = circle, label=\" { q2 } \", fontsize=12] q2; node [shape = point ]; qi qi -> S; S -> q1 [ label = \"a\" ]; S -> q2f [ label = \"b\" ]; S -> q2 [ label = \"c\" ]; q1 -> q2 [ label = \"b\" ]; q2f -> f [ label = \"b\" ]; q2f -> q2 [ label = \"c\" ]; q2 -> f [ label = \"b\" ]; q2 -> q2 [ label = \"c\" ]; } LaTeX If you want to draw finite-state machines with LaTeX, you might want to give tikz a try. This is the most minimalistic version I could create. It is equivalent to the nondeterministic finite-state machine I've described above: \\documentclass { scrartcl } \\usepackage { tikz } \\usetikzlibrary { arrows,automata } \\begin { document } \\begin { tikzpicture } [>=stealth',shorten >=1pt,auto,node distance=2cm] \\node [initial,state,accepting] (S) { $ S $ } ; \\node [state] (q1) [right of=S] { $ q_ 1 $ } ; \\node [state] (q2) [right of=q1] { $ q_ 2 $ } ; \\path [->] (S) edge [loop above] node { a } (S) edge node { a } (q1) (q1) edge [bend left] node { a } (S) edge node { b } (q2) (q2) edge [loop above] node { b } (q2) edge [bend left] node { b } (q1); \\end { tikzpicture } \\end { document } This was the most basic example which shows how to draw a finite-state automaton with LaTeX. You can get it as a PDF with this command: pdflatex latexsheet.tex -output-format = pdf If you want to see some more fancy stuff, take a look at this example of a non-deterministic finite state machine: Finite-state-machine with LaTeX \\documentclass { scrartcl } \\usepackage { tikz } \\usetikzlibrary { arrows,automata } \\begin { document } \\begin { tikzpicture } [>=stealth',shorten >=1pt,auto,node distance=2cm] \\node [initial,state,accepting] (S) { $ S $ } ; \\node [state] (q1) [right of=S] { $ q_ 1 $ } ; \\node [state] (q2) [right of=q1] { $ q_ 2 $ } ; \\path [->] (S) edge [loop above] node { a } (S); \\path [->, dashed] (S) edge node { a } (q1); \\path [->, dotted] (q1) edge [bend left] node { a } (S); \\path [->>, dotted] (q1) edge node { b } (q2); \\path (q2) edge [loop above] node { b } (q2) edge [bend left] node { b } (q1); \\end { tikzpicture } \\end { document } Markov models \\documentclass { scrartcl } \\usepackage { tikz } \\usetikzlibrary { arrows,automata } \\begin { document } \\begin { tikzpicture } [->,>=stealth',shorten >=1pt,node distance=2.8cm] % When you want to use // inside of nodes, you have to algin \\tikzstyle { every state } =[align=center] \\node [state,initial,label=below:Start] (Start) { A 0.6 \\\\ B 0.2 \\\\ C 0.2 } ; \\node [state,label=below:Mitte] (Mitte) [right of=Start] { A 0.1 \\\\ B 0.1 \\\\ C 0.8 } ; \\node [state,label=below:Ende] (Ende) [right of=Mitte] { A 0.5 \\\\ B 0.2 \\\\ C 0.3 } ; \\path (Start) edge node[above] { 0.2 } (Mitte); \\path (Mitte) edge node[above] { 0.8 } (Ende); \\path (Start) edge [loop above] node { 0.8 } (Start); \\path (Mitte) edge [loop above] node { 0.2 } (Mitte); \\path (Ende) edge [loop above] node { 1 } (Ende); \\end { tikzpicture } \\end { document } Further Reading DOT Node Shape reference ubuntuusers.de (German): Installation on Ubuntu Wikischool.de (German): Many examples","tags":"My bits and bytes","title":"How to draw a finite-state machine"},{"url":"https://martin-thoma.com/dvd-menu-in-youtube/","text":"Today a friend of mine posted an article about a very neat idea. He created a DVD-like menu with several YouTube clips. Just take a look: This idea is beautiful: It is simple, but it didn't come to my mind before. I knew overlays and saw them sometimes, but I never saw them being used in such a nice way. Great work, RenÃ©!","tags":"The Web","title":"DVD menu in YouTube"},{"url":"https://martin-thoma.com/einfuhrung-in-die-abzahlende-kombinatorik/","text":"Die abzÃ¤hlende Kombinatorik beschÃ¤ftigt sich mit der Bestimmung der Anzahl mÃ¶glicher Anordnungen oder Auswahlen. Begriffe Permutation Eine Permutation ist eine VerÃ¤nderung der Reihenfolge einer geordneten Anzahl von Objekten. (Weil die Objekte in irgend einer Art geordnet sein mÃ¼ssen, damit sich eine Reihenfolge Ã¤ndern kann, will ich diese Ansammlung nicht \"Menge\" nennen.) Beispiel: Wir haben eine Liste von Zahlen: [1, 2, 5, -7, -1, 3] Eine Permutation davon ist: [1, 2, 5, -7, 3, -1] Anagramme sind Permutationen: \"ANGSTBUDE\" und \"BUNDESTAG\" Das Wesentliche ist also, dass es bei Permutationen auf die Reihenfolge ankommt. k-Permutation Eine k-Permutation wÃ¤hlt aus n Objekten k aus. Wenn wir also die 6 Objekte [1, 2, 5, -7, -1, 3] haben, wÃ¤ren [1, 2, 5], [5, 2, 1], [-7, 2, 3] und [-7, 3, 3] verschiedene 3-Permutationen davon. Kombination und k-Kombination Bei einer Kombination kommt es nicht auf die Reihenfolge an. Sonst ist alles analog zu den Permutationen. Formeln Es gibt nur vier Formeln, die man sich merken sollte. Dabei sei n die Anzahl aller wÃ¤hlbaren Objekte: mit Wiederholungen ohne Wiederholungen k-Permutation $n&#94;k$ $\\frac{n!}{(n-k)!}$ k-Kombination $\\binom{n-1+k}{k}$ $\\binom{n}{k}$ Warum stimmt das? Wenn man n Objekte hat und k-mal eines davon auswÃ¤hlt, wobei die Reihenfolge eine Rolle spielt und man das Objekt danach immer wieder zurÃ¼ck legt (also Wiederholungen haben kann), dann hat man beim ersten mal n verschiedene WahlmÃ¶glichkeiten. Beim zweiten, dritten, ... k.-Zug auch. Es sind also \\(\\underbrace{n \\cdot n \\cdot ... \\cdot n}_\\text{k mal} = n&#94;k\\) MÃ¶glichkeiten. Wenn man die Objekte nicht wieder zurÃ¼ck legt, die Reihenfolge aber eine Rolle spielt, hat man beim ersten Zug wieder n MÃ¶glichkeiten. Beim zweiten Zug sind es (n-1), beim dritten (n-3), ... beim k.-Zug (n-k+1) MÃ¶glichkeiten. Also gilt: \\(\\underbrace{(n-0) \\cdot (n-1) \\cdot ... \\cdot (n- (k-1))}_\\text{k Faktoren} = \\prod_{i=0}&#94;{k-1} (n-i)= \\frac{n!}{(n-k)!}\\) Angenommen es spielt nun nur eine Rolle, welche Objekte man ausgewÃ¤hlt hat, aber nicht wann. Dann gibt es, wenn man die Objekte nicht wieder zurÃ¼cklegt, \\(\\frac{n!}{(n-k)!}\\) MÃ¶glichkeiten, abzÃ¼glich der MÃ¶glichkeiten, die nur bei Beachtung der Reihenfolge eine Rolle spielen. Das bedeutet, es muss noch durch k! geteilt werden. Das kann man sich klar machen, indem man eine bestimmte Menge an k ausgewÃ¤hlten Objekten betrachtet. Dann muss man entscheiden, welches das erste ist. DafÃ¼r gibt es k MÃ¶glichkeiten. FÃ¼r das zweite hat man (k-1) MÃ¶glichkeiten, usw. Das Bedeutet, es gibt fÃ¼r diesen Fall \\(\\frac{n!}{(n-k)! \\cdot k!} = \\binom{n}{k}\\) MÃ¶glichkeiten. Der schwerste Fall sind k-Kombinationen mit zurÃ¼cklegen. DafÃ¼r denkt man sich am besten, dass man eine Liste der Objekte hat. Nun macht man, um die n Objekte zu trennen, zwischen diese (n-1) Sternchen. Die Anzahl wird durch k Striche reprÃ¤sentiert. Nun kann man sich fragen, wie viele MÃ¶glichkeiten es gibt diese k Striche und (n-1) Sternchen anzuordnen. Das sind, wenn man die k Striche auf (n-1)+k PlÃ¤tze verteilt: \\(\\frac{(n-1+k)!}{(n-1)!} \\cdot \\underbrace{\\frac{1}{k!}}_\\text{Reihenfolge ist egal} = \\frac{(n-1+k)!}{(n-1)!k!}\\) Dies entspricht genau dem Binomialkoeffizienten: \\(\\binom{n-1+k}{k} = \\frac{(n-1+k)!}{k!((n-1+k)-k)!} = \\frac{(n-1+k)!}{k!(n-1)!}\\) Siehe auch Wikipedia: Kombinatorik (Der Artikel ist leider sehr mager. Eventuell hat jemand lust ihn zu ergÃ¤nzen?) AbzÃ¤hlende Kombinatorik Permutation Anagramm Binomialkoeffizient","tags":"German posts","title":"EinfÃ¼hrung in die abzÃ¤hlende Kombinatorik"},{"url":"https://martin-thoma.com/clip-love-tap/","text":"A five-minute reminder to not let love pass you by. Developed as original content for Walt Disney Pictures Short Films division.","tags":"The Web","title":"Clip: Love Tap"},{"url":"https://martin-thoma.com/wie-fuhre-ich-einen-sauberen-beweis/","text":"In der Mathematik spielen Beweise eine zentrale Rolle. Es gibt verschiedene Beweisarten, aber im folgenden will ich nur einen direkten Beweis fÃ¼hren. Dieses Beispiel wurde in der Ãœbung zu Analysis I von Herrn Bolleyer gemacht. Gliederung Beweise kann man in drei Teile gliedern: Voraussetzungen : Hier werden spezielle Objekte, die im Beweis benÃ¶tigt werden, definiert. Behauptung : Die Behauptung stellt eine Aussage Ã¼ber die Objekte in der Voraussetzung auf. Sie kann sehr kurz sein. Beweis : Der Beweis zeigt durch eine folge von logischen Schlussfolgerungen aus den Voraussetzungen, dass die Behauptung wahr ist. NÃ¶tig ist manchmal nur die Behauptung und der Beweis. Mit der Vorraussetzung ist der Beweis zwar vollstÃ¤ndig, allerdings wÃ¼rde ich vor dem eigentlichem Beweis eine Beweisidee begrÃ¼ÃŸen. Die Beweisidee kann sehr kurz sein. Das ist der eine Satz, der einem Studenten, der sich mit der Aussage beschÃ¤ftigt hat, sagt wie sie zu lÃ¶sen ist. Beispiel eines direkten Beweises Voraussetzung : Sei \\(M = \\{ x \\in \\mathbb{R}: |x-3| \\lt 2 \\}\\) Behauptung : \\(M = (1,5)\\) Beweis : Per Definition gilt: \\(|x-3| : = \\left \\{ \\begin{array}{ll} x & \\text{, falls } x \\geq 3 \\\\ -(x-3) & \\text{, falls } x \\lt 3 \\end{array} \\right.\\) \\( M = \\{x \\in \\mathbb{R} \\lt 2 \\} = \\underbrace{\\{x \\in \\mathbb{R} : |x-3| \\lt 2 \\land x \\geq 3 \\}}_{M_1} \\cup \\underbrace{\\{x \\in \\mathbb{R}: |x -3| \\lt 2 \\land x \\lt 3\\}}_{M_2}\\) Betrachte \\(M_1\\) : \\( x\\in M_1 \\Leftrightarrow |x-3| \\lt 2 \\land x \\geq 3\\) \\(\\Leftrightarrow x-3 \\lt 2 \\land x \\geq 3\\) \\(\\Leftrightarrow x \\lt 5 \\land x \\geq 3\\) \\(\\Leftrightarrow 3 \\leq x \\lt 5\\) Also gilt \\(M_1 = [3, 5)\\) Betrachte \\(M_2\\) : \\( x\\in M_2 \\Leftrightarrow |x-3| \\lt 2 \\land x \\lt 3\\) \\(\\Leftrightarrow -(x-3) \\lt 2 \\land x \\lt 3\\) \\(\\Leftrightarrow -x + 3 \\lt 2 \\land x \\lt 3\\) \\(\\Leftrightarrow 1 \\lt x \\land x \\lt 3\\) \\(\\Leftrightarrow 1 \\lt x \\lt 3\\) Also gilt \\(M_2 = (1,3)\\) Es gilt \\(M = M_1 \\cup M_2 = [3, 5) \\cup (1,3) = (1,5)\\) q.e.d. Weitere Beweisformen Der Induktionsbeweis ist sehr nÃ¼tzlich, wenn man eine Aussage fÃ¼r Elemente zeigen muss, die einen festen Abstand haben. Also z.B. eine Aussage fÃ¼r die NatÃ¼rlichen Zahlen oder die ganzen Zahlen. Der Widerspruchsbeweis ist gut geeignet, wenn notwendige, aber nicht hinreichende Kriterien fÃ¼r das Gegenteil der Behauptung nicht erfÃ¼llt sind. Siehe auch Wikipedia: Beweis Inoffizielles Script","tags":"German posts","title":"Wie fÃ¼hre ich einen sauberen Beweis?"},{"url":"https://martin-thoma.com/game-marble-run/","text":"Marble Run Go to the Game : marblerun.at Task : Create a Track for that little red dot, which is as long as possible. How to play : On the right side of the screen you can see a toolbar. Different bricks, some with special functions, can be used to build your track. My Record : 37m Programming : The entire page is written in HTML + JavaScript. They used the Prototype JS library.","tags":"The Web","title":"Game: Marble Run"},{"url":"https://martin-thoma.com/understanding-python-lists/","text":"This article is about Python lists. I just want to show you some examples of the unexpected behavior (for non-python-programmers) of lists in Python. Imagine you have the following Python source code: #!/usr/bin/python # -*- coding: utf-8 -*- import copy example1 = [[ 1 , 5 , 7 ],[ 3 , 6 ],[], [ 8 , 1 , 6 ]] example2 = example1 [:] example3 = list ( example1 ) example4 = copy . deepcopy ( example1 ) example1 [ 1 ][ 0 ] = 0 example1 . append ( 1 ) print example1 print example2 print example3 print example4 How should the output look like? Think about it a second, then scroll down. [[ 1 ,5,7 ] , [ 0 ,6 ] , [] , [ 8 ,1,6 ] ,1 ] [[ 1 ,5,7 ] , [ 0 ,6 ] , [] , [ 8 ,1,6 ]] [[ 1 ,5,7 ] , [ 0 ,6 ] , [] , [ 8 ,1,6 ]] [[ 1 ,5,7 ] , [ 3 ,6 ] , [] , [ 8 ,1,6 ]] The reason for this strange behavior is how lists are handled in Python. The variable itself is basically only the pointer to the list. If you slice the list (myList[:]) you copy each value of the list into another list. If myList was a nested list, it contained the pointers to the sublists. So, if you want to make a deep copy, you have to use the copy module. Scoping phimuemue added this example in my old blog: Another issue I ran into concerns the scoping of Python: i = 0 [ i for i in [ 1 , 2 , 3 ]] print ( i ) # yields 3 That means, python doesn't create a new variable for the list comprehension but uses the outer i. Recursive Lists a = [ 1 , 2 , 3 ] b = [ 4 , 5 , 6 ] a . append ( b ) print ( a ) [ 1 , 2 , 3 , [ 4 , 5 , 6 ]] b . append ( a ) print ( b ) [ 4 , 5 , 6 , [ 1 , 2 , 3 , [ ... ]]] print ( a ) [ 1 , 2 , 3 , [ 4 , 5 , 6 , [ ... ]]] Do you know more examples of unexpected behavior of python lists? Please share them in the comments!","tags":"Code","title":"Understanding Python Lists"},{"url":"https://martin-thoma.com/improvements-for-my-universitys-website/","text":"I am now studying at the Karlsruhe Institute of Technology (KIT). Although I think that the Websites of KIT is much better than the Website of most Universities, I can imagine several possibilities how the online services could be improved: Use OpenID I have 9 different accounts with 7 different passwords for university. After my first week. I guess it is impossible to use the same login system for all services of the university as we have many different teams of developers. But it is easily possible to get an OpenID provider. The students could have an URL like student.kit.edu/openid/u.... or something similar. The login would always happen at one place and this server could tell the other services that the right user is trying to get access. Some more information about OpenID is here: Wikipedia (the German article is much better) OpenID According to Dave (4:35 min) The Implications of OpenID (51:19 min) Customization It would help me a lot if I could customize my start page at studium.kit.edu by adding some links / text. Consistency The university was called \"University of Karlsruhe\" (\"UniversitÃ¤t Karlsruhe\" in German) a few years ago. Then they thought it was time to rename the university as they made major structural changes. URLs - one Top-level domain They also got a new URL. Before the new one is kit.edu, but it seems as if many pages were still on the old TLD : uni-karlsruhe.de: fsmi.uni-karlsruhe.de : fsmi.kit.edu mach.uni-karlsruhe.de : should be mach.kit.edu http://www.ira.uka.de/: webinscribe.ira.uka.de : should be webinscribe.kit.edu. Additionally, a link from studium.kit.edu to this service should be created. www.itas.fzk.de : should be itas.kit.edu. (I guess fzk means \"Forschungszentrum Karlsruhe\" - research center Karlsruhe) This could be fixed with the following steps: Find old URLs / Links (e.g. with RegEx and a crawler ) Introduce the new URL by one of those two possibilities: Make HTML-redirections for the new ones (e.g. from fsmi.kit.edu to www.fsmi.uni-karlsruhe.de) Move the content from the old space to the new space. Make sure that nothing breaks by adding a 301 status code . Replace all links to the old URL by the new URL. Wait at least one, rather two semester. Check which internal Websites still use the old URL and try to fix those links. Completely remove the old URL Services in one place KIT offers quite a lot of online services, such as Search for books in KIT-library bvprint : How much money is left on my printing-account? Webmail: u....@student.kit.edu / prename.lastname@student.kit.edu / u....@stud.uni-karlsruhe.de: owa.kit.edu - with Microsofts OWA s_...@atis.uka.de: webmail.ira.uni-karlsruhe.de - with Horde Groupware Web-Server with MySQL databases and phpMyAdmin New Sites : Create a site for you For some services you need to login via https://vpn.kit.edu : Print preview: https://scc-print.scc.kit.edu and the (buggy) newer version . PrintUtil : Which jobs are in the queue of the printer? Scanning: studscan.ira.uka.de I had to search for some services, like a SVN-Repository ( How do I get a SVN repository at KIT? ) The important services should be available at studium.kit.edu. I think this would be a link to the Webmail, to the printing services and webinscribe. Help the user to find what he needs Redundancy Sometimes it is good to provide several alternatives. I have one example: One of the most important URLs at my university's website is studium.kit.edu. In the first week, I typed quite often student.kit.edu. Google corrected kit to mit and the MIT has such a page. I think it would be a good idea to look at the 404-error log and check, if this occurs often. If it does, a redirect should probable be added. All redundant URLs should point to ONE target, of course. It's best to use a 301 redirection. Short, but meaningful URLs At the moment KIT makes use of such URLs: www.kit.edu/index.php should be kit.edu www.informatik.kit.edu/index.php should be informatik.kit.edu www.informatik.kit.edu/883.php should be informatik.kit.edu/informatik-bachelor www.informatik.kit.edu/interact.php should be informatik.kit.edu/interact This can be done by modifying the .htaccess-file (for the decision to redirect calls prefixed with www to a non-www page). In many cases you can use the URL which I would prefer, but you're redirected to the other one. This means if a professor is copying the ugly link to his presentation, all students will have to write it down. Helpfull 404 Page At the moment I get only: \"404 NOT FOUND\". This is not very helpful. You should provide a custom 404 error page . Use Feeds I would like to get the latest news about KIT, but I don't want to search for it. I also don't want to look at the homepage of KIT to check if I know the latest content. This should be done with a RSS feed. The start page should have an auto-detectable RSS-Feed. It can be added with the following HTML-Tag in the head-section of the document: < link rel = \"alternate\" type = \"application/rss+xml\" title = \"KIT News Feed\" href = \"/rss/\" /> Use HTML5 input tags HTML5 input tags can much more than the old ones. You can define autofocus for the first element, placeholders , autocomplete =off for password fields at the registration, patterns for clients side validation and much more types than text and password. Old browsers automatically fall back into a simple text input field. Examples for pages that could be improved: kit.edu : Add search engine autodiscovery Register library account studium.kit.edu kit.edu (the search box) kit.edu/studieren/6243.php (the contact form at the bottom) kit.edu/markt/userlogin (the login form) If somebody had much free time he could try to get valid HTML5 for the whole website. This isn't really helpful for the user (by now), but it would be nice to have a standard conform website. Payments You have to pay with the \"KIT-Card\" for meals in the cafeteria and if you want to print something. But you have to transfer the money to the printing account from your cafeteria account, before you can print anything. This seems to be not logical for me. Why do we have to use two university \"bank\" accounts?","tags":"The Web","title":"Improvements for my University's Website"},{"url":"https://martin-thoma.com/custom-404-error-pages/","text":"A 404 http status code means that no document could be found at the given URL. The reason could be a misspelled URL or moved content. Anyway, the user needs help now. The standard error page doesn't provide much information, so you should create a custom one. If you like more information, just Google for \"custom 404 page\". How to create a custom 404 error page Simply add the following line to your .htaccess file: ErrorDocument 404 /notfound.php (This will work only on an Apache webserver, of course). Now you have to create a notfound.php file. This file should provide the following information: Tell the user that he typed a wrong URL or that the link pointed to a target which doesn't exist Provide a search box Provide a link to a graphical sitemap Provide some funny / interesting content Make sure that a 404 http status code is still returned after your changes Good examples 60 Really Cool And Creative Error 404 Pages 36 Cool Custom Error 404 Pages 404 Error Pages: Reloaded Further Reading 404 Error Pages .com Wikipedia","tags":"The Web","title":"Custom 404 error pages"},{"url":"https://martin-thoma.com/search-engine-autodiscovery/","text":"Recently I read a very good post about search engine autodiscovery by Jan Phillip . Did you know that many browsers can detect an internal search engine automatically? Firefox gives you the possibility to add such a search engine to your browser: Firefox: Add search engine detected via autodiscovery OpenSearch OpenSearch is a collection of technologies. This project aims to create a standard for publishing the metadata which describes a search engine: name, description, URL-pattern, language, ... A OSSD looks like this: <OpenSearchDescription xmlns= \"http://a9.com/-/spec/opensearch/1.1/\" > <ShortName> Example </ShortName> <Description> My example search engine </Description> <InputEncoding> UTF-8 </InputEncoding> <Image height= \"16\" width= \"16\" type= \"image/x-icon\" > http://example.org/favicon.ico </Image> <Url type= \"text/html\" template= \"http://example.org/index.html#search={searchTerms}\" /> </OpenSearchDescription> The browser needs a hint where it can find the OSSD. So you have to add the following tag to your website: <link title = \"Example\" type = \"application/opensearchdescription+xml\" rel = \"search\" href = \"http://example.org/opensearch.xml\" > Now you can add the websites internal search engine automatically to Chrome and easily to Firefox and Internet Explorer 8+. Additionally, you can add this little piece of JavaScript to tell Firefox 2+ and Internet Explorer 7+ that your site supports OpenSearch: window . external . AddSearchProvider ( \"http://exampl.org/opensearch.xml\" ); Google Chrome Autodiscovery Google doesn't provide a UI for adding an internal search engine. Instead, you can add it via Settings: Add Search Engines via Settings in Google Chrome Chrome also adds the sites internal search engine automatically. Did you ever notice this? Here are some screenshots: Google Chrome Search - Hit tab to search this site Google Chrome Search - Search with the websites internal search engine Interestingly the auto discovery only works if the search engine is at the homepage. You have to have either an input field of the type search or of the type text with the name s : < form > < input type = \"search\" name = \"s\" /> </ form > or < form > < input type = \"text\" name = \"s\" /> </ form > Drawbacks It seems as if Safari didn't support OSSD natively. (14.04.2011) Internet Explorer 9 seems not to support OSSD. No support by Opera. This article in a nutshell opensearch.xml gives meta information about your websites internal search engine For Chromes autodiscovery you will need to add an input fild with \"type=search\" or \"name=s\" It is not necessary for Chrome that the user can see the form (display:none with CSS) nor that it the site start page is loaded long (meta redirect after 0 seconds). Adding the search engine manually is possible in almost all browsers With OSSD you can manage more than one internal search engine. Further reading OpenSearch.org: OpenSearch search clients Developer best practices guide David Walsh: Add Your Website to Firefox's Search Bar Using OpenSearch XML .","tags":"Code","title":"Search Engine Autodiscovery"},{"url":"https://martin-thoma.com/clip-bob-the-hamster/","text":"Bob tells the story of a little hamster that tries to follow his true love around the globe. Can he catch up? We all hope you have fun watching it! Enjoy!","tags":"The Web","title":"Clip: Bob the Hamster"},{"url":"https://martin-thoma.com/warlight-an-online-risk-clone/","text":"Risk is a great strategic game in which you have to conquer the world. Now I've found a clone called \"Warlight\": Warlight Go to the Game : WarLight on Kongregate Task : Conquer the world. How to play : Each turn you get armies depending on the number of countries / territories you control. My Record : I could solve Level 1 - 3 and Europe.","tags":"The Web","title":"WarLight: An online Risk clone"},{"url":"https://martin-thoma.com/community-chess/","text":"Community Chess is one of my projects. I can make something useful and play a bit. This project has now an own URL: community-chess.com It's a little bit crappy at the moment as I've just started studying, but I'll fix that. If you like to help, please write me an e-mail (info@martin-thoma.de). Everybody can help. Here are some examples: I need some people who can create a better design / color scheme use it and know chess rules know how to customize phpBB know how to write Ajax for a better GUI (playChess.php works with PHP and HTML at the moment) can speak other languages than English and German know how to advertise like to support this project with money (I have to pay 26.16 Euro per year for hosting this service. If I get more money I will save it for the next years hosting costs. If it's much more I could try to find a professional designer.)","tags":"The Web","title":"Community Chess"},{"url":"https://martin-thoma.com/analysis-i-teil-1/","text":"Begriffe und Bezeichnungen Mengen Es seien M und N Mengen. \\(M \\cup N\\) : Vereinigung - Die Elemente sind in M oder N \\(M \\cap N\\) : Durchschnitt (\"Schnittmenge\") - Die Elemente sind in M und N \\(M \\setminus N\\) : Differenzmenge - Die Elemente sind in M aber nicht in N \\(M \\subseteq N\\) : Teilmenge - Alle Elemente in M sind auch in N \\(\\emptyset\\) : Leere Menge \\(a \\in M\\) : a ist ein Element von M \\(a \\notin M\\) : a ist kein Element von M Funktionen Seien M, N Mengen mit \\(M \\neq \\emptyset \\neq N\\) . \\(f: \\underbrace{M}_{\\mathbb{D}} \\to \\underbrace{N}_{\\mathbb{W}}\\) Logische Zeichen \\(\\Rightarrow\\) : Implikation, z.B. \\(A \\Rightarrow B\\) : Aus A folgt B \\(\\Leftrightarrow\\) : Ã„quivalenz. \\(A \\Rightarrow B \\wedge B \\Rightarrow A\\) : Aus A folgt B und umgekehrt. \\(\\underbrace{: \\Leftrightarrow}_\\text{\"genau dann\"}\\) , z.B. \\(M \\subseteq N : \\Leftrightarrow \\text{aus } x \\in M \\text{ folgt stets } x \\in N\\) . \\(\\forall\\) : Allquantor , sprich \"fÃ¼r alle\" oder \"fÃ¼r jedes\" \\(\\exists\\) : Existenzquantor , sprich \"es gibt mindestens ein\" oder \"es existiert\" Reele Zahlen Die Grundmenge der Analysis ist die Menge \\(\\mathbb{R}\\) , die Menge der reelen Zahlen. Diese fÃ¼hren wir durch die folgenden 15 Axiome ein. KÃ¶rperaxiome In \\(\\mathbb{R}\\) seien zwei VerknÃ¼pfungen \"+\" und \"Â·\" gegeben. Sie ordnen jedem Paar \\(a, b \\in \\mathbb{R}\\) genau ein \\(ab := a \\cdot b \\in \\mathbb{R}\\) zu. Dabei soll gelten: \\(\\left. \\begin{array}{lllll} A.1 & a+ (b+c) & = & (a+b)+c & \\forall a, b, c \\in \\mathbb{R} \\\\ A.2 & a \\cdot (bc) & = & (ab) \\cdot c & \\forall a, b, c \\in \\mathbb{R} \\\\ \\end{array} \\right \\} \\text{Assoziativgesetze}\\) \\(\\left. \\begin{array}{lllll} A.3 & a + b & = & b + a & \\forall a, b \\in \\mathbb{R} \\\\ A.4 & a \\cdot b & = & b) \\cdot a & \\forall a, b \\in \\mathbb{R} \\\\ \\end{array} \\right \\} \\text{Kommutativgesetze}\\) \\(\\left. \\begin{array}{lllll} A.5 & \\exists 0 \\in \\mathbb{R} & : & a + 0 = a & \\forall a \\in \\mathbb{R} \\text{ (\"Null\")} \\\\ A.6 & \\exists 1 \\in \\mathbb{R} & : & a \\cdot 1 = a \\wedge 1 \\neq 0 & \\forall a \\in \\mathbb{R} \\text{ (\"Eins\")} \\\\ \\end{array} \\right \\} \\text{Neutrales Element}\\) \\(\\left. \\begin{array}{lllll} A.7 & \\forall a \\in \\mathbb{R} \\exists -a \\in \\mathbb{R} & : & a + (-a) = 0 \\\\ A.8 & \\forall a \\in \\mathbb{R} \\setminus {0} \\exists -a&#94;{-1} \\in \\mathbb{R} & : & a \\cdot a&#94;{-1} = 1 \\end{array} \\right \\} \\text{Inverses Element}\\) \\(\\text{A.9 } a(b+c) = ab+ac \\forall a, b, c \\in \\mathbb{R}\\) : Distributivgesetz Schreibweisen: fÃ¼r \\(a, b \\in \\mathbb{R}: a -b := a + (-b)\\) fÃ¼r \\(b \\neq 0: \\frac{a}{b} := a \\cdot b&#94;{-1}\\) Alle Rechenregeln bzgl der Grundrechenarten lassen sich aus A.1 - A.9 herleiten. Diese Regeln seien von nun an bekannt. Behauptung : Es existiert genau ein \\(0 \\in \\mathbb{R}: a+0 = a \\forall a \\in \\mathbb{R}\\) Beweis : Existenz: folgt aus A.5 Eindeutigkeit: Sei \\(\\tilde 0 \\in \\mathbb{R} \\text{ mit }a+\\tilde 0 a \\forall a \\in \\mathbb{R}\\) Mit \\(a = 0: 0 = 0 + \\tilde 0 \\underbrace{=}_{\\text{A.3}} \\tilde 0 + 0 \\underbrace{=}_{\\text{A.5}} = \\tilde 0\\) Behauptung : Ist \\(a \\in \\mathbb{R}\\text{, so ist }a \\cdot 0 = 0\\) Beweis : \\( b := a \\cdot 0 \\underbrace{\\Rightarrow}_\\text{A.5} b = a (0 + 0) \\Rightarrow a \\cdot 0 + a \\cdot 0 = b + b\\) \\(0 = b + (-b) = (b+b) + (-b) = b + (b + (-b)) = b + 0 = b\\) Anordnungsaxiome In \\(\\mathbb{R}\\) sei eine Relation \" \\(\\leq\\) \" gegeben. Dabei soll gelten: $ \\begin{array}{lll} A.10 & a \\leq b \\lor b \\leq a & \\forall a, b \\in \\mathbb{R} \\\\ A.11 & a \\leq b \\land b \\leq a & \\rightarrow a = b \\\\ A.12 & a \\leq b \\land b \\leq c & \\rightarrow a \\leq c \\\\ A.13 & a \\leq b \\rightarrow a + c \\leq b + c & \\forall c \\in \\mathbb{R} \\\\ A.14 & a \\leq b \\land 0 \\leq c \\Rightarrow a \\leq c \\end{array} $ Schreibweise: \\(a \\geq b: \\Leftrightarrow b \\geq a\\) \\(a \\lt b: \\Leftrightarrow a \\leq b \\land a \\neq b\\) \\(a \\gt b: \\Leftrightarrow b \\lt a\\) Alle Regeln fÃ¼r Ungleichungen lassen sich aus A.1 - A.14 herleiten. Diese Regeln seien nun bekannt. Definition : FÃ¼r \\(a \\in \\mathbb{R}\\) sei \\(|a| : = \\left \\{ \\begin{array}{ll} a & \\text{, falls } a \\geq 0 \\\\ -a & \\text{, falls } a \\lt 0 \\end{array} \\right.\\) Anschaulich: Der Betrag misst den absoluten Abstand zur 0 auf dem Zahlenstrahl. \\(|a-b| \\mathrel{\\widehat{=}} \\text{Abstand von a und b}\\) Satz : Seien \\(a, b \\in \\mathbb{R}\\) . Dann: \\(|a| \\geq 0\\) \\(|ab| = |a| \\cdot |b|\\) \\(\\pm a \\leq |a|\\) \\(|a+b| \\leq |a| + |b|\\) : Dreiecksungleichung \\(| |a| - |b| | \\leq | a-b|\\) Beweis : 1, 2, 3 leichte Ãœbung Beweis von 4. : Fall 1: \\(a+b \\geq 0\\) . Dann \\(|a+b| = a + b \\leq |a| + |b|\\) Fall 2: \\(a+b \\lt 0\\) . Dann \\(|a+b| = -(a+b) = (-a) + (-b) \\leq |a| + |b|\\) Beweis von 5. : \\(c := |a| - |b|\\) . Es ist \\(|a| = |a - b + b| \\leq |a - b | + |b| \\Rightarrow |a| - |b| \\leq |a - b|\\) , also \\(c \\leq |a - b|\\) Analog: \\( -c = |b| - |a| \\leq |b-a| = |a - b|\\) . Es ist \\(| |a| - |b| | = c \\text{ oder } = -c\\) . Intervalle Seien \\(a, b \\in \\mathbb{R} \\land a \\lt b\\) . \\((a,b) := \\{x \\in \\mathbb{R} a \\lt x \\lt b\\}\\) : offenes Intervall \\([a,b] := \\{x \\in \\mathbb{R} a \\leq x \\leq b\\}\\) : geschlossenes Intervall \\((a,b] := \\{x \\in \\mathbb{R} a \\lt x \\leq b\\}\\) : halboffenes Intervall \\([a,\\infty) := \\{x \\in \\mathbb{R} a \\leq x \\}\\) . \\((a,\\infty) := \\{x \\in \\mathbb{R} a \\lt x \\}\\) . \\((-\\infty,a]:= \\{x \\in \\mathbb{R} x \\leq a \\}\\) . \\((-\\infty,\\infty):= \\mathbb{R}\\) . \\([a,a]:= \\{a\\}\\) : entartetes Intervall","tags":"German posts","title":"Analysis I - Teil 1"},{"url":"https://martin-thoma.com/create-latex-timetable/","text":"LaTeX is a quite cool document markup language and document preparation system. You can easily create mathematical formulas. Today I've created a LaTeX timetable. Well, to be honest I have only used the timetable package from Pascal Gwosdek found on planetk.de . Here is the LaTeX-Code: \\documentclass [a4paper,10pt] { report } % Definitions \\usepackage { lscape } \\usepackage [height=25cm] { geometry } \\usepackage { timetable } \\begin { document } \\thispagestyle { empty } \\begin { landscape } \\noindent\\printheading { Stundenplan von Martin Thoma - 1. Semester } % Define the layout of your time tables \\setslotsize { 2.8cm }{ 0.3cm } \\setslotcount { 5 } { 40 } \\settopheight { 3 } \\settextframe { 0.8mm } % Retro \\setframetype [t] { 1 } \\seteventcornerradius { 0pt } % Print timestamps into event blocks %\\setprinttimestamps{2} % Define event types \\defineevent { lecture }{ 0.0 } { 0.28 }{ 1.0 } { 1.0 }{ 1.0 }{ 1.0 } \\defineevent { exercise-course } { 1.0 } { 0.4 } { 0.2 } { 1.0 }{ 1.0 }{ 1.0 } \\defineevent { tutorial } { 0.6 } { 0.8 } { 1.0 } { 1.0 }{ 1.0 }{ 1.0 } \\defineevent { langcourse } { 1.0 } { 0.4 } { 0.2 } { 1.0 }{ 1.0 }{ 1.0 } \\defineevent { work } { 0.21 }{ 0.5 } { 0.16 }{ 1.0 }{ 1.0 }{ 1.0 } % Start the time table \\begin { timetable } \\hours { 8 }{ 15 }{ 1 } \\germandays { 1 } \\event 1 { 0945 } { 1115 } { Betriebssysteme } { Bellosa } { 10.23 Nusselt } { lecture } \\event 1 { 1130 } { 1300 } { Wahrscheinlichkeits-theorie } { Hug } { 11.40 Tulla HS } { lecture } \\event 1 { 1400 } { 1530 } { Programmieren } { Pretschner } { 50.35 HS a. F. } { lecture } \\event 1 { 1545 } { 1715 } { LinAlg und Ana } { Leuzinger } { 30.46 Neue Chemie } { exercise-course } \\event 2 { 0800 } { 0930 } { Analysis I } { Schmoeger } { 30.46 Neue Chemie } { lecture } \\event 2 { 0945 } { 1115 } { Betriebssysteme } { Bellosa } { 20.40 HS 37 } { exercise-course } \\event 2 { 1130 } { 1300 } { Theoretische Grundlagen der Informatik } { Wagner } { 30.21 Gerthsen } { lecture } \\event 3 { 0800 } { 0930 } { LinAlg und Analytische Geometrie I } { Leuzinger } { 10.21 Daimler } { lecture } \\event 3 { 1400 } { 1530 } { Grundbegriffe der Informatik } { Schultz } { 50.35 HS a. F. } { lecture } \\event 4 { 0800 } { 0930 } { Analysis I } { Schmoeger } { 30.46 Neue Chemie } { lecture } \\event 4 { 1130 } { 1300 } { Theoretische Grundlagen der Informatik } { Wagner } { 30.21 Gerthsen } { lecture } \\event 5 { 0800 } { 0930 } { LinAlg und Analytische Geometrie I } { Leuzinger } { 11.40 Tulla HS } { lecture } \\event 5 { 0945 } { 1115 } { Grundbegriffe der Informatik } { Schultz } { 50.35 HS a. F. } { exercise-course } \\event 5 { 1545 } { 1715 } { Analysis I } { Schmoeger } { 10.21 Benz } { exercise-course } \\end { timetable } \\end { landscape } \\end { document } Here is the timetable and the example timtable in LaTeX . If you have a Linux machine, you can create the timetable with this command: pdflatex example.tex -output-format = pdf","tags":"Code","title":"Create LaTeX timetable"},{"url":"https://martin-thoma.com/einfuhrung-in-die-stochastik/","text":"In diesem Artikel werde ich ein paar einfache Definitionen, die fÃ¼r die Stochastik wichtig sind, einfÃ¼hren. Basisdefinitionen bei Zufallsexperimenten Was ist ein ideales Zufallsexperiment? Ein ideales Zufallsexperiment sollte gut beschrieben, wiederholbar und mit mehreren mÃ¶glichen AusgÃ¤ngen (also zufÃ¤llig), sein. Die ZufallsgrÃ¶ÃŸe, wie beispielsweise die erwÃ¼rfelte Zahl, nennt man Zufallsvariable . Es gibt auch noch die Statistische Variable . Wo der Unterschied ist, kann ich nicht sagen. Allerdings habe ich auf Wikipedia eine Diskussion geÃ¶ffnet und hoffe auf baldige KlÃ¤rung. Was sind Merkmale? Merkmale sind die AusgÃ¤nge eines Zufallsexperiments. Sie kÃ¶nnen folgendermaÃŸen gegliedert werden: quantitativ (Die ZufallsgrÃ¶ÃŸe(n) haben natÃ¼rlicherweise eine Ordnung) stetig (Es kÃ¶nnen in einem Intervall beliebige Werte angenommen werden, z.B. die GrÃ¶ÃŸe eines Menschen.) diskret (Es kÃ¶nnen nur bestimmte GrÃ¶ÃŸen angenommen werden, z.B. die GrÃ¶ÃŸe eines Menschen in ganzen Zentimetern.) qualitativ (Es gibt keine natÃ¼rliche Ordnung.) ordinal (Es geht um ZahlengrÃ¶ÃŸen, z.B. Noten.) nominal (Etwas vÃ¶llig anderes, z.B. Geschlecht.) Urliste / Stichprobe vom Umfang n: \\(x := (x_1, x_2, ..., x_n)\\) \\(H_x (a_j) := \\text{Anzahl der Stichprobenelemente in x, die gleich} a_j \\text{sind}\\) \\(H_x (a_j)\\) : Absolute HÃ¤ufigkeit \\(h_x(a_j) := \\frac{H_x (a_j)}{n}\\) : Relative HÃ¤ufigkeit Empirische Verteilungsfunktion \\(t \\mapsto \\underbrace{F_x(t)}_{\\text{empirische Verteilungsfunktion}} := \\sum \\limits_{j: a_j \\le t} {h_x (a_j)}, t \\in \\mathbb{R}\\) Eine alternative Definition der empirischen Verteilungsfunktion ist \\(F_x(t) := \\frac{1}{n} \\sum \\limits_{i=1}&#94;n 1 \\{ x_i \\le t \\}\\) Arithmetisches Mittel (\"Durchschnitt\"): \\(\\overline x = \\frac{1}{n} \\sum \\limits_{i=1}&#94;n x_i = \\frac{x_1 + ... + x_n}{n}\\) Welcher Wert liegt in der Mitte? Stichproben-Varianz : \\(s_x&#94;2 := \\frac{1}{n-1} \\sum \\limits_{i = 1}&#94;n (x_i - \\overline x)&#94;2\\) Stichproben-Standardabweichung : \\(s_x := + \\sqrt{s_x&#94;2}\\) Wie stark weichen die Werte von einander ab? Stichproben-Variationskoeffizient : \\(v_x := \\frac{s_x}{\\overline x}\\) Wie groÃŸ ist die Schwankung relativ zum Durchschnitt? Stichproben-Median / Zentralwert : WÃ¼rde mal alle Werte einer Stichprobe sortieren, sollte der Median der Wert in der Mitte sein. Das ist nicht der Durchschnitt! \\(\\tilde x := \\begin{cases} x_{\\frac{n+1}{2}}, & \\mbox{wenn } n \\mbox{ ungerade} \\\\ \\frac{1}{2} (x_\\frac{n}{2} + x_{\\frac{n}{2} + 1}), & \\mbox{wenn } n \\mbox{ gerade} \\end{cases} \\) Quantil : Das Quantil unterteilt die Verteilung der Werte der Zufallsvariablen in zwei Bereiche: Links vom \\(\\alpha\\) -Quantil liegen \\(100 \\cdot p\\) Prozent aller Beobachtungswerte bzw. \\(100 \\cdot p\\) Prozent der Gesamtzahl der Zufallswerte. Rechts davon liegen \\(100 \\cdot (1-p)\\) Prozent aller Beobachtungswerte bzw. \\(100 \\cdot (1-p)\\) Prozent der Gesamtzahl der Zufallswerte. Das Quartil ist das 0,25-Quantil. \\(\\alpha\\) -getrimmtes Stichprobenmittel: \\(\\overline x_\\alpha := \\frac{1}{n-2k} \\cdot (x_{n+1} + ... + x_{n-k})\\) Spezialfall: \\(\\overline x = \\overline x_0\\) Quartilsabstand: \\(\\tilde x_{0,75} - \\tilde x_{0,25}\\) Spannweite: \\(x_n - x_1\\) Visualisierungen Boxplot Weitere VisualisierungsmÃ¶glichkeiten: Punktwolke Streudiagramm AnnÃ¤herungen Durch eine Regressionsanalyse kann man ein Regressionsmodell erstellen. Es legt den Typ einer Regressionsfunktion fest. Eine Regressionsfunktion kann z.B. die Methode der kleinsten Quadrate sein: \\(\\sum \\limits_{j=1}&#94;{n}\\overbrace{(\\underbrace{y_i -a -b \\cdot x_j}_{\\text{Residuum}})&#94;2}&#94;{ \\begin{array}{l} \\text{Damit sich negative positive}\\\\ \\text{Abweichungen nicht gegenseitig}\\\\ \\text{aufheben} \\end{array} }\\) Geradenparameter errechnen Tja, hier hat er die Folien viel zu schnell durchgeschaltet ... ich habe nur folgendes: Regressionsgerade: \\(y = a&#94;* + b&#94;* \\cdot x\\) (eindeutig bestimmbar) \\(b&#94;* = \\frac{\\sum \\limits_{j=1}&#94;n (x_j - \\overline x) (y_j - \\overline y)} {\\sum \\limits_{j = 1}&#94;n (x_j - \\overline x)&#94;2}\\) und \\(a&#94;* = \\overline y - b&#94;* \\cdot \\overline x\\) mit \\(r_{xy} = \\frac{\\frac{1}{n-1} \\sum \\limits_{j=1}&#94;n (x_i - \\overline x)(y_j - \\overline y)} {b_x \\cdot b_y}\\) (Korrelationskoeffizient der Daten) gilt \\(b&#94;* = r_{xy} \\cdot \\frac{s_y}{s_x}\\) Irgendwas war noch mit der Cauchy-Schwarz Ungleichung . Falls jemand Anmerkungen hat, mehr mitgeschrieben hat oder einfach Fragen aufkommen: Postet doch einen Kommentar!","tags":"German posts","title":"EinfÃ¼hrung in die Stochastik"},{"url":"https://martin-thoma.com/password-changing-services/","text":"Today I've changed my PayPal password, because I thought it was time to do so. Now I know that the password changing service of PayPal can be improved quite a lot. I had to type the password about twelve times! This is the reason why I thought it was time to create some principles for good password changing services: User authentication : It is important that only the user can change the password. You have to force the user to type in his old password again. This should be done as a first step in the authentication. Nothing is more frustrating than being forced to type in your old password again and again as your new password wasn't valid. You could check if he typed in his old password less than a minute ago. Eliminate typos : Like every good service, PayPal wants you to type the password and the verification. It would be good, if two symbols were added to the textbox. One for the activation of caps lock and one for num lock . I think this has to be done by the browser. Client-side validation : The first time, I used a password which was considered as weak. A JavaScript informed me that it was weak, but I could submit the form. The form should be validated on the client. If it is not valid, don't let him submit the form. (The password has to be validated also on the server, of course.) Allow all characters : I was very negatively surprised as I was informed that PayPal doesn't allow \"non-printable characters\" like spaces. They informed me after I submitted, of course. It does make sense to warn the user if he uses special characters which might be difficult to type on other systems, like German umlauts (Ã¤Ã¶Ã¼Ã„Ã–ÃœÃŸ). But why the hell do they force me to use underscores instead of spaces? Do they print my password? Do they want that I print my password? Allow \"weak\" passwords : You should not allow weak passwords, of course. But you should have a good definition of weak. Less than 6 characters is weak. I wanted to use a 26-character password with upper- and lower case letters, spaces and one special character. This was considered as weak. If you read my post about MD5 cracking you have probably noticed, that it is much harder to crack a 26-character password with only lower case letters than a 8 character password with lower case, upper case and numbers. About \\(10&#94;{22}\\) times as much passwords are possible with 26 characters and 26 letters than with a character-space of 62 elements but only 8 places (see Wolfram|Alpha ). You can easily build a password if you use a sentence, not a word. This will be long and will quite possibly only have lower case letters, spaces and one upper case letter, but it is possible to remember it. Password Strength Allow long passwords : As the passwords should not be stored as plaintext, but hashed it doesn't really matter how long they are. If you use MD5, it will always take 32 characters. Why should you limit a user to only 20 characters (like PayPal does)? If the 26 character password is easier to remember, why do you want to restrict him to a shorter password which is easier to crack? I made the same annoying experiences with the password of my students account for university. They forced me to use a short password with a lower case and upper case letters, digits and special characters. Do you have some more suggestions for good passwords? Which websites have a very good password changing service?","tags":"The Web","title":"Password Changing Services"},{"url":"https://martin-thoma.com/md5-cracking/","text":"MD5 is a cryptographic hash function. This means, you can give the MD5 algorithm a string and it will return another 32-character long alphanumeric string. The returned string looks quite random, but it isn't. If you use the same input, you always get the same 32 character output. What is it good for? Well, imagine you had a web application. Now an attacker found a security whole and can read the password-column in the database. If it was plain text, he could use the passwords to log into the users accounts. As it is hashed and the hash function can't be simply reverted. So the attacker can't take any advantage of the passwords he just read. It is much more realistic that the attacker can read the whole database. So he can access sensitive user data. As it is very likely that you have some e-mail adresses in there, he could quite probably log into the e-mail accounts of the users with the same password. If the password is hashed, it's not that simple. He has to try to crack the MD5 hashed passwords. I'll describe and test in the following how easy this is and how it could be done. Tested Hashes MD5 is a widely used cryptographic hash function. I wanted to know how easy it is to crack them, so I tested it. I used those passwords: \"computer\": df53ca268240ca76670c8566ee54568a \"establishment\": f469410e5ec7594a9c41603e06ccf6a3 \"My Birthday\": ce9dbd008dac54422b90b3f82f58dd40 \"I'm born in 1990.\": 834649b6298642a7576b10c6705842d8 \"r4Nd0m9\": cc11c3de28e4425eff27b2fb5f216903 Online Crackers If you search for \"md5 cracker\" you find some md5 crackers . This website could crack computer , establishment and My Birthday . The other two hashes weren't cracked. John the Ripper Ubuntu-Users can easily install John the Ripper (sudo apt-get install john) and use it for cracking hashes. To do so, the have to create a file in their working directory (let's call it md5.txt) and execute the following command: john --format = raw-MD5 md5.txt Here is the time, john needed to crack the hashes: \"computer\": 0.521 seconds \"establishment\": after 1 h it wasn't cracked \"My Birthday\": after 5 min it wasn't cracked \"I'm born in 1990.\": after 5 min it wasn't cracked \"r4Nd0m9\": after 38 min it wasn't cracked Okay, these results aren't good. But you can also use a wordlist (e.g. the 15 MB list from http://www.bright-shadows.net/download/downloads.php) and the command john --wordlist:tbswordlist1.txt --format=raw-MD5 md5.txt \"computer\": df53ca268240ca76670c8566ee54568a \"establishment\": 0.568 seconds \"My Birthday\": not cracked \"I'm born in 1990.\": not cracked \"r4Nd0m9\": not cracked","tags":"The Web","title":"MD5 cracking"},{"url":"https://martin-thoma.com/challenge-websites/","text":"Challenge websites are websites which offer many tasks to solve and a ranking system. If you solve the challenges, you get points and your rank increases. You don't get anything else. No money, no price. Only the knowledge and the ranking. Which is enough in my opinion. It might sound strange to others, but its fun to try to find the error in an application or to try to get better than others. The topics could be anything, but most of the time you should exploit a security whole. All Challenge websites I know use categories to organize their challenges. I'll describe some of them later. Why should challenge websites be more famous? Some people think its exciting to get to know the internals of a system. Questions like \"What will happen if I take the absolute value of -2,147,483,648?\" come automatically to their mind. If you are not one of those guys, you might ask yourself \"Why -2147483648? Why not -1234?\". Well, the simple answer is that in almost every programming language integers have 32 bytes. This means, you can store 2&#94;32 values in this variable. As you have negative numbers, only 2&#94;31 for each side. As you have 0, for one side one less. The range of an integer is in most languages -2&#94;31 to +(2&#94;31 -1). So if you take the absolute value of -2&#94;31, you're out of that range. It is much more interesting to get to know what could possibly go wrong in other systems and to show others your punditry than setting up an isolated system and trying to get unexpected results. If you don't know about challenge websites it is quite likely that you will try your knowledge on productive systems. This might result in a real damage. Another reason why challenge websites should get more famous is the moral compass. Even very young children can get an awfully amount of knowledge in computers. They might be able to hack others, but they don't have a feeling for whats wrong and right. If they try their knowledge in on a challenge website, they get a community they can talk to. I guess the administrators will not be happy if they exploit their systems, but if they tell them how to fix it I guess they would not go to the police. (As it is very likely that the attacker didn't really cause any damage like the loss of personal information or shutting down a system for which customers paid for, I think it is very unlikely that they will got to police.). I think it's very likely that they will give the credits for the patch / bug on their site. hacker.org does so, for example. I could also imagine that software companies could be interested in such websites. Wouldn't it be a great idea to post programming challenges and to contact the people who rank high? What are common categories? JavaScript JavaScript password protections are not secure. They are very easy to exploit and the website owner can be sure, that he will not open a real security leak when he creates such a challenge. Some common tasks include: Looking into the source code of the webpage Deactivating JavaScript because you are redirected Understanding JavaScript Exploit Many websites have server side bugs or vulnerabilities. So you can create challenges for \"hackers\" to find and exploit those to get to a hidden page. These exploits could be: SQL injections XSS Missing password protection Code injection Possible rights escalation Cryptography Cryptography is the practice and study of techniques for secure communication in the presence of third parties. This means you know that others will read your messages, but this doesn't mean they have to get to know what it means. They will only see rubbish and hopefully they don't know how to translate it into a meaningful sentence. As cryptography is older than computers you can find very many cryptographical challenges. One of the most common ones is the Caesar cipher . Most ciphers are in at least one of the following categories: Classical Ciphers Substitution Ciphers Transposition Ciphers Block Ciphers Symmetrical Ciphers Asymmetrical Ciphers Steganography Steganography is the art of hiding data. In the case of cryptography, your opponent knows that he has the information. In case of steganography he might think that he has only a nice picture. Did you ever use invisible ink as a child? Congratulations, you have already applied steganography! Some common steganographic challenges are: Looking at the source code of a webpage Looking very exactly at a high resolution image Examining a .gif with multiple layers / a video Playing a sound really slow / fast Playing with the bits of an image CrackIts CrackIts are challenges where you have to change a binary to get the results. Cracks are quite common. Perhaps you know that some illegal versions a very expensive software which can be found online don't need the registration code. They were cracked. Flash / Java Applets It is basically always decompiling and understanding the crappy output. As a reallife-application you could imagine an online game where you want to get into the highscore. Decompile it, look at the place where it gets submitted and submit your wished high score. Programming Programming challenges have a time component. You need to solve a specific instance of a problem in, well, lets say three seconds. Enough time for a computer to connect to the webpage, download the problem, solve it and upload the solution. Most of the time by far not enough to solve it by hand. Logic, Math and Science A classical logic challenge is the riddle of the Sphinx . Another one is Einstein's riddle . I guess you can imagine what a math challenge is? 1 + 1 = x, solve to x would be one. The Impossible Puzzle would be another one. The science challenges are like the homework I had to do in school. Some are very difficult, others are quite easy. But the kind of questions which were very similar to the questions in school. Information Gathering Almost every challenge could also be in the \"Information Gathering\" category. Who doesn't try Google first? (Except if the answer is obvious, of course.) Basic tasks are to get to know something about the owner of a specific website or about the content of a website a few years ago. Some examples www.bright-shadows.net - The Back Sheep hacker.org WeChall ProjectEuler - for people who are interested in math challenges:","tags":"Cyberculture","title":"Challenge Websites"},{"url":"https://martin-thoma.com/when-geeks-become-parents/","text":"It's so funny what happens when Geeks become parents. This is what happens if your dad is a designer: Baby Batman Baby Hulk Hogan Baby Ogre Baby Soldier Baby Vampire The Original (or at least the highest resolution I found) is here as PDF . Giving your child some funny T-shirts is also quite common: Baby Geek: No! (found on zazzle ) It seems like someone liked RPGs here â˜º A friend of mine just shared this photo: Twins: Copy and Paste. Thanks to RenÃ© for sharing Do you have more images or perhaps stories of geeky parents? Please let me know in a comment!","tags":"The Web","title":"When Geeks become Parents"},{"url":"https://martin-thoma.com/game-qwerty-warriors-2/","text":"QWERTY Warriors 2 Go to the Game : QWERTY Warriors 2 on Kongregate Task : Survive as long as possible. How to play : You have to type the enemy-words as fast as possible. Your figure will automatically shoot at them when you type. My Record : 118,486 (Final Score, see below) QWERTY Warriors 2: Score","tags":"The Web","title":"Game: QWERTY Warriors 2"},{"url":"https://martin-thoma.com/order-categories-in-wordpress/","text":"Today, I've introduced a new category: My bits and bytes. I wanted to write something about my kitchen renovation . Additionally, I thing I will write from time to time about other topics than computer related ones. As I looked at my categories, I saw that they were ordered lexicographically. But I called my Blog \"Code, the Web and Cyberculture\", not \"Code, Cyberculture and the Web\". So I had to change it. Luckily, a plugin called Category Orders exists. It works fine with the latest WordPress (3.2.1): WordPress Plugin: Category Orders","tags":"The Web","title":"Order categories in WordPress"},{"url":"https://martin-thoma.com/kitchen-renovation-part-1/","text":"Most of you might know that I am currently a student. Living near the University is quite important for me as I hate traveling long. In the central part of Karlsruhe , the city I study in, most houses are very old. The house I live in was built around 1900 and modernized from time to time. A heater and electricity were added, for example. The flat is shared by students. My hirer told me that he will pay all cost of materials if I wanted to improve something. As a new leaser came and we had no washing machine we thought it was time to renovate the kitchen. The old kitchen Why did I renovate? We needed more space for a new washing machine. The old countertop was ugly, molded and had a water damage. The tap was loose. The tube for hot water was loose. Some photos Old countertop of our kitchen The old countertop Top of the old countertop Plans Kitchen before renovation Kitchen after renovation The renovation Tools I needed quite a lot of tools. I had to buy most of them when I saw that I couldn't continue without them: Drilling machine Plumber wrench Screwdrivers Silicone cartridge Spirit level Wrench Additionally I needed a hammer to get the wall plugs into the wall, some different screws and wall plugs, pliers, some tubes and some O-rings . Photos while working Crooked wall Heating pipes To save some money and to be sure that it really fits, I waited with the renovation until the washing machine was delivered. After it was here I had to move it quite often to get the ledge at it's place. As I removed the old countertop, I saw that a tube was loose. This had to be fixed. So I mounted it to the wall. Adding a working ledge is very important. I simply took some wood which was about the right size (4cm x 1cm) / length (about 1.5m). It gives your countertop the needed stability and you can make sure that it's exactly horizontally. Therefore you should use a spirit level. I drilled a small, long hole in the wall and used long wall plugs / screws. They are about 4cm in the wall. As you don't see those later, it doesn't have to look nice, but it has to be stable. You have to connect both countertops very good. If you don't do so, you will get water in there which will destroy the countertop over time. So we filled the space in between with wood glue and pressed them together with this screw construction. This little metal plate fixates the tap to the countertop. I put it for two days into vinegar to get rid of most of the rust, dirt and chalk. Before I did so, the whole plate was brown. Angle joints fix the countertop to the wall. I used 23 angle joints with 46 screws. Nothing will separate my countertop from the wall :D Removing silicone leftovers is a pretty time intensive work. You can remove a lot with a knife, but if the underground is tender you have to use some chemicals. The chemicals I used are called \"Max Bahr - Silikon Entferner\". It seems to be called \"Caulk Remover\" in English. I had to apply mine with a brush which was in the package. After 10 minutes, I could remove some more of the caulk. If you want to make a clean silicone clogging, you should mask the surrounding area. Adding a baseboard was one of the last steps. This small piece of would should prevent water from touching the wallpaper. Moreover it looks nice â˜º The new kitchen Kitchen after renovation Exact work: It fitted only with a few millimeters left. Good that I added some space to make sure it will fit. If I made the plate exactly as big as it could have been according to my first plan, I would have been in trouble. Conclusion I am proud of the result. The new kitchen looks nice, the countertop is very exact horizontally, no water drips out. Some parts could have been done better (like the silicone clogging), but I guess most could not be much better. The next time I do something like this I will hopefully not have to go about ten times to the hardware store :-/ Now I have some more tools :D","tags":"My bits and bytes","title":"Kitchen renovation - Part 1"},{"url":"https://martin-thoma.com/5-web-technologies-which-should-be-used-more-often/","text":"RSS-Feeds RSS-Feeds Everyone who wants to get informed about updates on websites has to use RSS Feeds. Every time any website you have in your Feed Reader makes an update, you can get instantly a little notice. Its a bit like e-mail, but you have the possibility to stop this service. You can't get spam, as the Feed owner doesn't get an identifier for you. OpenID OpenID It is really annoying to register on every single page you use. The idea behind OpenID is having one account for registering on many domains. If you want to log-in in Blogger, you are sent to Google. You type in your username and password and Google sends you back to Blogger. Here is another explanation: The process seems to be too complex for many users, so Google developed the Google Identity Toolkit (GIT). The technique is really nice, but I don't like the idea that I have to force my users to use Google (or a service of them). Though I use Google for almost everything. Ajax Ajax is a programming style. If you like to view another page or get some information which isn't already loaded, you don't have to reload the whole page. The Pages simply display the new content as soon as it has loaded the content. GMail makes heavy use of Ajax. Hierarchical Labels Well, I guess this is less a technology than an idea. I think it would be great if labels were used more often. I'd like to sort my personal files with labels, not with folders. The advantage of labels in comparison with folders is that you can add any number of labels to one object (file, e-mail, ...). But you can have a file only in one path if you don't copy the file. So you have to know how the person is thinking, if you want to find the file you are searching for. Example: You search for a file about you favorite books. Unfortunately, you don't remember if it was an Excel-file or a Word-file. Now you have this tree structure: Excel Documents School E-mails eBooks Math School Biology Chemistry English Math Word The document you a re searching for could be in Word; in School/English, in Documents/eBooks or in Excel. You you had labels for your files, you could just select the files with a \"Books\"-label. I wrote \"Hierarchical Labels\", because sometimes you have one label, that comes always with another one, but not the other way round. As I am not very interested in chemistry, all files about chemistry were for school. So if I tagged a file with \"chemistry\" it should automatically get the \"school\"-tag. Gravatar-Logo Gravatar Have you ever noticed blogs or other sites where some people have avatars and others don't? Sometimes, if a possibility to login is provided this is not really amazing. But where does the website get the pictures from if there is no possibility to log in? Gravatar (an abbreviation for globally recognized avatar) is a service for providing globally-unique avatars. This is good for any website, where you don't have the possibility to store large amounts of data or you don't want to be annoyed with different file types, resizing and users who can't manage to use your software. Here is a web service, that allows you to quickly see the Gravatars of one e-mail address. Links for developers OpenID libraries Working with Gravatar Howto Create an RSS 2.0 Feed","tags":"The Web","title":"5 Web Technologies which should be used more often"},{"url":"https://martin-thoma.com/clip-what-light/","text":"","tags":"The Web","title":"Clip: What Light"},{"url":"https://martin-thoma.com/comparing-dates-in-php-and-mysql/","text":"Sometimes you need to know compare PHP dates. You need to know what is later or if both dates are the same. PHP time formats and functions PHP knows these time / date formats: UNIX Timestamp: Integer - The number of seconds after 1970. Related functions are int mktime([ int \\$hour = date(\"H\") [, int \\$minute = date(\"i\") [, int \\$second = date(\"s\") [, int \\$month = date(\"n\") [, int \\$day = date(\"j\") [, int \\$year = date(\"Y\") [, int \\$is_dst = -1 ]]]]]]]) int time() string date( string \\$format [, int $timestamp = time() ] ) int strtotime( string \\$time [, int \\$now ] ) I recommend using YYYY-MM-DD HH:mm:ss if possible. Associative Arrays. The array looks like this Array ( [year] => 2006 [month] => 12 [day] => 12 [hour] => 10 [minute] => 0 [second] => 0 [fraction] => 0.5 [warning_count] => 0 [warnings] => Array() [error_count] => 0 [errors] => Array() [is_localtime] => ) The related functions are: array date_parse (string $date) array getdate ([ int $timestamp = time() ] ) DateTime Class : This class can do quite a lot. You should read the manual if you're interested in using it. Comparisons Comparing UNIX Timestamps is like comparing integers. No problem. Comparing Arrays is more interesting. What do you think will the following script print? <?php $d1 = date_parse ( \"2011-05-11\" ); $d2 = date_parse ( \"2011-05-11 13:00:00\" ); print_r ( $d1 ); print_r ( $d2 ); if ( $d1 < $d2 ) { echo '$d1 is less than $d2.' ; } else if ( $d1 == $d2 ) { echo '$d1 is equal to $d2.' ; } else { echo '$d1 is greater than $d2.' ; } ?> It prints '$d1 is less than $d2.' as date_parse (\"2011-05-11\"); is basically the same as date_parse (\"2011-05-11 00:00:00\"); You can compare the Array to an integer, but I don't know what PHP does. It seems as if the array would always be considered as being greater. If you use the functions you'll be fine. MySQL time formats and functions MySQL knows these date and time types and those functions . Here is a very short overview: DATETIME : 'YYYY-MM-DD HH:MM:SS' range is from '1000-01-01 00:00:00' to '9999-12-31 23:59:59' DATE : 'YYYY-MM-DD' range is from '1000-01-01' to '9999-12-31' TIMESTAMP : like DATETIME, but range is from '1970-01-01 00:00:01' UTC to '2038-01-19 03:14:07' UTC Those examples show more than a long explanation: mysql> SELECT CURTIME () ; -> '23:50:26' # Adding zero will NOT convert it to a UNIX timestamp: mysql> SELECT CURTIME () + 0 ; -> 235026 .000000 # An \"integered\" TIME mysql> SELECT NOW ( ) -> '2011-10-04 18:33:45' # Adding zero is a bad idea here, too: mysql> SELECT NOW ( ) +0 -> 20111004190945 .000000 # An \"integered\" DATETIME # If you want a UNIX Timestamp, use this function mysql> SELECT UNIX_TIMESTAMP () ; -> 1317746025 mysql> SELECT UNIX_TIMESTAMP ( '2011-10-04 18:33:45' ) ; -> 1317746025 # You can also convert it: mysql> SELECT UNIX_TIMESTAMP ( ` my_datetime_row ` ) FROM ` my_table ` Comparisons You can compare two DATETIMEs like this: SELECT ` my_row ` FROM ` my_table ` WHEN ` datetime1 ` < ` datetime2 ` It's of course not problem if you compare two UNIX Timestamps which are stored as integers in the database: SELECT ` my_row ` FROM ` my_table ` WHEN ` int1 ` < ` int2 ` But what happens if you compare a DATETIME with a Timestamp (integer)? SELECT ` my_row ` FROM ` my_table ` WHEN ` datetime1 ` < UNIX_TIMESTAMP () This is basically: SELECT ` my_row ` FROM ` my_table ` WHEN ` datetime1 ` < 1317750167 And it compares the \"integered\" DATETIME 20111004210710 for 2011-10-04 21:07:10 with 1317750167. This is obviously crap. Don't do it. Never. Instead you should convert your dates with UNIX_TIMESTAMP(your_datetime) or FROM_UNIXTIME(unix_timestamp). Comparing MySQL types with PHP types The simplest way to compare MySQL DATE formats with PHP types is using strtotime(...) or date(...) if needed. If you have a DATETIME and you want to know if it's in the past, you can use if (strtotime($datetime) < time()) { echo '$datetime is in the past.'; } From PHP to MySQL If you have a date you got via an date input field and want to submit it to MySQL, just use this piece of code: $mysqlFormat = date('Y-m-d H:i:s', strtotime($_POST['my_date']));","tags":"Code","title":"Comparing Dates in PHP and MySQL"},{"url":"https://martin-thoma.com/motion-of-the-sun/","text":"How is the sun moving, according to our latitude, the time of the day and the time of the year? Just take a look at astro.unl.edu and find it out! Motions of the sun","tags":"The Web","title":"Motion of the sun"},{"url":"https://martin-thoma.com/compare-planet-sizes/","text":"The diameter of Mercury measures about 4880 km. Can you imagine how much that is? I could not. But with www.sciencenetlinks.com you can compare it with the earth: Planet Size Comparison By the way, if you are interested in the universe, you should go to a planetarium . You can search the next one with maps.google.com . In Augsburg (Germany) it costs less than going to a 3D-cinema, but the movie showen in the planetarium is in 3D.","tags":"The Web","title":"Compare Planet Sizes"},{"url":"https://martin-thoma.com/game-z-type/","text":"Z-Type Go to the Game : www.phoboslab.org/ztype Task : Survive as long as possible How to play : Type the words which appear at the top as fast as possible. The ship shoots at the words. My Record : Final Score: 1505 with Accuracy of 94.2% Programming : This game is written in JavaScript with Impact .","tags":"The Web","title":"Game: Z-Type"},{"url":"https://martin-thoma.com/facepalm/","text":"With the Internet came a lot of new words. Cyberculture could be one of them, Googling or Hacktivism would be others. Did you know that the famous gesture of Piccard is called a Facepalm ? Piccard Facepalm The same word seems to exist also in German, so I'm quite sure that the word is new. (Although the Duden doesn't know it.) Although the gesture itself is obviously old: Cain by Henri Vidal, in the Tuileries Gardens, Paris, 1896","tags":"Cyberculture","title":"Facepalm"},{"url":"https://martin-thoma.com/if-computer-problems-were-real/","text":"Before the computer ... ... a memory was something you've lost with age ... an application was for employment ... a program was a TV show ... a cursor used profanity ... a keyboard was a piano ... a web was a spiders home ... a virus was the flue ... a CD was a bank account ... a hard drive was a long trip on the road ... a mouse pad was where a mouse lived ... a tree, leaf and root could be found in nature ... a path was wa way and if you had a 3,5 inch floppy... ... you hoped nobody found out. If you like this kind of humor, you might want to watch this video: Thanks to Javier Benek for the picture .","tags":"Cyberculture","title":"If Computer Problems Were Real"},{"url":"https://martin-thoma.com/colorize-your-scripts-output/","text":"The bash is very nice if you want to know exactly what your scripts are doing. Unfortunately, its almost always white colored text on a black background, without any accentuation. No bold text, nothing underlined and no colors are used. You can change this standard behaviour. You can add color to your output. This is the way you do it: The mini-program tput can initialize a terminal or query terminfo database. If you want to know more about it, you can take a look at the tput manpage . A quick example # Text color variables txtred = $( tput setaf 1 ) # Red txtreset = $( tput sgr0 ) # Reset your text echo \"Roses are ${ txtred } red ${ txtreset } .\" Simply copy this example line by line and then you'll see the expected example. A shorter way would be echo \"Roses are `tput setaf 1`red`tput sgr0`.\" The sgr attribuge tput sgr 0 1 turn off standout ; turn on underline tput sgr 0 0 turn off standout ; turn off underline tput sgr 1 1 turn on standout ; turn on underline tput sgr 1 0 turn on standout ; turn off underline tput sgr0 short for sgr 0 0 The setaf attribute setaf 1 Red setaf 2 Green setaf 3 Yellow setaf 4 Blue setaf 5 Purple setaf 6 Cyan setaf 7 Gray Misc Make your text bold: tput bold Reset your style: tput sgr0 Advanced Example Imagine you had a script which generated much output. All messages are important for you, but some are more important than others. You definitely want to see all \"[ERROR]\" output. So you want to apply a red and bold modification to the stream. This is the way how \"[ERROR]\" gets red and bold: ` tput setaf 1 `` tput bold ` [ ERROR ] ` tput sgr0 ` You can test it with echo \"`tput setaf 1``tput bold`[ERROR]`tput sgr0`\" I've created a little python script called output.py for testing purposes. It simply outputs a quite long Lorem ipsum text with some random [ERROR] messages. The next task is to replace the [ERROR] messages. The tool of my choice is sed. See the sed man page for more information. The basic usage is sed 's/search/replace/' So we pipe the output to sed: python output.py | sed 's/$$ERROR$$/MYLOOOOOOOOOOOOOOOOOONGTEST/' And now we bring it all together: python output.py | sed 's/[ERROR]/`tput setaf 1``tput bold`[ERROR]`tput sgr0`/' Doesn't work? Well, lets analyse it. Instead of replacing tput setaf 1 it gets printed directly. This means, something we did prevented the bash of replacing our command. If you look carefully at the command, you might see that I used ' instead of \". If you change this, everything is fine: python output.py | sed \"s/ $$ ERROR $$ /`tput setaf 1``tput bold`[ERROR]`tput sgr0`/\" Colorize C / C++ output You need ANSI color codes : #include <stdio.h> int main () { printf ( \" \\\\ 033[30m%s \\\\ 033[0m \\n \" , \"black?\" ); printf ( \" \\\\ 033[31m%s \\\\ 033[0m \\n \" , \"red\" ); printf ( \" \\\\ 033[32m%s \\\\ 033[0m \\n \" , \"lime\" ); printf ( \" \\\\ 033[33m%s \\\\ 033[0m \\n \" , \"yellow\" ); printf ( \" \\\\ 033[34m%s \\\\ 033[0m \\n \" , \"blue\" ); printf ( \" \\\\ 033[35m%s \\\\ 033[0m \\n \" , \"gray\" ); printf ( \" \\\\ 033[36m%s \\\\ 033[0m \\n \" , \"blue\" ); printf ( \" \\\\ 033[37m%s \\\\ 033[0m \\n \" , \"light gray\" ); printf ( \" \\\\ 033[38m%s \\\\ 033[0m \\n \" , \"black?\" ); printf ( \" \\\\ 033[39m%s \\\\ 033[0m \\n \" , \"black?\" ); printf ( \" \\\\ 033[41m%s \\\\ 033[0m \\n \" , \"red background\" ); printf ( \" \\\\ 033[1;34m%s \\\\ 033[0m \\n \" , \"bold and blue\" ); printf ( \" \\\\ 033[4m%s \\\\ 033[0m \\n \" , \"underlined\" ); printf ( \" \\\\ 033[9m%s \\\\ 033[0m \\n \" , \"strike\" ); return 0 ; } \\033 is the ASCII 27 ESC character. It has to be followed by \"[\". After that you can write one or two numbers separated by \";\". Then you have to write \"m\". You can get back to standard output with \"\\033[0m\". The numbers 30â€“37 change the color, 4 is a single underline. I guess these will also work for Java, but I didn't test it. Do you know what setaf or sgr stand for? Do you know further \"terminal enhancement\" tricks? Just leave a post!","tags":"Code","title":"Colorize your scripts output"},{"url":"https://martin-thoma.com/captcha/","text":"Spam is really a problem if you have a WordPress blog, a forum or a guestbook. A very common approach to solve this problem are CAPTCHAs - C ompletely A utomated P ublic T uring test to tell C omputers and H umans A part. The idea behind CAPTCHAs is to give the spammer a problem which is hard to solve for a computer program but easy to solve for a human. Most CAPTCHAs are really boring. I tried to find different categories of them, but most you will find online are in the \"Optical character recognition\" category: Optical character recognition Web Wiz CAPTCHA I hope nobody seriously pays the 6 Euro for Web Wiz . As many very simple CAPTCHAs it lacks a support for blind people. It is quite easy to read for humans, but I guess also for bots. They always use only five random characters which are written in blue. They added some dots and straight lines to make segmentation more difficult. I guess they never tried to hack their own CAPTCHA. If they did, they should be aware that those small dots don't change anything and the straight lines can easily be detected and removed. It also seems to me as if they only used one font. Google did some great work with reCAPTCHA . I think I'll write a longer post about this later, but to keep it short: They use the reader (or spammer) to digitalize the books they scan. So if someone uses very good algorithms to bypass their CAPTCHA, the spammer will help Google. This is a very nice way to end up in a win-win situation, isn't it? reCAPTCHA has also support for blind people. The characters you have to type in are actual words. This makes it a lot easier for humans to recognize the characters. reCAPTCHA is very easy to use. No need of GD or ImageMagick . If you can't read it, just reload it. Here is a screenshot of reCAPTCHA: reCAPTCHA Here is another \"traditional\" CAPTCHA example. SimpleCaptcha KittenAuth I have never seen a working demo of KittenAuth , but the idea is simple: You get 9 pictures and you're supposed to spot the cats: The KittenAuth system. Source: ThePCSpy.com Very simmiliar is ASIRRA : ASIRRA Basic human knowledge Another CAPTCHA-type is based on basic human knowledge. Text CAPTCHA is an example for this type. They ask you questions like: Which of milk, hotel or brain is a body part? How many letters in \"devotional\"? The word \"tamers\" has which letter in 2nd position? Enter the smallest number of 28, thirteen, twenty, 60, fifty six or 78: Which of knee, leg, ear or ankle is above the waist? I don't think this type is very good as the spammer has to do almost the same amount of work as the programmer. He has to parse the different types of questions, but I guess this isn't too hard. He might just ask Google: what is 7 minus 3 times 2? or what is the number of horns on a unicorn times the answer to life, the universe, and everything? . egglue - Egglue Semantic CAPTCHA Mathematics I've seen some CAPTCHAs asking for very basic math questions like the following one. They are very easy to bypass if you want to write a bot: CAPTCHA - Basic mathematics ( example ) Sometimes they are not that easy: Rosocosmos CAPTCHA - Found on hubpages.com Hard math CAPTCHA - found on random.irb.hr Social CAPTCHA I've just found Facebooks social CAPTCHA. I didn't read the article . I guess the idea is that you know the name of your friends, but a stranger doesn't. I had the same idea for a school website where you would have been forced to know the name of the teachers. Here is the example: Social CAPTCHA PLAYTHRU To get through this CAPTCHA, you have to play a short game. PLAYTHRU PLAYTHROU You can get PLAYTHRU here. Further reading Fun: xkcd: A New CAPTCHA Approach 24 WTF Captchas 25 Very Naughty Facebook Captchas Free CAPTCHA systems: reCAPTCHA : I recommend this one. cool php captcha Fight with Spam: 15+ Free Captcha Solutions Breaking or creating CAPTCHAs: How to break captchas PWNtcha Strong CAPTCHA Guidelines","tags":"The Web","title":"CAPTCHA"},{"url":"https://martin-thoma.com/shortfilms/","text":"Here is the second part \" Shortfilms, Part II \". Turbo TURBO is a high adrenaline short film in the tradition of The Karate Kid and Tron. It tells the story of Hugo Park ( Justin Chon , Twilight) a troubled youth whose only outlet for angst is a 4D fighting video game called \"Super Turbo Arena\". When Pharaoh King ( Jocko Sims , Crash the Series), the Michael Jordan of cyber-sports, announces a tournament to determine who will join his pro-team, Hugo sets his eyes on the prize. But, Hugo isn't the only gamer who wants fame and glory. If Hugo wants to win he's going to have to beat Shamus (David Lehre, Epic Movie), the all time Turbo champ at the local Pandemonium arcade, and Ruse Kapri, a feisty prep girl that knows how to win. Realizing he can't win on his skill alone, Hugo turns to his brother Tobias a former kick-boxer whose last match left him wheel-chair ridden. Together the two will mend old wounds and see if a washed up street fighter can teach a troubled teen how to become a virtual gladiator! Here is the imdb-entry . The Raven THE RAVEN Chris Black possesses a power that could lead to the destruction of the current regime, and they will stop at nothing to destroy him. The chase is on as Chris runs for his life in this sci-fi thriller set in an alternate and futuristic Los Angeles. Here is the imdb-entry . The Cat Piano Here is the imdb-entry . The Ghastly Gourmet Cooking Show Who do you call when there's a catering catastrophe? The Ghastly Gourmet team of course! Chip, Chop and Chunk are three beastly little chefs who can make a meal of (and out of) any situation, no matter how monstrous the request. It's a gleefully gross cooking show not for the feint hearted or weak stomached! Karma Currency - Charity Gift Vouchers Sebastian's Voodoo A voodoo doll must find the courage to save his friends from being pinned to death. On Time A traveling salesman selling the future in his suitcase.","tags":"The Web","title":"Shortfilms"},{"url":"https://martin-thoma.com/10-great-videos-on-vimeo/","text":"Vimeo is a video-sharing website like YouTube. The most obvious difference is the quality. Vimeo has over 3 million members. About 16,000 new videos get uploaded daily. Roughly 10% of all uploads are in HD. Here are 10 Great Videos I've found on Vimeo: Ben Goldacre: Bad Science Thought of You Captain Awesome The Saga of Biorn The Blackwater Gospel Aurora Borealis Iceland, EyjafjallajÃ¶kull Rabbitkadabra! Eye Of The Storm Salesman Pete","tags":"The Web","title":"10 Great Videos on Vimeo"},{"url":"https://martin-thoma.com/lolcats-hermes-favorite-activity/","text":"Cats are sometimes so crazy. This cat obviously loves being thrown on a bed. Have fun with the Lolcat-Clip:","tags":"Cyberculture","title":"Lolcats: Hermes'' Favorite Activity"},{"url":"https://martin-thoma.com/game-winterbells/","text":"Go to the Game : www.ferryhalim.com Task : Jump at as many bells / pigeons with your arctic hare as possible How to play : The arctic hare jumps automatically. You choose the direction in which he jumps / flies with your mouse. My Record : 44,960 If you thought that was good, just watch this video:","tags":"The Web","title":"Game: Winterbells"},{"url":"https://martin-thoma.com/game-lightbot-20/","text":"Lightbot 2.0 Go to the Game : Lightbot 2.0 on Kongregate Task : Solve the levels How to play : You can programm the Lightbot to move, jump and to switch its light on. By defining functions and using recursion you can keep your program code small. It's a nice online game where you can start to learn programming. My Record : All Basic and Recursion-Levels done.","tags":"The Web","title":"Game: Lightbot 2.0"},{"url":"https://martin-thoma.com/using-wikipedia-as-a-newssstream/","text":"I am very interested in the development of Google+. As I am also quite active on Wikipedia (just take a look at my edit counter ) I add all topics in which I am interested in to my personal watchlist. I added the RSS-Feed to my feed reader. So I get instantly a little pop-up as soon as the article changes. Great. ... if there wouldn't be so many reverts / minor edits. Most edits I get informed of are either bot-edits (The article is now available in Tiáº¿ng Viá»‡t! Fantastic!) or simply reverted after a few hours. I'm searching for a tool which reads my feed and generates a new feed. This new feed should contain only messages when relevant changes were made. Does something like this already exist? Does somebody want to invent such a web service? At the moment I don't have the time to do it myself, so I tagged this post with \"idea\". If you're searching for an idea for a new project, just take a look at those topics.","tags":"The Web","title":"Using Wikipedia as a Newssstream"},{"url":"https://martin-thoma.com/joke-electrical-engineering-vs-computer-science/","text":"Nerd-Crossing I've just stumbled upon this joke on wilk4.com . This is the reason why I didn't use OOP in any of my (small) projects and why I don't understand those people who want every piece of code in OOP-style: Once upon a time, in a kingdom not far from here, a king summoned two of his advisors for a test. He showed them both a shiny metal box with two slots in the top, a control knob, and a lever. \"What do you think this is?\" One advisor, an engineer , answered first. \"It is a toaster,\" he said. The king asked, \"How would you design an embedded computer for it?\" The engineer replied, \"Using a four-bit microcontroller, I would write a simple program that reads the darkness knob and quantizes its position to one of 16 shades of darkness, from snow white to coal black. The program would use that darkness level as the index to a 16-element table of initial timer values. Then it would turn on the heating elements and start the timer with the initial value selected from the table. At the end of the time delay, it would turn off the heat and pop up the toast. Come back next week, and I'll show you a working prototype.\" The second advisor, a computer scientist , immediately recognized the danger of such short-sighted thinking. He said, \"Toasters don't just turn bread into toast, they are also used to warm frozen waffles. What you see before you is really a breakfast food cooker. As the subjects of your kingdom become more sophisticated, they will demand more capabilities. They will need a breakfast food cooker that can also cook sausage, fry bacon, and make scrambled eggs. A toaster that only makes toast will soon be obsolete. If we don't look to the future, we will have to completely redesign the toaster in just a few years.\" \"With this in mind, we can formulate a more intelligent solution to the problem. First, create a class of breakfast foods. Specialize this class into subclasses: grains, pork, and poultry. The specialization process should be repeated with grains divided into toast, muffins, pancakes, and waffles; pork divided into sausage, links, and bacon; and poultry divided into scrambled eggs, hard- boiled eggs, poached eggs, fried eggs, and various omelet classes.\" \"The ham and cheese omelet class is worth special attention because it must inherit characteristics from the pork, dairy, and poultry classes. Thus, we see that the problem cannot be properly solved without multiple inheritance. At run time, the program must create the proper object and send a message to the object that says, 'Cook yourself.' The semantics of this message depend, of course, on the kind of object, so they have a different meaning to a piece of toast than to scrambled eggs.\" \"Reviewing the process so far, we see that the analysis phase has revealed that the primary requirement is to cook any kind of breakfast food. In the design phase, we have discovered some derived requirements. Specifically, we need an object-oriented language with multiple inheritance. Of course, users don't want the eggs to get cold while the bacon is frying, so concurrent processing is required, too.\" \"We must not forget the user interface. The lever that lowers the food lacks versatility, and the darkness knob is confusing. Users won't buy the product unless it has a user-friendly, graphical interface. When the breakfast cooker is plugged in, users should see a cowboy boot on the screen. Users click on it, and the message 'Booting UNIX v.8.3' appears on the screen. (UNIX 8.3 should be out by the time the product gets to the market.) Users can pull down a menu and click on the foods they want to cook.\" \"Having made the wise decision of specifying the software first in the design phase, all that remains is to pick an adequate hardware platform for the implementation phase. An Intel 80386 with 8MB of memory, a 30MB hard disk, and a VGA monitor should be sufficient. If you select a multitasking, object oriented language that supports multiple inheritance and has a built-in GUI, writing the program will be a snap. (Imagine the difficulty we would have had if we had foolishly allowed a hardware-first design strategy to lock us into a four-bit microcontroller!).\" The king wisely had the computer scientist beheaded, and they all lived happily ever after.","tags":"Code","title":"Joke: Electrical Engineering vs. Computer Science"},{"url":"https://martin-thoma.com/google-ngram-viewer/","text":"On October 14, 2010 Google announced that the number of scanned books is over 15 million. They did not simply scan those books, but they digitalized them. They can access not only image files, but the actual text. This allows Google to search in those books and to analyze the information. Google has processed 1,024,908,267,229 words of running text and is publishing the counts for all 1,176,470,663 five-word sequences that appear at least 40 times. One five-word-sequence would be a five-gram, a four-word-sequence a four-gram. Google has published the Ngram Viewer. This is a tool which allows the user to specify some Ngrams and search how often they appear over the years. Here is an example search: Google Ngram Viewer: Germany vs France The x-axis shows the years, the y-axis shows the percentage of the specified ngram of all ngrams. Don't bother with the numbers. If one curve is higher than the other, more books contained the specified Ngram. My example shows that the term \"France\" was more often in books than \"Germany\". Why is this the case? My first thought was that in the time of the two world wars more books should have been written about Germany. The answer is simply that I wrote \"germany\" instead of \"Germany\". So it's case sensitive: Google Ngram Viewer: Germany vs. France vs. Third-Reich You can compare how successful some books are: Google Ngram Viewer: Harry Potter vs. Lord of the Rings vs. The Da Vinci Code Quite interesting is also the interest in famous physicists: Google Ngram Viewer: Famous physicists You can try all sort of things: Google Ngram Viewer: Happy Did you get some interesting results? Please post a link! Sources Google Books . Received 24 September 2011. All Our N-gram are Belong to You . Received 24 September 2011. Video: What we learned from 5 million books .","tags":"The Web","title":"Google Ngram Viewer"},{"url":"https://martin-thoma.com/python-check-wiki-references-for-citation-template/","text":"Wikipedia articles are full of references. Those references should be formatted the same way. It is much easier to use a template for citations than trying to guess the right way how to cite. Unfortunately most Wikipedia users don't know the Template:Citation . So I try to fix all manual styled citations when I edit an article. Doing this manually is quite time intensive. This is the reason why I wrote a little Python-script. Examples < ref > [http://peter.mapledesign.co.uk/weblog/archives/python-is-slow Python is... slow?] December 21st, 2004 &mdash; Peter Bowyer &rsquo; s weblog] </ ref > should be < ref > {{Citation |url=http://peter.mapledesign.co.uk/weblog/archives/python-is-slow |title=Python is... slow? |accessdate=September 24, 2011}} </ ref > < ref > [http://www.nongnu.org/pydbc/ Contracts for Python], PyDBC </ ref > should be < ref > {{Citation |url=http://www.nongnu.org/pydbc/ |title=Contracts for Python |accessdate=September 24, 2011}} </ ref > So, all that has to be done is Finding all -Tags without a template in one article Trying to find the URL of this reference Filling out as much as possible for the user Asking the user for missing information Returning the new article wiki source code Downloading wiki source code Wikipedia offers an API for accessing the needed information. I will use this API and Pythons optparse , BeautifulSoup and HTMLParser to get the raw wiki text in UTF-8 encoding: #!/usr/bin/python # -*- coding: utf-8 -*- import urllib2 from optparse import OptionParser from BeautifulSoup import BeautifulStoneSoup import HTMLParser parser = OptionParser () parser . add_option ( \"-l\" , \"--lemma\" , dest = \"lemma\" , default = \"Python\" , type = \"string\" , help = \"Which lemma should be checked?\" ) parser . add_option ( \"-m\" , \"--language\" , dest = \"language\" , default = \"en\" , type = \"string\" , help = \"Which langauge should be used \" + \"(english wiki, geman wiki, ... )\" ) parser . add_option ( \"-v\" , \"--verbose\" , action = \"store_true\" , dest = \"verbose\" , default = False , help = \"Show more information.\" ) ( options , args ) = parser . parse_args () def load ( lemma , language = \"en\" , format = \"xml\" ): \"\"\" Get the Wikipedia Source Text (not the HTML source code) format:xml,json, ... language:en, de, ... Returns None if page doesn't exist \"\"\" lemma = lemma . replace ( \" \" , \"_\" ) url = 'http://' + language + '.wikipedia.org/w/api.php' + \\ '?action=query&format=' + format + \\ '&prop=revisions&rvprop=content' + \\ '&titles=' + lemma request = urllib2 . Request ( url ) handle = urllib2 . urlopen ( request ) text = handle . read () if format == 'xml' : soup = BeautifulStoneSoup ( text ) rev = soup . rev if rev != None : text = unicode ( rev . contents [ 0 ]) text = HTMLParser . HTMLParser () . unescape ( text ) text = text . encode ( \"utf-8\" ) else : return None return text We are now able to access the needed information. Now we need to get the references without templates. To do so, I will use the Python re module : import re def getRef ( page ): \"\"\" Get all references without templates \"\"\" pattern = \"(<ref>\\[.+?</ref>)\" prog = re . compile ( pattern ) m = re . findall ( pattern , page ) return m Now the single references have to get parsed and the user has to confirm or edit the results: import readline from datetime import date def rlinput ( prompt , prefill = '' ): \"\"\" Promt the user for input, but prefill it. \"\"\" readline . set_startup_hook ( lambda : readline . insert_text ( prefill )) try : return raw_input ( prompt ) finally : readline . set_startup_hook () def improve ( references , page ): \"\"\" Try to guess the right formatation for each reference and ask the user to confirm or edit the formatation of the reference. \"\"\" urlPattern = \"http.+? \" urlPatternCompiled = re . compile ( urlPattern ) today = date . today () accessdate = str ( today . strftime ( \"%B %d , %Y\" )) for refOld in references : url = re . findall ( urlPatternCompiled , refOld ) refNew = \"<ref>{{Citation \" + \\ \"|url=\" + str ( url [ 0 ]) + \\ \"|title= \" + \\ \"|accessdate=\" + accessdate + \\ \"}}</ref>\" refNew = rlinput ( refOld + \" (old): \\n \" , refNew ) page = page . replace ( refOld , refNew ) print \"\" return page Here is the full script: #!/usr/bin/python # -*- coding: utf-8 -*- import urllib2 from optparse import OptionParser from BeautifulSoup import BeautifulStoneSoup import HTMLParser import re import readline from datetime import date parser = OptionParser () parser . add_option ( \"-l\" , \"--lemma\" , dest = \"lemma\" , default = \"Python\" , type = \"string\" , help = \"Which lemma should be checked?\" ) parser . add_option ( \"-f\" , \"--file\" , dest = \"filename\" , help = \"write corrected wiki source code to FILE\" , metavar = \"FILE\" , default = \"wikioutput.txt\" ) parser . add_option ( \"-m\" , \"--language\" , dest = \"language\" , default = \"en\" , type = \"string\" , help = \"Which langauge should be used \" + \"(english wiki, geman wiki, ... )\" ) parser . add_option ( \"-v\" , \"--verbose\" , action = \"store_true\" , dest = \"verbose\" , default = False , help = \"Show more information.\" ) ( options , args ) = parser . parse_args () def load ( lemma , language = \"en\" , format = \"xml\" ): \"\"\" Get the Wikipedia Source Text (not the HTML source code) format:xml,json, ... language:en, de, ... Returns None if page doesn't exist \"\"\" lemma = lemma . replace ( \" \" , \"_\" ) url = 'http://' + language + '.wikipedia.org/w/api.php' + \\ '?action=query&format=' + format + \\ '&prop=revisions&rvprop=content' + \\ '&titles=' + lemma request = urllib2 . Request ( url ) handle = urllib2 . urlopen ( request ) text = handle . read () if format == 'xml' : soup = BeautifulStoneSoup ( text ) rev = soup . rev if rev != None : text = unicode ( rev . contents [ 0 ]) text = HTMLParser . HTMLParser () . unescape ( text ) text = text . encode ( \"utf-8\" ) else : return None return text def getRef ( page ): \"\"\" Get all references without templates \"\"\" pattern = \"(<ref>\\[.+?</ref>)\" prog = re . compile ( pattern ) m = re . findall ( prog , page ) return m def rlinput ( prompt , prefill = '' ): \"\"\" Promt the user for input, but prefill it. \"\"\" readline . set_startup_hook ( lambda : readline . insert_text ( prefill )) try : return raw_input ( prompt ) finally : readline . set_startup_hook () def improve ( references , page ): \"\"\" Try to guess the right formatation for each reference and ask the user to confirm or edit the formatation of the reference. \"\"\" urlPattern = \"http.+? \" urlPatternCompiled = re . compile ( urlPattern ) today = date . today () accessdate = str ( today . strftime ( \"%B %d , %Y\" )) for refOld in references : url = re . findall ( urlPatternCompiled , refOld ) refNew = \"<ref>{{Citation \" + \\ \"|url=\" + str ( url [ 0 ]) + \\ \"|title= \" + \\ \"|accessdate=\" + accessdate + \\ \"}}</ref>\" refNew = rlinput ( refOld + \" (old): \\n \" , refNew ) page = page . replace ( refOld , refNew ) print \"\" return page if __name__ == '__main__' : print ( \"If you need more parameters like 'date': \" + \\ \"http://en.wikipedia.org/wiki/Template:Citation#\" + \\ \"Full_citation_parameters\" ) page = load ( options . lemma ) references = getRef ( page ) page = improve ( references , page ) f = open ( options . filename , 'w' ) f . write ( page ) f . close () print ( \"Page has been written to %s .\" % options . filename ) This can be improved in several ways: Checking automatically the title / dead links Trying to find the publication date automatically Skip links with Templade:Dead link Search also for Text Here is the Wikipedia diff page . My little script seems to work.","tags":"Code","title":"Python: Check Wiki-references for citation template"},{"url":"https://martin-thoma.com/php-pear-mdb2/","text":"PEAR is short for P HP E xtension and A pplication R epository. It provides a very easy method to get some common classes. PEAR MDB2 is a database class. It is a successor of PEAR DB. I took a look at version 1.4.1 which is currently the latest stable one. Install PEAR You can install PEAR on Ubuntu via sudo apt-get install php-pear You can check if it is installed with phpinfo() : <?php phpinfo (); ?> Something like .:/usr/share/php:/usr/share/pear should be in your include_path . Install PEAR MDB2 PEAR MDB2 is then simply installed via sudo pear install MDB2 Then install the optional MySQL package: sudo pear install pear/MDB2#mysql Usage I took a small chess database to test this package. You can set it up with this sql file . It's sad, but only including MDB2.php shows 5 \"Deprecated\"-messages and 6 warings because of \"Strict Standards\". You can easily connect to the database: require_once \"MDB2.php\"; $db = new MDB2(); $dsn = \"mysql://chessuser:localpass@localhost/chess\"; $mdb2 = MDB2::factory($dsn); $mdb2->setFetchMode(MDB2_FETCHMODE_ASSOC); It is also very easy to fetch some data: $sql = 'SELECT * FROM `chess_users`'; $result = $mdb2->query($sql); while ($row = $result->fetchRow()) { print_r($row); } or $sql = 'SELECT * FROM `chess_users`'; $data = $mdb2->queryAll($sql); print_r($data); This results in: Array ( [user_id] => 1 [user_name] => abc [user_password] => 900150983cd24fb0d6963f7d28e17f72 [currentchesssoftware] => 0 ) Array ( [user_id] => 2 [user_name] => test [user_password] => 098f6bcd4621d373cade4e832627b4f6 [currentchesssoftware] => 0 ) You can set limits via MDB2: $sql = 'SELECT * FROM `chess_users`'; $mdb2->setLimit(1); $data = $mdb2->queryAll($sql); print_r($data); MDB2 offers lots of other features like choosing a (non)persistent connection, prepared statements or debuggin option. If you're interested in PEAR MDB2 I recommend to take a look at installationwiki.org. Sources PEAR . Received 24 September 2011. PEAR MDB2 . Received 24 September 2011. MDB2 on installationwiki.org. Received 24 September 2011.","tags":"Code","title":"PHP: PEAR MDB2"},{"url":"https://martin-thoma.com/data-visualization/","text":"The United States public debt increased from \\ \\(10.7 trillion in 2008 to \\\\) 14.2 trillion by February 2011. Google processes about 24 petabytes of data per day. About 21.9 people live in Mumbai. Today it is incredibly easy to gain raw data, but without context they aren't worth anything. You have to know some different information of the same context with which you can compare the given information. If I told you that 24 petabytes equals approximately 1,600 years of a high quality video you can get a feeling for the information. This can be done even better if you use graphical elements. Here are two great examples of data visualization. David McCandless Hans Rosling Sources and further reading Gapminder : A tool for data visualization. United States public debt. Received 23 September 2011. MapReduce. Portal.acm.org. Retrieved 16 August 2009. Mumbai. Received 23 September 2009.","tags":"The Web","title":"Data Visualization"},{"url":"https://martin-thoma.com/cleverbot-vs-wolframalpha/","text":"Cleverbot is an AI web application. You can chat with it and it tries to guess a good answer. This can be quite funny. I was curious how Cleverbot would answer when I compared it to Wolfram|Alpha , a useful answering engine. Here are two of my conversations: Cleverbot Cleverbot This Cleverbot isn't very clever... Did you get some funny chats? Please post a link to a screenshot of your chat! edit: I just found this video. Too funny â˜º","tags":"Cyberculture","title":"Cleverbot vs. Wolfram|Alpha"},{"url":"https://martin-thoma.com/getting-hardware-information-in-ubuntu/","text":"I'm using Ubuntu now for many years, but I always have to look the commands for retrieving hardware information up. Now I will not Google any longer but search in my own little cheat sheet. I guess most commands will work in every Linux distribution, but I tried it only in Ubuntu 10.04LTS. Maybe you need to install some packages. If you know more commands, please post a comment! CPU cat /proc/cpuinfo processor : 0 vendor_id : GenuineIntel cpu family : 6 model : 23 model name : Pentium ( R ) Dual-Core CPU T4500 @ 2 .30GHz stepping : 10 cpu MHz : 1200 .000 cache size : 1024 KB physical id : 0 siblings : 2 core id : 0 cpu cores : 2 apicid : 0 initial apicid : 0 fdiv_bug : no hlt_bug : no f00f_bug : no coma_bug : no fpu : yes fpu_exception : yes cpuid level : 13 wp : yes flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe nx lm constant_tsc arch_perfmon pebs bts aperfmperf pni dtes64 monitor ds_cpl est tm2 ssse3 cx16 xtpr pdcm xsave lahf_lm bogomips : 4588 .23 clflush size : 64 cache_alignment : 64 address sizes : 36 bits physical, 48 bits virtual power management: processor : 1 vendor_id : GenuineIntel cpu family : 6 model : 23 model name : Pentium ( R ) Dual-Core CPU T4500 @ 2 .30GHz stepping : 10 cpu MHz : 1200 .000 cache size : 1024 KB physical id : 0 siblings : 2 core id : 1 cpu cores : 2 apicid : 1 initial apicid : 1 fdiv_bug : no hlt_bug : no f00f_bug : no coma_bug : no fpu : yes fpu_exception : yes cpuid level : 13 wp : yes flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe nx lm constant_tsc arch_perfmon pebs bts aperfmperf pni dtes64 monitor ds_cpl est tm2 ssse3 cx16 xtpr pdcm xsave lahf_lm bogomips : 4588 .44 clflush size : 64 cache_alignment : 64 address sizes : 36 bits physical, 48 bits virtual power management: RAM free total used free shared buffers cached Mem: 4047112 1712724 2334388 0 94328 744808 -/+ buffers/cache: 873588 3173524 Swap: 8864760 0 8864760 Graphic card lspci | grep VGA 00 :02.0 VGA compatible controller: Intel Corporation Mobile 4 Series Chipset Integrated Graphics Controller ( rev 07 ) And some more details: lspci -s 00 :02.0 -v 00 :02.0 VGA compatible controller: Intel Corporation Mobile 4 Series Chipset Integrated Graphics Controller ( rev 07 ) Subsystem: Acer Incorporated [ ALI ] Device 048a Flags: bus master, fast devsel, latency 0 , IRQ 29 Memory at d0000000 ( 64 -bit, non-prefetchable ) [ size = 4M ] Memory at c0000000 ( 64 -bit, prefetchable ) [ size = 256M ] I/O ports at 4110 [ size = 8 ] Capabilities: <access denied> Kernel driver in use: i915 Kernel modules: i915 Audio Chipset lspci | grep Audio 00 :1b.0 Audio device: Intel Corporation 82801I ( ICH9 Family ) HD Audio Controller ( rev 03 ) And some more details: lspci -s 00 :1b.0 -v 00 :1b.0 Audio device: Intel Corporation 82801I ( ICH9 Family ) HD Audio Controller ( rev 03 ) Subsystem: Acer Incorporated [ ALI ] Device 048a Flags: bus master, fast devsel, latency 0 , IRQ 22 Memory at d6700000 ( 64 -bit, non-prefetchable ) [ size = 16K ] Capabilities: <access denied> Kernel driver in use: HDA Intel Kernel modules: snd-hda-intel Network Chipset lspci | grep Network 04 :00.0 Network controller: Atheros Communications Inc. AR9287 Wireless Network Adapter ( rev 01 ) Then get some more information: lspci -s 04 :00 -v 04 :00.0 Network controller: Atheros Communications Inc. AR9287 Wireless Network Adapter ( rev 01 ) Subsystem: Foxconn International, Inc. Device e034 Flags: bus master, fast devsel, latency 0 , IRQ 17 Memory at d4600000 ( 64 -bit, non-prefetchable ) [ size = 64K ] Capabilities: <access denied> Kernel driver in use: ath9k Kernel modules: ath9k Monitor The packages ddcprobe or xresprobe will help. Hard disk df -H Dateisystem Gr & ouml ;& szlig ; e Benut Verf Ben% Eingeh & auml ; ngt auf /dev/sda1 307G 28G 264G 10 % / none 2 ,1G 320k 2 ,1G 1 % /dev none 2 ,1G 934k 2 ,1G 1 % /dev/shm none 2 ,1G 209k 2 ,1G 1 % /var/run none 2 ,1G 0 2 ,1G 0 % /var/lock none 2 ,1G 0 2 ,1G 0 % /lib/init/rw","tags":"Code","title":"Getting Hardware Information in Ubuntu"},{"url":"https://martin-thoma.com/benchmarking-php/","text":"I used ApacheBenchmark ( ab ) to make a few Benchmark tests I was interested in. If you like to view some more, go to www.phpbench.com . The most important options are: -n: Number of requests to perform -c: Number of multiple requests to make An empty file: moose@pc07:~$ ab localhost/empty.php This is ApacheBench, Version 2 .3 & amp ; lt ; $Revision : 655654 $ & amp ; gt ; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking localhost ( be patient ) .....done Server Software: Apache/2.2.14 Server Hostname: localhost Server Port: 80 Document Path: /empty.php Document Length: 0 bytes Concurrency Level: 1 Time taken for tests: 0 .002 seconds Complete requests: 1 Failed requests: 0 Write errors: 0 Total transferred: 210 bytes HTML transferred: 0 bytes Requests per second: 461 .04 [ #/sec] (mean) Time per request: 2 .169 [ ms ] ( mean ) Time per request: 2 .169 [ ms ] ( mean, across all concurrent requests ) Transfer rate: 94 .55 [ Kbytes/sec ] received Connection Times ( ms ) min mean [ +/-sd ] median max Connect: 0 0 0 .0 0 0 Processing: 2 2 0 .0 2 2 Waiting: 0 0 0 .0 0 0 Total: 2 2 0 .0 2 2 Now I make 1000 requests to this empty file: ab -n 1000 -c 1 localhost/empty.php Time per request: 1.158 [ms] (mean) With a document of two bytes, I get 1.324 ms. A HTML-Document with 300 kB has 4.287 ms. Now I'll begin the test I'm interested in. It is related to this Stackoverflow Question . I'll make 10000 requests per Benchmark: for($i=0; $i<5; $i++) { $maximum = max( @count($MyArray[$i*7]), @count($MyArray[$i*7+1]), @count($MyArray[$i*7+2]), @count($MyArray[$i*7+3]), @count($MyArray[$i*7+4]), @count($MyArray[$i*7+5]), @count($MyArray[$i*7+6]) ); echo $maximum.' '; } 1.817 ms for($i=0; $i<5; $i++) { $chunk = array_intersect_key($MyArray, array($i*7=>1, $i*7+1=>2, $i*7+2=>3, $i*7+3=>4, $i*7+4=>5, $i*7+5=>6)); if(count($chunk) > 0){$maximum = max(array_map('count', $chunk));} else {$maximum = 0;} echo $maximum.' '; } 1.801 ms for($i=0;$i<5;$i++){ $arr = array(); for ($j=0;$j<=6;$j++) { if (isset($MyArray[$i*7+$j])) $arr[] = count($MyArray[$i*7+$j]); else {$arr[] = 0;} } $maximum = max($arr); echo $maximum.' '; } 1.742 ms","tags":"Code","title":"Benchmarking PHP"},{"url":"https://martin-thoma.com/funny-commercials/","text":"Those commercials are so funny! I have never seen commercials which are that funny in TV. Did you? Although I know some good IKEA commercials, I have never heard of most of the other companies. Enjoy the clips! Dirt Devil Berlitz Nando's IKEA - Tidy Up Ameriquest Don't judge too fast! Optician CPS Kellogs RWE After a lot of criticism in Germany for beein environmental unfriendly because of operating nuclear power plants, RWE seems to have created this commercial: Other Blogposts 30 Most Brilliant and Creative Condom Ads","tags":"The Web","title":"Funny Commercials"},{"url":"https://martin-thoma.com/browser-wars/","text":"The Usage of different browser verions is very interesting for me. Internet Explorer 6 causes many problems in Webdesign as it doesn't handle CSS and HTML as it should. This might be the reason why many Webdesigners want IE6 to die . (Before I forget it: Thanks to jeffmcneill for sharing this image as CC BY-SA.) As Google has stopped to support Internet Explorer 6 I hope the decline of its usage will speed up. Here are two cool websites, that track browser versions: IE6 Countdown IE6 Countdown Stat Counter Source: StatCounter Global Stats - Browser Version Market Share See also Browser Wars Usage share of web browsers Comparison of web browsers Mozilla Firefox Google Chrome Opera","tags":"The Web","title":"Browser Wars"},{"url":"https://martin-thoma.com/converting-files-with-linux/","text":"The following tips work under a Linux terminal and were tested with Ubuntu 10.04 LTS. I guess they will also work with other systems, as the programs are available for them. If you know some further file conversions, please let me know. I am also very interested in Web based conversions. PDF Convert a folder of PDF slides into text files of the same name. This is nice for using grep : $ for file in *.pdf ; do pdftotext \" $file \" ; done Convert PS to PDF with ghostscript ( source ): $ ps2pdf input.ps output.pdf Merge multiple PDFs into one ( source ) $ pdfunite in-1.pdf in-2.pdf in-n.pdf out.pdf pdf2jpg : Imagemagick does the trick $ convert -density 300 in.pdf -quality 90 out.jpg Image Files If you want to change image files via terminal, ImageMagick is a good choice. Resize Images to a maximum resolution convert \"OldPicture.jpg\" -resize 1600x1600 \"NewPicture.jpg\" You can also do this for a whole folder. Just go into that folder and: for i in *.jpg ; do convert $i -resize 1600x1600 $i ; done In case you have just taken many photos of a document and you want to send it as a single PDF via email. That's the way to go: for i in *.JPG ; do convert $i -resize 1200x1200 $i ; done ; convert *.JPG merged.pdf Create a Black-and-white picture and compress it $ djpeg \"OldPicture.jpg\" | ppmtopgm | cjpeg -qual 70 > \"NewPicture.jpg\" webp2png : First install webp , then $ dwebp OldPicture.webp -o NewPicture.png png2webp : First install webp , then $ cwebp OldPicture.png -o NewPicture.webp Rename Pictures : $ rename -n & rsquo ; s/ \\. jpg$/ \\. JPG/ & rsquo ; *.jpg Animations to series of images Note that you might have to adjust the %02d if your animation has more than 100 frames (two digits): $ convert -coalesce animated.gif single-image-%02d.png Audio Files Give all mp3 songs the same sound level (it's called Audio normalization ): $ mp3gain -a *.mp3 Merge many audio files to one : $ mp3wrap merged.mp3 one.mp3 two.mp3 Convert all .wav-files in one folder two .mp3-files and remove the *.wav-files : $ for i in *.wav ; do lame \" $i \" \" ${ i %wav } mp3\" ; rm \" $i \" ; done Minimize file size : $ lame -b 32 input.mp3 output.mp3 Split MP3 by silence : $ mp3splt -s -p th = -40,min = 3 ,rm input.mp3 Parameters (thank you, Victor !): -s : silence mode -p : specify arguments for the silence mode th : threshold level in dB to be considered silence min : minimum number of seconds to be considered as splitpoint rm : remove silence from splitted files Split MP3 by time : $ mp3splt input.mp3 -t 10 .00 splits the mp3 after every MM.SS , in this case after every 10 minutes and 0 seconds. So a 53 minutes MP3 would get splitted 5 times and hence result in 6 new files. Video Files For quite a lot purposes is the command line tool FFmpeg with its lots of options a good choice. For others might MEncoder be better. You might also want to install some codecs first: $ sudo apt-get install libavcodec-extra-52 libavdevice-extra-52 libavformat-extra-52 libavutil-extra-50 libpostproc-extra-51 libswscale-extra-0 libavcodec-unstripped-52 ubuntu-restricted-extras Merge many video files to one : $ cat One.mpg Two.mpg Three.mpg | ffmpeg -f mpeg -i - -vcodec copy -acodec copy \"Merged.mpg\" avi2mpg : $ ffmpeg -i \"Original.avi\" \"New.mpg\" mp42mpg : $ ffmpeg -i \"Original.mp4\" -target ntsc-vcd \"New.mpg\" mp42mp3 : $ ffmpeg -i Original.mp4 -f mp3 -ab 192000 -vn New.mp3 mod2avi : ? mts2avi ( MTS format info ): $ ffmpeg -i 00008 .MTS -acodec copy -vcodec libx264 -crf 21 -r 30000 /1001 -deinterlace -y -threads 0 output_file.avi vcd2avi : $ mencoder vcd://2 -o \"New.avi\" -oac copy -ovc lavc -lavcopts vcodec = mpeg4:vbitrate = 2000 ogv2avi : $ mencoder \"Original.ogv\" -ovc xvid -oac mp3lame -xvidencopts pass = 1 -o \"New.avi\" wmv2mpg : aspect=16/9 should eventually be changed to 4/3 or other aspects $ mencoder -of avi -ofps 25 \\ -oac mp3lame -lameopts cbr:br = 112 :aq = 3 :mode = 0 :vol = 0 \\ -vf hqdn3d,softskip,harddup \\ -ovc xvid \\ -xvidencopts bitrate = 501 :max_key_interval = 37 :aspect = 16 /9:turbo:nochroma_me:notrellis:max_bframes = 0 :vhq = 0 \\ Original.wmv \\ -o New.avi mkv2avi : $ mencoder \"Original.mkv\" -ovc lavc -lavcopts vcodec = mpeg4:vhq:vbitrate = 6000 -oac mp3lame -lameopts vbr = 3 -o \"New.avi\" Converting Flash Videos flv to mpg You might want to get the information of the video first: $ ffmpeg -i inputVideo.flv This is how you convert it: $ ffmpeg -i inputVideo.flv -acodec libmp3lame -ab 64k -s 320x240 -r 24 outputVideo.mpg -i input file -acodec audio codec -ab audio bitrate -s size -r fps where fps is the frame rate in Hz. The default value is 25Hz. Converting Flash Videos flv to avi $ ffmpeg -i inputVideo.flv -sameq -ab 128k outputVideo.avi Shortcuts for Linux Console I convert svg2png or pdf2png quite often for my articles. So I've created a command. You can create a command in Linux very easy: Enter echo $PATH in your console Go to /usr/bin or any other path in your PATH Create a file with the name of your command (e.g. svg2png) Fill the fill (see below for some examples). Make it executable: chmod +x svg2png My svg2png looks like this: #!/usr/bin/env python # -*- coding: utf-8 -*- import argparse parser = argparse . ArgumentParser ( description = \"convert a svg file to png\" ) parser . add_argument ( \"-i\" , \"--input\" , dest = \"input\" , help = \"read svg file\" , metavar = \"FILE\" ) parser . add_argument ( \"-o\" , \"--output\" , dest = \"output\" , help = \"output png file\" , metavar = \"FILE\" ) parser . add_argument ( \"-w\" , \"--width\" , dest = \"width\" , default = 512 , type = int , help = \"width of output png\" ) args = parser . parse_args () import os command = \"inkscape \" + args . input + \\ \" -w \" + str ( args . width ) + \" --export-png=\" + args . output os . system ( command ) print ( \"Executed command: \" + command ) My pdf2png looks like this: #!/usr/bin/env python # -*- coding: utf-8 -*- import argparse parser = argparse . ArgumentParser ( description = \"convert a svg file to png\" ) parser . add_argument ( \"-i\" , \"--input\" , dest = \"input\" , help = \"read svg file\" , metavar = \"FILE\" ) parser . add_argument ( \"-o\" , \"--output\" , dest = \"output\" , help = \"output png file\" , metavar = \"FILE\" ) parser . add_argument ( \"-w\" , \"--width\" , dest = \"width\" , default = 512 , type = int , help = \"width of output png\" ) args = parser . parse_args () import os commands = [] commands . append ( \"pdf2svg \" + args . input + \" ~\" + args . input + \".svg\" ) commands . append ( \"inkscape ~\" + args . input + \".svg --export-plain-svg=~\" + args . input + \".svg\" ) commands . append ( \"svg2png -i ~\" + args . input + \".svg -o \" + args . output + \" -w \" + str ( args . width )) commands . append ( \"rm ~\" + args . input + \".svg\" ) for command in commands : os . system ( command ) print ( \"Executed command: \" + command ) args = parser . parse_args ()","tags":"Code","title":"Converting Files with Linux"},{"url":"https://martin-thoma.com/tricks-with-htaccess/","text":"If your Website is running on an Apache2 Webserver, you can change the behavior of this server with .htaccess-files. Here are some examples: Enable htaccess-files Set AllowOverride to \"All\": sudo gedit /etc/apache2/sites-available/default Restart Apache: sudo /etc/init.d/apache2 reload Enable ExpiresOn / mod_rewrite This is for Ubuntu: sudo a2enmod rewrite expires sudo /etc/init.d/apache2 restart Prevent or allow directory listing Add the following line to your .htaccess-file to allow directory listing: Options +Indexes Add the following line to your .htaccess-file to prevent directory listing: Options -Indexes Prevent Hot Linking RewriteEngine on RewriteCond % { HTTP_REFERER } !&#94;$ RewriteCond % { HTTP_REFERER } !&#94;http:// ( www. ) ?your-domain.com/.*$ [ NC ] RewriteRule \\. ( gif | jpe?g | png ) $ - [ F ] Prevent Direct Access If you include some files with PHP, you might want that others can't access this file directly. So add the following to your .htaccess-file: <FilesMatch \"\\.(inc)\\.(php) $ \" > Order deny,allow Deny from all </FilesMatch> <FilesMatch \"\\.(tpl) $ \" > Order deny,allow Deny from all </FilesMatch>","tags":"Code","title":"Tricks with .htaccess"},{"url":"https://martin-thoma.com/ingenious-autocomplete/","text":"Did you notice some strange autocomplete-results? Keep in mind that Google gets those suggestions by other searches. They don't employ someone who tries to guess what you mean. So many others have searched for the term which is suggested. Here are some I've tested: Some nations: If you really like to know, you should go to Wikipedia . They have an article about Obesity in the United States . I thought obesity would be a serious problem in Germany , too. According to Wikipedia, Germany is only on rank 43 of the fattest nations. You can even find an article called \" Epidemiology of obesity \". I've heard of this in How I Met Your Mother . Some systems: Apache is one of the most common webservers. And many others: You don't search for Chuck Norris, Chuck Norris finds you! I hope you have seen Terminator. Otherwise, you don't know Skynet . Google Autocomplete: I hate it when ...","tags":"Cyberculture","title":"Ingenious Autocomplete"},{"url":"https://martin-thoma.com/epic-translation-fails/","text":"Online translation programs are getting better and they are great if you want to get a vague idea of the content of a Chinese website. Never the less you should know that the translations are not good enough by now: \"Spielzeugladen\" is German and means \"toy store\" Note the missing point. \"Was hast du an?\" means \"What do you wear?\" Did you know the Beatbox? Type \"pv zk pv pv zk pv zk zk pv pv pv zk pv zk zk pzk pzk pvzkpkzvpvzk kkkkkk bsch\", translate from German to German and listen to it: Here you can listen to the translation-song:","tags":"Cyberculture","title":"Epic Translation Fails"},{"url":"https://martin-thoma.com/8-animal-memes-in-cyberculture/","text":"Animals are quite often in some web memes: Lame Pun Coon Lame Pun Coon Philosoraptor Philosoraptor Lolcat Kung Fu Bear Ize knowz kung fu! Paranoid Parrot Paranoid Parrot Socially Awkward Penguin Socially Awkward Penguin Bachelor Frog Foul Bachelor Frog Courage Wolf Courage Wolf vs. Zombies Do you know more? Do you know some better ones of the described ones? Please, post a comment!","tags":"Cyberculture","title":"8 Animal Memes in Cyberculture"},{"url":"https://martin-thoma.com/animator-vs-animation/","text":"An animator faces his own animation in deadly combat. The battlefield? The Flash interface itself. A stick figure is created by an animator with the intent to torture. The stick figure drawn by the animator will be using everything he can find - the brush tool, the eraser tool - to get back at his tormentor. It's resourcefulness versus power. Who will win? You can find out yourself. The Original Animator vs. Animation is from Alan Becker on Deviantart .","tags":"Cyberculture","title":"Animator vs. Animation"},{"url":"https://martin-thoma.com/5-online-comic-websites/","text":"All of those Websites offer one small comic strip each day. Some of them are a bit geeky, so you might not understand them if you don't know anything about Linux / D&D. xkcd xkcd hijinks ensue www.hijinksensue.com Penny Arcade www.penny-arcade.com/comic The Perry Bible Fellowship Comics www.pbfcomics.com Realm of Atland www.realmofatland.com","tags":"Cyberculture","title":"5 Online Comic Websites"},{"url":"https://martin-thoma.com/freaky-wikipedia-articles/","text":"Wikipedia has a lot of articles (> 3.7 million). Sometimes, people have funny ideas for redirections / new articles : Pitbull with Lipstick - redirected to Sarah Palin The belief that a cosmic jewish zombie who was his own father can make you live forever if you symbolically eat his flesh and telepathically tell him you accept him as your master, so he can remove an evil force from your soul that is present in humanity( Source ) - Was a Redirect to Christianity 22.86 Centimetre Nails was a redirect to Nine Inch Nails . Comment: Trent Reznor is not likely to go metric any time soon. :D Recursive categories - joke page which subcategorized itself Nooooooooooooooooooooooooooooooooooooooooooooooo[... 200 more ...]ooooooo - a redirect to Darth Vader","tags":"Cyberculture","title":"Freaky Wikipedia Articles"},{"url":"https://martin-thoma.com/setting-up-wordpress/","text":"This article is about creating a new WordPress blog. This includes installing and basic customization. You need to know how how to upload files and how your MySQL database credentials. I used almost the same setup and I will update this post if I make some bad experiences with it. Requirements Minimum Webserver with: MySQL 5.0 or higher PHP 5.2.4 or higher 10 MB free space Any possibility to upload files Recommended The mod_rewrite Apache module. An FTP-Client (e.g. FileZilla) Installation Download the latest version from wordpress.org Decompress it and submit it to your Webserver. It should be directly in your working directory. Example: Use www.martin-thoma.com, not www.martin-thoma.com/wordpress/ Run the installation setup Fill in your database information (database name, host, database user, database password) Store wp-config.php in your WordPress-Folder. Make the most basic configuration of your blog (give it a title, create the admin account) Plugins Akismet : Protect your blog from spam. Don't forget to add your API Key. Sociable : A little, customizable link bar with icons to share the post on social networks. I miss Google+ â˜¹ SyntaxHighlighter Evolved : A syntax highlighter. Absolutely necessary, if you want to write about code. If you don't write about code, you don't need it. Twitter Tools : a plugin that creates a complete integration between your WordPress blog and your Twitter account. WordPress SEO by Yoast : XML-Sitemap, binding for Google/Bing Webmaster Tools WP-Piwik : Piwik is an OpenSource alternative to Google Analytics. You can get some information about your readers. Download the latest Piwik-Version here and install it on your Website. Don't forget to add your Auth token. Configuration Add the categories you want. Go to Posts â†’ Categories Set your default category. Go to Settings â†’ Writing Delete the \"Hello World!\" post. Delete \"Sample\" page. Set a default category in Settings â†’ Writing. Then delete the category \"Uncategorized\". Set up a custom theme. You can find free ones on wordpress.org/extend/themes . Use Permalinks . I use /%postname%/ as I want short URLs. Another plus of this URL is that the URL never changes. Finetuning www or non-www-URL : decide if you want www.martin-thoma.com or martin-thoma.com as your standard URL. Both should work, but one should redirect the user to the other. I choose to take martin-thoma.com as I like short URLs. Add this to your .htaccess if you want www.martin-thoma.com: RewriteEngine on RewriteCond % { HTTP_HOST } !&#94;www.martin-thoma.com$ RewriteRule &#94; ( .* ) $ http://www.martin-thoma.com/ $1 [ R = 301 ] Imprint : In Germany, you have to create an imprint. Even if you don't have to create one, I strongly recommend giving your readers the possibility to get to know who writes the posts. It gives you more credibility. Piwik Piwik Login â†’ Geolocation tab â†’ follow the instructions Sources and further reading Using Permalinks - Structure Tags. Retrieved 17 September 2011. SEO for WordPress â€“ The Complete Guide. Retrieved 17 September 2011.","tags":"The Web","title":"Setting up WordPress"},{"url":"https://martin-thoma.com/polyglots-crazy-programming-stuff/","text":"Have you ever heard of polyglots? This is so crazy. A polyglot is a program which can be interpreted as many programming languages. You don't believe me that something crazy like that is possible? Here is an example I've made: See public gist , as Jekyll keeps crashing with this. You can download the file at martin-thoma.com/python/polyglot.py . I used three languages in this piece of code: Python , Brainfuck and Whitespace . You can try it with ideone.com . But please, copy the whole code! It might be considered as cheating to use comments as often as I did and using two esoteric programming languages. Whitespace works only with whitespaces (space, tab) and Brainfuck needs only +-.;<>[]. Everything else is interpreted as a comment. When I have much more freetime and I don't know what to do, I'll probably write some code with a more interesting output and which is not that obvious.","tags":"Code","title":"Polyglots - Crazy Programming Stuff"},{"url":"https://martin-thoma.com/imprint/","text":"Martin Thoma ParkstraÃŸe 17 76131 Karlsruhe mail: info@martin-thoma.de Verantwortlicher fÃ¼r die Inhalte des Angebots ist Martin Thoma.","tags":"German posts","title":"Imprint"},{"url":"https://martin-thoma.com/author/martin-thoma/","text":"Martin Thoma My name is Martin Thoma . I am a 26 year old student from Karlsruhe, Germany . Do you want to know more about me? I've created a short English CV and a longer German CV . Other Profiles Science: ORCiD , arxiv and Shortscience , dblp Websites: martin-thoma.de Social: Google+ and Twitter StackOverflow linkedin Wikipedia ( de , en , commons and more languages on wikipedia.org) Paypal If somebody claims to be me, but the profile is not linked here, don't trust him/her/it.","tags":"My bits and bytes","title":"About Martin Thoma"}]}