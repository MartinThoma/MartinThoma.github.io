---
layout: post
title: Natural Language Processing
slug: nlp
author: Martin Thoma
date: 2017-05-24 20:00
category: Machine Learning
tags: Machine Learning, NLP
featured_image: logos/ml.png
---
Natural language processing (NLP) is a scientific field which deals with
language in textual form.

Tasks in NLP are:

* **Classification**:
    * Is an e-mail spam or not?
    * Topic: Is it about sports, science or religion?
    * Language: Is it English, German or French?
    * Sentence boundary: Is a character the boundary of a sentence or not?
* [**Named Entity Recognition**](https://en.wikipedia.org/wiki/Named-entity_recognition) (NER): Parse a text
  into names of places, people, organizations and non-names.
* **Machine Translation** (MT): Given a text in language A, return the same content in language B.
* **Text generation**: Generate text in a given style.
* **Similarity calculation**: Given a corpus of n texts and one text A as
  input, find passages of the corpus which are similar to passages of A. This
  can be used to detect if students copied content / copyright violation.
    * Minimum Edit Distance
* **Spelling correction**: Find places where the grammar / writing needs to be
  fixed.
* **Sentiment analysis**: Find out how users feel about something.
* **Word sense disambiguation**: If "mouse" is in a sentence, is it about the
  computer mouse or the animal.
* **POS Tagging**: Detect adjectives, verbs, nouns in a sentence.
* **Summarization** / **Paraphrasing**
* **Information extraction**: For example, find the date in a calender
  application when the user enters the name of the event.
* **Compound splitting**: For German, "Donaudampfschiffskapitän" can be split
  into the compounds "Donau" (a river) "dampfschiff" (steam boat) and "kapitän"
  (captain).


Data sources are:

* Twitter
* Wikipedia
* News websites
* Amazon Reviews


Typical libraries are:

* [**NLTK**](http://www.nltk.org/): The natural language toolkit. Written in Python, for Python. ([Book](http://www.nltk.org/book/ch01.html))
* [SpaCy](https://spacy.io/): According to [reddit](https://www.reddit.com/r/LanguageTechnology/comments/69xbkc/question_spacy_or_nltk/), it is cleaner than NLTK but less complete.
* [TextBlob](https://textblob.readthedocs.io/en/dev/): A simple to start
  toolkit for Python.
* CoreNLP: Faster than NLTK (source?), written in Java, Python wrappers available
* [gensim](https://radimrehurek.com/gensim/): topic modeling and document similarity analysis
* [fasttext](https://github.com/facebookresearch/fastText): a classifier on top of a sentence2vec model
* DeepText: an NLP engine
* Tensorflow
    * [syntaxnet](https://github.com/tensorflow/models/tree/master/syntaxnet) and Parsey McParseface ([paper](https://arxiv.org/pdf/1603.06042v1.pdf))

Well-known products are

* [aspell](https://github.com/GNUAspell/aspell)
* [Google n-gram Viewer](https://books.google.com/ngrams)
* [Google Translate](https://translate.google.com/)
* Quora: [Duplication detection](https://www.kaggle.com/c/quora-question-pairs)
* [IBM Watson](https://en.wikipedia.org/wiki/Watson_(computer))

## Corpora

<table class="table">
    <tr>
        <th>Name</th>
        <th>Tokens</th>
        <th>Types</th>
    </tr>
    <tr>
        <td>Switchboard phone conversations</td>
        <td class="text-right">2&thinsp;400&thinsp;000</td>
        <td class="text-right">20&thinsp;000</td>
    </tr>
    <tr>
        <td>Shakespeare</td>
        <td class="text-right">884&thinsp;000</td>
        <td class="text-right">31&thinsp;000</td>
    </tr>
    <tr>
        <td>Google N-Grams</td>
        <td class="text-right">1&thinsp;000&thinsp;000&thinsp;000&thinsp;000</td>
        <td class="text-right">13&thinsp;000&thinsp;000</td>
    </tr>
</table>


## Terminology / Methods

* n-gram model: Model language by counting word-tuples of length n.
* word2vec: Embedd any word in a (high-dimensional) vector space. Allows vector arithmetic.
* sentence2vec: Similar to word2vec.
* Stemming: Bring a word in a normed form (the stem). Mostly for verbs.
* Viterbi Algorithm
* Naive Bayes
* Maxent classifiers
* Statistical parsing
* Regular expressions (see [regexpal.com](http://regexpal.com/) to test)
* Lexer: One type of tokenizer
* Tokenizer: Splits a text into tokens.
* Tokenization: Segment the text into tokens.
* Fragment: A part of a word (e.g. if you transcribe spoken text and somebody stutters)
* Filled pauses: "uh" in English or "ähm" in German
* Lemma: Two words belong to the same lemma if they have the same stem, belong
  to the same POS and have the same meaning.
* Porters Algorithm


More might me in [my ML Glossary](https://martin-thoma.com/ml-glossary/).

## Resources

* Reddit: [/r/LanguageTechnology](https://www.reddit.com/r/LanguageTechnology/)
* StackExchange: [datascience.stackexchange.com](https://datascience.stackexchange.com/questions/tagged/nlp)
* Online Courses:
    * Coursera: [Introduction to Natural Language Processing](https://www.coursera.org/learn/natural-language-processing)
    * Stanford: [Natural Language Processing with Deep Learning](http://web.stanford.edu/class/cs224n/)
    * Dan Jurafsky and Chris Manning on YouTube: [Stanford NLP](https://www.youtube.com/watch?v=nfoudtpBV68&list=PL6397E4B26D00A269)
    * Oxford: [Lecture Notes](https://github.com/oxford-cs-deepnlp-2017/lectures)
    * [Machine Translation](http://mt-class.org/)