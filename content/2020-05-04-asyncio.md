---
layout: post
title: asyncio
slug: asyncio
author: Martin Thoma
date: 2020-05-04 20:00
category: Code
tags: Python, multithreading, multiprocessing, async
featured_image: logos/python.png
---
[asyncio](https://docs.python.org/3/library/asyncio.html#module-asyncio) is a
library to write concurrent code using the async/await syntax.

## Concurrency Basics

### Parallel vs Interleaved

Running things concurrently means to run them at the same time. There are two
ways to run stuff concurrently: In parallel or interleaved.

The following images show the difference for compute-bound two tasks:

<figure class="wp-caption aligncenter img-thumbnail">
    <a href="../images/2020/05/parallel-execution.svg"><img src="../images/2020/05/parallel-execution.svg" alt="Parallel Execution" style="width: 512px;"/></a>
    <figcaption class="text-center">Parallel Execution</figcaption>
</figure>

<figure class="wp-caption aligncenter img-thumbnail">
    <a href="../images/2020/05/interleaved-execution.svg"><img src="../images/2020/05/interleaved-execution.svg" alt="Interleaved Execution" style="width: 512px;"/></a>
    <figcaption class="text-center">Interleaved Execution</figcaption>
</figure>

Now you might wonder why on hell would you ever run things interleaved as it
takes more time in total, right?

### CPU-bound vs I/O-bound

Where does your program spend most of its time? In some cases, it's just
computationally heavy. For example, when you train a neural network you spend a
lot of time doing matrix multiplications. In other applications, you spend a
lot of time waiting for I/O: Downloading data from the internet, waiting for a
database to return the selected rows. Or simply reading files from disk.

Let's take a file explorer application as an example. You open a folder and you
want to see thumbnails of the images. They might be high-resolution images.

<figure class="wp-caption aligncenter img-thumbnail">
    <a href="../images/2020/05/file-explorer.png"><img src="../images/2020/05/file-explorer.png" alt="A file explorer" style="width: 512px;"/></a>
    <figcaption class="text-center">A file explorer</figcaption>
</figure>

Printing the names of the files and the file size is fast. But computing the
thumbnail takes a lot of time. So you can do the thumbnail-calculation in
parallel. My laptop has 4 CPUs and hence my laptop can calculate the thumbnails
of 4 images in parallel. The next bottleneck is reading the full-size images
for the thumbnail-calculation into memory. More time than calculating the
thumbnails. Hence the execution time is no longer bound by the speed of the
CPU, but by the speed of reading from disk. Here interleaved execution helps:

* Start reading a file into memory
* While the disk is spinning to the right point, continue computing a thumbnail

This means if interleaved tasks speed up the total running time of the
application, they have to compute stuff while I/O is running.


### Comparison

<table class="table">
    <thead>
        <tr>
            <th></th>
            <th>Processes</th>
            <th>Threads</th>
            <th>Coroutines</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Speed-up IO-bound tasks</td>
            <td style="color: green;">✔</td>
            <td style="color: green;">✔</td>
            <td style="color: green;">✔</td>
        </tr>
        <tr>
            <td>Speed-up CPU-bound tasks</td>
            <td style="color: green;">✔</td>
            <td style="color: red;">✗</td>
            <td style="color: red;">✗</td>
        </tr>
        <tr>
            <td>Use multiple CPU cores</td>
            <td style="color: green;">✔</td>
            <td style="color: red;">✗</td>
            <td style="color: red;">✗</td>
        </tr>
        <tr>
            <td>Scheduling</td>
            <td>preemptive</td>
            <td>cooperative</td>
            <td>cooperative</td>
        </tr>
        <tr>
            <td>Scalability</td>
            <td>~number of CPU cores</td>
            <td>~number of CPU cores x number of threads per core</td>
            <td>thousands</td>
        </tr>
    </tbody>
</table>


## Concurrency in Python


<table class="table">
    <thead>
        <tr>
            <th></th>
            <th>Processes</th>
            <th>Threads</th>
            <th>Coroutines</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Packages</td>
            <td><a href="https://docs.python.org/3/library/multiprocessing.html"><code>multiprocessing</code></a>, <a href="https://joblib.readthedocs.io/en/latest/parallel.html"><code>joblib</code></a></td>
            <td><a href="https://docs.python.org/3/library/threading.html"><code>threading</code></a></td>
            <td><a href="https://docs.python.org/3/library/asyncio.html"><code>asyncio</code></a>, <a href="https://greenlet.readthedocs.io/en/latest/"><code>greenlet</code></a></td>
        </tr>
    </tbody>
</table>

There is also the [`concurrent.futures`](https://docs.python.org/3.8/library/concurrent.futures.html#module-concurrent.futures)
package.


### Multiprocessing Example

```python
"""'Hello Word' example for multiprocessing in Python."""

import time
import multiprocessing
import random
from typing import List


def dispatch_jobs(data: List[int], nb_jobs: int):
    # Chunk the data
    total = len(data)
    chunk_size = total // nb_jobs
    chunks = split_data(data, chunk_size)

    # Create the jobs
    jobs = []
    for i, chunk in enumerate(chunks):
        j = multiprocessing.Process(target=job, args=(i, chunk))
        jobs.append(j)
    print(f"Created {len(jobs)} jobs.")

    # Start execution
    for j in jobs:
        j.start()


def split_data(data, n):
    return [data[i : i + n] for i in range(0, len(data), n)]


def job(job_id: int, data_slice: List[int]):
    for item in data_slice:
        print(f"job {job_id}: {item}")
        time.sleep(random.randint(0, 10) * 0.1)


if __name__ == "__main__":
    data = list(range(100))
    dispatch_jobs(data, nb_jobs=4)
```

A more exciting example would be matrix multiplication.


### Threading Example

```python
"""'Hello Word' example for multithreading in Python."""

import time
import threading
import random
from typing import List


def dispatch_jobs(data: List[int], nb_jobs: int):
    # Chunk the data
    total = len(data)
    chunk_size = total // nb_jobs
    chunks = split_data(data, chunk_size)

    # Create the jobs
    jobs = []
    for i, chunk in enumerate(chunks):
        j = threading.Thread(target=job, args=(i, chunk))
        jobs.append(j)
    print(f"Created {len(jobs)} jobs.")

    # Start execution
    for j in jobs:
        j.start()


def split_data(data, n):
    return [data[i : i + n] for i in range(0, len(data), n)]


def job(job_id: int, data_slice: List[int]):
    for item in data_slice:
        print(f"job {job_id}: {item}")
        time.sleep(random.randint(0, 10) * 0.1)


if __name__ == "__main__":
    data = list(range(100))
    dispatch_jobs(data, nb_jobs=4)
```

A more exiting example would be downloading of many files (e.g. imagenet)
or a link-checker.


### Asyncio Coroutines

One style of coroutines in Python makes use of <a href="https://docs.python.org/3/library/asyncio.html"><code>asyncio</code></a>.
You need an event loop which executes the functions. The [`await`](https://www.python.org/dev/peps/pep-0492/#await-expression)
statement the execution until the expression after the keyword returns. This
enables other coroutines to execute in between.

The async/await syntax was introduced in Python 3.5 with [PEP 492](https://www.python.org/dev/peps/pep-0492/)
and looks like this:

```python
import asyncio


async def main():
    print("Hello ...")
    await asyncio.sleep(1)
    print("... World!")


# Python 3.7+
asyncio.run(main())
```

Note that with `await asyncio.sleep(0)` you can let other coroutines run.
This might make sense if you have a compute-heavy coroutine.

A more exiting example would be downloading of many files (e.g. imagenet)
or a link-checker.


### Greenlet Coroutines

Greenlet provides another style of coroutines. In contrast to asyncio, where
you explicitly define functions as asynchronous and define when you want to
let others run with await, greenlets do it implicitly by monkey-patching
functions such as `sleep`.


## Web Frameworks

A lot of times ([1](https://medium.com/@mihaigeorge.c/web-rest-api-benchmark-on-a-real-life-application-ebb743a5d7a3), [2](https://www.freecodecamp.org/news/million-requests-per-second-with-python-95c137af319/), [3](https://www.techempower.com/benchmarks/#section=data-r18&hw=ph&test=query&b=4&l=yyg41p-6&w=zii097-z2bon3-6&d=8&o=8)) you might see benchmarks which show the number of requests per
second you can do with Flask / Django and the way higher number of requests/second you
can do with Node/Express.js or another web application framework.
I sometimes see mistakes like using the development server of Flask which is
not intended for production for those benchmarks (I think [here](https://medium.com/@BijanRahnema/express-vs-flask-vs-go-acc0879c2122#d993)). Instead, gunicorn should be used.

Anyway, those miss an important point: The web application framework is likely
not the bottleneck. The application logic itself, SSL, the database queries.
They likely dominate the execution time. I don't have those numbers at hand, but
[Miguel Grinberg](https://www.youtube.com/watch?v=gJ7CnUX_7YQ) makes this
point as well. You might get a feeling for it by looking at my [article about basic operations](https://martin-thoma.com/simple-operations/#latency).

Instead of this sole focus on efficiency, other factors need to be considered:
The stability of the framework. The size of the community. The number of
developers you can find to work on your application.


### Flask

Gunicorn has multiple [async workers](https://docs.gunicorn.org/en/stable/design.html#async-workers).
gevent and eventlet both use Greenlets. This way, you make a Flask app use
Greenlets by letting gevent / eventlet monkey-patch.

As Flask is based on WSGI, it cannot use asyncio. See [issue #3339](https://github.com/pallets/flask/issues/3339).

### Quart

[Quart](https://pgjones.gitlab.io/quart/) is similar to Flask, but uses the
async/await syntax (see [migration guide](https://pgjones.gitlab.io/quart/how_to_guides/flask_migration.html)).

Recommended by Miguel Grinberg as an alternative to Flask.

### Sanic

[Sanic](https://sanic.readthedocs.io/en/latest/) is a Python 3.6+ web server
and web framework which allows the usage of the async/await.

Recommended by Miguel Grinberg as an alternative to Flask.


### Starlette

[Starlette](https://www.starlette.io/) is an [ASGI](https://asgi.readthedocs.io/en/latest/) framework, for building asyncio services.

It should be used with an ASGI server, such as [uvicorn](http://www.uvicorn.org/).

### Others

There is also [aiohttp](https://docs.aiohttp.org/en/stable/) and [FastAPI](https://fastapi.tiangolo.com/).
I haven't used either of them and I don't know of any big player using them.
FastAPI has a couple of nice features:

* Documentation looks good
* Generates Swagger
* Uses pydantic

Negative about FastAPI is the fact that it is only driven by Sebastián Ramírez.
The repository is in his private account and I don't see a project governance
document like e.g. <a href="https://docs.scipy.org/doc/scipy/reference/dev/governance/governance.html">SciPy has</a>.
<a href="https://palletsprojects.com/governance/">Flasks Governance document</a> misses
some crucial parts, e.g. who is currently in charge and which organizations
decide that.

Being a one-person project means if that person gets hit by a bus, maintenance
might suddenly stop. If I use this for my web services, I have to start
maintaining this framework.

There is also [Twisted](https://en.wikipedia.org/wiki/Twisted_(software)) since 2002. I haven't used it,
I don't know anybody who used it and I don't know what it is doing.

## See also

* [Speed Up Your Python Program With Concurrency](https://realpython.com/python-concurrency/#how-to-speed-up-an-io-bound-program)
* StackExchange:
    * [How many threads can I run concurrently?](https://stackoverflow.com/q/4828296/562769)
    * [Cores vs Threads: How many threads should I run on this machine?](https://askubuntu.com/q/668538/10425)
    * [What is the difference between multiprocessing and subprocess?](https://stackoverflow.com/q/13606867/562769)
    * [What does async/await do?](https://stackoverflow.com/q/46363945/562769)
    * [What is the difference between concurrent.futures and asyncio.futures?](https://stackoverflow.com/q/29902908/562769)
    * [Concurrent.futures vs Multiprocessing in Python 3](https://stackoverflow.com/q/20776189/562769)
* Miguel Grinberg: [Asynchronous Web Development with Flask](https://www.youtube.com/watch?v=gJ7CnUX_7YQ), 2019.
* Miguel Grinberg: [Asynchronous Python for the Complete Beginner](https://www.youtube.com/watch?v=iG6fr81xHKA) in PyCon 2017
* Timo Furrer: [Awesome asyncio](https://github.com/timofurrer/awesome-asyncio)

Further concepts:

* [Futures and promises](https://en.wikipedia.org/wiki/Futures_and_promises)
