<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="utf-8"> 
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Martin Thoma" />
        <meta name="copyright" content="Martin Thoma" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Klausur, German posts, " />

<meta property="og:title" content="Probabilistische Planung "/>
<meta property="og:url" content="../probabilistische-planung/" />
<meta property="og:description" content="Dieser Artikel beschäftigt sich mit der Vorlesung „Probabilistische Planung“ am KIT. Er dient als Prüfungsvorbereitung. Ich habe die Vorlesungen bei Herrn Dr.-Ing. Marco Huber im Sommersemester 2015 und 2016 gehört. Der Artikel dient als Prüfungsvorbereitung und ist noch am Entstehen. In der Vorlesung &#39;Probabilistische Planung ..." />
<meta property="og:site_name" content="Martin Thoma" />
<meta property="og:article:author" content="Martin Thoma" />
<meta property="og:article:published_time" content="2016-05-11T20:00:00+02:00" />
<meta name="twitter:title" content="Probabilistische Planung ">
<meta name="twitter:description" content="Dieser Artikel beschäftigt sich mit der Vorlesung „Probabilistische Planung“ am KIT. Er dient als Prüfungsvorbereitung. Ich habe die Vorlesungen bei Herrn Dr.-Ing. Marco Huber im Sommersemester 2015 und 2016 gehört. Der Artikel dient als Prüfungsvorbereitung und ist noch am Entstehen. In der Vorlesung &#39;Probabilistische Planung ...">
<meta property="og:image" content="logos/klausur.png" />
<meta name="twitter:image" content="logos/klausur.png" >

        <title>Probabilistische Planung  · Martin Thoma
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.1/css/font-awesome.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="../theme/css/pygments.css" media="screen">
        <link rel="stylesheet" type="text/css" href="../theme/tipuesearch/tipuesearch.css" media="screen">
        <link rel="stylesheet" type="text/css" href="../theme/css/elegant.css" media="screen">
        <link rel="stylesheet" type="text/css" href="../static/custom.css" media="screen">

        <!-- MathJax -->
<script type="text/x-mathjax-config">
<!--
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [ ['$$', '$$'], ['\\[','\\]']],
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
    processEscapes: true
  }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
// -->
</script>
<script type="text/javascript" async
  src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
        
        <link href="https://martin-thoma.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Martin Thoma - Full Atom Feed" />
        <link href="https://martin-thoma.com/feeds/index.xml" type="application/rss+xml" rel="alternate" title="Martin Thoma - Full RSS Feed" />
    </head>
    <body>
        <div id="content-sans-footer">
        <div class="navbar navbar-static-top">
            <div class="navbar-inner">
                <div class="container-fluid">
                    <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </a>
                    <a class="brand" href="../"><span class=site-name>Martin Thoma</span></a>
                    <div class="nav-collapse collapse">
                        <ul class="nav pull-right top-menu">
                            <li ><a href="..">Home</a></li>
                            <li ><a href="../categories.html">Categories</a></li>
                            <li ><a href="../tags.html">Tags</a></li>
                            <li ><a href="../archives.html">Archives</a></li>
                            <li><form class="navbar-search" action="../search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row-fluid">
                <div class="span1"></div>
                <div class="span10">
<article>
<div class="row-fluid">
    <header class="page-header span10 offset2">
    <h1><a href="../probabilistische-planung/"> Probabilistische Planung  </a></h1>
    </header>
</div>

<div class="row-fluid">
    <div class="span2 table-of-content">
        <nav>
        <h4>Contents</h4>
        <div id="toc"><ul><li><a class="toc-href" href="#behandelter-stoff" title="Behandelter Stoff">Behandelter Stoff</a><ul><li><a class="toc-href" href="#ubersicht" title="&Uuml;bersicht">&Uuml;bersicht</a></li><li><a class="toc-href" href="#grundlagen" title="Grundlagen">Grundlagen</a></li><li><a class="toc-href" entscheidungs­probleme'="" href="#markovsche-entscheidungsprobleme" sche="" title="Markov">Markov'sche Entscheidungs&shy;probleme</a></li><li><a class="toc-href" href="#pomdps" title="POMDPs">POMDPs</a></li><li><a class="toc-href" href="#reinforcement-learning" title="Reinforcement Learning">Reinforcement Learning</a></li></ul></li><li><a class="toc-href" href="#prufungsfragen_1" title="Pr&uuml;fungsfragen">Pr&uuml;fungsfragen</a><ul><li><a class="toc-href" href="#mdp" title="MDP">MDP</a></li><li><a class="toc-href" href="#pomdp" title="POMDP">POMDP</a></li><li><a class="toc-href" href="#rl" title="RL">RL</a></li></ul></li><li><a class="toc-href" href="#material-und-links_1" title="Material und Links">Material und Links</a></li><li><a class="toc-href" href="#vorlesungsempfehlungen" title="Vorlesungsempfehlungen">Vorlesungsempfehlungen</a></li><li><a class="toc-href" href="#termine-und-klausurablauf" title="Termine und Klausurablauf">Termine und Klausurablauf</a></li></ul></div>
        </nav>
    </div>
    <div class="span8 article-content" id="contentAfterTitle">

            
            <div class="info">Dieser Artikel besch&auml;ftigt sich mit der Vorlesung &bdquo;Probabilistische Planung&ldquo; am KIT. Er dient als Pr&uuml;fungsvorbereitung. Ich habe die Vorlesungen bei <a href="http://ies.anthropomatik.kit.edu/mitarbeiter.php?person=huber">Herrn Dr.-Ing. Marco Huber</a> im Sommersemester 2015 und 2016 geh&ouml;rt. Der Artikel dient als Pr&uuml;fungsvorbereitung und ist noch am Entstehen.</div>
<p>In der Vorlesung 'Probabilistische Planung' werden drei Themen besprochen:</p>
<ul>
<li>Markov'sche Entscheidungsprobleme (MDPs)</li>
<li>Planung bei Messunsicherheiten</li>
<li>Reinforcement Learning (RL)</li>
</ul>
<h2 id="behandelter-stoff">Behandelter Stoff</h2>
<h3 id="ubersicht">&Uuml;bersicht</h3>
<table>
<tr>
<th>Datum</th>
<th>Kapitel</th>
<th>Inhalt</th>
</tr>
<tr>
<td>26.04.2016</td>
<td>Grundlagen</td>
<td>Wahrscheinlichkeitsraum, Grundraum, Ereignis&shy;raum, Resultate,
        Elementar&shy;ereignis, $\sigma$-Algebra, Wahrscheinlichkeits&shy;ma&szlig;,
        Bedingte Wahrscheinlichkeit, Ziegenproblem, Dichtefunktion</td>
</tr>
<tr>
<td>28.04.2016</td>
<td>Grundlagen</td>
<td>Allais-Paradoxon, TODO</td>
</tr>
<tr>
<td>06.05.2016</td>
<td>Grundlagen</td>
<td>TODO</td>
</tr>
<tr>
<td>11.05.2016</td>
<td>MDPs</td>
<td>Definition eines MDP, Plan vs. Strategie, <abbr title="Dynamische Programmierung">DP</abbr></td>
</tr>
<tr>
<td>18.05.2016</td>
<td>MDPs</td>
<td>Endliche Planungsprobleme, Value- und Policy-Iteration</td>
</tr>
<tr>
<td>25.05.2016</td>
<td>MDPs</td>
<td>K&uuml;rzeste-Wege Suche (Tiefensuche, Breitensuche, Dijkstra, A*, Branch &amp; Bound; Label-Korrektur-Algorithmus); Trellis-Diagramm; Differentialantrieb; Pontryagin's Minimumprinzip</td>
</tr>
<tr>
<td>01.06.2016</td>
<td>MDPs</td>
<td>Pontryagin's Minimumprinzip, Hamilton-Funktion; LQR</td>
</tr>
</table>
<p>Folien:</p>
<ul>
<li>25.05.2016: Folie 4 - Die Knoten sind Zust&auml;nde und die Kanten sind Aktionen</li>
<li><span class="math">\(g_{ij}^k = \infty\)</span>: Kein &Uuml;bergang von <span class="math">\(i\)</span> nach <span class="math">\(j\)</span> in Schritt <span class="math">\(k\)</span>.</li>
</ul>
<h3 id="grundlagen">Grundlagen</h3>
<p>Slides: <code>ProPlan-1-Anschrieb.pdf</code></p>
<dl>
<dt><dfn>$\sigma$-Algebra</dfn></dt>
<dd>Sei $S$ eine Menge und $\mathcal{A}$ ein Menge aus Teilmengen von $S$.
      $\mathcal{A}$ hei&szlig;t eine $\sigma$-Algebra &uuml;ber $S$, genau dann, wenn
      gilt:

      <ul>
<li>$S \in \mathcal{A}$</li>
<li>$\forall M \in \mathcal{A} \Rightarrow (S \setminus M) \in \mathcal{A}$</li>
<li>$M_1, M_2, \dots \in \mathcal{A} \Rightarrow \bigcup_{n \in \mathbb{N}} M_n \in \mathcal{A}$</li>
</ul>
</dd>
<dt><dfn>Wahrscheinlichkeitsma&szlig;</dfn></dt>
<dd>Eine Funktion $P: A \rightarrow \mathbb{R}$ hei&szlig;t Wahrscheinlichkeitsma&szlig;,
      wenn die Kolmogorov'schen Axiome gelten:

      <ul>
<li>$\forall M \in \mathcal{A}: P(M) \geq 0$</li>
<li>$\forall P(S) = 1$</li>
<li>$M_1, M_2, \in \mathcal{A} \land M_1 \cap M_2 = \emptyset \Rightarrow P(M_1 \cup M_2) = P(M_1) + P(M_2)$</li>
</ul>
</dd>
<dt><dfn>Normalverteilung</dfn></dt>
<dd>Die Normalverteilung $\mathcal{N}(\mu, \sigma^2)$ ist eine
      kontinuierliche Verteilung mit der Dichtefunktion

      $$f(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} e^{- \frac{(x - \mu)^2}{2\sigma^2}}$$


      </dd>
</dl>
<h3 id="markovsche-entscheidungsprobleme">Markov'sche Entscheidungs&shy;probleme</h3>
<p>Slides: <code>11.05.2016 - TODO</code></p>
<dl>
<dt><dfn id="mdp">Markov'sches Entscheidungsproblem</dfn> (<dfn>Markov Decision Process</dfn>, <dfn>MDP</dfn>)</dt>
<dd>Ein MDP wird durch 8&nbsp;Eigenschaften gekennzeichnet:

      <ol>
<li>Zustandsraum $X \subseteq \mathbb{R}^n$ mit Zust&auml;nden
              $x \in \mathcal{X}$.</li>
<li>Diskrete Zeitschritte $k=0, 1, \dots, N$ mit Endzeitpunkt
              $N$. Dabei ist der 0-te Schritt gegeben.</li>
<li>Initialzustand $x_o \in \mathcal{X}$ des Agenten zum Zeitpunkt $k=0$.</li>
<li>Nichtleere Aktionsmenge $A_k(x_0) \subseteq A$ mit Aktion $a_k$.
              H&auml;ufig $A_k(x_k)=A$ f&uuml;r alle $k=0, \dots, N$ (Zeit- und Zustandsinvarianz)</li>
<li>&Uuml;bergangswahrscheinlichkeit $x_{k+1} \leadsto P_x(\cdot | x_k, a_k)$.<br/>
              Markov-Annahme: $P_x(\cdot | x_k, a_k) = P(\cdot | x_{0:k}, a_{0:k})$,
              wobei die Notation $x_{0:k} = x_0, x_1, \dots, x_k$ bedeutet.
              Das hei&szlig;t, der Folgezustand ist nur vom Zustand $x_k$ und
              der gew&auml;hlten Aktion $a_k$ abh&auml;ngig.<br/>
              Im Fall diskreter Zust&auml;nde ist die
              &Uuml;bergangs&shy;wahrscheinlichkeit eine bedingte Z&auml;hldichte:
              $$f(x_{k+1} | x_k, a_k) = P_x(x=x_{k+1} | x_k, a_k)$$<br/>
              Bei kontinuierlichen Zust&auml;nden eine bedingte Wahrscheinlichkeits&shy;dichte:
              $$f(x_{k+1} | x_k, a_k) = \frac{\partial F(x | x_k, a_k)}{\partial x} |_{x=x_{k+1}}$$</li>
<li>Additive Kostenfunktion
              $$g_N (x_N) + L_{k=0}^{N-1} g_k(x_k, a_k)$$
              wobei $g_N$ die terminalen Kosten und $g_k$ Schrittkosten genannt
              werden.</li>
<li>Der Zustand ist f&uuml;r jedes $k$ <strong>direkt beobachtbar</strong>.

              <ul>
<li><strong>Vor</strong> Anwendung bzw Auswahl einer Aktion
                      $a_k$ zum Zeitpunkt $k$
                      $$x_{k+1} \sim P_x(\cdot | x_k, a_k)$$
                      wobei $x_k, a_k$ exakt bekannt sind.</li>
<li><strong>Nach</strong> Anwendung der Aktion $a_k$ zum
                      Zeitpunkt $k+1$ ist $x_{k+1}$ exakt bekannt.</li>
</ul>
</li>
<li><strong>Ziel</strong>: Minimierung der erwarteten Kosten
              $$J_{\pi_{0:N-1}}(x_0) := \mathbb{E}(g_N(x_k) + \sum_{k=0}^{N-1} g_k (x_k, \pi_k(x_k))$$
              bzgl. einer Strategie $\pi_{0:N-1} = (\pi_0, \pi_1, \dots, \pi_{N-1})$
              mit Funktionen $\pi_k(x_k) = a_k \in A_k(x_k)$.</li>
</ol>
</dd>
<dt><dfn>Strategie</dfn></dt>
<dd>Eine Strategie ist ein Plan mit Zustandsr&uuml;ckf&uuml;hrung</dd>
<dt><dfn id="nutzenfunktion">Nutzenfunktion</dfn></dt>
<dd>TODO</dd>
<dt><a href="https://en.wikipedia.org/wiki/Bellman_equation"><dfn id="bellman-equation">Bellman-Gleichungen</dfn></a></dt>
<dd>TODO</dd>
<dt><dfn id="q-function">Q-Funktion</dfn></dt>
<dd>TODO</dd>
<dt><a href="https://de.wikipedia.org/wiki/Dynamische_Programmierung"><dfn id="dynamic-programming">Dynamische Programmierung</dfn></a></dt>
<dd>TODO

      Laufzeitkomplexit&auml;t $\mathcal{O}(N |\mathcal{X}|^2 |A|)$

  </dd>
</dl>
<p>18.05.2016</p>
<dl>
<dt><dfn>Endliche Planungsproblem</dfn></dt>
<dd>Hat man einen endlichen Zustandsraum $\mathcal{X} = \{1, 2, \dots, n_x\} \subsetneq \mathbb{N}$ und eine endliche Aktionsmenge $A = \{1, 2, \dots, n_a\} \subsetneq \mathbb{N}$,
        in einem Planungsproblem, so spricht man von einem endlichen
        Planungsproblem.</dd>
<dt><dfn>Markov-Kette</dfn></dt>
<dd>&Uuml;bergangswahrscheinlichkeiten in einem endlichen Planungsproblem
        sind gegeben.

        Die naive L&ouml;sung mit Brute-Force ist in $\mathcal{O}(|A|^{N \cdot |X|})$.

    </dd>
<dt><dfn>Planungsprobleme nach Horizont</dfn></dt>
<dd>
<ul>
<li>$N=1$: Gierige Planung, ein einschrittiges Planungsproblem.
                       Hat geringe Komplexit&auml;t, aber zuk&uuml;nftige Effekte werden
                       nicht ber&uuml;cksichtig. Bei submodularen Kostenfunktionen
                       kann man die Kosten, die durch die gierige Planung
                       entstehen, absch&auml;tzen.</li>
<li>$N&lt;\infty$: Wurde bisher betrachtet und betrifft die meisten
                       Planungsprobleme. Nachteil ist, dass die Strategie $\pi_k$
                       zeitinvariant ist.</li>
<li>$N = \infty$: Bei Planungsproblemen mit sehr langem Horizont,
                       wenn ein Ende nicht abzulesen ist. Beispiele sind die
                       k&uuml;rzeste-Wege-Suche sowie bei Reinforcement Learning.
                       Probleme sind unendliche Kosten und die Zeitabh&auml;ngigkeit
                       der Schrittkosten und &Uuml;bergangswahrscheinlichkeiten.</li>
</ul>
</dd>
<dt><dfn>Diskontiertes Planungsproblem</dfn></dt>
<dd>
<ol>
<li>&Uuml;bergangswahrscheinlichkeiten und Schrittkosten sind
                Zeitinvariant, dh. $f_{ij}^k(a) = f_{ij}(a)$ und
                $g_k(i,a) = g(i, a) \forall k$.</li>
<li>Es gilt die optimale Wertefunktion $J^*$ zu finden, welche
                durch
                $$J^*(x_0) = \min_{\pi_0, \pi_1, \dots} (J_{\pi_0}(x_0))$$

                definiert ist. Diese minimiert die erwarteten <i>diskontierten
                Kosten</i>

                $$J_{\pi_0} (x_0) = \lim_{N \rightarrow \infty} \mathbb{E}(\alpha^N g(x_N)+ \sum_{k=0}^{N-1} \alpha^k \cdot g(x_k, \pi_k(x_k)))$$

                Dabei hei&szlig;t $\alpha \in (0, 1)$ ein <i>Diskontierungsfaktor</i>.
                Er verhindert, dass die Kosten unendlich werden.
            </li>
</ol>

        Dies kann man mit DP l&ouml;sen, indem man eine Vorw&auml;rtsrekursion macht:

        $$
        \begin{align}
        J_k(1) &amp;= \min_{a \in A(i)}(g(i, a) + \alpha \sum_{j=1}^{n_x} f_{ij}(a) \cdot J_{k-1}(j))\\
        J_0(i) &amp;= g(i)
        \end{align}
        $$

        Das ist m&ouml;glich, da das Problem zeitinvariant ist. Dies kann man durch
        Indexverschiebung zeigen.
    </dd>
<dt><dfn>Bellman-Operator</dfn></dt>
<dd>$$(T J) (i) = \min_{a \in A(i)} (g(i,a) + \alpha \cdot \sum_j f_{ij}(a) \cdot J(j))$$

        $$T^k J = \begin{cases}(T(T^{k-1} J)) &amp;\text{if } k \geq 1\\
                               J              &amp;\text{otherwise}
                  \end{cases}$$

        Es gilt: $$J^* = \lim_{N \rightarrow \infty} T^N J \text{ f&uuml;r beliebiges } J$$
    </dd>
<dt><dfn>Strategiebewertung</dfn></dt>
<dd>$$(T_\pi J)(i) = g(i, \pi(i)) + \alpha \cdot \sum_j f_{ij} (\pi(i)) \cdot J(j)$$

        F&uuml;r eine optimale Strategie $\pi^*$ gilt:

        $$(T J)(i) = (T_{\pi^*} J)(i)$$
    </dd>
<dt><dfn>Wertevektor</dfn></dt>
<dd>$$J = (J(1), \dots, J(nx))^T$$</dd>
<dt><a href="https://de.wikipedia.org/wiki/Kontraktion_(Mathematik)"><dfn>Kontraktion</dfn></a></dt>
<dd>Eine Funktion $f: M \rightarrow M$ in einem metrischen Raum $(M, d)$
        hei&szlig;t Kontraktion genau dann, wenn
        $$\exists \lambda \in [0, 1) \forall x, y \in M: d(f(x), f(y)) \leq \lambda d(x, y)$$
        gilt.</dd>
<dt><a href="https://de.wikipedia.org/wiki/Fixpunktsatz_von_Banach"><dfn>Banach'scher Fixpunktsatz</dfn></a></dt>
<dd>

        Sei $(M, d)$ ein vollst&auml;ndig metrischer Raum und $f$ eine Kontraktion,
        welche Lipschitz-Stetig ist mit Konstante $0 \leq \lambda &lt; 1$.
        Dann gilt:

        <ul>
<li>Es gibt genau einen Fixpunkt $\xi \in M$ mit $f(\xi) = \xi$.</li>
<li>TODO (Absch&auml;tzung)</li>
</ul>
</dd>
<dt><dfn>T-Kontraktion</dfn></dt>
<dd>F&uuml;r beliebige Wertevektoren $J, J'$, eine beliebige Strategie $\pi$
        und f&uuml;r alle $k=0,1, \dots$ gilt:

        $$d(T^k J, T^k J') = \leq \alpha^k \cdot d(J, J')$$
        $$d(T^k_\pi J, T_T^k J') \leq \alpha^k \cdot d (TODO)$$
    </dd>
<dt><dfn id="value-iteration">Werteiteration</dfn> (<dfn>Value Iteration</dfn>)</dt>
<dd>$$J^* = \lim_{N \rightarrow \infty} T^N J$$
        wobei $J^*$ die optimalen Kosten, $T$ der Bellman-Operator und $N$
        der Planungshorizont ist.

        TODO: Pseudocode

        </dd>
<dt><dfn>Satz von der Sation&auml;ren Strategie</dfn></dt>
<dd>
<ol>
<li>F&uuml;r jede station&auml;re Strategie $\pi = \pi_{0:N-1}$ erf&uuml;llt der
                dazugeh&ouml;rige Wertevektor $J_\pi$ die Fixpunktgleichung
                $J_\pi = T_\pi J_\pi$.
                Dabei ist $J_\pi$ der eindeutige Fixpunkt.</li>
<li>Eine sation&auml;re Strategie $\pi^*$ ist genau dann optimal, wenn
                $\pi^*$

                $$T J^* = T_{\pi^*} J^*$$

                erf&uuml;llt. (Also: Die optimale Strategie ist eine station&auml;re Strategie)</li>
</ol>

        Der Beweis f&uuml;r (1) folgt aus dem Banach'schen Fixpunktsatz.
    </dd>
<dt><dfn id="policy-iteration">Strategieiteration</dfn></dt>
<dd>Man kann beobachten, dass bei der Werteiteration die Stategie schneller
        konvergiert als der Wertevektor. Au&szlig;erdem ist die Anzahl der
        Strategien endlich, aber es gibt unendlich viele Wertevektoren.<br/>
<br/>
        (TODO: Pseudocode)
        <br/>
        Die folgenden beiden Schritte werden alternierend ausgef&uuml;hrt:

        <ol>
<li>Strategieauswertung</li>
<li>Strategieverbesserung</li>
</ol>

        Vergleich zwischen Werte- und Strategieiteration:

        <ul>
<li>Strategieiteration konvergiert in weniger Schritten</li>
<li>Jeder Schritt der Strategieiteration ist teurer als in der
                Werteoperation, da die Strategieauswertung die L&ouml;sung eines
                LGS ist (in $\mathcal{O}(n_x^3)$). Au&szlig;erdem ist
                die Strategieiteration nie f&uuml;r $\alpha=1$ l&ouml;sbar (kann auch
                sonst passieren).</li>
</ul>
</dd>
<dt><dfn>Label-Korrektur-Algorithmus</dfn></dt>
<dd>Der Label-Korrektur-Algorithmus ist ein Meta-Algorithmus zur
        k&uuml;rzeste-Wege-Suche dient. Spezialf&auml;lle von diesem sind die
        Tiefen- und Breitensuche, der <a href="https://de.wikipedia.org/wiki/Dijkstra-Algorithmus">Dijkstra-Algorithmus</a>, der <a href="https://de.wikipedia.org/wiki/A*-Algorithmus">A*-Algorithmus</a> sowie
        Branch &amp; Bound.</dd>
<dt><a href="https://de.wikipedia.org/wiki/Trellis-Code"><dfn id="trellis">Trellis-Diagramm</dfn></a></dt>
<dd>Eine Diagramm welches anzeigt welche Zust&auml;nde &uuml;ber die Zeit
        gew&auml;hlt werden.</dd>
<dt><a href="https://en.wikipedia.org/wiki/Pontryagin%27s_maximum_principle"><dfn id="pontryagins-minimum-principle">Pontryagin's Minimum-Prinzip</dfn></a></dt>
<dd>Das Pontryagin'sche Minimum-Prinzip k&ouml;nnte als die russische
        Variante der Bellman-Gleichungen f&uuml;r deterministische MDPs bezeichnet
        werden.<br/>

        TODO</dd>
<dt><a href="https://de.wikipedia.org/wiki/Hamilton-Funktion"><dfn>Hamilton-Funktion</dfn></a></dt>
<dd>TODO</dd>
<dt><dfn>Lineares Zustandsmodell</dfn></dt>
<dd>$$x_{k+1} = A_k + x_k + B_k \cdot a_k + w_k$$</dd>
<dt><a href="https://de.wikipedia.org/wiki/LQ-Regler"><dfn>Linearer Quadratischer Regulator</dfn></a> (<dfn>LQR</dfn>)</dt>
<dd>Der LQR ist ein Regler (Regulator) f&uuml;r einen lineareren Zustandsraum
        mit quadratischer Kostenfunktion.

        TODO</dd>
</dl>
<p><code>01.06.2016</code></p>
<h3 id="pomdps">POMDPs</h3>
<dl>
<dt><a href="https://en.wikipedia.org/wiki/Partially_observable_Markov_decision_process"><dfn id="pomdp">Partially observable Markov decision process</dfn></a> (POMDP)</dt>
<dd>TODO</dd>
</dl>
<h3 id="reinforcement-learning">Reinforcement Learning</h3>
<dl>
<dt><dfn id="rl">Reinforcement Learning</dfn></dt>
<dd>TODO</dd>
</dl>
<h2 id="prufungsfragen_1">Pr&uuml;fungsfragen</h2>
<ul>
<li>Welche 3 Themengebiete wurden in der Vorlesung behandelt und was sind die
  Unterschiede?<br/>
  &rarr; <a href="#mdp">MDP</a>, <a href="#pomdp">POMDP</a>, <a href="#rl">RL</a> (TODO: Agent-Umfeld-Diagram)</li>
<li>Wie ist eine Nutzenfunktion definiert?<br/>
  &rarr; TODO</li>
<li>Wie l&ouml;st man Optimierungsprobleme ohne Nebenbedingungen?<br/>
  &rarr; TODO</li>
<li>Beweisen Sie, dass der Gradient senkrecht auf die H&ouml;henlinien steht.<br/>
  &rarr; TODO</li>
<li>Wie l&ouml;st man Optimierungsprobleme mit Nebenbedingungen?<br/>
  &rarr; Lagrange (TODO)</li>
<li>Wann ist es leichter / schwerer das Optimierungsproblem zu l&ouml;sen?<br/>
  &rarr; TODO</li>
<li>Welche numerischen Methoden zur Optimierung kennen sie?<br/>
  &rarr; TODO</li>
</ul>
<h3 id="mdp">MDP</h3>
<ul>
<li>Wie lautet die Definition eines MDP?<br/>
  &rarr; Siehe <a href="#mdp">oben</a>.</li>
<li>Was versteht man unter dynamischer Programmierenung?<br/>
  &rarr; Siehe <a href="#dynamic-programming">oben</a>.</li>
<li>Wie lauten die Bellman-Gleichungen?<br/>
  &rarr; Siehe <a href="#bellman-equation">oben</a>.</li>
<li>Was ist an den Bellman-Gleichungen problematisch?<br/>
  &rarr; TODO</li>
</ul>
<h3 id="pomdp">POMDP</h3>
<ul>
<li>Wie lautet die Definition eines POMDP?<br/>
  &rarr; TODO</li>
<li>Wie lautet die Kostenfunktion eines POMDP?<br/>
  &rarr; TODO</li>
<li>Was ist PWLC?<br/>
  &rarr; TODO</li>
</ul>
<h3 id="rl">RL</h3>
<ul>
<li>Welche Arten von RL gibt es?<br/>
  &rarr; TODO</li>
</ul>
<h2 id="material-und-links_1">Material und Links</h2>
<ul>
<li><a href="http://ies.anthropomatik.kit.edu/lehre_proplan.php">Vorlesungswebsite</a></li>
</ul>
<h2 id="vorlesungsempfehlungen">Vorlesungsempfehlungen</h2>
<p>Folgende Vorlesungen sind &auml;hnlich:</p>
<ul>
<li><a href="https://martin-thoma.com/analysetechniken-grosser-datenbestaende/">Analysetechniken gro&szlig;er Datenbest&auml;nde</a></li>
<li><a href="https://martin-thoma.com/informationsfusion/">Informationsfusion</a></li>
<li><a href="https://martin-thoma.com/machine-learning-1-course/">Machine Learning 1</a></li>
<li><a href="https://martin-thoma.com/machine-learning-2-course/">Machine Learning 2</a></li>
<li><a href="https://martin-thoma.com/mustererkennung-klausur/">Mustererkennung</a></li>
<li><a href="https://martin-thoma.com/neuronale-netze-vorlesung/">Neuronale Netze</a></li>
<li><a href="https://martin-thoma.com/lma/">Lokalisierung Mobiler Agenten</a></li>
<li><a href="https://martin-thoma.com/probabilistische-planung/">Probabilistische Planung</a></li>
</ul>
<h2 id="termine-und-klausurablauf">Termine und Klausurablauf</h2>
<p>Die Veranstaltung wird m&uuml;ndlich gepr&uuml;ft.</p>
            
            <div id="disqus_thread"></div>
<script>
    /*
    var disqus_config = function () {
        this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() {  // REQUIRED CONFIGURATION VARIABLE: EDIT THE SHORTNAME BELOW
        var d = document, s = d.createElement('script');

        s.src = '//martinthoma.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

            <hr/>
        </div>
        <section>
        <div class="span2" style="float:right;font-size:0.9em;">
            <h4>Published</h4>
            <time pubdate="pubdate" datetime="2016-05-11T20:00:00+02:00">Mai 11, 2016</time>
            <br/>
            by <a rel="author" class="vcard author post-author" itemprop="author" href="../author/martin-thoma/"><span class="fn" itemscope="" itemtype="https://schema.org/Person"><span itemprop="name">Martin Thoma</span></span></a>
            <h4>Category</h4>
            <a class="category-link" href="../categories.html#german-posts-ref">German posts</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="../tags.html#klausur-ref">Klausur
                    <span>33</span>
</a></li>
            </ul>
<h4>Contact</h4>
    <a href="https://twitter.com/themoosemind" title="My Twitter Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-twitter sidebar-social-links"></i></a>
    <a href="mailto:info@martin-thoma.de" title="My Email Address" class="sidebar-social-links" target="_blank">
    <i class="fa fa-envelope sidebar-social-links"></i></a>
    <a href="https://github.com/MartinThoma" title="My Github Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-github sidebar-social-links"></i></a>
    <a href="http://stackoverflow.com/users/562769/martin-thoma" title="My Stackoverflow Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-stackoverflow sidebar-social-links"></i></a>
        </div>
        </section>
</div>
</article>
                </div>
                <div class="span1"></div>
            </div>
        </div>
        <div id="push"></div>
    </div>
<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-subtitle"><span class="site-name">Martin Thoma</span> - A blog about Code, the Web and Cyberculture</li>
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page">Talha Mansoor</a></li>
    </ul>
</div>
</footer>        <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>
        <script>
(function(){
    'use strict';

    /*
    Create intra-page links
    Requires that your headings already have an `id` attribute set (because that's what jekyll does)
    For every heading in your page, this adds a little anchor link `#` that you can click to get a permalink to the heading.
    Ignores `h1`, because you should only have one per page.
    The text content of the tag is used to generate the link, so it will fail "gracefully-ish" if you have duplicate heading text.

    Credit: https://gist.github.com/SimplGy/a229d25cdb19d7f21231
     */

    var headingNodes = [], results, link,
        tags = ['h2', 'h3', 'h4', 'h5', 'h6'];

    tags.forEach(function(tag){
        var contentTag = document.getElementById('contentAfterTitle');
      results = contentTag.getElementsByTagName(tag);
      Array.prototype.push.apply(headingNodes, results);
    });

    headingNodes.forEach(function(node){
      link = document.createElement('a');
      link.className = 'deepLink';
      link.textContent = ' ¶';
      link.href = '#' + node.getAttribute('id');
      node.appendChild(link);
    });

  })();
</script>
    </body>
    <!-- Theme: Elegant built for Pelican
    License : http://oncrashreboot.com/pelican-elegant -->
</html>