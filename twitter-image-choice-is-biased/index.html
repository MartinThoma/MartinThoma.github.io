<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Martin Thoma" />
        <meta name="copyright" content="Martin Thoma" />
        <link title = "Martin Thoma"
              type  = "application/opensearchdescription+xml"
              rel   = "search"
              href  = "../opensearch.xml">

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Twitter, Technology, Machine Learning, Social Media, Artificial Intelligence, My bits and bytes, " />

<meta property="og:title" content="How Twitter’s Image Choice is Biase "/>
<meta property="og:url" content="https://towardsdatascience.com/how-twitters-image-choice-is-biased-8d3f0ba63379" />
<meta property="og:description" content="Photo by Ravi Sharma on Unsplash Twitter shows preview-images of shared images. If the aspect ratio is not the wanted one, the image needs to be cropped for the preview. The way the cropping is done is supposedly not random. People seem to think that it is “smart” in the …" />
<meta property="og:site_name" content="Martin Thoma" />
<meta property="og:article:author" content="Martin Thoma" />
<meta property="og:article:published_time" content="2020-09-25T20:00:00+02:00" />
<meta name="twitter:title" content="How Twitter’s Image Choice is Biase ">
<meta name="twitter:description" content="Photo by Ravi Sharma on Unsplash Twitter shows preview-images of shared images. If the aspect ratio is not the wanted one, the image needs to be cropped for the preview. The way the cropping is done is supposedly not random. People seem to think that it is “smart” in the …">
<meta property="og:image" content="logos/star.png" />
<meta name="twitter:image" content="logos/star.png" >

        <title>How Twitter’s Image Choice is Biase  · Martin Thoma
</title>
        <!-- Latest compiled and minified CSS -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
        <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.1/css/font-awesome.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="../theme/css/pygments.css" media="screen">
        <link rel="stylesheet" type="text/css" href="../theme/tipuesearch/tipuesearch.css" media="screen">
        <link rel="stylesheet" type="text/css" href="../theme/css/elegant.css" media="screen">
        <link rel="stylesheet" type="text/css" href="../static/print.css" media="print">
        <link rel="stylesheet" type="text/css" href="../static/custom.css" media="screen">

        <!-- MathJax -->
<script type="text/x-mathjax-config">
<!--
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [ ['$$', '$$'], ['\\[','\\]']],
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
    processEscapes: true
  }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
// -->
</script>
<script type="text/javascript" async
  src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

        <link href="https://martin-thoma.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Martin Thoma - Full Atom Feed" />
        <link href="https://martin-thoma.com/feeds/index.xml" type="application/rss+xml" rel="alternate" title="Martin Thoma - Full RSS Feed" />
    </head>
    <body>
        <div id="content-sans-footer">
        <div class="navbar navbar-static-top navbar-default">
            <div class="container">
                <div class="container-fluid">
                    <div class="collapse navbar-collapse">
                        <ul class="nav pull-left top-menu navbar-nav">
                            <li><a href=".." style="font-family: 'Monaco', 'Inconsolata', 'Andale Mono', 'Lucida Console', 'Bitstream Vera Sans Mono', 'Courier New', Courier, Monospace;
                        font-size: 20px;" class="navbar-brand" tabindex="-1">Martin Thoma</a>
                            </li>
                        </ul>
                        <ul class="nav pull-right top-menu navbar-nav">
                            <li ><a href="..">Home</a></li>
                            <li ><a href="../categories.html">Categories</a></li>
                            <li ><a href="../tags.html">Tags</a></li>
                            <li ><a href="../archives.html">Archives</a></li>
                            <li><a href="../support-me/">Support me</a></li>
                            <li><form class="navbar-form" action="../search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="search" class="search-query form-control" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row">
                <div class="col-sm-1 col-md-1"></div>
                <div class="col-sm-10 col-md-10">
<article>
<div class="row">
    <header class="page-header col-sm-10 col-md-10 col-md-offset-2">
    <h1><a href="https://towardsdatascience.com/how-twitters-image-choice-is-biased-8d3f0ba63379"> How Twitter’s Image Choice is Biase  </a></h1>
    </header>
</div>

<div class="row">
    <div class="col-sm-2 col-md-2 table-of-content">
        <nav>
        <h4>Contents</h4>
        <div id="toc"><ul><li><a class="toc-href" href="#are-white-people-shown-more-often-than-black-people-in-twitter-previews" title="Are white people shown more often than black people in Twitter previews?">Are white people shown more often than black people in Twitter previews?</a></li><li><a class="toc-href" href="#biased-data-leads-to-biased-results" title="Biased Data Leads to Biased Results">Biased Data Leads to Biased Results</a></li><li><a class="toc-href" href="#bias-and-racism" title="Bias and Racism">Bias and Racism</a></li><li><a class="toc-href" href="#what-can-we-do-against-biased-ai-products" title="What can we do against biased AI products?">What can we do against biased AI products?</a></li><li><a class="toc-href" href="#see-also" title="See also">See also</a></li></ul></div>
        </nav>
    </div>
    <div class="col-sm-8 col-md-8 article-content" id="contentAfterTitle">

            
            <p><img alt="Photo by Ravi Sharma on Unsplash" src="https://cdn-images-1.medium.com/max/10368/0*zuJRjBe7Su-ygZMJ"/><em>Photo by <a href="https://unsplash.com/@ravinepz?utm_source=medium&amp;utm_medium=referral">Ravi Sharma</a> on <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral">Unsplash</a></em></p>
<p>Twitter shows preview-images of shared images. If the aspect ratio is not the wanted one, the image needs to be cropped for the preview.</p>
<p>The way the cropping is done is supposedly not random. People seem to think that it is &ldquo;smart&rdquo; in the sense that it chooses an interesting or reasonable part of the image. Maybe a crop is chosen that maximizes clicks.</p>
<p>So far, so good. But now there is this:</p>
<iframe frameborder="0" src="https://medium.com/media/2bb8dd06753f3b0f9e91f064ac8371bc"></iframe>
<p>You might not be able to see it, but there are two times two images: One of Senator McConnell and one of the former president Obama. Twitter chose to show McConnel for both images.</p>
<p>The German comedian Abdelkarim was pointing to Twitter showing preferably blonde people:</p>
<iframe frameborder="0" src="https://medium.com/media/afc725dd42bbd294aa937786e3914e16"></iframe>
<p>There are <a href="https://twitter.com/_jsimonovski/status/1307542747197239296">many</a> <a href="https://twitter.com/JefCaine/status/1307441209338544148">tweets</a> like this. For many, the impression seems to be that this bias towards some pictures is racist.</p>
<h2 id="are-white-people-shown-more-often-than-black-people-in-twitter-previews">Are white people shown more often than black people in Twitter previews?</h2>
<p>The <a href="https://twitter.com/bascule/status/1307440596668182528">follow-up tweets</a> are for sure very interesting and indicate that there could be an issue. From an outsider&rsquo;s perspective, it&rsquo;s pretty hard to tell. Twitter certainly receives many thousands of images and creates previews for them. A reasonable objective for a company is to maximize clicks. For example, Twitter could simply change the preview image depending on the user. This would mean that Twitter tries to estimate which users click more often on which types of images. If the user clicks more often on white people, then it shows more often white people.</p>
<p>I&rsquo;m not saying that this is what happens, but it could be.</p>
<p>Let&rsquo;s assume it&rsquo;s not. Let&rsquo;s assume everybody sees the same preview images in all cases. Then you could still optimize globally for click rates. If the Twitter population clicks more often on white people, the Twitter population get&rsquo;s to see white people.</p>
<h2 id="biased-data-leads-to-biased-results">Biased Data Leads to Biased Results</h2>
<p>In 2016, the Guardian published a very related article about an AI judging beauty and preferring white people:
<a href="https://www.theguardian.com/technology/2016/sep/08/artificial-intelligence-beauty-contest-doesnt-like-black-people"><strong>A beauty contest was judged by AI and the robots didn&rsquo;t like dark skin</strong>
<em>The first international beauty contest judged by &ldquo;machines&rdquo; was supposed to use objective factors such as facial&hellip;</em>www.theguardian.com</a></p>
<p>There is a key takeaway in this article:</p>
<blockquote>
<h1 id="machine-learning-systems-need-data-if-the-data-has-issues-the-machine-learning-system-has-issues">Machine Learning systems need data. If the data has issues, the Machine Learning system has issues.</h1>
</blockquote>
<p>The AI was trained on a dataset with few black people. The generalization the machine learning algorithm took from that is that being black does not correlate well with winning this contest. Which is correct. The gap where it becomes problematic is that it was used to judge &ldquo;objective&rdquo; beauty. It&rsquo;s a machine, it can&rsquo;t be biased. Right?</p>
<h2 id="bias-and-racism">Bias and Racism</h2>
<p>This for sure is interesting trivia, but does it have a bigger effect? Is the effect of less exposure on Twitter even negative?</p>
<p>It&rsquo;s weird for sure, it should be fixed for sure. I wouldn&rsquo;t call it racist, though. In my opinion, it&rsquo;s very unlikely that some Twitter developers had the evil master plan to harm black people by preferring to show white people in case two image crops are possible. Calling this racist distracts from the <a href="https://www.theguardian.com/us-news/2020/aug/27/white-supremacists-militias-infiltrate-us-police-report">many</a> <a href="https://www.nytimes.com/2020/05/27/opinion/racism-white-women.html">real</a> <a href="https://abcnews.go.com/US/bbq-becky-golfcart-gail-list-unnecessary-911-calls/story?id=58584961">racist</a> <a href="https://en.wikipedia.org/wiki/Killing_of_George_Floyd">cases</a> we have seen in the past few months. Events where one knows that the actors were aware of the effects their actions can have. Events where the effect was death.</p>
<p>A software developer writing a slightly smarter algorithm for image cropping than just taking a random crop is not racist. If the following statement is correct, it&rsquo;s simply sloppy work.</p>
<p>I&rsquo;ve also tried this myself by uploading an image with the four Teletubbies. You could now be outraged that it shows a white-only image or just conclude that the algorithm is pretty bad:</p>
<iframe frameborder="0" src="https://medium.com/media/2a9d93a6d8cbc33b3df83c1a465f8bea"></iframe>
<h2 id="what-can-we-do-against-biased-ai-products">What can we do against biased AI products?</h2>
<p>One simple reason why the algorithm might be biased is class imbalance. This can also be combined with a mismatch of the training data compared to the production data. One class is just represented way more often in the training dataset. One technique to deal with more frequent classes is to over-sample the less frequent ones or to under-sample the more frequent ones. Meaning the algorithm gets to see the training data of the under-represented class more often.</p>
<p>Very often, it is also possible to find application-specific solutions. For example, Twitter could simply not show preview images at all. Or show a random crop. Letting the user choose the crop would also be an option. Google also chose a drastic option when they faced bias issues in a machine learning product:
<a href="https://www.theguardian.com/technology/2018/jan/12/google-racism-ban-gorilla-black-people"><strong>Google&rsquo;s solution to accidental algorithmic racism: ban gorillas</strong>
<em>After Google was criticized in 2015 for an image-recognition algorithm that auto-tagged pictures of black people as&hellip;</em>www.theguardian.com</a></p>
<p>Post-processing is another option. If you notice that two candidates for good crops both contain faces, flip a coin which face to show. You can also try to be super smart about it, recognize famous people, and rank them according to their amount of Hashtags/mentions in the last 24 hours.</p>
<p>There are way more things to consider. If you&rsquo;re interested, I encourage you to read one of the following articles.</p>
<h2 id="see-also">See also</h2>
<ul>
<li>Jiayuan Huang, Alexander J. Smola, Arthur Gretton, Karsten M. Borgwardt, Bernhard Scholkopf: <a href="https://papers.nips.cc/paper/3075-correcting-sample-selection-bias-by-unlabeled-data.pdf">Correcting Sample Selection Bias by Unlabeled Data</a></li>
<li><a href="https://www.linkedin.com/in/jaspreetsan/?originalSubdomain=fr">Jaspreet Sandhu</a>: <a href="https://towardsdatascience.com/understanding-and-reducing-bias-in-machine-learning-6565e23900ac">Understanding and Reducing Bias in Machine Learning</a></li>
<li><a href="https://www.linkedin.com/in/salma-ghoneim/">Salma Ghoneim</a>: <a href="https://towardsdatascience.com/5-types-of-bias-how-to-eliminate-them-in-your-machine-learning-project-75959af9d3a0">5 Types of bias &amp; how to eliminate them in your machine learning project</a></li>
</ul>
            
            <div id="disqus_thread" class="no-print"></div>
<script>
    /*
    var disqus_config = function () {
        this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() {  // REQUIRED CONFIGURATION VARIABLE: EDIT THE SHORTNAME BELOW
        var d = document, s = d.createElement('script');

        s.src = '//martinthoma.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

            <hr/>
        </div>
        <section>
        <div class="col-sm-2 col-md-2" style="float:right;font-size:0.9em;">
            <h4>Published</h4>
            <time pubdate="pubdate" datetime="2020-09-25T20:00:00+02:00">Sep 25, 2020</time>
            <br/>
            by <a rel="author" class="vcard author post-author" itemprop="author" href="../author/martin-thoma/"><span class="fn" itemscope="" itemtype="https://schema.org/Person"><span itemprop="name">Martin Thoma</span></span></a>
            <h4>Category</h4>
            <a class="category-link" href="../categories.html#my-bits-and-bytes-ref">My bits and bytes</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="../tags.html#artificial-intelligence-ref">Artificial Intelligence
                    <span>2</span>
</a></li>
                <li><a href="../tags.html#machine-learning-ref">Machine Learning
                    <span>81</span>
</a></li>
                <li><a href="../tags.html#social-media-ref">Social Media
                    <span>1</span>
</a></li>
                <li><a href="../tags.html#technology-ref">Technology
                    <span>2</span>
</a></li>
                <li><a href="../tags.html#twitter-ref">Twitter
                    <span>1</span>
</a></li>
            </ul>
<h4>Contact</h4>
    <a href="https://twitter.com/themoosemind" title="My Twitter Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-twitter sidebar-social-links"></i></a>
    <a href="mailto:info@martin-thoma.de" title="My Email Address" class="sidebar-social-links" target="_blank">
    <i class="fa fa-envelope sidebar-social-links"></i></a>
    <a href="https://github.com/MartinThoma" title="My Github Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-github sidebar-social-links"></i></a>
    <a href="http://stackoverflow.com/users/562769/martin-thoma" title="My Stackoverflow Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-stackoverflow sidebar-social-links"></i></a>
        </div>
        </section>
</div>
</article>
                </div>
                <div class="col-sm-1 col-md-1"></div>
            </div>
        </div>
        <div id="push"></div>
    </div>
<footer class="no-print">
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-subtitle"><span class="site-name">Martin Thoma</span> - A blog about Code, the Web and Cyberculture</li>
        <li><a href="https://martin-thoma.com/feeds/index.xml">RSS-Feed</a></li>
        <li><a href="http://www.martin-thoma.de/privacy.htm">Datenschutzerkl&auml;rung</a></li>
        <li><a href="http://www.martin-thoma.de/impressum.htm">Impressum</a></li>
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page" tabindex="-1">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page" tabindex="-1">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page" tabindex="-1">Talha Mansoor</a></li>
    </ul>
</div>
</footer>        <script src="//code.jquery.com/jquery.min.js"></script>
        <!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>
        <script>
(function(){
    'use strict';

    /*
    Create intra-page links
    Requires that your headings already have an `id` attribute set
    For every heading in your page, this adds a little anchor link `#` that you can click to get a permalink to the heading.
    Ignores `h1`, because you should only have one per page.
    The text content of the tag is used to generate the link, so it will fail "gracefully-ish" if you have duplicate heading text.

    Credit: https://gist.github.com/SimplGy/a229d25cdb19d7f21231
     */

    var headingNodes = [], results, link,
        tags = ['h2', 'h3', 'h4', 'h5', 'h6'];

    tags.forEach(function(tag){
        var contentTag = document.getElementById('contentAfterTitle');
      results = contentTag.getElementsByTagName(tag);
      Array.prototype.push.apply(headingNodes, results);
    });

    headingNodes.forEach(function(node){
      link = document.createElement('a');
      link.className = 'deepLink';
      link.textContent = ' ¶';
      link.href = '#' + node.getAttribute('id');
      node.appendChild(link);
    });

  })();
</script>
    </body>
    <!-- Theme: Elegant built for Pelican
    License : http://oncrashreboot.com/pelican-elegant -->
</html>