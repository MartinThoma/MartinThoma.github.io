<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Martin Thoma" />
        <meta name="copyright" content="Martin Thoma" />
        <link title = "Martin Thoma"
              type  = "application/opensearchdescription+xml"
              rel   = "search"
              href  = "../opensearch.xml">

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="NLP, Reuters, Classification, Machine Learning, Machine Learning, " />

<meta property="og:title" content="The Reuters Dataset "/>
<meta property="og:url" content="../nlp-reuters/" />
<meta property="og:description" content="Reuters is a benchmark dataset for document classification. To be more precise, it is a multi-class (e.g. there are multiple classes), multi-label (e.g. each document can belong to many classes) dataset. It has 90 classes, 7769 training documents and 3019 testing documents. It is the ModApte (R(90 …" />
<meta property="og:site_name" content="Martin Thoma" />
<meta property="og:article:author" content="Martin Thoma" />
<meta property="og:article:published_time" content="2017-07-27T20:00:00+02:00" />
<meta name="twitter:title" content="The Reuters Dataset ">
<meta name="twitter:description" content="Reuters is a benchmark dataset for document classification. To be more precise, it is a multi-class (e.g. there are multiple classes), multi-label (e.g. each document can belong to many classes) dataset. It has 90 classes, 7769 training documents and 3019 testing documents. It is the ModApte (R(90 …">
<meta property="og:image" content="logos/ml.png" />
<meta name="twitter:image" content="logos/ml.png" >

        <title>The Reuters Dataset  · Martin Thoma
</title>
        <!-- Latest compiled and minified CSS -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
        <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.1/css/font-awesome.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="../theme/css/pygments.css" media="screen">
        <link rel="stylesheet" type="text/css" href="../theme/tipuesearch/tipuesearch.css" media="screen">
        <link rel="stylesheet" type="text/css" href="../theme/css/elegant.css" media="screen">
        <link rel="stylesheet" type="text/css" href="../static/custom.css" media="screen">

        <!-- MathJax -->
<script type="text/x-mathjax-config">
<!--
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [ ['$$', '$$'], ['\\[','\\]']],
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
    processEscapes: true
  }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
// -->
</script>
<script type="text/javascript" async
  src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

        <link href="https://martin-thoma.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Martin Thoma - Full Atom Feed" />
        <link href="https://martin-thoma.com/feeds/index.xml" type="application/rss+xml" rel="alternate" title="Martin Thoma - Full RSS Feed" />
    </head>
    <body>
        <div id="content-sans-footer">
        <div class="navbar navbar-static-top navbar-default">
            <div class="container">
                <div class="container-fluid">
                    <div class="collapse navbar-collapse">
                        <ul class="nav pull-left top-menu navbar-nav">
                            <li><a href=".." style="font-family: 'Monaco', 'Inconsolata', 'Andale Mono', 'Lucida Console', 'Bitstream Vera Sans Mono', 'Courier New', Courier, Monospace;
                        font-size: 20px;" class="navbar-brand">Martin Thoma</a>
                            </li>
                        </ul>
                        <ul class="nav pull-right top-menu navbar-nav">
                            <li ><a href="..">Home</a></li>
                            <li ><a href="../categories.html">Categories</a></li>
                            <li ><a href="../tags.html">Tags</a></li>
                            <li ><a href="../archives.html">Archives</a></li>
                            <li><a href="../support-me/">Support me</a></li>
                            <li><form class="navbar-form" action="../search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="search" class="search-query form-control" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row">
                <div class="col-sm-1 col-md-1"></div>
                <div class="col-sm-10 col-md-10">
<article>
<div class="row">
    <header class="page-header col-sm-10 col-md-10 col-md-offset-2">
    <h1><a href="../nlp-reuters/"> The Reuters Dataset  </a></h1>
    </header>
</div>

<div class="row">
    <div class="col-sm-2 col-md-2 table-of-content">
        <nav>
        <h4>Contents</h4>
        <div id="toc"><ul><li><a class="toc-href" href="#classes-and-labels" title="Classes and Labels">Classes and Labels</a></li><li><a class="toc-href" href="#multi-label-scoring" title="Multi-label Scoring">Multi-label Scoring</a></li><li><a class="toc-href" href="#n-gram-features" title="n-gram Features">n-gram Features</a></li><li><a class="toc-href" href="#classifier-comparison-tf-idf" title="Classifier comparison (tf-idf)">Classifier comparison (tf-idf)</a><ul><li><a class="toc-href" href="#multilayer-perceptron" title="Multilayer Perceptron">Multilayer Perceptron</a></li></ul></li><li><a class="toc-href" href="#code_1" title="Code">Code</a><ul><li><a class="toc-href" href="#data-loading" title="Data loading">Data loading</a></li><li><a class="toc-href" href="#mlp" title="MLP">MLP</a></li></ul></li><li><a class="toc-href" href="#see-also_1" title="See also">See also</a></li></ul></div>
        </nav>
    </div>
    <div class="col-sm-8 col-md-8 article-content" id="contentAfterTitle">

            
            <p>Reuters is a benchmark dataset for <a href="https://martin-thoma.com/document-classification/">document classification</a>.
To be more precise, it is a multi-class (e.g. there are multiple classes),
multi-label (e.g. each document can belong to many classes) dataset.
It has <strong>90 classes</strong>, <strong>7769 training documents</strong> and <strong>3019 testing documents</strong>.
It is the ModApte (R(90)) subest of the Reuters-21578 benchmark (<a href="https://stackoverflow.com/a/25149714/562769">source</a>).</p>
<p>The mean number of words per document, grouped by class, is between 93 and 1263
on the training set.</p>
<p>The training set has a <strong>vocabulary size of 35247</strong>. Even if you restrict it to
words which appear at least 5 times and at most 12672 times in the training
set, there are still 12017 words.</p>
<h2 id="classes-and-labels">Classes and Labels</h2>
<div class="highlight"><pre><span></span>                             nr of documents   mean number of
        class name            train   test    words in train set
     1: earn                : 2877    1087    104.4
     2: acq                 : 1650     719    150.1
     3: money-fx            :  538     179    219.0
     4: grain               :  433     149    223.6
     5: crude               :  389     189    247.3
     6: trade               :  368     117    294.3
     7: interest            :  347     131    198.0
     8: wheat               :  212      71    225.6
     9: ship                :  197      89    203.7
    10: corn                :  181      56    259.1
    11: money-supply        :  140      34    170.5
    12: dlr                 :  131      44    230.4
    13: sugar               :  126      36    247.2
    14: oilseed             :  124      47    277.9
    15: coffee              :  111      28    264.1
    16: gnp                 :  101      35    372.8
    17: gold                :   94      30    188.5
    18: veg-oil             :   87      37    291.0
    19: soybean             :   78      33    347.9
    20: livestock           :   75      24    222.9
    21: nat-gas             :   75      30    257.7
    22: bop                 :   75      30    288.1
    23: cpi                 :   69      28    235.4
    24: cocoa               :   55      18    266.4
    25: reserves            :   55      18    216.1
    26: carcass             :   50      18    259.7
    27: copper              :   47      18    201.6
    28: jobs                :   46      21    232.7
    29: yen                 :   45      14    282.8
    30: ipi                 :   41      12    232.1
    31: iron-steel          :   40      14    220.5
    32: cotton              :   39      20    366.3
    33: barley              :   37      14    272.9
    34: gas                 :   37      17    209.4
    35: rubber              :   37      12    274.5
    36: alum                :   35      23    180.5
    37: rice                :   35      24    359.8
    38: palm-oil            :   30      10    234.5
    39: meal-feed           :   30      19    387.1
    40: sorghum             :   24      10    511.3
    41: retail              :   23       2    324.8
    42: zinc                :   21      13    189.9
    43: silver              :   21       8    221.0
    44: pet-chem            :   20      12    204.9
    45: wpi                 :   19      10    200.9
    46: tin                 :   18      12    322.1
    47: rapeseed            :   18       9    168.6
    48: orange              :   16      11    169.6
    49: strategic-metal     :   16      11    205.6
    50: housing             :   16       4    207.2
    51: hog                 :   16       6    162.3
    52: lead                :   15      14    216.7
    53: soy-oil             :   14      11    568.7
    54: heat                :   14       5    190.4
    55: fuel                :   13      10    194.6
    56: soy-meal            :   13      13    551.0
    57: lei                 :   12       3    134.7
    58: sunseed             :   11       5    425.1
    59: dmk                 :   10       4    212.1
    60: lumber              :   10       6    242.1
    61: tea                 :    9       4    365.1
    62: income              :    9       7    286.4
    63: nickel              :    8       1    193.6
    64: oat                 :    8       6    648.4
    65: l-cattle            :    6       2    298.0
    66: instal-debt         :    5       1    134.3
    67: platinum            :    5       7    174.8
    68: groundnut           :    5       4    258.0
    69: rape-oil            :    5       3    167.2
    70: sun-oil             :    5       2    201.9
    71: coconut-oil         :    4       3    471.4
    72: jet                 :    4       1    109.6
    73: coconut             :    4       2    264.5
    74: propane             :    3       3    352.0
    75: potato              :    3       3    161.2
    76: cpu                 :    3       1    133.2
    77: rand                :    2       1    345.7
    78: palmkernel          :    2       1    326.3
    79: copra-cake          :    2       1    495.0
    80: dfl                 :    2       1    764.7
    81: naphtha             :    2       4    206.7
    82: palladium           :    2       1    93.0
    83: nzdlr               :    2       2    508.8
    84: groundnut-oil       :    1       1    277.5
    85: castor-oil          :    1       1    194.0
    86: sun-meal            :    1       1    153.0
    87: lin-oil             :    1       1    262.5
    88: cotton-oil          :    1       2    1262.7
    89: rye                 :    1       1    383.0
    90: nkr                 :    1       2    122.3
</pre></div>
<p>By far most documents have either one or two labels, but some have up to 15:</p>
<div class="highlight"><pre><span></span>labelcount= 1, documentcount=9160
labelcount= 2, documentcount=1173
labelcount= 3, documentcount= 255
labelcount= 4, documentcount=  91
labelcount= 5, documentcount=  52
labelcount= 6, documentcount=  27
labelcount= 7, documentcount=   9
labelcount= 8, documentcount=   7
labelcount= 9, documentcount=   5
labelcount=10, documentcount=   3
labelcount=11, documentcount=   2
labelcount=14, documentcount=   2
labelcount=12, documentcount=   1
labelcount=15, documentcount=   1
</pre></div>
<p>Let's look at the relationship between the classes. Which classes occur often
together? Are there classes which can be used to predict the presence of other
classes? For example, <code>wheat</code> should imply <code>grain</code>.</p>
<p>Here are the 50 strongest predictors:</p>
<div class="highlight"><pre><span></span>castor-oil =&gt; cotton-oil (0.999742566611)
castor-oil =&gt; groundnut-oil (0.999742566611)
castor-oil =&gt; lin-oil (0.999742566611)
castor-oil =&gt; nkr (0.999742566611)
castor-oil =&gt; rye (0.999742566611)
castor-oil =&gt; sun-meal (0.999742566611)
copra-cake =&gt; palmkernel (0.999742566611)
cotton-oil =&gt; castor-oil (0.999742566611)
cotton-oil =&gt; groundnut-oil (0.999742566611)
cotton-oil =&gt; lin-oil (0.999742566611)
cotton-oil =&gt; nkr (0.999742566611)
cotton-oil =&gt; rye (0.999742566611)
cotton-oil =&gt; sun-meal (0.999742566611)
groundnut-oil =&gt; castor-oil (0.999742566611)
groundnut-oil =&gt; cotton-oil (0.999742566611)
groundnut-oil =&gt; lin-oil (0.999742566611)
groundnut-oil =&gt; nkr (0.999742566611)
groundnut-oil =&gt; rye (0.999742566611)
groundnut-oil =&gt; sun-meal (0.999742566611)
lin-oil =&gt; castor-oil (0.999742566611)
lin-oil =&gt; cotton-oil (0.999742566611)
lin-oil =&gt; groundnut-oil (0.999742566611)
lin-oil =&gt; nkr (0.999742566611)
lin-oil =&gt; rye (0.999742566611)
lin-oil =&gt; sun-meal (0.999742566611)
nkr =&gt; castor-oil (0.999742566611)
nkr =&gt; cotton-oil (0.999742566611)
nkr =&gt; groundnut-oil (0.999742566611)
nkr =&gt; lin-oil (0.999742566611)
nkr =&gt; rye (0.999742566611)
nkr =&gt; sun-meal (0.999742566611)
palmkernel =&gt; copra-cake (0.999742566611)
rye =&gt; castor-oil (0.999742566611)
rye =&gt; cotton-oil (0.999742566611)
rye =&gt; groundnut-oil (0.999742566611)
rye =&gt; lin-oil (0.999742566611)
rye =&gt; nkr (0.999742566611)
rye =&gt; sun-meal (0.999742566611)
sun-meal =&gt; castor-oil (0.999742566611)
sun-meal =&gt; cotton-oil (0.999742566611)
sun-meal =&gt; groundnut-oil (0.999742566611)
sun-meal =&gt; lin-oil (0.999742566611)
sun-meal =&gt; nkr (0.999742566611)
sun-meal =&gt; rye (0.999742566611)
castor-oil =&gt; copra-cake (0.999613849916)
castor-oil =&gt; dfl (0.999613849916)
castor-oil =&gt; naphtha (0.999613849916)
castor-oil =&gt; nzdlr (0.999613849916)
castor-oil =&gt; palladium (0.999613849916)
castor-oil =&gt; palmkernel (0.999613849916)
</pre></div>
<h2 id="multi-label-scoring">Multi-label Scoring</h2>
<div class="warning">I have to work on the scoring; it seems as if I made a mistake in my experiments when I calculated the score.</div>
<p>I've never been in a multi-label context, so it was not directly clear to me
which scoring is used. Thanks to Chirag Nagpal who pointed me in the right
direction.</p>
<p>Let <span class="math">\(Y_i \in \{0, 1\}^k\)</span> be the set of correct labels for document <span class="math">\(i\)</span> and
<span class="math">\(Z_i \in \{0, 1\}^k\)</span> be the set of predicted labels:</p>
<ul>
<li><strong>Binary Accuracy</strong>: For each document, one has to make a decision for each possible
  category. Hence <span class="math">\(\text{acc} = \frac{1}{n}\sum_{i=1}^n \frac{|Y_i \cap Z_i|}{k}\)</span>. As most documents belong to one or two categories, the simplest
  classifier simply decides all the time that the document does not belong to
  any category. For the used dataset, this leads to an accuracy of 0.986. Hence
  accuracy is not suitable.</li>
<li><strong>Subset Accuracy</strong>: This is calculated by <code>sklearn</code>. The set of predicted
  labels must be exactly the same as the true labels.</li>
<li><strong>F1 score</strong>: See <a href="http://scikit-learn.org/stable/modules/model_evaluation.html#precision-recall-f-measure-metrics">user manual</a></li>
<li>Micro/macro averaged ROC or Precision/Recall curve:<ul>
<li>Micro: Calculate metrics globally by counting the total true positives,
  false negatives and false positives.</li>
<li>Macro: Calculate metrics for each label, and find their unweighted mean.
  This does not take label imbalance into account.</li>
</ul>
</li>
<li>Coverage error: See <a href="http://scikit-learn.org/stable/modules/model_evaluation.html#coverage-error">user manual</a></li>
</ul>
<p>A nice overview is given by <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.364.5612&amp;rep=rep1&amp;type=pdf#page=13">A Literature Survey on Algorithms for Multi-label Learning</a>.</p>
<h2 id="n-gram-features">n-gram Features</h2>
<p>See <a href="http://blog.alejandronolla.com/2013/05/20/n-gram-based-text-categorization-categorizing-text-with-python/">N-Gram-Based Text Categorization: Categorizing Text With Python</a>.</p>
<p>I will give this a try when I find some time. If you make it before, please
share the results. You could adjust <a href="https://github.com/MartinThoma/algorithms/blob/master/ML/nlp/reuters.py#L30">my tf-idf code</a>.</p>
<h2 id="classifier-comparison-tf-idf">Classifier comparison (tf-idf)</h2>
<p>The following are the accuracies as well as the training and test times. All
classifiers got the same tf-idf features.</p>
<div class="highlight"><pre><span></span>Used vocabulary size = 26147

Classifier                      Acc     F1
--------------------------------------------------------------------------------
MLP                           : 82.61% 85.56% in  676.44s train /    0.91s test
LinearSVC                     : 81.05% 84.04% in   27.00s train /    6.45s test
Logistic Regression (C=1000)  : 80.79% 84.10% in   35.48s train /    6.46s test
k nn 5                        : 72.97% 76.07% in    9.89s train / 1092.29s test
k nn 3                        : 72.28% 75.43% in    9.90s train / 1080.20s test
Logistic Regression (C=1)     : 67.47% 67.21% in   30.22s train /    6.44s test
Random Forest (200 estimators): 65.75% 64.36% in   57.56s train /    4.15s test
Random Forest (50 estimators) : 64.79% 63.69% in   14.82s train /    1.30s test
Decision Tree                 : 55.75% 53.23% in   28.43s train /    0.22s test
Naive Bayes                   : 43.86% 47.98% in  214.75s train /   88.79s test
SVM, linear                   : 33.55% 29.67% in 6326.33s train / 2397.51s test
</pre></div>
<p>There are a couple of things to notice here:</p>
<ul>
<li><strong>Speed</strong>:<ul>
<li>Naive Bayes and k-nn is slow</li>
<li>Random forests and MLP are fast</li>
<li>SVM depends extremely on the implementation (see <a href="https://stackoverflow.com/q/45384185/562769">What is the difference between LinearSVC and SVC(kernel=&ldquo;linear&rdquo;)?</a>)</li>
</ul>
</li>
<li><strong>Prediction Quality</strong>:<ul>
<li>LinearSVC, logistic regression and MLP are accurate</li>
<li>Achieving high binary accuracy seems to be easier than achieving high F1
  scores. It's no surprise that high subset accuracy is hard to achieve.</li>
</ul>
</li>
</ul>
<p>The MLP has a reasonable prediction quality and test time.</p>
<h3 id="multilayer-perceptron">Multilayer Perceptron</h3>
<p>When training a multilayer perceptron for a multi-label classification task, there
are two important things to keep in mind:</p>
<ul>
<li><strong>Output layer</strong>: Do not  use softmax, as the normalization does not make
  sense in this case.</li>
<li><strong>Loss</strong>: Use <a href="https://keras.io/losses/#binary_crossentropy"><code>`binary_crossentropy</code></a></li>
</ul>
<p>When you print precision, recall, F1-score and accuracy you note the following:</p>
<ul>
<li>Binary accuracy gets to 98% in the first epoch and over 99% in the second. It stays
  that high.</li>
<li>Precision is at about 4% in the first epoch and over 97% in the second. It
  stays that high.</li>
<li>Recall needs about 15 epochs of steady progress to get over 98%.</li>
</ul>
<p>As a consequence, the F1 score steadily increases. Hence by using other metrics
one can see that the classifier makes great improvements, although the accuracy
is pretty high from the beginning.</p>
<h2 id="code_1">Code</h2>
<p>See <a href="https://github.com/MartinThoma/algorithms/blob/master/ML/nlp/">GitHub</a>.</p>
<p>If you use it, please cite this article or link to this blog post:</p>
<div class="highlight"><pre><span></span>@Misc{Thom2017-reuters,
  Title                    = {The Reuters Dataset},

  Author                   = {Martin Thoma},
  Month                    = jul,
  Year                     = {2017},

  Url                      = {https://martin-thoma.com/nlp-reuters}
}
</pre></div>
<h3 id="data-loading">Data loading</h3>
<div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python</span>
<span class="c1"># -*- coding: utf-8 -*-</span>

<span class="sd">"""</span>
<span class="sd">Utility file for the Reuters text categorization benchmark dataset.</span>

<span class="sd">See also</span>
<span class="sd">--------</span>
<span class="sd">http://www.vision.caltech.edu/Image_Datasets/Caltech101/</span>
<span class="sd">"""</span>

<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">reuters</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MultiLabelBinarizer</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>

<span class="n">n_classes</span> <span class="o">=</span> <span class="mi">90</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">reuters</span><span class="o">.</span><span class="n">categories</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="p">{}):</span>
    <span class="sd">"""</span>
<span class="sd">    Load the Reuters dataset.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.</span>
<span class="sd">    """</span>
    <span class="n">stop_words</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s2">"english"</span><span class="p">)</span>
    <span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="n">stop_words</span><span class="p">)</span>
    <span class="n">mlb</span> <span class="o">=</span> <span class="n">MultiLabelBinarizer</span><span class="p">()</span>

    <span class="n">documents</span> <span class="o">=</span> <span class="n">reuters</span><span class="o">.</span><span class="n">fileids</span><span class="p">()</span>
    <span class="n">test</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">documents</span> <span class="k">if</span> <span class="n">d</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">'test/'</span><span class="p">)]</span>
    <span class="n">train</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">documents</span> <span class="k">if</span> <span class="n">d</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">'training/'</span><span class="p">)]</span>

    <span class="n">docs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">docs</span><span class="p">[</span><span class="s1">'train'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">reuters</span><span class="o">.</span><span class="n">raw</span><span class="p">(</span><span class="n">doc_id</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc_id</span> <span class="ow">in</span> <span class="n">train</span><span class="p">]</span>
    <span class="n">docs</span><span class="p">[</span><span class="s1">'test'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">reuters</span><span class="o">.</span><span class="n">raw</span><span class="p">(</span><span class="n">doc_id</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc_id</span> <span class="ow">in</span> <span class="n">test</span><span class="p">]</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'train'</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">'test'</span><span class="p">:</span> <span class="p">[]}</span>
    <span class="n">xs</span><span class="p">[</span><span class="s1">'train'</span><span class="p">]</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">[</span><span class="s1">'train'</span><span class="p">])</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
    <span class="n">xs</span><span class="p">[</span><span class="s1">'test'</span><span class="p">]</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">docs</span><span class="p">[</span><span class="s1">'test'</span><span class="p">])</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'train'</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">'test'</span><span class="p">:</span> <span class="p">[]}</span>
    <span class="n">ys</span><span class="p">[</span><span class="s1">'train'</span><span class="p">]</span> <span class="o">=</span> <span class="n">mlb</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">([</span><span class="n">reuters</span><span class="o">.</span><span class="n">categories</span><span class="p">(</span><span class="n">doc_id</span><span class="p">)</span>
                                     <span class="k">for</span> <span class="n">doc_id</span> <span class="ow">in</span> <span class="n">train</span><span class="p">])</span>
    <span class="n">ys</span><span class="p">[</span><span class="s1">'test'</span><span class="p">]</span> <span class="o">=</span> <span class="n">mlb</span><span class="o">.</span><span class="n">transform</span><span class="p">([</span><span class="n">reuters</span><span class="o">.</span><span class="n">categories</span><span class="p">(</span><span class="n">doc_id</span><span class="p">)</span>
                                <span class="k">for</span> <span class="n">doc_id</span> <span class="ow">in</span> <span class="n">test</span><span class="p">])</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'x_train'</span><span class="p">:</span> <span class="n">xs</span><span class="p">[</span><span class="s1">'train'</span><span class="p">],</span> <span class="s1">'y_train'</span><span class="p">:</span> <span class="n">ys</span><span class="p">[</span><span class="s1">'train'</span><span class="p">],</span>
            <span class="s1">'x_test'</span><span class="p">:</span> <span class="n">xs</span><span class="p">[</span><span class="s1">'test'</span><span class="p">],</span> <span class="s1">'y_test'</span><span class="p">:</span> <span class="n">ys</span><span class="p">[</span><span class="s1">'test'</span><span class="p">],</span>
            <span class="s1">'labels'</span><span class="p">:</span> <span class="nb">globals</span><span class="p">()[</span><span class="s2">"labels"</span><span class="p">]}</span>
    <span class="k">return</span> <span class="n">data</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">'__main__'</span><span class="p">:</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">"len(data['x_train'])={}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">'x_train'</span><span class="p">])))</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">"data['x_train'].shape={}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">'x_train'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
<h3 id="mlp">MLP</h3>
<div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env python</span>

<span class="sd">"""Train and evaluate a MLP."""</span>

<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">import</span> <span class="nn">reuters</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="kn">from</span> <span class="nn">scoring</span> <span class="kn">import</span> <span class="n">get_tptnfpfn</span><span class="p">,</span> <span class="n">get_accuracy</span><span class="p">,</span> <span class="n">get_f_score</span>


<span class="k">def</span> <span class="nf">create_model</span><span class="p">(</span><span class="n">nb_classes</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
    <span class="sd">"""Create a MLP model."""</span>
    <span class="n">input_</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">input_</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">nb_classes</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">'sigmoid'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">input_</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">recall</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Recall metric.</span>

<span class="sd">    Only computes a batch-wise average of recall.</span>

<span class="sd">    Computes the recall, a metric for multi-label classification of</span>
<span class="sd">    how many relevant items are selected.</span>
<span class="sd">    """</span>
    <span class="n">true_positives</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">y_true</span> <span class="o">*</span> <span class="n">y_pred</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="n">possible_positives</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="n">recall</span> <span class="o">=</span> <span class="n">true_positives</span> <span class="o">/</span> <span class="p">(</span><span class="n">possible_positives</span> <span class="o">+</span> <span class="n">K</span><span class="o">.</span><span class="n">epsilon</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">recall</span>


<span class="k">def</span> <span class="nf">precision</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Precision metric.</span>

<span class="sd">    Only computes a batch-wise average of precision.</span>

<span class="sd">    Computes the precision, a metric for multi-label classification of</span>
<span class="sd">    how many selected items are relevant.</span>

<span class="sd">    Source</span>
<span class="sd">    ------</span>
<span class="sd">    https://github.com/fchollet/keras/issues/5400#issuecomment-314747992</span>
<span class="sd">    """</span>
    <span class="n">true_positives</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">y_true</span> <span class="o">*</span> <span class="n">y_pred</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="n">predicted_positives</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">true_positives</span> <span class="o">/</span> <span class="p">(</span><span class="n">predicted_positives</span> <span class="o">+</span> <span class="n">K</span><span class="o">.</span><span class="n">epsilon</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">precision</span>


<span class="k">def</span> <span class="nf">f1</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="sd">"""Calculate the F1 score."""</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">precision</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">recall</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">((</span><span class="n">p</span> <span class="o">*</span> <span class="n">r</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">p</span> <span class="o">+</span> <span class="n">r</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">get_optimizer</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
    <span class="sd">"""Return an optimizer."""</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'optimizer'</span><span class="p">][</span><span class="s1">'initial_lr'</span><span class="p">]</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>  <span class="c1"># Using Adam instead of SGD to speed up training</span>
    <span class="k">return</span> <span class="n">optimizer</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">data_module</span><span class="p">):</span>
    <span class="sd">"""Load data, train model and evaluate it."""</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data_module</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="n">data_module</span><span class="o">.</span><span class="n">n_classes</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">'x_train'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">get_optimizer</span><span class="p">({</span><span class="s1">'optimizer'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'initial_lr'</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">}})</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span>
                  <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">f1</span><span class="p">,</span> <span class="s2">"accuracy"</span><span class="p">])</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">'x_train'</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">'y_train'</span><span class="p">],</span>
              <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
              <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
              <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">'x_test'</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">'y_test'</span><span class="p">]),</span>
              <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
              <span class="c1"># callbacks=callbacks</span>
              <span class="p">)</span>
    <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">get_tptnfpfn</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
    <span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">print</span><span class="p">((</span><span class="s2">"{clf_name:&lt;30}: {acc:0.2f}% {f1:0.2f}</span><span class="si">% i</span><span class="s2">n {train_time:0.2f}s "</span>
           <span class="s2">"train / {test_time:0.2f}s test"</span><span class="p">)</span>
          <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">clf_name</span><span class="o">=</span><span class="s2">"MLP"</span><span class="p">,</span>
                  <span class="n">acc</span><span class="o">=</span><span class="p">(</span><span class="n">get_accuracy</span><span class="p">(</span><span class="n">res</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">),</span>
                  <span class="n">f1</span><span class="o">=</span><span class="p">(</span><span class="n">get_f_score</span><span class="p">(</span><span class="n">res</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">),</span>
                  <span class="n">train_time</span><span class="o">=</span><span class="p">(</span><span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span><span class="p">),</span>
                  <span class="n">test_time</span><span class="o">=</span><span class="p">(</span><span class="n">t2</span> <span class="o">-</span> <span class="n">t1</span><span class="p">)))</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">'__main__'</span><span class="p">:</span>
    <span class="n">main</span><span class="p">(</span><span class="n">reuters</span><span class="p">)</span>
</pre></div>
<h2 id="see-also_1">See also</h2>
<ul>
<li>NLTK: <a href="http://www.nltk.org/book/ch02.html">Other datasets</a></li>
<li><a href="http://www.daviddlewis.com/resources/testcollections/reuters21578/">Reuters-21578</a></li>
<li>Publications:<ul>
<li><a href="http://www.cs.cornell.edu/people/tj/publications/joachims_98a.pdf">Text Categorization with Support Vector Machines: Learning with Many Relevant Features</a></li>
</ul>
</li>
<li>Blog posts:<ul>
<li>Miguel Malvarez: <a href="https://miguelmalvarez.com/2015/03/20/classifying-reuters-21578-collection-with-python-representing-the-data/">Classifying Reuters-21578 collection with Python: Representing the data</a></li>
<li>Miguel Malvarez: <a href="https://miguelmalvarez.com/2016/11/07/classifying-reuters-21578-collection-with-python/">Classifying Reuters-21578 collection with Python</a></li>
</ul>
</li>
</ul>
            
            <div id="disqus_thread"></div>
<script>
    /*
    var disqus_config = function () {
        this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() {  // REQUIRED CONFIGURATION VARIABLE: EDIT THE SHORTNAME BELOW
        var d = document, s = d.createElement('script');

        s.src = '//martinthoma.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

            <hr/>
        </div>
        <section>
        <div class="col-sm-2 col-md-2" style="float:right;font-size:0.9em;">
            <h4>Published</h4>
            <time pubdate="pubdate" datetime="2017-07-27T20:00:00+02:00">Jul 27, 2017</time>
            <br/>
            by <a rel="author" class="vcard author post-author" itemprop="author" href="../author/martin-thoma/"><span class="fn" itemscope="" itemtype="https://schema.org/Person"><span itemprop="name">Martin Thoma</span></span></a>
            <h4>Category</h4>
            <a class="category-link" href="../categories.html#machine-learning-ref">Machine Learning</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="../tags.html#classification-ref">Classification
                    <span>6</span>
</a></li>
                <li><a href="../tags.html#machine-learning-ref">Machine Learning
                    <span>59</span>
</a></li>
                <li><a href="../tags.html#nlp-ref">NLP
                    <span>3</span>
</a></li>
                <li><a href="../tags.html#reuters-ref">Reuters
                    <span>1</span>
</a></li>
            </ul>
<h4>Contact</h4>
    <a href="https://twitter.com/themoosemind" title="My Twitter Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-twitter sidebar-social-links"></i></a>
    <a href="mailto:info@martin-thoma.de" title="My Email Address" class="sidebar-social-links" target="_blank">
    <i class="fa fa-envelope sidebar-social-links"></i></a>
    <a href="https://github.com/MartinThoma" title="My Github Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-github sidebar-social-links"></i></a>
    <a href="http://stackoverflow.com/users/562769/martin-thoma" title="My Stackoverflow Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-stackoverflow sidebar-social-links"></i></a>
        </div>
        </section>
</div>
</article>
                </div>
                <div class="col-sm-1 col-md-1"></div>
            </div>
        </div>
        <div id="push"></div>
    </div>
<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-subtitle"><span class="site-name">Martin Thoma</span> - A blog about Code, the Web and Cyberculture</li>
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page">Talha Mansoor</a></li>
    </ul>
</div>
</footer>        <script src="//code.jquery.com/jquery.min.js"></script>
        <!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>
        <script>
(function(){
    'use strict';

    /*
    Create intra-page links
    Requires that your headings already have an `id` attribute set (because that's what jekyll does)
    For every heading in your page, this adds a little anchor link `#` that you can click to get a permalink to the heading.
    Ignores `h1`, because you should only have one per page.
    The text content of the tag is used to generate the link, so it will fail "gracefully-ish" if you have duplicate heading text.

    Credit: https://gist.github.com/SimplGy/a229d25cdb19d7f21231
     */

    var headingNodes = [], results, link,
        tags = ['h2', 'h3', 'h4', 'h5', 'h6'];

    tags.forEach(function(tag){
        var contentTag = document.getElementById('contentAfterTitle');
      results = contentTag.getElementsByTagName(tag);
      Array.prototype.push.apply(headingNodes, results);
    });

    headingNodes.forEach(function(node){
      link = document.createElement('a');
      link.className = 'deepLink';
      link.textContent = ' ¶';
      link.href = '#' + node.getAttribute('id');
      node.appendChild(link);
    });

  })();
</script>
    </body>
    <!-- Theme: Elegant built for Pelican
    License : http://oncrashreboot.com/pelican-elegant -->
</html>