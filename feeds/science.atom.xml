<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Martin Thoma - Science</title><link href="https://martin-thoma.com/" rel="alternate"></link><link href="https://martin-thoma.com/feeds/science.atom.xml" rel="self"></link><id>https://martin-thoma.com/</id><updated>2017-01-11T20:00:00+01:00</updated><entry><title>Paper List</title><link href="https://martin-thoma.com/paper-list/" rel="alternate"></link><published>2017-01-11T20:00:00+01:00</published><updated>2017-01-11T20:00:00+01:00</updated><author><name>Martin Thoma</name></author><id>tag:martin-thoma.com,2017-01-11:/paper-list/</id><summary type="html">&lt;p&gt;The following includes my reading list and a list of papers organized in tracks
which I can recommend to read. Most (all?) of them are about machine learning
and neural networks.&lt;/p&gt;
&lt;h2 id="reading-list"&gt;Reading List&lt;/h2&gt;
&lt;p&gt;I am aware of the following papers and I want to read them ... when I have time …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The following includes my reading list and a list of papers organized in tracks
which I can recommend to read. Most (all?) of them are about machine learning
and neural networks.&lt;/p&gt;
&lt;h2 id="reading-list"&gt;Reading List&lt;/h2&gt;
&lt;p&gt;I am aware of the following papers and I want to read them ... when I have time:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1610.09716v1"&gt;Doubly Convolutional Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1602.03616"&gt;Multifaceted Feature Visualization: Uncovering the Different Types of Features Learned By Each Neuron in Deep Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ieeexplore.ieee.org/document/7404017/?arnumber=7404017"&gt;Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1606.02492"&gt;Convolutional Neural Fabrics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.mitpressjournals.org/doi/abs/10.1162/106365602320169811"&gt;Evolving Neural Networks through Augmenting Topologies&lt;/a&gt; and &lt;a href="http://ieeexplore.ieee.org/document/6792316/"&gt;A Hypercube-Based Encoding for Evolving Large-Scale Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="best-of"&gt;Best of&lt;/h2&gt;
&lt;p&gt;The following is a list of papers, organized by the year I read (or written)
them. Not when they were published.&lt;/p&gt;
&lt;h3 id="2016"&gt;2016&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Lipton, Z.C., 2016. &lt;a href="http://zacklipton.com/media/papers/mythos_model_interpretability_lipton2016.pdf"&gt;The Mythos of Model Interpretability&lt;/a&gt;. IEEE Spectrum. (&lt;a href="http://www.shortscience.org/paper?bibtexKey=journals/corr/1606.03490"&gt;summary&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Zhang, C., Bengio, S., Hardt, M., Recht, B. and Vinyals, O., 2016. &lt;a href="https://arxiv.org/abs/1611.03530"&gt;Understanding deep learning requires rethinking generalization&lt;/a&gt;. arXiv preprint arXiv:1611.03530. (&lt;a href="http://www.shortscience.org/paper?bibtexKey=journals%2Fcorr%2F1611.03530"&gt;summary&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://papers.nips.cc/paper/6112-deep-learning-without-poor-local-minima"&gt;Deep Learning without Poor Local Minima&lt;/a&gt; and &lt;a href="https://papers.nips.cc/paper/6048-matrix-completion-has-no-spurious-local-minimum.pdf"&gt;Matrix Completion has No Spurious Local Minimum&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="tracks_1"&gt;Tracks&lt;/h2&gt;
&lt;h3 id="weight-initialization"&gt;Weight Initialization&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;X. Glorot and Y. Bengio, &amp;ldquo;&lt;a href="http://www.jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf?hc_location=ufi"&gt;Understanding the difficulty of training deep feedforward neural networks&lt;/a&gt;.&amp;rdquo; in Aistats, vol. 9, 2010, pp. 249&amp;ndash;256. (&lt;a href="http://www.shortscience.org/paper?bibtexKey=journals/jmlr/GlorotB10"&gt;summary&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;A. M. Saxe, J. L. McClelland, and S. Ganguli, &amp;ldquo;&lt;a href="https://arxiv.org/abs/1312.6120"&gt;Exact solutions to
the nonlinear dynamics of learning in deep linear neural networks&lt;/a&gt;,&amp;rdquo;
arXiv preprint arXiv:1312.6120, Dec. 2013. (&lt;a href="http://www.shortscience.org/paper?bibtexKey=journals/corr/1312.6120"&gt;summary&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;K. He, X. Zhang, S. Ren, and J. Sun, &amp;ldquo;&lt;a href="https://arxiv.org/abs/1502.01852"&gt;Delving deep into rectifiers: Surpassing human-level performance
on imagenet classification&lt;/a&gt;,&amp;rdquo; in Proceedings of the IEEE International
Conference on Computer Vision, Feb. 2015, pp. 1026&amp;ndash;1034. (&lt;a href="http://www.shortscience.org/paper?bibtexKey=journals/corr/1502.01852"&gt;summary&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;D. Mishkin and J. Matas, &amp;ldquo;&lt;a href="https://arxiv.org/abs/1511.06422"&gt;All you need is a good init&lt;/a&gt;,&amp;rdquo; arXiv
preprint arXiv:1511.06422,
Nov. 2015. (&lt;a href="http://www.shortscience.org/paper?bibtexKey=journals/corr/MishkinM15"&gt;summary&lt;/a&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="ideas_1"&gt;Ideas&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Establishing Human-Level scores for Benchmarks&lt;ul&gt;
&lt;li&gt;User Interfaces: What are good examples?&lt;/li&gt;
&lt;li&gt;Herarchical Classification&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pooling: Can it be replaced by convolutions?&lt;/li&gt;
&lt;li&gt;Ensembles: Train an ensemble, use it to get better labels than simple one-hot encoding, train new single network on new labels. (Possibly the same as &lt;a href="https://arxiv.org/abs/1503.02531"&gt;Distilling the Knowledge in a Neural Network&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;OCR and semantic segmentation&lt;/li&gt;
&lt;/ul&gt;</content><category term="Science"></category><category term="Papers"></category><category term="Reading"></category><category term="Academia"></category><category term="Computer Science"></category></entry><entry><title>Tools for Academia</title><link href="https://martin-thoma.com/tools-for-academia/" rel="alternate"></link><published>2016-05-17T20:00:00+02:00</published><updated>2016-05-17T20:00:00+02:00</updated><author><name>Martin Thoma</name></author><id>tag:martin-thoma.com,2016-05-17:/tools-for-academia/</id><summary type="html">&lt;p&gt;When you're studying or researching, there a quite a couple of tools which come
in very handy in various situations. In the last 5&amp;nbsp;years at university I
got to know quite a few, so I want to share my list with you.&lt;/p&gt;
&lt;h2 id="discovery"&gt;Discovery&lt;/h2&gt;
&lt;p&gt;Sometimes, I just like to stumble …&lt;/p&gt;</summary><content type="html">&lt;p&gt;When you're studying or researching, there a quite a couple of tools which come
in very handy in various situations. In the last 5&amp;nbsp;years at university I
got to know quite a few, so I want to share my list with you.&lt;/p&gt;
&lt;h2 id="discovery"&gt;Discovery&lt;/h2&gt;
&lt;p&gt;Sometimes, I just like to stumble around some papers. I'm not actively
searching anything, but just looking for something interesting. In my field
of research, &lt;a href="http://gitxiv.com/"&gt;gitxiv.com&lt;/a&gt; is really interesting for that.
But also the &lt;a href="http://arxiv.org/list/cs.CV/recent"&gt;recent papers at arXiv&lt;/a&gt;
and &lt;a href="https://trendingarxiv.smerity.com/"&gt;trendingarxiv&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I know that a couple of people recently liked
&lt;a href="http://arxitics.com/"&gt;arxitics.com&lt;/a&gt; and
&lt;a href="http://control.kylemcdonald.net/arxiv/"&gt;control.kylemcdonald.net/arxiv&lt;/a&gt;, but
I'm not using that too much.&lt;/p&gt;
&lt;p&gt;See also: &lt;a href="https://martin-thoma.com/how-to-find-new-papers/"&gt;How to find new Papers&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="search"&gt;Search&lt;/h2&gt;
&lt;p&gt;When I'm actively searching for papers where you know keywords,
&lt;a href="https://scholar.google.de/"&gt;scholar.google.com&lt;/a&gt; is the search engine of my
choice. &lt;a href="https://academic.microsoft.com"&gt;academic.microsoft.com&lt;/a&gt; could be
an interesting alternative.&lt;/p&gt;
&lt;h2 id="summaries-and-explanations"&gt;Summaries and Explanations&lt;/h2&gt;
&lt;p&gt;A site which I discovered in the beginning of 2016 is
&lt;a href="http://www.shortscience.org/"&gt;shortscience.org&lt;/a&gt;. It gives you the possibility
to save and share your summaries of papers. Have a look at
&lt;a href="http://www.shortscience.org/user?name=MartinThoma"&gt;my profile&lt;/a&gt; if you're
interested. The service is still in its early stages, but I like it very much.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.scholarpedia.org/article/Main_Page"&gt;Scholarpedia.org&lt;/a&gt; is a site
where you can finde some high-quality explanations. If I remember right, Hinton
wrote some articles on Scholarpedia.&lt;/p&gt;
&lt;p&gt;Of course, Wikipedia is always an option to get introduced to basics.&lt;/p&gt;
&lt;h2 id="writing"&gt;Writing&lt;/h2&gt;
&lt;p&gt;I do the actual writing with &lt;a href="https://martin-thoma.com/sublime-text/"&gt;Sublime Text&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="typesetting"&gt;Typesetting&lt;/h3&gt;
&lt;p&gt;The typesetting system of my choice is
&lt;a href="https://en.wikipedia.org/wiki/LaTeX"&gt;LaTeX&lt;/a&gt;. It produces beautiful results,
especially for mathematical formulae. A couple of years ago I wrote some
&lt;a href="https://martin-thoma.com/how-to-install-the-latest-latex-version/"&gt;installation instructions&lt;/a&gt;.
If you need help with something specific,
&lt;a href="http://tex.stackexchange.com/"&gt;tex.stackexchange.com&lt;/a&gt; is really nice.&lt;/p&gt;
&lt;p&gt;If you're only looking for a symbol to write with LaTeX, I can recommend
&lt;a href="http://write-math.com"&gt;write-math.com&lt;/a&gt;.
&lt;a href="http://tex.stackexchange.com/q/14/5645"&gt;Other options&lt;/a&gt; are available, too.&lt;/p&gt;
&lt;h3 id="content"&gt;Content&lt;/h3&gt;
&lt;p&gt;If I have questions about academic writing (the content), then
&lt;a href="http://academia.stackexchange.com/"&gt;academia.stackexchange.com&lt;/a&gt; is the site
of my choice.&lt;/p&gt;
&lt;h3 id="spell-and-stylechecking"&gt;Spell- and Stylechecking&lt;/h3&gt;
&lt;p&gt;I use &lt;a href="http://aspell.net/"&gt;&lt;code&gt;aspell&lt;/code&gt;&lt;/a&gt; for spellchecking and
&lt;a href="https://github.com/devd/Academic-Writing-Check"&gt;Academic-Writing-Check&lt;/a&gt; to get
some ideas where I might improve my writing style.&lt;/p&gt;
&lt;h3 id="reference-management"&gt;Reference Management&lt;/h3&gt;
&lt;p&gt;I like &lt;a href="https://martin-thoma.com/reference-management-with-jabref/"&gt;JabRef&lt;/a&gt; as
it is in the standard repositories of Ubuntu and works out of the box to
manage my references. I use it to fill my BibTeX files and add as much content
to papers as I can. JabRef also has some nice options to find / open the paper
for yourself.&lt;/p&gt;
&lt;h3 id="publishing"&gt;Publishing&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/"&gt;arxiv.org&lt;/a&gt; is one of the best places to publish your paper
quickly. Even faster, but a lot less reach has
&lt;a href="https://zenodo.org/"&gt;zenodo.org&lt;/a&gt;. The nice thing about Zenodo is that you can
share datasets, too.&lt;/p&gt;
&lt;p&gt;Zenodo also gives all your uploads a DOI and offers visitors various ways to
cite it. For example, for my &lt;a href="https://zenodo.org/record/50022"&gt;HWRT database&lt;/a&gt;
the BibTeX entry is&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@misc&lt;span class="nb"&gt;{&lt;/span&gt;thoma&lt;span class="nb"&gt;_&lt;/span&gt;2015&lt;span class="nb"&gt;_&lt;/span&gt;50022,
  author       = &lt;span class="nb"&gt;{&lt;/span&gt;Thoma, Martin&lt;span class="nb"&gt;}&lt;/span&gt;,
  title        = &lt;span class="nb"&gt;{&lt;/span&gt;HWRT database of handwritten symbols&lt;span class="nb"&gt;}&lt;/span&gt;,
  month        = jan,
  year         = 2015,
  doi          = &lt;span class="nb"&gt;{&lt;/span&gt;10.5281/zenodo.50022&lt;span class="nb"&gt;}&lt;/span&gt;,
  url          = &lt;span class="nb"&gt;{&lt;/span&gt;http://dx.doi.org/10.5281/zenodo.50022&lt;span class="nb"&gt;}&lt;/span&gt;
&lt;span class="nb"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="building-a-profile_1"&gt;Building a Profile&lt;/h2&gt;
&lt;p&gt;I'm not sure how important this is in Science, but there are some social
networks for researchers.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://orcid.org/"&gt;ORCiD&lt;/a&gt; is one site which aims to give researchers unique
numbers so that you can track who wrote what, even if people are in the same
field of research and have the same names. It also allows you to add a CV as
you can see with &lt;a href="http://orcid.org/0000-0002-6517-1690"&gt;my ORCiD&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Google Scholar offers a simple version of that, too. See
&lt;a href="https://scholar.google.de/citations?user=u52T6MYAAAAJ"&gt;my profile&lt;/a&gt; or
the &lt;a href="https://scholar.google.de/citations?user=JicYPdAAAAAJ"&gt;profile of Hinton&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="more"&gt;More&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Sci-Hub"&gt;Sci-Hub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://academictorrents.com/"&gt;academictorrents.com&lt;/a&gt;: I just found this on &lt;a href="https://www.reddit.com/r/MachineLearning/comments/4hqwza/andrej_karpathy_forced_to_take_down_stanford/"&gt;Reddit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.csauthors.net/distance/paul-erdos/alex-j-champandard"&gt;csauthors.net&lt;/a&gt; to calculate your Erd&amp;ouml;s number&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Machine Learning:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://keras.io/"&gt;Keras&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.tensorflow.org/"&gt;TensorFlow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ml-ka.de/paper-discussion-group/"&gt;ml-ka.de paper discussion group&lt;/a&gt; and the &lt;a href="https://www.facebook.com/groups/961427967221226/"&gt;ML-KA Facebook Group&lt;/a&gt; for news&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What do you use?&lt;/p&gt;</content><category term="Science"></category><category term="Academia"></category><category term="arXiv"></category></entry><entry><title>How to find new Papers</title><link href="https://martin-thoma.com/how-to-find-new-papers/" rel="alternate"></link><published>2015-12-03T07:30:00+01:00</published><updated>2015-12-03T07:30:00+01:00</updated><author><name>Martin Thoma</name></author><id>tag:martin-thoma.com,2015-12-03:/how-to-find-new-papers/</id><summary type="html">&lt;p&gt;A couple of people who are just participating in their first seminar might ask
themselves how you can find interesting new publications (papers). I would like
to shed some light on it.&lt;/p&gt;
&lt;h2 id="initial-research"&gt;Initial Research&lt;/h2&gt;
&lt;p&gt;The hardest part is when you're new to a field. You don't know which journals
are …&lt;/p&gt;</summary><content type="html">&lt;p&gt;A couple of people who are just participating in their first seminar might ask
themselves how you can find interesting new publications (papers). I would like
to shed some light on it.&lt;/p&gt;
&lt;h2 id="initial-research"&gt;Initial Research&lt;/h2&gt;
&lt;p&gt;The hardest part is when you're new to a field. You don't know which journals
are the important ones, which authors are most respected in the field, which
terms are used.&lt;/p&gt;
&lt;h3 id="journal-rankings"&gt;Journal Rankings&lt;/h3&gt;
&lt;p&gt;Automated journal rankings like the h5-index used by Google Scholar (see
&lt;a href="https://scholar.google.com/intl/en/scholar/metrics.html"&gt;metrics&lt;/a&gt;,
&lt;a href="https://en.wikipedia.org/wiki/H-index"&gt;Wikipedia&lt;/a&gt;) is one way to deal with the
lack of domain knowledge. Google Scholar even publishes a list of journals
per field (see &lt;a href="https://scholar.google.com/citations?view_op=top_venues&amp;amp;hl=en&amp;amp;vq=eng_computervisionpatternrecognition"&gt;Top publications in Computer Vision and Pattern Recognition&lt;/a&gt;).&lt;/p&gt;
&lt;figure class="aligncenter"&gt;
&lt;a href="../images/2015/12/google-scholar-top-publications.png"&gt;&lt;img alt="Google Scholar Journal ranking" class="" src="../images/2015/12/google-scholar-top-publications.png" style="max-width:500px;"/&gt;&lt;/a&gt;
&lt;figcaption class="text-center"&gt;Google Scholar Journal ranking&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3 id="algorithmic-ideas"&gt;Algorithmic Ideas&lt;/h3&gt;
&lt;p&gt;I've never tried it (on purpose), but the idea just came to my head: Use a
random walk. You start with some paper of which you don't really know if it is
good. Look at the references and try to weild out the ones which are obviously
not work trying (e.g. because they are websites). Now take a random one to
continue with. Do this a couple of times.&lt;/p&gt;
&lt;p&gt;The idea is that papers which are more important are much more often cited. So
you can hope to get to more important papers over time.&lt;/p&gt;
&lt;h3 id="the-hard-way"&gt;The hard way&lt;/h3&gt;
&lt;p&gt;Search for papers via Google. Look at the references. Search for papers in the
reference. Get a feeling for the language being used.&lt;/p&gt;
&lt;h2 id="ongoing-research_1"&gt;Ongoing Research&lt;/h2&gt;
&lt;p&gt;When you have a little bit of domain knowledge (or a starting paper given to
you by your supervisor) everything gets a lot easier.&lt;/p&gt;
&lt;p&gt;There are a couple of key strategies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Looking at the references of a paper&lt;/li&gt;
&lt;li&gt;Looking at what else the same author published&lt;/li&gt;
&lt;li&gt;Looking for similar titles&lt;/li&gt;
&lt;li&gt;Reading Journals&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For all three of them, I can highly recommend
&lt;a href="https://scholar.google.com"&gt;Google Scholar&lt;/a&gt;. They also offer a nice overview
/ statistics about authors so that you can get a feeling for their scientific
activity. But don't let you fool you by those numbers: It is possible to fake
them.&lt;/p&gt;
&lt;p&gt;The other nice thing is that Google Scholar makes citing publications
incredibly easy:&lt;/p&gt;
&lt;figure class="aligncenter"&gt;
&lt;a href="../images/2015/12/google-scholar-paper.png"&gt;&lt;img alt="Searching for a publication on Google Scholar" class="" src="../images/2015/12/google-scholar-paper.png" style="max-width:500px;"/&gt;&lt;/a&gt;
&lt;figcaption class="text-center"&gt;Searching for a publication on Google Scholar&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure class="aligncenter"&gt;
&lt;a href="../images/2015/12/citation.png"&gt;&lt;img alt="Citing a publication via Google Scholar" class="" src="../images/2015/12/citation.png" style="max-width:500px;"/&gt;&lt;/a&gt;
&lt;figcaption class="text-center"&gt;Citing a publication via Google Scholar&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3 id="the-arxiv"&gt;The arXiv&lt;/h3&gt;
&lt;p&gt;The arXiv can be seen as THE "modern way" journal. Depending on the field, it
has a VERY high reputation.&lt;/p&gt;
&lt;p&gt;For Pattern Recognition the reputation of the arXiv is amongst the highest ten
journals, but it there are some fields like physics where it is THE top journal
in several subfields like cosmology or high energy physics.&lt;/p&gt;
&lt;p&gt;What makes the arXiv stand out is the fact that you can read new papers every
day. I like to have a view at
&lt;a href="http://arxiv.org/list/cs.CV/recent"&gt;cs.CV/recent&lt;/a&gt; to keep myself informed
about new stuff. There are about&amp;nbsp;20 new publications per day. On some
days, there is nothing interesting, on other days like today quite a bit:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/pdf/1512.00596.pdf"&gt;The MegaFace Benchmark: 1 Million Faces for Recognition at Scale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/pdf/1512.00567.pdf"&gt;Rethinking the Inception Architecture for Computer Vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/pdf/1512.00517.pdf"&gt;Labeling the Features Not the Samples:
Efficient Video Classification with Minimal Supervision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/pdf/1512.00570.pdf"&gt;Attribute2Image: Conditional Image Generation from Visual Attributes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class="aligncenter"&gt;
&lt;a href="../images/2015/12/latest-arxiv-publications.png"&gt;&lt;img alt="Latest submissions on arXiv in Pattern Recognition and Computer Vision" class="" src="../images/2015/12/latest-arxiv-publications.png" style="max-width:500px;"/&gt;&lt;/a&gt;
&lt;figcaption class="text-center"&gt;Latest submissions on arXiv in Pattern Recognition and Computer Vision&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h2 id="filtering_1"&gt;Filtering&lt;/h2&gt;
&lt;p&gt;I filter publications like this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First, I look at the title. If that doesn't look interesting, I skip it. The
  more exact the title is, the better. If it is too vague, I sometimes skip it
  too because the authors seem not to be familiar with the scientific style of
  writing and thus are probably not able to write an interesting paper.&lt;/li&gt;
&lt;li&gt;Then I read the abstract. I expect to get to know what the paper is about.&lt;/li&gt;
&lt;li&gt;Then I look at images / tables (depending on the subject)&lt;/li&gt;
&lt;li&gt;I read the conclusion / last part&lt;/li&gt;
&lt;li&gt;I read the end of the introduction where it often says "the paper is
  structured as follows"&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I guess many researchers filter like this. This is important to know when you
write a paper.&lt;/p&gt;
&lt;p&gt;Recently, I've also got to know
&lt;a href="http://www.shortscience.org/"&gt;shortscience.org&lt;/a&gt;. It's a website where anybody
can add summaries / remarks of papers. This is pretty awesome if you want to
get the paper in context (especially of work which was released after the paper)
or if you just want to see what the key idea behind a paper is.&lt;/p&gt;
&lt;h2 id="see-also"&gt;See also&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://martin-thoma.com/tools-for-academia/"&gt;Tools for Academia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://trendingarxiv.smerity.com/"&gt;trendingarxiv&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="Science"></category><category term="Papers"></category><category term="Reading"></category><category term="Google Scholar"></category><category term="arXiv"></category></entry><entry><title>Reference Management with JabRef</title><link href="https://martin-thoma.com/reference-management-with-jabref/" rel="alternate"></link><published>2014-06-15T20:51:00+02:00</published><updated>2014-06-15T20:51:00+02:00</updated><author><name>Martin Thoma</name></author><id>tag:martin-thoma.com,2014-06-15:/reference-management-with-jabref/</id><summary type="html">&lt;p&gt;Keeping track of papers, articles and books or more general sources you can
cite is a task you will have to tackle when you're writing your thesis. One
way to store information is via BibTeX files.&lt;/p&gt;
&lt;p&gt;BibTeX is a reference management software that is used together with LaTeX.
If you're …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Keeping track of papers, articles and books or more general sources you can
cite is a task you will have to tackle when you're writing your thesis. One
way to store information is via BibTeX files.&lt;/p&gt;
&lt;p&gt;BibTeX is a reference management software that is used together with LaTeX.
If you're new to BibTeX or references in LaTeX in general you could read the
followin articles:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://tex.stackexchange.com/q/25701/5645"&gt;bibtex vs. biber and biblatex vs. natbib&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://tex.stackexchange.com/q/8411/5645"&gt;What is the difference between bibtex and biblatex?&lt;/a&gt; - I keep forgetting that all the time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I've tried to create a &lt;a href="https://github.com/MartinThoma/LaTeX-examples/tree/master/documents/biblatex-mwe"&gt;MWE for biblatex&lt;/a&gt;, but as I don't really know much about BibTeX it's probably not
the best resource to start with.&lt;/p&gt;
&lt;p&gt;A longer &lt;a href="https://github.com/MartinThoma/write-math/tree/master/bachelor-arbeit"&gt;working example of BibTeX&lt;/a&gt;
is my bachelors thesis (work is still in (slow) progress).&lt;/p&gt;
&lt;h2 id="what-is-jabref"&gt;What is JabRef?&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/JabRef"&gt;JabRef&lt;/a&gt; is a reference management
software that uses BibTeX as its native format. It looks like this:&lt;/p&gt;
&lt;figure class="aligncenter"&gt;
&lt;a href="../images/2014/06/jabref.png"&gt;&lt;img alt="JabRef" class="" src="../images/2014/06/jabref.png" style="max-width:500px;"/&gt;&lt;/a&gt;
&lt;figcaption class="text-center"&gt;JabRef&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h2 id="how-can-i-get-it"&gt;How can I get it?&lt;/h2&gt;
&lt;p&gt;JabRef 2.10 beta is part of the Debian sources. Thus it can be installed by&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt-get install jabref
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The official development page is &lt;a href="http://jabref.sourceforge.net/"&gt;jabref.sourceforge.net&lt;/a&gt;.
As it is written in Java it can be installed on all (or at least most) systems
where you have a JVM (thus: good news Windows / Mac users!).&lt;/p&gt;
&lt;h2 id="whats-good-about-jabref"&gt;What's good about JabRef?&lt;/h2&gt;
&lt;p&gt;You can easily add the information where the PDF is located on your system and
open the PDF directly via JabRef:&lt;/p&gt;
&lt;figure class="aligncenter"&gt;
&lt;a href="../images/2014/06/jabref-pdf.png"&gt;&lt;img alt="Adding PDF with JabRef" class="" src="../images/2014/06/jabref-pdf.png" style="max-width:500px;"/&gt;&lt;/a&gt;
&lt;figcaption class="text-center"&gt;Adding PDF with JabRef&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;This is especially powerfull with the search. As you can add quite a lot of
information to the entries (such as the abstract and comments) and searching
that is faster / easier than searching folders of PDFs, it's very convenient
to use JabRef for opening your PDFs:&lt;/p&gt;
&lt;figure class="aligncenter"&gt;
&lt;a href="../images/2014/06/jabref-searching.png"&gt;&lt;img alt="Searching with JabRef" class="" src="../images/2014/06/jabref-searching.png" style="max-width:500px;"/&gt;&lt;/a&gt;
&lt;figcaption class="text-center"&gt;Searching with JabRef&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The preview also helps you to see how it might appear in your document:&lt;/p&gt;
&lt;figure class="aligncenter"&gt;
&lt;a href="../images/2014/06/jabref-preview.png"&gt;&lt;img alt="JabRef preview" class="" src="../images/2014/06/jabref-preview.png" style="max-width:500px;"/&gt;&lt;/a&gt;
&lt;figcaption class="text-center"&gt;JabRef preview&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Another nice feature is the autocompletion of authors names and titles.&lt;/p&gt;
&lt;h2 id="what-could-be-better"&gt;What could be better?&lt;/h2&gt;
&lt;p&gt;It would be neat if you could automatically upload your BibTeX file and use
other peoples BibTeX files to &lt;strong&gt;complete the information&lt;/strong&gt; or to get informed of
possible errors in your database.&lt;/p&gt;
&lt;p&gt;Additionally, a good &lt;strong&gt;PDF reader&lt;/strong&gt; that is fast and allows annotations of which
JabRef would be aware would be awesome.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Speed&lt;/strong&gt; is quite often an issue with Java applications in my experience.
It takes about 5 seconds to open my BibTeX file of about 37 references. After
starting that it's ok.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Shortcuts&lt;/strong&gt; are important for tools that get used often, too. Although
JabRef has some reasonable shortcuts like &lt;kbd&gt;Ctr&lt;/kbd&gt;+&lt;kbd&gt;i&lt;/kbd&gt; for
importing a BibTeX file and &lt;kbd&gt;Ctr&lt;/kbd&gt;+&lt;kbd&gt;s&lt;/kbd&gt; for saving the current
BibTeX file, I miss &lt;kbd&gt;Ctrl&lt;/kbd&gt;+&lt;kbd&gt;f&lt;/kbd&gt; for searching the database.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Importing&lt;/strong&gt; other BibTeX files into the current BibTeX file is possible. But
I would also like to "import" BibTeX data by copy and pasting a single dataset.&lt;/p&gt;
&lt;h2 id="alternatives"&gt;Alternatives&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Mendeley"&gt;Mendeley&lt;/a&gt; is a closed-source alternative
with a built-in PDF reader. It seems to be fast and can complete information
when the title is given.&lt;/p&gt;</content><category term="Science"></category><category term="References"></category><category term="Software"></category><category term="LaTeX"></category></entry></feed>