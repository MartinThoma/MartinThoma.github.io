<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Martin Thoma - Machine Learning, Computer Vision, CIFAR 100</title><link href="https://martin-thoma.com/" rel="alternate"></link><link href="https://martin-thoma.com/feeds/machine-learning-computer-vision-cifar-100.atom.xml" rel="self"></link><id>https://martin-thoma.com/</id><updated>2017-03-11T20:00:00+01:00</updated><entry><title>Ensembles</title><link href="https://martin-thoma.com/ensembles/" rel="alternate"></link><published>2017-03-11T20:00:00+01:00</published><updated>2017-03-11T20:00:00+01:00</updated><author><name>Martin Thoma</name></author><id>tag:martin-thoma.com,2017-03-11:/ensembles/</id><summary type="html">&lt;p&gt;Models which are combinations of other models are called an &lt;strong&gt;ensemble&lt;/strong&gt;.
The simplest way to combine several classifiers is by averaging their predictions.&lt;/p&gt;
&lt;p&gt;For example, if you have three&amp;nbsp;models and four&amp;nbsp;classes, you might get
predictions like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model 1(x1) = [0.1, 0.5, 0.3, 0.1 â€¦&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;Models which are combinations of other models are called an &lt;strong&gt;ensemble&lt;/strong&gt;.
The simplest way to combine several classifiers is by averaging their predictions.&lt;/p&gt;
&lt;p&gt;For example, if you have three&amp;nbsp;models and four&amp;nbsp;classes, you might get
predictions like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model 1(x1) = [0.1, 0.5, 0.3, 0.1],
model 2(x1) = [0.5, 0.3, 0.1, 0.1],
model 3(x1) = [0.4, 0.4, 0.1, 0.1]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;the ensemble predicts
&lt;/p&gt;
&lt;div class="math"&gt;$$\left [\frac{0.1+0.5+0.4}{3}, \frac{0.5+0.3+0.4}{3}, \frac{0.4+0.2+0.2}{3}, \frac{0.1+0.1+0.1}{3} \right] \approx \left [0.3, 0.4, 0.2, 0.1 \right ]$$&lt;/div&gt;
&lt;p&gt; for &lt;span class="math"&gt;\(x_1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Note that this is different from pluarlity voting (PV) where every model gives
only one vote for the most likely class. In the case from above, it would be&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model 1(x1) = [0, 1, 0, 0],
model 2(x1) = [1, 0, 0, 0],
model 3(x1) = [1, 0, 0, 0]  # tie - lets just take the first
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So the plurality voting ensemble would predict class&amp;nbsp;1, whereas the
average probability ensemble predicts class&amp;nbsp;2. This comes from the fact
that everybody might have different first choices, but they might agree on the
second choice.&lt;/p&gt;
&lt;p&gt;Please note that a tie in the predictions of a classifier with less than
100&amp;nbsp;classes is unlikely due to the higher precision of floating point
numbers. However, a tie in votes can happen.&lt;/p&gt;
&lt;p&gt;According to Andrej Karpathy, this gives you about +2 percentage points in
accuracy.&lt;/p&gt;
&lt;h2 id="tiny-experiment-on-cifar-100"&gt;Tiny Experiment on CIFAR 100&lt;/h2&gt;
&lt;p&gt;I've just tried this with three (almost identical) models for &lt;a href="https://www.cs.toronto.edu/~kriz/cifar.html"&gt;CIFAR&amp;nbsp;100&lt;/a&gt;. All of
them were trained with &lt;a href="https://arxiv.org/abs/1412.6980"&gt;Adam&lt;/a&gt; with
the same training data (the same batches). Model 1 and model 3 only differed in
the second-last layer (one uses ReLU, the other tanh), model 1 and model 2 only
differed in the border mode for one convolutional layer (valid vs same).&lt;/p&gt;
&lt;p&gt;The accuracies of the single models were:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model 1: 57.02
model 2: 61.85
model 3: 48.59
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The ensemble accuracy is 62.98%. Hence the ensemble is 1.13 percentage points
better than the best single model!&lt;/p&gt;
&lt;p&gt;Although I have read things like this before, it is the first time I actually
tried it myself.&lt;/p&gt;
&lt;h2 id="ensemble-techniques"&gt;Ensemble Techniques&lt;/h2&gt;
&lt;p&gt;There are much more sophisticated ensemble techniques than simple averaging of
the output:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;&lt;a href="https://en.wikipedia.org/wiki/Bootstrap_aggregating"&gt;&lt;dfn id="bagging"&gt;Bagging&lt;/dfn&gt;&lt;/a&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;i&gt;How does it work?&lt;/i&gt; Train models on different data
        (Learnier is fit, results are mean/median aggregated)&lt;br/&gt;
&lt;i&gt;Why is it used?&lt;/i&gt; Reduction of variance&lt;br/&gt;
&lt;i&gt;Common techniques:&lt;/i&gt;
&lt;ul&gt;
&lt;li&gt;Random subspaces: Take a part of the features (e.g. Random Forests)&lt;/li&gt;
&lt;li&gt;Pasting: Take a part of the training data without replacement&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;dt&gt;&lt;a href="https://en.wikipedia.org/wiki/Boosting_(machine_learning)"&gt;&lt;dfn id="boosting"&gt;Boosting&lt;/dfn&gt;&lt;/a&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;i&gt;How does it work?&lt;/i&gt; Train one classifier.
        Obtain the results. Weight the training data higher if the classifier got
        it wrong. Train a new classifier on the weighted training data. Iterate.&lt;br/&gt;
&lt;i&gt;Why is it used?&lt;/i&gt; Reduction of bias
        &lt;i&gt;Examples:&lt;/i&gt; &lt;a href="https://en.wikipedia.org/wiki/AdaBoost"&gt;AdaBoost&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Gradient_boosting"&gt;Gradient boosting&lt;/a&gt;
&lt;/dd&gt;
&lt;dt&gt;&lt;a href="https://en.wikipedia.org/wiki/Ensemble_learning#Stacking"&gt;&lt;dfn id="stacking"&gt;Stacking&lt;/dfn&gt;&lt;/a&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;i&gt;How does it work?&lt;/i&gt; Train $n$ classifiers on the data. Train
        a classifier on the predictions of the $n$ classifiers.&lt;br/&gt;
&lt;i&gt;Why is it used?&lt;/i&gt; Reduction of bias and reduction of variance&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;I made some images to make this more clear:&lt;/p&gt;
&lt;figure class="wp-caption aligncenter img-thumbnail"&gt;
&lt;img alt="Bagging" src="../images/2017/03/bagging.jpg" style="width:512px;"/&gt;
&lt;figcaption class="text-center"&gt;Bagging trains the classifiers on different data.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure class="wp-caption aligncenter img-thumbnail"&gt;
&lt;img alt="Boosting reweights the training data" src="../images/2017/03/boosting.jpg" style="width:512px;"/&gt;
&lt;figcaption class="text-center"&gt;Boosting reweights the training data.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure class="wp-caption aligncenter img-thumbnail"&gt;
&lt;img alt="Stacking" src="../images/2017/03/stacking.jpg" style="width:512px;"/&gt;
&lt;figcaption class="text-center"&gt;Stacking trains the combiner.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h2 id="combiners"&gt;Combiners&lt;/h2&gt;
&lt;p&gt;Some choices for combiners are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Average of predictions of base classifiers&lt;/li&gt;
&lt;li&gt;Plurality vote (sometimes also called majority vote)&lt;/li&gt;
&lt;li&gt;Learning&lt;ul&gt;
&lt;li&gt;Naive Bayes&lt;/li&gt;
&lt;li&gt;Neural Network&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="see-also"&gt;See also&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/stable/modules/ensemble.html"&gt;sklearn ensemble user guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.scholarpedia.org/article/Ensemble_learning"&gt;Scholarpedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MIT 6.034 Artificial Intelligence: &lt;a href="https://www.youtube.com/watch?v=UHBmv7qCey4"&gt;17. Learning: Boosting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="machine learning"></category><category term="ensembles"></category></entry></feed>