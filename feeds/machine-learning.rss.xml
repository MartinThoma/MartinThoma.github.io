<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Martin Thoma</title><link>https://martin-thoma.com/</link><description>A blog about Code, the Web and Cyberculture</description><atom:link href="https://martin-thoma.com/feeds/machine-learning.rss.xml" rel="self"></atom:link><lastBuildDate>Wed, 10 Feb 2016 21:35:00 +0100</lastBuildDate><item><title>Collaborative Filtering</title><link>https://martin-thoma.com/collaborative-filtering/</link><description>&lt;p&gt;Suppose you are in the Netflix setting: You have &lt;span markdown="0"&gt;&lt;span class="math"&gt;\(M\)&lt;/span&gt;&lt;/span&gt;
movies, &lt;span markdown="0"&gt;&lt;span class="math"&gt;\(N\)&lt;/span&gt;&lt;/span&gt; users and integer ratings
&lt;span markdown="0"&gt;&lt;span class="math"&gt;\(1, \dots, K\)&lt;/span&gt;&lt;/span&gt; for some movies by some users.&lt;/p&gt;
&lt;p&gt;You want to predict all missing values. This means you want to say how the
users would rate movies they have not actually rated.&lt;/p&gt;
&lt;p&gt;Please note that ratings for products on Amazon might be a very similar
situation. It might also be similar to the StumbleUpon rating.&lt;/p&gt;
&lt;h2 id="the-problem"&gt;The Problem&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Much Data&lt;/strong&gt;: You have 17&amp;thinsp;000 movies, 480&amp;thinsp;000 users and
  100&amp;thinsp;000&amp;thinsp;000 ratings of movies by those users.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Missing Data&lt;/strong&gt;: Although you have a lot of ratings, a complete dataset
  would be &lt;span markdown="0"&gt;&lt;span class="math"&gt;\(17\cdot 10^3 \cdot 480 \cdot 10^3 = 8160 \cdot 10^6\)&lt;/span&gt;&lt;/span&gt;
  ratings. This means you only have about 12% of all possible ratings. There
  is a lot of data missing.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="a-solution"&gt;A Solution&lt;/h2&gt;
&lt;p&gt;Train one RBM per user, but share weights amongst the RBMs. This simply means
the weights are averaged.&lt;/p&gt;
&lt;p&gt;The visible units are movies. But instead of having binary visible units, the
units have &lt;span markdown="0"&gt;&lt;span class="math"&gt;\(K=5\)&lt;/span&gt;&lt;/span&gt; states on which softmax is applied.&lt;/p&gt;
&lt;p&gt;The hidden units (about 100) model dependencies between movie ratings.&lt;/p&gt;
&lt;p&gt;When you now want to predict the missing ratings, you can just perform a
sampling in the user-specific RBM. You calculate the values of the hidden units,
then you have a vector for this user which describes the users preferences.
You add the missing movies with the weights from the other users and sample
back.&lt;/p&gt;
&lt;h2 id="material"&gt;Material&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Salakhutdinov, Mnih and Hinton: &lt;a href="http://www.cs.toronto.edu/~rsalakhu/papers/rbmcf.pdf"&gt;Restricted Boltzmann machines for collaborative filtering&lt;/a&gt;. In Proceedings of the 24th international conference on Machine learning, 2007.&lt;/li&gt;
&lt;li&gt;Hinton: &lt;a href="https://www.youtube.com/watch?v=fzAuXMg_7n4"&gt;5. RBMs for Collaborative Filtering
&lt;/a&gt; on YouTube. 9th of November 2013.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://academictorrents.com/details/9b13183dc4d60676b773c9e2cd6de5e5542cee9a"&gt;Netflix Prize Data Set&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Martin Thoma</dc:creator><pubDate>Wed, 10 Feb 2016 21:35:00 +0100</pubDate><guid>tag:martin-thoma.com,2016-02-10:collaborative-filtering/</guid><category>Rating</category></item><item><title>Softmax</title><link>https://martin-thoma.com/softmax/</link><description>&lt;p&gt;Softmax is an activation function for multi-layer perceptrons (MLPs). It is
a function which gets applied to a vector in &lt;span markdown="0"&gt;&lt;span class="math"&gt;\(\mathbb{x} \in \mathbb{R}^K\)&lt;/span&gt;&lt;/span&gt;
and returns a vector in &lt;span markdown="0"&gt;&lt;span class="math"&gt;\([0, 1]^K\)&lt;/span&gt;&lt;/span&gt; with the
property that the sum of all elements is 1:&lt;/p&gt;
&lt;div&gt;$$\varphi(\mathbb{x})_j = \frac{e^{x_j}}{\sum_{k=1}^K e^{x_k}} \;\;\;\text{ for } j=1, \dots, K$$&lt;/div&gt;
&lt;h2 id="python-implementation"&gt;Python implementation&lt;/h2&gt;
&lt;p&gt;The implementation is straight forward:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="ch"&gt;#! /usr/bin/env python&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Calculate the softmax of a list of numbers w.&lt;/span&gt;

&lt;span class="sd"&gt;    Parameters&lt;/span&gt;
&lt;span class="sd"&gt;    ----------&lt;/span&gt;
&lt;span class="sd"&gt;    w : list of numbers&lt;/span&gt;

&lt;span class="sd"&gt;    Return&lt;/span&gt;
&lt;span class="sd"&gt;    ------&lt;/span&gt;
&lt;span class="sd"&gt;    a list of the same length as w of non-negative numbers&lt;/span&gt;

&lt;span class="sd"&gt;    Examples&lt;/span&gt;
&lt;span class="sd"&gt;    --------&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;gt;&amp;gt;&amp;gt; softmax([0.1, 0.2])&lt;/span&gt;
&lt;span class="sd"&gt;    array([ 0.47502081,  0.52497919])&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;gt;&amp;gt;&amp;gt; softmax([-0.1, 0.2])&lt;/span&gt;
&lt;span class="sd"&gt;    array([ 0.42555748,  0.57444252])&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;gt;&amp;gt;&amp;gt; softmax([0.9, -10])&lt;/span&gt;
&lt;span class="sd"&gt;    array([  9.99981542e-01,   1.84578933e-05])&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;gt;&amp;gt;&amp;gt; softmax([0, 10])&lt;/span&gt;
&lt;span class="sd"&gt;    array([  4.53978687e-05,   9.99954602e-01])&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;dist&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;dist&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"__main__"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;doctest&lt;/span&gt;
    &lt;span class="n"&gt;doctest&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;testmod&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="short-analysis"&gt;Short analysis&lt;/h2&gt;
&lt;p&gt;One obvious property of the softmax function is that the sum of all elements
is one due to the normalization in the denominator.&lt;/p&gt;
&lt;p&gt;By printing the following you can see that values below 1 get closer together
and elements above 1 get farer away.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;percentage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;before&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;before&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;before&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;after&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;before&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Before: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;before&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;before&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"After:  &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;after&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;after&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;60&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;experiments&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;experiments&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;experiments&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;experiments&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;0.6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.8&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;experiments&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reverse&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;percentage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;gives&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Before: [ 1.1  1.1  1. ]
After:  [ 1.10517092  1.10517092  1.        ]
------------------------------------------------------------
Before: [3 2 1]
After:  [ 7.3890561   2.71828183  1.        ]
------------------------------------------------------------
Before: [ 1.33333333  1.16666667  1.        ]
After:  [ 1.22140276  1.10517092  1.        ]
------------------------------------------------------------
&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Martin Thoma</dc:creator><pubDate>Tue, 09 Feb 2016 18:09:00 +0100</pubDate><guid>tag:martin-thoma.com,2016-02-09:softmax/</guid><category>Machine Learning</category><category>Neuronal Networks</category><category>Activation Functions</category></item><item><title>Comparing Classifiers</title><link>https://martin-thoma.com/comparing-classifiers/</link><description>&lt;p&gt;Classification problems occur quite often and many different classification
algorithms have been described and implemented. But what is the best algorithm
for a given error function and dataset?&lt;/p&gt;
&lt;p&gt;I read questions like "I have problem X. What is the best classifier?" quite
often and my first impulse is always to write: Just try them!&lt;/p&gt;
&lt;p&gt;I guess people asking this question might think that it is super difficult to
do so. However, the sklearn tutorial contains a very nice example where
many classifiers are compared (&lt;a href="http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html"&gt;source&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;This article gives you an overview over some classifiers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"&gt;SVM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"&gt;k-nearest neighbors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"&gt;Random Forest&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html"&gt;AdaBoost Classifier&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"&gt;Gradient Boosting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html"&gt;Naive Bayes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/0.16/modules/generated/sklearn.lda.LDA.html"&gt;LDA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/0.16/modules/generated/sklearn.qda.QDA.html"&gt;QDA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.BernoulliRBM.html"&gt;RBMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"&gt;Logistic Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.BernoulliRBM.html"&gt;RBM&lt;/a&gt; + Logistic Regression Classifier&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of course, neural networks are also one very powerful ML classifier I may not
forget. As sklearn does not have neural networks, I've installed
&lt;a href="https://github.com/tensorflow/skflow"&gt;&lt;code&gt;skflow&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="tutorial-example"&gt;Tutorial example&lt;/h2&gt;
&lt;p&gt;The sklearn tutorial creates three datasets with 100&amp;nbsp;points per dataset and
2&amp;nbsp;dimensions per point:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Moons&lt;/strong&gt;: Two interleaving half-circles&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Circles&lt;/strong&gt;: A larger circle containing the smaller one&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Linear&lt;/strong&gt;: A linearly seperable dataset&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Each of those three datasets has added noise. This means for some points there
might be no way of classifying them correclty.&lt;/p&gt;
&lt;p&gt;Here are the results&lt;/p&gt;
&lt;figure class="aligncenter"&gt;
&lt;a href="../images/2016/01/ml-classifiers-1.png"&gt;&lt;img alt="k nearest neighbors, linear and RBFSVM" class="" src="../images/2016/01/ml-classifiers-1.png" style="max-width:500px;"/&gt;&lt;/a&gt;
&lt;figcaption class="text-center"&gt;k nearest neighbors, linear and RBFSVM&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;One can see that k nearest neighbors gives arbitrary decision boundaries.
Overall, they look reasonable. However, there are often strange zig-zag
patterns.&lt;/p&gt;
&lt;p&gt;The linear SVM in contrast has a very easy decision boundary: a line. It is no
suprise that it can't deal with the moons dataset. Note that a random guess
would be right in 50% of the cases.&lt;/p&gt;
&lt;p&gt;The RBF SVM has very nice decision boundary. It is smooth, matches the pattern
and is able to adjust to all three examles.&lt;/p&gt;
&lt;figure class="aligncenter"&gt;
&lt;a href="../images/2016/01/ml-classifiers-2.png"&gt;&lt;img alt="Decision Tree, Random Forest, AdaBoost" class="" src="../images/2016/01/ml-classifiers-2.png" style="max-width:500px;"/&gt;&lt;/a&gt;
&lt;figcaption class="text-center"&gt;Decision Tree, Random Forest, AdaBoost&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Decision Trees, Decision Forests and AdaBoost all show very similar
patterns. The boundaries change in parallel to the coordinate axes which looks
very unnatural.&lt;/p&gt;
&lt;figure class="aligncenter"&gt;
&lt;a href="../images/2016/01/ml-classifiers-3.png"&gt;&lt;img alt="Naive Bayes, LDA, QDA" class="" src="../images/2016/01/ml-classifiers-3.png" style="max-width:500px;"/&gt;&lt;/a&gt;
&lt;figcaption class="text-center"&gt;Naive Bayes, LDA, QDA&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Naive Bayes shows nice, smooth patterns. However, those patterns seem to be
a bit too simple. LDA is again linear (see linear SVM). Comparing QDA to
Naive Bayes is interesting. Although they get similar performance for the first
dataset, I would argue that the naive bayes classifier is much better as it is
much more confident for its classification. Even more extrem is the last example.
I'm astonished that the QDA gets 93% with that boundary; Naive Bayes seems to
find a much better boundary.&lt;/p&gt;
&lt;h2 id="the-hardware"&gt;The hardware&lt;/h2&gt;
&lt;p&gt;The following comparison is done on a PC with an &lt;a href="http://ark.intel.com/de/products/77781/Intel-Core-i7-4820K-Processor-10M-Cache-up-to-3_90-GHz"&gt;Intel i7-4820K CPU&lt;/a&gt; and a NVIDIA GeForce GTX Titan Black
GPU.&lt;/p&gt;
&lt;h2 id="mnist"&gt;MNIST&lt;/h2&gt;
&lt;p&gt;MNIST is a dataset of &lt;span markdown="0"&gt;&lt;span class="math"&gt;\(28\text{px} \times 28\text{px}\)&lt;/span&gt;&lt;/span&gt; greyscale images.
Each of the images contains a digit (0, 1, 2, 3, 4, 5, 6, 7, 8, 9). The
task is to classify the image into one of the 10 digit classes.&lt;/p&gt;
&lt;p&gt;Guessing randomly will give an accuracy of &lt;span markdown="0"&gt;&lt;span class="math"&gt;\(\frac{1}{10} = 0.1\)&lt;/span&gt;&lt;/span&gt;.&lt;/p&gt;
&lt;h3 id="neural-networks"&gt;Neural Networks&lt;/h3&gt;
&lt;p&gt;Please note that there are neural networks which get much better accuracy.
Most notably the &lt;a href="https://www.tensorflow.org/versions/master/tutorials/mnist/pros/index.html#deep-mnist-for-experts"&gt;MNIST Expert tutorial&lt;/a&gt; with 99.2% accuracy.&lt;/p&gt;
&lt;h4 id="simple-network"&gt;Simple Network&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Classifier&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;NN&lt;/span&gt; &lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;
&lt;span class="n"&gt;Training&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;79.5696&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Testing&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.3480&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Confusion&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;2248&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;2565&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;2258&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt; &lt;span class="mi"&gt;2294&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;23&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;2161&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;2014&lt;/span&gt;   &lt;span class="mi"&gt;17&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;11&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt; &lt;span class="mi"&gt;2237&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;2355&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;   &lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;   &lt;span class="mi"&gt;17&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;2161&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt; &lt;span class="mi"&gt;2340&lt;/span&gt;&lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.9798&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="dropout-network"&gt;Dropout Network&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Classifier&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;NN&lt;/span&gt; &lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt; &lt;span class="n"&gt;dropout&lt;/span&gt;
&lt;span class="n"&gt;Training&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;118.2654&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Testing&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.3918&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Confusion&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;2250&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;2567&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt; &lt;span class="mi"&gt;2272&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;26&lt;/span&gt; &lt;span class="mi"&gt;2260&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;24&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;   &lt;span class="mi"&gt;19&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;2152&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;1983&lt;/span&gt;   &lt;span class="mi"&gt;20&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;   &lt;span class="mi"&gt;21&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;11&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;2237&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;2363&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;2170&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;19&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="mi"&gt;2337&lt;/span&gt;&lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.9780&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="cnn"&gt;CNN&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Classifier&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;CNN&lt;/span&gt;
&lt;span class="n"&gt;Training&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;391.8810&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Testing&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;1.2035&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Confusion&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;2243&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;2548&lt;/span&gt;   &lt;span class="mi"&gt;20&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="mi"&gt;2253&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;   &lt;span class="mi"&gt;17&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;2290&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;2164&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;15&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;2016&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;12&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt; &lt;span class="mi"&gt;2227&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;2374&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;15&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="mi"&gt;2145&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;24&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;2306&lt;/span&gt;&lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.9769&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="svm"&gt;SVM&lt;/h3&gt;
&lt;p&gt;There is a ton of literature / papers about &lt;abbr title="Support Vector Machines"&gt;SVMs&lt;/abbr&gt;.
I've summed up the basics on &lt;a href="https://martin-thoma.com/svm-with-sklearn/"&gt;Using SVMs with sklearn&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I've trained two SVMs: A simple, linear one and one with an RBF kernel as I
found it online (I'm sorry, I don't remember where I found those parameters :-/).&lt;/p&gt;
&lt;p&gt;Please note the the SVM implementation of sklearn does not use the GPU.
However, there are &lt;a href="http://fastml.com/running-things-on-a-gpu/"&gt;GPU implmentations of SVMs&lt;/a&gt;
around.&lt;/p&gt;
&lt;h4 id="linear-svm"&gt;Linear SVM&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Classifier&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;linear&lt;/span&gt; &lt;span class="n"&gt;SVM&lt;/span&gt;
&lt;span class="n"&gt;Training&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;168.6950&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Testing&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;158.0101&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Confusion&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;2226&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;2537&lt;/span&gt;   &lt;span class="mi"&gt;18&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;   &lt;span class="mi"&gt;17&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;12&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="mi"&gt;2158&lt;/span&gt;   &lt;span class="mi"&gt;25&lt;/span&gt;   &lt;span class="mi"&gt;24&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;   &lt;span class="mi"&gt;27&lt;/span&gt;   &lt;span class="mi"&gt;19&lt;/span&gt;   &lt;span class="mi"&gt;25&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;   &lt;span class="mi"&gt;46&lt;/span&gt; &lt;span class="mi"&gt;2188&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;   &lt;span class="mi"&gt;47&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;18&lt;/span&gt;   &lt;span class="mi"&gt;27&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;   &lt;span class="mi"&gt;19&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;2117&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;49&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;18&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;   &lt;span class="mi"&gt;73&lt;/span&gt;   &lt;span class="mi"&gt;20&lt;/span&gt; &lt;span class="mi"&gt;1872&lt;/span&gt;   &lt;span class="mi"&gt;31&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;26&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;20&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;   &lt;span class="mi"&gt;22&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;   &lt;span class="mi"&gt;30&lt;/span&gt; &lt;span class="mi"&gt;2179&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;5&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;   &lt;span class="mi"&gt;32&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;   &lt;span class="mi"&gt;30&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;2268&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;   &lt;span class="mi"&gt;51&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;11&lt;/span&gt;   &lt;span class="mi"&gt;39&lt;/span&gt;   &lt;span class="mi"&gt;26&lt;/span&gt;   &lt;span class="mi"&gt;47&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;   &lt;span class="mi"&gt;40&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="mi"&gt;2018&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;11&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;   &lt;span class="mi"&gt;24&lt;/span&gt;   &lt;span class="mi"&gt;64&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;61&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt; &lt;span class="mi"&gt;2189&lt;/span&gt;&lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.9416&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id="adjusted-svm"&gt;Adjusted SVM&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Classifier&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;adj&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;SVM&lt;/span&gt;
&lt;span class="n"&gt;Training&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;347.1539&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Testing&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;234.5724&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Confusion&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;2258&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;2566&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;2280&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt; &lt;span class="mi"&gt;2304&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;2183&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;2026&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;2245&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;2373&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;2166&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;   &lt;span class="mi"&gt;19&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="mi"&gt;2329&lt;/span&gt;&lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.9840&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="random-forest"&gt;Random Forest&lt;/h3&gt;
&lt;p&gt;Data:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;n_estimators=50&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;n_jobs=10&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Classifier&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Random&lt;/span&gt; &lt;span class="n"&gt;Forest&lt;/span&gt;
&lt;span class="n"&gt;Training&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;2.1359&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Testing&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;26.0763&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Confusion&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;2246&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;2543&lt;/span&gt;   &lt;span class="mi"&gt;18&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;2233&lt;/span&gt;   &lt;span class="mi"&gt;20&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;36&lt;/span&gt; &lt;span class="mi"&gt;2240&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;20&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt;   &lt;span class="mi"&gt;19&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;2142&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;   &lt;span class="mi"&gt;38&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;   &lt;span class="mi"&gt;30&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt; &lt;span class="mi"&gt;1977&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;13&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;   &lt;span class="mi"&gt;15&lt;/span&gt; &lt;span class="mi"&gt;2210&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;   &lt;span class="mi"&gt;29&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;   &lt;span class="mi"&gt;19&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;2315&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;   &lt;span class="mi"&gt;34&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;   &lt;span class="mi"&gt;18&lt;/span&gt;   &lt;span class="mi"&gt;17&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;   &lt;span class="mi"&gt;26&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="mi"&gt;2103&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;10&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;   &lt;span class="mi"&gt;24&lt;/span&gt;   &lt;span class="mi"&gt;27&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;20&lt;/span&gt;   &lt;span class="mi"&gt;18&lt;/span&gt; &lt;span class="mi"&gt;2262&lt;/span&gt;&lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.9641&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Alternatively:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;max_depth=5&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;n_estimators=10&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max_features=1&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Classifier&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Random&lt;/span&gt; &lt;span class="n"&gt;Forest&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;Training&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.2077&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Testing&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;22.2770&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Confusion&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1955&lt;/span&gt;   &lt;span class="mi"&gt;32&lt;/span&gt;   &lt;span class="mi"&gt;63&lt;/span&gt;   &lt;span class="mi"&gt;64&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;  &lt;span class="mi"&gt;109&lt;/span&gt;   &lt;span class="mi"&gt;21&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;2524&lt;/span&gt;   &lt;span class="mi"&gt;20&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;252&lt;/span&gt;  &lt;span class="mi"&gt;425&lt;/span&gt; &lt;span class="mi"&gt;1198&lt;/span&gt;  &lt;span class="mi"&gt;151&lt;/span&gt;   &lt;span class="mi"&gt;64&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;  &lt;span class="mi"&gt;145&lt;/span&gt;   &lt;span class="mi"&gt;15&lt;/span&gt;   &lt;span class="mi"&gt;55&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;136&lt;/span&gt;  &lt;span class="mi"&gt;195&lt;/span&gt;  &lt;span class="mi"&gt;140&lt;/span&gt; &lt;span class="mi"&gt;1641&lt;/span&gt;   &lt;span class="mi"&gt;28&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;   &lt;span class="mi"&gt;22&lt;/span&gt;   &lt;span class="mi"&gt;95&lt;/span&gt;   &lt;span class="mi"&gt;65&lt;/span&gt;   &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;92&lt;/span&gt;  &lt;span class="mi"&gt;320&lt;/span&gt;   &lt;span class="mi"&gt;21&lt;/span&gt;   &lt;span class="mi"&gt;45&lt;/span&gt; &lt;span class="mi"&gt;1199&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;   &lt;span class="mi"&gt;76&lt;/span&gt;  &lt;span class="mi"&gt;153&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;  &lt;span class="mi"&gt;288&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;312&lt;/span&gt;  &lt;span class="mi"&gt;383&lt;/span&gt;   &lt;span class="mi"&gt;67&lt;/span&gt;  &lt;span class="mi"&gt;655&lt;/span&gt;   &lt;span class="mi"&gt;78&lt;/span&gt;  &lt;span class="mi"&gt;268&lt;/span&gt;   &lt;span class="mi"&gt;47&lt;/span&gt;   &lt;span class="mi"&gt;94&lt;/span&gt;  &lt;span class="mi"&gt;134&lt;/span&gt;   &lt;span class="mi"&gt;31&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;199&lt;/span&gt;  &lt;span class="mi"&gt;364&lt;/span&gt;  &lt;span class="mi"&gt;125&lt;/span&gt;   &lt;span class="mi"&gt;58&lt;/span&gt;   &lt;span class="mi"&gt;96&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;1408&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;83&lt;/span&gt;  &lt;span class="mi"&gt;424&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;   &lt;span class="mi"&gt;70&lt;/span&gt;  &lt;span class="mi"&gt;101&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;19&lt;/span&gt; &lt;span class="mi"&gt;1555&lt;/span&gt;   &lt;span class="mi"&gt;56&lt;/span&gt;   &lt;span class="mi"&gt;98&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;392&lt;/span&gt;  &lt;span class="mi"&gt;574&lt;/span&gt;   &lt;span class="mi"&gt;44&lt;/span&gt;  &lt;span class="mi"&gt;147&lt;/span&gt;   &lt;span class="mi"&gt;52&lt;/span&gt;   &lt;span class="mi"&gt;17&lt;/span&gt;   &lt;span class="mi"&gt;71&lt;/span&gt;  &lt;span class="mi"&gt;106&lt;/span&gt;  &lt;span class="mi"&gt;773&lt;/span&gt;   &lt;span class="mi"&gt;39&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;71&lt;/span&gt;  &lt;span class="mi"&gt;338&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;   &lt;span class="mi"&gt;43&lt;/span&gt;  &lt;span class="mi"&gt;579&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;  &lt;span class="mi"&gt;632&lt;/span&gt;   &lt;span class="mi"&gt;24&lt;/span&gt;  &lt;span class="mi"&gt;681&lt;/span&gt;&lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.5715&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="k-nearest-neightbors"&gt;k nearest neightbors&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Classifier&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;
&lt;span class="n"&gt;Training&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;4.6439&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Testing&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;1261.7815&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Confusion&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;2260&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;2572&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;16&lt;/span&gt;   &lt;span class="mi"&gt;15&lt;/span&gt; &lt;span class="mi"&gt;2235&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;   &lt;span class="mi"&gt;26&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt; &lt;span class="mi"&gt;2276&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;27&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;4&lt;/span&gt;   &lt;span class="mi"&gt;19&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;2131&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;45&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;10&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;28&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="mi"&gt;1977&lt;/span&gt;   &lt;span class="mi"&gt;25&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;12&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="mi"&gt;2239&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;18&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;2349&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;29&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;11&lt;/span&gt;   &lt;span class="mi"&gt;32&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;   &lt;span class="mi"&gt;36&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;   &lt;span class="mi"&gt;34&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="mi"&gt;2053&lt;/span&gt;   &lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;   &lt;span class="mi"&gt;26&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;19&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="mi"&gt;2303&lt;/span&gt;&lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.9695&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="decision-tree"&gt;Decision Tree&lt;/h3&gt;
&lt;p&gt;Data:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;max_depth=5&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Classifier&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Decision&lt;/span&gt; &lt;span class="n"&gt;Tree&lt;/span&gt;
&lt;span class="n"&gt;Training&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;3.1346&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Testing&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.0313&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Confusion&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1767&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;   &lt;span class="mi"&gt;25&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;  &lt;span class="mi"&gt;120&lt;/span&gt;  &lt;span class="mi"&gt;137&lt;/span&gt;   &lt;span class="mi"&gt;71&lt;/span&gt;  &lt;span class="mi"&gt;114&lt;/span&gt;   &lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;2065&lt;/span&gt;  &lt;span class="mi"&gt;128&lt;/span&gt;  &lt;span class="mi"&gt;108&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt;   &lt;span class="mi"&gt;17&lt;/span&gt;   &lt;span class="mi"&gt;41&lt;/span&gt;   &lt;span class="mi"&gt;66&lt;/span&gt;  &lt;span class="mi"&gt;131&lt;/span&gt;   &lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;42&lt;/span&gt;   &lt;span class="mi"&gt;44&lt;/span&gt; &lt;span class="mi"&gt;1248&lt;/span&gt;   &lt;span class="mi"&gt;37&lt;/span&gt;  &lt;span class="mi"&gt;121&lt;/span&gt;   &lt;span class="mi"&gt;21&lt;/span&gt;  &lt;span class="mi"&gt;227&lt;/span&gt;   &lt;span class="mi"&gt;76&lt;/span&gt;  &lt;span class="mi"&gt;339&lt;/span&gt;  &lt;span class="mi"&gt;159&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;33&lt;/span&gt;   &lt;span class="mi"&gt;22&lt;/span&gt;   &lt;span class="mi"&gt;32&lt;/span&gt; &lt;span class="mi"&gt;1484&lt;/span&gt;   &lt;span class="mi"&gt;33&lt;/span&gt;  &lt;span class="mi"&gt;107&lt;/span&gt;   &lt;span class="mi"&gt;52&lt;/span&gt;   &lt;span class="mi"&gt;81&lt;/span&gt;  &lt;span class="mi"&gt;266&lt;/span&gt;  &lt;span class="mi"&gt;238&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;15&lt;/span&gt;   &lt;span class="mi"&gt;45&lt;/span&gt;   &lt;span class="mi"&gt;33&lt;/span&gt; &lt;span class="mi"&gt;1284&lt;/span&gt;   &lt;span class="mi"&gt;42&lt;/span&gt;   &lt;span class="mi"&gt;42&lt;/span&gt;   &lt;span class="mi"&gt;45&lt;/span&gt;  &lt;span class="mi"&gt;213&lt;/span&gt;  &lt;span class="mi"&gt;492&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;42&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;   &lt;span class="mi"&gt;21&lt;/span&gt;  &lt;span class="mi"&gt;229&lt;/span&gt;  &lt;span class="mi"&gt;166&lt;/span&gt;  &lt;span class="mi"&gt;577&lt;/span&gt;  &lt;span class="mi"&gt;137&lt;/span&gt;  &lt;span class="mi"&gt;123&lt;/span&gt;  &lt;span class="mi"&gt;254&lt;/span&gt;  &lt;span class="mi"&gt;510&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;34&lt;/span&gt;   &lt;span class="mi"&gt;33&lt;/span&gt;   &lt;span class="mi"&gt;66&lt;/span&gt;   &lt;span class="mi"&gt;24&lt;/span&gt;  &lt;span class="mi"&gt;103&lt;/span&gt;   &lt;span class="mi"&gt;65&lt;/span&gt; &lt;span class="mi"&gt;1734&lt;/span&gt;   &lt;span class="mi"&gt;24&lt;/span&gt;  &lt;span class="mi"&gt;102&lt;/span&gt;   &lt;span class="mi"&gt;86&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;10&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;  &lt;span class="mi"&gt;179&lt;/span&gt;   &lt;span class="mi"&gt;57&lt;/span&gt;   &lt;span class="mi"&gt;53&lt;/span&gt;   &lt;span class="mi"&gt;21&lt;/span&gt;   &lt;span class="mi"&gt;19&lt;/span&gt; &lt;span class="mi"&gt;1775&lt;/span&gt;   &lt;span class="mi"&gt;79&lt;/span&gt;  &lt;span class="mi"&gt;210&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;98&lt;/span&gt;  &lt;span class="mi"&gt;129&lt;/span&gt;   &lt;span class="mi"&gt;43&lt;/span&gt;   &lt;span class="mi"&gt;43&lt;/span&gt;   &lt;span class="mi"&gt;42&lt;/span&gt;  &lt;span class="mi"&gt;160&lt;/span&gt;   &lt;span class="mi"&gt;29&lt;/span&gt; &lt;span class="mi"&gt;1439&lt;/span&gt;  &lt;span class="mi"&gt;231&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;   &lt;span class="mi"&gt;86&lt;/span&gt;   &lt;span class="mi"&gt;59&lt;/span&gt;  &lt;span class="mi"&gt;125&lt;/span&gt;   &lt;span class="mi"&gt;95&lt;/span&gt;   &lt;span class="mi"&gt;36&lt;/span&gt;   &lt;span class="mi"&gt;75&lt;/span&gt;  &lt;span class="mi"&gt;167&lt;/span&gt; &lt;span class="mi"&gt;1734&lt;/span&gt;&lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.6540&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="adaboost"&gt;Adaboost&lt;/h3&gt;
&lt;p&gt;You should note that you can use arbitrary base classifiers with Adaboost.
The default ones of &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html"&gt;&lt;code&gt;sklearn.ensemble.AdaBoostClassifier&lt;/code&gt;&lt;/a&gt; is &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"&gt;&lt;code&gt;sklearn.tree.DecisionTreeClassifies&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Classifier&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;AdaBoost&lt;/span&gt;
&lt;span class="n"&gt;Training&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;37.6443&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Testing&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;1.5815&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Confusion&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;1994&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;75&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;  &lt;span class="mi"&gt;113&lt;/span&gt;   &lt;span class="mi"&gt;51&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;15&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;2435&lt;/span&gt;   &lt;span class="mi"&gt;27&lt;/span&gt;   &lt;span class="mi"&gt;22&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;   &lt;span class="mi"&gt;37&lt;/span&gt;   &lt;span class="mi"&gt;42&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;97&lt;/span&gt;   &lt;span class="mi"&gt;39&lt;/span&gt; &lt;span class="mi"&gt;1341&lt;/span&gt;   &lt;span class="mi"&gt;85&lt;/span&gt;   &lt;span class="mi"&gt;39&lt;/span&gt;   &lt;span class="mi"&gt;38&lt;/span&gt;  &lt;span class="mi"&gt;416&lt;/span&gt;   &lt;span class="mi"&gt;39&lt;/span&gt;  &lt;span class="mi"&gt;196&lt;/span&gt;   &lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;108&lt;/span&gt;   &lt;span class="mi"&gt;52&lt;/span&gt;   &lt;span class="mi"&gt;37&lt;/span&gt; &lt;span class="mi"&gt;1508&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt;  &lt;span class="mi"&gt;313&lt;/span&gt;   &lt;span class="mi"&gt;66&lt;/span&gt;   &lt;span class="mi"&gt;64&lt;/span&gt;  &lt;span class="mi"&gt;122&lt;/span&gt;   &lt;span class="mi"&gt;65&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;11&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt;   &lt;span class="mi"&gt;48&lt;/span&gt;   &lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="mi"&gt;1662&lt;/span&gt;   &lt;span class="mi"&gt;49&lt;/span&gt;   &lt;span class="mi"&gt;23&lt;/span&gt;  &lt;span class="mi"&gt;134&lt;/span&gt;   &lt;span class="mi"&gt;90&lt;/span&gt;  &lt;span class="mi"&gt;155&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;81&lt;/span&gt;   &lt;span class="mi"&gt;56&lt;/span&gt;   &lt;span class="mi"&gt;30&lt;/span&gt;  &lt;span class="mi"&gt;309&lt;/span&gt;   &lt;span class="mi"&gt;51&lt;/span&gt; &lt;span class="mi"&gt;1255&lt;/span&gt;   &lt;span class="mi"&gt;57&lt;/span&gt;   &lt;span class="mi"&gt;17&lt;/span&gt;  &lt;span class="mi"&gt;129&lt;/span&gt;   &lt;span class="mi"&gt;84&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;29&lt;/span&gt;   &lt;span class="mi"&gt;28&lt;/span&gt;  &lt;span class="mi"&gt;151&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;   &lt;span class="mi"&gt;80&lt;/span&gt;   &lt;span class="mi"&gt;43&lt;/span&gt; &lt;span class="mi"&gt;1914&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;   &lt;span class="mi"&gt;17&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;25&lt;/span&gt;   &lt;span class="mi"&gt;37&lt;/span&gt;   &lt;span class="mi"&gt;33&lt;/span&gt;   &lt;span class="mi"&gt;36&lt;/span&gt;   &lt;span class="mi"&gt;70&lt;/span&gt;   &lt;span class="mi"&gt;30&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;1761&lt;/span&gt;   &lt;span class="mi"&gt;37&lt;/span&gt;  &lt;span class="mi"&gt;388&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;30&lt;/span&gt;   &lt;span class="mi"&gt;80&lt;/span&gt;   &lt;span class="mi"&gt;48&lt;/span&gt;  &lt;span class="mi"&gt;215&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt;   &lt;span class="mi"&gt;85&lt;/span&gt;   &lt;span class="mi"&gt;30&lt;/span&gt;   &lt;span class="mi"&gt;19&lt;/span&gt; &lt;span class="mi"&gt;1615&lt;/span&gt;   &lt;span class="mi"&gt;77&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;13&lt;/span&gt;   &lt;span class="mi"&gt;29&lt;/span&gt;   &lt;span class="mi"&gt;68&lt;/span&gt;   &lt;span class="mi"&gt;66&lt;/span&gt;  &lt;span class="mi"&gt;356&lt;/span&gt;   &lt;span class="mi"&gt;74&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;  &lt;span class="mi"&gt;171&lt;/span&gt;   &lt;span class="mi"&gt;78&lt;/span&gt; &lt;span class="mi"&gt;1533&lt;/span&gt;&lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.7367&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="gradient-boosting"&gt;Gradient Boosting&lt;/h3&gt;
&lt;p&gt;Gradient boosting with &lt;code&gt;xgboost&lt;/code&gt; has won in the Rossmann Store Sales prediction
(&lt;a href="http://blog.kaggle.com/2015/12/21/rossmann-store-sales-winners-interview-1st-place-gert/"&gt;source&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;See also:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://blog.kaggle.com/2015/09/22/caterpillar-winners-interview-1st-place-gilberto-josef-leustagos-mario/"&gt;Caterpillar Winners' Interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.kaggle.com/2015/10/20/caterpillar-winners-interview-3rd-place-team-shift-workers/"&gt;Caterpillar Winners' Interview: 3rd place&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.kaggle.com/2015/09/28/liberty-mutual-property-inspection-winners-interview-qingchen-wang/"&gt;Liberty Mutual Property Inspection, Winner's Interview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.kaggle.com/2015/10/21/recruit-coupon-purchase-winners-interview-2nd-place-halla-yang/"&gt;Recruit Coupon Purchase Winner's Interview: 2nd place&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.kaggle.com/2015/10/30/dato-winners-interview-2nd-place-mortehu/"&gt;Dato Truly Native? Winner's Interview: 2nd place&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Classifier&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Gradient&lt;/span&gt; &lt;span class="n"&gt;Boosting&lt;/span&gt;
&lt;span class="n"&gt;Training&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;2409.8094&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Testing&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.4159&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Confusion&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;2214&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;24&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;2528&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="mi"&gt;2165&lt;/span&gt;   &lt;span class="mi"&gt;34&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;   &lt;span class="mi"&gt;22&lt;/span&gt;   &lt;span class="mi"&gt;37&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;   &lt;span class="mi"&gt;27&lt;/span&gt; &lt;span class="mi"&gt;2182&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;   &lt;span class="mi"&gt;42&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;22&lt;/span&gt;   &lt;span class="mi"&gt;37&lt;/span&gt;   &lt;span class="mi"&gt;23&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;2088&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;   &lt;span class="mi"&gt;65&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;9&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;   &lt;span class="mi"&gt;41&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="mi"&gt;1928&lt;/span&gt;   &lt;span class="mi"&gt;27&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;   &lt;span class="mi"&gt;18&lt;/span&gt;   &lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;15&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;19&lt;/span&gt;   &lt;span class="mi"&gt;29&lt;/span&gt; &lt;span class="mi"&gt;2181&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;6&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt;   &lt;span class="mi"&gt;27&lt;/span&gt;   &lt;span class="mi"&gt;15&lt;/span&gt;   &lt;span class="mi"&gt;22&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;2246&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;   &lt;span class="mi"&gt;71&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;5&lt;/span&gt;   &lt;span class="mi"&gt;20&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;   &lt;span class="mi"&gt;25&lt;/span&gt;   &lt;span class="mi"&gt;15&lt;/span&gt;   &lt;span class="mi"&gt;29&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt; &lt;span class="mi"&gt;2057&lt;/span&gt;   &lt;span class="mi"&gt;38&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;6&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;   &lt;span class="mi"&gt;24&lt;/span&gt;   &lt;span class="mi"&gt;49&lt;/span&gt;   &lt;span class="mi"&gt;15&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;54&lt;/span&gt;   &lt;span class="mi"&gt;17&lt;/span&gt; &lt;span class="mi"&gt;2205&lt;/span&gt;&lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.9435&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="naive-bayes"&gt;Naive Bayes&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Classifier&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Naive&lt;/span&gt; &lt;span class="n"&gt;Bayes&lt;/span&gt;
&lt;span class="n"&gt;Training&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.3814&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Testing&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.8863&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Confusion&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;2094&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;   &lt;span class="mi"&gt;56&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;69&lt;/span&gt;   &lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="mi"&gt;2432&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;   &lt;span class="mi"&gt;28&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;77&lt;/span&gt;   &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;278&lt;/span&gt;   &lt;span class="mi"&gt;64&lt;/span&gt;  &lt;span class="mi"&gt;703&lt;/span&gt;  &lt;span class="mi"&gt;143&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;  &lt;span class="mi"&gt;558&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;  &lt;span class="mi"&gt;528&lt;/span&gt;   &lt;span class="mi"&gt;26&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;202&lt;/span&gt;  &lt;span class="mi"&gt;136&lt;/span&gt;   &lt;span class="mi"&gt;18&lt;/span&gt;  &lt;span class="mi"&gt;791&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;  &lt;span class="mi"&gt;106&lt;/span&gt;   &lt;span class="mi"&gt;21&lt;/span&gt;  &lt;span class="mi"&gt;886&lt;/span&gt;  &lt;span class="mi"&gt;178&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;96&lt;/span&gt;   &lt;span class="mi"&gt;26&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;  &lt;span class="mi"&gt;296&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;  &lt;span class="mi"&gt;169&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt;  &lt;span class="mi"&gt;535&lt;/span&gt; &lt;span class="mi"&gt;1038&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;327&lt;/span&gt;   &lt;span class="mi"&gt;63&lt;/span&gt;   &lt;span class="mi"&gt;15&lt;/span&gt;   &lt;span class="mi"&gt;39&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;   &lt;span class="mi"&gt;87&lt;/span&gt;  &lt;span class="mi"&gt;100&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="mi"&gt;1253&lt;/span&gt;  &lt;span class="mi"&gt;166&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;34&lt;/span&gt;   &lt;span class="mi"&gt;51&lt;/span&gt;   &lt;span class="mi"&gt;17&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="mi"&gt;2109&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;52&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;19&lt;/span&gt;   &lt;span class="mi"&gt;21&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;23&lt;/span&gt;   &lt;span class="mi"&gt;20&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;  &lt;span class="mi"&gt;737&lt;/span&gt;  &lt;span class="mi"&gt;123&lt;/span&gt; &lt;span class="mi"&gt;1462&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;39&lt;/span&gt;  &lt;span class="mi"&gt;326&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;   &lt;span class="mi"&gt;18&lt;/span&gt;   &lt;span class="mi"&gt;25&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="mi"&gt;1482&lt;/span&gt;  &lt;span class="mi"&gt;281&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;15&lt;/span&gt;   &lt;span class="mi"&gt;26&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;41&lt;/span&gt;   &lt;span class="mi"&gt;40&lt;/span&gt; &lt;span class="mi"&gt;2240&lt;/span&gt;&lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.5615&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="lda"&gt;LDA&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Classifier&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;LDA&lt;/span&gt;
&lt;span class="n"&gt;Training&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;20.6464&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Testing&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.0910&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Confusion&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;2131&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;   &lt;span class="mi"&gt;47&lt;/span&gt;   &lt;span class="mi"&gt;20&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;   &lt;span class="mi"&gt;36&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;2454&lt;/span&gt;   &lt;span class="mi"&gt;20&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;   &lt;span class="mi"&gt;71&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;22&lt;/span&gt;   &lt;span class="mi"&gt;71&lt;/span&gt; &lt;span class="mi"&gt;1873&lt;/span&gt;   &lt;span class="mi"&gt;77&lt;/span&gt;   &lt;span class="mi"&gt;51&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;   &lt;span class="mi"&gt;82&lt;/span&gt;   &lt;span class="mi"&gt;20&lt;/span&gt;  &lt;span class="mi"&gt;101&lt;/span&gt;    &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;5&lt;/span&gt;   &lt;span class="mi"&gt;32&lt;/span&gt;   &lt;span class="mi"&gt;56&lt;/span&gt; &lt;span class="mi"&gt;1992&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;   &lt;span class="mi"&gt;77&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;   &lt;span class="mi"&gt;40&lt;/span&gt;   &lt;span class="mi"&gt;80&lt;/span&gt;   &lt;span class="mi"&gt;44&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;1&lt;/span&gt;   &lt;span class="mi"&gt;21&lt;/span&gt;   &lt;span class="mi"&gt;17&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;1983&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;   &lt;span class="mi"&gt;21&lt;/span&gt;  &lt;span class="mi"&gt;142&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;19&lt;/span&gt;   &lt;span class="mi"&gt;18&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;  &lt;span class="mi"&gt;112&lt;/span&gt;   &lt;span class="mi"&gt;18&lt;/span&gt; &lt;span class="mi"&gt;1682&lt;/span&gt;   &lt;span class="mi"&gt;37&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;  &lt;span class="mi"&gt;103&lt;/span&gt;   &lt;span class="mi"&gt;58&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;28&lt;/span&gt;   &lt;span class="mi"&gt;30&lt;/span&gt;   &lt;span class="mi"&gt;32&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;43&lt;/span&gt;   &lt;span class="mi"&gt;51&lt;/span&gt; &lt;span class="mi"&gt;2046&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;37&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;16&lt;/span&gt;   &lt;span class="mi"&gt;57&lt;/span&gt;   &lt;span class="mi"&gt;25&lt;/span&gt;   &lt;span class="mi"&gt;20&lt;/span&gt;   &lt;span class="mi"&gt;70&lt;/span&gt;    &lt;span class="mi"&gt;8&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;1990&lt;/span&gt;   &lt;span class="mi"&gt;11&lt;/span&gt;  &lt;span class="mi"&gt;220&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;   &lt;span class="mi"&gt;9&lt;/span&gt;  &lt;span class="mi"&gt;113&lt;/span&gt;   &lt;span class="mi"&gt;16&lt;/span&gt;   &lt;span class="mi"&gt;64&lt;/span&gt;   &lt;span class="mi"&gt;33&lt;/span&gt;  &lt;span class="mi"&gt;115&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="mi"&gt;1781&lt;/span&gt;   &lt;span class="mi"&gt;61&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;15&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;   &lt;span class="mi"&gt;35&lt;/span&gt;  &lt;span class="mi"&gt;133&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;  &lt;span class="mi"&gt;122&lt;/span&gt;   &lt;span class="mi"&gt;22&lt;/span&gt; &lt;span class="mi"&gt;2032&lt;/span&gt;&lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.8642&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="qda"&gt;QDA&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Classifier&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;QDA&lt;/span&gt;
&lt;span class="n"&gt;Training&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;23.0527&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Testing&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;6.2259&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
&lt;span class="n"&gt;Confusion&lt;/span&gt; &lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="o"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;2212&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;   &lt;span class="mi"&gt;20&lt;/span&gt;    &lt;span class="mi"&gt;5&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;66&lt;/span&gt; &lt;span class="mi"&gt;2409&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;32&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;   &lt;span class="mi"&gt;39&lt;/span&gt;   &lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;961&lt;/span&gt;   &lt;span class="mi"&gt;25&lt;/span&gt;  &lt;span class="mi"&gt;689&lt;/span&gt;  &lt;span class="mi"&gt;143&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;  &lt;span class="mi"&gt;310&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;  &lt;span class="mi"&gt;166&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1231&lt;/span&gt;   &lt;span class="mi"&gt;48&lt;/span&gt;   &lt;span class="mi"&gt;29&lt;/span&gt;  &lt;span class="mi"&gt;606&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt;   &lt;span class="mi"&gt;66&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;  &lt;span class="mi"&gt;232&lt;/span&gt;  &lt;span class="mi"&gt;110&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;810&lt;/span&gt;   &lt;span class="mi"&gt;22&lt;/span&gt;   &lt;span class="mi"&gt;25&lt;/span&gt;   &lt;span class="mi"&gt;27&lt;/span&gt;  &lt;span class="mi"&gt;250&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;  &lt;span class="mi"&gt;143&lt;/span&gt;   &lt;span class="mi"&gt;17&lt;/span&gt;  &lt;span class="mi"&gt;345&lt;/span&gt;  &lt;span class="mi"&gt;568&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;909&lt;/span&gt;   &lt;span class="mi"&gt;15&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt;   &lt;span class="mi"&gt;33&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;  &lt;span class="mi"&gt;214&lt;/span&gt;  &lt;span class="mi"&gt;140&lt;/span&gt;    &lt;span class="mi"&gt;4&lt;/span&gt;  &lt;span class="mi"&gt;666&lt;/span&gt;   &lt;span class="mi"&gt;74&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;83&lt;/span&gt;   &lt;span class="mi"&gt;18&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="mi"&gt;2146&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;81&lt;/span&gt;   &lt;span class="mi"&gt;13&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;   &lt;span class="mi"&gt;52&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;    &lt;span class="mi"&gt;2&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;  &lt;span class="mi"&gt;776&lt;/span&gt;  &lt;span class="mi"&gt;120&lt;/span&gt; &lt;span class="mi"&gt;1352&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="mi"&gt;487&lt;/span&gt;  &lt;span class="mi"&gt;181&lt;/span&gt;   &lt;span class="mi"&gt;18&lt;/span&gt;   &lt;span class="mi"&gt;20&lt;/span&gt;    &lt;span class="mi"&gt;6&lt;/span&gt;   &lt;span class="mi"&gt;17&lt;/span&gt;   &lt;span class="mi"&gt;58&lt;/span&gt;    &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="mi"&gt;1320&lt;/span&gt;  &lt;span class="mi"&gt;105&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
 &lt;span class="o"&gt;[&lt;/span&gt;  &lt;span class="mi"&gt;65&lt;/span&gt;   &lt;span class="mi"&gt;14&lt;/span&gt;   &lt;span class="mi"&gt;12&lt;/span&gt;    &lt;span class="mi"&gt;7&lt;/span&gt;   &lt;span class="mi"&gt;10&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;   &lt;span class="mi"&gt;23&lt;/span&gt;   &lt;span class="mi"&gt;33&lt;/span&gt; &lt;span class="mi"&gt;2225&lt;/span&gt;&lt;span class="o"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;Accuracy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.5561&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="mnist-summary_1"&gt;MNIST Summary&lt;/h2&gt;
&lt;table class="table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Classifier&lt;/th&gt;
&lt;th&gt;Accuracy&lt;/th&gt;
&lt;th&gt;Training Time&lt;/th&gt;
&lt;th&gt;Testing Time&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;MLP (500:200)&lt;/td&gt;
&lt;td style="text-align: right"&gt;97.98%&lt;/td&gt;
&lt;td style="text-align: right"&gt;79.5696s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.3480s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dropout NN (500:200)&lt;/td&gt;
&lt;td style="text-align: right"&gt;97.80%&lt;/td&gt;
&lt;td style="text-align: right"&gt;118.2654s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.3918s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CNN&lt;br/&gt;(32 5&amp;times;5 filters : 2&amp;times;2 max pool : 64 5&amp;times;5 filters : 2&amp;times;2 max pool : 1024)&lt;/td&gt;
&lt;td style="text-align: right"&gt;97.69%&lt;/td&gt;
&lt;td style="text-align: right"&gt;391.8810s&lt;/td&gt;
&lt;td style="text-align: right"&gt;1.2035s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Adjusted SVM&lt;/td&gt;
&lt;td style="text-align: right"&gt;&lt;b&gt;98.40%&lt;/b&gt;&lt;/td&gt;
&lt;td style="text-align: right"&gt;347.1539s&lt;/td&gt;
&lt;td class="danger" style="text-align: right"&gt;234.5724s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Linear SVM&lt;/td&gt;
&lt;td style="text-align: right"&gt;94.16%&lt;/td&gt;
&lt;td style="text-align: right"&gt;168.6950s&lt;/td&gt;
&lt;td class="danger" style="text-align: right"&gt;158.0101s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Random Forest (n_estimators=50, n_jobs=10)&lt;/td&gt;
&lt;td style="text-align: right"&gt;96.41%&lt;/td&gt;
&lt;td style="text-align: right"&gt;2.1359s&lt;/td&gt;
&lt;td class="danger" style="text-align: right"&gt;26.0763s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Random Forest (n_estimators=10, max_features=1, max_depth=5)&lt;/td&gt;
&lt;td class="danger" style="text-align: right"&gt;57.15%&lt;/td&gt;
&lt;td style="text-align: right"&gt;&lt;b&gt;0.2077s&lt;/b&gt;&lt;/td&gt;
&lt;td class="danger" style="text-align: right"&gt;22.2770s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;k nearest neightbors (k=3)&lt;/td&gt;
&lt;td style="text-align: right"&gt;96.95%&lt;/td&gt;
&lt;td style="text-align: right"&gt;4.6439s&lt;/td&gt;
&lt;td class="danger" style="text-align: right"&gt;1261.7815s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Decision Tree(max_depth=5)&lt;/td&gt;
&lt;td class="danger" style="text-align: right"&gt;65.40%&lt;/td&gt;
&lt;td style="text-align: right"&gt;3.1346s&lt;/td&gt;
&lt;td style="text-align: right"&gt;&lt;b&gt;0.0313s&lt;/b&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Adaboost&lt;/td&gt;
&lt;td class="danger" style="text-align: right"&gt;73.67%&lt;/td&gt;
&lt;td style="text-align: right"&gt;37.6443s&lt;/td&gt;
&lt;td style="text-align: right"&gt;1.5815s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Naive Bayes&lt;/td&gt;
&lt;td class="danger" style="text-align: right"&gt;56.15%&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.3814s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.8863s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;LDA&lt;/td&gt;
&lt;td style="text-align: right"&gt;86.42%&lt;/td&gt;
&lt;td style="text-align: right"&gt;20.6464s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0910s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;QDA&lt;/td&gt;
&lt;td class="danger" style="text-align: right"&gt;55.61%&lt;/td&gt;
&lt;td style="text-align: right"&gt;23.0527s&lt;/td&gt;
&lt;td class="danger" style="text-align: right"&gt;6.2259s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Gradient Boosting&lt;/td&gt;
&lt;td style="text-align: right"&gt;94.35%&lt;/td&gt;
&lt;td style="text-align: right"&gt;2409.8094s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.4159s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Logistic Regression (C=1)&lt;/td&gt;
&lt;td style="text-align: right"&gt;91.47%&lt;/td&gt;
&lt;td style="text-align: right"&gt;272.1309s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0531s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Logistic Regression (C=10000)&lt;/td&gt;
&lt;td style="text-align: right"&gt;91.23%&lt;/td&gt;
&lt;td style="text-align: right"&gt;1807.0624s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0529s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id="iris-summary"&gt;IRIS summary&lt;/h2&gt;
&lt;p&gt;Just for fun, I tried the script from above with very minor adjustments to the
&lt;a href="https://en.wikipedia.org/wiki/Iris_flower_data_set"&gt;IRIS flower dataset&lt;/a&gt;:&lt;/p&gt;
&lt;table class="table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Classifier&lt;/th&gt;
&lt;th&gt;Accuracy&lt;/th&gt;
&lt;th&gt;Training Time&lt;/th&gt;
&lt;th&gt;Testing Time&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;AdaBoost&lt;/td&gt;
&lt;td style="text-align: right"&gt;92.00%&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.1203s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0101s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Decision Tree&lt;/td&gt;
&lt;td style="text-align: right"&gt;92.00%&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0005s&lt;/td&gt;
&lt;td style="text-align: right"&gt;&lt;b&gt;0.0001s&lt;/b&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Gradient Boosting&lt;/td&gt;
&lt;td style="text-align: right"&gt;92.00%&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.2227s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0007s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;LDA&lt;/td&gt;
&lt;td style="text-align: right"&gt;&lt;b&gt;96.00%&lt;/b&gt;&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0027s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0002s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NN 20:5&lt;/td&gt;
&lt;td style="text-align: right"&gt;90.00%&lt;/td&gt;
&lt;td style="text-align: right"&gt;1.6628s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0046s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Naive Bayes&lt;/td&gt;
&lt;td style="text-align: right"&gt;90.00%&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0010s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0004s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;QDA&lt;/td&gt;
&lt;td style="text-align: right"&gt;94.00%&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0009s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0003s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Random Forest&lt;/td&gt;
&lt;td style="text-align: right"&gt;90.00%&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.2147s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.1395s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Random Forest 2&lt;/td&gt;
&lt;td style="text-align: right"&gt;90.00%&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.1481s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.1249s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SVM, adj.&lt;/td&gt;
&lt;td style="text-align: right"&gt;90.00%&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0010s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0004s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SVM, linear&lt;/td&gt;
&lt;td class="danger" style="text-align: right"&gt;88.00%&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0006s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0002s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;k nn&lt;/td&gt;
&lt;td style="text-align: right"&gt;92.00%&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0007s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0009s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Logistic Regression (C=1)&lt;/td&gt;
&lt;td class="danger" style="text-align: right"&gt;88.00%&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0011s&lt;/td&gt;
&lt;td style="text-align: right"&gt;&lt;b&gt;0.0001s&lt;/b&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Logistic Regression (C=1000)&lt;/td&gt;
&lt;td style="text-align: right"&gt;92.00%&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0010s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0002s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;RBM 100&lt;/td&gt;
&lt;td class="danger" style="text-align: right"&gt;78.00%&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0233s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0003s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;RBM 100, n_iter=20&lt;/td&gt;
&lt;td class="danger" style="text-align: right"&gt;70.00%&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0427s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0003s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;RBM 200, n_iter=40, LR=0.01, Reg: C=1&lt;/td&gt;
&lt;td class="danger" style="text-align: right"&gt;88.00%&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.2463s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0005s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;RBM 200, n_iter=40, LR=0.01, Reg: C=10000&lt;/td&gt;
&lt;td style="text-align: right"&gt;90.00%&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.2437s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0005s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;RBM 256&lt;/td&gt;
&lt;td class="danger" style="text-align: right"&gt;84.00%&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0424s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0006s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;RBM 512, n_iter=100&lt;/td&gt;
&lt;td class="danger" style="text-align: right"&gt;84.00%&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0723s&lt;/td&gt;
&lt;td style="text-align: right"&gt;0.0010s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id="tldr"&gt;TL;DR&lt;/h2&gt;
&lt;p&gt;Neural networks take their time to train and a feeling for the topology, but
their classification results are nice and the testing time is good as well.&lt;/p&gt;
&lt;p&gt;Random Forests and SVMs are also a model a type of model one should think of.
However, the stard implementation is very slow compared to neural networks.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://scikit-learn.org/0.16/modules/generated/sklearn.lda.LDA.html"&gt;&lt;code&gt;sklearn.lda.LDA&lt;/code&gt;&lt;/a&gt;
might also be worth a try. The rest seems to be quite bad compared with those
classifiers.&lt;/p&gt;
&lt;p&gt;The code which generated the examples from above is &lt;a href="https://github.com/MartinThoma/algorithms/tree/master/ML/mnist/many-classifiers"&gt;here&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Martin Thoma</dc:creator><pubDate>Tue, 19 Jan 2016 20:13:00 +0100</pubDate><guid>tag:martin-thoma.com,2016-01-19:comparing-classifiers/</guid><category>Python</category><category>Machine Learning</category><category>Classification</category></item><item><title>Function Approximation</title><link>https://martin-thoma.com/function-approximation/</link><description>&lt;p&gt;I was recently quite disappointed by how bad neural networks are for function
approximation (see &lt;a href="http://datascience.stackexchange.com/q/9495/8820"&gt;How should a neural network for unbound function approximation be structured?&lt;/a&gt;). However, I've just found that
Gaussian processes are great for function approximation!&lt;/p&gt;
&lt;p&gt;There are two important types of function approximation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Interpolation&lt;/strong&gt;: What values does the function have in between of known
  values?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Extrapolation&lt;/strong&gt;: What values does the function have outsive of the known
  values?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I did a couple of very quick examples which look promising.&lt;/p&gt;
&lt;h2 id="examples"&gt;Examples&lt;/h2&gt;
&lt;h3 id="square"&gt;Square&lt;/h3&gt;
&lt;p&gt;Approximating &lt;span class="math"&gt;\(f(x) = x^2\)&lt;/span&gt; worked very good:&lt;/p&gt;
&lt;figure class="aligncenter"&gt;
&lt;a href="../images/2016/01/gauss-x2.png"&gt;&lt;img alt="f(x) = x^2" class="" src="../images/2016/01/gauss-x2.png" style="max-width:500px;"/&gt;&lt;/a&gt;
&lt;figcaption class="text-center"&gt;f(x) = x^2&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;I've tried if with higher order polynomials, more complex polynomials. No
problem.&lt;/p&gt;
&lt;h3 id="sin"&gt;Sin&lt;/h3&gt;
&lt;p&gt;Approximating &lt;span class="math"&gt;\(f(x) = \sin(3x)\)&lt;/span&gt; seems to be more complicated:&lt;/p&gt;
&lt;figure class="aligncenter"&gt;
&lt;a href="../images/2016/01/gaussian-process-sin-3x.png"&gt;&lt;img alt="f(x) = sin(3x)" class="" src="../images/2016/01/gaussian-process-sin-3x.png" style="max-width:500px;"/&gt;&lt;/a&gt;
&lt;figcaption class="text-center"&gt;f(x) = sin(3x)&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;I guess a human would see the wave pattern and do a better job here.&lt;/p&gt;
&lt;h3 id="exp"&gt;exp&lt;/h3&gt;
&lt;p&gt;Approximating &lt;span class="math"&gt;\(f(x) = e^x\)&lt;/span&gt; works similar well as polynomials. One can see
that it does not perfectly fit it, but compared the the range of values seen
before and the distance from the last seen value I think this is absolutely
acceptable:&lt;/p&gt;
&lt;figure class="aligncenter"&gt;
&lt;a href="../images/2016/01/gauss-exponential.png"&gt;&lt;img alt="f(x) = e^x" class="" src="../images/2016/01/gauss-exponential.png" style="max-width:500px;"/&gt;&lt;/a&gt;
&lt;figcaption class="text-center"&gt;f(x) = e^x&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3 id="noise"&gt;noise&lt;/h3&gt;
&lt;p&gt;It is claimed that Gaussian processes implicitly model noise so that they can
easily deal with noise. However, in my experients this seems not to work so
great. The reason might be that I had points in &lt;span class="math"&gt;\([-3, 3]\)&lt;/span&gt; of the function&lt;/p&gt;
&lt;div class="math"&gt;$$f(x) = x^2$$&lt;/div&gt;
&lt;p&gt;with point-wise gaussian noise &lt;span class="math"&gt;\(N \sim \mathcal{N}(0, 1)\)&lt;/span&gt;. So the noise is
quite domintant on that intervall. One of the examples where it worked better
is:&lt;/p&gt;
&lt;figure class="aligncenter"&gt;
&lt;a href="../images/2016/01/gauss-noise.png"&gt;&lt;img alt="f(x) = x^2 with gaussian noise" class="" src="../images/2016/01/gauss-noise.png" style="max-width:500px;"/&gt;&lt;/a&gt;
&lt;figcaption class="text-center"&gt;f(x) = x^2 with gaussian noise&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3 id="make-it-brake"&gt;Make it brake&lt;/h3&gt;
&lt;p&gt;I was a bit suspicious if I had another mistake here. So I wanted it to break.
This was the reason why I created the following function&lt;/p&gt;
&lt;div class="math"&gt;$$f(x) = \begin{cases}x^2 &amp;amp;\text{if } x \geq 0\\\\-1 &amp;amp;\text{otherwise}\end{cases}$$&lt;/div&gt;
&lt;figure class="aligncenter"&gt;
&lt;a href="../images/2016/01/gauss-cases.png"&gt;&lt;img alt="Function with discontinuity" class="" src="../images/2016/01/gauss-cases.png" style="max-width:500px;"/&gt;&lt;/a&gt;
&lt;figcaption class="text-center"&gt;Function with discontinuity&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The predicted value is obviously not correct, but you should note that almost
all function values are within the 95% confidence intervall!&lt;/p&gt;
&lt;h2 id="code_1"&gt;Code&lt;/h2&gt;
&lt;p&gt;The following code needs &lt;a href="http://docs.scipy.org/doc/numpy-1.10.1/user/install.html"&gt;&lt;code&gt;numpy&lt;/code&gt;&lt;/a&gt;
and &lt;a href="http://scikit-learn.org/stable/install.html"&gt;&lt;code&gt;sklearn&lt;/code&gt;&lt;/a&gt;. For the plots,
you need &lt;a href="http://matplotlib.org/users/installing.html"&gt;&lt;code&gt;matplotlib&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="ch"&gt;#!/usr/bin/env python&lt;/span&gt;

&lt;span class="sd"&gt;"""Example how to use gaussion processes for regression."""&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;gaussian_process&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="c1"&gt;# Create the dataset&lt;/span&gt;
    &lt;span class="n"&gt;x_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;atleast_2d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;
    &lt;span class="n"&gt;y_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;x_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;atleast_2d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;

    &lt;span class="c1"&gt;# Define the Regression Modell and fit it&lt;/span&gt;
    &lt;span class="n"&gt;gp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gaussian_process&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GaussianProcess&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;theta0&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                          &lt;span class="n"&gt;thetaL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                          &lt;span class="n"&gt;thetaU&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;gp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Evaluate the result&lt;/span&gt;
    &lt;span class="n"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mse&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;eval_MSE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"MSE: &lt;/span&gt;&lt;span class="si"&gt;%0.4f&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mse&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"max MSE: &lt;/span&gt;&lt;span class="si"&gt;%0.4f&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mse&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;plot_graph&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mse&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"x^2"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;    Function which gets approximated&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;

    &lt;span class="n"&gt;noise&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)))]&lt;/span&gt;
    &lt;span class="n"&gt;noise&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;atleast_2d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;noise&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;noise&lt;/span&gt;
    &lt;span class="c1"&gt;# Totally fails for that one:&lt;/span&gt;
    &lt;span class="c1"&gt;# y = []&lt;/span&gt;
    &lt;span class="c1"&gt;# for el in x:&lt;/span&gt;
    &lt;span class="c1"&gt;#     if el &amp;gt;= 0:&lt;/span&gt;
    &lt;span class="c1"&gt;#         y.append(el**2)&lt;/span&gt;
    &lt;span class="c1"&gt;#     else:&lt;/span&gt;
    &lt;span class="c1"&gt;#         y.append(-1)&lt;/span&gt;
    &lt;span class="c1"&gt;# return np.array(y)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;plot_graph&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mse&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;function_tex&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# Plot the function, the prediction and the 95% confidence interval&lt;/span&gt;
    &lt;span class="c1"&gt;# based on the MSE&lt;/span&gt;
    &lt;span class="n"&gt;sigma&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mse&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;pl&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;'r:'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;u'$f(x) = &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;$'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;function_tex&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'r.'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;u'Observations'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'b-'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;u'Prediction'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fill&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[::&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]]),&lt;/span&gt;
            &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;y_pred&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mf"&gt;1.9600&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_pred&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mf"&gt;1.9600&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;)[::&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]]),&lt;/span&gt;
            &lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="o"&gt;=.&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'b'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ec&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'None'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'95&lt;/span&gt;&lt;span class="si"&gt;% c&lt;/span&gt;&lt;span class="s1"&gt;onfidence interval'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'$x$'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'$f(x)$'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;y_min&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mf"&gt;1.1&lt;/span&gt;
    &lt;span class="n"&gt;y_max&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mf"&gt;1.1&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_min&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_max&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'upper left'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;pl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="see-also"&gt;See also&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.gaussianprocess.org/"&gt;www.gaussianprocess.org&lt;/a&gt;: The definitive book about gaussian processes. It's freely available online!&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Kriging"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;sklearn: &lt;a href="http://scikit-learn.org/stable/modules/gaussian_process.html"&gt;Gaussian Processes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;sklearn: &lt;a href="http://scikit-learn.org/stable/auto_examples/gaussian_process/plot_gp_regression.html"&gt;Gaussian Processes regression: basic introductory example&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Martin Thoma</dc:creator><pubDate>Mon, 18 Jan 2016 20:00:00 +0100</pubDate><guid>tag:martin-thoma.com,2016-01-18:function-approximation/</guid><category>Machine Learning</category><category>Regression</category></item><item><title>Using SVMs with sklearn</title><link>https://martin-thoma.com/svm-with-sklearn/</link><description>&lt;p&gt;Support Vector Machines (SVMs) is a group of powerful classifiers. In this
article, I will give a short impression of how they work. I continue
with an example how to use SVMs with sklearn.&lt;/p&gt;
&lt;h2 id="svm-theory"&gt;SVM theory&lt;/h2&gt;
&lt;p&gt;&lt;abbr title="Support Vector Machines"&gt;SVMs&lt;/abbr&gt; can be described with
5&amp;nbsp;ideas in mind:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;b&gt;Linear, binary classifiers&lt;/b&gt;: If data is linearly separable, it
        can be separated by a hyperplane. There is one hyperplane which
        maximizes the distance to the next datapoints (support vectors). This
        hyperplane should be taken:&lt;br/&gt;
&lt;div&gt;
          $$
          \begin{aligned}
              \text{minimize}_{\mathbf{w}, b}\,&amp;amp;\frac{1}{2} \|\mathbf{w}\|^2\\
              \text{s.t. }&amp;amp; \forall_{i=1}^m y_i \cdot \underbrace{(\langle \mathbf{w}, \mathbf{x}_i\rangle + b)}_{\text{Classification}} \geq 1
          \end{aligned}$$&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Slack variables&lt;/b&gt;: Even if the underlying process which generates
          the features for the two classes is linearly separable, noise can
          make the data not separable. The introduction of &lt;i&gt;slack&amp;nbsp;variables&lt;/i&gt;
          to relax the requirement of linear separability solves
          this problem. The trade-off between accepting some errors and a more
          complex model is weighted by a parameter $C \in \mathbb{R}_0^+$. The
          bigger $C$, the more errors are accepted. The new optimization
          problem is:
          $$
          \begin{aligned}
              \text{minimize}_{\mathbf{w}, b}\,&amp;amp;\frac{1}{2} \|\mathbf{w}\|^2 + C \cdot \sum_{i=1}^m \xi_i\\
              \text{s.t. }&amp;amp; \forall_{i=1}^m y_i \cdot (\langle \mathbf{w}, \mathbf{x}_i\rangle + b) \geq 1 - \xi_i
          \end{aligned}$$

          Note that $0 \le \xi_i \le 1$ means that the data point is within
          the margin, whereas $\xi_i \ge 1$ means it is misclassified. An
          SVM with $C &amp;gt; 0$ is also called a &lt;i&gt;soft-margin SVM&lt;/i&gt;.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Dual Problem&lt;/b&gt;: The primal problem is to find the normal vector $\mathbf{w}$ and the
          bias $b$. The dual problem is to express $\mathbf{w}$ as a linear
          combination of the training data $\mathbf{x}_i$:
          $$\mathbf{w} = \sum_{i=1}^m \alpha_i y_i \mathbf{x}_i$$
          where $y_i \in \{-1, 1\}$ represents the class of the training
          example and $\alpha_i$ are Lagrange multipliers. The usage of
          Lagrange multipliers is explained with some examples
          in [&lt;a href="#ref-smi04" name="ref-smi04-anchor"&gt;Smi04&lt;/a&gt;]. The usage of the Lagrange multipliers
          $\alpha_i$ changes the optimization problem depend on the
          $\alpha_i$ which are weights for the feature vectors. It turns
          out that most $\alpha_i$ will be zero. The non-zero weighted vectors
          are called &lt;i&gt;support&amp;nbsp;vectors&lt;/i&gt;.

          The optimization problem is now, according to [&lt;a href="#ref-bur98" name="ref-bur98-anchor"&gt;Bur98&lt;/a&gt;] (a great read; if you really want to understand it I can recommend it!):
          $$
          \begin{aligned}
              \text{maximize}_{\alpha_i}\,&amp;amp; \sum_{i=1}^m \alpha_i - \frac{1}{2} \sum_{i=1}^m \sum_{j=1}^m \alpha_i \alpha_j y_i y_j \langle \mathbf{x}_i, \mathbf{x}_j \rangle\\
              \text{s.t. } &amp;amp; \forall_{i=1}^m 0 \leq \alpha_i \leq C\\
              \text{s.t. } &amp;amp; \sum_{i=1}^m \alpha_i y_i = 0
          \end{aligned}$$&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Kernel-Trick&lt;/b&gt;: Not every dataset is linearly separable. This problem is approached
          by transforming the feature vectors $\mathbf{x}$ with a non-linear
          mapping $\Phi$ into a higher dimensional (probably
          $\infty$-dimensional) space. As the feature vectors $\mathbf{x}$
          are only used within scalar product
          $\langle \mathbf{x}_i, \mathbf{x}_j \rangle$, it is not necessary to
          do the transformation. It is enough to do the calculation
          $$K(\mathbf{x}_i, \mathbf{x}_j) = \langle \mathbf{x}_i, \mathbf{x}_j \rangle$$

          This function $K$ is called a &lt;i&gt;kernel&lt;/i&gt;. The idea of never
          explicitly transforming the vectors $\mathbf{x}_i$ to the higher
          dimensional space is called the &lt;i&gt;kernel&amp;nbsp;trick&lt;/i&gt;. Common kernels
          include the polynomial kernel
          $$K_P(\mathbf{x}_i, \mathbf{x}_j) = (\langle \mathbf{x}_i, \mathbf{x}_j \rangle + r)^p$$
          of degree $p$ and coefficient $r$, the Gaussian &lt;abbr title="Radial Basis Function"&gt;RBF&lt;/abbr&gt; kernel
          $$K_{\text{Gauss}}(\mathbf{x}_i, \mathbf{x}_j) = e^{\frac{-\gamma\|\mathbf{x}_i - \mathbf{x}_j\|^2}{2 \sigma^2}}$$
          and the sigmoid kernel
          $$K_{\text{tanh}}(\mathbf{x}_i, \mathbf{x}_j) = \tanh(\gamma \langle \mathbf{x}_i, \mathbf{x}_j \rangle - r)$$
          where the parameter $\gamma$ determines how much influence single
          training examples have.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Multiple Classes&lt;/b&gt;: By using the &lt;i&gt;one-vs-all&lt;/i&gt; or the
        &lt;i&gt;one-vs-one&lt;/i&gt; strategy it is possible to get a classifying system
        which can distinguish many classes.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A nice visualization of the transformation of the data in a higher-dimensional
space was done by&lt;/p&gt;
&lt;p&gt;TeamGrizzly's channel: &lt;a href="https://youtu.be/9NrALgHFwTo"&gt;Performing nonlinear classification via linear separation in higher dimensional space&lt;/a&gt; on YouTube. 22.11.2010.&lt;/p&gt;
&lt;p&gt;See also:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://math.stackexchange.com/a/1620256/6876"&gt;What is an example of a SVM kernel, where one implicitly uses an infinity-dimensional space?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/a/4630731/562769"&gt;SVM - hard or soft margins?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="sklearn"&gt;sklearn&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;sklearn&lt;/code&gt; is the machine learning toolkit to get started for Python. It has
a very good documentation and many functions. You can find &lt;a href="http://scikit-learn.org/stable/install.html"&gt;installation
instructions&lt;/a&gt; on their website.&lt;/p&gt;
&lt;p&gt;It also includes &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC"&gt;&lt;code&gt;sklearn.svm.SVC&lt;/code&gt;&lt;/a&gt;.
SVC is short for &lt;em&gt;support vector classifier&lt;/em&gt; and this is how you use it for
the MNIST dataset.&lt;/p&gt;
&lt;p&gt;Parameters for which you might want a further explanation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cache_size&lt;/code&gt;: &lt;a href="http://datascience.stackexchange.com/a/996/8820"&gt;datascience.stackexchange.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="ch"&gt;#!/usr/bin/env python&lt;/span&gt;

&lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;Train a SVM to categorize 28x28 pixel images into digits (MNIST dataset).&lt;/span&gt;
&lt;span class="sd"&gt;"""&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="sd"&gt;"""Orchestrate the retrival of data, training and testing."""&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_data&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="c1"&gt;# Get classifier&lt;/span&gt;
    &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.svm&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SVC&lt;/span&gt;
    &lt;span class="n"&gt;clf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SVC&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;probability&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="c1"&gt;# cache_size=200,&lt;/span&gt;
              &lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"rbf"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;2.8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;gamma&lt;/span&gt;&lt;span class="o"&gt;=.&lt;/span&gt;&lt;span class="mo"&gt;0073&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Start fitting. This may take a while"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# take all of it - make that number lower for experiments&lt;/span&gt;
    &lt;span class="n"&gt;examples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'train'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'X'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'train'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'X'&lt;/span&gt;&lt;span class="p"&gt;][:&lt;/span&gt;&lt;span class="n"&gt;examples&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'train'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'y'&lt;/span&gt;&lt;span class="p"&gt;][:&lt;/span&gt;&lt;span class="n"&gt;examples&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="n"&gt;analyze&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;analyze&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;    Analyze how well a classifier performs on data.&lt;/span&gt;

&lt;span class="sd"&gt;    Parameters&lt;/span&gt;
&lt;span class="sd"&gt;    ----------&lt;/span&gt;
&lt;span class="sd"&gt;    clf : classifier object&lt;/span&gt;
&lt;span class="sd"&gt;    data : dict&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="c1"&gt;# Get confusion matrix&lt;/span&gt;
    &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt;
    &lt;span class="n"&gt;predicted&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'test'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'X'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Confusion matrix:&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;
          &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;confusion_matrix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'test'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'y'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                                   &lt;span class="n"&gt;predicted&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Accuracy: &lt;/span&gt;&lt;span class="si"&gt;%0.4f&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'test'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'y'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                                                     &lt;span class="n"&gt;predicted&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="c1"&gt;# Print example&lt;/span&gt;
    &lt;span class="n"&gt;try_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'test'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'X'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;try_id&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;  &lt;span class="c1"&gt;# clf.predict_proba&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"out: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'test'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'X'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;try_id&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;view_image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'test'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'X'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;try_id&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
               &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'test'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'y'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;try_id&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;view_image&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;    View a single image.&lt;/span&gt;

&lt;span class="sd"&gt;    Parameters&lt;/span&gt;
&lt;span class="sd"&gt;    ----------&lt;/span&gt;
&lt;span class="sd"&gt;    image : numpy array&lt;/span&gt;
&lt;span class="sd"&gt;        Make sure this is of the shape you want.&lt;/span&gt;
&lt;span class="sd"&gt;    label : str&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cm&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Label: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gray&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_data&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;    Get data ready to learn with.&lt;/span&gt;

&lt;span class="sd"&gt;    Returns&lt;/span&gt;
&lt;span class="sd"&gt;    -------&lt;/span&gt;
&lt;span class="sd"&gt;    dict&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="n"&gt;simple&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;simple&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="c1"&gt;# Load the simple, but similar digits dataset&lt;/span&gt;
        &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;load_digits&lt;/span&gt;
        &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.utils&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;shuffle&lt;/span&gt;
        &lt;span class="n"&gt;digits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_digits&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;el&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flatten&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;el&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;digits&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;images&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;digits&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;

        &lt;span class="c1"&gt;# Scale data to [-1, 1] - This is of mayor importance!!!&lt;/span&gt;
        &lt;span class="c1"&gt;# In this case, I know the range and thus I can (and should) scale&lt;/span&gt;
        &lt;span class="c1"&gt;# manually. However, this might not always be the case.&lt;/span&gt;
        &lt;span class="c1"&gt;# Then try sklearn.preprocessing.MinMaxScaler or&lt;/span&gt;
        &lt;span class="c1"&gt;# sklearn.preprocessing.StandardScaler&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;255.0&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

        &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;
        &lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                            &lt;span class="n"&gt;test_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.33&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                            &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'train'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'X'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                          &lt;span class="s1"&gt;'y'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
                &lt;span class="s1"&gt;'test'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'X'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                         &lt;span class="s1"&gt;'y'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;}}&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="c1"&gt;# Load the original dataset&lt;/span&gt;
        &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;fetch_mldata&lt;/span&gt;
        &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.utils&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;shuffle&lt;/span&gt;
        &lt;span class="n"&gt;mnist&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fetch_mldata&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'MNIST original'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mnist&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;
        &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mnist&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;

        &lt;span class="c1"&gt;# Scale data to [-1, 1] - This is of mayor importance!!!&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;255.0&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

        &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.cross_validation&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;
        &lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                            &lt;span class="n"&gt;test_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.33&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                            &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'train'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'X'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                          &lt;span class="s1"&gt;'y'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
                &lt;span class="s1"&gt;'test'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'X'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                         &lt;span class="s1"&gt;'y'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;}}&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="results"&gt;Results&lt;/h2&gt;
&lt;p&gt;The script from above gives the following results:&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;Confusion matrix for an SVM classifier on the MNIST dataset&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;th&gt;4&lt;/th&gt;
&lt;th&gt;5&lt;/th&gt;
&lt;th&gt;6&lt;/th&gt;
&lt;th&gt;7&lt;/th&gt;
&lt;th&gt;8&lt;/th&gt;
&lt;th&gt;9&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;2258&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;2566&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;2280&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;14&lt;/td&gt;
&lt;td&gt;2304&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;4&lt;/th&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;2183&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;5&lt;/th&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;2026&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;6&lt;/th&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2245&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;7&lt;/th&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;2373&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;8&lt;/th&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;2166&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;9&lt;/th&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;19&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;2329&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;Accuracy: 98.40%&lt;/li&gt;
&lt;li&gt;Error: 1.60%&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Looks pretty good to me. However, note that there are much better results.
The best on &lt;a href="http://yann.lecun.com/exdb/mnist/"&gt;the official website&lt;/a&gt; has an
error of 0.23% and is a committee of 35 convolutional neural networks.&lt;/p&gt;
&lt;p&gt;The best SVM I could find has an error of 0.56% and applies a polynomial kernel
of degree&amp;nbsp;9 as well as some preprocessing.&lt;/p&gt;
&lt;h2 id="references"&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;[&lt;a href="#ref-smi04-anchor" name="ref-smi04"&gt;Smi04&lt;/a&gt;] B. T. Smith, &amp;ldquo;Lagrange multipliers tutorial in the context of support
  vector machines,&amp;rdquo; Memorial University of Newfoundland St. John&amp;rsquo;s,
  Newfoundland, Canada, Jun. 2004.&lt;/li&gt;
&lt;li&gt;[&lt;a href="#ref-bur98-anchor" name="ref-bur98"&gt;Bur98&lt;/a&gt;] C. J. Burges, &amp;ldquo;&lt;a href="http://research.microsoft.com/pubs/67119/svmtutorial.pdf"&gt;A tutorial on support vector machines for pattern recognition&lt;/a&gt;&amp;rdquo;, Data&amp;nbsp;mining and knowledge discovery, vol. 2, no. 2, pp.
  121&amp;ndash;167, 1998.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="see-also"&gt;See also&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html"&gt;Recognizing hand-written digits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Trung Huynh's tech blog: &lt;a href="http://www.trungh.com/2013/04/digit-recognition-using-svm-in-python/"&gt;Digit Recognition using SVM in Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html"&gt;Classifier comparison&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-learn.org/stable/supervised_learning.html"&gt;Supervised learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stats.stackexchange.com/questions/80398/how-can-svm-find-an-infinite-feature-space-where-linear-separation-is-always-p"&gt;How can SVM 'find' an infinite feature space where linear separation is always possible?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Martin Thoma</dc:creator><pubDate>Thu, 14 Jan 2016 12:25:00 +0100</pubDate><guid>tag:martin-thoma.com,2016-01-14:svm-with-sklearn/</guid><category>Python</category><category>Machine Learning</category><category>SVM</category><category>Classification</category></item><item><title>Tensor Flow - A quick impression</title><link>https://martin-thoma.com/tensor-flow-quick/</link><description>&lt;p&gt;Tensor Flow is a machine learning toolkit which recently got published by
Google. They published it under &lt;a href="https://tldrlegal.com/license/apache-license-2.0-(apache-2.0)"&gt;Apache License 2.0&lt;/a&gt;. Looking at the source code overview, it seems to be mainly C++
with a significant bit of Python.&lt;/p&gt;
&lt;p&gt;I guess the abstract of the
&lt;a href="http://download.tensorflow.org/paper/whitepaper2015.pdf"&gt;Whitepaper&lt;/a&gt; is a good
description what TensorFlow is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;TensorFlow is an interface for expressing machine learning algorithms, and an
implementation for executing such algorithms. A computation expressed using
TensorFlow can be executed with little or no change on a wide variety of
heterogeneous systems, ranging from mobile devices such as phones and tablets
up to large-scale distributed systems of hundreds of machines and thousands
of computational devices such as GPU cards. The system is flexible and can be
used to express a wide variety of algorithms, including training and
inference algorithms for deep neural network models, and it has been used for
conducting research and for deploying machine learning systems into
production across more than a dozen areas of computer science and other
fields, including speech recognition, computer vision, robotics, information
retrieval, natural language processing, geographic information extraction,
and computational drug discovery. This paper describes the TensorFlow
interface and an implementation of that interface that we have built at
Google. The TensorFlow API and a reference implementation were released as an
open-source package under the Apache 2.0 license in November, 2015 and are
available at www.tensorflow.org.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The core seems to be written in C++, but it has a Python front end.&lt;/p&gt;
&lt;p&gt;By now, I couldn't test much because I just made my GPU machine unusable
(while trying to get the GPU General Computing practical software to run...).
I'll try to expand this article as soon as possible, but I guess it might
take several weeks until I have enough time. Lets see...&lt;/p&gt;
&lt;h2 id="installation"&gt;Installation&lt;/h2&gt;
&lt;p&gt;The documentation about the installation makes a VERY good impression. Better
than anything I can write in a few minutes, so ... &lt;a href="http://tensorflow.org/get_started/os_setup.md"&gt;RTFM&lt;/a&gt;
 😜&lt;/p&gt;
&lt;p&gt;For Linux systems with CUDA and without root privileges, you can install it
with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;$ pip install https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl --user
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;But remember you have to set the environment variable &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt; and
&lt;code&gt;CUDA_HOME&lt;/code&gt;. For many configurations, adding the following lines to your
&lt;code&gt;.bashrc&lt;/code&gt; will work:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;$&lt;span class="s2"&gt;LD_LIBRARY_PATH:/usr/local/cuda/lib64"&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;CUDA_HOME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/usr/local/cuda
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="mnist"&gt;MNIST&lt;/h2&gt;
&lt;p&gt;The following code can be used to check if your Tensor Flow installation is
working. You have to have the &lt;a href="https://gist.github.com/MartinThoma/f37150d0c521f598b08a"&gt;&lt;code&gt;get_mnist_data_tf.py&lt;/code&gt;&lt;/a&gt;
in the same directory as the following script. I've - more or less - directly
copied it from &lt;a href="http://tensorflow.org/tutorials/mnist/pros/index.md"&gt;the tutorial&lt;/a&gt;.
Just execute the script below and see if it finishes without throwing errors.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="ch"&gt;#!/usr/bin/env python&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;get_mnist_data_tf&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;read_data_sets&lt;/span&gt;
&lt;span class="n"&gt;mnist&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;read_data_sets&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"MNIST_data/"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;one_hot&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;tf&lt;/span&gt;
&lt;span class="n"&gt;sess&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;InteractiveSession&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"float"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;784&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;y_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"float"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;W&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;784&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;span class="n"&gt;sess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;initialize_all_variables&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;W&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cross_entropy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;train_step&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GradientDescentOptimizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;minimize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cross_entropy&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;batch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mnist&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next_batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;train_step&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;feed_dict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y_&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]})&lt;/span&gt;
&lt;span class="n"&gt;correct_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;equal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;accuracy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;correct_prediction&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"float"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;feed_dict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;mnist&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;images&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                               &lt;span class="n"&gt;y_&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;mnist&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;}))&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;weight_variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;initial&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;initial&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;bias_variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;initial&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;initial&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;conv2d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;W&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conv2d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;W&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;strides&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'SAME'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;max_pool_2x2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max_pool&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ksize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                        &lt;span class="n"&gt;strides&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'SAME'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;W_conv1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;weight_variable&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;b_conv1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bias_variable&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="n"&gt;x_image&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="n"&gt;h_conv1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv2d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_image&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;W_conv1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b_conv1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;h_pool1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;max_pool_2x2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h_conv1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;W_conv2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;weight_variable&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;b_conv2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bias_variable&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="n"&gt;h_conv2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv2d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h_pool1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;W_conv2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b_conv2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;h_pool2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;max_pool_2x2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h_conv2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;W_fc1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;weight_variable&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;b_fc1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bias_variable&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="n"&gt;h_pool2_flat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h_pool2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;h_fc1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h_pool2_flat&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;W_fc1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b_fc1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;keep_prob&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"float"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;h_fc1_drop&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h_fc1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;keep_prob&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;W_fc2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;weight_variable&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;b_fc2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bias_variable&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="n"&gt;y_conv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h_fc1_drop&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;W_fc2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b_fc2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;cross_entropy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_conv&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;train_step&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;AdamOptimizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1e-4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;minimize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cross_entropy&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;correct_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;equal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_conv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;accuracy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;correct_prediction&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"float"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;sess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;initialize_all_variables&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;batch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mnist&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next_batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;train_accuracy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;feed_dict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y_&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;keep_prob&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"step &lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s2"&gt;, training accuracy &lt;/span&gt;&lt;span class="si"&gt;%g&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_accuracy&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="n"&gt;train_step&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;feed_dict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y_&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;keep_prob&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"test accuracy &lt;/span&gt;&lt;span class="si"&gt;%g&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;feed_dict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;mnist&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;images&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;mnist&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;keep_prob&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;}))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="observations"&gt;Observations&lt;/h2&gt;
&lt;p&gt;While looking at the MNIST example, I made a couple of observations. Let's
begin with the nice parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tensor Flow has a usable documentation (e.g. &lt;a href="http://tensorflow.org/api_docs/python/nn.md"&gt;The neural network part&lt;/a&gt;). Not great, as Lasagne where you have lots of details (e.g. &lt;a href="http://lasagne.readthedocs.org/en/latest/modules/nonlinearities.html#lasagne.nonlinearities.sigmoid"&gt;activation functions&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Seems to be quite easy to use.&lt;/li&gt;
&lt;li&gt;Seems to be well-tested by simply being used in many different projects by
  Google.&lt;/li&gt;
&lt;li&gt;Just like Theano (and thus Lasagne), Tensor flow has automatic
  differenciation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Not sure:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How easy is it to share trained models? In which format would you do so?&lt;/li&gt;
&lt;li&gt;How easy is it to understand a shared model?&lt;/li&gt;
&lt;li&gt;How easy is it to get something new to Tensor Flow like recurrent layers?
  (Actually, this seems rather to show that either the Whitepaper is a bit
  misleading or the documentation / Google search is not that good. In the
  whitepaper they write something about LTSM models, but I couldn't find any docs
  about that. Only by manually going through the manual,
  &lt;a href="http://tensorflow.org/tutorials/recurrent/index.md"&gt;I found it&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Not so nice:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Doesn't work with Python&amp;nbsp;3.&lt;/li&gt;
&lt;li&gt;They don't follow &lt;a href="https://www.python.org/dev/peps/pep-0008/"&gt;PEP8&lt;/a&gt;. I know
  that there is a &lt;a href="https://google.github.io/styleguide/pyguide.html"&gt;Python style guide by Google&lt;/a&gt;,
  but it does not seem to follow that one either. See the next section for
  some more detailed feedback.&lt;/li&gt;
&lt;li&gt;Just like the other Toolkits, you need CUDA. It doesn't work with OpenCL.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="pep8"&gt;PEP8&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Whitespace&lt;/li&gt;
&lt;li&gt;&lt;code&gt;W = tf.Variable(tf.zeros([784, 10]))&lt;/code&gt; should be
    &lt;code&gt;W = tf.Variable(tf.zeros([784, 10]))&lt;/code&gt;.
    Missing whitespaces happened quite often.&lt;/li&gt;
&lt;li&gt;Indent with 2&amp;nbsp;spaces instead of 4&amp;nbsp;spaces. The Google guide seems
    also to use 4.&lt;/li&gt;
&lt;li&gt;Newlines between functions are missing.&lt;/li&gt;
&lt;li&gt;Print statement instead of a print function was used &amp;amp;rightarrow;
  only Python&amp;nbsp;2, not Python&amp;nbsp;3.&lt;/li&gt;
&lt;li&gt;I'm not sure why &lt;code&gt;y_&lt;/code&gt; has the trailing underscore. According to
  &lt;a href="https://www.python.org/dev/peps/pep-0008/#descriptive-naming-styles"&gt;PEP8&lt;/a&gt;,
  a single trailing underscore is used by convention to avoid conflicts with
  Python keyword.&lt;/li&gt;
&lt;li&gt;A mixture of different styles as pointed out on &lt;a href="http://beust.com/weblog/2015/11/09/tensorflows-rough-exterior/"&gt;Credric's Blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="videos_1"&gt;Videos&lt;/h2&gt;
&lt;iframe allowfullscreen="" frameborder="0" height="288" src="https://www.youtube-nocookie.com/embed/oZikw5k_2FM?rel=0" width="512"&gt;&lt;/iframe&gt;
&lt;p&gt;Starting at 21m 2s:&lt;/p&gt;
&lt;iframe allowfullscreen="" frameborder="0" height="288" src="https://www.youtube-nocookie.com/embed/90-S1M7Ny_o?rel=0" width="512"&gt;&lt;/iframe&gt;
&lt;h2 id="alternatives-similar-software"&gt;Alternatives / Similar software&lt;/h2&gt;
&lt;p&gt;As I don't really know by now what Tensor Flow is doing, I can't pin-point
alternatives. But I have some educated guesses:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://deeplearning.net/software/theano/"&gt;Theano&lt;/a&gt; has been around for quite
  a while and seems to have a similar approach with its computational graph.
  Enhanced by &lt;a href="http://lasagne.readthedocs.org/en/latest/"&gt;Lasagne&lt;/a&gt;, it is a
  pretty good alternative when it comes to neural networks. Lasagne has an
  exceptionally good documentation, but parts of the tutorial could still be
  improved.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://caffe.berkeleyvision.org/"&gt;Caffe&lt;/a&gt; was something I recently tried.
  I didn't like it too much due to the lack of documentation, but it certainly
  is a big project. Especially when it comes to images.&lt;/li&gt;
&lt;li&gt;I haven't tried, but they look promising:&lt;/li&gt;
&lt;li&gt;&lt;a href="http://chainer.org/"&gt;Chainer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mxnet.readthedocs.org/en/latest/"&gt;MXNet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://rll.berkeley.edu/cgt/"&gt;CGT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://torch.ch/"&gt;Torch&lt;/a&gt; has a very nice example for &lt;a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/"&gt;a character
    predictor&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="see-also"&gt;See also&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://tensorflow.org/"&gt;Official Website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/tensorflow"&gt;github.com/tensorflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://download.tensorflow.org/paper/whitepaper2015.pdf"&gt;TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://news.ycombinator.com/item?id=10532957"&gt;news.ycombinator.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.reddit.com/r/programming/comments/3s4vkn/google_brains_deep_learning_library_tensorflow_is/"&gt;reddit.com/r/programming&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Martin Thoma</dc:creator><pubDate>Wed, 11 Nov 2015 22:33:00 +0100</pubDate><guid>tag:martin-thoma.com,2015-11-11:tensor-flow-quick/</guid><category>Machine Learning</category><category>Python</category></item><item><title>Lasagne for Python Newbies</title><link>https://martin-thoma.com/lasagne-for-python-newbies/</link><description>&lt;p&gt;Lasagne is a Python package for training neural networks. The nice thing about
Lasagne is that it is possible to write Python code and execute the training
on nVidea GPUs with automatically generated CUDA code.&lt;/p&gt;
&lt;p&gt;However, installing Lasagne is not that easy. Especially if you are not
familiar with Python. This article aims to guide you through the installation
process.&lt;/p&gt;
&lt;h2 id="python"&gt;Python&lt;/h2&gt;
&lt;p&gt;Ubuntu-based systems will have Python installed, but I'm not too sure about
pip. You can get it with&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;$ sudo apt-get install python-pip
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Make sure you have Python and &lt;code&gt;pip&lt;/code&gt;, the standard Python package installer.
Type the following commands to check if you have both:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;$ python --version
Python 2.7.8

$ pip --version
pip 6.1.1 from /usr/local/lib/python2.7/dist-packages &lt;span class="o"&gt;(&lt;/span&gt;python 2.7&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="sklearn"&gt;sklearn&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://scikit-learn.org/stable/"&gt;sklearn&lt;/a&gt; is a nice package for machine
learning. You can install it with&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;$ pip install scikit-learn
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;(When I write commands like this you either have to execute
&lt;code&gt;sudo pip install scikit-learn&lt;/code&gt; or &lt;code&gt;pip install scikit-learn --user&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;This should work without problems.&lt;/p&gt;
&lt;p&gt;Each classifier has a &lt;code&gt;fit&lt;/code&gt; method and a &lt;code&gt;predict&lt;/code&gt; method. See
&lt;a href="http://scikit-learn.org/stable/auto_examples/svm/plot_iris.html"&gt;iris example&lt;/a&gt;
to get a feeling how to use it. It provides a lot of useful functions like
&lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html"&gt;&lt;code&gt;train_test_split&lt;/code&gt;&lt;/a&gt;
and has an awesome documentation.&lt;/p&gt;
&lt;p&gt;You don't need this for Lasagne, but it might be good to use sklearn and
Lasagne in combination.&lt;/p&gt;
&lt;h2 id="graphics-drivers-and-cuda"&gt;Graphics drivers and CUDA&lt;/h2&gt;
&lt;p&gt;Make sure CUDA runs on your system by the following commands.
If it doesn't run, you could try the following guides:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://askubuntu.com/q/451672/10425"&gt;Installing and testing CUDA in Ubuntu 14.04&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.r-tutor.com/gpu-computing/cuda-installation/cuda6.5-ubuntu"&gt;Installing CUDA Toolkit 6.5 on Ubuntu 14.04 Linux&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.nvidia.com/cuda/cuda-getting-started-guide-for-linux/#axzz3XaMVcNwV"&gt;NVIDIA CUDA Getting Started Guide for Linux&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Run&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;$ nvidia-smi -L
GPU 0: GeForce GTX TITAN Black &lt;span class="o"&gt;(&lt;/span&gt;UUID: GPU-abcdef12-abcd-1234-1234-01234567890a&lt;span class="o"&gt;)&lt;/span&gt;

$ nvcc --version
nvcc: NVIDIA &lt;span class="o"&gt;(&lt;/span&gt;R&lt;span class="o"&gt;)&lt;/span&gt; Cuda compiler driver
Copyright &lt;span class="o"&gt;(&lt;/span&gt;c&lt;span class="o"&gt;)&lt;/span&gt; 2005-2013 NVIDIA Corporation
Built on Thu_Mar_13_11:58:58_PDT_2014
Cuda compilation tools, release 6.0, V6.0.1

$ nvidia-smi -a

&lt;span class="o"&gt;==============&lt;/span&gt;NVSMI &lt;span class="nv"&gt;LOG&lt;/span&gt;&lt;span class="o"&gt;==============&lt;/span&gt;

Timestamp                           : Fri Apr &lt;span class="m"&gt;17&lt;/span&gt; 18:44:41 2015
Driver Version                      : 331.79

Attached GPUs                       : 1
GPU 0000:01:00.0
    Product Name                    : GeForce GTX TITAN Black
    Display Mode                    : N/A
    Display Active                  : N/A
    Persistence Mode                : Disabled
    Accounting Mode                 : N/A
    Accounting Mode Buffer Size     : N/A
    Driver Model
        Current                     : N/A
        Pending                     : N/A
    Serial Number                   : N/A
    GPU UUID                        : GPU-fcff168f-a045-2f95-7a4f-8e1cf26a24eb
    Minor Number                    : 0
    VBIOS Version                   : 80.80.4E.00.01
    Inforom Version
        Image Version               : N/A
        OEM Object                  : N/A
        ECC Object                  : N/A
        Power Management Object     : N/A
    GPU Operation Mode
        Current                     : N/A
        Pending                     : N/A
    PCI
        Bus                         : 0x01
        Device                      : 0x00
        Domain                      : 0x0000
        Device Id                   : 0x100C10DE
        Bus Id                      : 0000:01:00.0
        Sub System Id               : 0x106610DE
        GPU Link Info
            PCIe Generation
                Max                 : N/A
                Current             : N/A
            Link Width
                Max                 : N/A
                Current             : N/A
        Bridge Chip
            Type                    : N/A
            Firmware                : N/A
    Fan Speed                       : &lt;span class="m"&gt;26&lt;/span&gt; %
    Performance State               : N/A
    Clocks Throttle Reasons         : N/A
    FB Memory Usage
        Total                       : &lt;span class="m"&gt;6143&lt;/span&gt; MiB
        Used                        : &lt;span class="m"&gt;39&lt;/span&gt; MiB
        Free                        : &lt;span class="m"&gt;6104&lt;/span&gt; MiB
    BAR1 Memory Usage
        Total                       : N/A
        Used                        : N/A
        Free                        : N/A
    Compute Mode                    : Default
    Utilization
        Gpu                         : N/A
        Memory                      : N/A
    Ecc Mode
        Current                     : N/A
        Pending                     : N/A
    ECC Errors
        Volatile
            Single Bit
                Device Memory       : N/A
                Register File       : N/A
                L1 Cache            : N/A
                L2 Cache            : N/A
                Texture Memory      : N/A
                Total               : N/A
            Double Bit
                Device Memory       : N/A
                Register File       : N/A
                L1 Cache            : N/A
                L2 Cache            : N/A
                Texture Memory      : N/A
                Total               : N/A
        Aggregate
            Single Bit
                Device Memory       : N/A
                Register File       : N/A
                L1 Cache            : N/A
                L2 Cache            : N/A
                Texture Memory      : N/A
                Total               : N/A
            Double Bit
                Device Memory       : N/A
                Register File       : N/A
                L1 Cache            : N/A
                L2 Cache            : N/A
                Texture Memory      : N/A
                Total               : N/A
    Retired Pages
        Single Bit ECC              : N/A
        Double Bit ECC              : N/A
        Pending                     : N/A
    Temperature
        Gpu                         : &lt;span class="m"&gt;29&lt;/span&gt; C
    Power Readings
        Power Management            : N/A
        Power Draw                  : N/A
        Power Limit                 : N/A
        Default Power Limit         : N/A
        Enforced Power Limit        : N/A
        Min Power Limit             : N/A
        Max Power Limit             : N/A
    Clocks
        Graphics                    : N/A
        SM                          : N/A
        Memory                      : N/A
    Applications Clocks
        Graphics                    : N/A
        Memory                      : N/A
    Default Applications Clocks
        Graphics                    : N/A
        Memory                      : N/A
    Max Clocks
        Graphics                    : N/A
        SM                          : N/A
        Memory                      : N/A
    Compute Processes               : N/A
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;to see if CUDA was installed correctly.&lt;/p&gt;
&lt;h2 id="theano"&gt;Theano&lt;/h2&gt;
&lt;p&gt;The installation of Theano is a bit tricky (see &lt;a href="http://deeplearning.net/software/theano/install.html"&gt;official page&lt;/a&gt;). I don't remember if I installed additional packages, but try&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;$ sudo -H pip install theano
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Make sure that your &lt;code&gt;~/.theanorc&lt;/code&gt; exists and looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;[global]
device=gpu
floatX=float32
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that &lt;code&gt;float32&lt;/code&gt; is required, even if you have a 64bit system.&lt;/p&gt;
&lt;p&gt;To test your installation, save the following as &lt;code&gt;theanotest.py&lt;/code&gt; and execute
it with &lt;code&gt;python theanotest.py&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="ch"&gt;#!/usr/bin/env python&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;theano&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shared&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sandbox&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;theano.tensor&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;T&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;

&lt;span class="n"&gt;vlen&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;30&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;768&lt;/span&gt;  &lt;span class="c1"&gt;# 10 x #cores x # threads per core&lt;/span&gt;
&lt;span class="n"&gt;iters&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;

&lt;span class="n"&gt;rng&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RandomState&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shared&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;asarray&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rng&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rand&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vlen&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;floatX&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;([],&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;maker&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fgraph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;toposort&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;t0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;xrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;iters&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;t1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;'Looping &lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt; times took'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;iters&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;t0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'seconds'&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;'Result is'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;any&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;op&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Elemwise&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;maker&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fgraph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;toposort&lt;/span&gt;&lt;span class="p"&gt;()]):&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Used the cpu'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Used the gpu'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It should print the following (well, something similar):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Using gpu device 0: GeForce GTX TITAN Black
[GpuElemwise{exp,no_inplace}(&amp;lt;CudaNdarrayType(float32, vector)&amp;gt;), HostFromGpu(GpuElemwise{exp,no_inplace}.0)]
Looping 1000 times took 0.38205909729 seconds
Result is [ 1.23178029  1.61879349  1.52278066 ...,  2.20771813  2.29967761
  1.62323296]
Used the gpu
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Especially "used the gpu" is important. Theano code work on both, CPU and GPU.
If you have a GPU and it does not currently work on a task and it is configured
correctly, then Theano should automatically use the GPU.&lt;/p&gt;
&lt;p&gt;(Don't try to run two Theano scripts at a time ... weird things could happen.)&lt;/p&gt;
&lt;h2 id="lasagne"&gt;Lasagne&lt;/h2&gt;
&lt;p&gt;Lasagne is hosted at Github: &lt;a href="https://github.com/Lasagne/Lasagne"&gt;https://github.com/Lasagne/Lasagne&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Currently, it is not on pip as Sander wants to wait until we get to version
1.0. So you have to install it manually:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;$ git clone https://github.com/Lasagne/Lasagne.git
$ &lt;span class="nb"&gt;cd&lt;/span&gt; Lasagne
Lasagne$ sudo -H python setup.py install
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now you can test if it worked by executing the MNIST example in Lasagne
(&lt;a href="http://yann.lecun.com/exdb/mnist/"&gt;MNIST&lt;/a&gt; is a huge digit dataset). This
might first take some time to download, but should then run quite fast. If
your machine does not use the GPU it will take ages (e.g. on my laptop it takes
about a minute for one epoch)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;Lasagne/examples$ python mnist.py
Loading data...
Downloading MNIST dataset
Building model and compiling functions...
/usr/local/lib/python2.7/dist-packages/Lasagne-0.1dev-py2.7.egg/lasagne/init.py:30: UserWarning: The uniform initializer no longer uses Glorot et al.'s approach to determine the bounds, but defaults to the range (-0.01, 0.01) instead. Please use the new GlorotUniform initializer to get the old behavior. GlorotUniform is now the default for all layers.
  warnings.warn("The uniform initializer no longer uses Glorot et al.'s "
/usr/local/lib/python2.7/dist-packages/Lasagne-0.1dev-py2.7.egg/lasagne/layers/helper.py:55: UserWarning: get_all_layers() has been changed to return layers in topological order. The former implementation is still available as get_all_layers_old(), but will be removed before the first release of Lasagne. To ignore this warning, use `warnings.filterwarnings('ignore', '.*topo.*')`.
  warnings.warn("get_all_layers() has been changed to return layers in "
Starting training...
Epoch 1 of 500 took 72.593s
  training loss:        1.330231
  validation loss:        0.470251
  validation accuracy:        87.54 %%
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="nolearn"&gt;nolearn&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/dnouri/nolearn"&gt;nolearn&lt;/a&gt; is another Python package. It was
created to make using Lasagne even simpler.&lt;/p&gt;
&lt;p&gt;You can install it via&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;$ git clone https://github.com/dnouri/nolearn.git
$ &lt;span class="nb"&gt;cd&lt;/span&gt; nolearn
$ python setup.py install --user
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For example, the following code downloads the MNIST dataset, trains a model on
it and evaluates the result for a single image:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="ch"&gt;#!/usr/bin/env python&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;lasagne&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;lasagne&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;layers&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;lasagne.updates&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;nesterov_momentum&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;nolearn.lasagne&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;NeuralNet&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;gzip&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pickle&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;


&lt;span class="n"&gt;PY2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;version_info&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;PY2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;urllib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;urlretrieve&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;pickle_load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;encoding&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;pickle&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;urllib.request&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;urlretrieve&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;pickle_load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;encoding&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;pickle&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;encoding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;encoding&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;DATA_URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'http://deeplearning.net/data/mnist/mnist.pkl.gz'&lt;/span&gt;
&lt;span class="n"&gt;DATA_FILENAME&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'mnist.pkl.gz'&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_load_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;DATA_URL&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;DATA_FILENAME&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Load data from `url` and store the result in `filename`."""&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exists&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Downloading MNIST dataset"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;urlretrieve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;gzip&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'rb'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;pickle_load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;encoding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'latin-1'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;load_data&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="sd"&gt;"""Get data with labels, split into training, validation and test set."""&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_load_data&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;y_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;asarray&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;y_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;asarray&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_valid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;asarray&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;y_valid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;y_valid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;y_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;num_examples_train&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="n"&gt;num_examples_valid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="n"&gt;num_examples_test&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="n"&gt;input_dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="n"&gt;output_dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;nn_example&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;net1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;NeuralNet&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="s1"&gt;'input'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;InputLayer&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'hidden'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DenseLayer&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'output'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DenseLayer&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                &lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="c1"&gt;# layer parameters:&lt;/span&gt;
        &lt;span class="n"&gt;input_shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="n"&gt;hidden_num_units&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="c1"&gt;# number of units in 'hidden' layer&lt;/span&gt;
        &lt;span class="n"&gt;output_nonlinearity&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;lasagne&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nonlinearities&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;output_num_units&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="c1"&gt;# 10 target values for the digits 0, 1, 2, ..., 9&lt;/span&gt;

        &lt;span class="c1"&gt;# optimization method:&lt;/span&gt;
        &lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;nesterov_momentum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;update_learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;update_momentum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;

        &lt;span class="n"&gt;max_epochs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;verbose&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Train the network&lt;/span&gt;
    &lt;span class="n"&gt;net1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'X_train'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'y_train'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="c1"&gt;# Try the network on new data&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Feature vector (100-110): &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'X_test'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;110&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Label: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'y_test'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Predicted: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;net1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'X_test'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]])))&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_data&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Got &lt;/span&gt;&lt;span class="si"&gt;%i&lt;/span&gt;&lt;span class="s2"&gt; testing datasets."&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'X_train'&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;nn_example&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The output is&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;# Neural Network with 79510 learnable parameters

## Layer information

  #  name      size
---  ------  ------
  0  input      784
  1  hidden     100
  2  output      10

  epoch    train loss    valid loss    train/val    valid acc  dur
-------  ------------  ------------  -----------  -----------  -----
      1       0.59132       0.32314      1.82993      0.90988  1.70s
      2       0.30733       0.26644      1.15348      0.92623  1.96s
      3       0.25879       0.23606      1.09629      0.93363  2.09s
      4       0.22680       0.21424      1.05865      0.93897  2.13s
      5       0.20187       0.19633      1.02827      0.94313  2.21s
      6       0.18129       0.18187      0.99685      0.94758  1.81s
      7       0.16398       0.16992      0.96506      0.95074  2.14s
      8       0.14941       0.16020      0.93265      0.95262  1.88s
      9       0.13704       0.15189      0.90222      0.95460  2.15s
     10       0.12633       0.14464      0.87342      0.95707  2.21s
Feature vector (100-110): [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
Label: 7
Predicted: [7]
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="see-also"&gt;See also&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.pyimagesearch.com/2014/09/22/getting-started-deep-learning-python/"&gt;Getting Started with Deep Learning and Python&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Martin Thoma</dc:creator><pubDate>Fri, 17 Apr 2015 19:26:00 +0200</pubDate><guid>tag:martin-thoma.com,2015-04-17:lasagne-for-python-newbies/</guid><category>Python</category><category>Machine Learning</category></item><item><title>Gradient Descent, the Delta Rule and Backpropagation</title><link>https://martin-thoma.com/gradient-descent-the-delta-rule-and-backpropagation/</link><description>&lt;p&gt;If you learn about machine learning you will stumble over three terms that are
related:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gradient descent,&lt;/li&gt;
&lt;li&gt;the Delta rule and&lt;/li&gt;
&lt;li&gt;backpropagation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Gradient descent is a way to find a minimum in a high-dimensional space. You
go in direction of the steepest descent.&lt;/p&gt;
&lt;p&gt;The delta rule is an update rule for single layer perceptrons. It makes use
of gradient descent.&lt;/p&gt;
&lt;p&gt;Backpropagation is an efficient implementation of gradient descent, where a
rule can be formulated which has some recursively defined parts. Those parts
belong to neurons of different layers and get calculated from the output-layer
(last layer) to the first hidden layer.&lt;/p&gt;
&lt;h2 id="see-also"&gt;See also&lt;/h2&gt;
&lt;p&gt;Wikipedia pages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Gradient_descent"&gt;Gradient descent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Delta_rule"&gt;Delta rule&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Backpropagation"&gt;Backpropagation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Martin Thoma</dc:creator><pubDate>Sun, 26 Oct 2014 21:06:00 +0100</pubDate><guid>tag:martin-thoma.com,2014-10-26:gradient-descent-the-delta-rule-and-backpropagation/</guid><category>Machine Learning</category><category>AI</category></item><item><title>The Twiddle Algorithm</title><link>https://martin-thoma.com/the-twiddle-algorithm/</link><description>&lt;p&gt;Twiddle is an algorithm that tries to find a good choice of parameters &lt;span class="math"&gt;\(p\)&lt;/span&gt;
for an algorithm &lt;span class="math"&gt;\(\mathcal{A}\)&lt;/span&gt; that returns an error.&lt;/p&gt;
&lt;p&gt;The algorithm is quite simple to implement. I guess gradient descent might be
better for most cases, but Twiddle does not require any knowledge about the
algorithm &lt;span class="math"&gt;\(\mathcal{A}\)&lt;/span&gt; which might be a big advantage. And you don't have to
calculate the gradient of high dimensional functions, which is nice, too.&lt;/p&gt;
&lt;h2 id="the-algorithm"&gt;The algorithm&lt;/h2&gt;
&lt;p&gt;Here is some pythonic pseudo code. &lt;code&gt;A&lt;/code&gt; is an algorithm that returns an error.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c1"&gt;# Choose an initialization parameter vector&lt;/span&gt;
&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="c1"&gt;# Define potential changes&lt;/span&gt;
&lt;span class="n"&gt;dp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="c1"&gt;# Calculate the error&lt;/span&gt;
&lt;span class="n"&gt;best_err&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;threshold&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.001&lt;/span&gt;

&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;threshold&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
        &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;dp&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;err&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;err&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;best_err&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="c1"&gt;# There was some improvement&lt;/span&gt;
            &lt;span class="n"&gt;best_err&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;err&lt;/span&gt;
            &lt;span class="n"&gt;dp&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="mf"&gt;1.1&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="c1"&gt;# There was no improvement&lt;/span&gt;
            &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;dp&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;  &lt;span class="c1"&gt;# Go into the other direction&lt;/span&gt;
            &lt;span class="n"&gt;err&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;err&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;best_err&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;  &lt;span class="c1"&gt;# There was an improvement&lt;/span&gt;
                &lt;span class="n"&gt;best_err&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;err&lt;/span&gt;
                &lt;span class="n"&gt;dp&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="mf"&gt;1.05&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;  &lt;span class="c1"&gt;# There was no improvement&lt;/span&gt;
                &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;dp&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="c1"&gt;# As there was no improvement, the step size in either&lt;/span&gt;
                &lt;span class="c1"&gt;# direction, the step size might simply be too big.&lt;/span&gt;
                &lt;span class="n"&gt;dp&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="mf"&gt;0.95&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="see-also"&gt;See also&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=2uQ2BSzDvXs"&gt;Twiddle - CS373 Unit 5 - Udacity&lt;/a&gt;:
  Explanation of Twiddle by Sebastian Thrun&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.htw-mechlab.de/index.php/numerische-optimierung-in-matlab-mit-twiddle-algorithmus/"&gt;Numerische Optimierung in Matlab mit Twiddle-Algorithmus&lt;/a&gt; (German)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://forums.udacity.com/questions/1023236/twiddle-vs-gradient-descent"&gt;twiddle vs gradient descent&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Martin Thoma</dc:creator><pubDate>Sat, 06 Sep 2014 13:49:00 +0200</pubDate><guid>tag:martin-thoma.com,2014-09-06:the-twiddle-algorithm/</guid><category>Python</category><category>AI</category><category>Machine Learning</category></item><item><title>GPUs - Supercomputers for your home</title><link>https://martin-thoma.com/gpus-supercomputers-for-your-home/</link><description>&lt;p&gt;A few days ago I got some of my neural net code to work with a GPU.
The GPU is called "Tesla C2075". It is able to get 515 GFlops peak performance.
It has 448 CUDA cores that work with 1.15 GHz and it has 6GB GDDR5 memory.&lt;/p&gt;
&lt;p&gt;My code needed about 10 hours to run before. After that, it only needed 10
minutes. That is 60 times faster! The library that did this miracle for me is
called &lt;a href="http://deeplearning.net/software/theano/"&gt;Theano&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Out of curiosity, I've searched for current high-end gamer graphic cards.
I found nVidia Titan Z:&lt;/p&gt;
&lt;iframe allowfullscreen="" frameborder="0" height="288" src="//www.youtube.com/embed/2JjxgJcXVE0" width="512"&gt;&lt;/iframe&gt;
&lt;p&gt;The Titan Z has 5760 CUDA cores. It can get 4061 GFLOPS x2 and has 12 GB of
memory. That technological wonder-work costs only 2802 Euro.&lt;/p&gt;
&lt;p&gt;To put that into perspective: In 2005, you would probably have been on place
68 of the TOP500 supercomputers world wide! (&lt;a href="http://www.top500.org/list/2005/06/?page=1"&gt;source&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Isn't that crazy?&lt;/p&gt;
&lt;h2 id="see-also"&gt;See also:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-titan-z/specifications"&gt;Titan Z Specification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://superuser.com/questions/805217/what-are-the-differences-between-scientific-gpus-and-gaming-gpus"&gt;What are the differences between &amp;ldquo;scientific GPUs&amp;rdquo; and &amp;ldquo;gaming GPUs&amp;rdquo;?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Martin Thoma</dc:creator><pubDate>Wed, 20 Aug 2014 23:26:00 +0200</pubDate><guid>tag:martin-thoma.com,2014-08-20:gpus-supercomputers-for-your-home/</guid><category>Python</category><category>Theano</category><category>GPU</category><category>nVidea</category><category>CUDA</category><category>AI</category><category>Machine Learning</category></item><item><title>A.I. in Computer Games</title><link>https://martin-thoma.com/ai-in-computer-games/</link><description>&lt;p&gt;Artificial Intelligences (A.I.s) are computer programs that are able to adjust
their behaviour according to data they see. So A.I.s are able to adjust to
the data a human player generates.&lt;/p&gt;
&lt;figure&gt;
&lt;img alt="Game A.I.s" src="http://imgs.xkcd.com/comics/game_ais.png"&gt;
&lt;figcaption&gt;Game A.I.s&lt;/figcaption&gt;
&lt;/img&gt;&lt;/figure&gt;
&lt;h2 id="solved-games"&gt;Solved games&lt;/h2&gt;
&lt;p&gt;There is a number of games which are definitely solved. That means the A.I.
plays perfectly:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tic-Tac-Toe&lt;/li&gt;
&lt;li&gt;Connect Four: &lt;a href="http://www.informatik.uni-trier.de/~fernau/DSL0607/Masterthesis-Viergewinnt.pdf"&gt;A Knowledge-based Approach of Connect-Four&lt;/a&gt;. Amsterdam, 1988. Victor Allis.&lt;/li&gt;
&lt;li&gt;Checkers:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See also: &lt;a href="https://en.wikipedia.org/wiki/Solved_game"&gt;Solved Game&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="computers-win-always"&gt;Computers win always&lt;/h2&gt;
&lt;p&gt;A second category are games in which A.I.s always win against human players, but
they don't have a perfect strategy. Or at least we have not proven that they
have a perfect strategy:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chess&lt;/li&gt;
&lt;li&gt;Go on a 5&amp;times;5 board&lt;/li&gt;
&lt;li&gt;Reversi on a 4&amp;times;4 board&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Update: There are advances on the 19&amp;times;19 field:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://storage.googleapis.com/deepmind-data/assets/papers/deepmind-mastering-go.pdf"&gt;Paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Nature: &lt;a href="http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html"&gt;Mastering the game of Go with deep neural networks and tree search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;YouTube by nature: &lt;a href="https://www.youtube.com/watch?v=g-dKXOlsf98"&gt;The computer that mastered Go&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Google Blog: &lt;a href="https://googleblog.blogspot.de/2016/01/alphago-machine-learning-game-go.html"&gt;AlphaGo: using machine learning to master the ancient game of Go&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="unspecialized-game-ais"&gt;Unspecialized Game A.I.s&lt;/h2&gt;
&lt;p&gt;The following video is an explanation and demo of software Tom Murphy VII wrote that learns how to play a Nintendo Entertainment System game and then automatically plays it.
It's called "learnfun" (for learn function).&lt;/p&gt;
&lt;p&gt;You might want to skip to 6:13 for the demo:&lt;/p&gt;
&lt;iframe allowfullscreen="" frameborder="0" height="288" src="http://www.youtube.com/embed/xOCurBYI_gY" width="512"&gt;&lt;/iframe&gt;
&lt;p&gt;Research paper published in SIGBOVIK 2013: "&lt;a href="http://tom7.org/mario/mario.pdf"&gt;The first level of Super Mario Bros. is easy with lexicographic ordering a and time travel ...after that it gets a little tricky&lt;/a&gt;."&lt;/p&gt;
&lt;p&gt;There is a follow-up video with Zelda, Punch-Out, Dr. Mario, Contra, Wall Street Kid
and Russian Attack:&lt;/p&gt;
&lt;iframe allowfullscreen="" frameborder="0" height="288" src="//www.youtube.com/embed/YGJHR9Ovszs?list=UU3azLjQuz9s5qk76KEXaTvA" width="512"&gt;&lt;/iframe&gt;
&lt;p&gt;And a third episode with Super Mario, Gradius, Mega Man 2, Pro Wrestling, Color
a Dinosaur, Nintendo Pinball, Cliffhanger, Arkanoid, Double Dare, Ice hockey:&lt;/p&gt;
&lt;iframe allowfullscreen="" frameborder="0" height="288" src="//www.youtube.com/embed/Q-WgQcnessA" width="512"&gt;&lt;/iframe&gt;
&lt;h2 id="super-mario-ai-competition"&gt;Super Mario A.I. Competition&lt;/h2&gt;
&lt;iframe allowfullscreen="" frameborder="0" height="288" src="http://www.youtube.com/embed/bBZ7kEphv3s?start=385" width="512"&gt;&lt;/iframe&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Martin Thoma</dc:creator><pubDate>Tue, 01 Jul 2014 23:52:00 +0200</pubDate><guid>tag:martin-thoma.com,2014-07-01:ai-in-computer-games/</guid><category>AI</category><category>games</category><category>Machine Learning</category></item><item><title>Classification with PyBrain</title><link>https://martin-thoma.com/classification-with-pybrain/</link><description>&lt;p&gt;PyBrain is a Python library for machine learning. It's in version 0.31 and
the last change is 2 months ago (&lt;a href="https://github.com/pybrain/pybrain"&gt;source&lt;/a&gt;).
The source code is licensed under &lt;a href="https://tldrlegal.com/license/bsd-3-clause-license-(revised)"&gt;BSD 3 Clause License&lt;/a&gt;. The &lt;a href="http://pybrain.org/docs/"&gt;documentation&lt;/a&gt; is usable, but for
from perfect.&lt;/p&gt;
&lt;h2 id="classification-example"&gt;Classification example&lt;/h2&gt;
&lt;p&gt;The following is a slightly modified example from the documentation. It shows
how PyBrain starts learning to classify 2-dimensional datapoints into 3 classes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="ch"&gt;#!/usr/bin/env python&lt;/span&gt;
&lt;span class="c1"&gt;# -*- coding: utf-8 -*-&lt;/span&gt;

&lt;span class="c1"&gt;# Source: http://pybrain.org/docs/tutorial/fnn.html&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pybrain.datasets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ClassificationDataSet&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pybrain.utilities&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;percentError&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pybrain.tools.shortcuts&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;buildNetwork&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pybrain.supervised.trainers&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BackpropTrainer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pybrain.structure.modules&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SoftmaxLayer&lt;/span&gt;

&lt;span class="c1"&gt;# Only needed for data generation and graphical output&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pylab&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ion&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ioff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;draw&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;contourf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;plot&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;diag&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;meshgrid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;where&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;numpy.random&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;multivariate_normal&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;normalvariate&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;generate_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;INPUT_FEATURES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
    &lt;span class="n"&gt;CLASSES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
    &lt;span class="n"&gt;means&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="n"&gt;cov&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;diag&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; &lt;span class="n"&gt;diag&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.2&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; &lt;span class="n"&gt;diag&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;1.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.7&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
    &lt;span class="n"&gt;alldata&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ClassificationDataSet&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;INPUT_FEATURES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nb_classes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;CLASSES&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;minX&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;maxX&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;means&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;means&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;minY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;maxY&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;means&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;means&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;klass&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;CLASSES&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;features&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;multivariate_normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;means&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;klass&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;cov&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;klass&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;features&lt;/span&gt;
            &lt;span class="n"&gt;minX&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;maxX&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;minX&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxX&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;minY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;maxY&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;minY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;alldata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;addSample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;klass&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'minX'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;minX&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'maxX'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;maxX&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="s1"&gt;'minY'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;minY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'maxY'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;maxY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'d'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;alldata&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;generate_data2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;alldata&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ClassificationDataSet&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nb_classes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;minX&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;maxX&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
    &lt;span class="n"&gt;minY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;maxY&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;normalvariate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.6&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;normalvariate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;minX&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;maxX&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;minX&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxX&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;minY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;maxY&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;minY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;alldata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;addSample&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;normalvariate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;normalvariate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;alldata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;addSample&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'minX'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;minX&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'maxX'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;maxX&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="s1"&gt;'minY'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;minY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'maxY'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;maxY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'d'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;alldata&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;perceptron&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hidden_neurons&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weightdecay&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;INPUT_FEATURES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
    &lt;span class="n"&gt;CLASSES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
    &lt;span class="n"&gt;HIDDEN_NEURONS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hidden_neurons&lt;/span&gt;
    &lt;span class="n"&gt;WEIGHTDECAY&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;weightdecay&lt;/span&gt;
    &lt;span class="n"&gt;MOMENTUM&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;momentum&lt;/span&gt;

    &lt;span class="c1"&gt;# Generate the labeled set&lt;/span&gt;
    &lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;generate_data&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="c1"&gt;#g = generate_data2()&lt;/span&gt;
    &lt;span class="n"&gt;alldata&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'d'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;minX&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;maxX&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;minY&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;maxY&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'minX'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'maxX'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'minY'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'maxY'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="c1"&gt;# Split data into test and training dataset&lt;/span&gt;
    &lt;span class="n"&gt;tstdata&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;trndata&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;alldata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;splitWithProportion&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.25&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;trndata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_convertToOneOfMany&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  &lt;span class="c1"&gt;# This is necessary, but I don't know why&lt;/span&gt;
    &lt;span class="n"&gt;tstdata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_convertToOneOfMany&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  &lt;span class="c1"&gt;# http://stackoverflow.com/q/8154674/562769&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Number of training patterns: &lt;/span&gt;&lt;span class="si"&gt;%i&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trndata&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Input and output dimensions: &lt;/span&gt;&lt;span class="si"&gt;%i&lt;/span&gt;&lt;span class="s2"&gt;, &lt;/span&gt;&lt;span class="si"&gt;%i&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trndata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;indim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                   &lt;span class="n"&gt;trndata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;outdim&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Hidden neurons: &lt;/span&gt;&lt;span class="si"&gt;%i&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;HIDDEN_NEURONS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"First sample (input, target, class):"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trndata&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'input'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;trndata&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'target'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;trndata&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'class'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="n"&gt;fnn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;buildNetwork&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trndata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;indim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;HIDDEN_NEURONS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;trndata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;outdim&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                       &lt;span class="n"&gt;outclass&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;SoftmaxLayer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;trainer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BackpropTrainer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fnn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;trndata&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;MOMENTUM&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                              &lt;span class="n"&gt;verbose&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;weightdecay&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;WEIGHTDECAY&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Visualization&lt;/span&gt;
    &lt;span class="n"&gt;ticksX&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;minX&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;maxX&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ticksY&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;minY&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;maxY&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;meshgrid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ticksX&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ticksY&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# need column vectors in dataset, not arrays&lt;/span&gt;
    &lt;span class="n"&gt;griddata&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ClassificationDataSet&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;INPUT_FEATURES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nb_classes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;CLASSES&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;griddata&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;addSample&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;Y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ravel&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;trainer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;trainEpochs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;trnresult&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;percentError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trainer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;testOnClassData&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
                                 &lt;span class="n"&gt;trndata&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'class'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;tstresult&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;percentError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trainer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;testOnClassData&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                                 &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tstdata&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;tstdata&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'class'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"epoch: &lt;/span&gt;&lt;span class="si"&gt;%4d&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;trainer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;totalepochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
              &lt;span class="s2"&gt;"  train error: &lt;/span&gt;&lt;span class="si"&gt;%5.2f%%&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;trnresult&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
              &lt;span class="s2"&gt;"  test error: &lt;/span&gt;&lt;span class="si"&gt;%5.2f%%&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;tstresult&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fnn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;activateOnDataset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;griddata&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# the highest output activation gives the class&lt;/span&gt;
        &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# always print on the same canvas&lt;/span&gt;
        &lt;span class="n"&gt;ioff&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  &lt;span class="c1"&gt;# interactive graphics off&lt;/span&gt;
        &lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;   &lt;span class="c1"&gt;# clear the plot&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
            &lt;span class="n"&gt;here&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tstdata&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'class'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tstdata&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'input'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;here&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;tstdata&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'input'&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;here&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'o'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;  &lt;span class="c1"&gt;# safety check against flat field&lt;/span&gt;
            &lt;span class="n"&gt;contourf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# plot the contour&lt;/span&gt;
        &lt;span class="n"&gt;ion&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  &lt;span class="c1"&gt;# interactive graphics on&lt;/span&gt;
        &lt;span class="n"&gt;draw&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  &lt;span class="c1"&gt;# update the plot&lt;/span&gt;

    &lt;span class="n"&gt;ioff&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;argparse&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ArgumentParser&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ArgumentDefaultsHelpFormatter&lt;/span&gt;

    &lt;span class="n"&gt;parser&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ArgumentParser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;formatter_class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ArgumentDefaultsHelpFormatter&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Add more options if you like&lt;/span&gt;
    &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-H"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;metavar&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"H"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dest&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"hidden_neurons"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"number of neurons in the hidden layer"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-d"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;metavar&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"W"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dest&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"weightdecay"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"weightdecay"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-m"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;metavar&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"M"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dest&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"momentum"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"momentum"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse_args&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="n"&gt;perceptron&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_neurons&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;weightdecay&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;See it in action:&lt;/p&gt;
&lt;iframe allowfullscreen="" frameborder="0" height="315" src="//www.youtube.com/embed/FjvO3zqVYSw" width="420"&gt;&lt;/iframe&gt;
&lt;h2 id="resources"&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://pybrain.org/"&gt;Official website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;StackExchange&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/tagged/pybrain"&gt;StackOverflow&lt;/a&gt;: 134 questions&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stats.stackexchange.com/search?q=pybrain"&gt;stats.SE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.reddit.com/r/MachineLearning/search?q=pybrain&amp;amp;restrict_sr=on"&gt;reddit.com/r/MachineLearning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Martin Thoma</dc:creator><pubDate>Mon, 16 Jun 2014 01:02:00 +0200</pubDate><guid>tag:martin-thoma.com,2014-06-16:classification-with-pybrain/</guid><category>Python</category><category>PyBrain</category><category>Neural Network</category><category>Classification</category><category>AI</category><category>Machine Learning</category></item></channel></rss>