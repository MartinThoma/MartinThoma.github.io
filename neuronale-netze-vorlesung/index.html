<!DOCTYPE html>
<html lang="en">
  <!-- type: head.html -->
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    
    

    
        <meta name="thumbnail" content="//martin-thoma.com/images/logos/klausur.png" />
        <meta property="og:image" content="//martin-thoma.com/images/logos/klausur.png" />
    

    <meta property="og:type" content="blog"/>

    <title>Neuronale Netze - Klausur</title>
    <link rel="stylesheet" href="//martin-thoma.com/css/screen.css" type="text/css" media="screen" />
    <link rel="stylesheet" href="//martin-thoma.com/css/style.css" type="text/css" media="screen" />
    <link rel="stylesheet" href="//martin-thoma.com/css/pygments.css" type="text/css" media="screen" />
    <link rel="stylesheet" href="//martin-thoma.com/css/tocplus-screen.css" type="text/css" media="screen" />
    <link rel="stylesheet" href="//martin-thoma.com/css/print.css" type="text/css" media="print" />
    <link rel="stylesheet" href="//martin-thoma.com/css/handheld.css" type="text/css" media="only screen and (max-device-width: 480px)" />

    <link rel="alternate" type="application/rss+xml" title="Martin Thoma RSS Feed" href="//martin-thoma.com/feed/" /><!--TODO-->
    <link rel="shortcut icon" href="//martin-thoma.com/favicon.ico" type="image/x-icon" />

    <link rel="canonical" href="//martin-thoma.com/neuronale-netze-vorlesung" />
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:site" content="@themoosemind"/>
<meta name="twitter:creator" content="@themoosemind"/>
<meta name="twitter:title" content="Neuronale Netze - Klausur"/>

    <meta name="twitter:description" content="A blog about Code, the Web and Cyberculture" />


    <meta name="twitter:image" content="//martin-thoma.com/images/logos/klausur.png"/>



<meta name="twitter:url" content="//martin-thoma.com/neuronale-netze-vorlesung"/>
<meta name="twitter:domain" content="Martin Thoma.com"/>


    <script type='text/javascript' src="//martin-thoma.com/js/jquery.js"></script>
    <script type='text/javascript' src="//martin-thoma.com/js/jquery-migrate.min.js"></script>
    <style type="text/css">div#toc_container {width: 275px;}</style>
    <style type="text/css" id="syntaxhighlighteranchor"></style>

<!-- Latest compiled and minified CSS bootstrap -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
</head>

<!-- type: post.html -->
<body>
    <div id="wrapper">
        <div id="container" class="container">
            <div class="span-16">
                <!-- type: header.html -->
<div id="header" role="banner">
    <h1><a href="//martin-thoma.com">Martin Thoma</a></h1>
    <h2>A blog about Code, the Web and Cyberculture.</h2>
</div>
<nav class="navcontainer" role="navigation">
    <ul id="nav">
        <li class=""><a href="//martin-thoma.com">Home</a></li>
        <li class="page_item page-item-41 "><a href="//martin-thoma.com/author/martin-thoma/">About Me</a></li>
        <li class="page_item page-item-91 "><a href="//martin-thoma.com/imprint/">Imprint</a></li>
    </ul>
</nav>

                <div id="content">
                    <article class="post type-post format-standard hentry clearfix ">
                        <h2 class="title entry-title">Neuronale Netze - Klausur</h2>
                        <div class="postdate entry-date">
                            <time datetime="2015-04-27T21:15:00+02:00">
                                April
                                27th,
                                  
                                2015
                            </time>
                        </div>

                        <div class="entry">
                            <div class="info">Dieser Artikel beschäftigt sich mit der Vorlesung „Neuronale Netze“ am KIT. Er dient als Prüfungsvorbereitung. Ich habe die Vorlesungen bei <a href="http://isl.anthropomatik.kit.edu/english/21_74.php">Herrn Prof. Dr. Alexander Waibel</a> im Sommersemester 2015 gehört. Der Artikel wird bis zur mündlichen Prüfung laufend erweitert.</div>

<div id="toc_container" class="toc_light_blue no_bullets">
   <p class="toc_title">Contents</p>
   <ul class="toc_list">
      <li class="toc_level-1 toc_section-1">
         <a href="#tocAnchor-1-1"><span class="tocnumber">1</span> <span class="toctext">Behandelter Stoff</span></a>
         <ul>
            <li class="toc_level-2 toc_section-2">
               <a href="#tocAnchor-1-1-1"><span class="tocnumber">1.1</span> <span class="toctext">Vorlesung</span></a>
            </li>
            <li class="toc_level-2 toc_section-3">
               <a href="#tocAnchor-1-1-2"><span class="tocnumber">1.2</span> <span class="toctext">NN01-Intro.pdf</span></a>
            </li>
            <li class="toc_level-2 toc_section-4">
               <a href="#tocAnchor-1-1-3"><span class="tocnumber">1.3</span> <span class="toctext">NN02-Classification.pdf</span></a>
            </li>
            <li class="toc_level-2 toc_section-5">
               <a href="#tocAnchor-1-1-4"><span class="tocnumber">1.4</span> <span class="toctext">V04: Perceptron</span></a>
            </li>
            <li class="toc_level-2 toc_section-6">
               <a href="#tocAnchor-1-1-5"><span class="tocnumber">1.5</span> <span class="toctext">V05: Features</span></a>
            </li>
            <li class="toc_level-2 toc_section-7">
               <a href="#tocAnchor-1-1-6"><span class="tocnumber">1.6</span> <span class="toctext">V06: Backpropagation</span></a>
            </li>
            <li class="toc_level-2 toc_section-8">
               <a href="#tocAnchor-1-1-7"><span class="tocnumber">1.7</span> <span class="toctext">V07: Feature Learning</span></a>
            </li>
            <li class="toc_level-2 toc_section-9">
               <a href="#tocAnchor-1-1-8"><span class="tocnumber">1.8</span> <span class="toctext">V08: Deep Learning</span></a>
            </li>
            <li class="toc_level-2 toc_section-10">
               <a href="#tocAnchor-1-1-9"><span class="tocnumber">1.9</span> <span class="toctext">V09: Reinforcement Learning</span></a>
            </li>
            <li class="toc_level-2 toc_section-11">
               <a href="#tocAnchor-1-1-10"><span class="tocnumber">1.10</span> <span class="toctext">V10: SOM</span></a>
            </li>
            <li class="toc_level-2 toc_section-12">
               <a href="#tocAnchor-1-1-11"><span class="tocnumber">1.11</span> <span class="toctext">V11: RBMs</span></a>
            </li>
            <li class="toc_level-2 toc_section-13">
               <a href="#tocAnchor-1-1-12"><span class="tocnumber">1.12</span> <span class="toctext">V12: RNNs</span></a>
            </li>
            <li class="toc_level-2 toc_section-14">
               <a href="#tocAnchor-1-1-13"><span class="tocnumber">1.13</span> <span class="toctext">V13: NNlearning-tricks</span></a>
            </li>
            <li class="toc_level-2 toc_section-15">
               <a href="#tocAnchor-1-1-14"><span class="tocnumber">1.14</span> <span class="toctext">V14: DNN CV</span></a>
            </li>
            <li class="toc_level-2 toc_section-16">
               <a href="#tocAnchor-1-1-15"><span class="tocnumber">1.15</span> <span class="toctext">V15: Speech-Independence</span></a>
            </li>
         </ul>
      </li>
      <li class="toc_level-1 toc_section-17">
         <a href="#tocAnchor-1-17"><span class="tocnumber">2</span> <span class="toctext">Visualisierung von Netzen</span></a>
      </li>
      <li class="toc_level-1 toc_section-18">
         <a href="#tocAnchor-1-18"><span class="tocnumber">3</span> <span class="toctext">Material und Links</span></a>
      </li>
      <li class="toc_level-1 toc_section-19">
         <a href="#tocAnchor-1-19"><span class="tocnumber">4</span> <span class="toctext">Übungsbetrieb</span></a>
      </li>
      <li class="toc_level-1 toc_section-20">
         <a href="#tocAnchor-1-20"><span class="tocnumber">5</span> <span class="toctext">Termine und Klausurablauf</span></a>
      </li>
   </ul>
</div><h2 id="tocAnchor-1-1">Behandelter Stoff</h2>

<h3 id="tocAnchor-1-1-1">Vorlesung</h3>

<table>
<tr>
    <th>Datum</th>
    <th>Kapitel</th>
    <th>Inhalt</th>
</tr>
<tr>
    <td>15.04.2015</td>
    <td><a href="https://ies.anthropomatik.kit.edu/ies/download/lehre/me/ME-Kap1_V33.pdf">Einleitung</a></td>
    <td>-</td>
</tr>
<tr>
    <td>21.04.2015</td>
    <td>LVQ and related Techiques</td>
    <td>k-Means, OLVQ1, kompetitives Lernen, Mode Seeker, PCA</td>
</tr>
<tr>
    <td>22.04.2015</td>
    <td>-</td>
    <td>Übung</td>
</tr>
<tr>
    <td>28.04.2015</td>
    <td>Perceptron</td>
    <td>-</td>
</tr>
<tr>
    <td>12.05.2015</td>
    <td>Auto-Encoder</td>
    <td>Denoising- und Sparse Autoencoder, Bottleneck-Features<a href="https://de.wikipedia.org/wiki/Kullback-Leibler-Divergenz">Kullback-Leibler-Divergenz</a>; <a href="https://de.wikipedia.org/wiki/Kettenregel#Mathematische_Formulierung">Kettenregel</a></td>
</tr>
<tr>
    <td>13.05.2015</td>
    <td>Deep Learning</td>
    <td>Momentum, Rprop, Newbob, L1/L2-Regularisierung (\(|w|\), \(w^2\)), weight decay</td>
</tr>
<tr>
    <td>19.05.2015</td>
    <td>Übung</td>
    <td>-</td>
</tr>
<tr>
    <td>20.05.2015</td>
    <td>Übung</td>
    <td>-</td>
</tr>
<tr>
    <td>26.05.2015</td>
    <td><abbr title="Self Organizing Map">SOM</abbr></td>
    <td>Hebbian Learning, "<abbr title="Vector Quantization">VQ</abbr>" mit SOM</td>
</tr>
<tr>
    <td>09.06.2015</td>
    <td>Effizientes Lernen</td>
    <td>Paralleles Lernen; Quickprop; Alternative Fehlerfunktion (cross entropy, <abbr title="Classification Figure of Merit">CFM</abbr>);
        weight elimination / regularization</td>
</tr>
<tr>
    <td>15.07.2015</td>
    <td>Summary</td>
    <td>When to use which objective function (cross entropy, MSE); Backpropagation; Weight initialization; Regularization (L2 weight decay, dropout); Time Delay NN; Recurrent Networks; Applications (Speech Recognition, Computer Vision)</td>
</tr>
</table>

<h3 id="tocAnchor-1-1-2">NN01-Intro.pdf</h3>

<ul>
<li>Human Brain vs. Computer (Processing/Processors, Accuracy, Speed, Hardware, Design)</li>
<li>Aufbau eines biologischen Neurons (vgl. <a href="https://de.wikipedia.org/wiki/Nervenzelle#.C3.9Cberblick_.C3.BCber_den_Aufbau_einer_Nervenzelle">Wikipedia</a>)</li>
</ul>

<h3 id="tocAnchor-1-1-3">NN02-Classification.pdf</h3>

<div style="width: 510px" class="wp-caption aligncenter">
   <a href="../images/2015/12/perceptron-or.png">
      <img src="../images/2015/12/perceptron-or.png" alt="Rosenblatt-Perceptron which realizes logical or" width="" height="" class="" />
   </a>
   <p class="wp-caption-text">Rosenblatt-Perceptron which realizes logical or</p>
</div>

<ul>
<li>McCullch-Pitts Neuron (weights, bias, activation function is step function)</li>
<li>Rosenblatt Perceptron Algorithmus</li>
<li>Backpropagation</li>
<li>Curse of Dimensionality</li>
<li><a href="https://de.wikipedia.org/wiki/Kerndichtesch%C3%A4tzer">Parzen Window</a></li>
<li>Features: Nominal, Ordinal, Intervallskaliert, Verhältnisskaliert</li>
</ul>

<dl>
  <dt><dfn>Bayes-Rule</dfn> (Source: <a href="https://en.wikipedia.org/wiki/Bayes%27_rule">wikipedia</a>)</dt>
  <dd>Given events \(A_1\), \(A_2\) and \(B\), Bayes' rule states that the conditional odds of \(A_1:A_2\) given \(B\) are equal to the marginal odds of \(A_1:A_2\) multiplied by the Bayes factor or likelihood ratio \(\Lambda\):

\[O(A_1:A_2|B) = \Lambda(A_1:A_2|B) \cdot O(A_1:A_2) ,\]

where

\[\Lambda(A_1:A_2|B) = \frac{P(B|A_1)}{P(B|A_2)}.\]</dd>
  <dt><dfn>Parametrischer Klassifizierer</dfn></dt>
  <dd>Ein Klassifizierer heißt <i>parametrisch</i>, wenn er eine Wahrscheinlichkeitsverteilungsannahme macht.</dd>
  <dt><dfn>Naiver Bayes-Klassifikator</dfn></dt>
  <dd>Ein Klassifizierer heißt naiver Bayes-Klassifikator, wenn er den
      Satz von Bayes unter der naiven Annahme der Unabhängigkeit der Features
      benutzt.</dd>
  <dt><dfn>Normalverteilung</dfn></dt>
  <dd>Eine stetige Zufallsvariable \(X\) mit der Wahrscheinlichkeitsdichte
      \(f\colon\mathbb{R}\to\mathbb{R}\), gegeben durch<br />
      \(f(x) = \frac {1}{\sigma\sqrt{2\pi}} e^{-\frac {1}{2} \left(\frac{x-\mu}{\sigma}\right)^2}\)<br />
      heißt \(\mathcal N\left(\mu, \sigma^2\right)\)-verteilt, normalverteilt
      mit den Erwartungswert \(\mu\) und Varianz \(\sigma^2\).</dd>
  <dt><dfn>Multivariate Normalverteilung</dfn> (vgl. <a href="https://de.wikipedia.org/wiki/Mehrdimensionale_Normalverteilung">Wikipedia</a>)</dt>
  <dd>Eine \(p\)-dimensionale reelle Zufallsvariable \(X\) ist normalverteilt
      mit Erwartungswertvektor \(\mu\) und  (positiv definiter) Kovarianzmatrix
      \(\Sigma\), wenn sie eine Dichtefunktion der Form
      \[f_X(x)=\frac{1}{ \sqrt{(2\pi)^p \det(\Sigma)} } \exp \left( -\frac{1}{2}(x-\mu)^{T}\Sigma^{-1}(x-\mu) \right)\]
besitzt. Man schreibt
\[X\sim \mathcal N_p(\mu, \Sigma).\]</dd>
  <dt><dfn>Gauß'scher Klassifizierer</dfn></dt>
  <dd>Ein (naiver) Bayes-Klassifikator, welcher von normalverteilten Daten
      ausgeht heißt <i>Gauß'scher Klassifizierer</i>.</dd>
  <dt><dfn>Principal Component Analysis</dfn> (<dfn>PCA</dfn>, <dfn>Hauptkomponentenanalyse</dfn> - vgl. <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">Wikipedia</a>)</dt>
  <dd>Die Hauptkomponentenanalyse ist ein Verfahren zur
      Dimensionalitätsreduktion von ungelabelten Daten im \(\mathbb{R}^n\).
      Sie projeziert die Daten auf diejenige Hyperebene im
      \(\mathbb{R}^d\), die den durch die Projektion stattfindenden
      Datenverlust minimal hält.
      Dabei ist \(d \in 1, \dots, n\) beliebig wählbar.

      Die Transformation der Daten \(X\) findet durch eine Matrixmultiplikation
      \(Y = P \cdot X\) statt. Die Matrix \(P\) besteht aus den ersten \(d\)
      Eigenvektoren der Kovarianzmatrix der Features \(X\):

      \(P = (v_1, \dots, v_d)\) mit
      \(\lambda_j v_j = C_X v_j\) für \(j=1,\dots,d\)

      Außerdem gilt: \(C_X = \frac{1}{n-1} X X^T\) </dd>
</dl>

<h3 id="tocAnchor-1-1-4">V04: Perceptron</h3>

<p>Slide name: V04_2015-04-28_Perceptron.pdf</p>

<dl>
  <dt><dfn>McCulloch–Pitts (MCP) Neuron</dfn></dt>
  <dd>Ein MLP-Neuron is ein Algorithmus zur binären Klassifizierung. Er hat
      \(m+1\), mit \(m \in \mathbb{N}_{&gt; 0}\) inputs \(x_i \in \{0, 1\}\). Davon
      ist der erste (nullte) Konstant gleich Eins und wird <i>Bias</i> genannt.
      Jeder Input wird mit eingem Gewicht \(w_i \in \mathbb{R}\) multipliziert,
      alle gewichteten Inputs werden addiert und schließlich wird die
      Stufenfunktion
      \(\varphi(x) = \begin{cases}1 &amp;\text{falls } x &gt; 0\\0 &amp;\text{sonst} \end{cases}\)
      angewendet.
  </dd>
  <dt><dfn>Rosenblatt-Perzeptron</dfn></dt>
  <dd>Wie das McCulloch–Pitts (MCP) Neuron, nur ist \(x_i \in \mathbb{R}\) und
      ein Lernalgorithmus ist gegeben. Dieser addiert den
      \(\lambda \in (0, 1)\) gewichteten, fehlklassifizierten Vektor auf die
      Gewichte \(w_i\). \(\lambda\) heißt die <i>Lernrate</i>.
  </dd>
  <dt><dfn>Pocket Perceptron Algorithm</dfn></dt>
  <dd>Ein Lernalgorithmus für ein Rosenblatt-Perzeptron. Dieser konvergiert zu
      Gewichten, welche die wenigsten Beispiele falsch klassifiziert.
  </dd>
  <dt><dfn>Sigmoid-Funktion</dfn></dt>
  <dd>\(\varphi(x) = \frac{1}{1+e^{-x}}\)</dd>
  <dt><dfn>Softmax-Funktion</dfn></dt>
  <dd>\(\varphi(a_i) = \frac{e^{a_i}}{\sum_{k} e^{a_k}}\) wobei \(a_i\) die
      Aktivierung des \(i\)-ten Neurons der selben Schicht ist.</dd>
  <dt><dfn>Perzeptron</dfn> / <dfn>Logistic Neuron</dfn></dt>
  <dd><abbr title="Mean Squared Error">MSE</abbr> + Sigmoid activation function</dd>
</dl>

<p>Fakten:</p>

<ul>
<li>Das Rosenblatt-Perzeptron findet eine lineare Trenngrenze, wenn sie
existiert.</li>
<li>Probleme vom Rosenblatt-Perzeptron:

<ul>
<li>XOR</li>
<li>Nicht-linear trennbare Daten</li>
<li>Nicht-trennbare Daten</li>
<li>Wahl der Lernrate und der Startgewichte</li>
</ul></li>
<li>Aufbau eines biologischen Neurons (Axon, Dendriten, Zellkörper, Ranviersche
Schnürringe, Synapsen)</li>
<li>Glia-Zellen</li>
</ul>

<p>Fragen:</p>

<ul>
<li>Folie 6: Ist der Input nicht in [0, 1]?</li>
</ul>

<h3 id="tocAnchor-1-1-5">V05: Features</h3>

<p>Slide name: V05_2015-04-29_Features.pdf</p>

<dl>
  <dt><dfn>Rectified Linear Unit</dfn> (<dfn>ReLU</dfn>)</dt>
  <dd>\(\varphi(x) = \max(0, x)\)</dd>
  <dt><dfn>Softplus</dfn></dt>
  <dd>\(\varphi(x) = \log(1 + e^x)\)</dd>
  <dt><dfn>Feed Forward Neural Network</dfn></dt>
  <dd>A Feed Forward Neural Network is a learning algorithm which takes
      a fixed-size input feature vector, applies varous matrix multiplications
      and point-wise non-linear functions to obtain a fixed-size output
      vector.</dd>
  <dt><dfn>Multilayer Perceptron</dfn></dt>
  <dd>A Multilayer Perceptron is a special type of Feed Forward Neural Network.
      It consists of fully connected layers only.</dd>
  <dt><dfn>Metrik</dfn> (siehe <a href="https://de.wikipedia.org/wiki/Metrischer_Raum#Formale_Definition">Wikipedia</a>)</dt>
  <dd>Sei \(X\) eine Menge und \(d:X \times X \rightarrow \mathbb{R}\) eine
      Abbildung. \(d\) heißt Metrik auf \(X\), wenn gilt:
      <ul>
          <li>\(d(x, y) = 0 \geq x=y \;\;\; \forall x, y \in X\)</li>
          <li>\(d(x,y)=d(y,x=\)</li>
          <li>\(d(x,y) \leq d(x,z) + d(z,y)\)</li>
      </ul>
  </dd>
  <dt><dfn>Jaccard-Metrik</dfn> (siehe <a href="https://de.wikipedia.org/wiki/Jaccard-Koeffizient#Jaccard-Metrik">Wikipedia</a>)</dt>
  <dd>Es seien \(A, B\) Mengen und \(J(A, B) := \frac{|A \cup B| - |A \cap B|}{|A \cup B|}\).
      Dann heißt \(J\) die Jaccard-Metrik.
  </dd>
  <dt><dfn>Levenshtein-Distanz</dfn> (siehe <a href="https://de.wikipedia.org/wiki/Levenshtein-Distanz">Wikipedia</a>)</dt>
  <dd>Es seien \(a, b\) Zeichenketten, \(|a|\) die Länge der Zeichenkette \(a\)
      und \(\delta_{a_i \neq b_j}\) genau dann 1, wenn das \(i\)-te Zeichen von
      \(a\) und das \(j\)-te Zeichen von \(b\) sich unterscheiden.

      Dann heißt \(d_L(a, b)\) die Levenshtein-Distanz:
      \[d_L(a,b) := lev_{a,b}(|a|, |b|)\]
      \[\text{lev}_{a,b}(i, j) = \begin{cases}\max(i,j) &amp;\text{falls} \min(i,j) = 0,\\
        \min \begin{cases}\text{lev}_{a,b}(i-1,j)+1\\
                          \text{lev}_{a,b}(i,j-1)+1\\
                          \text{lev}_{a,b}(i-1,j-1)+\delta_{(a_i \neq b_j)}\\\end{cases} &amp;\text{sonst}\end{cases}\]
  </dd>
</dl>

<p>Fragen:</p>

<ul>
<li>Welche Feed Forward Neuronalen Netze existieren, die keine Multilayer
Perceptronen sind?</li>
<li>Welche Skalentypen gibt es für Merkmale (Features)?

<ul>
<li>Nominale Merkmale: Nur Gleichheit kann überprüft werden</li>
<li>Ordinale Merkmale: Es existiert eine "kleiner gleich"-Relation</li>
<li>Intervallskalierte Merkmale:

<ul>
<li>Die Differenz der Merkmale hat eine Semantik</li>
<li>Es existiert jedoch kein "wirklicher" Nullpunkt</li>
</ul></li>
<li>Verhältnisskalierte Merkmale: Wie Intervallskaliert, aber mit absolutem
Nullpunkt.</li>
</ul></li>
</ul>

<h3 id="tocAnchor-1-1-6">V06: Backpropagation</h3>

<p>Slide name: V06_2015-05-05_Backpropagation.pdf</p>

<dl>
    <dt><dfn>Kreuzentropie Fehlerfunktion</dfn>
        (<dfn>Cross-Entropy</dfn>,
         vgl. <a href="https://de.wikipedia.org/wiki/Kreuzentropie">Wikipedia</a>)</dt>
    <dd>\[E_{-x} = - \sum_{k}[t_k^x \log(o_k^x) + (1-t_k^x) \log (1- o_k^x)]\]
        wobei \(x\) der Feature-Vektor ist, \(k\) ein Neuron des letzen
        Layers, \(t\) der wahre Wert (d.h. der gewünschte Output),
        \(o\) der tatsächliche Output ist.</dd>
</dl>

<ul>
<li>Stochastic Gradient Descent</li>
<li>Batch Gradient Descent</li>
</ul>

<h3 id="tocAnchor-1-1-7">V07: Feature Learning</h3>

<p>Slide name: V07_12-05-2015_Feature_Learning.pdf</p>

<dl>
    <dt><dfn>Autoencoder</dfn> (vgl. <a href="https://en.wikipedia.org/wiki/Autoencoder">Wikipedia</a>)</dt>
    <dd>Ein Autoencoder ist ein neuronales Netz, welches darauf trainiert wird
        die Input-Daten am Output wieder zu replizieren.</dd>
    <dt><dfn>Bottleneck Features</dfn></dt>
    <dd>Unter Bottleneck-Features versteht man eine Schicht in einem
        neuronalem Netz, welche wesentlich kleiner ist als die vorhergehende
        und nachfolgende Schicht.</dd>
    <dt><dfn>Kullback-Leibler-Divergenz</dfn> (vgl. <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Wikipedia</a>)</dt>
    <dd>Die Kullback-Leibler-Divergenz ist ein Maß für die Unterschiedlichkeit
        zweier Wahrscheinlichkeitsverteilungen \(P, Q\). Für
        diskrete Verteilungen ist sie definiert als:
        \[KL(P||Q) := \sum_{x \in X} P(x) \cdot \log \frac{P(x)}{Q(x)}\]</dd>
    <dt><dfn>Denoising Autoencoder</dfn></dt>
    <dd>Ein Autoencoder, welcher trainiert wird rauschen zu entfernen.</dd>
</dl>

<p>Fakten:</p>

<ul>
<li>Eine lineare Aktivierungsfunktion wird in einer Repräsentation im
Bottleneck-Feature resultieren, die PCA ähnelt.</li>
<li>Fehlerfunktion:

<ul>
<li><abbr title="Cross Entropy">CE</abbr> bei binären Ausgaben (d.h. Input-Features)</li>
<li><abbr title="Mean squared error">MSE</abbr> bei reelen Ausgaben (d.h. Input-Features)</li>
</ul></li>
</ul>

<p>Fragen:</p>

<ul>
<li>Wie muss man die Grafik zu Stacked Denoising Autoencodern verstehen?</li>
</ul>

<h3 id="tocAnchor-1-1-8">V08: Deep Learning</h3>

<p>Slide name: V08_2015-05-13_Deep_Learning.pdf</p>

<dl>
    <dt><dfn>Deep Neural Networks</dfn></dt>
    <dd>Neural Networks with at least two hidden layers with nonlinear
        activation functions.</dd>
    <dt><dfn>Hyperparameter</dfn></dt>
    <dd>Hyperparameter \(\theta\) eines neuronalen Netzes sind Parameter,
        welche nicht gelernt werden.</dd>
    <dt><dfn>Learnin Rate Scheduling</dfn></dt>
    <dd>Start with a learning rate \(\eta\) and reduce it while training</dd>
    <dt><dfn>Exponential Decay Learning Rate</dfn></dt>
    <dd>\(\eta_t = \eta_{t-1} \cdot \alpha = \eta_0 \cdot \alpha^t\) mit \(\alpha \in (0, 1)\)</dd>
    <dt><dfn>Performance Scheduling</dfn></dt>
    <dd>Measure the error on the cross validation set and decrease the learning
        rate when the algorithm stops improving.</dd>
    <dt><dfn>RProp</dfn> (siehe <a href="https://en.wikipedia.org/wiki/Rprop">Wikipedia</a>)</dt>
    <dd>RProp is a learning rate scheduling method which is only based on the
        sign of the gradient. It increases the learning rate when the sign of
        the gradient doesn't change and increases it when the sign of the
        gradient changes.</dd>
    <dt><dfn><abbr title="adaptive gradient">AdaGrad</abbr></dfn> (siehe <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#AdaGrad">Wikipedia</a>)</dt>
    <dd>\[\eta_{tij} = \frac{\eta_0}{\sqrt{1 + \sum_k {(\frac{\partial E^{t-k}}{\partial w_{ij}})}^2}}\]</dd>
    <dt><dfn>Newbob Scheduling</dfn></dt>
    <dd>Newbob scheduling is a combination of Exponential decay learning rate
        scheduling and performance scheduling. It starts with a learning rate
        \(\eta_0\). When the validation error stops decreasing, switch to
        exponentially decaying learning rate. Terminate when the validation
        error stops decreasing again.</dd>
    <dt><dfn>Cross Entropy Error function</dfn> (CE)</dt>
    <dd>\[E_{CE}(w) = - \sum_{x \in X} \sum_{k} [t_k^x \log(o_k^x + (1-t_k^x) \log(1-o_k^x))]\]
        where \(w\) is the weight vector, \(X\) is the set of training
        examples (feature vectors),
        \(t_k^x = \begin{cases}1 &amp;\text{if } x \text{ is of class }k\\0&amp;\text{otherwise}\end{cases}\)
        and \(o_k^x\) is the output at neuron \(k\) of the network for the
        feature vector \(x\).</dd>
    <dt><dfn>Mean Squared Error function</dfn> (MSE)</dt>
    <dd>\[E_{MSE}(w) = \frac{1}{2}\sum_{x \in X} \sum_{k} (t_k^x - o_k^x)^2\]
        where \(w\) is the weight vector, \(X\) is the set of training
        examples (feature vectors), \(t_k^x = \begin{cases}1 &amp;\text{if } x \text{ is of class }k\\0&amp;\text{otherwise}\end{cases}\) and \(o_k^x\) is the output
        at neuron \(k\) of the network for the feature vector \(x\).</dd>
</dl>

<ul>
<li>Pretraining</li>
<li>TDNNs CNNs</li>
<li>Design choices (hyperparameters):

<ul>
<li>Topology (Width of layers, number of layers)</li>
<li>Activation functions</li>
<li>Error function</li>
<li>Mini-Batch size</li>
<li>Training function</li>
<li>Preprocessing</li>
<li>Initial Weights</li>
</ul></li>
<li>MSE vs CE:

<ul>
<li>MSE penetalizes large differences much more than small ones</li>
<li>MSE works well for function approximation</li>
<li>CE works well on classification tasks</li>
</ul></li>
</ul>

<p>Fragen:</p>

<ul>
<li>AdaGrad (Folie 34)</li>
<li>Optimal drain damage (Folie 36)</li>
</ul>

<h3 id="tocAnchor-1-1-9">V09: Reinforcement Learning</h3>

<p>Slide name: V09_2015-05-26-Reinforcement-Learning.pdf</p>

<dl>
    <dt><dfn>Markov Decision Process</dfn> (<dfn>MDP</dfn>, vgl. <a href="https://de.wikipedia.org/wiki/Markow-Entscheidungsproblem">Wikipedia</a>)</dt>
    <dd>Ein Markovscher Entscheidungsprozess ist ein 5-Tupel
        \((S, A, T, r, p_0)\), wobei
        <ul>
            <li>\(S\) eine endliche Zustandsmenge,</li>
            <li>\(A\) eine endliche Menge von Aktionen,</li>
            <li>\(T_a(s, s') = T(s_{t+1}=s'|s_t = s, a_t = a)\) die
                Wahrscheinlichkeit zu einem beliebigen Zeitpunkt von Zustand
                \(s\) mit der Aktion \(a\) in den Zustand \(a'\) zu kommen
                (engl. Transition),</li>
            <li>\(r_a(s, s')\) ist die Belohnung (Reward), die man direkt
                erhält wenn man erhält wenn man von Zustand \(s\) mit Aktion
                \(a\) in Zustand \(s'\) kommt,</li>
            <li>\(p_0\) ist die Startverteilung auf die Zustände \(S\)</li>
        </ul>
    </dd>
    <dt><dfn>Diskontierungsfaktor</dfn></dt>
    <dd>Ein Diskontierungsfaktor \(\gamma \in [0, 1]\) encodiert
        den Bedeutungsverlust zwischen einer direkten Belohnung und
        einer späteren Belohnung. Es sollte \(\gamma &lt; 1\) gelten um
        unendliche Belohnungen zu vermeiden.</dd>
    <dt><dfn>Strategie</dfn> (engl. <dfn>Policy</dfn>)</dt>
    <dd>Eine Strategie \(\pi:S \rightarrow A\) sagt einem Agenten welche
        Aktion er in welchem Zustand ausführen soll.</dd>
    <dt><dfn>Q-Funktion</dfn> (Action-Value function)</dt>
    <dd>Die Q-Funktion \(Q^\pi: S \times A \rightarrow \mathbb{R}\) weißt jeder
        Aktion in jedem Zustand einen Wert zu unter der Annahme, dass
        die Strategie \(\pi\) genutzt wird.</dd>
    <dt><dfn>V-Funktion</dfn> (State-Value function)</dt>
    <dd>Die V-Funktion \(V^\pi: S \rightarrow \mathbb{R}\) weißt jeder
        jedem Zustand die Erwartete Belohnung zu unter der Annahme, dass
        die Strategie \(\pi\) genutzt wird.</dd>
    <dt><dfn>\(\varepsilon\)-Greedy Strategy</dfn></dt>
    <dd>Explore \(\varepsilon\)% of the time. Otherwise, follow what you
        currently believe is best.</dd>
    <dt><dfn>\(\varepsilon\)-decreasing Strategy</dfn></dt>
    <dd>Explore \(\varepsilon\)% of the time. Otherwise, follow what you
        currently believe is best. Reduce \(\varepsilon\) over time.</dd>
    <dt><dfn>\(\varepsilon\)-first Strategy</dfn></dt>
    <dd>Explore for \(\varepsilon\) steps and then do what you think is best.</dd>
    <dt><dfn>Adaptive \(\varepsilon\)-greedy Strategy</dfn></dt>
    <dd>Explore \(\varepsilon\)% of the time. Otherwise, follow what you
        currently believe is best. Reduce \(\varepsilon\) based on what you
        learn.</dd>
    <dt><dfn>Episode</dfn></dt>
    <dd>A run through an <abbr title="Markov Decision Process">MDP</abbr> from
        a start state to an end state.</dd>
    <dt><dfn>Monte Carlo Policy Evaluation</dfn></dt>
    <dd>Initialize state values \(V^\pi\) and iterate:
        <ol>
            <li>Generate an episode</li>
            <li>foreach state \(s\) in episode:
            <ol>
                <li>Get the reward \(\hat{R}\) from that state on</li>
                <li>\(\hat{R} = \sum_{j=0}^\infty \gamma^j r_j\)</li>
                <li>\(V_{k+1}^\pi (s) \leftarrow V_k^pi (s) (1-\alpha)+\alpha \hat{R}\)</li>
                <li></li>
            </ol>
            </li>
        </ol>
        where \(\alpha\) is the learning rate.
    </dd>
    <dt><dfn>Temporal Difference Learning</dfn> (vgl. <a href="https://de.wikipedia.org/wiki/Temporal_Difference_Learning">Wikipedia</a>)</dt>
    <dd>TODO?</dd>
</dl>

<p>Konvention:</p>

<ul>
<li>Eine optimale Strategie wird mit (\pi^*) bezeichnet.</li>
</ul>

<p>Fragen:</p>

<ul>
<li>Was bedeutet es, wenn in einem MDP der Diskontierungsfaktor (\gamma = 0)
ist? → Nur der aktuelle Reward ist wichtig. Effektiv nimmt der Agent immer
das nächste Feld, welche den höchsten Reward bietet (bzw. die Aktion, die
den größten 1-Aktion Erwartungswert liefert).</li>
<li>Was bedeutet es, wenn in einem MDP der Diskontierungsfaktor (\gamma = 1)
ist? → Der Agent versucht die Summe der Belohnungen insgesamt zu maximieren.</li>
</ul>

<p>TODOs:</p>

<ul>
<li>What is Policy Iteration?</li>
<li>SARSA - State-Action-Reward-State-Action</li>
<li>Q-Learning</li>
</ul>

<h3 id="tocAnchor-1-1-10">V10: SOM</h3>

<p>Slide name: V10_2015-05-26_SOM.pdf</p>

<dl>
    <dt><dfn>Selbstorganisierende Karten</dfn> (<dfn>SOM</dfn>, <dfn>Kohonennetze</dfn>, vgl. <a href="https://de.wikipedia.org/wiki/Selbstorganisierende_Karte">Wikipedia</a>)</dt>
    <dd>SOMs sind eine Art von Neuronalen Netzen.</dd>
</dl>

<p>Siehe auch:</p>

<ul>
<li><a href="https://codesachin.wordpress.com/2015/11/28/self-organizing-maps-with-googles-tensorflow/">Self-Organizing Maps with Google’s TensorFlow</a></li>
<li><a href="http://www.ai-junkie.com/ann/som/som1.html">Kohonen's Self Organizing Feature Maps</a> by ai-junkie</li>
</ul>

<h3 id="tocAnchor-1-1-11">V11: RBMs</h3>

<p>Slide name: V11_2015-05-27_RBMs</p>

<dl>
    <dt><dfn>Hopfield-Netz</dfn> (vgl. <a href="https://de.wikipedia.org/wiki/Hopfield-Netz">Wikipedia</a>)</dt>
    <dd>Ein Hopfield-Netz besteht nur aus einer Schicht von McCulloch-Pitts
        Neuronen. Jedes Neuron ist mit jedem anderen Neuron (also nicht sich
        selbst) und allen Inputs verbunden. Die Schicht funktioniert
        gleichzeitig als Ein- und Ausgabeschicht.</dd>
    <dt><dfn>Boltzmann-Maschine</dfn> (vgl. <a href="https://de.wikipedia.org/wiki/Boltzmann-Maschine">Wikipedia</a>)</dt>
    <dd>Boltzmann-Maschinen sind stochastische neuronale Netzwerke, welche
        duch belibige ungerichtete Graphen repräsentiert werden können. Die
        neuronen sind binär; sie feuern also entweder oder nicht. Es gibt
        insbesondere keine Unterschiede in der Stärke mit der sie feuern.</dd>
    <dt><dfn>Restricted Boltzmann machine</dfn> (<dfn>RBM</dfn>, vgl. <a href="https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine">Wikipedia</a>)</dt>
    <dd>Im Gegensatz zur Boltzmann-Maschine muss die Restricted
        Boltzmann-Machine (RBM) aus einem bipartitem Graph bestehen. Dies
        erlaubt ein effizienteres Trainingsverfahren.</dd>
    <dt><dfn>Simulated annealing</dfn> (vgl. <a href="https://de.wikipedia.org/wiki/Simulated_annealing">Wikipedia</a>)</dt>
    <dd>Simulated annealing ist ein heuristisches Optimierungsverfahren.

        Sei \(D\) ein Wertebereich einer Funktion \(f: D \rightarrow \mathbb{R}\)
        und \(U: D \rightarrow \mathcal{P}(D)\) eine Funktion, welche die
        Umgebung eines Punktes angibt. Sei \(T: \mathbb{N}_0 \rightarrow \mathbb{R}_{&gt; 0}\)
        die Temperatur zum Zeitpunkt \(t \in \mathbb{N}_0\).

        Gesucht ist \(\text{arg min}_{x \in D} f(x)\).

        Wähle zum Zeitpunkt \(t=0\) einen zufälligen Startwert \(x \in D\).

        Gehe nun iterativ vor und jeweils einen Zeitschritt weiter:

        Nehme einen Punkt aus der Umgebung \(y \in U(x)\). Wenn
        \(f(y) \leq f(x)\), dann überschreibe \(x \leftarrow y\). Falls nicht,
        dann überschreibe es mit der Wahrscheinlichkeit \(\exp \left (-\frac{f(y)-f(x)}{T(t)} \right )\).

        Speichere in jedem Schritt den bisher besten Wert.
        </dd>
</dl>

<p>Anwendungen:</p>

<ul>
<li>RBMs:

<ul>
<li>Collaborative Filtering: User-rating prediction for movie database. The
problem is that not every user has rated all movies.</li>
</ul></li>
</ul>

<p>Fragen:</p>

<ul>
<li>Hopfield-Netze:

<ul>
<li>Wie trainiert man sie?</li>
<li>Wo werden / wurden sie benutzt?</li>
</ul></li>
</ul>

<p>Siehe auch:</p>

<ul>
<li>Deeplearning.net: <a href="http://deeplearning.net/tutorial/rbm.html">Restricted Boltzmann Machines (RBM)</a></li>
<li>Wikipedia: <a href="https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine">Restricted Boltzmann machine</a></li>
</ul>

<h3 id="tocAnchor-1-1-12">V12: RNNs</h3>

<p>Slide name: V12_2015-06-02_RNNs.pdf</p>

<dl>
    <dt><dfn>Elman-Netz</dfn> (vgl. <a href="https://de.wikipedia.org/wiki/Elman-Netz">Wikipedia</a>)</dt>
    <dd>Ein rekurrentes neuronales Netzwerk, bei dem die Ausgabe eines
        hidden layers im nächsten Zeitschritt als Eingabe verwendet wird.</dd>
    <dt><dfn>Jordan-Netz</dfn> (vgl. <a href="https://de.wikipedia.org/wiki/Jordan-Netz">Wikipedia</a>)</dt>
    <dd>Ein rekurrentes neuronales Netzwerk, bei dem die Ausgabe der
        Ausgabeschicht im nächsten Zeitschritt als Eingabe verwendet wird.</dd>
    <dt><dfn>Backpropagation through Time</dfn> (<dfn>BPTT</dfn>)</dt>
    <dd>Ein Trainingsalgorithmus für rekurrente neuronale Netze, bei dem
        das Netz "ausgerollt" wird. Das rekurrente Netz wird also als unendlich
        großes nicht-rekurrentes Netz behandelt.</dd>
    <dt><dfn>Vanishing gradient problem</dfn> (vgl. <a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem">Wikipedia</a>)</dt>
    <dd>Das Problem des verschwindenden Gradienten ist eine Herausforderung im
        Kontext neuronaler Netze, welche mit Backpropagation trainiert
        werden. Insbesondere bei sehr tiefen oder rekurrenten Netzen
        kann es passieren, dass der Gradient bei den ersten Schichten sehr
        niedrig ist, sodass das Netz sehr langsam lernt. Aufgrund numerischer
        Ungenauigkeit kann dies sogar dazu führen, dass das Netz in den
        ersten Schichten nicht lernen kann.</dd>
    <dt><dfn>Long short-term memory</dfn> (vgl. <dfn>LSTM</dfn>, <a href="https://en.wikipedia.org/wiki/Long_short-term_memory">Wikipedia</a>)</dt>
    <dd>Ein LSTM ist ein Typ eines neuronalen Netzwerks. Das besondere an
        LSTM Netzen sind "intelligente" Neuronen, welche über Gates bestimmen
        ob ein Wert gespeichert wird und wie lange.</dd>
</dl>

<p>Siehe auch:</p>

<ul>
<li><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Recurrent Neural Networks</a></li>
<li><a href="http://www.cs.toronto.edu/%7Eilya/fourth.cgi?prefix=E%3D&amp;numChars=300">Char-Predictor online Demo</a></li>
<li><a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/">Recurrent Neural Networks Tutorial, Part 1 – Introduction to RNNs</a></li>
<li>YouTube: <a href="https://www.youtube.com/watch?v=SKMpmAOUa2Q">Vanishing Gradient</a> (5:24 min)</li>
</ul>

<h3 id="tocAnchor-1-1-13">V13: NNlearning-tricks</h3>

<p>Slide name: V13_2015-06-09_NNlearning-tricks.pdf</p>

<dl>
    <dt><dfn>Momentum</dfn></dt>
    <dd>In der Update-Regel \(\Delta w_{ij}^* (t+1) = \Delta w_{ij} (t+1) + \alpha \Delta w_{ij}(t)\) wird der Term \(\Delta w_{ij}(t)\) als <i>Momentum</i> bezeichnet.
        Der Skalar \(\alpha \in [0, 1]\) gewichtet diesen und ist ein
        Hyperparameter.</dd>
    <dt><dfn>Quickprop</dfn> (<a href="https://en.wikipedia.org/wiki/Quickprop">Wikipedia</a>)</dt>
    <dd>Quickprop ist ein Trainingsverfahren für neuronale Netze. TODO: Wie funktioniert es?</dd>
    <dt><dfn>Weight Decay</dfn></dt>
    <dd>Passe die Fehlerfunktion an: \(E = MSE + \lambda \sum_{i,j} w_{ij}^2\)</dd>
    <dt><dfn>Weight Elimination</dfn></dt>
    <dd>Passe die Fehlerfunktion an: \(E = MSE + \lambda \sum_{i,j} \frac{w_{ij}^2}{1+w_{ij}^2}\)</dd>
    <dt><dfn>Optimal Brain Damage</dfn></dt>
    <dd>Optimal Brain Damage entfernt nach dem Training Verbindungen die
        sehr kleine \(|w_{ij}|\) haben.

        Besser: Entferne Verbindungen, die geringen Einfluss auf die
        Fehlerfunktion haben.</dd>
    <dt><dfn>Cascade Correlation Architecture</dfn> (siehe Fahlman und Lebiere: <a href="http://papers.nips.cc/paper/207-the-cascade-correlation-learning-architecture.pdf">The Cascade-Correlation Learning Architecture</a>)</dt>
    <dd>Die Cascade Correlation Architecture wird Schritt für Schritt
        aufgebaut. Sie ist keine typische Multilayer-Architektur.</dd>
</dl>

<p>Speed-ups sind möglich durch:</p>

<ul>
<li>Momentum</li>
<li>Überspringen von bereits gut gelernten Beispielen</li>
<li>Dynamische Anpassung der Lernrate $\eta$</li>
<li>Quickprop</li>
<li>Gute Initialisierung</li>
</ul>

<p>Lernen kann getweakt werden:</p>

<ul>
<li>Fehlerfunktion anpassen

<ul>
<li><abbr title="Mean Squared Error">MSE</abbr></li>
<li>Cross-Entropy</li>
<li><abbr title="Classification Figure of Merit">CFM</abbr></li>
</ul></li>
<li>Overfitting verhindern

<ul>
<li>Weight decay</li>
<li>Weight elimination</li>
<li>Optimal Brain Damage</li>
<li>Optimal Brain Surgeon</li>
</ul></li>
<li>Schrittweise Netzkonstruktion

<ul>
<li>Cascade Correlation</li>
<li>Meiosis Netzwerke (siehe Stephen Jose Hanson: <a href="http://papers.nips.cc/paper/227-meiosis-networks.pdf">Meiosis Networks </a>)</li>
<li><abbr title="Automativ Structure Optimalization">ASO</abbr>: TODO - wie
funktioniert das?</li>
</ul></li>
</ul>

<p>Fragen:</p>

<ul>
<li>Folie 19: Was passiert hier? (TODO)</li>
</ul>

<h3 id="tocAnchor-1-1-14">V14: DNN CV</h3>

<p>Slide name: V14_2015-06-10_DNN_CV .pdf</p>

<dl>
    <dt><dfn>SIFT</dfn> (<dfn>Scale-invariant feature transform</dfn>, siehe <a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform">Wikipedia</a>)</dt>
    <dd>Unter SIFT versteht man bestimmte Features in der Bildverarbeitung,
        welche invariant unter skalierung sind.</dd>
    <dt><dfn>Texton</dfn> (siehe <a href="https://en.wikipedia.org/wiki/Texton">Wikipedia</a> und <a href="http://vcla.stat.ucla.edu/old/Chengen_Research/texton.htm">UCLA</a>)</dt>
    <dd>Unter einem Texton versteht man grundlegende, kleine Features eines
        Bildes. Diese Bilden die kleinsten als unterschiedlich wahrnehmbaren
        Einheiten.</dd>
    <dt><dfn>Convolutional Neural Network</dfn> (<dfn>CNN</dfn>, siehe <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Wikipedia</a>)</dt>
    <dd>Ein CNN ist ein Neuronales Netzwerk, welches mindestens eine Schicht
        hat, welche die Parameter eines Kernels für eine Faltung lernt.</dd>
    <dt><dfn>Feature Map</dfn></dt>
    <dd>Im Kontext von CNNs versteht man unter einer Feature-Map die Ausgabe
        eines Kernels in einem Convolutional Layer.</dd>
</dl>

<p>Facts:</p>

<ul>
<li>Pooling: Max, Mean, Probabilistic</li>
</ul>

<h3 id="tocAnchor-1-1-15">V15: Speech-Independence</h3>

<p>Slide name: V15_2015-06-17_Speech-Independence.pdf</p>

<h2 id="tocAnchor-1-17">Visualisierung von Netzen</h2>

<p>Häufig wird die Architektur neuronaler Netze grafisch dargestellt. Dabei ist
mir folgendes aufgefallen:</p>

<ul>
<li>Im Innenren von Neuronen wird die Aktivierungsfunktion "geplottet". Das heißt
bei der Sigmoidfunktion wird etwas S-Förmiges dargestellt, bei der
sign-Funktion etwas eckiges, bei ReLU ein horizontaler Strich gefolgt von
einem Strich im 45-Grad Winkel ... (TODO: Beispiele aufzeichnen)</li>
<li>Typischerweise ist der Input links (oder alternativ unten) und der Output
rechts (oder alternativ oben)</li>
</ul>

<h2 id="tocAnchor-1-18">Material und Links</h2>

<ul>
<li><a href="http://ies.anthropomatik.kit.edu/lehre_mustererkennung.php">Vorlesungswebsite</a></li>
<li><a href="https://github.com/thanhleha/NNPraktikum">NNPraktikum</a>: Toolkit für die Übungsblätter</li>
<li>StackExchange

<ul>
<li>✓ <a href="http://stats.stackexchange.com/q/74082/25741">What is the difference in Bayesian estimate and maximum likelihood estimate?</a></li>
<li>✓ <a href="http://datascience.stackexchange.com/q/9172/8820">Can k-means clustering get shells as clusters?</a></li>
<li><a href="http://datascience.stackexchange.com/q/9177/8820">How is the Schwarz Criterion defined?</a></li>
<li><a href="http://datascience.stackexchange.com/q/9195/8820">Are there studies which examine dropout vs other regularizations?</a></li>
<li><a href="http://datascience.stackexchange.com/q/9175/8820">How do subsequent convolution layers work?</a></li>
<li>✓ <a href="http://datascience.stackexchange.com/q/9212/8820">Is Maxout the same as max pooling?</a></li>
<li><a href="http://robotics.stackexchange.com/q/8617/11257">What is \(\alpha \sin(\theta) + \beta \frac{d \theta}{d t}\) in the inverted pole problem?</a></li>
<li>✓ <a href="http://datascience.stackexchange.com/q/9233/8820">(Why) do activation functions have to be monotonic?</a></li>
<li><a href="http://datascience.stackexchange.com/q/9302/8820">The cross-entropy error function in neural networks</a></li>
</ul></li>
<li><a href="http://imgur.com/a/Hqolp">Visualizing Optimization Algos</a></li>
<li><a href="http://phiresky.github.io/kogsys-demos/neural-network/">Neural Network demo</a></li>
<li><a href="https://github.com/Marvin182/NeuralNets">Skript von Marvin Ritter</a></li>
</ul>

<h2 id="tocAnchor-1-19">Übungsbetrieb</h2>

<p>Übungsblätter sind freiwillig.</p>

<h2 id="tocAnchor-1-20">Termine und Klausurablauf</h2>

<p><strong>Datum</strong>: nach Terminvereinbarung<br />
<strong>Ort</strong>: <a href="http://www.kithub.de/map/2210">Gebäude 50.20</a><br />
<strong>Übungsschein</strong>: gibt es nicht<br />
<strong>Bonuspunkte</strong>: gibt es nicht<br />
<strong>Erlaubte Hilfsmittel</strong>: keine</p>

                        </div>
                        <div class="postmeta">Posted in
                            
                                <a href="//martin-thoma.com/category/deutschland/">german posts</a><!--TODO: Displayed category name should be upper case! -->
                             | Tags:
                            
                                
                                    <a href="//martin-thoma.com/tag/klausur/">Klausur</a>
                                
                            
                                , <a href="//martin-thoma.com/tag/machine-learning/">Machine Learning</a>
                                
                            
                                , <a href="//martin-thoma.com/tag/neural-networks/">Neural Networks</a>
                                
                             by <a rel="author" class="vcard author" href="//martin-thoma.com/author/martin-thoma/"><span class="fn">Martin Thoma</span></a> on <span class="updated"><span class="value-title" title="2015-04-27 21:15:00 +0200">
                                April
                                27th
                                  ,
                                2015</span></span></div>

                            <div class="navigation clearfix">
                                <div class="alignleft">
                                
                                    &laquo; <a href="//martin-thoma.com/mustererkennung-klausur/" rel="prev">Mustererkennung - Klausur</a>
                                
                                </div>
                                <div class="alignright">
                                
                                    <a href="//martin-thoma.com/machine-learning-2-course/" rel="next">Machine Learning 2 - Vorlesung</a> &raquo;
                                
                                </div>
                            </div>

                        </article>
                        <div id="respond">
                            <h3>Leave a Reply</h3>
                                <!-- comment discuss code -->
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'martinthoma'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    <!-- comment discuss code -->

                        </div>
                    </div>
                </div>
            <div class="span-8 last">
                <div id="subscriptions">
<a href="//martin-thoma.com/feed/"><img src="//martin-thoma.com/css/images/rss.png" alt="Subscribe to RSS Feed" title="Subscribe to RSS Feed" width="72" height="47" /></a>		
<a href="https://twitter.com/#!/themoosemind" title="Follow me on Twitter!"><img src="//martin-thoma.com/css/images/twitter.png" title="Follow me on Twitter!" alt="Follow me on Twitter!"  width="76" height="47" /></a>
</div>

                <div id="sidebar">
                <!-- type: searchbox.html - TODO-->
<ul>
    <li id="search">
        <div class="searchlayout">
            <form method="get" id="searchform" action="http://google.com/cse" role="search">
                <input type="hidden" name="cx" value="017345337424948206369:qrnnnentkkk" />
                <input type="search" value="" name="q" id="s" placeholder="Search with Google"/>
                <input type="image" src="//martin-thoma.com/css/images/search.gif" style="border:0; vertical-align: top;" alt="search"/> 
            </form>
        </div>
    </li>
</ul>

                <div class="addthis_toolbox">   
    <div class="custom_images">
            <a href="http://twitter.com/share?url=//martin-thoma.com/neuronale-netze-vorlesung&amp;hashtags=klausur,machine-learning,neural-networks,&amp;via=themoosemind" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/twitter.png" width="32" height="32" alt="Twitter" /></a>
            <a href="http://del.icio.us/post?url=//martin-thoma.com/neuronale-netze-vorlesung&amp;title=Neuronale%20Netze%20-%20Klausur" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/delicious.png" width="32" height="32" alt="Delicious" /></a>
            <a href="http://www.facebook.com/sharer.php?u=//martin-thoma.com/neuronale-netze-vorlesung" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/facebook.png" width="32" height="32" alt="Facebook" /></a>
            <a href="http://digg.com/submit?phase=2&amp;url=//martin-thoma.com/neuronale-netze-vorlesung&amp;title=Neuronale%20Netze%20-%20Klausur" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/digg.png" width="32" height="32" alt="Digg" /></a>
            <a href="http://www.stumbleupon.com/submit?url=//martin-thoma.com/neuronale-netze-vorlesung&amp;title=Neuronale%20Netze%20-%20Klausur" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/stumbleupon.png" width="32" height="32" alt="Stumbleupon" /></a>
            <a href="https://plusone.google.com/_/+1/confirm?hl=en&amp;url=//martin-thoma.com/neuronale-netze-vorlesung" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/gplus.png" width="32" height="32" alt="Google Plus" /></a>
            <a href="http://reddit.com/submit?url=//martin-thoma.com/neuronale-netze-vorlesung&amp;title=Neuronale%20Netze%20-%20Klausur" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/reddit.png" width="32" height="32" alt="Reddit" /></a>
    </div>
</div>

                <ul>
                    <li id="categories-3" class="widget widget_categories">
                        <!-- type: categories -->
<h2 class="widgettitle">Categories</h2>
    <ul>
        <li class="cat-item cat-item-11"><a href="//martin-thoma.com/category/code/" title="Tipps for coding in different languages like Python oder C++.">Code</a></li>
        <li class="cat-item cat-item-21"><a href="//martin-thoma.com/category/web/" title="New emerging websites and technologies.">The Web</a></li>
        <li class="cat-item cat-item-31"><a href="//martin-thoma.com/category/cyberculture/" title="Lolcats, planking, Trollfaces, ...">Cyberculture</a></li>
        <li class="cat-item cat-item-3404"><a href="//martin-thoma.com/category/maths/" title="View all posts filed under Mathematics">Mathematics</a></li>
        <li class="cat-item cat-item-881"><a href="//martin-thoma.com/category/bits-and-bytes/" title="Sometimes posts don&#039;t fit in any category.">My bits and bytes</a></li>
        <li class="cat-item cat-item-41"><a href="//martin-thoma.com/category/deutschland/" title="[All Posts here are written in German about German topics] - Die Bahn, unsere Politik und Europa.">German posts</a></li>
	</ul>

                    </li>
                    <li id="tag_cloud-3" class="widget widget_tag_cloud">
                        <h2 class="widgettitle">Tags</h2>
                        <div class="tagcloud"><a style='font-size: 130.77%' href='//martin-thoma.com/tag/ai/' title='9 topics'>AI</a>
<a style='font-size: 102.65%' href='//martin-thoma.com/tag/algebra/' title='6 topics'>Algebra</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/assembly-language/' title='5 topics'>Assembly language</a>
<a style='font-size: 102.65%' href='//martin-thoma.com/tag/bash/' title='6 topics'>Bash</a>
<a style='font-size: 192.76%' href='//martin-thoma.com/tag/c/' title='22 topics'>C</a>
<a style='font-size: 138.07%' href='//martin-thoma.com/tag/cpp/' title='10 topics'>CPP</a>
<a style='font-size: 113.34%' href='//martin-thoma.com/tag/challenge/' title='7 topics'>Challenge</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/chrome/' title='5 topics'>Chrome</a>
<a style='font-size: 138.07%' href='//martin-thoma.com/tag/clip/' title='10 topics'>Clip</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/command-line/' title='5 topics'>Command Line</a>
<a style='font-size: 102.65%' href='//martin-thoma.com/tag/computer-science/' title='6 topics'>Computer science</a>
<a style='font-size: 122.60%' href='//martin-thoma.com/tag/digitaltechnik/' title='8 topics'>Digitaltechnik</a>
<a style='font-size: 102.65%' href='//martin-thoma.com/tag/flashgames/' title='6 topics'>Flashgames</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/geometry/' title='5 topics'>Geometry</a>
<a style='font-size: 130.77%' href='//martin-thoma.com/tag/google/' title='9 topics'>Google</a>
<a style='font-size: 122.60%' href='//martin-thoma.com/tag/google-code-jam/' title='8 topics'>Google Code Jam</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/html5/' title='5 topics'>HTML5</a>
<a style='font-size: 130.77%' href='//martin-thoma.com/tag/it-security/' title='9 topics'>IT-Security</a>
<a style='font-size: 226.92%' href='//martin-thoma.com/tag/java/' title='36 topics'>Java</a>
<a style='font-size: 102.65%' href='//martin-thoma.com/tag/javascript/' title='6 topics'>JavaScript</a>
<a style='font-size: 178.84%' href='//martin-thoma.com/tag/kit/' title='18 topics'>KIT</a>
<a style='font-size: 211.92%' href='//martin-thoma.com/tag/klausur/' title='29 topics'>Klausur</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/kogsys/' title='5 topics'>KogSys</a>
<a style='font-size: 201.63%' href='//martin-thoma.com/tag/latex/' title='25 topics'>LaTeX</a>
<a style='font-size: 178.84%' href='//martin-thoma.com/tag/linear-algebra/' title='18 topics'>Linear algebra</a>
<a style='font-size: 170.67%' href='//martin-thoma.com/tag/linux/' title='16 topics'>Linux</a>
<a style='font-size: 138.07%' href='//martin-thoma.com/tag/machine-learning/' title='10 topics'>Machine Learning</a>
<a style='font-size: 122.60%' href='//martin-thoma.com/tag/matrix/' title='8 topics'>Matrix</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/os/' title='5 topics'>OS</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/operating-systems/' title='5 topics'>Operating Systems</a>
<a style='font-size: 130.77%' href='//martin-thoma.com/tag/php/' title='9 topics'>PHP</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/physics/' title='5 topics'>Physics</a>
<a style='font-size: 239.24%' href='//martin-thoma.com/tag/programming/' title='43 topics'>Programming</a>
<a style='font-size: 130.77%' href='//martin-thoma.com/tag/project-euler/' title='9 topics'>Project Euler</a>
<a style='font-size: 270.00%' href='//martin-thoma.com/tag/python/' title='67 topics'>Python</a>
<a style='font-size: 102.65%' href='//martin-thoma.com/tag/review/' title='6 topics'>Review</a>
<a style='font-size: 130.77%' href='//martin-thoma.com/tag/swt-i/' title='9 topics'>SWT I</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/science/' title='5 topics'>Science</a>
<a style='font-size: 130.77%' href='//martin-thoma.com/tag/theoretical-computer-science/' title='9 topics'>Theoretical computer science</a>
<a style='font-size: 102.65%' href='//martin-thoma.com/tag/tikz/' title='6 topics'>Tikz</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/ubuntu/' title='5 topics'>Ubuntu</a>
<a style='font-size: 156.27%' href='//martin-thoma.com/tag/video/' title='13 topics'>Video</a>
<a style='font-size: 130.77%' href='//martin-thoma.com/tag/vimeo/' title='9 topics'>Vimeo</a>
<a style='font-size: 138.07%' href='//martin-thoma.com/tag/web-development/' title='10 topics'>Web Development</a>
<a style='font-size: 102.65%' href='//martin-thoma.com/tag/wikipedia/' title='6 topics'>Wikipedia</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/windows-7/' title='5 topics'>Windows 7</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/wolfram-alpha/' title='5 topics'>Wolfram|Alpha</a>
<a style='font-size: 144.69%' href='//martin-thoma.com/tag/youtube/' title='11 topics'>YouTube</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/advertising/' title='5 topics'>advertising</a>
<a style='font-size: 122.60%' href='//martin-thoma.com/tag/algorithms/' title='8 topics'>algorithms</a>
<a style='font-size: 113.34%' href='//martin-thoma.com/tag/analysis/' title='7 topics'>analysis</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/cheat-sheet/' title='5 topics'>cheat sheet</a>
<a style='font-size: 166.20%' href='//martin-thoma.com/tag/funny/' title='15 topics'>funny</a>
<a style='font-size: 166.20%' href='//martin-thoma.com/tag/learning/' title='15 topics'>learning</a>
<a style='font-size: 138.07%' href='//martin-thoma.com/tag/lecture-notes/' title='10 topics'>lecture-notes</a>
<a style='font-size: 253.74%' href='//martin-thoma.com/tag/mathematics/' title='53 topics'>mathematics</a>
<a style='font-size: 189.53%' href='//martin-thoma.com/tag/puzzle/' title='21 topics'>puzzle</a>
</div>
                    </li>
                </ul>
                </div>
            </div>
        </div><!--/container-->
            <footer id="footer">
                <a href="//martin-thoma.com"><strong>Martin Thoma</strong></a> -  A blog about Code, the Web and Cyberculture. <br />
                <div class="footer-credits">
                    <a href="http://flexithemes.com/themes/modern-style/">Modern Style</a> theme by <a href="http://flexithemes.com/">FlexiThemes</a>
                </div>
            </footer><!--/footer-->

    </div><!--/wrapper-->
<!-- type: footer -->
<!-- MathJax -->
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/javascript">
<!--
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [ ['$$', '$$'], ['\\[','\\]']],
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
    processEscapes: true
  }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
// -->
</script>
<!-- TOC Plus -->
<script type='text/javascript'>
/* <![CDATA[ */
var tocplus = {"visibility_show":"show","visibility_hide":"hide","width":"275px"};
/* ]]> */
</script>
<script type='text/javascript' src="//martin-thoma.com/js/tocplus-front.js"></script>

</body>
</html>

