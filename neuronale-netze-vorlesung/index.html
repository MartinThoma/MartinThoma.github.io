<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Martin Thoma" />
        <meta name="copyright" content="Martin Thoma" />
        <link title = "Martin Thoma"
              type  = "application/opensearchdescription+xml"
              rel   = "search"
              href  = "../opensearch.xml">

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Klausur, Machine Learning, Neural Networks, RL, German posts, " />

<meta property="og:title" content="Neuronale Netze - Klausur "/>
<meta property="og:url" content="../neuronale-netze-vorlesung/" />
<meta property="og:description" content="Dieser Artikel beschäftigt sich mit der Vorlesung „Neuronale Netze“ am KIT. Er dient als Prüfungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr. Alexander Waibel im Sommersemester 2015 gehört. Behandelter Stoff Vorlesung Datum Kapitel Inhalt 15.04.2015 Einleitung - 21.04.2015 LVQ and related Techiques k-Means, OLVQ1, kompetitives Lernen …" />
<meta property="og:site_name" content="Martin Thoma" />
<meta property="og:article:author" content="Martin Thoma" />
<meta property="og:article:published_time" content="2015-04-27T21:15:00+02:00" />
<meta name="twitter:title" content="Neuronale Netze - Klausur ">
<meta name="twitter:description" content="Dieser Artikel beschäftigt sich mit der Vorlesung „Neuronale Netze“ am KIT. Er dient als Prüfungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr. Alexander Waibel im Sommersemester 2015 gehört. Behandelter Stoff Vorlesung Datum Kapitel Inhalt 15.04.2015 Einleitung - 21.04.2015 LVQ and related Techiques k-Means, OLVQ1, kompetitives Lernen …">
<meta property="og:image" content="logos/klausur.png" />
<meta name="twitter:image" content="logos/klausur.png" >

        <title>Neuronale Netze - Klausur  · Martin Thoma
</title>
        <!-- Latest compiled and minified CSS -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
        <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.1/css/font-awesome.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="../theme/css/pygments.css" media="screen">
        <link rel="stylesheet" type="text/css" href="../theme/tipuesearch/tipuesearch.css" media="screen">
        <link rel="stylesheet" type="text/css" href="../theme/css/elegant.css" media="screen">
        <link rel="stylesheet" type="text/css" href="../static/custom.css" media="screen">

        <!-- MathJax -->
<script type="text/x-mathjax-config">
<!--
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [ ['$$', '$$'], ['\\[','\\]']],
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
    processEscapes: true
  }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
// -->
</script>
<script type="text/javascript" async
  src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

        <link href="https://martin-thoma.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Martin Thoma - Full Atom Feed" />
        <link href="https://martin-thoma.com/feeds/index.xml" type="application/rss+xml" rel="alternate" title="Martin Thoma - Full RSS Feed" />
    </head>
    <body>
        <div id="content-sans-footer">
        <div class="navbar navbar-static-top navbar-default">
            <div class="container">
                <div class="container-fluid">
                    <div class="collapse navbar-collapse">
                        <ul class="nav pull-left top-menu navbar-nav">
                            <li><a href=".." style="font-family: 'Monaco', 'Inconsolata', 'Andale Mono', 'Lucida Console', 'Bitstream Vera Sans Mono', 'Courier New', Courier, Monospace;
                        font-size: 20px;" class="navbar-brand">Martin Thoma</a>
                            </li>
                        </ul>
                        <ul class="nav pull-right top-menu navbar-nav">
                            <li ><a href="..">Home</a></li>
                            <li ><a href="../categories.html">Categories</a></li>
                            <li ><a href="../tags.html">Tags</a></li>
                            <li ><a href="../archives.html">Archives</a></li>
                            <li><a href="../support-me/">Support me</a></li>
                            <li><form class="navbar-form" action="../search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="search" class="search-query form-control" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row">
                <div class="col-sm-1 col-md-1"></div>
                <div class="col-sm-10 col-md-10">
<article>
<div class="row">
    <header class="page-header col-sm-10 col-md-10 col-md-offset-2">
    <h1><a href="../neuronale-netze-vorlesung/"> Neuronale Netze - Klausur  </a></h1>
    </header>
</div>

<div class="row">
    <div class="col-sm-2 col-md-2 table-of-content">
        <nav>
        <h4>Contents</h4>
        <div id="toc"><ul><li><a class="toc-href" href="#behandelter-stoff" title="Behandelter Stoff">Behandelter Stoff</a><ul><li><a class="toc-href" href="#vorlesung" title="Vorlesung">Vorlesung</a></li><li><a class="toc-href" href="#nn01-intropdf" title=" NN01-Intro.pdf"> NN01-Intro.pdf</a></li><li><a class="toc-href" href="#nn02-classificationpdf" title="NN02-Classification.pdf">NN02-Classification.pdf</a></li><li><a class="toc-href" href="#v03-lvq" title="V03: LVQ">V03: LVQ</a></li><li><a class="toc-href" href="#v04-perceptron" title="V04: Perceptron">V04: Perceptron</a></li><li><a class="toc-href" href="#v05-features" title="V05: Features">V05: Features</a></li><li><a class="toc-href" href="#v06-backpropagation" title="V06: Backpropagation">V06: Backpropagation</a></li><li><a class="toc-href" href="#v07-feature-learning" title="V07: Feature Learning">V07: Feature Learning</a></li><li><a class="toc-href" href="#v08-deep-learning" title="V08: Deep Learning">V08: Deep Learning</a></li><li><a class="toc-href" href="#v09-reinforcement-learning" title="V09: Reinforcement Learning">V09: Reinforcement Learning</a></li><li><a class="toc-href" href="#v10-som" title="V10: SOM">V10: SOM</a></li><li><a class="toc-href" href="#v11-rbms" title=" V11: RBMs"> V11: RBMs</a></li><li><a class="toc-href" href="#v12-rnns" title="V12: RNNs">V12: RNNs</a></li><li><a class="toc-href" href="#v13-nn-learning-tricks" title="V13: NN learning tricks">V13: NN learning tricks</a></li><li><a class="toc-href" href="#v14-dnn-cv" title="V14: DNN CV">V14: DNN CV</a></li><li><a class="toc-href" href="#v15-speech-independence" title="V15: Speech-Independence">V15: Speech-Independence</a></li></ul></li><li><a class="toc-href" href="#visualisierung-von-netzen_1" title="Visualisierung von Netzen">Visualisierung von Netzen</a></li><li><a class="toc-href" href="#interpretation-of-errors" title="Interpretation of errors">Interpretation of errors</a></li><li><a class="toc-href" href="#aktivierungsfunktionen" title=" Aktivierungsfunktionen"> Aktivierungsfunktionen</a></li><li><a class="toc-href" href="#topology-learning" title=" Topology Learning"> Topology Learning</a></li><li><a class="toc-href" href="#einordnung" title=" Einordnung"> Einordnung</a></li><li><a class="toc-href" href="#learning-rate-scheduling" title=" Learning Rate Scheduling"> Learning Rate Scheduling</a></li><li><a class="toc-href" href="#prufungsfragen" title="Pr&uuml;fungsfragen">Pr&uuml;fungsfragen</a></li><li><a class="toc-href" href="#material-und-links" title="Material und Links">Material und Links</a></li><li><a class="toc-href" href="#literatur" title="Literatur">Literatur</a></li><li><a class="toc-href" href="#vorlesungsempfehlungen" title="Vorlesungsempfehlungen">Vorlesungsempfehlungen</a></li><li><a class="toc-href" href="#ubungsbetrieb" title="&Uuml;bungsbetrieb">&Uuml;bungsbetrieb</a></li><li><a class="toc-href" href="#termine-und-klausurablauf" title="Termine und Klausurablauf">Termine und Klausurablauf</a></li></ul></div>
        </nav>
    </div>
    <div class="col-sm-8 col-md-8 article-content" id="contentAfterTitle">

            
            <div class="info">Dieser Artikel besch&auml;ftigt sich mit der Vorlesung &bdquo;Neuronale Netze&ldquo; am KIT. Er dient als Pr&uuml;fungsvorbereitung. Ich habe die Vorlesungen bei <a href="http://isl.anthropomatik.kit.edu/english/21_74.php">Herrn Prof. Dr. Alexander Waibel</a> im Sommersemester 2015 geh&ouml;rt.</div>
<h2 id="behandelter-stoff">Behandelter Stoff</h2>
<h3 id="vorlesung">Vorlesung</h3>
<table>
<tr>
<th>Datum</th>
<th>Kapitel</th>
<th>Inhalt</th>
</tr>
<tr>
<td>15.04.2015</td>
<td><a href="#intro">Einleitung</a></td>
<td>-</td>
</tr>
<tr>
<td>21.04.2015</td>
<td>LVQ and related Techiques</td>
<td>k-Means, OLVQ1, kompetitives Lernen, Mode Seeker, PCA</td>
</tr>
<tr>
<td>22.04.2015</td>
<td>-</td>
<td>&Uuml;bung</td>
</tr>
<tr>
<td>28.04.2015</td>
<td>Perceptron</td>
<td>-</td>
</tr>
<tr>
<td>12.05.2015</td>
<td>Auto-Encoder</td>
<td>Denoising- und Sparse Autoencoder, Bottleneck-Features, <a href="https://de.wikipedia.org/wiki/Kullback-Leibler-Divergenz">Kullback-Leibler-Divergenz</a>; <a href="https://de.wikipedia.org/wiki/Kettenregel#Mathematische_Formulierung">Kettenregel</a></td>
</tr>
<tr>
<td>13.05.2015</td>
<td>Deep Learning</td>
<td>Momentum, Rprop, Newbob, L1/L2-Regularisierung ($|w|$, $w^2$), weight decay</td>
</tr>
<tr>
<td>19.05.2015</td>
<td>&Uuml;bung</td>
<td>-</td>
</tr>
<tr>
<td>20.05.2015</td>
<td>&Uuml;bung</td>
<td>-</td>
</tr>
<tr>
<td>26.05.2015</td>
<td><abbr title="Self Organizing Map">SOM</abbr></td>
<td>Hebbian Learning, "<abbr title="Vector Quantization">VQ</abbr>" mit SOM</td>
</tr>
<tr>
<td>09.06.2015</td>
<td>Effizientes Lernen</td>
<td>Paralleles Lernen; Quickprop; Alternative Fehlerfunktion (cross entropy, <abbr title="Classification Figure of Merit">CFM</abbr>);
        weight elimination / regularization</td>
</tr>
<tr>
<td>15.07.2015</td>
<td>Summary</td>
<td>When to use which objective function (cross entropy, MSE); Backpropagation; Weight initialization; Regularization (L2 weight decay, dropout); Time Delay NN; Recurrent Networks; Applications (Speech Recognition, Computer Vision)</td>
</tr>
</table>
<h3 id="nn01-intropdf"><a name="intro"></a> NN01-Intro.pdf</h3>
<ul>
<li>Human Brain vs. Computer (Processing/Processors, Accuracy, Speed, Hardware, Design)</li>
<li>Aufbau eines biologischen Neurons (vgl. <a href="https://de.wikipedia.org/wiki/Nervenzelle#.C3.9Cberblick_.C3.BCber_den_Aufbau_einer_Nervenzelle">Wikipedia</a>)</li>
</ul>
<h3 id="nn02-classificationpdf">NN02-Classification.pdf</h3>
<figure class="aligncenter">
<a href="../images/2015/12/perceptron-or.png"><img alt="Rosenblatt-Perceptron which realizes logical or" class="" src="../images/2015/12/perceptron-or.png" style="max-width:500px;"/></a>
<figcaption class="text-center">Rosenblatt-Perceptron which realizes logical or</figcaption>
</figure>
<ul>
<li>McCulloch-Pitts Neuron (weights, bias, activation function is step function)</li>
<li>Rosenblatt Perceptron Algorithmus</li>
<li>Backpropagation</li>
<li>Curse of Dimensionality</li>
<li><a href="https://de.wikipedia.org/wiki/Kerndichtesch%C3%A4tzer">Parzen Window</a></li>
<li>Features: Nominal, Ordinal, Intervallskaliert, Verh&auml;ltnisskaliert</li>
</ul>
<dl>
<dt><a href="https://en.wikipedia.org/wiki/Bayes%27_rule"><dfn>Bayes-Rule</dfn></a></dt>
<dd>Given events $A_1$, $A_2$ and $B$, Bayes' rule states that the conditional odds of $A_1:A_2$ given $B$ are equal to the marginal odds of $A_1:A_2$ multiplied by the Bayes factor or likelihood ratio $\Lambda$:

$$O(A_1:A_2|B) = \Lambda(A_1:A_2|B) \cdot O(A_1:A_2) ,$$

where

$$\Lambda(A_1:A_2|B) = \frac{P(B|A_1)}{P(B|A_2)}.$$</dd>
<dt><dfn>Parametrischer Klassifizierer</dfn></dt>
<dd>Ein Klassifizierer hei&szlig;t <i>parametrisch</i>, wenn er eine Wahrscheinlichkeitsverteilungsannahme macht.</dd>
<dt><dfn>Naiver Bayes-Klassifikator</dfn></dt>
<dd>Ein Klassifizierer hei&szlig;t naiver Bayes-Klassifikator, wenn er den
      Satz von Bayes unter der naiven Annahme der Unabh&auml;ngigkeit der Features
      benutzt.</dd>
<dt><dfn>Normalverteilung</dfn></dt>
<dd>Eine stetige Zufallsvariable $X$ mit der Wahrscheinlichkeitsdichte
      $f\colon\mathbb{R}\to\mathbb{R}$, gegeben durch<br/>
      $f(x) = \frac {1}{\sigma\sqrt{2\pi}} e^{-\frac {1}{2} \left(\frac{x-\mu}{\sigma}\right)^2}$<br/>
      hei&szlig;t $\mathcal N\left(\mu, \sigma^2\right)$-verteilt, normalverteilt
      mit den Erwartungswert $\mu$ und Varianz $\sigma^2$.</dd>
<dt><a href="https://de.wikipedia.org/wiki/Mehrdimensionale_Normalverteilung"><dfn>Multivariate Normalverteilung</dfn></a></dt>
<dd>Eine $p$-dimensionale reelle Zufallsvariable $X$ ist normalverteilt
      mit Erwartungswertvektor $\mu$ und  (positiv definiter) Kovarianzmatrix
      $\Sigma$, wenn sie eine Dichtefunktion der Form
      $$f_X(x)=\frac{1}{ \sqrt{(2\pi)^p \det(\Sigma)} } \exp \left( -\frac{1}{2}(x-\mu)^{T}\Sigma^{-1}(x-\mu) \right)$$
besitzt. Man schreibt
$$X\sim \mathcal N_p(\mu, \Sigma).$$</dd>
<dt><dfn>Gau&szlig;'scher Klassifizierer</dfn></dt>
<dd>Ein (naiver) Bayes-Klassifikator, welcher von normalverteilten Daten
      ausgeht hei&szlig;t <i>Gau&szlig;'scher Klassifizierer</i>.</dd>
<dt><a href="https://en.wikipedia.org/wiki/Principal_component_analysis" name="pca"><dfn>Principal Component Analysis</dfn></a> (<dfn>PCA</dfn>, <dfn>Hauptkomponentenanalyse</dfn>)</dt>
<dd>Die Hauptkomponentenanalyse ist ein Verfahren zur
      Dimensionalit&auml;tsreduktion von ungelabelten Daten im $\mathbb{R}^n$.
      Sie projeziert die Daten auf diejenige Hyperebene im
      $\mathbb{R}^d$, die den durch die Projektion stattfindenden
      Datenverlust minimal h&auml;lt.
      Dabei ist $d \in 1, \dots, n$ beliebig w&auml;hlbar.

      Die Transformation der Daten $X$ findet durch eine Matrixmultiplikation
      $Y = P \cdot X$ statt. Die Matrix $P$ besteht aus den ersten $d$
      Eigenvektoren der Kovarianzmatrix der Features $X$:

      $P = (v_1, \dots, v_d)$ mit
      $\lambda_j v_j = C_X v_j$ f&uuml;r $j=1,\dots,d$

      Au&szlig;erdem gilt: $C_X = \frac{1}{n-1} X X^T$ </dd>
</dl>
<h3 id="v03-lvq">V03: LVQ</h3>
<p>Slide name: <code>V03_2015-04-21_LVQ.pdf</code></p>
<ul>
<li>k-Means</li>
<li>Fuzzy k-Means</li>
<li>Vector Quantization (VQ) is an unsupervised clustering algorithm</li>
<li>Learning Vector Quantization is supervised.</li>
</ul>
<h3 id="v04-perceptron">V04: Perceptron</h3>
<p>Slide name: <code>V04_2015-04-28_Perceptron.pdf</code></p>
<dl>
<dt><dfn>McCulloch&ndash;Pitts (MCP) Neuron</dfn></dt>
<dd>Ein MLP-Neuron is ein Algorithmus zur bin&auml;ren Klassifizierung. Er hat
      $m+1$, mit $m \in \mathbb{N}_{&gt; 0}$ inputs $x_i \in \{0, 1\}$. Davon
      ist der erste (nullte) Konstant gleich Eins und wird <i>Bias</i> genannt.
      Jeder Input wird mit eingem Gewicht $w_i \in \mathbb{R}$ multipliziert,
      alle gewichteten Inputs werden addiert und schlie&szlig;lich wird die
      Stufenfunktion
      $\varphi(x) = \begin{cases}1 &amp;\text{falls } x &gt; 0\\0 &amp;\text{sonst} \end{cases}$
      angewendet.

      Man lernt mit MCP Neuronen, indem man
      $$\Delta w = \eta \delta x$$
      $$w \gets w + \Delta w$$
      berechnet, wobei $\eta \in (0, 1)$ die Lernrate ist, $x$ ein Trainingsdatum
      und $\delta = y_{\text{target}} - y$ die Abweichung vom gew&uuml;nschten
      Ergebnis ist. Diese Regel wird auch Perceptron Learning Rule genannt.
  </dd>
<dt><dfn>Rosenblatt-Perzeptron</dfn></dt>
<dd>Wie das McCulloch&ndash;Pitts (MCP) Neuron, nur ist $x_i \in \mathbb{R}$ und
      ein Lernalgorithmus ist gegeben. Dieser addiert den
      $\eta \in (0, 1)$ gewichteten, fehlklassifizierten Vektor auf die
      Gewichte $w_i$. $\eta$ hei&szlig;t die <i>Lernrate</i>.

      Man lernt mit MCP Neuronen, indem man
      $$\Delta w = \eta \delta x$$
      $$w \gets w + \Delta w$$
      berechnet, wobei $\eta \in (0, 1)$ die Lernrate ist, $x$ ein Trainingsdatum
      und $\delta = - \frac{\partial E}{\partial w}$ der Gradient auf der
      Fehleroberfl&auml;che in Abh&auml;ngigkeit von den Gewichten ist. Es wird also
      Gradient descent verwendet.
  </dd>
<dt><dfn>Pocket Perceptron Algorithm</dfn></dt>
<dd>Ein Lernalgorithmus f&uuml;r ein Rosenblatt-Perzeptron. Dieser konvergiert zu
      Gewichten, welche die wenigsten Beispiele falsch klassifiziert.
  </dd>
<dt><dfn>Sigmoid-Funktion</dfn></dt>
<dd>$\varphi(x) = \frac{1}{1+e^{-x}}$</dd>
<dt><dfn>Softmax-Funktion</dfn></dt>
<dd>$\varphi(a_i) = \frac{e^{a_i}}{\sum_{k} e^{a_k}}$ wobei $a_i$ die
      Aktivierung des $i$-ten Neurons der selben Schicht ist.</dd>
<dt><dfn>Perzeptron</dfn> / <dfn>Logistic Neuron</dfn></dt>
<dd><abbr title="Mean Squared Error">MSE</abbr> + Sigmoid activation function</dd>
</dl>
<p>Fakten:</p>
<ul>
<li>Das Rosenblatt-Perzeptron findet eine lineare Trenngrenze, wenn sie
  existiert.</li>
<li>Probleme vom Rosenblatt-Perzeptron:</li>
<li>Nicht-linear trennbare Daten wie z.B. das XOR-Problem</li>
<li>Nicht-trennbare Daten</li>
<li>Wahl der Lernrate und der Startgewichte</li>
<li>Aufbau eines biologischen Neurons (Axon, Dendriten, Zellk&ouml;rper, Ranviersche
  Schn&uuml;rringe, Synapsen)</li>
<li>Glia-Zellen</li>
</ul>
<h3 id="v05-features">V05: Features</h3>
<p>Slide name: <code>V05_2015-04-29_Features.pdf</code></p>
<dl>
<dt><dfn>Rectified Linear Unit</dfn> (<dfn>ReLU</dfn>)</dt>
<dd>$\varphi(x) = \max(0, x)$</dd>
<dt><dfn>Leaky ReLU</dfn></dt>
<dd>$\varphi(x) = \max(0.01x, x)$</dd>
<dt><dfn>Softplus</dfn></dt>
<dd>$\varphi(x) = \log(1 + e^x)$</dd>
<dt><dfn>Feed Forward Neural Network</dfn></dt>
<dd>A Feed Forward Neural Network is a learning algorithm which takes
      a fixed-size input feature vector, applies varous matrix multiplications
      and point-wise non-linear functions to obtain a fixed-size output
      vector.</dd>
<dt><dfn>Multilayer Perceptron</dfn></dt>
<dd>A Multilayer Perceptron is a special type of Feed Forward Neural Network.
      It consists of fully connected layers only.

      <figure class="wp-caption aligncenter">
<img alt="Draft of a multilayer Perceptron (MLP)." src="//martin-thoma.com/images/2016/02/feed-forward-perceptron.png"/>
<figcaption>Figure 1: Draft of multilayer Perceptron (MLP). The bias units are
                   grey, the input units are red, the hidden units are green
                   and the output unit is blue. The edges are directed from
                   input, to hidden, to output and from the bias to hidden / output.</figcaption>
</figure>
</dd>
<dt><a href="https://de.wikipedia.org/wiki/Metrischer_Raum#Formale_Definition"><dfn>Metrik</dfn></a></dt>
<dd>Sei $X$ eine Menge und $d:X \times X \rightarrow \mathbb{R}$ eine
      Abbildung. $d$ hei&szlig;t Metrik auf $X$, wenn gilt:
      <ul>
<li>$d(x, y) = 0 \geq x=y \;\;\; \forall x, y \in X$</li>
<li>$d(x,y)=d(y,x)$</li>
<li>$d(x,y) \leq d(x,z) + d(z,y)$</li>
</ul>
</dd>
<dt><a href="https://de.wikipedia.org/wiki/Jaccard-Koeffizient#Jaccard-Metrik"><dfn>Jaccard-Metrik</dfn></a></dt>
<dd>Es seien $A, B$ Mengen und $J(A, B) := \frac{|A \cup B| - |A \cap B|}{|A \cup B|}$.
      Dann hei&szlig;t $J$ die Jaccard-Metrik.
  </dd>
<dt><a href="https://de.wikipedia.org/wiki/Levenshtein-Distanz"><dfn>Levenshtein-Distanz</dfn></a></dt>
<dd>Es seien $a, b$ Zeichenketten, $|a|$ die L&auml;nge der Zeichenkette $a$
      und $\delta_{a_i \neq b_j}$ genau dann 1, wenn das $i$-te Zeichen von
      $a$ und das $j$-te Zeichen von $b$ sich unterscheiden.

      Dann hei&szlig;t $d_L(a, b)$ die Levenshtein-Distanz:
      $$d_L(a,b) := lev_{a,b}(|a|, |b|)$$
      $$\text{lev}_{a,b}(i, j) = \begin{cases}\max(i,j) &amp;\text{falls} \min(i,j) = 0,\\
        \min \begin{cases}\text{lev}_{a,b}(i-1,j)+1\\
                          \text{lev}_{a,b}(i,j-1)+1\\
                          \text{lev}_{a,b}(i-1,j-1)+\delta_{(a_i \neq b_j)}\\\end{cases} &amp;\text{sonst}\end{cases}$$
  </dd>
</dl>
<p>Fragen:</p>
<ul>
<li>Welche Feed Forward Neuronalen Netze existieren, die keine Multilayer
  Perceptronen sind?<br/>
  &rarr; CNNs, TDNNs, SOMs.</li>
<li>Welche Skalentypen gibt es f&uuml;r Merkmale (Features)?<ul>
<li>Nominale Merkmale: Nur Gleichheit kann &uuml;berpr&uuml;ft werden</li>
<li>Ordinale Merkmale: Es existiert eine "kleiner gleich"-Relation</li>
<li>Intervallskalierte Merkmale:<ul>
<li>Die Differenz der Merkmale hat eine Semantik</li>
<li>Es existiert jedoch kein "wirklicher" Nullpunkt</li>
</ul>
</li>
<li>Verh&auml;ltnisskalierte Merkmale: Wie Intervallskaliert, aber mit absolutem
  Nullpunkt.</li>
</ul>
</li>
</ul>
<h3 id="v06-backpropagation">V06: Backpropagation</h3>
<p>Slide name: <code>V06_2015-05-05_Backpropagation.pdf</code></p>
<dl>
<dt><a href="https://de.wikipedia.org/wiki/Kreuzentropie"><dfn>Kreuzentropie Fehlerfunktion</dfn></a>
        (<dfn>Cross-Entropy</dfn>)</dt>
<dd>$$E_{-x} = - \sum_{k}[t_k^x \log(o_k^x) + (1-t_k^x) \log (1- o_k^x)]$$
        wobei $x$ der Feature-Vektor ist, $k$ ein Neuron des letzen
        Layers, $t$ der wahre Wert (d.h. der gew&uuml;nschte Output),
        $o$ der tats&auml;chliche Output ist.</dd>
</dl>
<ul>
<li>Stochastic Gradient Descent</li>
<li>Batch Gradient Descent</li>
</ul>
<h3 id="v07-feature-learning">V07: Feature Learning</h3>
<p>Slide name: <code>V07_12-05-2015_Feature_Learning.pdf</code></p>
<dl>
<dt><a href="https://en.wikipedia.org/wiki/Autoencoder"><dfn>Autoencoder</dfn></a></dt>
<dd>Ein Autoencoder ist ein neuronales Netz, welches darauf trainiert wird
        die Input-Daten am Output wieder zu replizieren.</dd>
<dt><dfn>Bottleneck Features</dfn></dt>
<dd>Unter Bottleneck-Features versteht man eine Schicht in einem
        neuronalem Netz, welche wesentlich kleiner ist als die vorhergehende
        und nachfolgende Schicht.</dd>
<dt><a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence"><dfn>Kullback-Leibler-Divergenz</dfn></a></dt>
<dd>Die Kullback-Leibler-Divergenz ist ein Ma&szlig; f&uuml;r die Unterschiedlichkeit
        zweier Wahrscheinlichkeitsverteilungen $P, Q$. F&uuml;r
        diskrete Verteilungen ist sie definiert als:
        $$KL(P||Q) := \sum_{x \in X} P(x) \cdot \log \frac{P(x)}{Q(x)}$$</dd>
<dt><dfn>Denoising Autoencoder</dfn></dt>
<dd>Ein Autoencoder, welcher trainiert wird rauschen zu entfernen.</dd>
</dl>
<p>Fakten:</p>
<ul>
<li>Eine lineare Aktivierungsfunktion wird in einer Repr&auml;sentation im
  Bottleneck-Feature resultieren, die PCA &auml;hnelt.</li>
<li>Fehlerfunktion:</li>
<li><abbr title="Cross Entropy">CE</abbr> bei bin&auml;ren Ausgaben (d.h. Input-Features)</li>
<li><abbr title="Mean squared error">MSE</abbr> bei reelen Ausgaben (d.h. Input-Features)</li>
</ul>
<p>Fragen:</p>
<ul>
<li>Wie muss man die Grafik zu Stacked Denoising Autoencodern verstehen?</li>
</ul>
<h3 id="v08-deep-learning">V08: Deep Learning</h3>
<p>Slide name: <code>V08_2015-05-13_Deep_Learning.pdf</code></p>
<dl>
<dt><dfn>Deep Neural Networks</dfn></dt>
<dd>Neural Networks with at least two hidden layers with nonlinear
        activation functions.</dd>
<dt><dfn>Hyperparameter</dfn></dt>
<dd>Hyperparameter $\theta$ eines neuronalen Netzes sind Parameter,
        welche nicht gelernt werden.</dd>
<dt><a id="scheduling"></a><dfn>Learning Rate Scheduling</dfn></dt>
<dd>Start with a learning rate $\eta$ and reduce it while training.</dd>
<dt><dfn id="exponential-decay-lr">Exponential Decay Learning Rate</dfn></dt>
<dd>$\eta_t = \eta_{t-1} \cdot \alpha = \eta_0 \cdot \alpha^t$ mit $\alpha \in (0, 1)$</dd>
<dt><dfn id="performance-scheduling">Performance Scheduling</dfn></dt>
<dd>Measure the error on the cross validation set and decrease the learning
        rate when the algorithm stops improving.</dd>
<dt><a href="https://en.wikipedia.org/wiki/Rprop"><dfn id="rprop">RProp</dfn></a></dt>
<dd>RProp is a learning rate scheduling method which is only based on the
        sign of the gradient. It increases the learning rate when the sign of
        the gradient doesn't change and decreases or resets it when the sign of the
        gradient changes. Rprop has an own learning rate for every single
        feature.</dd>
<dt><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#AdaGrad"><dfn id="adagrad"><abbr title="adaptive gradient">AdaGrad</abbr></dfn></a> (vgl. Folie 34)</dt>
<dd>$$\eta_{tij} = \frac{\eta_0}{\sqrt{1 + \sum_k {(\frac{\partial E^{t-k}}{\partial w_{ij}})}^2}}$$

    where $\eta_0$ is an initial learning rate, $t$ is the epoch, $i,j$ refer to neurons.</dd>
<dt><dfn id="newbob">Newbob Scheduling</dfn></dt>
<dd>Newbob scheduling is a combination of exponential decay learning rate
        scheduling and performance scheduling. It starts with a learning rate
        $\eta_0$. When the validation error stops decreasing, switch to
        exponentially decaying learning rate. Terminate when the validation
        error stops decreasing again.</dd>
<dt><a name="dfn-cross-entropy"></a><dfn>Cross Entropy Error function</dfn> (CE)</dt>
<dd>$$E_{CE}(w) = - \sum_{x \in X} \sum_{k} [t_k^x \log(o_k^x) + (1-t_k^x) \log(1-o_k^x)]$$
        where $w$ is the weight vector, $X$ is the set of training
        examples (feature vectors),
        $t_k^x = \begin{cases}1 &amp;\text{if } x \text{ is of class }k\\0&amp;\text{otherwise}\end{cases}$
        and $o_k^x$ is the output at neuron $k$ of the network for the
        feature vector $x$.</dd>
<dt><dfn>Mean Squared Error function</dfn> (MSE)</dt>
<dd>$$E_{MSE}(w) = \frac{1}{2}\sum_{x \in X} \sum_{k} (t_k^x - o_k^x)^2$$
        where $w$ is the weight vector, $X$ is the set of training
        examples (feature vectors), $k$ is the range of output neurons,
        $t_k^x = \begin{cases}1 &amp;\text{if } x \text{ is of class }k\\0&amp;\text{otherwise}\end{cases}$ and $o_k^x$ is the output
        at neuron $k$ of the network for the feature vector $x$.</dd>
<dt><dfn>Convolutional Neural Networks</dfn> (<dfn>CNNs</dfn>)</dt>
<dd>Feed-Forward Neuronale Netze, welche durch geteilte Gewichte (weight
        sharing) grafische Filter lernen. CNNs sind aktuell in der Computer
        Vission Stand der Technik.</dd>
<dt><dfn>Time-Delay Neural Networks</dfn> (<dfn>TDNNs</dfn>)</dt>
<dd>TDNNs wenden wie CNNs weight sharing an um Filter zu lernen. Sie
        werden in der <abbr title="Automatic Speech Recognition">ASR</abbr>
        verwendet und lernen auch Filter. Allerdings wird hier &uuml;ber die Zeit
        hinweg gefaltet.</dd>
<dt><dfn>Multi-State Time-Delay Neural Networks</dfn> (<dfn>MS-TDNNs</dfn>, siehe [<a href="#ref-haf92" name="ref-haf92-anchor">Haf92</a>])</dt>
<dd>MS-TDNNs codieren die alignment-Suche im Netzwerk. Sie sind
        hybride Netze (so wie HMM-DeepNN Hybrids von Mircosoft).</dd>
</dl>
<figure class="aligncenter">
<a href="../images/2016/02/visualizing-opt-algorithms-rprop-gradient-descent-momentum.png"><img alt="RProp by Ryan Harris" class="" src="../images/2016/02/visualizing-opt-algorithms-rprop-gradient-descent-momentum.png" style="max-width:500px;"/></a>
<figcaption class="text-center">RProp by Ryan Harris (<a href="https://www.youtube.com/watch?v=Cy2g9_hR-5Y">source</a>). Rot ist der Gradientenabstieg, blau ist mit momentum, rosa ist RProp</figcaption>
</figure>
<ul>
<li>Pretraining</li>
<li>Design choices (hyperparameters):<ul>
<li>Topology (Width of layers, number of layers)</li>
<li>Activation functions</li>
<li>Error function</li>
<li>Mini-Batch size</li>
<li>Training function</li>
<li>Preprocessing</li>
<li>Initial Weights</li>
</ul>
</li>
<li>MSE vs <a href="#dfn-cross-entropy"><abbr title="Cross Entropy">CE</abbr></a>:<ul>
<li>MSE penetalizes large differences much more than small ones</li>
<li>MSE works well for function approximation</li>
<li>CE works well on classification tasks</li>
</ul>
</li>
</ul>
<h3 id="v09-reinforcement-learning">V09: Reinforcement Learning</h3>
<p>Slide name: <code>V09_2015-05-26-Reinforcement-Learning.pdf</code></p>
<dl>
<dt><dfn>Markov Decision Process</dfn> (<dfn>MDP</dfn>)</dt>
<dd>Siehe <a href="../machine-learning-1-course/#mdp">ML 1</a>.</dd>
<dt><dfn>Diskontierungsfaktor</dfn></dt>
<dd>Siehe <a href="../probabilistische-planung#discount-factor">Probabilistische Planung</a>.</dd>
<dt><dfn>Strategie</dfn> (engl. <dfn>Policy</dfn>)</dt>
<dd>Siehe <a href="../probabilistische-planung#policy">Probabilistische Planung</a>.</dd>
<dt><dfn>Q-Funktion</dfn> (Action-Value function)</dt>
<dd>Siehe <a href="../probabilistische-planung/#q-function">Probabilistische Planung</a>.</dd>
<dt><dfn>V-Funktion</dfn> (State-Value function)</dt>
<dd>Siehe <a href="../machine-learning-1-course/#v-function">ML 1</a>.</dd>
<dt><dfn>$\varepsilon$-Greedy Strategy</dfn></dt>
<dd>Siehe <a href="../probabilistische-planung#epsilon-greedy-exploration">Probabilistische Planung</a>.</dd>
<dt><dfn>$\varepsilon$-decreasing Strategy</dfn></dt>
<dd>Siehe <a href="../probabilistische-planung#epsilon-decreasing-strategy">Probabilistische Planung</a>.</dd>
<dt><dfn>$\varepsilon$-first Strategy</dfn></dt>
<dd>Siehe <a href="../probabilistische-planung#epsilon-first-strategy">Probabilistische Planung</a>.</dd>
<dt><dfn>Adaptive $\varepsilon$-greedy Strategy</dfn></dt>
<dd>Siehe <a href="../probabilistische-planung#adaptive-epsilon-greedy-strategy">Probabilistische Planung</a>.</dd>
<dt><dfn>Episode</dfn></dt>
<dd>Siehe <a href="../probabilistische-planung#episode">Probabilistische Planung</a>.</dd>
<dt><dfn>Monte Carlo Policy Evaluation</dfn></dt>
<dd>Initialize state values $V^\pi$ and iterate:
        <ol>
<li>Generate an episode</li>
<li>foreach state $s$ in episode:
            <ol>
<li>Get the reward $\hat{R}$ from that state on</li>
<li>$\hat{R} = \sum_{j=0}^\infty \gamma^j r_j$</li>
<li>$V_{k+1}^\pi (s) \leftarrow V_k^pi (s) (1-\alpha)+\alpha \hat{R}$</li>
</ol>
</li>
</ol>
        where $\alpha$ is the learning rate.
    </dd>
<dt><dfn>Temporal Difference Learning</dfn> (<dfn>TD-Learning</dfn>)</dt>
<dd>Siehe <a href="../machine-learning-1-course/#td-learning">ML1</a></dd>
<dt><dfn>Q-Learning</dfn></dt>
<dd>Siehe <a href="../probabilistische-planung/#q-learning">Probabilistische Planung</a>.</dd>
<dt><dfn>SARSA</dfn></dt>
<dd>Siehe <a href="../probabilistische-planung/#sarsa">Probabilistische Planung</a>.</dd>
<dt><dfn>Strategie-Iteration</dfn> (<dfn>Policy iteration</dfn>)</dt>
<dd>Siehe <a href="../probabilistische-planung/#policy-iteration">Probabilistische Planung</a>.</dd>
</dl>
<p>Konvention:</p>
<ul>
<li>Eine optimale Strategie wird mit <span markdown="0"><span class="math">\(\pi^*\)</span></span> bezeichnet.</li>
</ul>
<p>Fragen:</p>
<ul>
<li>Was bedeutet es, wenn in einem MDP der Diskontierungsfaktor
  <span markdown="0"><span class="math">\(\gamma = 0\)</span></span>
  ist?<br/>
  &rarr; Nur der aktuelle Reward ist wichtig. Effektiv nimmt der Agent immer
  das n&auml;chste Feld, welche den h&ouml;chsten Reward bietet (bzw. die Aktion, die
  den gr&ouml;&szlig;ten 1-Aktion Erwartungswert liefert).</li>
<li>Was bedeutet es, wenn in einem MDP der Diskontierungsfaktor
  <span markdown="0"><span class="math">\(\gamma = 1\)</span></span>
  ist?<br/>
  &rarr; Der Agent versucht die Summe der Belohnungen insgesamt zu maximieren.</li>
</ul>
<p>Siehe auch:</p>
<ul>
<li><a href="http://www.nervanasys.com/demystifying-deep-reinforcement-learning/">Demystifying Deep Reinforcement Learning</a></li>
</ul>
<h3 id="v10-som">V10: SOM</h3>
<p>Slide name: <code>V10_2015-05-26_SOM.pdf</code></p>
<dl>
<dt><dfn>Hebbsche Lernregel</dfn></dt>
<dd>what fires together, wires together</dd>
<dt><a href="https://de.wikipedia.org/wiki/Selbstorganisierende_Karte"><dfn>Selbstorganisierende Karten</dfn></a> (<dfn>SOM</dfn>, <dfn>Kohonennetze</dfn>)</dt>
<dd>SOMs sind eine Art von Neuronalen Netzen. Die neuronen von SOMs sind
    auf einem Gitter angeordnet. Es gibt nur zwei Schichten: Die Input-Neuronen
    und die Neuronen auf dem Gitter. Jedes Input-Neuron ist mit jedem Neuron
    auf dem Gitter verbunden.

    <figure class="wp-caption aligncenter">
<img alt="Draft of a self-organizing map (SOM)." src="//martin-thoma.com/images/2016/02/self-organizing-map.png"/>
<figcaption>Figure 2: Draft of self-organizing map (SOM).</figcaption>
</figure>

    Training:
    <ol>
<li><b>Initialisierung</b>: Die Gewichte
            <span markdown="0">$w_{ji}$</span> von dem
            <span markdown="0">$i$</span>-ten Input-Neuron zum Neuron (<span markdown="0">$i = 1, ..., n$</span>)
            <span markdown="0">$j$</span> auf dem Gitter werden zuf&auml;llig
            initialisiert.</li>
<li><b>Sampling</b>: Nehme ein zuf&auml;lliges Beispiel
            <span markdown="0">$x$</span> der Trainingsdaten.</li>
<li><b>Matching</b>: Finde das Neuron
            <span markdown="0">$j_{\text{min}}$</span>, f&uuml;r das die Gewichte
            dem Input am &auml;hnlichsten sind:
            <div>$$j_{\text{min}} = \text{arg min}_j \sum_{i=1}^n (x_i - w_{ji})^2$$</div></li>
<li><b>Update</b>: Passe die Gewichte des gewinnenden Neurons $i$ sowie der Nachbarschaft $j$ an: $w_j = w_j + \eta h(j, i(x))(x - w)$</li>
<li><b>Repeat</b>: Und zur&uuml;ck zu Schritt 2.</li>
</ol>

    Siehe auch:

    <ul>
<li>Uwe Schneider: <a href="http://www2.htw-dresden.de/~iwe/Belege/Schneider/som.html">Self Organizing Map - ein Demonstrationsbeispiel</a>, 2001.</li>
<li><a href="https://codesachin.wordpress.com/2015/11/28/self-organizing-maps-with-googles-tensorflow/">Self-Organizing Maps with Google&rsquo;s TensorFlow</a></li>
<li>J. A. Bullinaria: <a href="http://www.cs.bham.ac.uk/~jxb/NN/l16.pdf">Self Organizing Maps: Fundamentals</a>, 2004.</li>
<li><a href="http://www.ai-junkie.com/ann/som/som1.html">Kohonen's Self Organizing Feature Maps</a> by ai-junkie</li>
</ul>
</dd>
</dl>
<h3 id="v11-rbms"><a name="rbm"></a> V11: RBMs</h3>
<p>Slide name: <code>V11_2015-05-27_RBMs</code></p>
<dl>
<dt><a href="https://de.wikipedia.org/wiki/Hopfield-Netz"><dfn id="hopfield-network">Hopfield-Netz</dfn></a> (siehe [<a href="#ref-hop82" name="ref-hop82-anchor">Hop82</a>], [<a href="#ref-kri05" name="ref-kri05-anchor">Kri05</a>])</dt>
<dd>Ein Hopfield-Netz besteht nur aus einer Schicht von McCulloch-Pitts
        Neuronen. Jedes Neuron ist mit jedem anderen Neuron (also nicht sich
        selbst) und allen Inputs verbunden. Die Schicht funktioniert
        gleichzeitig als Ein- und Ausgabeschicht.

        Hopfield-Netze werden in einem einzigen durchgang Trainiert. Dabei wird
        auf das Gewicht von Neuron $i$ zu Neuron $j$ + 1 addiert, wenn
        das Bit $i$ des Trainingsmusters gleich ist. Falls das nicht der Fall
        ist, wird von dem Gewicht 1 subtrahiert:

        $$w_{ij} = \sum_{p} (2 a^{(i)}_p - 1) \cdot (2 a^{(j)}_p - 1)$$

        Jedes Gewicht ist zum start des Trainings 0. Das Training ist also
        einfach nur ein Z&auml;hlen, wie h&auml;ufig die Stellen &uuml;bereinstimmen.

      <figure class="wp-caption aligncenter">
<img alt="Draft of a hopfield network." src="//martin-thoma.com/images/2016/02/hopfield-network.png"/>
<figcaption>Figure 3: Draft of Hopfield network. Every node is an input node.
                   The McCullogh-Pitts nodes are updated asynchronously. When
                   the state of the node doesn't change any more, they contain
                   the output of the network. Learned are the weights between
                   the nodes.</figcaption>
</figure>
</dd>
<dt><a href="https://de.wikipedia.org/wiki/Boltzmann-Maschine"><dfn>Boltzmann-Maschine</dfn></a></dt>
<dd>Boltzmann-Maschinen sind
        stochastische neuronale Netzwerke, welche duch belibige ungerichtete
        Graphen repr&auml;sentiert werden k&ouml;nnen. Die neuronen sind bin&auml;r; sie
        feuern also entweder oder nicht. Es gibt insbesondere keine
        Unterschiede in der St&auml;rke mit der sie feuern.

        Siehe auch: <a href="http://www.scholarpedia.org/article/Boltzmann_machine">Scholarpedia</a>
</dd>
<dt><a href="https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine"><dfn>Restricted Boltzmann machine</dfn></a> (<dfn>RBM</dfn>)</dt>
<dd>Eine <i>RBM</i> ist ein neuronales Netz mit nur einem Hidden Layer.
      Es ist gleichzeitig ein Spezialfall von
      <abbr title="Markov Random Fields">MRFs</abbr>.

      Im Gegensatz zur Boltzmann-Maschine muss die Restricted Boltzmann-Machine
      (RBM) aus einem bipartitem Graph bestehen. Dies erlaubt ein effizienteres
      Trainingsverfahren (Contrastive Divergence).

      Die Energie des Netzwerkes ist
      $$- \sum_{i &lt; j} w_{ij} s_i s_j - \sum_i b_i s_i$$
      wobei $s_i, s_j$ die bin&auml;ren Zust&auml;nde der Knoten $i, j$ sind. Der
      Name "Boltzmann" kommt von dieser Energie (man kann den Netzwerkzust&auml;nden
      wahrscheinlichkeiten zuweisen, die direkt Proportional zu $e^{-E}$)
      sind.

      <figure class="wp-caption aligncenter">
<img alt="Draft of an RBM." src="//martin-thoma.com/images/2016/02/restricted-botzmann-machine.png"/>
<figcaption>Figure 4: Draft of an RBM. The learned parameters are red.</figcaption>
</figure>

      Es werden keine Verbindungen zwischen den Hidden Units erlaubt (daher das "restricted" - Quelle: <a href="https://youtu.be/IcOMKXAw5VA?t=5m42s">Hinton, 2015</a>).<br/>
<br/>
      Siehe <a href="https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf">A Practical Guide to Training Restricted Boltzmann Machines</a> von Hinton, 2010.</dd>
      sowie <a href="https://www.youtube.com/watch?v=lekCh_i32iE">Interence in RBMs</a>
<dt><a name="contrastive-divergence"></a><dfn>Contrastive Divergence</dfn> (<dfn>CD</dfn>, <dfn>CD-$k$</dfn>, siehe <a href="https://www.youtube.com/watch?v=MD8qXWucJBY">YouTube Video</a>, <a href="https://www.youtube.com/watch?v=wMb7cads0go">2</a> von Hugo Larochelle)</dt>
<dd>Contrastive Divergence ist ein Trainingsalgorithmus f&uuml;r RBMs.

      Ein Hyperparameter ist $k \in \mathbb{N}$.

      Er geht wie folgt vor:

      <ol>
<li>Lege den Trainingsvektor $x^{(t)}$ an die Eingabeknoten an.</li>
<li>Berechne die Wahrscheinlichkeit f&uuml;r jede Hidden Unit, dass diese gleich 1 ist. Setze sie mit dieser Wahrscheinlichkeit gleich 1.</li>
<li>Berechne die Wahrscheinlichkeit f&uuml;r jeden Eingabeknoten, dass dieser gleich 1 ist. Setze ihn mit dieser Wahrscheinlichkeit gleich 1.</li>
<li>Gehe zu Schritt 2. Wiederhole dies f&uuml;r $k$ Schritte (dies wird auch Gibbs-Sampling genannt).
              Das, was nach dem $k$-fachem Gibbs-Sampling in der Eingabeschicht
              steht wird auch "negative sample $\tilde x$" genannt.</li>
<li>Update der Parameter:
            \begin{align}
                W &amp;\leftarrow W + \eta (h(x^{(t)}) {x^{(t)}}^T - h(\tilde x) {\tilde x}^T)\\
                b_h &amp;\leftarrow b_h + \eta (h(x^{(t)}) - h(\tilde x))\\
                b_v &amp;\leftarrow b_v + \eta (x^{(t)} - \tilde x)
              \end{align}
            wobei $\eta \in (0, 1) $ die Lernrate ist,
            $b_h \in \mathbb{R}^n_h$ der Bias-Vektor der Hidden Units und
            $b_v \in \mathbb{R}^{n_v}$ der Bias-Vektor der Eingabeknoten ist.
            $h = \text{sigmoid}(b_h + W x)$ ist ein Vektor, welcher f&uuml;r die
            einzelnen Hidden Units sagt wie wahrscheinlich es ist, dass diese
            gleich 1 sind.
          </li>
</ol>

      In der Praxis funktioniert es schon mit $k=1$ f&uuml;r Pre-Training. Wenn
      $k$ gro&szlig; ist konvergiert $\tilde x$ gegen den wahren Modellwert. Das
      w&auml;re dann eine Monte-Carlo Estimation.
  </dd>
<dt><a href="https://de.wikipedia.org/wiki/Simulated_annealing"><dfn id="simulated-annealing">Simulated annealing</dfn></a></dt>
<dd>Simulated annealing ist ein heuristisches Optimierungsverfahren.

        Sei $D$ ein Wertebereich einer Funktion $f: D \rightarrow \mathbb{R}$
        und $U: D \rightarrow \mathcal{P}(D)$ eine Funktion, welche die
        Umgebung eines Punktes angibt. Sei $T: \mathbb{N}_0 \rightarrow \mathbb{R}_{&gt; 0}$
        die Temperatur zum Zeitpunkt $t \in \mathbb{N}_0$.

        Gesucht ist $\text{arg min}_{x \in D} f(x)$.

        W&auml;hle zum Zeitpunkt $t=0$ einen zuf&auml;lligen Startwert $x \in D$.

        Gehe nun iterativ vor und jeweils einen Zeitschritt weiter:

        Nehme einen Punkt aus der Umgebung $y \in U(x)$. Wenn
        $f(y) \leq f(x)$, dann &uuml;berschreibe $x \leftarrow y$. Falls nicht,
        dann &uuml;berschreibe es mit der Wahrscheinlichkeit $\exp \left (-\frac{f(y)-f(x)}{T(t)} \right )$.

        Speichere in jedem Schritt den bisher besten Wert.
        </dd>
</dl>
<p>Anwendungen:</p>
<ul>
<li>Hopfield-Netze: Hopfield-Netze kann man f&uuml;r das <abbr title="Traveling Salesman Problem">TSP</abbr> einsetzen und auch als Assoziativspeicher nutzen. Allerdings haben sich Hopfield-Netze nie wirklich durchgesetzt.</li>
<li>RBMs: <a href="../collaborative-filtering/">Collaborative Filtering</a></li>
</ul>
<p>Siehe auch:</p>
<ul>
<li>Deeplearning.net: <a href="http://deeplearning.net/tutorial/rbm.html">Restricted Boltzmann Machines (RBM)</a></li>
<li>A. Barra, A. Bernacchia, E. Santucci und P. Contucci: <a href="http://www.sciencedirect.com/science/article/pii/S0893608012001608">On the equivalence of Hopfield networks and Boltzmann Machines</a>in <em>Neural Networks</em>, 2012.</li>
</ul>
<h3 id="v12-rnns">V12: RNNs</h3>
<p>Slide name: <code>V12_2015-06-02_RNNs.pdf</code></p>
<dl>
<dt><a href="https://de.wikipedia.org/wiki/Elman-Netz"><dfn>Elman-Netz</dfn></a></dt>
<dd>Ein rekurrentes neuronales Netzwerk, bei dem die Ausgabe eines
        hidden layers im n&auml;chsten Zeitschritt als Eingabe verwendet wird.</dd>
<dt><a href="https://de.wikipedia.org/wiki/Jordan-Netz"><dfn>Jordan-Netz</dfn></a></dt>
<dd>Ein rekurrentes neuronales Netzwerk, bei dem die Ausgabe der
        Ausgabeschicht im n&auml;chsten Zeitschritt als Eingabe verwendet wird.</dd>
<dt><dfn>Backpropagation through Time</dfn> (<dfn>BPTT</dfn>)</dt>
<dd>Ein Trainingsalgorithmus f&uuml;r rekurrente neuronale Netze, bei dem
        das Netz "ausgerollt" wird. Das rekurrente Netz wird also als unendlich
        gro&szlig;es nicht-rekurrentes Netz behandelt.</dd>
<dt><a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem"><dfn>Vanishing gradient problem</dfn></a></dt>
<dd>Das Problem des verschwindenden Gradienten ist eine Herausforderung im
        Kontext neuronaler Netze, welche mit Backpropagation trainiert
        werden. Insbesondere bei sehr tiefen oder rekurrenten Netzen
        kann es passieren, dass der Gradient bei den ersten Schichten sehr
        niedrig ist, sodass das Netz sehr langsam lernt. Aufgrund numerischer
        Ungenauigkeit kann dies sogar dazu f&uuml;hren, dass das Netz in den
        ersten Schichten nicht lernen kann.</dd>
<dt><a href="https://en.wikipedia.org/wiki/Long_short-term_memory"><dfn>Long short-term memory</dfn></a> (<dfn>LSTM</dfn>)</dt>
<dd>Ein LSTM ist ein Typ eines neuronalen Netzwerks. Das besondere an
        LSTM Netzen sind "intelligente" Neuronen, welche &uuml;ber Gates bestimmen
        ob ein Wert gespeichert wird und wie lange.</dd>
</dl>
<p>Siehe auch:</p>
<ul>
<li>Andrej Karpathy: <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Recurrent Neural Networks</a>, 21.&nbsp;May&nbsp;2015.</li>
<li>Christopher Olah: <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a>, 27. August 2015.</li>
<li><a href="http://www.cs.toronto.edu/~ilya/fourth.cgi?prefix=E%3D&amp;numChars=300">Char-Predictor online Demo</a></li>
<li><a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/">Recurrent Neural Networks Tutorial, Part 1 &ndash; Introduction to RNNs</a></li>
<li>YouTube: <a href="https://www.youtube.com/watch?v=SKMpmAOUa2Q">Vanishing Gradient</a> (5:24 min)</li>
<li><a href="http://datascience.stackexchange.com/q/9510/8820">Where does the name 'LSTM' come from?</a></li>
<li>Greff, Srivastava, Koutn&iacute;k, Steunebrink, Schmidhuber: <a href="http://arxiv.org/abs/1503.04069v1">LSTM: A Search Space Odyssey</a>. arxiv, 2015.</li>
<li>Reddit: <a href="https://www.reddit.com/r/MachineLearning/comments/44bxdj/scrn_vs_lstm/czp4hqr">The Idea of LSTMs</a></li>
</ul>
<h3 id="v13-nn-learning-tricks">V13: NN learning tricks</h3>
<p>Slide name: <code>V13_2015-06-09_NNlearning-tricks.pdf</code></p>
<dl>
<dt><dfn id="momentum">Momentum</dfn></dt>
<dd>In der Update-Regel $\Delta w_{ij}^* (t+1) = \Delta w_{ij} (t+1) + \alpha \Delta w_{ij}(t)$ wird der Term $\Delta w_{ij}(t)$ als <i>Momentum</i> bezeichnet.
        Der Skalar $\alpha \in [0, 1]$ gewichtet diesen und ist ein
        Hyperparameter.<br/>
<br/>
        Siehe auch:

        <a href="http://ufldl.stanford.edu/tutorial/supervised/OptimizationStochasticGradientDescent/#momentum">Optimization: Stochastic Gradient Descent</a>
</dd>
<dt><a href="https://en.wikipedia.org/wiki/Quickprop"><dfn>Quickprop</dfn></a></dt>
<dd>Quickprop ist ein Trainingsverfahren f&uuml;r neuronale Netze. Der Lernalgorithmus
        nimmt an, dass die Fehlerebene lokal durch eine parabel approximiert
        werden kann. Das Gewichtsupdate im Schritt $k$ ist demnach vom
        Gradienten und dem Gewichtsupdate das vorherigen Schrittes abh&auml;ngig:

        $$\Delta^{(k)} \, w_{ij} = \Delta^{(k-1)} \, w_{ij} \left ( \frac{\nabla_{ij} \, E^{(k)}}{\nabla_{ij} \, E^{(k-1)} - \nabla_{ij} \, E^{(k)}} \right)$$</dd>
<dt><dfn>Weight Decay</dfn></dt>
<dd>Passe die Fehlerfunktion an: $E = MSE + \lambda \sum_{i,j} w_{ij}^2$</dd>
<dt><dfn>Weight Elimination</dfn></dt>
<dd>Passe die Fehlerfunktion an: $E = MSE + \lambda \sum_{i,j} \frac{w_{ij}^2}{1+w_{ij}^2}$</dd>
<dt><dfn>Optimal Brain Damage</dfn> (<dfn>OBD</dfn>)</dt>
<dd>Optimal Brain Damage entfernt nach dem Training Verbindungen die
        sehr kleine $|w_{ij}|$ haben.

        Besser: Entferne Verbindungen, die geringen Einfluss auf die
        Fehlerfunktion haben.</dd>
<dt><dfn>Cascade Correlation</dfn> (siehe Fahlman und Lebiere: <a href="http://papers.nips.cc/paper/207-the-cascade-correlation-learning-architecture.pdf">The Cascade-Correlation Learning Architecture</a>)</dt>
<dd>Cascade Correlation ist ein konstruktiver Algorithmus zum erzeugen
        von Feed-Forward Neuronalen Netzen. Diese haben eine andere Architektur
        als typische multilayer Perceptrons. Bei Netzen, welche durch
        Cascade Correlation aufgebaut werden, ist jede Hidden Unit mit
        den Input-Neuronen verbunden, mit den Output-Neuronen und mit allen
        Hidden Units in der Schicht zuvor.<br/>
<br/>
<iframe allowfullscreen="" frameborder="0" height="288" src="https://www.youtube-nocookie.com/embed/1E3XZr-bzZ4" width="512"></iframe>
<br/>
        Siehe <a href="http://datascience.stackexchange.com/q/9672/8820">How exactly does adding a new unit work in Cascade Correlation?</a></dd>
<dt><dfn>Meiosis Netzwerke</dfn> (siehe Stephen Jose Hanson: <a href="http://papers.nips.cc/paper/227-meiosis-networks.pdf">Meiosis Networks</a>)</dt>
<dd>Meiosis Netzwerke bauen ein neuronales Netz auf. Sie beginnen mit einer
        einzelnen hidden Unit. Diese hidden Unit wird aufgespalten, wenn die
        "Unsicherheit" zu gro&szlig; ist (vgl. paper f&uuml;r Kritierum; vgl. <a href="http://www.shortscience.org/paper?bibtexKey=conf/nips/Hanson89#martinthoma">summary</a>).<br/>
</dd>
<dt><dfn>Automatic Structure Optimization</dfn> (<dfn>ASO</dfn>, siehe [<a href="#ref-bod93" name="ref-bod93-anchor">Bod93</a>])</dt>
<dd>Der ASO-Algorithmus passt folgende Hyperparameter im Training
        automatisch an:

        <ul>
<li>Anzahl der Hidden Units</li>
<li>Gr&ouml;&szlig;e des Input-Fensers (ASR-Spezifisch)</li>
<li>Anzahl der Zust&auml;nde, welche "Accoustic Events" repr&auml;sentieren</li>
</ul>
</dd>
<dt><dfn>Classification Figure of Merit</dfn> (<dfn>CFM</dfn>, siehe [<a href="#ref-ham90" name="ref-ham90-anchor">Ham90</a>])</dt>
<dd>
        $$E_{CFM}(w) = \sum_k \frac{\alpha}{1 + e^{-\beta \Delta_k + \gamma}}$$
        wobei
        <ul>
<li>$k$: Klasse</li>
<li>$\alpha, \beta, \gamma$: Hyperparameter</li>
<li>$\Delta_k = o_t - o_k$: Differenz des wahren (true) nodes und des anderen Knotens.</li>
</ul>
</dd>
</dl>
<p>Speed-ups des Trainings sind m&ouml;glich durch:</p>
<ul>
<li>Momentum</li>
<li>&Uuml;berspringen von bereits gut gelernten Beispielen</li>
<li>Dynamische Anpassung der Lernrate <span markdown="0"><span class="math">\(\eta\)</span></span></li>
<li>Quickprop</li>
<li>Gute Initialisierung (z.b. <span markdown="0"><span class="math">\(w \sim U(- 4 \cdot \sqrt{\frac{6}{n_j + n_{j+1}}}, 4 \cdot \sqrt{\frac{6}{n_j + n_{j+1}}})\)</span></span>)</li>
</ul>
<p>Lernen kann getweakt werden:</p>
<ul>
<li>Den Betrag des Gradienten um eine kleine Konstante vergr&ouml;&szlig;ern (Folie 19+20)</li>
<li>Fehlerfunktion anpassen<ul>
<li><abbr title="Mean Squared Error">MSE</abbr></li>
<li><a href="#dfn-cross-entropy">Cross-Entropy</a></li>
<li><abbr title="Classification Figure of Merit">CFM</abbr></li>
</ul>
</li>
<li>Overfitting verhindern<ul>
<li>Weight decay</li>
<li>Weight elimination</li>
<li>Optimal Brain Damage</li>
<li>Optimal Brain Surgeon</li>
</ul>
</li>
<li>Schrittweise Netzkonstruktion<ul>
<li>Cascade Correlation</li>
<li>Meiosis Netzwerke</li>
<li><abbr title="Automatic Structure Optimalization">ASO</abbr></li>
</ul>
</li>
</ul>
<h3 id="v14-dnn-cv">V14: DNN CV</h3>
<p>Slide name: <code>V14_2015-06-10_DNN_CV .pdf</code></p>
<dl>
<dt><a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform"><dfn>SIFT</dfn></a> (<dfn>Scale-invariant feature transform</dfn>)</dt>
<dd>Unter SIFT versteht man bestimmte Features in der Bildverarbeitung,
        welche invariant unter skalierung sind.</dd>
<dt><a href="https://en.wikipedia.org/wiki/Texton"><dfn>Texton</dfn></a> (siehe <a href="http://vcla.stat.ucla.edu/old/Chengen_Research/texton.htm">UCLA</a>)</dt>
<dd>Unter einem Texton versteht man grundlegende, kleine Features eines
        Bildes. Diese Bilden die kleinsten als unterschiedlich wahrnehmbaren
        Einheiten.</dd>
<dt><a href="https://en.wikipedia.org/wiki/Convolutional_neural_network"><dfn>Convolutional Neural Network</dfn></a> (<dfn>CNN</dfn>)</dt>
<dd>Ein CNN ist ein Neuronales Netzwerk, welches mindestens eine Schicht
        hat, welche die Parameter eines Kernels f&uuml;r eine Faltung lernt.</dd>
<dt><dfn>Feature Map</dfn></dt>
<dd>Im Kontext von CNNs versteht man unter einer Feature-Map die Ausgabe
        eines Kernels in einem Convolutional Layer.</dd>
</dl>
<p>Facts:</p>
<ul>
<li>Pooling: Max, Mean, Probabilistic</li>
</ul>
<h3 id="v15-speech-independence">V15: Speech-Independence</h3>
<p>Slide name: <code>V15_2015-06-17_Speech-Independence.pdf</code></p>
<h2 id="visualisierung-von-netzen_1">Visualisierung von Netzen</h2>
<p>H&auml;ufig wird die Architektur neuronaler Netze grafisch dargestellt. Dabei ist
mir folgendes aufgefallen:</p>
<ul>
<li>Im Innenren von Neuronen wird die Aktivierungsfunktion "geplottet". Das hei&szlig;t
  bei der Sigmoidfunktion wird etwas S-F&ouml;rmiges dargestellt, bei der
  sign-Funktion etwas eckiges, bei ReLU ein horizontaler Strich gefolgt von
  einem Strich im 45-Grad Winkel.</li>
<li>Typischerweise ist der Input links (oder alternativ unten) und der Output
  rechts (oder alternativ oben)</li>
</ul>
<h2 id="interpretation-of-errors">Interpretation of errors</h2>
<figure class="wp-caption aligncenter">
<img alt="Training and Testing error over epochs" src="//martin-thoma.com/images/2016/02/2d-epochs-overfitting.png"/>
<figcaption>Figure 5: Training and Testing error over epochs. At some point overfitting happens.</figcaption>
</figure>
<figure class="wp-caption aligncenter">
<img alt="Training and Testing error over training data" src="//martin-thoma.com/images/2016/02/variance-bias.png"/>
<figcaption>Figure 6: Training and Testing error over training data. At some point overfitting happens.</figcaption>
</figure>
<p>If you have a problem with high variance, you can train more epochs, get more
data or better features.</p>
<p>If you have a problem with high bias, you should get better features or a
better classifier.</p>
<p>Please note that Figure&nbsp;6 also gives you a feeling for how much new
training data will help you with your problem.</p>
<h2 id="aktivierungsfunktionen"><a name="activations"></a> Aktivierungsfunktionen</h2>
<table class="table" style="width:800px;">
<thead>
<tr>
<th>Name</th>
<th>Function <span markdown="0">$\varphi(x)$</span></th>
<th>Range of values</th>
<th>Differentiable</th>
<th><span markdown="0">$\varphi'(x)$</span></th>
<th>Layer</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr>
<td>Signum</td>
<td><span markdown="0">$\varphi(x) = \begin{cases}+1 &amp;\text{if } x &gt; 0\\-1 &amp;\text{if } x &lt; 0\end{cases}$</span></td>
<td style="text-align: center;"><span markdown="0">$\{-1, 1\}$</span></td>
<td style="text-align: center;">Yes<br/>(except 0)</td>
<td><span markdown="0">$\varphi'(x) = 0$</span></td>
<td style="text-align: center;">No</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>Heaviside Step function</td>
<td><span markdown="0">$\varphi(x) = \begin{cases}+1 &amp;\text{if } x &gt; 0\\0 &amp;\text{if } x &lt; 0\end{cases}$</span></td>
<td style="text-align: center;"><span markdown="0">$\{0, 1\}$</span></td>
<td style="text-align: center;">Yes<br/>(except 0)</td>
<td><span markdown="0">$\varphi'(x) = 0$</span></td>
<td style="text-align: center;">No</td>
<td>McCullch-Pitts; Rosenblatt</td>
</tr>
<tr>
<td>Sigmoid</td>
<td><span markdown="0">$\varphi(x) = \frac{1}{1+e^{-x}}$</span></td>
<td style="text-align: center;"><span markdown="0">$[0, 1]$</span></td>
<td style="text-align: center;">Yes</td>
<td><span markdown="0">$\varphi'(x) = \frac{e^x}{(e^x +1)^2}$</span></td>
<td style="text-align: center;">No</td>
<td>Smoothed version of the heaviside step function</td>
</tr>
<tr>
<td><abbr title="Tangens Hyperbolicus">tanh</abbr></td>
<td><span markdown="0">$\varphi(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} = \tanh(x)$</span></td>
<td style="text-align: center;"><span markdown="0">$[-1, 1]$</span></td>
<td style="text-align: center;">Yes</td>
<td><span markdown="0">$\varphi'(x) = \text{sech}^2(x)$</span></td>
<td style="text-align: center;">No</td>
<td>Smoothed version of the signum function</td>
</tr>
<tr>
<td><abbr title="Rectified Linear Unit">ReLU</abbr></td>
<td><span markdown="0">$\varphi(x) = \max(0, x)$</span></td>
<td style="text-align: center;"><span markdown="0">$[0, \infty)$</span></td>
<td style="text-align: center;">Yes<br/>(except 0)</td>
<td><span markdown="0">$\varphi'(x) = \begin{cases}1 &amp;\text{if } x &gt; 0\\0 &amp;\text{if } x &lt; 0\end{cases}$</span></td>
<td style="text-align: center;">No</td>
<td>Standard in CNNs</td>
</tr>
<tr>
<td>Leaky ReLU</td>
<td><span markdown="0">$\varphi(x) = \max(\alpha x, x)$</span> mit typischerweise <span markdown="0">$\alpha = 0.01$</span></td>
<td style="text-align: center;"><span markdown="0">$(-\infty, +\infty)$</span></td>
<td style="text-align: center;">Yes<br/>(except 0)</td>
<td><span markdown="0">$\varphi'(x) = \begin{cases}1 &amp;\text{if } x &gt; 0\\0.01 &amp;\text{if } x &lt; 0\end{cases}$</span></td>
<td style="text-align: center;">No</td>
<td>Fixes the dying ReLU problem<sup>[<a href="http://datascience.stackexchange.com/q/5706/8820">1</a>]</sup></td>
</tr>
<tr>
<td>Softplus</td>
<td><span markdown="0">$\varphi(x) = \log(e^x + 1)$</span></td>
<td style="text-align: center;"><span markdown="0">$(0, \infty)$</span></td>
<td style="text-align: center;">Yes</td>
<td><span markdown="0">$\varphi'(x) = \frac{e^x}{e^x + 1}$</span></td>
<td style="text-align: center;">No</td>
<td>Smoothed ReLU</td>
</tr>
<tr>
<td><abbr title="Exponential Linear Unit">ELU</abbr></td>
<td><span markdown="0">$\varphi(\mathbf{x}) = \begin{cases}x &amp;\text{if } x &gt; 0\\\alpha (e^x - 1) &amp;\text{otherwise}\end{cases}$</span></td>
<td style="text-align: center;"><span markdown="0">$(-\infty, +\infty)$</span></td>
<td style="text-align: center;">Yes</td>
<td><span markdown="0">$\varphi'(x) = \begin{cases}1 &amp;\text{if } x &gt; 0\\\alpha e^x &amp;\text{otherwise}\end{cases}$</span></td>
<td style="text-align: center;">No</td>
<td>&nbsp;</td>
</tr>
<tr>
<td><a href="../softmax">Softmax</a></td>
<td><span markdown="0">$o(\mathbf{z})_j = \frac{e^{z_j}}{\sum_{k=1}^K e^{z_k}}$</span></td>
<td style="text-align: center;"><span markdown="0">$[0, 1]^K$</span></td>
<td style="text-align: center;">Yes</td>
<td>differentiable</td>
<td style="text-align: center;">Yes</td>
<td>Standard for classification problems as the output can be interpreted as a probability distribution.</td>
</tr>
<tr>
<td>Maxout</td>
<td><span markdown="0">$o(\mathbf{z}) = \max_{z \in \mathbf{z}} z$</span></td>
<td style="text-align: center;"><span markdown="0">$(-\infty, +\infty)$</span></td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">Yes</td>
<td>&nbsp;</td>
</tr>
</tbody>
</table>
<p>See also:</p>
<ul>
<li>Bing Xu, Naiyan Wang, Tianqi Chen, Mu Li: <a href="http://arxiv.org/abs/1505.00853">Empirical Evaluation of Rectified Activations in Convolutional Network</a>. arxiv, 2015</li>
<li>Djork-Arn&eacute; Clevert, Thomas Unterthiner, Sepp Hochreiter: <a href="http://arxiv.org/abs/1511.07289">Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)</a>. arxiv, 2015.</li>
</ul>
<h2 id="topology-learning"><a name="topology-learning"></a> Topology Learning</h2>
<p><strong>Growing approaches</strong></p>
<ul>
<li>Fahlman, Lebiere: <a href="http://papers.nips.cc/paper/207-the-cascade-correlation-learning-architecture.pdf">The Cascade-Correlation Learning Architecture</a>. 1989.</li>
<li>Hanson: <a href="http://papers.nips.cc/paper/227-meiosis-networks.pdf">Meiosis Networks</a>. 1990.</li>
<li>C&ocirc;t&eacute;, Larochelle: <a href="http://arxiv.org/abs/1502.02476">An Infinite Restricted Boltzmann Machine</a>. 2015</li>
</ul>
<p><strong>Pruning approaches</strong></p>
<ul>
<li>Le Cun, Denker, Solla: <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-90b.pdf">Optimal Brain Damage</a>. 1989.</li>
<li>Hassibi, Stork: <a href="http://ee.caltech.edu/Babak/pubs/conferences/00298572.pdf">Optimal Brain Surgeon and General Network Pruning</a>. 1993.</li>
</ul>
<p><strong>Genetic Approaches</strong></p>
<ul>
<li><a href="https://www.cs.ucf.edu/~kstanley/neat.html">NEAT</a></li>
<li><a href="http://eplex.cs.ucf.edu/hyperNEATpage/">HyperNEAT</a></li>
</ul>
<p>See also:</p>
<ul>
<li>Reddit: <a href="https://www.reddit.com/r/MachineLearning/comments/44ld5c/interesting_papers_on_learning_automatically/">Interesting papers on learning automatically learning neural network topology</a></li>
</ul>
<h2 id="einordnung"><a name="einordnung"></a> Einordnung</h2>
<p>Neuronale netze kann man durch folgende Kriterien mit einander vergleichen:</p>
<ul>
<li><strong>Deterministisch / Stochastisch</strong>: Ist die Aktivierung der neuronen
  stochastische oder deterministisch?</li>
<li><strong>Inferenz</strong>: Feed-Forward oder Rekurrent? Wie funktioniert die Auswertung?</li>
<li><strong>Training</strong>: Wie lernt man?</li>
<li><strong>Verwendung</strong>: Wo wird das Netzwerk typischerweise eingesetzt?</li>
</ul>
<table class="table" style="width:800px;">
<thead>
<tr>
<th style="width: 180px;">Netzwerk</th>
<th>Deterministisch</th>
<th>Inferenz</th>
<th>Training</th>
<th>Verwendung</th>
</tr>
</thead>
<tbody>
<tr>
<th>McCulloch-Pitts Neuron</th>
<td style="text-align: center;">Yes</td>
<td>Feed-Forward</td>
<td>Supervised</td>
<td>Classification of linear separable data</td>
</tr>
<tr>
<th>Rosenblatt Perceptron</th>
<td style="text-align: center;">Yes</td>
<td>Feed-Forward</td>
<td>Supervised</td>
<td>Classification of linear separable data</td>
</tr>
<tr>
<th>Multilayer Perceptron</th>
<td style="text-align: center;">Yes</td>
<td>Feed-Forward</td>
<td>Supervised (Backpropagation)</td>
<td>Classification</td>
</tr>
<tr>
<th><abbr title="Convolutional Neural Networks">CNN</abbr></th>
<td style="text-align: center;">Yes</td>
<td>Feed-Forward</td>
<td>Supervised (Backpropagation + weight sharing)</td>
<td>Computer Vision</td>
</tr>
<tr>
<th><abbr title="Time Delay Neural Networks">TDNNs</abbr></th>
<td style="text-align: center;">Yes</td>
<td>Feed-Forward</td>
<td>Supervised (Backpropagation + weight sharing)</td>
<td><abbr title="Automatic Speech Recognition">ASR</abbr></td>
</tr>
<tr>
<th><abbr title="Long Short-Term Memory">LSTM</abbr></th>
<td style="text-align: center;">Yes</td>
<td>Recurrent</td>
<td><abbr title="Backpropagation Through Time">BPTT</abbr></td>
<td>Mapping sequences (Generating texts, machine translation)</td>
</tr>
<tr>
<th><abbr title="Self-Organizing Maps">SOMs</abbr></th>
<td style="text-align: center;">Yes</td>
<td>Feed-Forward</td>
<td>Unsupervised (competitive learning)</td>
<td>Visualisierung / Dimensionalit&auml;tsreduktion: Mapping of high-dimensional data on 2D; <abbr title="Content-Based Image Retrival">CBIR</abbr>; <a href="https://www.youtube.com/watch?v=8tnxgfE6glI">TSP</a></td>
</tr>
<tr>
<th>Hopfield networks</th>
<td style="text-align: center;">Yes</td>
<td>Recurrent</td>
<td>Unsupervised (Hebbsche Lernregel)</td>
<td>Associative memories, <a href="http://perso.ens-lyon.fr/eric.thierry/Graphes2010/alice-julien-laferriere.pdf">travelling salesman</a></td>
</tr>
<!--
    <tr>
        <th>Helmholtz machines</th>
        <td>stochastic</td>
        <td>TODO</td>
        <td>wake-sleep algorithm</td>
        <td>TODO</td>
    </tr>
    -->
<tr>
<th>Boltzmann machines</th>
<td>stochastic</td>
<td>Simulated Annealing</td>
<td><a href="http://www.cs.toronto.edu/~rsalakhu/papers/bm.pdf">Annealed Importance Sampling</a></td>
<td>(not used)</td>
</tr>
<tr>
<th><abbr title="Restricted Boltzmann Machines">RBMs</abbr></th>
<td>stochastic</td>
<td><span markdown="0">$p(h_j=1|x) = \text{sigmoid}(b_{v,j} + W_j x)$</span><br/>
<span markdown="0">$p(x_k=1|h) = \text{sigmoid}(b_{h,k} + h^T W_k)$</span></td>
<td><a href="#contrastive-divergence">Contrastive Divergence</a>&nbsp;(CD-$k$)</td>
<td><a href="http://www.cs.toronto.edu/~rsalakhu/papers/rbmcf.pdf">Collaborative Filtering</a></td>
</tr>
</tbody>
</table>
<h2 id="learning-rate-scheduling"><a name="lr-scheduling"></a> Learning Rate Scheduling</h2>
<ul>
<li>Fixed: The learning rate doesn't change. This is the standard stochastic
  gradient descent algorithm.</li>
<li><a href="#rprop">RProp</a></li>
<li>RMSProp (Root Mean Square Propagation): <a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf">Slides</a></li>
<li><a href="#exponential-decay-lr">Exponential Decay Learning Rate</a></li>
<li><a href="#newbob">Newbob</a></li>
<li><a href="#performance-scheduling">Performance Scheduling</a></li>
<li><a href="#adagrad">AdaGrad</a></li>
</ul>
<p>There are a couple of publications which deal with LR scheduling:</p>
<ul>
<li><a href="http://papers.nips.cc/paper/400-note-on-learning-rate-schedules-for-stochastic-optimization.pdf">Note on Learning Rate Schedules for Stochastic Optimization </a></li>
<li><a href="https://arxiv.org/pdf/1206.1106.pdf">No More Pesky Learning Rates</a></li>
<li><a href="http://sebastianruder.com/optimizing-gradient-descent/">Optimizing Gradient Descent</a></li>
</ul>
<p>I'm not too sure, but I think <a href="#momentum">momentum</a> is not a
learning rate scheduling algorithm.</p>
<p>See also:</p>
<ul>
<li><a href="http://stackoverflow.com/a/33711600/562769">What is <code>lr_policy</code> in Caffe?</a></li>
<li><a href="http://imgur.com/a/Hqolp">Visualizing Optimization Algos</a> <a href="http://imgur.com/s25RsOr">2</a> on imgur.com by <a href="https://www.reddit.com/r/MachineLearning/comments/2gopfa/visualizing_gradient_optimization_techniques/cklhott">Alec Radford</a></li>
</ul>
<h2 id="prufungsfragen">Pr&uuml;fungsfragen</h2>
<ul>
<li>Was ist der Unterschied zwischen Backpropagation und Gradient descent?<br/>
        &rarr; Backpropagation ist eine geschickte Umsetzung des Gradientenabstiegs,
           bei der es vermieden wird Berechnungen mehrfach durchzuf&uuml;hren.</li>
<li>Welche Typen von Neuronalen Netzen gibt es?<br/>
        &rarr; Siehe <a href="#einordnung">Einordnung</a></li>
<li>Welche Aktivierungsfuktionen gibt es?<br/>
        &rarr; Siehe <a href="#activations">&Uuml;bersicht</a></li>
<li>Welche Aktivierungsfunktionen machen bei einem einzelnen Perzeptron keinen Sinn?<br/>
        &rarr; Softmax wegen der Normierung; Maxout</li>
<li>Welche Aktivierungsfunktion macht in einem MLP keinen Sinn?<br/>
        &rarr; Nur lineare, da insgesamt eine lineare Funktion herauskommt.</li>
<li>Wof&uuml;r kann man neuronale Netze einsetzen?<br/>
        &rarr; Klassifikation, <a href="http://datascience.stackexchange.com/q/9495/8820">Funktionsapproximation</a>, Encoding, Dimensionalit&auml;tsreduktion,
        Assoziativspeicher</li>
<li>Welche M&ouml;glichkeiten zur Regularisierung gibt es?<br/>
        &rarr; L1, L2, Dropout, Weight Decay</li>
<li>Wie kann der Standard Gradient descent Algorithmus angepasst werden
        um den Lernvorgang zu beschleunigen?<br/>
        &rarr; Momentum, Exponential Decay Learning Rate, Performance Scheduling,
           Newbob, AdaGrad, RProp</li>
<li>Welche Alternativen zu standard Gradient Descent gibt es?<br/>
        &rarr; Quickprop, (L-)BFGS, Conjugate Gradient, Quasi-Newtonian (vgl. <a href="https://www.reddit.com/r/MachineLearning/comments/4582s0/overview_of_optimization_algorithms/">Reddit</a>, <a href="https://martin-thoma.com/optimization-basics">Optimization Basics</a>).</li>
<li>Wie kann man Netztopologien aufbauen?<br/>
        &rarr; Meiosis, Cascade Correlation, Optimal Brain Damage / Surgeon (vgl. <a href="https://www.reddit.com/r/MachineLearning/comments/44ld5c/interesting_papers_on_learning_automatically/">Reddit</a>).</li>
</ul>
<h2 id="material-und-links">Material und Links</h2>
<ul>
<li><a href="http://ies.anthropomatik.kit.edu/lehre_mustererkennung.php">Vorlesungswebsite</a></li>
<li><a href="https://github.com/thanhleha/NNPraktikum">NNPraktikum</a>: Toolkit f&uuml;r die &Uuml;bungsbl&auml;tter</li>
<li>StackExchange</li>
<li>✓ <a href="http://stats.stackexchange.com/q/74082/25741">What is the difference in Bayesian estimate and maximum likelihood estimate?</a></li>
<li>✓ <a href="http://datascience.stackexchange.com/q/9172/8820">Can k-means clustering get shells as clusters?</a></li>
<li><a href="http://datascience.stackexchange.com/q/9177/8820">How is the Schwarz Criterion defined?</a></li>
<li><a href="http://datascience.stackexchange.com/q/9195/8820">Are there studies which examine dropout vs other regularizations?</a></li>
<li><a href="http://datascience.stackexchange.com/q/9175/8820">How do subsequent convolution layers work?</a></li>
<li>✓ <a href="http://datascience.stackexchange.com/q/9212/8820">Is Maxout the same as max pooling?</a></li>
<li><a href="http://robotics.stackexchange.com/q/8617/11257">What is <span class="math">\(\alpha \sin(\theta) + \beta \frac{d \theta}{d t}\)</span> in the inverted pole problem?</a></li>
<li>✓ <a href="http://datascience.stackexchange.com/q/9233/8820">(Why) do activation functions have to be monotonic?</a></li>
<li><a href="http://datascience.stackexchange.com/q/9302/8820">The cross-entropy error function in neural networks</a></li>
<li><a href="http://datascience.stackexchange.com/q/5706/8820">What is the &ldquo;dying ReLU&rdquo; problem in neural networks?</a> and <a href="http://stats.stackexchange.com/q/176794/25741">How does rectilinear activation function solve the vanishing gradient problem in neural networks?</a></li>
<li><a href="http://imgur.com/a/Hqolp">Visualizing Optimization Algos</a> <a href="http://imgur.com/s25RsOr">2</a> on imgur.com by <a href="https://www.reddit.com/r/MachineLearning/comments/2gopfa/visualizing_gradient_optimization_techniques/cklhott">Alec Radford</a></li>
<li><a href="http://phiresky.github.io/kogsys-demos/neural-network/">Neural Network demo</a></li>
<li><a href="https://github.com/Marvin182/NeuralNets">Skript von Marvin Ritter</a></li>
<li><a href="//martin-thoma.com/machine-learning-1-course/">Machine Learning 1</a> und <a href="//martin-thoma.com/machine-learning-2-course/">Machine Learning 2</a> am KIT</li>
<li>Coursera: <a href="https://class.coursera.org/neuralnets-2012-001/lecture">Neural Networks for Machine Learning</a> by Geoffrey Hinton</li>
</ul>
<h2 id="literatur">Literatur</h2>
<ul>
<li>[<a href="#ref-mit97-anchor" name="ref-mit97">Mit97</a>] T. Mitchell.
  Machine Learning. McGraw-Hill, 1997.</li>
<li>[<a href="#ref-hop82-anchor" name="ref-hop82">Hop82</a>] J. J. Hopfield.
  <a href="http://www.pnas.org/content/79/8/2554.full.pdf">Neural networks and physical systems with emergent collective computational abilities</a> in Proceedings of the national academy of sciences, 1982.</li>
<li>[<a href="#ref-kri05-anchor" name="ref-kri05">Kri05</a>] D. Kriesel.
  <a href="http://www.dkriesel.com/_media/science/neuronalenetze-de-zeta2-2col-dkrieselcom.pdf">Neuronale Netze</a>. 2005.</li>
<li>[<a href="#ref-bod93-anchor" name="ref-bod93">Bod93</a>] U. Bodenhausen und A. Waibel.
  <a href="http://isl.anthropomatik.kit.edu/cmu-kit/downloads/tuning_by_Doing_Flexibility_through_automatic_structure_optimization(1).pdf">Tuning by doing: Flexibility through automatic structure optimization</a> in Third European Conference on Speech Communication and Technology, 1993.</li>
<li>[<a href="#ref-haf92-anchor" name="ref-haf92">Haf92</a>] P. Haffner und A. Waibel.
  <a href="http://isl.anthropomatik.kit.edu/downloads/0135_Kopie_.pdf">Multi-state time delay networks for continuous speech recognition</a> in Advances in neural information processing systems, 1992.</li>
<li>[<a href="#ref-ham90-anchor" name="ref-ham90">Ham90</a>] J. Hampshire and A. Waibel.
  A Novel Objective Function for Improved Phoneme Recognition Using Time Delay Neural Networks. IEEE Transactions on Neural Networks, 1990.</li>
</ul>
<h2 id="vorlesungsempfehlungen">Vorlesungsempfehlungen</h2>
<p>Folgende Vorlesungen sind &auml;hnlich:</p>
<ul>
<li><a href="https://martin-thoma.com/analysetechniken-grosser-datenbestaende/">Analysetechniken gro&szlig;er Datenbest&auml;nde</a></li>
<li><a href="https://martin-thoma.com/informationsfusion/">Informationsfusion</a></li>
<li><a href="https://martin-thoma.com/machine-learning-1-course/">Machine Learning 1</a></li>
<li><a href="https://martin-thoma.com/machine-learning-2-course/">Machine Learning 2</a></li>
<li><a href="https://martin-thoma.com/mustererkennung-klausur/">Mustererkennung</a></li>
<li><a href="https://martin-thoma.com/neuronale-netze-vorlesung/">Neuronale Netze</a></li>
<li><a href="https://martin-thoma.com/lma/">Lokalisierung Mobiler Agenten</a></li>
<li><a href="https://martin-thoma.com/probabilistische-planung/">Probabilistische Planung</a></li>
</ul>
<h2 id="ubungsbetrieb">&Uuml;bungsbetrieb</h2>
<p>&Uuml;bungsbl&auml;tter sind freiwillig.</p>
<h2 id="termine-und-klausurablauf">Termine und Klausurablauf</h2>
<p><strong>Datum</strong>: nach Terminvereinbarung<br/>
<strong>Ort</strong>: <a href="http://www.kithub.de/map/2210">Geb&auml;ude 50.20</a><br/>
<strong>&Uuml;bungsschein</strong>: gibt es nicht<br/>
<strong>Bonuspunkte</strong>: gibt es nicht<br/>
<strong>Erlaubte Hilfsmittel</strong>: keine</p>
            
            <div id="disqus_thread"></div>
<script>
    /*
    var disqus_config = function () {
        this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() {  // REQUIRED CONFIGURATION VARIABLE: EDIT THE SHORTNAME BELOW
        var d = document, s = d.createElement('script');

        s.src = '//martinthoma.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

            <hr/>
        </div>
        <section>
        <div class="col-sm-2 col-md-2" style="float:right;font-size:0.9em;">
            <h4>Published</h4>
            <time pubdate="pubdate" datetime="2015-04-27T21:15:00+02:00">Apr 27, 2015</time>
            <br/>
            by <a rel="author" class="vcard author post-author" itemprop="author" href="../author/martin-thoma/"><span class="fn" itemscope="" itemtype="https://schema.org/Person"><span itemprop="name">Martin Thoma</span></span></a>
            <h4>Category</h4>
            <a class="category-link" href="../categories.html#german-posts-ref">German posts</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="../tags.html#klausur-ref">Klausur
                    <span>35</span>
</a></li>
                <li><a href="../tags.html#machine-learning-ref">Machine Learning
                    <span>36</span>
</a></li>
                <li><a href="../tags.html#neural-networks-ref">Neural Networks
                    <span>5</span>
</a></li>
                <li><a href="../tags.html#rl-ref">RL
                    <span>5</span>
</a></li>
            </ul>
<h4>Contact</h4>
    <a href="https://twitter.com/themoosemind" title="My Twitter Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-twitter sidebar-social-links"></i></a>
    <a href="mailto:info@martin-thoma.de" title="My Email Address" class="sidebar-social-links" target="_blank">
    <i class="fa fa-envelope sidebar-social-links"></i></a>
    <a href="https://github.com/MartinThoma" title="My Github Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-github sidebar-social-links"></i></a>
    <a href="http://stackoverflow.com/users/562769/martin-thoma" title="My Stackoverflow Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-stackoverflow sidebar-social-links"></i></a>
        </div>
        </section>
</div>
</article>
                </div>
                <div class="col-sm-1 col-md-1"></div>
            </div>
        </div>
        <div id="push"></div>
    </div>
<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-subtitle"><span class="site-name">Martin Thoma</span> - A blog about Code, the Web and Cyberculture</li>
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page">Talha Mansoor</a></li>
    </ul>
</div>
</footer>        <script src="//code.jquery.com/jquery.min.js"></script>
        <!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>
        <script>
(function(){
    'use strict';

    /*
    Create intra-page links
    Requires that your headings already have an `id` attribute set (because that's what jekyll does)
    For every heading in your page, this adds a little anchor link `#` that you can click to get a permalink to the heading.
    Ignores `h1`, because you should only have one per page.
    The text content of the tag is used to generate the link, so it will fail "gracefully-ish" if you have duplicate heading text.

    Credit: https://gist.github.com/SimplGy/a229d25cdb19d7f21231
     */

    var headingNodes = [], results, link,
        tags = ['h2', 'h3', 'h4', 'h5', 'h6'];

    tags.forEach(function(tag){
        var contentTag = document.getElementById('contentAfterTitle');
      results = contentTag.getElementsByTagName(tag);
      Array.prototype.push.apply(headingNodes, results);
    });

    headingNodes.forEach(function(node){
      link = document.createElement('a');
      link.className = 'deepLink';
      link.textContent = ' ¶';
      link.href = '#' + node.getAttribute('id');
      node.appendChild(link);
    });

  })();
</script>
    </body>
    <!-- Theme: Elegant built for Pelican
    License : http://oncrashreboot.com/pelican-elegant -->
</html>