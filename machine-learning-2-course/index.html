<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Martin Thoma" />
        <meta name="copyright" content="Martin Thoma" />
        <link title = "Martin Thoma"
              type  = "application/opensearchdescription+xml"
              rel   = "search"
              href  = "../opensearch.xml">

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Klausur, Machine Learning, Clustering, RL, German posts, " />

<meta property="og:title" content="Machine Learning 2 "/>
<meta property="og:url" content="../machine-learning-2-course/" />
<meta property="og:description" content="Dieser Artikel beschäftigt sich mit der Vorlesung „Machine Learning 2“ am KIT. Er dient als Prüfungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr. Marius Zöllner im Sommersemester 2015 gehört. Es gibt auch einen Artikel zu Machine Learning 1. Behandelter Stoff Einführung Slides: 01_Einfu__hrung_MLII.pdf Rückblick auf ML 1. MLNN …" />
<meta property="og:site_name" content="Martin Thoma" />
<meta property="og:article:author" content="Martin Thoma" />
<meta property="og:article:published_time" content="2015-05-11T11:00:00+02:00" />
<meta name="twitter:title" content="Machine Learning 2 ">
<meta name="twitter:description" content="Dieser Artikel beschäftigt sich mit der Vorlesung „Machine Learning 2“ am KIT. Er dient als Prüfungsvorbereitung. Ich habe die Vorlesungen bei Herrn Prof. Dr. Marius Zöllner im Sommersemester 2015 gehört. Es gibt auch einen Artikel zu Machine Learning 1. Behandelter Stoff Einführung Slides: 01_Einfu__hrung_MLII.pdf Rückblick auf ML 1. MLNN …">
<meta property="og:image" content="logos/klausur.png" />
<meta name="twitter:image" content="logos/klausur.png" >

        <title>Machine Learning 2  · Martin Thoma
</title>
        <!-- Latest compiled and minified CSS -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
        <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.1/css/font-awesome.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="../theme/css/pygments.css" media="screen">
        <link rel="stylesheet" type="text/css" href="../theme/tipuesearch/tipuesearch.css" media="screen">
        <link rel="stylesheet" type="text/css" href="../theme/css/elegant.css" media="screen">
        <link rel="stylesheet" type="text/css" href="../static/custom.css" media="screen">

        <!-- MathJax -->
<script type="text/x-mathjax-config">
<!--
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [ ['$$', '$$'], ['\\[','\\]']],
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
    processEscapes: true
  }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
// -->
</script>
<script type="text/javascript" async
  src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

        <link href="https://martin-thoma.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Martin Thoma - Full Atom Feed" />
        <link href="https://martin-thoma.com/feeds/index.xml" type="application/rss+xml" rel="alternate" title="Martin Thoma - Full RSS Feed" />
    </head>
    <body>
        <div id="content-sans-footer">
        <div class="navbar navbar-static-top navbar-default">
            <div class="container">
                <div class="container-fluid">
                    <div class="collapse navbar-collapse">
                        <ul class="nav pull-left top-menu navbar-nav">
                            <li><a href=".." style="font-family: 'Monaco', 'Inconsolata', 'Andale Mono', 'Lucida Console', 'Bitstream Vera Sans Mono', 'Courier New', Courier, Monospace;
                        font-size: 20px;" class="navbar-brand">Martin Thoma</a>
                            </li>
                        </ul>
                        <ul class="nav pull-right top-menu navbar-nav">
                            <li ><a href="..">Home</a></li>
                            <li ><a href="../categories.html">Categories</a></li>
                            <li ><a href="../tags.html">Tags</a></li>
                            <li ><a href="../archives.html">Archives</a></li>
                            <li><a href="../support-me/">Support me</a></li>
                            <li><form class="navbar-form" action="../search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="search" class="search-query form-control" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row">
                <div class="col-sm-1 col-md-1"></div>
                <div class="col-sm-10 col-md-10">
<article>
<div class="row">
    <header class="page-header col-sm-10 col-md-10 col-md-offset-2">
    <h1><a href="../machine-learning-2-course/"> Machine Learning 2  </a></h1>
    </header>
</div>

<div class="row">
    <div class="col-sm-2 col-md-2 table-of-content">
        <nav>
        <h4>Contents</h4>
        <div id="toc"><ul><li><a class="toc-href" href="#behandelter-stoff" title="Behandelter Stoff">Behandelter Stoff</a><ul><li><a class="toc-href" href="#einfuhrung" title="Einf&uuml;hrung">Einf&uuml;hrung</a></li><li><a class="toc-href" href="#semi-supervised-learning" title="Semi-Supervised Learning">Semi-Supervised Learning</a></li><li><a class="toc-href" href="#ssl-and-active-learning" title="SSL and Active Learning">SSL and Active Learning</a></li><li><a class="toc-href" href="#reinforcement-learning" title="Reinforcement Learning">Reinforcement Learning</a></li><li><a class="toc-href" href="#dynamische-bayessche-netze" title="Dynamische Bayessche Netze">Dynamische Bayessche Netze</a></li><li><a class="toc-href" href="#probablistisch-relationale-modelle" title="Probablistisch Relationale Modelle">Probablistisch Relationale Modelle</a></li><li><a class="toc-href" href="#gaussche-prozesse" title="Gaussche Prozesse">Gaussche Prozesse</a></li><li><a class="toc-href" href="#deep-learning" title="Deep Learning">Deep Learning</a></li><li><a class="toc-href" href="#convolutional-neural-networks" title="Convolutional Neural Networks">Convolutional Neural Networks</a></li><li><a class="toc-href" href="#spiking-neural-nets" title="Spiking Neural Nets">Spiking Neural Nets</a></li><li><a class="toc-href" href="#evaluation" title="Evaluation">Evaluation</a></li></ul></li><li><a class="toc-href" href="#prufungsfragen_1" title="Pr&uuml;fungsfragen">Pr&uuml;fungsfragen</a></li><li><a class="toc-href" href="#material-und-links" title="Material und Links">Material und Links</a></li><li><a class="toc-href" href="#literatur" title="Literatur">Literatur</a></li><li><a class="toc-href" href="#ubungsbetrieb" title="&Uuml;bungsbetrieb">&Uuml;bungsbetrieb</a></li><li><a class="toc-href" href="#vorlesungsempfehlungen" title="Vorlesungsempfehlungen">Vorlesungsempfehlungen</a></li><li><a class="toc-href" href="#kontakt" title="Kontakt">Kontakt</a></li><li><a class="toc-href" href="#termine-und-klausurablauf" title="Termine und Klausurablauf">Termine und Klausurablauf</a></li></ul></div>
        </nav>
    </div>
    <div class="col-sm-8 col-md-8 article-content" id="contentAfterTitle">

            
            <div class="info">Dieser Artikel besch&auml;ftigt sich mit der Vorlesung &bdquo;Machine Learning 2&ldquo; am KIT. Er dient als Pr&uuml;fungsvorbereitung. Ich habe die Vorlesungen bei <a href="http://tks.anthropomatik.kit.edu/21_52.php">Herrn Prof. Dr. Marius Z&ouml;llner</a> im Sommersemester&nbsp;2015 geh&ouml;rt. <br/>Es gibt auch einen Artikel zu <a href="http://martin-thoma.com/machine-learning-1-course/">Machine Learning 1</a>.</div>
<h2 id="behandelter-stoff">Behandelter Stoff</h2>
<h3 id="einfuhrung">Einf&uuml;hrung</h3>
<p>Slides: <a href="https://ilias.studium.kit.edu/ilias.php?ref_id=429607&amp;cmd=sendfile&amp;cmdClass=ilrepositorygui&amp;cmdNode=ed&amp;baseClass=ilRepositoryGUI"><code>01_Einfu__hrung_MLII.pdf</code></a></p>
<p>R&uuml;ckblick auf <a href="//martin-thoma.com/machine-learning-1-course/">ML 1</a>.
MLNN steht &uuml;brigens f&uuml;r <i>Multi-Layer Neural Network</i>.</p>
<h3 id="semi-supervised-learning">Semi-Supervised Learning</h3>
<p>Slides: <a href="https://ilias.studium.kit.edu/ilias.php?ref_id=432731&amp;cmd=sendfile&amp;cmdClass=ilrepositorygui&amp;cmdNode=ed&amp;baseClass=ilRepositoryGUI"><code>02_Semi-supervised-learning.pdf</code></a></p>
<dl>
<dt><dfn>&Uuml;berwachtes Lernen</dfn> (engl. <dfn>Supervised Learning</dfn>)</dt>
<dd>Alle Trainingsdaten liegen mit Labels vor.</dd>
<dt><dfn>Un&uuml;berwachtes Lernen</dfn> (engl. <dfn>Unsupervised Learning</dfn>)</dt>
<dd>Alle Trainingsdaten liegen ohne Labels vor.</dd>
<dt><a href="https://en.wikipedia.org/wiki/Semi-supervised_learning"><dfn>Semi-Supervised Learning</dfn></a> (<dfn>SSL</dfn>)</dt>
<dd>Die meisten Trainingsdaten liegen ohne Labels vor, jedoch gibt es f&uuml;r
      jede Klasse auch gelabelte Daten.</dd>
<dt><dfn>Self-Learning</dfn> (<dfn>Self-Training</dfn>, <dfn>Self-Labeling</dfn>, <dfn>Decision-directed learning</dfn>)</dt>
<dd><i>Self-Training</i> ist ein Algorithmus zum Semi-supervised Learning.
      Er geht wie folgt vor:
      <ol>
<li>Trainiere mit gelabelten Daten.</li>
<li>Werte ungelabelte Daten aus.</li>
<li>F&uuml;ge Daten, bei denen sich der Klassifizierer sicher ist, zu
              den Trainingsdaten hinzu.</li>
<li>Zur&uuml;ck zu Schritt&nbsp;1.</li>
</ol>

      Dabei sind folgende Variationen vorstellbar:
      <ul>
<li>F&uuml;ge alle Daten hinzu.</li>
<li>F&uuml;ge nur Daten hinzu, bei denen sich der Klassifizierer sicher ist.</li>
<li>Gewichte Daten mit der Sicherheit.</li>
</ul>
</dd>
<dt><dfn>Co-Training</dfn> (<dfn>Mit-Lernen</dfn>)</dt>
<dd><i>Co-Training</i> ist ein Algorithmus zum Semi-supervised Learning.
      Er geht wie folgt vor:
      <ol>
<li>Splitte jeden Feature-Vektor auf die gleiche Art in zwei
              Feature-Vektoren mit disjunkten Features auf.</li>
<li>Trainiere zwei unterschiedliche Klassifizierer auf den beiden
              unterschiedlichen Feature-Mengen der gelabelten Daten.</li>
<li>Label mit den beiden Klassifizieren die ungelabelten Daten.</li>
<li>F&uuml;ge ungelabelte Daten dem Trainingsdatensatz (also den
              gelabelten Daten) hinzu, falls die Klassifizierer f&uuml;r diese eine
              hohe Konfidenz aufweisen.</li>
<li>Zur&uuml;ck zu Schritt&nbsp;2.</li>
</ol>

      Dabei sind folgende Variationen vorstellbar:
      <ul>
<li>Demokratisches Voting: Bei mehr als 2&nbsp;Klassifizierern.</li>
<li>Schwellwert: Nur hinzuf&uuml;gen, wenn alle Klassifizierer jeweils
              eine Schwelle &uuml;berschreiten.</li>
<li>Gewichtes Voting: Alle Klassifizierer zusammen m&uuml;ssen eine
              Schwelle &uuml;berschreiten.</li>
</ul>
</dd>
<dt><dfn>Low Density Separation</dfn></dt>
<dd>Methoden, welche Low Density separation benutze versuchen die
      Entscheidungsgrenze in eine Region niedriger Dichte zu legen. Ein Beispiel
      ist die <i>Transductive SVM</i>.</dd>
</dl>
<p>Weiteres:</p>
<p>Hier k&ouml;nnte ich mir gut vorstellen, dass man eine Bachelor / Master-Arbeit
macht. Man k&ouml;nnte sich gro&szlig;e gelabelte Datens&auml;tze suchen, einen gewissen Teil
der Labels weglassen (also einige Trainingsdaten als "ungelabelt" behandeln)
und die verschiedenen <abbr title="Semi-Supervised Learning">SSL</abbr>-Methoden
untersuchen. Bis zu 20% gelabelte Daten hoch w&auml;re es interessant; also z.B.
(0.5%, 1%, 2%, 3%, 5%, 10%, 15%, 20% gelabelte Daten). Mit mehr gelabelten
Daten k&ouml;nnte man argumentieren, dass man es sich vermutlich leisten k&ouml;nnte auch
den Rest noch zu labeln. Siehe Folie 28-31.</p>
<h3 id="ssl-and-active-learning">SSL and Active Learning</h3>
<p>Slides: <code>03_Semi-supervised+Active-learning.pdf</code></p>
<dl>
<dt><a href="https://de.wikipedia.org/wiki/Lagrange-Multiplikator"><dfn>Lagrange-Multiplikator</dfn></a></dt>
<dd>Lagrange-Multiplikatoren sind ein Verfahren der Optimierungstheorie.
      Sie werden genutzt, wenn ein Optimierungsproblem mit Nebenbedingungen
      vorliegt. Durch sie kann die Nebenbedingung eliminiert werden.</dd>
<dt><dfn id="active-learning">Active Learning</dfn> (<dfn>Aktives Lernen</dfn>)</dt>
<dd>Die Lernmaschine w&auml;hlt die zu lernenden Daten selbst aus.<br/>
<br/>
      Verfahren:

      <ul>
<li><a href="#query-synthesis">Query Synthesis</a></li>
<li><a href="#selective-sampling">Selective Sampling</a></li>
<li><a href="#pool-based-active-learning">Pool-Based Active Learning</a></li>
<li><a href="#query-by-committee">Query-by-Committee</a></li>
</ul>
</dd>
<dt><dfn id="query-synthesis">Query Synthesis</dfn> (siehe <a href="http://burrsettles.com/pub/settles.activelearning.pdf">Active Learning Literature Survey</a>)</dt>
<dd>Der Lerner kann Feature-Vektoren (Querys)
      <a href="https://en.wikipedia.org/wiki/De_novo">de novo</a>, also von
      Grund auf neu / selbst erzeugen. Er kann f&uuml;r diesen neuen Query ein
      Orakel befragen, was das Label ist.</dd>
<dt><dfn id="selective-sampling">Selective Sampling</dfn> (Selektive Entnahme, siehe <a href="http://dl.acm.org/citation.cfm?id=2503327">Selective sampling and active learning from single and multiple teachers</a>)</dt>
<dd>Selective Sampling ist eine Methode des aktiven Lernens. Dabei wird
      jede Runde $t$ dem Lerner ein Feature-Vektor $x_t \in \mathbb{R}^n$
      pr&auml;sentiert. Der Lerner muss sich jede Runde entscheiden, ob er einen
      Preis bezahlt um das Label zu sehen. Der Lerner hat also zwei Ziele, die
      miteinander in Konflikt stehen: Er will alles richtig klassifizieren,
      aber zugleich die Kosten so niedrig wie m&ouml;glich halten.</dd>
<dt><dfn id="pool-based-active-learning">Pool-Based Active Learning</dfn></dt>
<dd>Pool-Based Active Learning ist eine Methode des aktiven Lernens. Dabei
      wird von einem Pool an ungelabelten Daten $\mathcal{U}$ ausgegangen
      und einem deutlich kleineren Pool $\mathcal{L}$ an gelabelten Daten.
      Queries werden aus $\mathcal{U}$ gezogen. Dabei wird ganz
      $\mathcal{U}$ evaluiert und f&uuml;r den hilfreichsten Feature-Vektor
      $x \in \mathcal{U}$ nach einem Label gefragt.</dd>
<dt><dfn>Hinge-Funktion</dfn></dt>
<dd>$$f(x) = \max(x, 0)$$</dd>
<dt><dfn id="query-by-committee">Query-by-Committee</dfn> (<dfn>QBC</dfn>)</dt>
<dd>Es wird ein Committee $\mathcal{C}$ an Klassifikatoren trainiert,
      welches gemeinsam (z.B. durch majority vote) eine Klassifikation trifft.

    Allgemeiner Ansatz:
    <ul>
<li>Trainiere eine Menge $\mathcal{C}$ an Klassifikatoren</li>
<li>W&auml;hle neue Daten, wenn die Hypothesen Wiederspr&uuml;chlich sind</li>
</ul>

    Selektive Entnahme:
    <ol>
<li>Beobachte neue Instanz $x$ und werte diese mit $\mathcal{C}$ aus</li>
<li>Frage das Label ab, falls es einen Wiederspruch in den Hypothesen
            von $\mathcal{C}$ f&uuml;r $x$ gibt.</li>
<li>Neu trainiren, zur&uuml;ck zu 1</li>
</ol>

    Pool-based Active Learning:
    <ol>
<li>Messung des Wiederspruchs der Hypothesen f&uuml;r alle Instanzen $x$</li>
<li>Ranking (z.B. Entropie)</li>
<li>Abfrage der Labels f&uuml;r die $k$ widerspr&uuml;chlichsten Instanzen</li>
<li>Neu trainiren, zur&uuml;ck zu 1</li>
</ol>
</dd>
</dl>
<p>Weiteres:</p>
<ul>
<li>Ausrei&szlig;erproblem: Ausrei&szlig;er sollten im QBC nicht genommen werden. Dazu k&ouml;nnte
  die Dichte im Datenraum gemessen werden.</li>
</ul>
<h3 id="reinforcement-learning">Reinforcement Learning</h3>
<p>Slides: <code>04_Reinforcement_Learning_II.pdf</code></p>
<p>Siehe auch:</p>
<ul>
<li><a href="https://martin-thoma.com/probabilistische-planung/">Probabilistische Planung</a></li>
<li><a href="https://martin-thoma.com/neuronale-netze-vorlesung/#tocAnchor-1-1-9">Neuronale Netze</a></li>
<li><a href="https://martin-thoma.com/machine-learning-1-course/#tocAnchor-1-1-4">Machine Learning 1</a></li>
<li><a href="https://github.com/MartinThoma/cat-vs-mouse">Cat vs. Mouse code</a></li>
<li>Berkeley<ul>
<li>CS188 Intro to AI: <a href="http://ai.berkeley.edu/reinforcement.html">Project 3: Reinforcement Learning</a></li>
<li>Dan Klein, Pieter Abbeel: <a href="https://www.youtube.com/watch?v=w33Lplx49_A">Lecture 10: Reinforcement Learning</a> on YouTube. University of California, Berkeley. This expalins TD-learning.</li>
</ul>
</li>
</ul>
<dl>
<dt><a href="https://de.wikipedia.org/wiki/Markow-Entscheidungsproblem"><dfn>Markov Decision Process</dfn></a> (<dfn>MDP</dfn>)</dt>
<dd>Ein Markovscher Entscheidungsprozess ist ein 5-Tupel
      $(S, A, T, r, p_0)$, wobei
      <ul>
<li>$S$ eine endliche Zustandsmenge,</li>
<li>$A$ eine endliche Menge von Aktionen,</li>
<li>$T_a(s, s') = T(s_{t+1}=s'|s_t = s, a_t = a)$ die
              Wahrscheinlichkeit zu einem beliebigen Zeitpunkt von Zustand
              $s$ mit der Aktion $a$ in den Zustand $a'$ zu kommen
              (engl. Transition),</li>
<li>$r_a(s, s')$ ist die Belohnung (Reward), die man direkt
              erh&auml;lt wenn man erh&auml;lt wenn man von Zustand $s$ mit Aktion
              $a$ in Zustand $s'$ kommt,</li>
<li>$p_0$ ist die Startverteilung auf die Zust&auml;nde $S$</li>
</ul>
</dd>
<dt><dfn>Partially observable Markov decision process</dfn> (<dfn>POMDP</dfn>)<a name="pomdp-definition"></a></dt>
<dd>Ein <i>partially observable Markov decision process</i> ist ein
      7-tupel <span markdown="0">$S, A, T, R, \Omega, O, \gamma$</span>, wobei

      <ul>
<li>$S$ die Zustandsmenge,</li>
<li>$A$ die Aktionsmenge,</li>
<li>$T: S \times A \times S \rightarrow \mathbb{R}$ die probabilisitische Zustands&uuml;bergangsfunktion (transition function) ist,</li>
<li>$R: S \times A \rightarrow \mathbb{R}$ die Reward-Funktion,</li>
<li>$\Omega$ die Menge der m&ouml;glichen Beobachtungen,</li>
<li>$O$ die Wahrscheinlichkeit der Beobachtungen, gegeben ein Zustand und eine Aktion und</li>
<li>$\gamma \in [0, 1]$ der Diskontierungsfaktor</li>
</ul>
      ist.
  </dd>
<dt><dfn>Options</dfn></dt>
<dd>Eine <i>Option</i> ist wohl-definiertes Verhalten, welches im
      hierarchischen <abbr title="Reinforcement Learning">RL</abbr> eingesetzt
      werden kann. Es ist ein Baustein f&uuml;r komplexe Pl&auml;ne.
      Options werden in Semi-MDPs eingesetzt und ersetzen dort die
      Aktionen.</dd>
<dt><dfn>Hierarchien Abstrakter Maschinen</dfn> (<dfn>HAM</dfn>)</dt>
<dd>Ein <abbr title="Markov Decision Process">MDP</abbr> wird mit
      Maschinen $\{M_i\}$ kombiniert. Jede Maschine repr&auml;sentiert einen
      Teil der Policy. Jede Maschine verwendet eigene Zust&auml;nde $m_t^i$
      und globale Zust&auml;nde $s_t$. Maschinen werden durch Zustandsautomaten
      abgebildet.</dd>
<dt><dfn>MaxQ-Dekomposition</dfn> (siehe [<a href="#ref-die00" name="ref-die00-anchor">Die00</a>])</dt>
<dd>Das zu l&ouml;sende MDP $M$ wird als Menge von Unteraufgaben $\{M_0, \dots, M_n\}$
      interpretiert. Dabei ist $M_0$ das Haupt-MDP.

      TODO.</dd>
</dl>
<p>Folie 35:</p>
<ul>
<li>NODO: Was hei&szlig;t hier "mit festen Knoten"?</li>
</ul>
<h3 id="dynamische-bayessche-netze"><a name="dynamic-bayes-networks"></a>Dynamische Bayessche Netze</h3>
<p>Slides: <code>05_DynamischeBayesscheNetze.pdf</code></p>
<dl>
<dt><a href="https://de.wikipedia.org/wiki/Bedingte_Wahrscheinlichkeit#Multiplikationssatz"><dfn>Multiplikationssatz</dfn></a></dt>
<dd>Seien $A, B, X_i$ Ereignisse. Dann gilt:
      $$P(X_1, \dots, X_n) = P(X_1) \cdot \prod_{k=2}^n P(X_k | X_{k-1}, \dots, X_1)$$
      und insbesondere
      $$P(A\cap B) = P(A, B) = P(A\mid B) \cdot P(B)$$</dd>
<dt><a href="https://de.wikipedia.org/wiki/Bedingte_Wahrscheinlichkeit#Gesetz_der_totalen_Wahrscheinlichkeit"><dfn>Gesetz der totalen Wahrscheinlichkeit</dfn></a></dt>
<dd>Seien $A_1, \dots, A_n$ paarweise disjunkte Ereignisse mit
      $A = \sum_{i=1}^n A_i$. Dann gilt f&uuml;r jedes beliebige Ereignis $B$:
      $$P(B) = \sum_{i=1}^n P(B | A_i) \cdot P(A_i) = P(A_i, B)$$</dd>
<dt><a href="https://de.wikipedia.org/wiki/Satz_von_Bayes"><dfn>Satz von Bayes</dfn></a></dt>
<dd>Seinen $A, B$ Ereignisse mit $P(B) &gt; 0$. Dann gilt
      $$P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}$$

      Hierbei hei&szlig;t $P(A|B)$ die <i>a posteriori Wahrscheinlichkeit</i>,
      $P(B|A)$ die <i>likelihood</i>, $P(A)$ die
      <i>a priori Verteilung &uuml;ber $A$</i> und $P(B)$ die
      <i>a priori Verteilung &uuml;ber $B$</i>.</dd>
<dt><a href="https://de.wikipedia.org/wiki/Bayessches_Netz"><dfn>Bayessches Netz</dfn></a> (Siehe <a href="https://www.youtube.com/watch?v=VfyxPtlqZh4">Lecture 13: Bayes Nets</a>)</dt>
<dd>Ein <i>Bayessches Netz</i> ist ein <abbr title="Directed Acyclical
      Graph">DAG</abbr>, bei dem die Knoten Zufallsvariablen und die Kanten
      bedingte Abh&auml;ngigkeiten beschreiben.

      Bayessche Netze sind zur Modellierung kausaler Zusammenh&auml;nge geeignet.</dd>
<dt><a href="https://de.wikipedia.org/wiki/Markov_Random_Field"><dfn>Markov Random Field</dfn></a></dt>
<dd>Siehe <a href="https://martin-thoma.com/machine-learning-1-course/#mrf-definition">ML 1</a></dd>
<dt><a href="https://en.wikipedia.org/wiki/Dynamic_Bayesian_network"><dfn>Dynamisches Bayessches Netz</dfn></a></dt>
<dd><i>Dynamische Bayessche Netze</i> sind Bayessche Netze zur Beschreibung
      dynamischer Prozesse.</dd>
<dt><a href="https://en.wikipedia.org/wiki/Markov_blanket"><dfn>Markov Blanket</dfn></a></dt>
<dd>Sei $G=(V,E)$ ein DAG zu einem Bayesschen Netz und $v_S \in V$.
      Dann ist der Markov Blanket die folgende Knotenmenge $B \subseteq V \setminus \{v_S\}$:

      <ul>
<li>Die Elternknoten von $v_S$ sind in $B$.</li>
<li>Die Kindknoten $K = \{v_{K_1}, \dots, v_{K_n}\}$ sind in $B$</li>
<li>Die Elternknoten von $K$, ausgenommen von $v_S$, sind in
              $B$</li>
</ul>

      Diese Knotenmenge macht $v_S$ unabh&auml;ngig von anderen Knoten.</dd>
<dt><a href="https://en.wikipedia.org/wiki/Naive_Bayes_spam_filtering"><dfn>Naive Bayes Spam Filter</dfn></a></dt>
<dd>Ein naiver Bayes Spamfilter nutzt h&auml;ufig Bag-of-Words Features. Man berechnet die Wahrscheinlichkeit,
      dass eine gegebene E-Mail Spam ist. Dazu geht man davon aus, dass die
      W&ouml;rter in einer E-Mail unabh&auml;ngig von einander sind und nutzt den
      Satz von Bayes.
      Siehe <a href="https://de.wikipedia.org/wiki/Bayes-Klassifikator#Beispiel">Bayes-Klassifikator</a>
      f&uuml;r eine detailiertere Beschreibung.</dd>
<dt><dfn id="bayes-filter">Bayes Filter</dfn></dt>
<dd>Ein Bayes Filter ist eine Familie von Zufallsvariablen. Das k&ouml;nnte z.B.
      die $(x,y,z)$ Position eines GPS-Sensors sein. Diese Position ist
      verrauscht.

      Nun gibt es drei m&ouml;gliche Anfragen:

      <ul>
<li><b>Filtern</b>: Es liegen Messungen $Z_0, \dots, Z_t$ vor,
              sage die aktuelle Position $X_t$ vorher. Also <i>filtere das
              Rauschen</i> aus $Z_t$ unter ber&uuml;cksichtigung, dass wir uns
              noch nicht teleportieren k&ouml;nnen:
              $$P(X_t | Z_t, \dots, Z_0)$$</li>
<li><b>Pr&auml;dizieren</b>: Es liegen Messungen $Z_0, \dots, Z_t$ vor,
              sage die Position $X_{t+k}$ vorher:
              $$P(X_{t+k} | Z_t, \dots, Z_0)$$</li>
<li><b>Gl&auml;tten</b>: Es liegen Messungen $Z_0, \dots, Z_t$ vor,
              sage die Position $P(X_{t-k} | Z_t, \dots, Z_0)$ vorher.</li>
</ul>

      Beispiele f&uuml;r Bayes-Filter sind

      <ul>
<li><a href="https://martin-thoma.com/kalman-filter/">Kalman-Filter</a></li>
<li><abbr title="Hidden Markov Model">HMM</abbr></li>
<li>Partikel Filter</li>
</ul>
</dd>
<dt><dfn>Naiver Bayes'scher Spam Filter</dfn></dt>
<dd>Ein probabilistischer Klassifikator welcher die Unabh&auml;ngigkeit der
      Features vorraussetzt wird <i>naiv</i> genannt.<br/>
<br/>
      Der naive bayessche Spam Filter nutzt Bayes Theorem um die
      Wahrscheinlichkeit zu berechnen, dass eine E-Mail Spam ist.
      </dd>
<dt><dfn>Kalman-Filter</dfn></dt>
<dd>Der Kalman-Filter ist ein Bayes-Filter. Er wird z.B. zum Sch&auml;tzen einer
      Fahrzeugtrajektorie eingesetzt.

      Der Kalman-Filter besteht aus zwei Schritten:

       <ul>
<li><b>Predict</b> the next step of the system given the previous
               measurements.</li>
<li><b>Update</b> the estimate of the current state given the
               measurement of this time step.</li>
</ul>

       Siehe <a href="https://martin-thoma.com/kalman-filter/">Kalman-Filter Artikel</a>
       f&uuml;r Details.
    </dd>
<dt><a href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm" name="em-algorithmus"><dfn>Expectation Maximizaion Algorithm</dfn></a> (<dfn>EM-Algorithmus</dfn>)</dt>
<dd>
        Der EM-Algorithmus ist ein Clusteringalgorithmus mit weicher
        Clusterzugeh&ouml;rigkeit. Er findet die Parameter f&uuml;r gegebene Verteilungen
        (&uuml;blicherweise multivariate Normalverteilungen).

        Er l&ouml;st das Henne-Ei Problem
        <ul>
<li>Wenn man wei&szlig; wie genau die Wahrscheinlichkeitsverteilungen
                der Cluster parametrisiert sind ist es leicht die Daten den
                Clustern zuzuordnen.</li>
<li>Wenn man die Daten einem Cluster zuordnen kann, dann ist es
                leicht die Parameter der Wahrscheinlichkeitsverteilung zu
                sch&auml;tzen.</li>
</ul>

        Wenn man sowohl Clusterzugeh&ouml;rigkeit als auch die Parameter der
        Verteilung sch&auml;tzen muss ist es schwer. Man kann "zuf&auml;llig" die
        initialen Parameter w&auml;hlen, dann die Zuordnung machen.

        Der EM-Algorithmus iteriert nach der initialisierung der Parameter:

        <ul>
<li><b>Expectation</b>: Sch&auml;tze f&uuml;r jeden Datenpunkte die
                Clusterzugeh&ouml;rigkeit.</li>
<li><strong>Maximization</strong>: Parameter der Cluster neu
                berechnen. Also f&uuml;r jeden Cluster $A$
                <ul>
<li>$\mu_A = \frac{\sum_{i=1}^N w_{i, A} \cdot x_i}{\sum_{i=1}^N w_{i, A}}$</li>
<li>$\sigma_A^2 = \frac{\sum_{i=1}^N w_{i,A} (x_i + \mu_A)^2}{\sum_{i=1}^N w_{i,A}}$</li>
</ul>
                wobei $w_{i,A}$ die Wahrscheinlichkeit der Zugeh&ouml;rigkeit des
                Punktes $i$ zu Cluster $A$ ist.
                </li>
</ul>

        Der EM-Algorithmus ist mit $k$-means verwandt.

        Siehe <a href="https://www.youtube.com/watch?v=REypj2sy_5U">Mixture Models 1: the EM algorithm</a>
</dd>
</dl>
<p>Typische Fragestellungen:</p>
<ul>
<li>Gegeben ist die Struktur eines Bayesschen Netzes: Wie lautet die Verteilung?</li>
<li>Dies wird &uuml;blicherweise mit dem <abbr title="Expectation Maximimization">EM</abbr>-Algorithmus
  gel&ouml;st.</li>
</ul>
<p>Anwendungsf&auml;lle:</p>
<ul>
<li>Automatische Diagnose, gegeben die Symptome (Bayessches Netz)</li>
<li>Fahrzeugverfolgung: Vorhersage von Routen, welche die Fahrzeuge nehmen werden
  (Dynamisches Bayessches Netz)</li>
</ul>
<p>Anmerkungen: Die Folien sind hier sehr gut! Insbesondere Folie&nbsp;14-23
sollte man sich ansehen.</p>
<p>Es scheint folgende Beziehung zu gelten: HMMs, Kalman-Filter, Extended
Kalman-Filter, Partikel Filter sind Beispiele f&uuml;r Bayes-Filter. Bayes-Filter
sind Beispiele f&uuml;r dynamische Bayessche Netze.</p>
<p>Siehe auch:</p>
<ul>
<li>Udacity: <a href="https://www.youtube.com/watch?v=8O9GV4SUToA&amp;index=77&amp;list=PLAwxTw4SYaPkCSYXw6-a_aAoXVKLDwnHK">Artificial Intelligence for Robotics</a> - good content for Kalman Filters</li>
</ul>
<ul class="gallery mw-gallery-traditional" style="max-width: 326px; width: 326px;">
<li class="gallerybox" style="width: 155px">
<div style="width: 155px">
<div class="thumb" style="width: 150px;">
<div style="margin:21px auto;height: 113px;line-height: 150px;">
<a class="image" href="../images/2016/01/tracking-robots.png">
<img alt="" src="../images/2016/01/tracking-robots.png" style="max-width: 120px; max-height: 120px;">
</img></a>
</div>
</div>
<div class="gallerytext">Tracking Robots</div>
</div>
</li>
<li class="gallerybox" style="width: 155px">
<div style="width: 155px">
<div class="thumb" style="width: 150px;">
<div style="margin:21px auto;height: 113px;line-height: 150px;">
<a class="image" href="../images/2016/01/probabilisitc-graphical-models.png">
<img alt="" src="../images/2016/01/probabilisitc-graphical-models.png" style="max-width: 120px; max-height: 120px;">
</img></a>
</div>
</div>
<div class="gallerytext">Probabilistic Graphical Models</div>
</div>
</li>
</ul>
<h3 id="probablistisch-relationale-modelle">Probablistisch Relationale Modelle</h3>
<p>Slides: <code>06_Probablistisch_Relationale_Modelle.pdf</code></p>
<p>Siehe auch:</p>
<ul>
<li>C. Howard and M. Stumptner and others. Model Construction
  Algorithms for Object-Oriented Probabilistic Relational Models. FLAIRS
  Conference, 2006.</li>
<li>C. Howard and M. Stumptner. <a href="http://ieeexplore.ieee.org/xpl/login.jsp?arnumber=1592031">Situation assessments using object oriented
  probabilistic relational models</a>,
  in 8th International Conference on Information Fusion, 2005, vol.2. doi:
  10.1109/ICIF.2005.1592031</li>
</ul>
<dl>
<dt><dfn>Objektorientierte Probablistisch Relationales Modelle</dfn> (<dfn>OPRM</dfn>)</dt>
<dd>Ein OPRM besteht nach [<a href="#ref-schu15" name="ref-schu15-anchor">Schu15</a>] aus

  <ul>
<li>Eine Klassenmenge $\mathbf{C} = \{C_1, \dots, C_n\}$,</li>
<li>einer partiellen Ordnung &uuml;ber C, welche die Klassenhierarchie definiert,</li>
<li>einer Menge einfacher, nicht probabilisitscher Attribute $\Lambda_C = \{\lambda_1, \dots, \lambda_n \forall C \in \mathbf{C}\}$,</li>
<li>einer Menge beschreibender Attribute $\Delta_C = \{\delta_1, \dots, \delta_n\} \forall C \in \mathbf{C}$,</li>
<li>einer Menge komplexer Attribute $\Phi_C = \{\phi_1, \dots, \phi_n\} \forall C \in \mathbf{C}$.
          Die komplexen Attribute beschreiben funktionale Beziehungen zwischen Klassen.</li>
</ul>

    Dieses Modell wurde in <a href="https://staff.fnwi.uva.nl/j.m.mooij/libDAI/">libDAI</a>
    umgesetzt.
  </dd>
</dl>
<h3 id="gaussche-prozesse">Gaussche Prozesse</h3>
<p>Slides: <code>07_Gaussche_Prozesse.pdf</code></p>
<p>I suggest reading the first two chapters of the online book
<a href="http://www.gaussianprocess.org/">gaussianprocess.org</a> before
starting to read the slides.</p>
<p>See also:</p>
<ul>
<li><a href="https://martin-thoma.com/function-approximation/">Function Approximation</a></li>
<li>The Talking Machines: <a href="http://www.thetalkingmachines.com/blog/2016/1/28/openai-and-gaussian-processes">OpenAI and Gaussian Processes</a></li>
</ul>
<dl>
<dt><a href="https://de.wikipedia.org/wiki/Lineare_Regression"><dfn>Lineare Regression</dfn></a></dt>
<dd>Die lineare Regression ist ein Modell zur approximation von Datenpunkten
      $(x, y) \in \mathbb{R}^n \times \mathbb{R}$ durch eine
      lineare Funktion, d.h. einer Funktion der Form $f(x) = x^T \cdot w$.
      Dabei ist $w \in \mathbb{R}^n$.<br/>
<br/>
      Wenn man als Optimierungskriterium den quadratischen Abstand
      $$E(f, data) = \sum_{(x,y) \in data} (f(x) - y)^2$$
      nimmt, dann ist eine optimale L&ouml;sung durch
      $$w = (X^T X)^{-1} X^T y$$
      gegeben.<br/>
<br/>
      Siehe auch: <a href="http://math.stackexchange.com/q/691812/6876">Proof of when is $A=X^T X$ invertible?</a>
      sowie <a href="http://math.stackexchange.com/q/1626052/6876">Does a transformation + linear regression give the same regression as fitting a quadratic function?</a>
</dd>
<dt><dfn>Affine Regression</dfn></dt>
<dd>Die affine Regression ist ein Modell zur approximation von Datenpunkten
      $(x, y) \in \mathbb{R}^n \times \mathbb{R}$ durch eine
      affine Funktion, d.h. einer Funktion der Form $f(x) = x^T \cdot w + b$.
      Dabei ist $w \in \mathbb{R}^n, b \in \mathbb{R}$. Um das Problem auf
      ein lineares zu reduzieren kann man den Feature-Vektor $x$ durch ein
      konstantes Feature $x_0 = 1$ erweitern.
      </dd>
<dt><dfn>Korrelationskoeffizient</dfn></dt>
<dd>Der Korrelationskoeffizient $\kappa(X, Y) \in [-1, 1]$ ist ein Ma&szlig; f&uuml;r
      den linearen Zusammenhang zwischen zwei Zufallsvariablen $X, Y$. Er
      ist definiert als
      $$\kappa(X, Y) := \frac{Cov(X, Y)}{\sigma(X) \cdot \sigma(Y)}$$</dd>
<dt><a href="https://de.wikipedia.org/wiki/Gau%C3%9F-Prozess"><dfn>Gausscher Prozess</dfn></a> (<dfn>Kriging</dfn>, <a href="https://www.youtube.com/watch?v=4vGiHC35j9s">Machine learning - Introduction to Gaussian processes</a> by Nando De Freitas)</dt>
<dd>Gaussche Prozesse approximieren eine Funktion dadurch, dass sie an jedem
      Punkt eine Normalverteilung (Gauss-Verteilung) annehmen.<br/>
<br/>
      Siehe <a href="https://en.wikipedia.org/wiki/Kriging">Gaussian process regression</a>.</dd>
</dl>
<h3 id="deep-learning">Deep Learning</h3>
<p>Slides: <code>08_DeepLearning.pdf</code></p>
<p>Siehe auch:</p>
<ul>
<li><a href="//martin-thoma.com/neuronale-netze-vorlesung/">Neuronale Netze Vorlesung</a></li>
<li>Udacity: <a href="https://class.coursera.org/neuralnets-2012-001/lecture">Neural Networks for Machine Learning</a> by Hinton.</li>
</ul>
<dl>
<dt><dfn>Deep Belief Netz</dfn> (<dfn>DBN</dfn>)</dt>
<dd>Ein Deep Belief Netz ist ein gerichtetes, azyklisches, probabilistisches
      graphisches Modell.</dd>
<dt><dfn>Restricted Boltzmann machine</dfn> (<dfn>RBM</dfn>)</dt>
<dd>Siehe <a href="../neuronale-netze-vorlesung/#rbm">Neuronale Netze</a></dd>
<dt><dfn>Contrastive Divergence</dfn> (<dfn>CD</dfn>, <dfn>CD-$k$</dfn>)</dt>
<dd>Siehe <a href="../neuronale-netze-vorlesung/#contrastive-divergence">Neuronale Netze</a></dd>
<dt><dfn>Contrastive Wake-Sleep Algorithm</dfn> (siehe <a href="https://www.youtube.com/watch?v=znQfKBOGnJ8">The wake-sleep algorithm</a> von Hinton - Lecture 13d aus "<a href="https://www.coursera.org/course/neuralnets">Neural Networks for Machine Learning</a>")</dt>
<dd>Der Wake-Sleep Algorithmus ist ein Trainingsalgorithmus f&uuml;r gerichtete
      graphische Modelle wie Sigmoid Belief Networks. Er ist nicht f&uuml;r RBMs.

      Man hat im Grunde zwei Netzwerke mit der gleichen Topologie, jedoch ist
      die Richtung vertauscht: Das eine Netz stellt die Hypothese aus den Daten
      auf, das andere Netz geniert neue Daten aus einer gegebenen Hypothese.

      In der <b>wake phase</b> wird die Eingabe genutzt um die Hypothese zu
      erzeugen. In dieser Phase werden die Gewichte f&uuml;r das Generative Modell
      trainiert. Dieses soll die Aktivierung der vorhergehenden Schicht
      rekonstruieren.

      In der <b>sleep phase</b> wird das generative Modell genutzt um aus dem
      Modell samples zu erzeugen. Dann trainiert man die Gewichte des
      erkennenden Netzes (also vergleichbar mit der wake phase, nur anders
      rum).

      <br/>
      Siehe <a href="http://www.cs.toronto.edu/~fritz/absps/ncfast.pdf">A Fast Learning Algorithm for Deep Belief Nets</a></dd>
</dl>
<h4 id="probleme-von-tiefen-netzen-und-wie-man-sie-losen-kann">Probleme von Tiefen Netzen und wie man sie l&ouml;sen kann:</h4>
<ul>
<li><strong>Lange Trainingsdauer</strong>: GPUs / mehr Rechenpower / weniger Parameter durch
  Parameter sharing, z.B. in <abbr title="Convolutional Neural Networks">CNNs</abbr>
  / <abbr title="Time Delay Neural Networks">TDNNs</abbr></li>
<li><strong>Extrem viele gelabelte Trainingsdaten werden ben&ouml;tigt</strong>: Internet
  (z.B. Wikipedia, Soziale Netzwerke, Amazon Mechanical Turk) reduziert dieses
  Problem; Nutzen ungelabelter Daten durch <abbr title="Semi-Supervised Learning">SSL</abbr>
  in Auto-Encodern</li>
<li><strong>Lokale Minima</strong></li>
<li><strong>Overfitting</strong>: Regularisation</li>
</ul>
<h4 id="siehe-auch">Siehe auch</h4>
<ul>
<li><a href="http://www.cs.toronto.edu/~hinton/adi/index.htm">MNIST Demo</a> (Flash):
  Neuronales Netz welches Ziffern generiert</li>
<li>Geoffry Hinton: <a href="https://www.youtube.com/watch?v=IcOMKXAw5VA">Deep Learning</a>
  on YouTube, 2015. 43&nbsp;minutes. (Topics: RBMs)</li>
</ul>
<h3 id="convolutional-neural-networks">Convolutional Neural Networks</h3>
<p>Slides: <code>09_ConvolutionalNeuralNetworks.pdf</code></p>
<p>Siehe auch: <a href="//martin-thoma.com/neuronale-netze-vorlesung/">Neuronale Netze Vorlesung</a></p>
<dl>
<dt><a href="https://de.wikipedia.org/wiki/Convolutional_Neural_Network"><dfn>Convolutional Neural Networks</dfn></a> (<dfn>CNNs</dfn>)</dt>
<dd><abbr title="Convolutional Neural Networks">CNNs</abbr> sind neuronale
      Netze welche weight sharing einsetzen. Sie setzen eine diskrete Faltung
      um. Ein CNN muss mindestens einen <i>Convolutional Layer</i> haben.
      Dieser hat folgende Parameter:
      <ul>
<li>Padding: None, Zero, Copy</li>
<li>Stride: $s \in \mathbb{N}_{&gt; 0}$</li>
<li>Filter Size: $(x,y) \in \mathbb{N}^2$</li>
<li>Number of filters: How many filters should get learned?</li>
</ul></dd>
<dt><dfn>Feature Map</dfn></dt>
<dd>Nach einem Convolutional Layer hat man die Ausgabe der Filter, welche
      auf die Eingabe angewandt wurden. Diese nennt man <i>Feature Map</i>.
      F&uuml;r jeden Filter bekommt man eine Feature Map. Die Feature Maps sind
      wiederum Eingaben f&uuml;r die n&auml;chsten Schichten.</dd>
<dt><dfn>Pooling Layer</dfn></dt>
<dd>Ein <i>pooling layer</i> ist eine Schicht in einem CNN, welche
      Features zusammenfasst. Pooling Schichten haben folgende Parameter:

      <ul>
<li>Gr&ouml;&szlig;e: Typischerweise $3 \times 3$</li>
<li>Stride $s \in \mathbb{N}$: Typischerweise gleich der Gr&ouml;&szlig;e des Pooling-Bereichs (also 3).</li>
<li>Art: max, mean</li>
</ul>

      Typischerweise reduziert sie die Anzahl der Features, da typischerweise
      ein $s &gt; 1$ gew&auml;hlt wird.</dd>
</dl>
<h3 id="spiking-neural-nets">Spiking Neural Nets</h3>
<p>Slides: <code>10_SpikingNeuralNets.pdf</code></p>
<dl>
<dt><a href="https://de.wikipedia.org/wiki/Gepulste_neuronale_Netze"><dfn>Spiking Neural Networks</dfn></a></dt>
<dd>Gepulste neuronale Netze versuchen nat&uuml;rliche neuronen realistisch
      abzubilden. Das Hodgkin-Huxley Neuronenmodell wurde bereits 1952
      vorgestellt.</dd>
<dt><dfn>Hodgkin-Huxley Neuronenmodell</dfn></dt>
<dd>Das <i>Hodgkin-Huxley Neuronenmodell</i> modelliert die elektrochemischen
      Vorg&auml;nge innerhalb eines Neurons mit elektrischen Baugliedern. Dies
      resultiert in Differenzialgleichungen mit 4&nbsp;Variablen (Kapazit&auml;t
      der Membran, Widerst&auml;nde der Ionenkan&auml;le, Gleichgewichtspotentiale,
      &Ouml;ffnung der Ionenkan&auml;le).

      Das Modell ist realistisch, aber sehr komplex. </dd>
<dt><dfn>LIF Neuronenmodell</dfn> (Leaky integrate and Fire)</dt>
<dd>Das <i>LIF Neuronenmodell</i> modelliert ein Neuron durch eine
      gew&ouml;hnliche Differentialgleichung erster Ordnung.</dd>
<dt><dfn>SRM Neuronenmodell</dfn> (Spike Response Model)</dt>
<dd>Das <i>SRM Neuronenmodell</i> modelliert die Refraktionszeit. Das ist
      die Zeit, in der kein neues Aktionspotential aufgebaut werden kann.

      Das SRM ist ein rein ph&auml;nomenologisches Modell, welches trotz der
      Einfachheit allgemeiner ist als das LIF-Modell.</dd>
</dl>
<h3 id="evaluation">Evaluation</h3>
<p>Slides: <code>11_Evaluation.pdf</code></p>
<h4 id="fur-klassifikation">F&uuml;r Klassifikation:</h4>
<dl>
<dt><a href="https://de.wikipedia.org/wiki/Konfusionsmatrix"><dfn>Konfusionsmatrix</dfn></a></dt>
<dd>Eine Konfusionsmatrix ist eine Tabelle, in welcher die Spalten angeben,
      welche Hypothese gemacht wurde (Testentscheid) und die Zeilen den wahren
      Wert angeben. So kann f&uuml;r beliebig viele Klassen gezeigt werden, wie gut
      der Klassifikator ist und welche Art der Verwechslung er macht.</dd>
<dt><dfn>Klassifikationsfehler</dfn></dt>
<dd>$\text{Klassifikationsfehler} = \frac{\text{Fehlerhafte Hypothesen}}{\text{Anzahl aller Beispiele}} \in [0, 1]$</dd>
<dt><dfn>Klassifikationsg&uuml;te</dfn></dt>
<dd>Klassifikationsg&uuml;te = 1 - Klassifikationsfehler</dd>
<dt><dfn>False Alarm Rate</dfn> (<dfn>FA</dfn>, <dfn>Falsch Positiv Rate</dfn>, <dfn>FPR</dfn>)</dt>
<dd>Es sei FP die Anzahl der False Positive Testdaten, also der Testdaten
      f&uuml;r welche <i>Positive</i> vorhergesagt wurde, die aber negative sind. Weiter
      sei TN die Anzahl der True Negatives, also der Testdaten, f&uuml;r welche
      korrekterweise negative vorhergesagt wurde.

      Dann ist die <i>FPR</i> definiert als
      $$\text{FPR} := \frac{FP}{FP + TN} \in [0, 1]$$

      Die FPR gibt also den Anteil an, wie viele der tats&auml;chlich negativen
      f&auml;lschlicherweise als positiv erkannt wurden.</dd>
<dt><dfn>Miss-Rate</dfn> (<dfn>MR</dfn>, <dfn>Falsch Negativ Rate</dfn>, <dfn>FNR</dfn>)</dt>
<dd>$$FNR := \frac{FN}{TP + FN} \in [0, 1]$$</dd>
<dt><dfn>Recall</dfn> (<dfn>True Positive Rate</dfn>, <dfn>TPR</dfn>, <dfn>Sensitivit&auml;t</dfn>)</dt>
<dd>$$TPR = \frac{TP}{TP + FN} = 1 - FNR \in [0, 1]$$

      Der Recall gibt den Anteil der erkannten positiven aus allen positiven
      an.

      <i>Sensitivit&auml;t</i> ist ein in der Medizin &uuml;blicher Begriff.</dd>
<dt><dfn>Precision</dfn> (<dfn>Genauigkeit</dfn>)</dt>
<dd>$$Precision = \frac{TP}{TP + FP} \in [0, 1]$$

      Die Precision gibt den Anteil der real positiven aus den als positiv
      erkannten an.</dd>
<dt><dfn>ROC-Graph</dfn> (<dfn>Receiver-Operator Curve</dfn>)</dt>
<dd>Der ROC-Graph gibt f&uuml;r einen Klassifikator, bei dem man einen Parameter
      einstellen kann, den Fehler an.

      Die $x$-Achse ist dabei die FPR, die $y$-Achse die TPR.</dd>
<dt><dfn>Spezifit&auml;t</dfn></dt>
<dd>Der Begriff der <i>Spezifit&auml;t</i> ist in der Medizin &uuml;blich und
      ist definiert durch
      $$Spezifit&auml;t = \frac{TN}{TN + FP} = 1 - FPR$$

      Es ist eine Art recall f&uuml;r die negative Klasse. Im Beispiel eines
      medizinischen Tests w&auml;re das der Anteil der Gesunden, bei denen
      tats&auml;chlich auch die Diagnose "Gesund" gestellt wurde.</dd>
<dt><dfn>PRC-Graph</dfn> (<dfn>Precision-Recall-Graph</dfn>)</dt>
<dd>Die $x$-Achse ist Recall, die $y$-Achse ist Precision.</dd>
<dt><dfn>F-Ma&szlig;</dfn></dt>
<dd>$$F_\alpha = \frac{precision \cdot recall}{\alpha^2 \cdot precision + recall}$$</dd>
</dl>
<p>Alternative:</p>
<ul>
<li>Aufstellen einer Kostenfunktion und optimieren nach Kosten.</li>
<li>Plotten der Anzahl der Trainingsdaten (<span markdown="0"><span class="math">\(x\)</span></span>-Achse) und des Fehlers
  (<span markdown="0"><span class="math">\(y\)</span></span>-Achse). Die Kurven sollten der Test-Fehler sowie der Trainingsfehler
  sein. Damit l&auml;sst sich absch&auml;tzen, ob mehr Trainingsdaten ohne eine
  Ver&auml;nderung des Modells hilfreich sind.</li>
</ul>
<h4 id="fur-regression">F&uuml;r Regression</h4>
<dl>
<dt><dfn>Mittlerer Quadratischer Fehler</dfn> (<dfn>MSE</dfn>, <dfn>Mean Squared Error</dfn>)</dt>
<dd>$$E(f, data) = \frac{1}{|data|} \sum_{(x, y) \in data} (f(x) - y)^2$$</dd>
<dt><dfn>Relativer Quadratischer Fehler</dfn></dt>
<dd>$$E(f, data) = \frac{\sum_{(x, y) \in data} (f(x) - y)^2}{\sum_{(x,y) \in data} (y - \mu)^2}$$</dd>
<dt><dfn>Mittlerer Absoluter Fehler</dfn></dt>
<dd>$$E(f, data) = \frac{1}{|data|} \sum_{(x, y) \in data} |f(x) - y|$$</dd>
</dl>
<h4 id="siehe-auch_1">Siehe auch</h4>
<ul>
<li><a href="https://de.wikipedia.org/wiki/Beurteilung_eines_bin&auml;ren_Klassifikators">Beurteilung eines bin&auml;ren Klassifikators</a></li>
<li><a href="https://en.wikipedia.org/wiki/False_positives_and_false_negatives">False positives and false negatives</a></li>
<li>Matt Zeiler: <a href="https://www.youtube.com/watch?v=ghEmQSxT6tw">Visualizing and Understanding Deep Neural Networks</a> on YouTube, 2015. 48 minutes.</li>
</ul>
<h2 id="prufungsfragen_1">Pr&uuml;fungsfragen</h2>
<ul>
<li>Was versteht man unter einer "Transductive SVM"?<br/>
    &rarr; Eine Transductive SVM ist eine <abbr title="Support Vector Machine">SVM</abbr>
       welche neben gelabelten Daten auch noch ungelabelte benutzt. Sie versucht
       die Trennebene durch eine Region geringer Dichte zu legen.</li>
<li>Wie lautet die Optimierungsformel der transductive SVM?<br/>
        &rarr; $$\text{minimize}_{w, b, y^*} \frac{1}{2} \|w\|^2$$
        unter den Nebenbedingungen
        $$\forall i \in 1, \dots, n: y_i (w \cdot x_i - b) \geq 1$$
        und
        $$\forall j \in 1, \dots, k: y_j^* (w \cdot x_j^* -b) \geq 1\text{ with }y_j^* \in \{-1, 1\}$$

        Dabei sind $D^* = \{x_i^* | i = 1, \dots, k\}$ ungelabelte Daten.
    </li>
<li>Was macht man im Reinforcement Learning, wenn Aktionen l&auml;nger dauern?<br/>
        &rarr; Options verwenden (TODO: Wie &auml;ndert sich die Value Iteration Formel
           nun bzgl. der Zeit?)</li>
<li>Warum hei&szlig;en POMDPs "Partially Observable"?<br/>
        &rarr; Weil der Agent zwar Feedback &uuml;ber die Umgebung bekommt, aber nicht
           direkt erf&auml;hrt in welchem Zustand er ist. Siehe
           <a href="#pomdp-definition">Definition</a>.</li>
<li>Welche Active Learning Techniken gibt es?<br/>
        &rarr; Query / Selective / Pool-based (vgl. <a href="#tocAnchor-1-1-4">Query-by-Committee</a>)</li>
<li>Wie nennt man ein instanziiertes OPRM?<br/>
        &rarr; TODO (Skelett?)</li>
<li>Wie funktioniert aktives Lernen bei SVMs?<br/>
        &rarr; Bei SVMs gibt es die Dualit&auml;t zwischen dem Feature-Space und dem
           Hypothesenraum. In dem Feature-Space stellen
           die Achsen <span markdown="0">$x_i$</span> die Features dar, Trainingsdaten Punkte sind und
           die SVM durch die Trennebene visualisiert wird. Im Hypothesenraum
           sind die Achsen <span markdown="0">$w_i$</span> zusammen der
           Normalenvektor der SVM, die verschiedenen Trennebenen der SVMs sind
           hier Punkte. Die Daten geben Bedingungen an die SVM vor, welche
           in diesem Raum als Hyperebenen dargestellt werden k&ouml;nnen. Der Margin ist
           in diesem Raum ein Kreis, der die Bedingungs-Hyperebenen ber&uuml;hrt.

           Beim aktiven lernen versucht man den Version-Space im Inneren der
           Bedungungs-Hyperebenen so schnell zu verkleinern wie m&ouml;glich.</li>
<li>Was versteht man unter Transduktivem Lernen?<br/>
        &rarr; Unter Transduktiver Inferenz versteht man das Schlie&szlig;en von
           Trainingsbeispielen direkt auf auf spezifische Testf&auml;lle.</li>
<li>Wie nennt man die Wahrscheinlichkeit des aktiellen Zustands in POMDPs?<br/>
        &rarr; Belief.</li>
</ul>
<h2 id="material-und-links">Material und Links</h2>
<ul>
<li><a href="http://tks.anthropomatik.kit.edu/28_176.php">Vorlesungswebsite</a></li>
<li><a href="https://ilias.studium.kit.edu/goto_produktiv_crs_429082.html">Ilias</a>: Ist passwortgesch&uuml;tzt</li>
<li><a href="//martin-thoma.com/machine-learning-1-course/">Zusammenfassung der Vorlesung ML 1</a></li>
</ul>
<h2 id="literatur">Literatur</h2>
<ul>
<li>[<a href="#ref-schu15-anchor" name="ref-schu15">Schu15</a>] J. Schulz.
  Erkennung von Interaktionen zwischen Verkehrsteilnehmern zur
  Verhaltenspr&auml;diktion. Masterarbeit am FZI. Karlsruhe, 2015. Man kann
  <a href="https://www.fzi.de/wir-ueber-uns/organisation/mitarbeiter/address/kuhnt/">Florian Kuhnt</a>
  um Zugang dazu fragen.</li>
<li>[<a href="#ref-die00-anchor" name="ref-die00">Die00</a>] T. Dietterich.
  <a href="https://www.jair.org/media/639/live-639-1834-jair.pdf">Hierarchical
  Reinforcement Learning with the MAXQ Value Function Decomposition</a>.
  Journal of Artificial Intelligence Research, 2000.</li>
</ul>
<h2 id="ubungsbetrieb">&Uuml;bungsbetrieb</h2>
<p>Es gibt keine &Uuml;bungsbl&auml;tter, keine &Uuml;bungen, keine Tutorien und keine
Bonuspunkte.</p>
<h2 id="vorlesungsempfehlungen">Vorlesungsempfehlungen</h2>
<p>Folgende Vorlesungen sind &auml;hnlich:</p>
<ul>
<li><a href="https://martin-thoma.com/analysetechniken-grosser-datenbestaende/">Analysetechniken gro&szlig;er Datenbest&auml;nde</a></li>
<li><a href="https://martin-thoma.com/informationsfusion/">Informationsfusion</a></li>
<li><a href="https://martin-thoma.com/machine-learning-1-course/">Machine Learning 1</a></li>
<li><a href="https://martin-thoma.com/machine-learning-2-course/">Machine Learning 2</a></li>
<li><a href="https://martin-thoma.com/mustererkennung-klausur/">Mustererkennung</a></li>
<li><a href="https://martin-thoma.com/neuronale-netze-vorlesung/">Neuronale Netze</a></li>
<li><a href="https://martin-thoma.com/lma/">Lokalisierung Mobiler Agenten</a></li>
<li><a href="https://martin-thoma.com/probabilistische-planung/">Probabilistische Planung</a></li>
</ul>
<h2 id="kontakt">Kontakt</h2>
<ul>
<li>goettl@fzi.de: Sonja G&ouml;ttl (Sekretariat, zum Anmelden zur m&uuml;ndlichen Pr&uuml;fung)</li>
</ul>
<h2 id="termine-und-klausurablauf">Termine und Klausurablauf</h2>
<p><strong>Datum</strong>: Freitag, der 29.07.2016 von 12:30-13:30 Uhr<br/>
<strong>Ort</strong>: H&ouml;rs&auml;le Hertz, Gr. HS und MTI<br/>
<strong>Zeit</strong>: 60&nbsp;min<br/>
<strong>&Uuml;bungsschein</strong>: gibt es nicht<br/>
<strong>Bonuspunkte</strong>: gibt es nicht<br/>
<strong>Ergebnisse</strong>: werden ca. 5&nbsp;-&nbsp;10&nbsp;min. nach der m&uuml;ndlichen Pr&uuml;fung gesagt<br/>
<strong>Erlaubte Hilfsmittel</strong>: keine</p>
            
            <div id="disqus_thread"></div>
<script>
    /*
    var disqus_config = function () {
        this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() {  // REQUIRED CONFIGURATION VARIABLE: EDIT THE SHORTNAME BELOW
        var d = document, s = d.createElement('script');

        s.src = '//martinthoma.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

            <hr/>
        </div>
        <section>
        <div class="col-sm-2 col-md-2" style="float:right;font-size:0.9em;">
            <h4>Published</h4>
            <time pubdate="pubdate" datetime="2015-05-11T11:00:00+02:00">Mai 11, 2015</time>
            <br/>
            by <a rel="author" class="vcard author post-author" itemprop="author" href="../author/martin-thoma/"><span class="fn" itemscope="" itemtype="https://schema.org/Person"><span itemprop="name">Martin Thoma</span></span></a>
            <h4>Category</h4>
            <a class="category-link" href="../categories.html#german-posts-ref">German posts</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="../tags.html#clustering-ref">Clustering
                    <span>4</span>
</a></li>
                <li><a href="../tags.html#klausur-ref">Klausur
                    <span>35</span>
</a></li>
                <li><a href="../tags.html#machine-learning-ref">Machine Learning
                    <span>56</span>
</a></li>
                <li><a href="../tags.html#rl-ref">RL
                    <span>6</span>
</a></li>
            </ul>
<h4>Contact</h4>
    <a href="https://twitter.com/themoosemind" title="My Twitter Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-twitter sidebar-social-links"></i></a>
    <a href="mailto:info@martin-thoma.de" title="My Email Address" class="sidebar-social-links" target="_blank">
    <i class="fa fa-envelope sidebar-social-links"></i></a>
    <a href="https://github.com/MartinThoma" title="My Github Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-github sidebar-social-links"></i></a>
    <a href="http://stackoverflow.com/users/562769/martin-thoma" title="My Stackoverflow Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-stackoverflow sidebar-social-links"></i></a>
        </div>
        </section>
</div>
</article>
                </div>
                <div class="col-sm-1 col-md-1"></div>
            </div>
        </div>
        <div id="push"></div>
    </div>
<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-subtitle"><span class="site-name">Martin Thoma</span> - A blog about Code, the Web and Cyberculture</li>
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page">Talha Mansoor</a></li>
    </ul>
</div>
</footer>        <script src="//code.jquery.com/jquery.min.js"></script>
        <!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>
        <script>
(function(){
    'use strict';

    /*
    Create intra-page links
    Requires that your headings already have an `id` attribute set (because that's what jekyll does)
    For every heading in your page, this adds a little anchor link `#` that you can click to get a permalink to the heading.
    Ignores `h1`, because you should only have one per page.
    The text content of the tag is used to generate the link, so it will fail "gracefully-ish" if you have duplicate heading text.

    Credit: https://gist.github.com/SimplGy/a229d25cdb19d7f21231
     */

    var headingNodes = [], results, link,
        tags = ['h2', 'h3', 'h4', 'h5', 'h6'];

    tags.forEach(function(tag){
        var contentTag = document.getElementById('contentAfterTitle');
      results = contentTag.getElementsByTagName(tag);
      Array.prototype.push.apply(headingNodes, results);
    });

    headingNodes.forEach(function(node){
      link = document.createElement('a');
      link.className = 'deepLink';
      link.textContent = ' ¶';
      link.href = '#' + node.getAttribute('id');
      node.appendChild(link);
    });

  })();
</script>
    </body>
    <!-- Theme: Elegant built for Pelican
    License : http://oncrashreboot.com/pelican-elegant -->
</html>