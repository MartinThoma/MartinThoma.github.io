<!DOCTYPE html>
<html lang="en">
  <!-- type: head.html -->
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    
    

    
        <meta name="thumbnail" content="//martin-thoma.com/images/logos/ai.png" />
        <meta property="og:image" content="//martin-thoma.com/images/logos/ai.png" />
    

    <meta property="og:type" content="blog"/>

    <title>Using SVMs with sklearn</title>
    <link rel="stylesheet" href="//martin-thoma.com/css/screen.css" type="text/css" media="screen" />
    <link rel="stylesheet" href="//martin-thoma.com/css/style.css" type="text/css" media="screen" />
    <link rel="stylesheet" href="//martin-thoma.com/css/pygments.css" type="text/css" media="screen" />
    <link rel="stylesheet" href="//martin-thoma.com/css/tocplus-screen.css" type="text/css" media="screen" />
    <link rel="stylesheet" href="//martin-thoma.com/css/print.css" type="text/css" media="print" />
    <link rel="stylesheet" href="//martin-thoma.com/css/handheld.css" type="text/css" media="only screen and (max-device-width: 480px)" />

    <link rel="alternate" type="application/rss+xml" title="Martin Thoma RSS Feed" href="//martin-thoma.com/feed/" /><!--TODO-->
    <link rel="shortcut icon" href="//martin-thoma.com/favicon.ico" type="image/x-icon" />

    <link rel="canonical" href="//martin-thoma.com/svm-with-sklearn" />
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:site" content="@themoosemind"/>
<meta name="twitter:creator" content="@themoosemind"/>
<meta name="twitter:title" content="Using SVMs with sklearn"/>

    <meta name="twitter:description" content="A blog about Code, the Web and Cyberculture" />


    <meta name="twitter:image" content="//martin-thoma.com/images/logos/ai.png"/>



<meta name="twitter:url" content="//martin-thoma.com/svm-with-sklearn"/>
<meta name="twitter:domain" content="Martin Thoma.com"/>


    <script type='text/javascript' src="//martin-thoma.com/js/jquery.js"></script>
    <script type='text/javascript' src="//martin-thoma.com/js/jquery-migrate.min.js"></script>
    <style type="text/css">div#toc_container {width: 275px;}</style>
    <style type="text/css" id="syntaxhighlighteranchor"></style>

<!-- MathJax -->
<script type="text/x-mathjax-config">
<!--
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [ ['$$', '$$'], ['\\[','\\]']],
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
    processEscapes: true
  }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
// -->
</script>
<script type="text/javascript" async
  src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<!-- Latest compiled and minified CSS bootstrap -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
</head>

<!-- type: post.html -->
<body>
    <div id="wrapper">
        <div id="container" class="container">
            <div class="span-16">
                <!-- type: header.html -->
<div id="header" role="banner">
    <h1><a href="//martin-thoma.com">Martin Thoma</a></h1>
    <h2 style="margin-top: 0;">A blog about Code, the Web and Cyberculture.</h2>
</div>
<nav class="navcontainer" role="navigation">
    <ul id="nav">
        <li class=""><a href="//martin-thoma.com">Home</a></li>
        <li class="page_item page-item-41 "><a href="//martin-thoma.com/author/martin-thoma/">About Me</a></li>
        <li class="page_item page-item-91 "><a href="//martin-thoma.com/imprint/">Imprint</a></li>
    </ul>
</nav>

                <div id="content">
                    <article class="post type-post format-standard hentry clearfix ">
                        <h2 class="title entry-title">Using SVMs with sklearn</h2>
                        <div class="postdate entry-date">
                            <time datetime="2016-01-14T12:25:00+01:00">
                                January
                                14th,
                                  
                                2016
                            </time>
                        </div>

                        <div class="entry" id="contentAfterTitle">
                            <p>Support Vector Machines (SVMs) is a group of powerful classifiers. In this
article, I will give a short impression of how they work. I continue
with an example how to use SVMs with sklearn.</p>

<div id="toc_container" class="toc_light_blue no_bullets">
   <p class="toc_title">Contents</p>
   <ul class="toc_list">
      <li class="toc_level-1 toc_section-1">
         <a href="#tocAnchor-1-1"><span class="tocnumber">1</span> <span class="toctext">SVM theory</span></a>
      </li>
      <li class="toc_level-1 toc_section-2">
         <a href="#tocAnchor-1-2"><span class="tocnumber">2</span> <span class="toctext">sklearn</span></a>
      </li>
      <li class="toc_level-1 toc_section-3">
         <a href="#tocAnchor-1-3"><span class="tocnumber">3</span> <span class="toctext">Results</span></a>
      </li>
      <li class="toc_level-1 toc_section-4">
         <a href="#tocAnchor-1-4"><span class="tocnumber">4</span> <span class="toctext">References</span></a>
      </li>
      <li class="toc_level-1 toc_section-5">
         <a href="#tocAnchor-1-5"><span class="tocnumber">5</span> <span class="toctext">See also</span></a>
      </li>
   </ul>
</div><h2 id="tocAnchor-1-1">SVM theory</h2>

<p><abbr title="Support Vector Machines">SVMs</abbr> can be described with
5 ideas in mind:</p>

<ol>
    <li><b>Linear, binary classifiers</b>: If data is linearly separable, it
        can be separated by a hyperplane. There is one hyperplane which
        maximizes the distance to the next datapoints (support vectors). This
        hyperplane should be taken:<br />
        <div>
          \[
          \begin{aligned}
              \text{minimize}_{\mathbf{w}, b}\,&amp;\frac{1}{2} \|\mathbf{w}\|^2\\
              \text{s.t. }&amp; \forall_{i=1}^m y_i \cdot \underbrace{(\langle \mathbf{w}, \mathbf{x}_i\rangle + b)}_{\text{Classification}} \geq 1
          \end{aligned}\]</div></li>
    <li><b>Slack variables</b>: Even if the underlying process which generates
          the features for the two classes is linearly separable, noise can
          make the data not separable. The introduction of <i>slack variables</i>
          to relax the requirement of linear separability solves
          this problem. The trade-off between accepting some errors and a more
          complex model is weighted by a parameter \(C \in \mathbb{R}_0^+\). The
          bigger \(C\), the more errors are accepted. The new optimization
          problem is:
          \[
          \begin{aligned}
              \text{minimize}_{\mathbf{w}}\,&amp;\frac{1}{2} \|\mathbf{w}\|^2 + C \cdot \sum_{i=1}^m \xi_i\\
              \text{s.t. }&amp; \forall_{i=1}^m y_i \cdot (\langle \mathbf{w}, \mathbf{x}_i\rangle + b) \geq 1 - \xi_i
          \end{aligned}\]

          Note that \(0 \le \xi_i \le 1\) means that the data point is within
          the margin, whereas \(\xi_i \ge 1\) means it is misclassified. An
          SVM with \(C &gt; 0\) is also called a <i>soft-margin SVM</i>.</li>
    <li><b>Dual Problem</b>: The primal problem is to find the normal vector \(\mathbf{w}\) and the
          bias \(b\). The dual problem is to express \(\mathbf{w}\) as a linear
          combination of the training data \(\mathbf{x}_i\):
          \[\mathbf{w} = \sum_{i=1}^m \alpha_i y_i \mathbf{x}_i\]
          where \(y_i \in \{-1, 1\}\) represents the class of the training
          example and \(\alpha_i\) are Lagrange multipliers. The usage of
          Lagrange multipliers is explained with some examples
          in [<a href="#ref-smi04" name="ref-smi04-anchor" id="ref-smi04-anchor">Smi04</a>]. The usage of the Lagrange multipliers
          \(\alpha_i\) changes the optimization problem depend on the
          \(\alpha_i\) which are weights for the feature vectors. It turns
          out that most \(\alpha_i\) will be zero. The non-zero weighted vectors
          are called <i>support vectors</i>.

          The optimization problem is now, according to [<a href="#ref-bur98" name="ref-bur98-anchor" id="ref-bur98-anchor">Bur98</a>] (a great read; if you really want to understand it I can recommend it!):
          \[
          \begin{aligned}
              \text{maximize}_{\mathbf{w}}\,&amp; \sum_{i=1}^m \alpha_i - \frac{1}{2} \sum_{i=1}^m \sum_{j=1}^m \alpha_i \alpha_j y_i y_j \langle \mathbf{x}_i, \mathbf{x}_j \rangle\\
              \text{s.t. } &amp; \forall_{i=1}^m 0 \leq \alpha_i \leq C\\
              \text{s.t. } &amp; \sum_{i=1}^m \alpha_i y_i = 0
          \end{aligned}\]</li>
    <li><b>Kernel-Trick</b>: Not every dataset is linearly separable. This problem is approached
          by transforming the feature vectors \(\mathbf{x}\) with a non-linear
          mapping \(\Phi\) into a higher dimensional (probably
          \(\infty\)-dimensional) space. As the feature vectors \(\mathbf{x}\)
          are only used within scalar product
          \(\langle \mathbf{x}_i, \mathbf{x}_j \rangle\), it is not necessary to
          do the transformation. It is enough to do the calculation
          \[K(\mathbf{x}_i, \mathbf{x}_j) = \langle \mathbf{x}_i, \mathbf{x}_j \rangle\]

          This function \(K\) is called a <i>kernel</i>. The idea of never
          explicitly transforming the vectors \(\mathbf{x}_i\) to the higher
          dimensional space is called the <i>kernel trick</i>. Common kernels
          include the polynomial kernel
          \[K_P(\mathbf{x}_i, \mathbf{x}_j) = (\langle \mathbf{x}_i, \mathbf{x}_j \rangle + r)^p\]
          of degree \(p\) and coefficient \(r\), the Gaussian <abbr title="Radial Basis Function">RBF</abbr> kernel
          \[K_{\text{Gauss}}(\mathbf{x}_i, \mathbf{x}_j) = e^{\frac{-\gamma\|\mathbf{x}_i - \mathbf{x}_j\|^2}{2 \sigma^2}}\]
          and the sigmoid kernel
          \[K_{\text{tanh}}(\mathbf{x}_i, \mathbf{x}_j) = \tanh(\gamma \langle \mathbf{x}_i, \mathbf{x}_j \rangle - r)\]
          where the parameter \(\gamma\) determines how much influence single
          training examples have.</li>
    <li><b>Multiple Classes</b>: By using the <i>one-vs-all</i> or the
        <i>one-vs-one</i> strategy it is possible to get a classifying system
        which can distinguish many classes.</li>
</ol>

<p>A nice visualization of the transformation of the data in a higher-dimensional
space was done by</p>

<p>TeamGrizzly’s channel: <a href="https://youtu.be/9NrALgHFwTo">Performing nonlinear classification via linear separation in higher dimensional space</a> on YouTube. 22.11.2010.</p>

<p>See also:</p>

<ul>
  <li><a href="http://math.stackexchange.com/a/1620256/6876">What is an example of a SVM kernel, where one implicitly uses an infinity-dimensional space?</a></li>
  <li><a href="http://stackoverflow.com/a/4630731/562769">SVM - hard or soft margins?</a></li>
</ul>

<h2 id="tocAnchor-1-2">sklearn</h2>

<p><code>sklearn</code> is the machine learning toolkit to get started for Python. It has
a very good documentation and many functions. You can find <a href="http://scikit-learn.org/stable/install.html">installation
instructions</a> on their website.</p>

<p>It also includes <a href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC"><code>sklearn.svm.SVC</code></a>.
SVC is short for <em>support vector classifier</em> and this is how you use it for
the MNIST dataset.</p>

<p>Parameters for which you might want a further explanation:</p>

<ul>
  <li><code>cache_size</code>: <a href="http://datascience.stackexchange.com/a/996/8820">datascience.stackexchange.com</a></li>
</ul>

<div class="highlighter-coderay"><div class="CodeRay">
  <div class="code"><pre><span class="line-numbers">  <a href="#n1" name="n1" id="n1">1</a></span><span style="color:#777">#!/usr/bin/env python</span>
<span class="line-numbers">  <a href="#n2" name="n2" id="n2">2</a></span>
<span class="line-numbers">  <a href="#n3" name="n3" id="n3">3</a></span><span style="color:#D42"><span style="color:black">"""</span><span></span></span>
<span class="line-numbers">  <a href="#n4" name="n4" id="n4">4</a></span><span style="color:#D42"><span></span><span>Train a SVM to categorize 28x28 pixel images into digits (MNIST dataset).</span><span></span></span>
<span class="line-numbers">  <a href="#n5" name="n5" id="n5">5</a></span><span style="color:#D42"><span></span><span style="color:black">"""</span></span>
<span class="line-numbers">  <a href="#n6" name="n6" id="n6">6</a></span>
<span class="line-numbers">  <a href="#n7" name="n7" id="n7">7</a></span><span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">numpy</span> <span style="color:#080;font-weight:bold">as</span> np
<span class="line-numbers">  <a href="#n8" name="n8" id="n8">8</a></span>
<span class="line-numbers">  <a href="#n9" name="n9" id="n9">9</a></span>
<span class="line-numbers"> <strong><a href="#n10" name="n10" id="n10">10</a></strong></span><span style="color:#080;font-weight:bold">def</span> <span style="color:#06B;font-weight:bold">main</span>():
<span class="line-numbers"> <a href="#n11" name="n11" id="n11">11</a></span>    <span style="color:#D42"><span style="color:black">"""</span><span>Orchestrate the retrival of data, training and testing.</span><span style="color:black">"""</span></span>
<span class="line-numbers"> <a href="#n12" name="n12" id="n12">12</a></span>    data = get_data()
<span class="line-numbers"> <a href="#n13" name="n13" id="n13">13</a></span>
<span class="line-numbers"> <a href="#n14" name="n14" id="n14">14</a></span>    <span style="color:#777"># Get classifier</span>
<span class="line-numbers"> <a href="#n15" name="n15" id="n15">15</a></span>    <span style="color:#080;font-weight:bold">from</span> <span style="color:#B44;font-weight:bold">sklearn.svm</span> <span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">SVC</span>
<span class="line-numbers"> <a href="#n16" name="n16" id="n16">16</a></span>    clf = SVC(probability=<span style="color:#069">False</span>,  <span style="color:#777"># cache_size=200,</span>
<span class="line-numbers"> <a href="#n17" name="n17" id="n17">17</a></span>              kernel=<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">"</span><span style="color:#D20">rbf</span><span style="color:#710">"</span></span>, C=<span style="color:#60E">2.8</span>, gamma=<span style="color:#60E">.0073</span>)
<span class="line-numbers"> <a href="#n18" name="n18" id="n18">18</a></span>
<span class="line-numbers"> <a href="#n19" name="n19" id="n19">19</a></span>    print(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">"</span><span style="color:#D20">Start fitting. This may take a while</span><span style="color:#710">"</span></span>)
<span class="line-numbers"> <strong><a href="#n20" name="n20" id="n20">20</a></strong></span>
<span class="line-numbers"> <a href="#n21" name="n21" id="n21">21</a></span>    <span style="color:#777"># take all of it - make that number lower for experiments</span>
<span class="line-numbers"> <a href="#n22" name="n22" id="n22">22</a></span>    examples = <span style="color:#369;font-weight:bold">len</span>(data[<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">train</span><span style="color:#710">'</span></span>][<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">X</span><span style="color:#710">'</span></span>])
<span class="line-numbers"> <a href="#n23" name="n23" id="n23">23</a></span>    clf.fit(data[<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">train</span><span style="color:#710">'</span></span>][<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">X</span><span style="color:#710">'</span></span>][:examples], data[<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">train</span><span style="color:#710">'</span></span>][<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">y</span><span style="color:#710">'</span></span>][:examples])
<span class="line-numbers"> <a href="#n24" name="n24" id="n24">24</a></span>
<span class="line-numbers"> <a href="#n25" name="n25" id="n25">25</a></span>    analyze(clf, data)
<span class="line-numbers"> <a href="#n26" name="n26" id="n26">26</a></span>
<span class="line-numbers"> <a href="#n27" name="n27" id="n27">27</a></span>
<span class="line-numbers"> <a href="#n28" name="n28" id="n28">28</a></span><span style="color:#080;font-weight:bold">def</span> <span style="color:#06B;font-weight:bold">analyze</span>(clf, data):
<span class="line-numbers"> <a href="#n29" name="n29" id="n29">29</a></span>    <span style="color:#D42"><span style="color:black">"""</span><span></span></span>
<span class="line-numbers"> <strong><a href="#n30" name="n30" id="n30">30</a></strong></span><span style="color:#D42"><span></span><span>    Analyze how well a classifier performs on data.</span><span></span></span>
<span class="line-numbers"> <a href="#n31" name="n31" id="n31">31</a></span><span style="color:#D42"><span></span><span></span></span>
<span class="line-numbers"> <a href="#n32" name="n32" id="n32">32</a></span><span style="color:#D42"><span></span><span>    Parameters</span><span></span></span>
<span class="line-numbers"> <a href="#n33" name="n33" id="n33">33</a></span><span style="color:#D42"><span></span><span>    ----------</span><span></span></span>
<span class="line-numbers"> <a href="#n34" name="n34" id="n34">34</a></span><span style="color:#D42"><span></span><span>    clf : classifier object</span><span></span></span>
<span class="line-numbers"> <a href="#n35" name="n35" id="n35">35</a></span><span style="color:#D42"><span></span><span>    data : dict</span><span></span></span>
<span class="line-numbers"> <a href="#n36" name="n36" id="n36">36</a></span><span style="color:#D42"><span></span><span>    </span><span style="color:black">"""</span></span>
<span class="line-numbers"> <a href="#n37" name="n37" id="n37">37</a></span>    <span style="color:#777"># Get confusion matrix</span>
<span class="line-numbers"> <a href="#n38" name="n38" id="n38">38</a></span>    <span style="color:#080;font-weight:bold">from</span> <span style="color:#B44;font-weight:bold">sklearn</span> <span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">metrics</span>
<span class="line-numbers"> <a href="#n39" name="n39" id="n39">39</a></span>    predicted = clf.predict(data[<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">test</span><span style="color:#710">'</span></span>][<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">X</span><span style="color:#710">'</span></span>])
<span class="line-numbers"> <strong><a href="#n40" name="n40" id="n40">40</a></strong></span>    print(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">"</span><span style="color:#D20">Confusion matrix:</span><span style="color:#b0b">\n</span><span style="color:#D20">%s</span><span style="color:#710">"</span></span> %
<span class="line-numbers"> <a href="#n41" name="n41" id="n41">41</a></span>          metrics.confusion_matrix(data[<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">test</span><span style="color:#710">'</span></span>][<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">y</span><span style="color:#710">'</span></span>],
<span class="line-numbers"> <a href="#n42" name="n42" id="n42">42</a></span>                                   predicted))
<span class="line-numbers"> <a href="#n43" name="n43" id="n43">43</a></span>    print(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">"</span><span style="color:#D20">Accuracy: %0.4f</span><span style="color:#710">"</span></span> % metrics.accuracy_score(data[<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">test</span><span style="color:#710">'</span></span>][<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">y</span><span style="color:#710">'</span></span>],
<span class="line-numbers"> <a href="#n44" name="n44" id="n44">44</a></span>                                                     predicted))
<span class="line-numbers"> <a href="#n45" name="n45" id="n45">45</a></span>
<span class="line-numbers"> <a href="#n46" name="n46" id="n46">46</a></span>    <span style="color:#777"># Print example</span>
<span class="line-numbers"> <a href="#n47" name="n47" id="n47">47</a></span>    try_id = <span style="color:#00D">1</span>
<span class="line-numbers"> <a href="#n48" name="n48" id="n48">48</a></span>    out = clf.predict(data[<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">test</span><span style="color:#710">'</span></span>][<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">X</span><span style="color:#710">'</span></span>][try_id])  <span style="color:#777"># clf.predict_proba</span>
<span class="line-numbers"> <a href="#n49" name="n49" id="n49">49</a></span>    print(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">"</span><span style="color:#D20">out: %s</span><span style="color:#710">"</span></span> % out)
<span class="line-numbers"> <strong><a href="#n50" name="n50" id="n50">50</a></strong></span>    size = <span style="color:#369;font-weight:bold">int</span>(<span style="color:#369;font-weight:bold">len</span>(data[<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">test</span><span style="color:#710">'</span></span>][<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">X</span><span style="color:#710">'</span></span>][try_id])**(<span style="color:#60E">0.5</span>))
<span class="line-numbers"> <a href="#n51" name="n51" id="n51">51</a></span>    view_image(data[<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">test</span><span style="color:#710">'</span></span>][<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">X</span><span style="color:#710">'</span></span>][try_id].reshape((size, size)),
<span class="line-numbers"> <a href="#n52" name="n52" id="n52">52</a></span>               data[<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">test</span><span style="color:#710">'</span></span>][<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">y</span><span style="color:#710">'</span></span>][try_id])
<span class="line-numbers"> <a href="#n53" name="n53" id="n53">53</a></span>
<span class="line-numbers"> <a href="#n54" name="n54" id="n54">54</a></span>
<span class="line-numbers"> <a href="#n55" name="n55" id="n55">55</a></span><span style="color:#080;font-weight:bold">def</span> <span style="color:#06B;font-weight:bold">view_image</span>(image, label=<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">"</span><span style="color:#710">"</span></span>):
<span class="line-numbers"> <a href="#n56" name="n56" id="n56">56</a></span>    <span style="color:#D42"><span style="color:black">"""</span><span></span></span>
<span class="line-numbers"> <a href="#n57" name="n57" id="n57">57</a></span><span style="color:#D42"><span></span><span>    View a single image.</span><span></span></span>
<span class="line-numbers"> <a href="#n58" name="n58" id="n58">58</a></span><span style="color:#D42"><span></span><span></span></span>
<span class="line-numbers"> <a href="#n59" name="n59" id="n59">59</a></span><span style="color:#D42"><span></span><span>    Parameters</span><span></span></span>
<span class="line-numbers"> <strong><a href="#n60" name="n60" id="n60">60</a></strong></span><span style="color:#D42"><span></span><span>    ----------</span><span></span></span>
<span class="line-numbers"> <a href="#n61" name="n61" id="n61">61</a></span><span style="color:#D42"><span></span><span>    image : numpy array</span><span></span></span>
<span class="line-numbers"> <a href="#n62" name="n62" id="n62">62</a></span><span style="color:#D42"><span></span><span>        Make sure this is of the shape you want.</span><span></span></span>
<span class="line-numbers"> <a href="#n63" name="n63" id="n63">63</a></span><span style="color:#D42"><span></span><span>    label : str</span><span></span></span>
<span class="line-numbers"> <a href="#n64" name="n64" id="n64">64</a></span><span style="color:#D42"><span></span><span>    </span><span style="color:black">"""</span></span>
<span class="line-numbers"> <a href="#n65" name="n65" id="n65">65</a></span>    <span style="color:#080;font-weight:bold">from</span> <span style="color:#B44;font-weight:bold">matplotlib.pyplot</span> <span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">show</span>, <span style="color:#B44;font-weight:bold">imshow</span>, <span style="color:#B44;font-weight:bold">cm</span>
<span class="line-numbers"> <a href="#n66" name="n66" id="n66">66</a></span>    print(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">"</span><span style="color:#D20">Label: %s</span><span style="color:#710">"</span></span> % label)
<span class="line-numbers"> <a href="#n67" name="n67" id="n67">67</a></span>    imshow(image, cmap=cm.gray)
<span class="line-numbers"> <a href="#n68" name="n68" id="n68">68</a></span>    show()
<span class="line-numbers"> <a href="#n69" name="n69" id="n69">69</a></span>
<span class="line-numbers"> <strong><a href="#n70" name="n70" id="n70">70</a></strong></span>
<span class="line-numbers"> <a href="#n71" name="n71" id="n71">71</a></span><span style="color:#080;font-weight:bold">def</span> <span style="color:#06B;font-weight:bold">get_data</span>():
<span class="line-numbers"> <a href="#n72" name="n72" id="n72">72</a></span>    <span style="color:#D42"><span style="color:black">"""</span><span></span></span>
<span class="line-numbers"> <a href="#n73" name="n73" id="n73">73</a></span><span style="color:#D42"><span></span><span>    Get data ready to learn with.</span><span></span></span>
<span class="line-numbers"> <a href="#n74" name="n74" id="n74">74</a></span><span style="color:#D42"><span></span><span></span></span>
<span class="line-numbers"> <a href="#n75" name="n75" id="n75">75</a></span><span style="color:#D42"><span></span><span>    Returns</span><span></span></span>
<span class="line-numbers"> <a href="#n76" name="n76" id="n76">76</a></span><span style="color:#D42"><span></span><span>    -------</span><span></span></span>
<span class="line-numbers"> <a href="#n77" name="n77" id="n77">77</a></span><span style="color:#D42"><span></span><span>    dict</span><span></span></span>
<span class="line-numbers"> <a href="#n78" name="n78" id="n78">78</a></span><span style="color:#D42"><span></span><span>    </span><span style="color:black">"""</span></span>
<span class="line-numbers"> <a href="#n79" name="n79" id="n79">79</a></span>    simple = <span style="color:#069">False</span>
<span class="line-numbers"> <strong><a href="#n80" name="n80" id="n80">80</a></strong></span>    <span style="color:#080;font-weight:bold">if</span> simple:  <span style="color:#777"># Load the simple, but similar digits dataset</span>
<span class="line-numbers"> <a href="#n81" name="n81" id="n81">81</a></span>        <span style="color:#080;font-weight:bold">from</span> <span style="color:#B44;font-weight:bold">sklearn.datasets</span> <span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">load_digits</span>
<span class="line-numbers"> <a href="#n82" name="n82" id="n82">82</a></span>        <span style="color:#080;font-weight:bold">from</span> <span style="color:#B44;font-weight:bold">sklearn.utils</span> <span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">shuffle</span>
<span class="line-numbers"> <a href="#n83" name="n83" id="n83">83</a></span>        digits = load_digits()
<span class="line-numbers"> <a href="#n84" name="n84" id="n84">84</a></span>        x = [np.array(el).flatten() <span style="color:#080;font-weight:bold">for</span> el <span style="color:#080;font-weight:bold">in</span> digits.images]
<span class="line-numbers"> <a href="#n85" name="n85" id="n85">85</a></span>        y = digits.target
<span class="line-numbers"> <a href="#n86" name="n86" id="n86">86</a></span>
<span class="line-numbers"> <a href="#n87" name="n87" id="n87">87</a></span>        <span style="color:#777"># Scale data to [-1, 1] - This is of mayor importance!!!</span>
<span class="line-numbers"> <a href="#n88" name="n88" id="n88">88</a></span>        <span style="color:#777"># In this case, I know the range and thus I can (and should) scale</span>
<span class="line-numbers"> <a href="#n89" name="n89" id="n89">89</a></span>        <span style="color:#777"># manually. However, this might not always be the case.</span>
<span class="line-numbers"> <strong><a href="#n90" name="n90" id="n90">90</a></strong></span>        <span style="color:#777"># Then try sklearn.preprocessing.MinMaxScaler or</span>
<span class="line-numbers"> <a href="#n91" name="n91" id="n91">91</a></span>        <span style="color:#777"># sklearn.preprocessing.StandardScaler</span>
<span class="line-numbers"> <a href="#n92" name="n92" id="n92">92</a></span>        x = x/<span style="color:#60E">255.0</span>*<span style="color:#00D">2</span> - <span style="color:#00D">1</span>
<span class="line-numbers"> <a href="#n93" name="n93" id="n93">93</a></span>
<span class="line-numbers"> <a href="#n94" name="n94" id="n94">94</a></span>        x, y = shuffle(x, y, random_state=<span style="color:#00D">0</span>)
<span class="line-numbers"> <a href="#n95" name="n95" id="n95">95</a></span>
<span class="line-numbers"> <a href="#n96" name="n96" id="n96">96</a></span>        <span style="color:#080;font-weight:bold">from</span> <span style="color:#B44;font-weight:bold">sklearn.cross_validation</span> <span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">train_test_split</span>
<span class="line-numbers"> <a href="#n97" name="n97" id="n97">97</a></span>        x_train, x_test, y_train, y_test = train_test_split(x, y,
<span class="line-numbers"> <a href="#n98" name="n98" id="n98">98</a></span>                                                            test_size=<span style="color:#60E">0.33</span>,
<span class="line-numbers"> <a href="#n99" name="n99" id="n99">99</a></span>                                                            random_state=<span style="color:#00D">42</span>)
<span class="line-numbers"><strong><a href="#n100" name="n100" id="n100">100</a></strong></span>        data = {<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">train</span><span style="color:#710">'</span></span>: {<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">X</span><span style="color:#710">'</span></span>: x_train,
<span class="line-numbers"><a href="#n101" name="n101" id="n101">101</a></span>                          <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">y</span><span style="color:#710">'</span></span>: y_train},
<span class="line-numbers"><a href="#n102" name="n102" id="n102">102</a></span>                <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">test</span><span style="color:#710">'</span></span>: {<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">X</span><span style="color:#710">'</span></span>: x_test,
<span class="line-numbers"><a href="#n103" name="n103" id="n103">103</a></span>                         <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">y</span><span style="color:#710">'</span></span>: y_test}}
<span class="line-numbers"><a href="#n104" name="n104" id="n104">104</a></span>    <span style="color:#080;font-weight:bold">else</span>:  <span style="color:#777"># Load the original dataset</span>
<span class="line-numbers"><a href="#n105" name="n105" id="n105">105</a></span>        <span style="color:#080;font-weight:bold">from</span> <span style="color:#B44;font-weight:bold">sklearn.datasets</span> <span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">fetch_mldata</span>
<span class="line-numbers"><a href="#n106" name="n106" id="n106">106</a></span>        <span style="color:#080;font-weight:bold">from</span> <span style="color:#B44;font-weight:bold">sklearn.utils</span> <span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">shuffle</span>
<span class="line-numbers"><a href="#n107" name="n107" id="n107">107</a></span>        mnist = fetch_mldata(<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">MNIST original</span><span style="color:#710">'</span></span>)
<span class="line-numbers"><a href="#n108" name="n108" id="n108">108</a></span>
<span class="line-numbers"><a href="#n109" name="n109" id="n109">109</a></span>        x = mnist.data
<span class="line-numbers"><strong><a href="#n110" name="n110" id="n110">110</a></strong></span>        y = mnist.target
<span class="line-numbers"><a href="#n111" name="n111" id="n111">111</a></span>
<span class="line-numbers"><a href="#n112" name="n112" id="n112">112</a></span>        <span style="color:#777"># Scale data to [-1, 1] - This is of mayor importance!!!</span>
<span class="line-numbers"><a href="#n113" name="n113" id="n113">113</a></span>        x = x/<span style="color:#60E">255.0</span>*<span style="color:#00D">2</span> - <span style="color:#00D">1</span>
<span class="line-numbers"><a href="#n114" name="n114" id="n114">114</a></span>
<span class="line-numbers"><a href="#n115" name="n115" id="n115">115</a></span>        x, y = shuffle(x, y, random_state=<span style="color:#00D">0</span>)
<span class="line-numbers"><a href="#n116" name="n116" id="n116">116</a></span>
<span class="line-numbers"><a href="#n117" name="n117" id="n117">117</a></span>        <span style="color:#080;font-weight:bold">from</span> <span style="color:#B44;font-weight:bold">sklearn.cross_validation</span> <span style="color:#080;font-weight:bold">import</span> <span style="color:#B44;font-weight:bold">train_test_split</span>
<span class="line-numbers"><a href="#n118" name="n118" id="n118">118</a></span>        x_train, x_test, y_train, y_test = train_test_split(x, y,
<span class="line-numbers"><a href="#n119" name="n119" id="n119">119</a></span>                                                            test_size=<span style="color:#60E">0.33</span>,
<span class="line-numbers"><strong><a href="#n120" name="n120" id="n120">120</a></strong></span>                                                            random_state=<span style="color:#00D">42</span>)
<span class="line-numbers"><a href="#n121" name="n121" id="n121">121</a></span>        data = {<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">train</span><span style="color:#710">'</span></span>: {<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">X</span><span style="color:#710">'</span></span>: x_train,
<span class="line-numbers"><a href="#n122" name="n122" id="n122">122</a></span>                          <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">y</span><span style="color:#710">'</span></span>: y_train},
<span class="line-numbers"><a href="#n123" name="n123" id="n123">123</a></span>                <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">test</span><span style="color:#710">'</span></span>: {<span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">X</span><span style="color:#710">'</span></span>: x_test,
<span class="line-numbers"><a href="#n124" name="n124" id="n124">124</a></span>                         <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">y</span><span style="color:#710">'</span></span>: y_test}}
<span class="line-numbers"><a href="#n125" name="n125" id="n125">125</a></span>    <span style="color:#080;font-weight:bold">return</span> data
<span class="line-numbers"><a href="#n126" name="n126" id="n126">126</a></span>
<span class="line-numbers"><a href="#n127" name="n127" id="n127">127</a></span>
<span class="line-numbers"><a href="#n128" name="n128" id="n128">128</a></span><span style="color:#080;font-weight:bold">if</span> __name__ == <span style="background-color:hsla(0,100%,50%,0.05)"><span style="color:#710">'</span><span style="color:#D20">__main__</span><span style="color:#710">'</span></span>:
<span class="line-numbers"><a href="#n129" name="n129" id="n129">129</a></span>    main()
<span class="line-numbers"><strong><a href="#n130" name="n130" id="n130">130</a></strong></span>
</pre></div>
</div>
</div>

<h2 id="tocAnchor-1-3">Results</h2>

<p>The script from above gives the following results:</p>

<table>
    <caption>Confusion matrix for an SVM classifier on the MNIST dataset</caption>
    <thead>
    <tr>
        <th></th>
        <th>0</th>
        <th>1</th>
        <th>2</th>
        <th>3</th>
        <th>4</th>
        <th>5</th>
        <th>6</th>
        <th>7</th>
        <th>8</th>
        <th>9</th>
    </tr>
    </thead>
    <tbody>
    <tr>
        <th>0</th>
        <td>2258</td>
        <td>1</td>
        <td>4</td>
        <td>1</td>
        <td>2</td>
        <td>2</td>
        <td>3</td>
        <td>1</td>
        <td>4</td>
        <td>2</td>
    </tr>
    <tr>
        <th>1</th>
        <td>1</td>
        <td>2566</td>
        <td>9</td>
        <td>1</td>
        <td>1</td>
        <td>0</td>
        <td>0</td>
        <td>7</td>
        <td>3</td>
        <td>0</td>
    </tr>
    <tr>
        <th>2</th>
        <td>4</td>
        <td>1</td>
        <td>2280</td>
        <td>5</td>
        <td>4</td>
        <td>0</td>
        <td>1</td>
        <td>9</td>
        <td>8</td>
        <td>2</td>
    </tr>
    <tr>
        <th>3</th>
        <td>0</td>
        <td>0</td>
        <td>14</td>
        <td>2304</td>
        <td>1</td>
        <td>13</td>
        <td>0</td>
        <td>6</td>
        <td>8</td>
        <td>2</td>
    </tr>
    <tr>
        <th>4</th>
        <td>2</td>
        <td>2</td>
        <td>2</td>
        <td>0</td>
        <td>2183</td>
        <td>0</td>
        <td>7</td>
        <td>5</td>
        <td>0</td>
        <td>10</td>
    </tr>
    <tr>
        <th>5</th>
        <td>4</td>
        <td>0</td>
        <td>0</td>
        <td>16</td>
        <td>3</td>
        <td>2026</td>
        <td>12</td>
        <td>1</td>
        <td>4</td>
        <td>3</td>
    </tr>
    <tr>
        <th>6</th>
        <td>7</td>
        <td>5</td>
        <td>3</td>
        <td>0</td>
        <td>5</td>
        <td>2</td>
        <td>2245</td>
        <td>0</td>
        <td>4</td>
        <td>0</td>
    </tr>
    <tr>
        <th>7</th>
        <td>1</td>
        <td>6</td>
        <td>11</td>
        <td>2</td>
        <td>5</td>
        <td>1</td>
        <td>0</td>
        <td>2373</td>
        <td>5</td>
        <td>13</td>
    </tr>
    <tr>
        <th>8</th>
        <td>3</td>
        <td>9</td>
        <td>4</td>
        <td>9</td>
        <td>4</td>
        <td>10</td>
        <td>2</td>
        <td>3</td>
        <td>2166</td>
        <td>5</td>
    </tr>
    <tr>
        <th>9</th>
        <td>3</td>
        <td>2</td>
        <td>2</td>
        <td>6</td>
        <td>19</td>
        <td>6</td>
        <td>0</td>
        <td>12</td>
        <td>10</td>
        <td>2329</td>
    </tr>
    </tbody>
</table>

<ul>
  <li>Accuracy: 98.40%</li>
  <li>Error: 1.60%</li>
</ul>

<p>Looks pretty good to me. However, note that there are much better results.
The best on <a href="http://yann.lecun.com/exdb/mnist/">the official website</a> has an
error of 0.23% and is a committee of 35 convolutional neural networks.</p>

<p>The best SVM I could find has an error of 0.56% and applies a polynomial kernel
of degree 9 as well as some preprocessing.</p>

<h2 id="tocAnchor-1-4">References</h2>

<ul>
  <li>[<a href="#ref-smi04-anchor" name="ref-smi04" id="ref-smi04">Smi04</a>] B. T. Smith, “Lagrange multipliers tutorial in the context of support
vector machines,” Memorial University of Newfoundland St. John’s,
Newfoundland, Canada, Jun. 2004.</li>
  <li>[<a href="#ref-bur98-anchor" name="ref-bur98" id="ref-bur98">Bur98</a>] C. J. Burges, “<a href="http://research.microsoft.com/pubs/67119/svmtutorial.pdf">A tutorial on support vector machines for pattern recognition</a>”, Data mining and knowledge discovery, vol. 2, no. 2, pp.
121–167, 1998.</li>
</ul>

<h2 id="tocAnchor-1-5">See also</h2>

<ul>
  <li><a href="http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html">Recognizing hand-written digits</a></li>
  <li>Trung Huynh’s tech blog: <a href="http://www.trungh.com/2013/04/digit-recognition-using-svm-in-python/">Digit Recognition using SVM in Python</a></li>
  <li><a href="http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html">Classifier comparison</a></li>
  <li><a href="http://scikit-learn.org/stable/supervised_learning.html">Supervised learning</a></li>
</ul>

                        </div>
                        <div class="postmeta">Posted in
                            
                                <a href="//martin-thoma.com/category/code/">code</a><!--TODO: Displayed category name should be upper case! -->
                             | Tags:
                            
                                
                                    <a href="//martin-thoma.com/tag/python/">Python</a>
                                
                            
                                , <a href="//martin-thoma.com/tag/machine-learning/">Machine Learning</a>
                                
                            
                                , <a href="//martin-thoma.com/tag/svm/">SVM</a>
                                
                            
                                , <a href="//martin-thoma.com/tag/classification/">Classification</a>
                                
                             by <a rel="author" class="vcard author" href="//martin-thoma.com/author/martin-thoma/"><span class="fn">Martin Thoma</span></a> on <span class="updated"><span class="value-title" title="2016-01-14 12:25:00 +0100">
                                January
                                14th
                                  ,
                                2016</span></span></div>

                            <div class="navigation clearfix">
                                <div class="alignleft">
                                
                                    &laquo; <a href="//martin-thoma.com/explaining-away/" rel="prev">Explaining Away</a>
                                
                                </div>
                                <div class="alignright">
                                
                                    <a href="//martin-thoma.com/function-approximation/" rel="next">Function Approximation</a> &raquo;
                                
                                </div>
                            </div>

                        </article>
                        <div id="respond">
                            <h3>Leave a Reply</h3>
                                <!-- comment discuss code -->
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'martinthoma'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="//disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    <!-- comment discuss code -->

                        </div>
                    </div>
                </div>
            <div class="span-8 last">
                <div id="subscriptions">
<a href="//martin-thoma.com/feed/"><img src="//martin-thoma.com/css/images/rss.png" alt="Subscribe to RSS Feed" title="Subscribe to RSS Feed" width="72" height="47" /></a>		
<a href="https://twitter.com/#!/themoosemind" title="Follow me on Twitter!"><img src="//martin-thoma.com/css/images/twitter.png" title="Follow me on Twitter!" alt="Follow me on Twitter!"  width="76" height="47" /></a>
</div>

                <div id="sidebar">
                <!-- type: searchbox.html - TODO-->
<ul>
    <li id="search">
        <div class="searchlayout">
            <form method="get" id="searchform" action="//google.com/cse" role="search">
                <input type="hidden" name="cx" value="017345337424948206369:qrnnnentkkk" />
                <input type="search" value="" name="q" id="s" placeholder="Search with Google"/>
                <input type="image" src="//martin-thoma.com/css/images/search.gif" style="border:0; vertical-align: top;" alt="search"/> 
            </form>
        </div>
    </li>
</ul>

                <div class="addthis_toolbox">   
    <div class="custom_images">
            <a href="//twitter.com/share?url=//martin-thoma.com/svm-with-sklearn&amp;hashtags=python,machine-learning,svm,classification,&amp;via=themoosemind" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/twitter.png" width="32" height="32" alt="Twitter" /></a>
            <a href="//del.icio.us/post?url=//martin-thoma.com/svm-with-sklearn&amp;title=Using%20SVMs%20with%20sklearn" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/delicious.png" width="32" height="32" alt="Delicious" /></a>
            <a href="//www.facebook.com/sharer.php?u=//martin-thoma.com/svm-with-sklearn" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/facebook.png" width="32" height="32" alt="Facebook" /></a>
            <a href="//digg.com/submit?phase=2&amp;url=//martin-thoma.com/svm-with-sklearn&amp;title=Using%20SVMs%20with%20sklearn" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/digg.png" width="32" height="32" alt="Digg" /></a>
            <a href="//www.stumbleupon.com/submit?url=//martin-thoma.com/svm-with-sklearn&amp;title=Using%20SVMs%20with%20sklearn" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/stumbleupon.png" width="32" height="32" alt="Stumbleupon" /></a>
            <a href="//plusone.google.com/_/+1/confirm?hl=en&amp;url=//martin-thoma.com/svm-with-sklearn" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/gplus.png" width="32" height="32" alt="Google Plus" /></a>
            <a href="//reddit.com/submit?url=//martin-thoma.com/svm-with-sklearn&amp;title=Using%20SVMs%20with%20sklearn" target="_blank"><img src="//martin-thoma.com/css/images/socialicons/reddit.png" width="32" height="32" alt="Reddit" /></a>
    </div>
</div>

                <ul>
                    <li id="categories-3" class="widget widget_categories">
                        <!-- type: categories -->
<h2 class="widgettitle">Categories</h2>
    <ul>
        <li class="cat-item cat-item-11"><a href="//martin-thoma.com/category/code/" title="Tipps for coding in different languages like Python oder C++.">Code</a></li>
        <li class="cat-item cat-item-21"><a href="//martin-thoma.com/category/web/" title="New emerging websites and technologies.">The Web</a></li>
        <li class="cat-item cat-item-31"><a href="//martin-thoma.com/category/cyberculture/" title="Lolcats, planking, Trollfaces, ...">Cyberculture</a></li>
        <li class="cat-item cat-item-3404"><a href="//martin-thoma.com/category/maths/" title="View all posts filed under Mathematics">Mathematics</a></li>
        <li class="cat-item cat-item-881"><a href="//martin-thoma.com/category/bits-and-bytes/" title="Sometimes posts don&#039;t fit in any category.">My bits and bytes</a></li>
        <li class="cat-item cat-item-41"><a href="//martin-thoma.com/category/deutschland/" title="[All Posts here are written in German about German topics] - Die Bahn, unsere Politik und Europa.">German posts</a></li>
	</ul>

                    </li>
                    <li id="tag_cloud-3" class="widget widget_tag_cloud">
                        <h2 class="widgettitle">Tags</h2>
                        <div class="tagcloud"><a style='font-size: 130.31%' href='//martin-thoma.com/tag/ai/' title='9 topics'>AI</a>
<a style='font-size: 102.50%' href='//martin-thoma.com/tag/algebra/' title='6 topics'>Algebra</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/assembly-language/' title='5 topics'>Assembly language</a>
<a style='font-size: 102.50%' href='//martin-thoma.com/tag/bash/' title='6 topics'>Bash</a>
<a style='font-size: 191.61%' href='//martin-thoma.com/tag/c/' title='22 topics'>C</a>
<a style='font-size: 137.54%' href='//martin-thoma.com/tag/cpp/' title='10 topics'>CPP</a>
<a style='font-size: 113.08%' href='//martin-thoma.com/tag/challenge/' title='7 topics'>Challenge</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/chrome/' title='5 topics'>Chrome</a>
<a style='font-size: 137.54%' href='//martin-thoma.com/tag/clip/' title='10 topics'>Clip</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/command-line/' title='5 topics'>Command Line</a>
<a style='font-size: 102.50%' href='//martin-thoma.com/tag/computer-science/' title='6 topics'>Computer science</a>
<a style='font-size: 122.23%' href='//martin-thoma.com/tag/digitaltechnik/' title='8 topics'>Digitaltechnik</a>
<a style='font-size: 102.50%' href='//martin-thoma.com/tag/flashgames/' title='6 topics'>Flashgames</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/geometry/' title='5 topics'>Geometry</a>
<a style='font-size: 130.31%' href='//martin-thoma.com/tag/google/' title='9 topics'>Google</a>
<a style='font-size: 122.23%' href='//martin-thoma.com/tag/google-code-jam/' title='8 topics'>Google Code Jam</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/html5/' title='5 topics'>HTML5</a>
<a style='font-size: 130.31%' href='//martin-thoma.com/tag/it-security/' title='9 topics'>IT-Security</a>
<a style='font-size: 225.38%' href='//martin-thoma.com/tag/java/' title='36 topics'>Java</a>
<a style='font-size: 102.50%' href='//martin-thoma.com/tag/javascript/' title='6 topics'>JavaScript</a>
<a style='font-size: 177.85%' href='//martin-thoma.com/tag/kit/' title='18 topics'>KIT</a>
<a style='font-size: 210.55%' href='//martin-thoma.com/tag/klausur/' title='29 topics'>Klausur</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/kogsys/' title='5 topics'>KogSys</a>
<a style='font-size: 200.38%' href='//martin-thoma.com/tag/latex/' title='25 topics'>LaTeX</a>
<a style='font-size: 177.85%' href='//martin-thoma.com/tag/linear-algebra/' title='18 topics'>Linear algebra</a>
<a style='font-size: 169.77%' href='//martin-thoma.com/tag/linux/' title='16 topics'>Linux</a>
<a style='font-size: 155.53%' href='//martin-thoma.com/tag/machine-learning/' title='13 topics'>Machine Learning</a>
<a style='font-size: 122.23%' href='//martin-thoma.com/tag/matrix/' title='8 topics'>Matrix</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/os/' title='5 topics'>OS</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/operating-systems/' title='5 topics'>Operating Systems</a>
<a style='font-size: 130.31%' href='//martin-thoma.com/tag/php/' title='9 topics'>PHP</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/physics/' title='5 topics'>Physics</a>
<a style='font-size: 237.57%' href='//martin-thoma.com/tag/programming/' title='43 topics'>Programming</a>
<a style='font-size: 130.31%' href='//martin-thoma.com/tag/project-euler/' title='9 topics'>Project Euler</a>
<a style='font-size: 270.00%' href='//martin-thoma.com/tag/python/' title='69 topics'>Python</a>
<a style='font-size: 102.50%' href='//martin-thoma.com/tag/review/' title='6 topics'>Review</a>
<a style='font-size: 130.31%' href='//martin-thoma.com/tag/swt-i/' title='9 topics'>SWT I</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/science/' title='5 topics'>Science</a>
<a style='font-size: 130.31%' href='//martin-thoma.com/tag/theoretical-computer-science/' title='9 topics'>Theoretical computer science</a>
<a style='font-size: 102.50%' href='//martin-thoma.com/tag/tikz/' title='6 topics'>Tikz</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/ubuntu/' title='5 topics'>Ubuntu</a>
<a style='font-size: 155.53%' href='//martin-thoma.com/tag/video/' title='13 topics'>Video</a>
<a style='font-size: 130.31%' href='//martin-thoma.com/tag/vimeo/' title='9 topics'>Vimeo</a>
<a style='font-size: 137.54%' href='//martin-thoma.com/tag/web-development/' title='10 topics'>Web Development</a>
<a style='font-size: 102.50%' href='//martin-thoma.com/tag/wikipedia/' title='6 topics'>Wikipedia</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/windows-7/' title='5 topics'>Windows 7</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/wolfram-alpha/' title='5 topics'>Wolfram|Alpha</a>
<a style='font-size: 144.07%' href='//martin-thoma.com/tag/youtube/' title='11 topics'>YouTube</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/advertising/' title='5 topics'>advertising</a>
<a style='font-size: 122.23%' href='//martin-thoma.com/tag/algorithms/' title='8 topics'>algorithms</a>
<a style='font-size: 113.08%' href='//martin-thoma.com/tag/analysis/' title='7 topics'>analysis</a>
<a style='font-size: 90.00%' href='//martin-thoma.com/tag/cheat-sheet/' title='5 topics'>cheat sheet</a>
<a style='font-size: 165.34%' href='//martin-thoma.com/tag/funny/' title='15 topics'>funny</a>
<a style='font-size: 165.34%' href='//martin-thoma.com/tag/learning/' title='15 topics'>learning</a>
<a style='font-size: 137.54%' href='//martin-thoma.com/tag/lecture-notes/' title='10 topics'>lecture-notes</a>
<a style='font-size: 251.91%' href='//martin-thoma.com/tag/mathematics/' title='53 topics'>mathematics</a>
<a style='font-size: 188.42%' href='//martin-thoma.com/tag/puzzle/' title='21 topics'>puzzle</a>
</div>
                    </li>
                </ul>
                </div>
            </div>
        </div><!--/container-->
            <footer id="footer">
                <a href="//martin-thoma.com"><strong>Martin Thoma</strong></a> -  A blog about Code, the Web and Cyberculture. <br />
                <div class="footer-credits">
                    <a href="http://flexithemes.com/themes/modern-style/">Modern Style</a> theme by <a href="http://flexithemes.com/">FlexiThemes</a>
                </div>
            </footer><!--/footer-->

    </div><!--/wrapper-->
<!-- type: footer -->
<!-- TOC Plus -->
<script type='text/javascript'>
/* <![CDATA[ */
var tocplus = {"visibility_show":"show","visibility_hide":"hide","width":"275px"};
/* ]]> */
</script>
<script type='text/javascript' src="//martin-thoma.com/js/tocplus-front.js"></script>
<script>
(function(){
    'use strict';

    /*
    Create intra-page links
    Requires that your headings already have an `id` attribute set (because that's what jekyll does)
    For every heading in your page, this adds a little anchor link `#` that you can click to get a permalink to the heading.
    Ignores `h1`, because you should only have one per page.
    The text content of the tag is used to generate the link, so it will fail "gracefully-ish" if you have duplicate heading text.

    Credit: https://gist.github.com/SimplGy/a229d25cdb19d7f21231
     */

    var headingNodes = [], results, link,
        tags = ['h2', 'h3', 'h4', 'h5', 'h6'];

    tags.forEach(function(tag){
        var contentTag = document.getElementById('contentAfterTitle');
      results = contentTag.getElementsByTagName(tag);
      Array.prototype.push.apply(headingNodes, results);
    });

    headingNodes.forEach(function(node){
      link = document.createElement('a');
      link.className = 'deepLink';
      link.textContent = ' ¶';
      link.href = '#' + node.getAttribute('id');
      node.appendChild(link);
    });

  })();
</script>
</body>
</html>

